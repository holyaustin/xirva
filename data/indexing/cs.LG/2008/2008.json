[{"id": "2008.00025", "submitter": "Rafael Gomes Mantovani", "authors": "Rafael Gomes Mantovani, Andr\\'e Luis Debiaso Rossi, Edesio\n  Alcoba\\c{c}a, Jadson Castro Gertrudes, Sylvio Barbon Junior, Andr\\'e Carlos\n  Ponce de Leon Ferreira de Carvalho", "title": "Rethinking Default Values: a Low Cost and Efficient Strategy to Define\n  Hyperparameters", "comments": "44 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) algorithms have been increasingly applied to problems\nfrom several different areas. Despite their growing popularity, their\npredictive performance is usually affected by the values assigned to their\nhyperparameters (HPs). As consequence, researchers and practitioners face the\nchallenge of how to set these values. Many users have limited knowledge about\nML algorithms and the effect of their HP values and, therefore, do not take\nadvantage of suitable settings. They usually define the HP values by trial and\nerror, which is very subjective, not guaranteed to find good values and\ndependent on the user experience. Tuning techniques search for HP values able\nto maximize the predictive performance of induced models for a given dataset,\nbut have the drawback of a high computational cost. Thus, practitioners use\ndefault values suggested by the algorithm developer or by tools implementing\nthe algorithm. Although default values usually result in models with acceptable\npredictive performance, different implementations of the same algorithm can\nsuggest distinct default values. To maintain a balance between tuning and using\ndefault values, we propose a strategy to generate new optimized default values.\nOur approach is grounded on a small set of optimized values able to obtain\npredictive performance values better than default settings provided by popular\ntools. After performing a large experiment and a careful analysis of the\nresults, we concluded that our approach delivers better default values.\nBesides, it leads to competitive solutions when compared to tuned values,\nmaking it easier to use and having a lower cost. We also extracted simple rules\nto guide practitioners in deciding whether to use our new methodology or a HP\ntuning approach.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 18:23:35 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 18:36:38 GMT"}, {"version": "v3", "created": "Thu, 8 Jul 2021 15:41:53 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Mantovani", "Rafael Gomes", ""], ["Rossi", "Andr\u00e9 Luis Debiaso", ""], ["Alcoba\u00e7a", "Edesio", ""], ["Gertrudes", "Jadson Castro", ""], ["Junior", "Sylvio Barbon", ""], ["de Carvalho", "Andr\u00e9 Carlos Ponce de Leon Ferreira", ""]]}, {"id": "2008.00029", "submitter": "Ben Adlam", "authors": "Ben Adlam, Jasper Snoek, and Samuel L. Smith", "title": "Cold Posteriors and Aleatoric Uncertainty", "comments": "5 pages, 3 figures", "journal-ref": "ICML workshop on Uncertainty and Robustness in Deep Learning\n  (2020)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has observed that one can outperform exact inference in Bayesian\nneural networks by tuning the \"temperature\" of the posterior on a validation\nset (the \"cold posterior\" effect). To help interpret this phenomenon, we argue\nthat commonly used priors in Bayesian neural networks can significantly\noverestimate the aleatoric uncertainty in the labels on many classification\ndatasets. This problem is particularly pronounced in academic benchmarks like\nMNIST or CIFAR, for which the quality of the labels is high. For the special\ncase of Gaussian process regression, any positive temperature corresponds to a\nvalid posterior under a modified prior, and tuning this temperature is directly\nanalogous to empirical Bayes. On classification tasks, there is no direct\nequivalence between modifying the prior and tuning the temperature, however\nreducing the temperature can lead to models which better reflect our belief\nthat one gains little information by relabeling existing examples in the\ntraining set. Therefore although cold posteriors do not always correspond to an\nexact inference procedure, we believe they may often better reflect our true\nprior beliefs.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 18:37:31 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Adlam", "Ben", ""], ["Snoek", "Jasper", ""], ["Smith", "Samuel L.", ""]]}, {"id": "2008.00030", "submitter": "Panagiotis Petsagkourakis", "authors": "Panagiotis Petsagkourakis, Ilya Orson Sandoval, Eric Bradford,\n  Federico Galvanin, Dongda Zhang and Ehecatl Antonio del Rio-Chanona", "title": "Chance Constrained Policy Optimization for Process Control and\n  Optimization", "comments": "arXiv admin note: text overlap with arXiv:2006.02750", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chemical process optimization and control are affected by 1) plant-model\nmismatch, 2) process disturbances, and 3) constraints for safe operation.\nReinforcement learning by policy optimization would be a natural way to solve\nthis due to its ability to address stochasticity, plant-model mismatch, and\ndirectly account for the effect of future uncertainty and its feedback in a\nproper closed-loop manner; all without the need of an inner optimization loop.\nOne of the main reasons why reinforcement learning has not been considered for\nindustrial processes (or almost any engineering application) is that it lacks a\nframework to deal with safety critical constraints. Present algorithms for\npolicy optimization use difficult-to-tune penalty parameters, fail to reliably\nsatisfy state constraints or present guarantees only in expectation. We propose\na chance constrained policy optimization (CCPO) algorithm which guarantees the\nsatisfaction of joint chance constraints with a high probability - which is\ncrucial for safety critical tasks. This is achieved by the introduction of\nconstraint tightening (backoffs), which are computed simultaneously with the\nfeedback policy. Backoffs are adjusted with Bayesian optimization using the\nempirical cumulative distribution function of the probabilistic constraints,\nand are therefore self-tuned. This results in a general methodology that can be\nimbued into present policy optimization algorithms to enable them to satisfy\njoint chance constraints with high probability. We present case studies that\nanalyze the performance of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 14:20:35 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 12:34:26 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Petsagkourakis", "Panagiotis", ""], ["Sandoval", "Ilya Orson", ""], ["Bradford", "Eric", ""], ["Galvanin", "Federico", ""], ["Zhang", "Dongda", ""], ["del Rio-Chanona", "Ehecatl Antonio", ""]]}, {"id": "2008.00032", "submitter": "Cristina Zuheros", "authors": "Cristina Zuheros, Eugenio Mart\\'inez-C\\'amara, Enrique Herrera-Viedma,\n  and Francisco Herrera", "title": "Sentiment Analysis based Multi-person Multi-criteria Decision Making\n  Methodology using Natural Language Processing and Deep Learning for Smarter\n  Decision Aid. Case study of restaurant choice using TripAdvisor reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision making models are constrained by taking the expert evaluations with\npre-defined numerical or linguistic terms. We claim that the use of sentiment\nanalysis will allow decision making models to consider expert evaluations in\nnatural language. Accordingly, we propose the Sentiment Analysis based\nMulti-person Multi-criteria Decision Making (SA-MpMcDM) methodology for smarter\ndecision aid, which builds the expert evaluations from their natural language\nreviews, and even from their numerical ratings if they are available. The\nSA-MpMcDM methodology incorporates an end-to-end multi-task deep learning model\nfor aspect based sentiment analysis, named DOC-ABSADeepL model, able to\nidentify the aspect categories mentioned in an expert review, and to distill\ntheir opinions and criteria. The individual evaluations are aggregated via the\nprocedure named criteria weighting through the attention of the experts. We\nevaluate the methodology in a case study of restaurant choice using TripAdvisor\nreviews, hence we build, manually annotate, and release the TripR-2020 dataset\nof restaurant reviews. We analyze the SA-MpMcDM methodology in different\nscenarios using and not using natural language and numerical evaluations. The\nanalysis shows that the combination of both sources of information results in a\nhigher quality preference vector.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 18:45:52 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 14:18:41 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Zuheros", "Cristina", ""], ["Mart\u00ednez-C\u00e1mara", "Eugenio", ""], ["Herrera-Viedma", "Enrique", ""], ["Herrera", "Francisco", ""]]}, {"id": "2008.00036", "submitter": "Fabrizio Falchi Prof.", "authors": "Tiziano Fagni, Fabrizio Falchi, Margherita Gambini, Antonio Martella,\n  Maurizio Tesconi", "title": "TweepFake: about Detecting Deepfake Tweets", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0251415", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advances in language modeling significantly improved the\ngenerative capabilities of deep neural models: in 2019 OpenAI released GPT-2, a\npre-trained language model that can autonomously generate coherent, non-trivial\nand human-like text samples. Since then, ever more powerful text generative\nmodels have been developed. Adversaries can exploit these tremendous generative\ncapabilities to enhance social bots that will have the ability to write\nplausible deepfake messages, hoping to contaminate public debate. To prevent\nthis, it is crucial to develop deepfake social media messages detection\nsystems. However, to the best of our knowledge no one has ever addressed the\ndetection of machine-generated texts on social networks like Twitter or\nFacebook. With the aim of helping the research in this detection field, we\ncollected the first dataset of \\real deepfake tweets, TweepFake. It is real in\nthe sense that each deepfake tweet was actually posted on Twitter. We collected\ntweets from a total of 23 bots, imitating 17 human accounts. The bots are based\non various generation techniques, i.e., Markov Chains, RNN, RNN+Markov, LSTM,\nGPT-2. We also randomly selected tweets from the humans imitated by the bots to\nhave an overall balanced dataset of 25,572 tweets (half human and half bots\ngenerated). The dataset is publicly available on Kaggle. Lastly, we evaluated\n13 deepfake text detection methods (based on various state-of-the-art\napproaches) to both demonstrate the challenges that Tweepfake poses and create\na solid baseline of detection techniques. We hope that TweepFake can offer the\nopportunity to tackle the deepfake detection on social media messages as well.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 19:01:13 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 16:40:26 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Fagni", "Tiziano", ""], ["Falchi", "Fabrizio", ""], ["Gambini", "Margherita", ""], ["Martella", "Antonio", ""], ["Tesconi", "Maurizio", ""]]}, {"id": "2008.00047", "submitter": "Bingyin Zhao", "authors": "Bingyin Zhao, Yingjie Lao", "title": "Class-Oriented Poisoning Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poisoning attacks on machine learning systems compromise the model\nperformance by deliberately injecting malicious samples in the training dataset\nto influence the training process. Prior works focus on either availability\nattacks (i.e., lowering the overall model accuracy) or integrity attacks (i.e.,\nenabling specific instance based backdoor). In this paper, we advance the\nadversarial objectives of the availability attacks to a per-class basis, which\nwe refer to as class-oriented poisoning attacks. We demonstrate that the\nproposed attack is capable of forcing the corrupted model to predict in two\nspecific ways: (i) classify unseen new images to a targeted \"supplanter\" class,\nand (ii) misclassify images from a \"victim\" class while maintaining the\nclassification accuracy on other non-victim classes. To maximize the\nadversarial effect, we propose a gradient-based framework that manipulates the\nlogits to retain/eliminate the desired/undesired feature information in the\ngenerated poisoning images. Using newly defined metrics at the class level, we\nillustrate the effectiveness of the proposed class-oriented poisoning attacks\non various models (e.g., LeNet-5, Vgg-9, and ResNet-50) over a wide range of\ndatasets (e.g., MNIST, CIFAR-10, and ImageNet-ILSVRC2012).\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 19:27:37 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zhao", "Bingyin", ""], ["Lao", "Yingjie", ""]]}, {"id": "2008.00051", "submitter": "Sebastian U. Stich", "authors": "Ahmad Ajalloeian and Sebastian U. Stich", "title": "On the Convergence of SGD with Biased Gradients", "comments": "Accepted to ICML 2020 Workshop \"Beyond First Order Methods in ML\n  Systems\", updated 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the complexity of biased stochastic gradient methods (SGD), where\nindividual updates are corrupted by deterministic, i.e. biased error terms. We\nderive convergence results for smooth (non-convex) functions and give improved\nrates under the Polyak-Lojasiewicz condition. We quantify how the magnitude of\nthe bias impacts the attainable accuracy and the convergence rates (sometimes\nleading to divergence).\n  Our framework covers many applications where either only biased gradient\nupdates are available, or preferred, over unbiased ones for performance\nreasons. For instance, in the domain of distributed learning, biased gradient\ncompression techniques such as top-k compression have been proposed as a tool\nto alleviate the communication bottleneck and in derivative-free optimization,\nonly biased gradient estimators can be queried. We discuss a few guiding\nexamples that show the broad applicability of our analysis.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 19:37:59 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 19:49:46 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Ajalloeian", "Ahmad", ""], ["Stich", "Sebastian U.", ""]]}, {"id": "2008.00052", "submitter": "Nadejda Drenska", "authors": "Nadejda Drenska, Jeff Calder", "title": "Online Prediction With History-Dependent Experts: The General Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.GT cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of prediction of binary sequences with expert advice in\nthe online setting, which is a classic example of online machine learning. We\ninterpret the binary sequence as the price history of a stock, and view the\npredictor as an investor, which converts the problem into a stock prediction\nproblem. In this framework, an investor, who predicts the daily movements of a\nstock, and an adversarial market, who controls the stock, play against each\nother over $N$ turns. The investor combines the predictions of $n\\geq 2$\nexperts in order to make a decision about how much to invest at each turn, and\naims to minimize their regret with respect to the best-performing expert at the\nend of the game. We consider the problem with history-dependent experts, in\nwhich each expert uses the previous $d$ days of history of the market in making\ntheir predictions. We prove that the value function for this game, rescaled\nappropriately, converges as $N\\to \\infty$ at a rate of $O(N^{-1/6})$ to the\nviscosity solution of a nonlinear degenerate elliptic PDE, which can be\nunderstood as the Hamilton-Jacobi-Issacs equation for the two-person game. As a\nresult, we are able to deduce asymptotically optimal strategies for the\ninvestor. Our results extend those established by the first author and R.V.Kohn\n[13] for $n=2$ experts and $d\\leq 4$ days of history. To appear in\nCommunications on Pure and Applied Mathematics.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 19:40:20 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 21:49:27 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Drenska", "Nadejda", ""], ["Calder", "Jeff", ""]]}, {"id": "2008.00077", "submitter": "Matheus Nunes", "authors": "Matheus Nunes and Gisele L. Pappa", "title": "Neural Architecture Search in Graph Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-61377-8", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performing analytical tasks over graph data has become increasingly\ninteresting due to the ubiquity and large availability of relational\ninformation. However, unlike images or sentences, there is no notion of\nsequence in networks. Nodes (and edges) follow no absolute order, and it is\nhard for traditional machine learning (ML) algorithms to recognize a pattern\nand generalize their predictions on this type of data. Graph Neural Networks\n(GNN) successfully tackled this problem. They became popular after the\ngeneralization of the convolution concept to the graph domain. However, they\npossess a large number of hyperparameters and their design and optimization is\ncurrently hand-made, based on heuristics or empirical intuition. Neural\nArchitecture Search (NAS) methods appear as an interesting solution to this\nproblem. In this direction, this paper compares two NAS methods for optimizing\nGNN: one based on reinforcement learning and a second based on evolutionary\nalgorithms. Results consider 7 datasets over two search spaces and show that\nboth methods obtain similar accuracies to a random search, raising the question\nof how many of the search space dimensions are actually relevant to the\nproblem.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 21:04:24 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Nunes", "Matheus", ""], ["Pappa", "Gisele L.", ""]]}, {"id": "2008.00088", "submitter": "Safa Otoum", "authors": "Safa Otoum and Burak Kantarci and Hussein Mouftah", "title": "A Comparative Study of AI-based Intrusion Detection Techniques in\n  Critical Infrastructures", "comments": "ACM Transaction on Internet Technology, 2020 22 pages, 11 Figures, 3\n  Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volunteer computing uses Internet-connected devices (laptops, PCs, smart\ndevices, etc.), in which their owners volunteer them as storage and computing\npower resources, has become an essential mechanism for resource management in\nnumerous applications. The growth of the volume and variety of data traffic in\nthe Internet leads to concerns on the robustness of cyberphysical systems\nespecially for critical infrastructures. Therefore, the implementation of an\nefficient Intrusion Detection System for gathering such sensory data has gained\nvital importance. In this paper, we present a comparative study of Artificial\nIntelligence (AI)-driven intrusion detection systems for wirelessly connected\nsensors that track crucial applications. Specifically, we present an in-depth\nanalysis of the use of machine learning, deep learning and reinforcement\nlearning solutions to recognize intrusive behavior in the collected traffic. We\nevaluate the proposed mechanisms by using KD'99 as real attack data-set in our\nsimulations. Results present the performance metrics for three different IDSs\nnamely the Adaptively Supervised and Clustered Hybrid IDS (ASCH-IDS),\nRestricted Boltzmann Machine-based Clustered IDS (RBC-IDS) and Q-learning based\nIDS (QL-IDS) to detect malicious behaviors. We also present the performance of\ndifferent reinforcement learning techniques such as\nState-Action-Reward-State-Action Learning (SARSA) and the Temporal Difference\nlearning (TD). Through simulations, we show that QL-IDS performs with 100%\ndetection rate while SARSA-IDS and TD-IDS perform at the order of 99.5%.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 20:55:57 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Otoum", "Safa", ""], ["Kantarci", "Burak", ""], ["Mouftah", "Hussein", ""]]}, {"id": "2008.00103", "submitter": "Peter Christen", "authors": "David J. Hand, Peter Christen, Nishadi Kirielle", "title": "F*: An Interpretable Transformation of the F-measure", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The F-measure, also known as the F1-score, is widely used to assess the\nperformance of classification algorithms. However, some researchers find it\nlacking in intuitive interpretation, questioning the appropriateness of\ncombining two aspects of performance as conceptually distinct as precision and\nrecall, and also questioning whether the harmonic mean is the best way to\ncombine them. To ease this concern, we describe a simple transformation of the\nF-measure, which we call F* (F-star), which has an immediate practical\ninterpretation.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 22:37:08 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 22:26:20 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 02:03:47 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Hand", "David J.", ""], ["Christen", "Peter", ""], ["Kirielle", "Nishadi", ""]]}, {"id": "2008.00104", "submitter": "Elliot Creager", "authors": "Martin Mladenov, Elliot Creager, Omer Ben-Porat, Kevin Swersky,\n  Richard Zemel, Craig Boutilier", "title": "Optimizing Long-term Social Welfare in Recommender Systems: A\n  Constrained Matching Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most recommender systems (RS) research assumes that a user's utility can be\nmaximized independently of the utility of the other agents (e.g., other users,\ncontent providers). In realistic settings, this is often not true---the\ndynamics of an RS ecosystem couple the long-term utility of all agents. In this\nwork, we explore settings in which content providers cannot remain viable\nunless they receive a certain level of user engagement. We formulate the\nrecommendation problem in this setting as one of equilibrium selection in the\ninduced dynamical system, and show that it can be solved as an optimal\nconstrained matching problem. Our model ensures the system reaches an\nequilibrium with maximal social welfare supported by a sufficiently diverse set\nof viable providers. We demonstrate that even in a simple, stylized dynamical\nRS model, the standard myopic approach to recommendation---always matching a\nuser to the best provider---performs poorly. We develop several scalable\ntechniques to solve the matching problem, and also draw connections to various\nnotions of user regret and fairness, arguing that these outcomes are fairer in\na utilitarian sense.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 22:40:47 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 20:57:28 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Mladenov", "Martin", ""], ["Creager", "Elliot", ""], ["Ben-Porat", "Omer", ""], ["Swersky", "Kevin", ""], ["Zemel", "Richard", ""], ["Boutilier", "Craig", ""]]}, {"id": "2008.00113", "submitter": "Shakila Khan Rumi", "authors": "Shakila Khan Rumi, Kyle K. Qin, Flora D. Salim", "title": "Multi-officer Routing for Patrolling High Risk Areas Jointly Learned\n  from Check-ins, Crime and Incident Response Data", "comments": "21 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well-crafted police patrol route design is vital in providing community\nsafety and security in the society. Previous works have largely focused on\npredicting crime events with historical crime data. The usage of large-scale\nmobility data collected from Location-Based Social Network, or check-ins, and\nPoint of Interests (POI) data for designing an effective police patrol is\nlargely understudied. Given that there are multiple police officers being on\nduty in a real-life situation, this makes the problem more complex to solve. In\nthis paper, we formulate the dynamic crime patrol planning problem for multiple\npolice officers using check-ins, crime, incident response data, and POI\ninformation. We propose a joint learning and non-random optimisation method for\nthe representation of possible solutions where multiple police officers patrol\nthe high crime risk areas simultaneously first rather than the low crime risk\nareas. Later, meta-heuristic Genetic Algorithm (GA) and Cuckoo Search (CS) are\nimplemented to find the optimal routes. The performance of the proposed\nsolution is verified and compared with several state-of-art methods using\nreal-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 23:33:14 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Rumi", "Shakila Khan", ""], ["Qin", "Kyle K.", ""], ["Salim", "Flora D.", ""]]}, {"id": "2008.00115", "submitter": "Chao Fan", "authors": "Ankit Ramchandani, Chao Fan, Ali Mostafavi", "title": "DeepCOVIDNet: An Interpretable Deep Learning Model for Predictive\n  Surveillance of COVID-19 Using Heterogeneous Features and their Interactions", "comments": "16 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a deep learning model to forecast the range of\nincrease in COVID-19 infected cases in future days and we present a novel\nmethod to compute equidimensional representations of multivariate time series\nand multivariate spatial time series data. Using this novel method, the\nproposed model can both take in a large number of heterogeneous features, such\nas census data, intra-county mobility, inter-county mobility, social distancing\ndata, past growth of infection, among others, and learn complex interactions\nbetween these features. Using data collected from various sources, we estimate\nthe range of increase in infected cases seven days into the future for all U.S.\ncounties. In addition, we use the model to identify the most influential\nfeatures for prediction of the growth of infection. We also analyze pairs of\nfeatures and estimate the amount of observed second-order interaction between\nthem. Experiments show that the proposed model obtains satisfactory predictive\nperformance and fairly interpretable feature analysis results; hence, the\nproposed model could complement the standard epidemiological models for\nnational-level surveillance of pandemics, such as COVID-19. The results and\nfindings obtained from the deep learning model could potentially inform\npolicymakers and researchers in devising effective mitigation and response\nstrategies. To fast-track further development and experimentation, the code\nused to implement the proposed model has been made fully open source.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 23:37:38 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Ramchandani", "Ankit", ""], ["Fan", "Chao", ""], ["Mostafavi", "Ali", ""]]}, {"id": "2008.00118", "submitter": "James Stokes", "authors": "James Stokes, Javier Robledo Moreno, Eftychios A. Pnevmatikakis,\n  Giuseppe Carleo", "title": "Phases of two-dimensional spinless lattice fermions with first-quantized\n  deep neural-network quantum states", "comments": null, "journal-ref": "Phys. Rev. B 102, 205122 (2020)", "doi": "10.1103/PhysRevB.102.205122", "report-no": null, "categories": "cond-mat.str-el cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First-quantized deep neural network techniques are developed for analyzing\nstrongly coupled fermionic systems on the lattice. Using a Slater-Jastrow\ninspired ansatz which exploits deep residual networks with convolutional\nresidual blocks, we approximately determine the ground state of spinless\nfermions on a square lattice with nearest-neighbor interactions. The\nflexibility of the neural-network ansatz results in a high level of accuracy\nwhen compared to exact diagonalization results on small systems, both for\nenergy and correlation functions. On large systems, we obtain accurate\nestimates of the boundaries between metallic and charge ordered phases as a\nfunction of the interaction strength and the particle density.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 23:43:52 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Stokes", "James", ""], ["Moreno", "Javier Robledo", ""], ["Pnevmatikakis", "Eftychios A.", ""], ["Carleo", "Giuseppe", ""]]}, {"id": "2008.00123", "submitter": "Dane Taylor", "authors": "N. Benjamin Erichson, Dane Taylor, Qixuan Wu and Michael W. Mahoney", "title": "Noise-Response Analysis of Deep Neural Networks Quantifies Robustness\n  and Fingerprints Structural Malware", "comments": "9 pages, 7 figures, accepted to the SIAM International Conference on\n  Data Mining (SDM 21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquity of deep neural networks (DNNs), cloud-based training, and\ntransfer learning is giving rise to a new cybersecurity frontier in which\nunsecure DNNs have `structural malware' (i.e., compromised weights and\nactivation pathways). In particular, DNNs can be designed to have backdoors\nthat allow an adversary to easily and reliably fool an image classifier by\nadding a pattern of pixels called a trigger. It is generally difficult to\ndetect backdoors, and existing detection methods are computationally expensive\nand require extensive resources (e.g., access to the training data). Here, we\npropose a rapid feature-generation technique that quantifies the robustness of\na DNN, `fingerprints' its nonlinearity, and allows us to detect backdoors (if\npresent). Our approach involves studying how a DNN responds to noise-infused\nimages with varying noise intensity, which we summarize with titration curves.\nWe find that DNNs with backdoors are more sensitive to input noise and respond\nin a characteristic way that reveals the backdoor and where it leads (its\n`target'). Our empirical results demonstrate that we can accurately detect\nbackdoors with high confidence orders-of-magnitude faster than existing\napproaches (seconds versus hours).\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 23:52:58 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 19:51:30 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Erichson", "N. Benjamin", ""], ["Taylor", "Dane", ""], ["Wu", "Qixuan", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2008.00138", "submitter": "Alexander Wong", "authors": "Hossein Aboutalebi, Mohammad Javad Shafiee, Michelle Karg, Christian\n  Scharfenberger, and Alexander Wong", "title": "Vulnerability Under Adversarial Machine Learning: Bias or Variance?", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior studies have unveiled the vulnerability of the deep neural networks in\nthe context of adversarial machine learning, leading to great recent attention\ninto this area. One interesting question that has yet to be fully explored is\nthe bias-variance relationship of adversarial machine learning, which can\npotentially provide deeper insights into this behaviour. The notion of bias and\nvariance is one of the main approaches to analyze and evaluate the\ngeneralization and reliability of a machine learning model. Although it has\nbeen extensively used in other machine learning models, it is not well explored\nin the field of deep learning and it is even less explored in the area of\nadversarial machine learning.\n  In this study, we investigate the effect of adversarial machine learning on\nthe bias and variance of a trained deep neural network and analyze how\nadversarial perturbations can affect the generalization of a network. We derive\nthe bias-variance trade-off for both classification and regression applications\nbased on two main loss functions: (i) mean squared error (MSE), and (ii)\ncross-entropy. Furthermore, we perform quantitative analysis with both\nsimulated and real data to empirically evaluate consistency with the derived\nbias-variance tradeoffs. Our analysis sheds light on why the deep neural\nnetworks have poor performance under adversarial perturbation from a\nbias-variance point of view and how this type of perturbation would change the\nperformance of a network. Moreover, given these new theoretical findings, we\nintroduce a new adversarial machine learning algorithm with lower computational\ncomplexity than well-known adversarial machine learning strategies (e.g., PGD)\nwhile providing a high success rate in fooling deep neural networks in lower\nperturbation magnitudes.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 00:58:54 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Aboutalebi", "Hossein", ""], ["Shafiee", "Mohammad Javad", ""], ["Karg", "Michelle", ""], ["Scharfenberger", "Christian", ""], ["Wong", "Alexander", ""]]}, {"id": "2008.00151", "submitter": "Takanori Fujiwara", "authors": "Takanori Fujiwara, Jian Zhao, Francine Chen, Kwan-Liu Ma", "title": "A Visual Analytics Framework for Contrastive Network Analysis", "comments": "To appear in IEEE Conference on Visual Analytics Science and\n  Technology (VAST) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.GR cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common network analysis task is comparison of two networks to identify\nunique characteristics in one network with respect to the other. For example,\nwhen comparing protein interaction networks derived from normal and cancer\ntissues, one essential task is to discover protein-protein interactions unique\nto cancer tissues. However, this task is challenging when the networks contain\ncomplex structural (and semantic) relations. To address this problem, we design\nContraNA, a visual analytics framework leveraging both the power of machine\nlearning for uncovering unique characteristics in networks and also the\neffectiveness of visualization for understanding such uniqueness. The basis of\nContraNA is cNRL, which integrates two machine learning schemes, network\nrepresentation learning (NRL) and contrastive learning (CL), to generate a\nlow-dimensional embedding that reveals the uniqueness of one network when\ncompared to another. ContraNA provides an interactive visualization interface\nto help analyze the uniqueness by relating embedding results and network\nstructures as well as explaining the learned features by cNRL. We demonstrate\nthe usefulness of ContraNA with two case studies using real-world datasets. We\nalso evaluate through a controlled user study with 12 participants on network\ncomparison tasks. The results show that participants were able to both\neffectively identify unique characteristics from complex networks and interpret\nthe results obtained from cNRL.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 02:18:10 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 01:46:51 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Fujiwara", "Takanori", ""], ["Zhao", "Jian", ""], ["Chen", "Francine", ""], ["Ma", "Kwan-Liu", ""]]}, {"id": "2008.00157", "submitter": "Flavio de Barros Vidal", "authors": "Ana Paula G. S. de Almeida and Flavio de Barros Vidal", "title": "L-CNN: A Lattice cross-fusion strategy for multistream convolutional\n  neural networks", "comments": "5 pages, 3 figures", "journal-ref": "Electronics Letters, vol. 55, no. 22, pp. 1180-1182, 2029", "doi": "10.1049/el.2019.2631", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a fusion strategy for multistream convolutional networks,\nthe Lattice Cross Fusion. This approach crosses signals from convolution layers\nperforming mathematical operation-based fusions right before pooling layers.\nResults on a purposely worsened CIFAR-10, a popular image classification data\nset, with a modified AlexNet-LCNN version show that this novel method\noutperforms by 46% the baseline single stream network, with faster convergence,\nstability, and robustness.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 03:08:28 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["de Almeida", "Ana Paula G. S.", ""], ["Vidal", "Flavio de Barros", ""]]}, {"id": "2008.00167", "submitter": "Yixiao Chen", "authors": "Yixiao Chen, Linfeng Zhang, Han Wang and E Weinan", "title": "DeePKS: a comprehensive data-driven approach towards chemically accurate\n  density functional theory", "comments": null, "journal-ref": null, "doi": "10.1021/acs.jctc.0c00872", "report-no": null, "categories": "physics.comp-ph cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general machine learning-based framework for building an\naccurate and widely-applicable energy functional within the framework of\ngeneralized Kohn-Sham density functional theory. To this end, we develop a way\nof training self-consistent models that are capable of taking large datasets\nfrom different systems and different kinds of labels. We demonstrate that the\nfunctional that results from this training procedure gives chemically accurate\npredictions on energy, force, dipole, and electron density for a large class of\nmolecules. It can be continuously improved when more and more data are\navailable.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 04:30:37 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 20:33:11 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Chen", "Yixiao", ""], ["Zhang", "Linfeng", ""], ["Wang", "Han", ""], ["Weinan", "E", ""]]}, {"id": "2008.00176", "submitter": "Furkan Eris", "authors": "Furkan Eris, Sadullah Canakci, Cansu Demirkiran, Ajay Joshi", "title": "Custom Tailored Suite of Random Forests for Prefetcher Adaptation", "comments": "4 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To close the gap between memory and processors, and in turn improve\nperformance, there has been an abundance of work in the area of\ndata/instruction prefetcher designs. Prefetchers are deployed in each level of\nthe memory hierarchy, but typically, each prefetcher gets designed without\ncomprehensively accounting for other prefetchers in the system. As a result,\nthese individual prefetcher designs do not always complement each other, and\nthat leads to low average performance gains and/or many negative outliers. In\nthis work, we propose SuitAP (Suite of random forests for Adaptation of\nPrefetcher system configuration), which is a hardware prefetcher adapter that\nuses a suite of random forests to determine at runtime which prefetcher should\nbe ON at each memory level, such that they complement each other. Compared to a\ndesign with no prefetchers, using SuitAP we improve IPC by 46% on average\nacross traces generated from SPEC2017 suite with 12KB overhead. Moreover, we\nalso reduce negative outliers using SuitAP.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 05:43:38 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Eris", "Furkan", ""], ["Canakci", "Sadullah", ""], ["Demirkiran", "Cansu", ""], ["Joshi", "Ajay", ""]]}, {"id": "2008.00177", "submitter": "Xin Li", "authors": "Jiahuang Lin, Xin Li, Gennady Pekhimenko", "title": "Multi-node Bert-pretraining: Cost-efficient Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, large scale Transformer-based language models such as BERT, GPT-2,\nand XLNet have brought about exciting leaps in state-of-the-art results for\nmany Natural Language Processing (NLP) tasks. One of the common trends in these\nrecent models is a significant increase in model complexity, which introduces\nboth more weights and computation. Moreover, with the advent of large-scale\nunsupervised datasets, training time is further extended due to the increased\namount of data samples within a single training epoch. As a result, to train\nthese models within a reasonable time, machine learning (ML) programmers often\nrequire advanced hardware setups such as the premium GPU-enabled NVIDIA DGX\nworkstations or specialized accelerators such as Google's TPU Pods. Our work\naddresses this limitation and demonstrates that the BERT pre-trained model can\nbe trained within 2 weeks on an academic-size cluster of widely available GPUs\nthrough careful algorithmic and software optimizations. In this paper, we\npresent these optimizations on how to improve single device training\nthroughput, distribute the training workload over multiple nodes and GPUs, and\novercome the communication bottleneck introduced by the large data exchanges\nover the network. We show that we are able to perform pre-training on BERT\nwithin a reasonable time budget (12 days) in an academic setting, but with a\nmuch less expensive and less aggressive hardware resource requirement than in\npreviously demonstrated industrial settings based on NVIDIA DGX machines or\nGoogle's TPU Pods.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 05:49:20 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Lin", "Jiahuang", ""], ["Li", "Xin", ""], ["Pekhimenko", "Gennady", ""]]}, {"id": "2008.00178", "submitter": "Mohit Prabhushankar", "authors": "Mohit Prabhushankar, Gukyeong Kwon, Dogancan Temel, and Ghassan\n  AlRegib", "title": "Contrastive Explanations in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual explanations are logical arguments based on visual features that\njustify the predictions made by neural networks. Current modes of visual\nexplanations answer questions of the form $`Why \\text{ } P?'$. These $Why$\nquestions operate under broad contexts thereby providing answers that are\nirrelevant in some cases. We propose to constrain these $Why$ questions based\non some context $Q$ so that our explanations answer contrastive questions of\nthe form $`Why \\text{ } P, \\text{} rather \\text{ } than \\text{ } Q?'$. In this\npaper, we formalize the structure of contrastive visual explanations for neural\nnetworks. We define contrast based on neural networks and propose a methodology\nto extract defined contrasts. We then use the extracted contrasts as a plug-in\non top of existing $`Why \\text{ } P?'$ techniques, specifically Grad-CAM. We\ndemonstrate their value in analyzing both networks and data in applications of\nlarge-scale recognition, fine-grained recognition, subsurface seismic analysis,\nand image quality assessment.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 05:50:01 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Prabhushankar", "Mohit", ""], ["Kwon", "Gukyeong", ""], ["Temel", "Dogancan", ""], ["AlRegib", "Ghassan", ""]]}, {"id": "2008.00181", "submitter": "Huaxiu Yao", "authors": "Jiatu Shi, Huaxiu Yao, Xian Wu, Tong Li, Zedong Lin, Tengfei Wang,\n  Binqiang Zhao", "title": "Relation-aware Meta-learning for Market Segment Demand Prediction with\n  Limited Records", "comments": "First two authors contributed equally; Accepted by WSDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E-commerce business is revolutionizing our shopping experiences by providing\nconvenient and straightforward services. One of the most fundamental problems\nis how to balance the demand and supply in market segments to build an\nefficient platform. While conventional machine learning models have achieved\ngreat success on data-sufficient segments, it may fail in a large-portion of\nsegments in E-commerce platforms, where there are not sufficient records to\nlearn well-trained models. In this paper, we tackle this problem in the context\nof market segment demand prediction. The goal is to facilitate the learning\nprocess in the target segments by leveraging the learned knowledge from\ndata-sufficient source segments. Specifically, we propose a novel algorithm,\nRMLDP, to incorporate a multi-pattern fusion network (MPFN) with a\nmeta-learning paradigm. The multi-pattern fusion network considers both local\nand seasonal temporal patterns for segment demand prediction. In the\nmeta-learning paradigm, transferable knowledge is regarded as the model\nparameter initialization of MPFN, which are learned from diverse source\nsegments. Furthermore, we capture the segment relations by combining\ndata-driven segment representation and segment knowledge graph representation\nand tailor the segment-specific relations to customize transferable model\nparameter initialization. Thus, even with limited data, the target segment can\nquickly find the most relevant transferred knowledge and adapt to the optimal\nparameters. We conduct extensive experiments on two large-scale industrial\ndatasets. The results justify that our RMLDP outperforms a set of\nstate-of-the-art baselines. Besides, RMLDP has been deployed in Taobao, a\nreal-world E-commerce platform. The online A/B testing results further\ndemonstrate the practicality of RMLDP.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 06:02:16 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 00:15:23 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Shi", "Jiatu", ""], ["Yao", "Huaxiu", ""], ["Wu", "Xian", ""], ["Li", "Tong", ""], ["Lin", "Zedong", ""], ["Wang", "Tengfei", ""], ["Zhao", "Binqiang", ""]]}, {"id": "2008.00190", "submitter": "Nikola Zlatanov", "authors": "Farzad Shahrivari and Nikola Zlatanov", "title": "On Supervised Classification of Feature Vectors with Independent and\n  Non-Identically Distributed Elements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the problem of classifying feature vectors with\nmutually independent but non-identically distributed elements. First, we show\nthe importance of this problem. Next, we propose a classifier and derive an\nanalytical upper bound on its error probability. We show that the error\nprobability goes to zero as the length of the feature vectors grows, even when\nthere is only one training feature vector per label available. Thereby, we show\nthat for this important problem at least one asymptotically optimal classifier\nexists. Finally, we provide numerical examples where we show that the\nperformance of the proposed classifier outperforms conventional classification\nalgorithms when the number of training data is small and the length of the\nfeature vectors is sufficiently high.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 06:49:50 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 00:58:05 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Shahrivari", "Farzad", ""], ["Zlatanov", "Nikola", ""]]}, {"id": "2008.00203", "submitter": "Jiawen Huang", "authors": "Jiawen Huang, Yun-Ning Hung, Ashis Pati, Siddharth Kumar Gururani,\n  Alexander Lerch", "title": "Score-informed Networks for Music Performance Assessment", "comments": "To appear at 21st International Society for Music Information\n  Retrieval Conference, Montr\\'eal, Canada, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The assessment of music performances in most cases takes into account the\nunderlying musical score being performed. While there have been several\nautomatic approaches for objective music performance assessment (MPA) based on\nextracted features from both the performance audio and the score, deep neural\nnetwork-based methods incorporating score information into MPA models have not\nyet been investigated. In this paper, we introduce three different models\ncapable of score-informed performance assessment. These are (i) a convolutional\nneural network that utilizes a simple time-series input comprising of aligned\npitch contours and score, (ii) a joint embedding model which learns a joint\nlatent space for pitch contours and scores, and (iii) a distance matrix-based\nconvolutional neural network which utilizes patterns in the distance matrix\nbetween pitch contours and musical score to predict assessment ratings. Our\nresults provide insights into the suitability of different architectures and\ninput representations and demonstrate the benefits of score-informed models as\ncompared to score-independent models.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 07:46:24 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Huang", "Jiawen", ""], ["Hung", "Yun-Ning", ""], ["Pati", "Ashis", ""], ["Gururani", "Siddharth Kumar", ""], ["Lerch", "Alexander", ""]]}, {"id": "2008.00209", "submitter": "Hiroshi Fuketa", "authors": "Hiroshi Fuketa and Yukinori Morita", "title": "Neural ODE with Temporal Convolution and Time Delay Neural Networks for\n  Small-Footprint Keyword Spotting", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose neural network models based on the neural ordinary\ndifferential equation (NODE) for small-footprint keyword spotting (KWS). We\npresent techniques to apply NODE to KWS that make it possible to adopt Batch\nNormalization to NODE-based network and to reduce the number of computations\nduring inference. Finally, we show that the number of model parameters of the\nproposed model is smaller by 68% than that of the conventional KWS model.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 08:01:20 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 12:06:36 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Fuketa", "Hiroshi", ""], ["Morita", "Yukinori", ""]]}, {"id": "2008.00217", "submitter": "Siyuan Liang", "authors": "Siyuan Liang, Xingxing Wei, Siyuan Yao and Xiaochun Cao", "title": "Efficient Adversarial Attacks for Visual Object Tracking", "comments": null, "journal-ref": "eccv 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual object tracking is an important task that requires the tracker to find\nthe objects quickly and accurately. The existing state-ofthe-art object\ntrackers, i.e., Siamese based trackers, use DNNs to attain high accuracy.\nHowever, the robustness of visual tracking models is seldom explored. In this\npaper, we analyze the weakness of object trackers based on the Siamese network\nand then extend adversarial examples to visual object tracking. We present an\nend-to-end network FAN (Fast Attack Network) that uses a novel drift loss\ncombined with the embedded feature loss to attack the Siamese network based\ntrackers. Under a single GPU, FAN is efficient in the training speed and has a\nstrong attack performance. The FAN can generate an adversarial example at 10ms,\nachieve effective targeted attack (at least 40% drop rate on OTB) and\nuntargeted attack (at least 70% drop rate on OTB).\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 08:47:58 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Liang", "Siyuan", ""], ["Wei", "Xingxing", ""], ["Yao", "Siyuan", ""], ["Cao", "Xiaochun", ""]]}, {"id": "2008.00238", "submitter": "Pavan Magesh", "authors": "Pavan Rajkumar Magesh, Richard Delwin Myloth, Rijo Jackson Tom", "title": "An Explainable Machine Learning Model for Early Detection of Parkinson's\n  Disease using LIME on DaTscan Imagery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parkinson's disease (PD) is a degenerative and progressive neurological\ncondition. Early diagnosis can improve treatment for patients and is performed\nthrough dopaminergic imaging techniques like the SPECT DaTscan. In this study,\nwe propose a machine learning model that accurately classifies any given\nDaTscan as having Parkinson's disease or not, in addition to providing a\nplausible reason for the prediction. This is kind of reasoning is done through\nthe use of visual indicators generated using Local Interpretable Model-Agnostic\nExplainer (LIME) methods. DaTscans were drawn from the Parkinson's Progression\nMarkers Initiative database and trained on a CNN (VGG16) using transfer\nlearning, yielding an accuracy of 95.2%, a sensitivity of 97.5%, and a\nspecificity of 90.9%. Keeping model interpretability of paramount importance,\nespecially in the healthcare field, this study utilises LIME explanations to\ndistinguish PD from non-PD, using visual superpixels on the DaTscans. It could\nbe concluded that the proposed system, in union with its measured\ninterpretability and accuracy may effectively aid medical workers in the early\ndiagnosis of Parkinson's Disease.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 10:44:03 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Magesh", "Pavan Rajkumar", ""], ["Myloth", "Richard Delwin", ""], ["Tom", "Rijo Jackson", ""]]}, {"id": "2008.00247", "submitter": "Atmadeep Banerjee", "authors": "Atmadeep Banerjee", "title": "Meta-DRN: Meta-Learning for 1-Shot Image Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern deep learning models have revolutionized the field of computer vision.\nBut, a significant drawback of most of these models is that they require a\nlarge number of labelled examples to generalize properly. Recent developments\nin few-shot learning aim to alleviate this requirement. In this paper, we\npropose a novel lightweight CNN architecture for 1-shot image segmentation. The\nproposed model is created by taking inspiration from well-performing\narchitectures for semantic segmentation and adapting it to the 1-shot domain.\nWe train our model using 4 meta-learning algorithms that have worked well for\nimage classification and compare the results. For the chosen dataset, our\nproposed model has a 70% lower parameter count than the benchmark, while having\nbetter or comparable mean IoU scores using all 4 of the meta-learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 11:23:37 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Banerjee", "Atmadeep", ""]]}, {"id": "2008.00250", "submitter": "Zhao Rui", "authors": "Rui Zhao, Xinjie Wang, Junjuan Xia, and Liseng Fan", "title": "Deep Reinforcement Learning Based Mobile Edge Computing for Intelligent\n  Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate mobile edge computing (MEC) networks for\nintelligent internet of things (IoT), where multiple users have some\ncomputational tasks assisted by multiple computational access points (CAPs). By\noffloading some tasks to the CAPs, the system performance can be improved\nthrough reducing the latency and energy consumption, which are the two\nimportant metrics of interest in the MEC networks. We devise the system by\nproposing the offloading strategy intelligently through the deep reinforcement\nlearning algorithm. In this algorithm, Deep Q-Network is used to automatically\nlearn the offloading decision in order to optimize the system performance, and\na neural network (NN) is trained to predict the offloading action, where the\ntraining data is generated from the environmental system. Moreover, we employ\nthe bandwidth allocation in order to optimize the wireless spectrum for the\nlinks between the users and CAPs, where several bandwidth allocation schemes\nare proposed. In further, we use the CAP selection in order to choose one best\nCAP to assist the computational tasks from the users. Simulation results are\nfinally presented to show the effectiveness of the proposed reinforcement\nlearning offloading strategy. In particular, the system cost of latency and\nenergy consumption can be reduced significantly by the proposed deep\nreinforcement learning based algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 11:45:54 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zhao", "Rui", ""], ["Wang", "Xinjie", ""], ["Xia", "Junjuan", ""], ["Fan", "Liseng", ""]]}, {"id": "2008.00297", "submitter": "Evgenios Kornaropoulos", "authors": "Evgenios M. Kornaropoulos, Silei Ren, Roberto Tamassia", "title": "The Price of Tailoring the Index to Your Data: Poisoning Attacks on\n  Learned Index Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of learned index structures relies on the idea that the\ninput-output functionality of a database index can be viewed as a prediction\ntask and, thus, be implemented using a machine learning model instead of\ntraditional algorithmic techniques. This novel angle for a decades-old problem\nhas inspired numerous exciting results in the intersection of machine learning\nand data structures. However, the main advantage of learned index structures,\ni.e., the ability to adjust to the data at hand via the underlying ML-model,\ncan become a disadvantage from a security perspective as it could be exploited.\n  In this work, we present the first study of poisoning attacks on learned\nindex structures. The required poisoning approach is different from all\nprevious works since the model under attack is trained on a cumulative\ndistribution function (CDF) and, thus, every injection on the training set has\na cascading impact on multiple data values. We formulate the first poisoning\nattacks on linear regression models trained on the CDF, which is a basic\nbuilding block of the proposed learned index structures. We generalize our\npoisoning techniques to attack a more advanced two-stage design of learned\nindex structures called recursive model index (RMI), which has been shown to\noutperform traditional B-Trees. We evaluate our attacks on real-world and\nsynthetic datasets under a wide variety of parameterizations of the model and\nshow that the error of the RMI increases up to $300\\times$ and the error of its\nsecond-stage models increases up to $3000\\times$.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 17:12:04 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Kornaropoulos", "Evgenios M.", ""], ["Ren", "Silei", ""], ["Tamassia", "Roberto", ""]]}, {"id": "2008.00299", "submitter": "Mohammed Bany Muhammad", "authors": "Mohammed Bany Muhammad, Mohammed Yeasin", "title": "Eigen-CAM: Class Activation Map using Principal Components", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9206626", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are ubiquitous due to the ease of developing models and\ntheir influence on other domains. At the heart of this progress is\nconvolutional neural networks (CNNs) that are capable of learning\nrepresentations or features given a set of data. Making sense of such complex\nmodels (i.e., millions of parameters and hundreds of layers) remains\nchallenging for developers as well as the end-users. This is partially due to\nthe lack of tools or interfaces capable of providing interpretability and\ntransparency. A growing body of literature, for example, class activation map\n(CAM), focuses on making sense of what a model learns from the data or why it\nbehaves poorly in a given task. This paper builds on previous ideas to cope\nwith the increasing demand for interpretable, robust, and transparent models.\nOur approach provides a simpler and intuitive (or familiar) way of generating\nCAM. The proposed Eigen-CAM computes and visualizes the principle components of\nthe learned features/representations from the convolutional layers. Empirical\nstudies were performed to compare the Eigen-CAM with the state-of-the-art\nmethods (such as Grad-CAM, Grad-CAM++, CNN-fixations) by evaluating on\nbenchmark datasets such as weakly-supervised localization and localizing\nobjects in the presence of adversarial noise. Eigen-CAM was found to be robust\nagainst classification errors made by fully connected layers in CNNs, does not\nrely on the backpropagation of gradients, class relevance score, maximum\nactivation locations, or any other form of weighting features. In addition, it\nworks with all CNN models without the need to modify layers or retrain models.\nEmpirical results show up to 12% improvement over the best method among the\nmethods compared on weakly supervised object localization.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 17:14:13 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Muhammad", "Mohammed Bany", ""], ["Yeasin", "Mohammed", ""]]}, {"id": "2008.00305", "submitter": "Omid Poursaeed", "authors": "Omid Poursaeed, Tianxing Jiang, Han Qiao, Nayun Xu, Vladimir G. Kim", "title": "Self-supervised Learning of Point Clouds via Orientation Estimation", "comments": "3DV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point clouds provide a compact and efficient representation of 3D shapes.\nWhile deep neural networks have achieved impressive results on point cloud\nlearning tasks, they require massive amounts of manually labeled data, which\ncan be costly and time-consuming to collect. In this paper, we leverage 3D\nself-supervision for learning downstream tasks on point clouds with fewer\nlabels. A point cloud can be rotated in infinitely many ways, which provides a\nrich label-free source for self-supervision. We consider the auxiliary task of\npredicting rotations that in turn leads to useful features for other tasks such\nas shape classification and 3D keypoint prediction. Using experiments on\nShapeNet and ModelNet, we demonstrate that our approach outperforms the\nstate-of-the-art. Moreover, features learned by our model are complementary to\nother self-supervised methods and combining them leads to further performance\nimprovement.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 17:49:45 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 01:46:11 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Poursaeed", "Omid", ""], ["Jiang", "Tianxing", ""], ["Qiao", "Han", ""], ["Xu", "Nayun", ""], ["Kim", "Vladimir G.", ""]]}, {"id": "2008.00308", "submitter": "Tim Po\\v{s}tuvan", "authors": "Tim Po\\v{s}tuvan, Semir Salki\\'c, Lovro \\v{S}ubelj", "title": "Learning-based link prediction analysis for Facebook100 network", "comments": "8 pages, 7 figures, 3 tables", "journal-ref": "Applied Informatics Vol 29 No 2 (2021), 83-94", "doi": "10.31449/upinf.vol29.num2.112", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In social network science, Facebook is one of the most interesting and widely\nused social networks and media platforms. Its data contributed to significant\nevolution of social network research and link prediction techniques, which are\nimportant tools in link mining and analysis. This paper gives the first\ncomprehensive analysis of link prediction on the Facebook100 network. We study\nperformance and evaluate multiple machine learning algorithms on different\nfeature sets. To derive features we use network embeddings and topology-based\ntechniques such as node2vec and vectors of similarity metrics. In addition, we\nalso employ node-based features, which are available for Facebook100 network,\nbut rarely found in other datasets. The adopted approaches are discussed and\nresults are clearly presented. Lastly, we compare and review applied models,\nwhere overall performance and classification rates are presented.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 18:03:57 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 23:46:04 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Po\u0161tuvan", "Tim", ""], ["Salki\u0107", "Semir", ""], ["\u0160ubelj", "Lovro", ""]]}, {"id": "2008.00311", "submitter": "Aria HasanzadeZonuzy", "authors": "Aria HasanzadeZonuzy, Archana Bura, Dileep Kalathil and Srinivas\n  Shakkottai", "title": "Learning with Safety Constraints: Sample Complexity of Reinforcement\n  Learning for Constrained MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many physical systems have underlying safety considerations that require that\nthe policy employed ensures the satisfaction of a set of constraints. The\nanalytical formulation usually takes the form of a Constrained Markov Decision\nProcess (CMDP). We focus on the case where the CMDP is unknown, and RL\nalgorithms obtain samples to discover the model and compute an optimal\nconstrained policy. Our goal is to characterize the relationship between safety\nconstraints and the number of samples needed to ensure a desired level of\naccuracy -- both objective maximization and constraint satisfaction -- in a PAC\nsense. We explore two classes of RL algorithms, namely, (i) a generative model\nbased approach, wherein samples are taken initially to estimate a model, and\n(ii) an online approach, wherein the model is updated as samples are obtained.\nOur main finding is that compared to the best known bounds of the unconstrained\nregime, the sample complexity of constrained RL algorithms are increased by a\nfactor that is logarithmic in the number of constraints, which suggests that\nthe approach may be easily utilized in real systems.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 18:17:08 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 03:06:54 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 20:51:27 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["HasanzadeZonuzy", "Aria", ""], ["Bura", "Archana", ""], ["Kalathil", "Dileep", ""], ["Shakkottai", "Srinivas", ""]]}, {"id": "2008.00312", "submitter": "Xinyang Zhang", "authors": "Xinyang Zhang, Zheng Zhang, Shouling Ji and Ting Wang", "title": "Trojaning Language Models for Fun and Profit", "comments": "Additional experiments and text editing; To appear in 2021 6th IEEE\n  European Symposium on Security and Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the emergence of a new paradigm of building\nnatural language processing (NLP) systems: general-purpose, pre-trained\nlanguage models (LMs) are composed with simple downstream models and fine-tuned\nfor a variety of NLP tasks. This paradigm shift significantly simplifies the\nsystem development cycles. However, as many LMs are provided by untrusted third\nparties, their lack of standardization or regulation entails profound security\nimplications, which are largely unexplored.\n  To bridge this gap, this work studies the security threats posed by malicious\nLMs to NLP systems. Specifically, we present TROJAN-LM, a new class of\ntrojaning attacks in which maliciously crafted LMs trigger host NLP systems to\nmalfunction in a highly predictable manner. By empirically studying three\nstate-of-the-art LMs (BERT, GPT-2, XLNet) in a range of security-critical NLP\ntasks (toxic comment detection, question answering, text completion) as well as\nuser studies on crowdsourcing platforms, we demonstrate that TROJAN-LM\npossesses the following properties: (i) flexibility - the adversary is able to\nflexibly dene logical combinations (e.g., 'and', 'or', 'xor') of arbitrary\nwords as triggers, (ii) efficacy - the host systems misbehave as desired by the\nadversary with high probability when trigger-embedded inputs are present, (iii)\nspecificity - the trojan LMs function indistinguishably from their benign\ncounterparts on clean inputs, and (iv) fluency - the trigger-embedded inputs\nappear as fluent natural language and highly relevant to their surrounding\ncontexts. We provide analytical justification for the practicality of\nTROJAN-LM, and further discuss potential countermeasures and their challenges,\nwhich lead to several promising research directions.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 18:22:38 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 21:52:58 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Zhang", "Xinyang", ""], ["Zhang", "Zheng", ""], ["Ji", "Shouling", ""], ["Wang", "Ting", ""]]}, {"id": "2008.00323", "submitter": "David Burt", "authors": "David R. Burt and Carl Edward Rasmussen and Mark van der Wilk", "title": "Convergence of Sparse Variational Inference in Gaussian Processes\n  Regression", "comments": "Extended version of http://proceedings.mlr.press/v97/burt19a.html\n  (arxiv version: arXiv:1903.03571 ). Published in Journal of Machine Learning\n  Research: http://jmlr.org/papers/v21/19-1015.html. Code available at:\n  https://github.com/markvdw/RobustGP", "journal-ref": "Journal of Machine Learning Research, 21(131), 1-63 (2020)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes are distributions over functions that are versatile and\nmathematically convenient priors in Bayesian modelling. However, their use is\noften impeded for data with large numbers of observations, $N$, due to the\ncubic (in $N$) cost of matrix operations used in exact inference. Many\nsolutions have been proposed that rely on $M \\ll N$ inducing variables to form\nan approximation at a cost of $\\mathcal{O}(NM^2)$. While the computational cost\nappears linear in $N$, the true complexity depends on how $M$ must scale with\n$N$ to ensure a certain quality of the approximation. In this work, we\ninvestigate upper and lower bounds on how $M$ needs to grow with $N$ to ensure\nhigh quality approximations. We show that we can make the KL-divergence between\nthe approximate model and the exact posterior arbitrarily small for a\nGaussian-noise regression model with $M\\ll N$. Specifically, for the popular\nsquared exponential kernel and $D$-dimensional Gaussian distributed covariates,\n$M=\\mathcal{O}((\\log N)^D)$ suffice and a method with an overall computational\ncost of $\\mathcal{O}(N(\\log N)^{2D}(\\log\\log N)^2)$ can be used to perform\ninference.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 19:23:34 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Burt", "David R.", ""], ["Rasmussen", "Carl Edward", ""], ["van der Wilk", "Mark", ""]]}, {"id": "2008.00325", "submitter": "Corey Nolet", "authors": "Corey J. Nolet, Victor Lafargue, Edward Raff, Thejaswi Nanditale, Tim\n  Oates, John Zedlewski, Joshua Patterson", "title": "Bringing UMAP Closer to the Speed of Light with GPU Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Uniform Manifold Approximation and Projection (UMAP) algorithm has become\nwidely popular for its ease of use, quality of results, and support for\nexploratory, unsupervised, supervised, and semi-supervised learning. While many\nalgorithms can be ported to a GPU in a simple and direct fashion, such efforts\nhave resulted in inefficient and inaccurate versions of UMAP. We show a number\nof techniques that can be used to make a faster and more faithful GPU version\nof UMAP, and obtain speedups of up to 100x in practice. Many of these design\nchoices/lessons are general purpose and may inform the conversion of other\ngraph and manifold learning algorithms to use GPUs. Our implementation has been\nmade publicly available as part of the open source RAPIDS cuML library\n(https://github.com/rapidsai/cuml).\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 19:35:56 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 02:27:07 GMT"}, {"version": "v3", "created": "Mon, 29 Mar 2021 09:15:12 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Nolet", "Corey J.", ""], ["Lafargue", "Victor", ""], ["Raff", "Edward", ""], ["Nanditale", "Thejaswi", ""], ["Oates", "Tim", ""], ["Zedlewski", "John", ""], ["Patterson", "Joshua", ""]]}, {"id": "2008.00331", "submitter": "Anupama Nandi", "authors": "Raef Bassily, Shay Moran and Anupama Nandi", "title": "Learning from Mixtures of Private and Public Populations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of a new model of supervised learning under privacy\nconstraints. Imagine a medical study where a dataset is sampled from a\npopulation of both healthy and unhealthy individuals. Suppose healthy\nindividuals have no privacy concerns (in such case, we call their data\n\"public\") while the unhealthy individuals desire stringent privacy protection\nfor their data. In this example, the population (data distribution) is a\nmixture of private (unhealthy) and public (healthy) sub-populations that could\nbe very different.\n  Inspired by the above example, we consider a model in which the population\n$\\mathcal{D}$ is a mixture of two sub-populations: a private sub-population\n$\\mathcal{D}_{\\sf priv}$ of private and sensitive data, and a public\nsub-population $\\mathcal{D}_{\\sf pub}$ of data with no privacy concerns. Each\nexample drawn from $\\mathcal{D}$ is assumed to contain a privacy-status bit\nthat indicates whether the example is private or public. The goal is to design\na learning algorithm that satisfies differential privacy only with respect to\nthe private examples.\n  Prior works in this context assumed a homogeneous population where private\nand public data arise from the same distribution, and in particular designed\nsolutions which exploit this assumption. We demonstrate how to circumvent this\nassumption by considering, as a case study, the problem of learning linear\nclassifiers in $\\mathbb{R}^d$. We show that in the case where the privacy\nstatus is correlated with the target label (as in the above example), linear\nclassifiers in $\\mathbb{R}^d$ can be learned, in the agnostic as well as the\nrealizable setting, with sample complexity which is comparable to that of the\nclassical (non-private) PAC-learning. It is known that this task is impossible\nif all the data is considered private.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 20:11:50 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Bassily", "Raef", ""], ["Moran", "Shay", ""], ["Nandi", "Anupama", ""]]}, {"id": "2008.00335", "submitter": "Haoran Su", "authors": "Haoran Su, Kejian Shi, Li Jin and Joseph Y.J. Chow", "title": "V2I Connectivity-Based Dynamic Queue-Jump Lane for Emergency Vehicles: A\n  Deep Reinforcement Learning Approach", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergency vehicle (EMV) service is a key function of cities and is\nexceedingly challenging due to urban traffic congestion. A main reason behind\nEMV service delay is the lack of communication and cooperation between vehicles\nblocking EMVs. In this paper, we study the improvement of EMV service under V2I\nconnectivity. We consider the establishment of dynamic queue jump lanes (DQJLs)\nbased on real-time coordination of connected vehicles. We develop a novel\nMarkov decision process formulation for the DQJL problem, which explicitly\naccounts for the uncertainty of drivers' reaction to approaching EMVs. We\npropose a deep neural network-based reinforcement learning algorithm that\nefficiently computes the optimal coordination instructions. We also validate\nour approach on a micro-simulation testbed using Simulation of Urban Mobility\n(SUMO). Validation results show that with our proposed methodology, the\ncentralized control system saves approximately 15\\% EMV passing time than the\nbenchmark system.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 20:34:16 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 17:53:17 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Su", "Haoran", ""], ["Shi", "Kejian", ""], ["Jin", "Li", ""], ["Chow", "Joseph Y. J.", ""]]}, {"id": "2008.00357", "submitter": "Aria Khademi", "authors": "Aria Khademi, Vasant Honavar", "title": "A Causal Lens for Peeking into Black Box Predictive Models: Predictive\n  Model Interpretation via Causal Attribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing adoption of predictive models trained using machine\nlearning across a wide range of high-stakes applications, e.g., health care,\nsecurity, criminal justice, finance, and education, there is a growing need for\neffective techniques for explaining such models and their predictions. We aim\nto address this problem in settings where the predictive model is a black box;\nThat is, we can only observe the response of the model to various inputs, but\nhave no knowledge about the internal structure of the predictive model, its\nparameters, the objective function, and the algorithm used to optimize the\nmodel. We reduce the problem of interpreting a black box predictive model to\nthat of estimating the causal effects of each of the model inputs on the model\noutput, from observations of the model inputs and the corresponding outputs. We\nestimate the causal effects of model inputs on model output using variants of\nthe Rubin Neyman potential outcomes framework for estimating causal effects\nfrom observational data. We show how the resulting causal attribution of\nresponsibility for model output to the different model inputs can be used to\ninterpret the predictive model and to explain its predictions. We present\nresults of experiments that demonstrate the effectiveness of our approach to\nthe interpretation of black box predictive models via causal attribution in the\ncase of deep neural network models trained on one synthetic data set (where the\ninput variables that impact the output variable are known by design) and two\nreal-world data sets: Handwritten digit classification, and Parkinson's disease\nseverity prediction. Because our approach does not require knowledge about the\npredictive model algorithm and is free of assumptions regarding the black box\npredictive model except that its input-output responses be observable, it can\nbe applied, in principle, to any black box predictive model.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 23:20:57 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Khademi", "Aria", ""], ["Honavar", "Vasant", ""]]}, {"id": "2008.00358", "submitter": "Yuyan Wang", "authors": "Benjamin Moseley, Kirk Pruhs, Alireza Samadian, Yuyan Wang", "title": "Relational Algorithms for k-means Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives a k-means approximation algorithm that is efficient in the\nrelational algorithms model. This is an algorithm that operates directly on a\nrelational database without performing a join to convert it to a matrix whose\nrows represent the data points. The running time is potentially exponentially\nsmaller than $N$, the number of data points to be clustered that the relational\ndatabase represents.\n  Few relational algorithms are known and this paper offers techniques for\ndesigning relational algorithms as well as characterizing their limitations. We\nshow that given two data points as cluster centers, if we cluster points\naccording to their closest centers, it is NP-Hard to approximate the number of\npoints in the clusters on a general relational input. This is trivial for\nconventional data inputs and this result exemplifies that standard algorithmic\ntechniques may not be directly applied when designing an efficient relational\nalgorithm. This paper then introduces a new method that leverages rejection\nsampling and the $k$-means++ algorithm to construct an O(1)-approximate k-means\nsolution.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 23:21:40 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 22:18:08 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Moseley", "Benjamin", ""], ["Pruhs", "Kirk", ""], ["Samadian", "Alireza", ""], ["Wang", "Yuyan", ""]]}, {"id": "2008.00362", "submitter": "Zili Yi", "authors": "Zili Yi, Qiang Tang, Vishnu Sanjay Ramiya Srinivasan, Zhan Xu", "title": "Animating Through Warping: an Efficient Method for High-Quality Facial\n  Expression Animation", "comments": "18 pages, 13 figures, Accepted to ACM Multimedia 2020", "journal-ref": null, "doi": "10.1145/3394171.3413926", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in deep neural networks have considerably improved the art of\nanimating a still image without operating in 3D domain. Whereas, prior arts can\nonly animate small images (typically no larger than 512x512) due to memory\nlimitations, difficulty of training and lack of high-resolution (HD) training\ndatasets, which significantly reduce their potential for applications in movie\nproduction and interactive systems. Motivated by the idea that HD images can be\ngenerated by adding high-frequency residuals to low-resolution results produced\nby a neural network, we propose a novel framework known as Animating Through\nWarping (ATW) to enable efficient animation of HD images.\n  Specifically, the proposed framework consists of two modules, a novel\ntwo-stage neural-network generator and a novel post-processing module known as\nAnimating Through Warping (ATW). It only requires the generator to be trained\non small images and can do inference on an image of any size. During inference,\nan HD input image is decomposed into a low-resolution component(128x128) and\nits corresponding high-frequency residuals. The generator predicts the\nlow-resolution result as well as the motion field that warps the input face to\nthe desired status (e.g., expressions categories or action units). Finally, the\nResWarp module warps the residuals based on the motion field and adding the\nwarped residuals to generates the final HD results from the naively up-sampled\nlow-resolution results. Experiments show the effectiveness and efficiency of\nour method in generating high-resolution animations. Our proposed framework\nsuccessfully animates a 4K facial image, which has never been achieved by prior\nneural models. In addition, our method generally guarantee the temporal\ncoherency of the generated animations. Source codes will be made publicly\navailable.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 23:52:33 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Yi", "Zili", ""], ["Tang", "Qiang", ""], ["Srinivasan", "Vishnu Sanjay Ramiya", ""], ["Xu", "Zhan", ""]]}, {"id": "2008.00363", "submitter": "Satyananda Kashyap", "authors": "Satyananda Kashyap, Alexandros Karargyris, Joy Wu, Yaniv Gur, Arjun\n  Sharma, Ken C. L. Wong, Mehdi Moradi, Tanveer Syeda-Mahmood", "title": "Looking in the Right place for Anomalies: Explainable AI through\n  Automatic Location Learning", "comments": "5 pages, Paper presented as a poster at the International Symposium\n  on Biomedical Imaging, 2020, Paper Number 655", "journal-ref": "2020 IEEE 17th International Symposium on Biomedical Imaging\n  (ISBI)", "doi": "10.1109/ISBI45749.2020.9098370", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has now become the de facto approach to the recognition of\nanomalies in medical imaging. Their 'black box' way of classifying medical\nimages into anomaly labels poses problems for their acceptance, particularly\nwith clinicians. Current explainable AI methods offer justifications through\nvisualizations such as heat maps but cannot guarantee that the network is\nfocusing on the relevant image region fully containing the anomaly. In this\npaper, we develop an approach to explainable AI in which the anomaly is assured\nto be overlapping the expected location when present. This is made possible by\nautomatically extracting location-specific labels from textual reports and\nlearning the association of expected locations to labels using a hybrid\ncombination of Bi-Directional Long Short-Term Memory Recurrent Neural Networks\n(Bi-LSTM) and DenseNet-121. Use of this expected location to bias the\nsubsequent attention-guided inference network based on ResNet101 results in the\nisolation of the anomaly at the expected location when present. The method is\nevaluated on a large chest X-ray dataset.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 00:02:37 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Kashyap", "Satyananda", ""], ["Karargyris", "Alexandros", ""], ["Wu", "Joy", ""], ["Gur", "Yaniv", ""], ["Sharma", "Arjun", ""], ["Wong", "Ken C. L.", ""], ["Moradi", "Mehdi", ""], ["Syeda-Mahmood", "Tanveer", ""]]}, {"id": "2008.00380", "submitter": "Sharmin Majumder", "authors": "Sharmin Majumder, Nasser Kehtarnavaz", "title": "Vision and Inertial Sensing Fusion for Human Action Recognition : A\n  Review", "comments": "14 pages,4 figures,2 tables. Submitted to IEEE Sensors Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human action recognition is used in many applications such as video\nsurveillance, human computer interaction, assistive living, and gaming. Many\npapers have appeared in the literature showing that the fusion of vision and\ninertial sensing improves recognition accuracies compared to the situations\nwhen each sensing modality is used individually. This paper provides a survey\nof the papers in which vision and inertial sensing are used simultaneously\nwithin a fusion framework in order to perform human action recognition. The\nsurveyed papers are categorized in terms of fusion approaches, features,\nclassifiers, as well as multimodality datasets considered. Challenges as well\nas possible future directions are also stated for deploying the fusion of these\ntwo sensing modalities under realistic conditions.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 02:06:44 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Majumder", "Sharmin", ""], ["Kehtarnavaz", "Nasser", ""]]}, {"id": "2008.00386", "submitter": "Franck Dernoncourt", "authors": "Lidan Wang, Franck Dernoncourt, Trung Bui", "title": "Bayesian Optimization for Selecting Efficient Machine Learning Models", "comments": "Published at CIKM MoST-Rec 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The performance of many machine learning models depends on their\nhyper-parameter settings. Bayesian Optimization has become a successful tool\nfor hyper-parameter optimization of machine learning algorithms, which aims to\nidentify optimal hyper-parameters during an iterative sequential process.\nHowever, most of the Bayesian Optimization algorithms are designed to select\nmodels for effectiveness only and ignore the important issue of model training\nefficiency. Given that both model effectiveness and training time are important\nfor real-world applications, models selected for effectiveness may not meet the\nstrict training time requirements necessary to deploy in a production\nenvironment. In this work, we present a unified Bayesian Optimization framework\nfor jointly optimizing models for both prediction effectiveness and training\nefficiency. We propose an objective that captures the tradeoff between these\ntwo metrics and demonstrate how we can jointly optimize them in a principled\nBayesian Optimization framework. Experiments on model selection for\nrecommendation tasks indicate models selected this way significantly improves\nmodel training efficiency while maintaining strong effectiveness as compared to\nstate-of-the-art Bayesian Optimization algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 02:56:30 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Wang", "Lidan", ""], ["Dernoncourt", "Franck", ""], ["Bui", "Trung", ""]]}, {"id": "2008.00394", "submitter": "Xiaogang Wang", "authors": "Xiaogang Wang, Marcelo H Ang Jr and Gim Hee Lee", "title": "Point Cloud Completion by Learning Shape Priors", "comments": "IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In view of the difficulty in reconstructing object details in point cloud\ncompletion, we propose a shape prior learning method for object completion. The\nshape priors include geometric information in both complete and the partial\npoint clouds. We design a feature alignment strategy to learn the shape prior\nfrom complete points, and a coarse to fine strategy to incorporate partial\nprior in the fine stage. To learn the complete objects prior, we first train a\npoint cloud auto-encoder to extract the latent embeddings from complete points.\nThen we learn a mapping to transfer the point features from partial points to\nthat of the complete points by optimizing feature alignment losses. The feature\nalignment losses consist of a L2 distance and an adversarial loss obtained by\nMaximum Mean Discrepancy Generative Adversarial Network (MMD-GAN). The L2\ndistance optimizes the partial features towards the complete ones in the\nfeature space, and MMD-GAN decreases the statistical distance of two point\nfeatures in a Reproducing Kernel Hilbert Space. We achieve state-of-the-art\nperformances on the point cloud completion task. Our code is available at\nhttps://github.com/xiaogangw/point-cloud-completion-shape-prior.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 04:00:32 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 08:07:03 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Wang", "Xiaogang", ""], ["Ang", "Marcelo H", "Jr"], ["Lee", "Gim Hee", ""]]}, {"id": "2008.00397", "submitter": "Liu Yang", "authors": "Liu Yang, Fanqi Meng, Ming-Kuang Daniel Wu, Vicent Ying, Xianchao Xu", "title": "SeqDialN: Sequential Visual Dialog Networks in Joint Visual-Linguistic\n  Representation Space", "comments": "18 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we formulate a visual dialog as an information flow in which\neach piece of information is encoded with the joint visual-linguistic\nrepresentation of a single dialog round. Based on this formulation, we consider\nthe visual dialog task as a sequence problem consisting of ordered\nvisual-linguistic vectors. For featurization, we use a Dense Symmetric\nCo-Attention network as a lightweight vison-language joint representation\ngenerator to fuse multimodal features (i.e., image and text), yielding better\ncomputation and data efficiencies. For inference, we propose two Sequential\nDialog Networks (SeqDialN): the first uses LSTM for information propagation\n(IP) and the second uses a modified Transformer for multi-step reasoning (MR).\nOur architecture separates the complexity of multimodal feature fusion from\nthat of inference, which allows simpler design of the inference engine. IP\nbased SeqDialN is our baseline with a simple 2-layer LSTM design that achieves\ndecent performance. MR based SeqDialN, on the other hand, recurrently refines\nthe semantic question/history representations through the self-attention stack\nof Transformer and produces promising results on the visual dialog task. On\nVisDial v1.0 test-std dataset, our best single generative SeqDialN achieves\n62.54% NDCG and 48.63% MRR; our ensemble generative SeqDialN achieves 63.78%\nNDCG and 49.98% MRR, which set a new state-of-the-art generative visual dialog\nmodel. We fine-tune discriminative SeqDialN with dense annotations and boost\nthe performance up to 72.41% NDCG and 55.11% MRR. In this work, we discuss the\nextensive experiments we have conducted to demonstrate the effectiveness of our\nmodel components. We also provide visualization for the reasoning process from\nthe relevant conversation rounds and discuss our fine-tuning methods. Our code\nis available at https://github.com/xiaoxiaoheimei/SeqDialN\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 04:57:54 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Yang", "Liu", ""], ["Meng", "Fanqi", ""], ["Wu", "Ming-Kuang Daniel", ""], ["Ying", "Vicent", ""], ["Xu", "Xianchao", ""]]}, {"id": "2008.00404", "submitter": "Yixin Su", "authors": "Yixin Su, Rui Zhang, Sarah Erfani, Zhenghua Xu", "title": "Detecting Beneficial Feature Interactions for Recommender Systems", "comments": "14 pages, 7 figures, 5 tables, AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature interactions are essential for achieving high accuracy in recommender\nsystems. Many studies take into account the interaction between every pair of\nfeatures. However, this is suboptimal because some feature interactions may not\nbe that relevant to the recommendation result, and taking them into account may\nintroduce noise and decrease recommendation accuracy. To make the best out of\nfeature interactions, we propose a graph neural network approach to effectively\nmodel them, together with a novel technique to automatically detect those\nfeature interactions that are beneficial in terms of recommendation accuracy.\nThe automatic feature interaction detection is achieved via edge prediction\nwith an L0 activation regularization. Our proposed model is proved to be\neffective through the information bottleneck principle and statistical\ninteraction theory. Experimental results show that our model (i) outperforms\nexisting baselines in terms of accuracy, and (ii) automatically identifies\nbeneficial feature interactions.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 06:08:23 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 04:51:57 GMT"}, {"version": "v3", "created": "Sat, 26 Sep 2020 02:23:31 GMT"}, {"version": "v4", "created": "Sat, 2 Jan 2021 06:37:45 GMT"}, {"version": "v5", "created": "Tue, 30 Mar 2021 00:47:40 GMT"}, {"version": "v6", "created": "Tue, 18 May 2021 11:57:21 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Su", "Yixin", ""], ["Zhang", "Rui", ""], ["Erfani", "Sarah", ""], ["Xu", "Zhenghua", ""]]}, {"id": "2008.00408", "submitter": "Jonathan Pan", "authors": "Jonathan Pan", "title": "Blackbox Trojanising of Deep Learning Models : Using non-intrusive\n  network structure and binary alterations", "comments": "6 pages, 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in Artificial Intelligence namely in Deep Learning has\nheightened its adoption in many applications. Some are playing important roles\nto the extent that we are heavily dependent on them for our livelihood.\nHowever, as with all technologies, there are vulnerabilities that malicious\nactors could exploit. A form of exploitation is to turn these technologies,\nintended for good, to become dual-purposed instruments to support deviant acts\nlike malicious software trojans. As part of proactive defense, researchers are\nproactively identifying such vulnerabilities so that protective measures could\nbe developed subsequently. This research explores a novel blackbox trojanising\napproach using a simple network structure modification to any deep learning\nimage classification model that would transform a benign model into a deviant\none with a simple manipulation of the weights to induce specific types of\nerrors. Propositions to protect the occurrence of such simple exploits are\ndiscussed in this research. This research highlights the importance of\nproviding sufficient safeguards to these models so that the intended good of AI\ninnovation and adoption may be protected.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 06:33:47 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Pan", "Jonathan", ""]]}, {"id": "2008.00410", "submitter": "Yashesh Dhebar", "authors": "Yashesh Dhebar and Kalyanmoy Deb", "title": "Interpretable Rule Discovery Through Bilevel Optimization of Split-Rules\n  of Nonlinear Decision Trees for Classification Problems", "comments": "Total 26 pages and 30 figures. Main Paper: 12 pages, 12 figures.\n  Supplementary Document: 14 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For supervised classification problems involving design, control, other\npractical purposes, users are not only interested in finding a highly accurate\nclassifier, but they also demand that the obtained classifier be easily\ninterpretable. While the definition of interpretability of a classifier can\nvary from case to case, here, by a humanly interpretable classifier we restrict\nit to be expressed in simplistic mathematical terms. As a novel approach, we\nrepresent a classifier as an assembly of simple mathematical rules using a\nnon-linear decision tree (NLDT). Each conditional (non-terminal) node of the\ntree represents a non-linear mathematical rule (split-rule) involving features\nin order to partition the dataset in the given conditional node into two\nnon-overlapping subsets. This partitioning is intended to minimize the impurity\nof the resulting child nodes. By restricting the structure of split-rule at\neach conditional node and depth of the decision tree, the interpretability of\nthe classifier is assured. The non-linear split-rule at a given conditional\nnode is obtained using an evolutionary bilevel optimization algorithm, in which\nwhile the upper-level focuses on arriving at an interpretable structure of the\nsplit-rule, the lower-level achieves the most appropriate weights\n(coefficients) of individual constituents of the rule to minimize the net\nimpurity of two resulting child nodes. The performance of the proposed\nalgorithm is demonstrated on a number of controlled test problems, existing\nbenchmark problems, and industrial problems. Results on two to 500-feature\nproblems are encouraging and open up further scopes of applying the proposed\napproach to more challenging and complex classification tasks.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 06:35:32 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Dhebar", "Yashesh", ""], ["Deb", "Kalyanmoy", ""]]}, {"id": "2008.00422", "submitter": "Themistoklis Botsas", "authors": "Themistoklis Botsas, Lachlan R. Mason and Indranil Pan", "title": "Rule-based Bayesian regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel rule-based approach for handling regression problems.\nThe new methodology carries elements from two frameworks: (i) it provides\ninformation about the uncertainty of the parameters of interest using Bayesian\ninference, and (ii) it allows the incorporation of expert knowledge through\nrule-based systems. The blending of those two different frameworks can be\nparticularly beneficial for various domains (e.g. engineering), where, even\nthough the significance of uncertainty quantification motivates a Bayesian\napproach, there is no simple way to incorporate researcher intuition into the\nmodel. We validate our models by applying them to synthetic applications: a\nsimple linear regression problem and two more complex structures based on\npartial differential equations. Finally, we review the advantages of our\nmethodology, which include the simplicity of the implementation, the\nuncertainty reduction due to the added information and, in some occasions, the\nderivation of better point predictions, and we address limitations, mainly from\nthe computational complexity perspective, such as the difficulty in choosing an\nappropriate algorithm and the added computational burden.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 07:20:45 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Botsas", "Themistoklis", ""], ["Mason", "Lachlan R.", ""], ["Pan", "Indranil", ""]]}, {"id": "2008.00444", "submitter": "Pablo Montero Manso", "authors": "Pablo Montero-Manso and Rob J Hyndman", "title": "Principles and Algorithms for Forecasting Groups of Time Series:\n  Locality and Globality", "comments": "version preprint IJF", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting groups of time series is of increasing practical importance, e.g.\nforecasting the demand for multiple products offered by a retailer or server\nloads within a data center. The local approach to this problem considers each\ntime series separately and fits a function or model to each series. The global\napproach fits a single function to all series. For groups of similar time\nseries, global methods outperform the more established local methods. However,\nrecent results show good performance of global models even in heterogeneous\ndatasets. This suggests a more general applicability of global methods,\npotentially leading to more accurate tools and new scenarios to study.\n  Formalizing the setting of forecasting a set of time series with local and\nglobal methods, we provide the following contributions:\n  1) Global methods are not more restrictive than local methods, both can\nproduce the same forecasts without any assumptions about similarity of the\nseries. Global models can succeed in a wider range of problems than previously\nthought.\n  2) Basic generalization bounds for local and global algorithms. The\ncomplexity of local methods grows with the size of the set while it remains\nconstant for global methods. In large datasets, a global algorithm can afford\nto be quite complex and still benefit from better generalization. These bounds\nserve to clarify and support recent experimental results in the field, and\nguide the design of new algorithms. For the class of autoregressive models,\nthis implies that global models can have much larger memory than local methods.\n  3) In an extensive empirical study, purposely naive algorithms derived from\nthese principles, such as global linear models or deep networks result in\nsuperior accuracy.\n  In particular, global linear models can provide competitive accuracy with two\norders of magnitude fewer parameters than local methods.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 10:22:05 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 07:37:02 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 23:34:48 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Montero-Manso", "Pablo", ""], ["Hyndman", "Rob J", ""]]}, {"id": "2008.00456", "submitter": "Iman Nematollahi", "authors": "Iman Nematollahi and Oier Mees and Lukas Hermann and Wolfram Burgard", "title": "Hindsight for Foresight: Unsupervised Structured Dynamics Models from\n  Physical Interaction", "comments": "Accepted at the 2020 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge for an agent learning to interact with the world is to reason\nabout physical properties of objects and to foresee their dynamics under the\neffect of applied forces. In order to scale learning through interaction to\nmany objects and scenes, robots should be able to improve their own performance\nfrom real-world experience without requiring human supervision. To this end, we\npropose a novel approach for modeling the dynamics of a robot's interactions\ndirectly from unlabeled 3D point clouds and images. Unlike previous approaches,\nour method does not require ground-truth data associations provided by a\ntracker or any pre-trained perception network. To learn from unlabeled\nreal-world interaction data, we enforce consistency of estimated 3D clouds,\nactions and 2D images with observed ones. Our joint forward and inverse network\nlearns to segment a scene into salient object parts and predicts their 3D\nmotion under the effect of applied actions. Moreover, our object-centric model\noutputs action-conditioned 3D scene flow, object masks and 2D optical flow as\nemergent properties. Our extensive evaluation both in simulation and with\nreal-world data demonstrates that our formulation leads to effective,\ninterpretable models that can be used for visuomotor control and planning.\nVideos, code and dataset are available at http://hind4sight.cs.uni-freiburg.de\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 11:04:49 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Nematollahi", "Iman", ""], ["Mees", "Oier", ""], ["Hermann", "Lukas", ""], ["Burgard", "Wolfram", ""]]}, {"id": "2008.00461", "submitter": "Oguzhan Gencoglu", "authors": "Oguzhan Gencoglu", "title": "Large-scale, Language-agnostic Discourse Classification of Tweets During\n  COVID-19", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": "10.3390/make2040032", "report-no": null, "categories": "cs.SI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying the characteristics of public attention is an essential\nprerequisite for appropriate crisis management during severe events such as\npandemics. For this purpose, we propose language-agnostic tweet representations\nto perform large-scale Twitter discourse classification with machine learning.\nOur analysis on more than 26 million COVID-19 tweets shows that large-scale\nsurveillance of public discourse is feasible with computationally lightweight\nclassifiers by out-of-the-box utilization of these representations.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 11:12:56 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 15:03:58 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Gencoglu", "Oguzhan", ""]]}, {"id": "2008.00476", "submitter": "Chang Liu", "authors": "Guanlin Li, Chang Liu, Han Yu, Yanhong Fan, Libang Zhang, Zongyue\n  Wang, Meiqin Wang", "title": "SCNet: A Neural Network for Automated Side-Channel Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The side-channel attack is an attack method based on the information gained\nabout implementations of computer systems, rather than weaknesses in\nalgorithms. Information about system characteristics such as power consumption,\nelectromagnetic leaks and sound can be exploited by the side-channel attack to\ncompromise the system. Much research effort has been directed towards this\nfield. However, such an attack still requires strong skills, thus can only be\nperformed effectively by experts. Here, we propose SCNet, which automatically\nperforms side-channel attacks. And we also design this network combining with\nside-channel domain knowledge and different deep learning model to improve the\nperformance and better to explain the result. The results show that our model\nachieves good performance with fewer parameters. The proposed model is a useful\ntool for automatically testing the robustness of computer systems.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 13:14:12 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Li", "Guanlin", ""], ["Liu", "Chang", ""], ["Yu", "Han", ""], ["Fan", "Yanhong", ""], ["Zhang", "Libang", ""], ["Wang", "Zongyue", ""], ["Wang", "Meiqin", ""]]}, {"id": "2008.00483", "submitter": "Zuyue Fu", "authors": "Zuyue Fu, Zhuoran Yang, Zhaoran Wang", "title": "Single-Timescale Actor-Critic Provably Finds Globally Optimal Policy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the global convergence and global optimality of actor-critic, one of\nthe most popular families of reinforcement learning algorithms. While most\nexisting works on actor-critic employ bi-level or two-timescale updates, we\nfocus on the more practical single-timescale setting, where the actor and\ncritic are updated simultaneously. Specifically, in each iteration, the critic\nupdate is obtained by applying the Bellman evaluation operator only once while\nthe actor is updated in the policy gradient direction computed using the\ncritic. Moreover, we consider two function approximation settings where both\nthe actor and critic are represented by linear or deep neural networks. For\nboth cases, we prove that the actor sequence converges to a globally optimal\npolicy at a sublinear $O(K^{-1/2})$ rate, where $K$ is the number of\niterations. To the best of our knowledge, we establish the rate of convergence\nand global optimality of single-timescale actor-critic with linear function\napproximation for the first time. Moreover, under the broader scope of policy\noptimization with nonlinear function approximation, we prove that actor-critic\nwith deep neural network finds the globally optimal policy at a sublinear rate\nfor the first time.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 14:01:49 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 05:25:16 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Fu", "Zuyue", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""]]}, {"id": "2008.00498", "submitter": "Zhicheng Cao", "authors": "Zhicheng Cao, Xi Cen and Liaojun Pang", "title": "HyperFaceNet: A Hyperspectral Face Recognition Method Based on Deep\n  Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face recognition has already been well studied under the visible light and\nthe infrared,in both intra-spectral and cross-spectral cases. However, how to\nfuse different light bands, i.e., hyperspectral face recognition, is still an\nopen research problem, which has the advantages of richer information retaining\nand all-weather functionality over single band face recognition. Among the very\nfew works for hyperspectral face recognition, traditional non-deep learning\ntechniques are largely used. Thus, we in this paper bring deep learning into\nthe topic of hyperspectral face recognition, and propose a new fusion model\n(termed HyperFaceNet) especially for hyperspectral faces. The proposed fusion\nmodel is characterized by residual dense learning, a feedback style encoder and\na recognition-oriented loss function. During the experiments, our method is\nproved to be of higher recognition rates than face recognition using either\nvisible light or the infrared. Moreover, our fusion model is shown to be\nsuperior to other general-purposed image fusion methods including\nstate-of-the-arts, in terms of both image quality and recognition performance.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 14:59:24 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 09:46:33 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Cao", "Zhicheng", ""], ["Cen", "Xi", ""], ["Pang", "Liaojun", ""]]}, {"id": "2008.00500", "submitter": "Zhide Wang", "authors": "Yanling Chang and Alfredo Garcia and Zhide Wang", "title": "Dynamic Discrete Choice Estimation with Partially Observable States and\n  Hidden Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic discrete choice models are used to estimate the intertemporal\npreferences of an agent as described by a reward function based upon observable\nhistories of states and implemented actions. However, in many applications,\nsuch as reliability and healthcare, the system state is only partially\nobservable or hidden (e.g., the level of deterioration of an engine, the\ncondition of a disease), and the decision maker only has access to information\nimperfectly correlated with the true value of the hidden state. In this paper,\nwe consider the estimation of a dynamic discrete choice model with state\nvariables and system dynamics hidden to both the agent and the modeler, thus\ngeneralizing the model in Rust(1987) to partially observable cases. We examine\nthe structural properties of the model and prove that this model is still\nidentifiable if the cardinality of the state space, the discount factor, the\ndistribution of random shocks, and the rewards for a given (reference) action\nare given. We analyze both theoretically and numerically the potential\nmis-specification errors that may be incurred when the Rust's model is\nimproperly used in partially observable settings. We further apply the model to\na subset of dataset in Rust(1987) for bus engine mileage and replacement\ndecisions. The results show that our model can improve model fit as measured by\nthe $\\log$-likelihood function by $17.73\\%$ and the $\\log$-likelihood ratio\ntest shows that our model statistically outperforms the Rust's model.\nInterestingly, our hidden state model also reveals an economically meaningful\nroute assignment behavior in the dataset which was hitherto ignored, i.e.\nroutes with lower mileage are assigned to buses believed to be in worse\ncondition.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 15:04:27 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 20:22:07 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Chang", "Yanling", ""], ["Garcia", "Alfredo", ""], ["Wang", "Zhide", ""]]}, {"id": "2008.00506", "submitter": "Yushuo Guan", "authors": "Yushuo Guan, Pengyu Zhao, Bingxuan Wang, Yuanxing Zhang, Cong Yao,\n  Kaigui Bian, Jian Tang", "title": "Differentiable Feature Aggregation Search for Knowledge Distillation", "comments": "A feature distillation method via differentiable architecture search", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation has become increasingly important in model\ncompression. It boosts the performance of a miniaturized student network with\nthe supervision of the output distribution and feature maps from a\nsophisticated teacher network. Some recent works introduce multi-teacher\ndistillation to provide more supervision to the student network. However, the\neffectiveness of multi-teacher distillation methods are accompanied by costly\ncomputation resources. To tackle with both the efficiency and the effectiveness\nof knowledge distillation, we introduce the feature aggregation to imitate the\nmulti-teacher distillation in the single-teacher distillation framework by\nextracting informative supervision from multiple teacher feature maps.\nSpecifically, we introduce DFA, a two-stage Differentiable Feature Aggregation\nsearch method that motivated by DARTS in neural architecture search, to\nefficiently find the aggregations. In the first stage, DFA formulates the\nsearching problem as a bi-level optimization and leverages a novel bridge loss,\nwhich consists of a student-to-teacher path and a teacher-to-student path, to\nfind appropriate feature aggregations. The two paths act as two players against\neach other, trying to optimize the unified architecture parameters to the\nopposite directions while guaranteeing both expressivity and learnability of\nthe feature aggregation simultaneously. In the second stage, DFA performs\nknowledge distillation with the derived feature aggregation. Experimental\nresults show that DFA outperforms existing methods on CIFAR-100 and CINIC-10\ndatasets under various teacher-student settings, verifying the effectiveness\nand robustness of the design.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 15:42:29 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Guan", "Yushuo", ""], ["Zhao", "Pengyu", ""], ["Wang", "Bingxuan", ""], ["Zhang", "Yuanxing", ""], ["Yao", "Cong", ""], ["Bian", "Kaigui", ""], ["Tang", "Jian", ""]]}, {"id": "2008.00511", "submitter": "Andrea Bassich", "authors": "Andrea Bassich, Francesco Foglino, Matteo Leonetti and Daniel Kudenko", "title": "Curriculum Learning with a Progression Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curriculum Learning for Reinforcement Learning is an increasingly popular\ntechnique that involves training an agent on a defined sequence of intermediate\ntasks, called a Curriculum, to increase the agent's performance and learning\nspeed. This paper introduces a novel paradigm for automatic curriculum\ngeneration based on a progression of task complexity. Different progression\nfunctions are introduced, including an autonomous online task progression based\non the performance of the agent. The progression function also determines how\nlong the agent should train on each intermediate task, which is an open problem\nin other task-based curriculum approaches. The benefits and wide applicability\nof our approach are shown by empirically comparing its performance to two\nstate-of-the-art Curriculum Learning algorithms on a grid world and on a\ncomplex simulated navigation domain.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 16:18:41 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Bassich", "Andrea", ""], ["Foglino", "Francesco", ""], ["Leonetti", "Matteo", ""], ["Kudenko", "Daniel", ""]]}, {"id": "2008.00524", "submitter": "Snehal Jauhri", "authors": "Snehal Jauhri, Carlos Celemin, Jens Kober", "title": "Interactive Imitation Learning in State-Space", "comments": "Presented at the 4th Conference on Robot Learning (CoRL) 2020, 11\n  pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation Learning techniques enable programming the behavior of agents\nthrough demonstrations rather than manual engineering. However, they are\nlimited by the quality of available demonstration data. Interactive Imitation\nLearning techniques can improve the efficacy of learning since they involve\nteachers providing feedback while the agent executes its task. In this work, we\npropose a novel Interactive Learning technique that uses human feedback in\nstate-space to train and improve agent behavior (as opposed to alternative\nmethods that use feedback in action-space). Our method titled Teaching\nImitative Policies in State-space~(TIPS) enables providing guidance to the\nagent in terms of `changing its state' which is often more intuitive for a\nhuman demonstrator. Through continuous improvement via corrective feedback,\nagents trained by non-expert demonstrators using TIPS outperformed the\ndemonstrator and conventional Imitation Learning agents.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 17:23:54 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 11:37:48 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Jauhri", "Snehal", ""], ["Celemin", "Carlos", ""], ["Kober", "Jens", ""]]}, {"id": "2008.00539", "submitter": "Aaron Hein", "authors": "Aaron Hein, Casey Cole, Homayoun Valafar", "title": "An Investigation in Optimal Encoding of Protein Primary Sequence for\n  Structure Prediction by Artificial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and the use of neural networks has increased precipitously\nover the past few years primarily due to the ever-increasing accessibility to\ndata and the growth of computation power. It has become increasingly easy to\nharness the power of machine learning for predictive tasks. Protein structure\nprediction is one area where neural networks are becoming increasingly popular\nand successful. Although very powerful, the use of ANN require selection of\nmost appropriate input/output encoding, architecture, and class to produce the\noptimal results. In this investigation we have explored and evaluated the\neffect of several conventional and newly proposed input encodings and selected\nan optimal architecture. We considered 11 variations of input encoding, 11\nalternative window sizes, and 7 different architectures. In total, we evaluated\n2,541 permutations in application to the training and testing of more than\n10,000 protein structures over the course of 3 months. Our investigations\nconcluded that one-hot encoding, the use of LSTMs, and window sizes of 9, 11,\nand 15 produce the optimal outcome. Through this optimization, we were able to\nimprove the quality of protein structure prediction by predicting the {\\phi}\ndihedrals to within 14{\\deg} - 16{\\deg} and {\\psi} dihedrals to within\n23{\\deg}- 25{\\deg}. This is a notable improvement compared to previously\nsimilar investigations.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 18:57:01 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Hein", "Aaron", ""], ["Cole", "Casey", ""], ["Valafar", "Homayoun", ""]]}, {"id": "2008.00544", "submitter": "Wentian Zhao", "authors": "Wentian Zhao, Seokhwan Kim, Ning Xu, Hailin Jin", "title": "Video Question Answering on Screencast Tutorials", "comments": null, "journal-ref": null, "doi": "10.24963/ijcai.2020/148", "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new video question answering task on screencast\ntutorials. We introduce a dataset including question, answer and context\ntriples from the tutorial videos for a software. Unlike other video question\nanswering works, all the answers in our dataset are grounded to the domain\nknowledge base. An one-shot recognition algorithm is designed to extract the\nvisual cues, which helps enhance the performance of video question answering.\nWe also propose several baseline neural network architectures based on various\naspects of video contexts from the dataset. The experimental results\ndemonstrate that our proposed models significantly improve the question\nanswering performances by incorporating multi-modal contexts and domain\nknowledge.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 19:27:42 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zhao", "Wentian", ""], ["Kim", "Seokhwan", ""], ["Xu", "Ning", ""], ["Jin", "Hailin", ""]]}, {"id": "2008.00546", "submitter": "Janith C. Petangoda", "authors": "Janith Petangoda, Nick A. M. Monk and Marc Peter Deisenroth", "title": "A Foliated View of Transfer Learning", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning considers a learning process where a new task is solved by\ntransferring relevant knowledge from known solutions to related tasks. While\nthis has been studied experimentally, there lacks a foundational description of\nthe transfer learning problem that exposes what related tasks are, and how they\ncan be exploited. In this work, we present a definition for relatedness between\ntasks and identify foliations as a mathematical framework to represent such\nrelationships.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 19:30:59 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Petangoda", "Janith", ""], ["Monk", "Nick A. M.", ""], ["Deisenroth", "Marc Peter", ""]]}, {"id": "2008.00558", "submitter": "Barbara Benato", "authors": "Barbara Caroline Benato and Jancarlo Ferreira Gomes and Alexandru\n  Cristian Telea and Alexandre Xavier Falc\\~ao", "title": "Semi-supervised deep learning based on label propagation in a 2D\n  embedded space", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While convolutional neural networks need large labeled sets for training\nimages, expert human supervision of such datasets can be very laborious.\nProposed solutions propagate labels from a small set of supervised images to a\nlarge set of unsupervised ones to obtain sufficient truly-and-artificially\nlabeled samples to train a deep neural network model. Yet, such solutions need\nmany supervised images for validation. We present a loop in which a deep neural\nnetwork (VGG-16) is trained from a set with more correctly labeled samples\nalong iterations, created by using t-SNE to project the features of its last\nmax-pooling layer into a 2D embedded space in which labels are propagated using\nthe Optimum-Path Forest semi-supervised classifier. As the labeled set improves\nalong iterations, it improves the features of the neural network. We show that\nthis can significantly improve classification results on test data (using only\n1\\% to 5\\% of supervised samples) of three private challenging datasets and two\npublic ones.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 20:08:54 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 14:30:27 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Benato", "Barbara Caroline", ""], ["Gomes", "Jancarlo Ferreira", ""], ["Telea", "Alexandru Cristian", ""], ["Falc\u00e3o", "Alexandre Xavier", ""]]}, {"id": "2008.00565", "submitter": "Georgios Arvanitidis", "authors": "Georgios Arvanitidis, S{\\o}ren Hauberg, Bernhard Sch\\\"olkopf", "title": "Geometrically Enriched Latent Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common assumption in generative models is that the generator immerses the\nlatent space into a Euclidean ambient space. Instead, we consider the ambient\nspace to be a Riemannian manifold, which allows for encoding domain knowledge\nthrough the associated Riemannian metric. Shortest paths can then be defined\naccordingly in the latent space to both follow the learned manifold and respect\nthe ambient geometry. Through careful design of the ambient metric we can\nensure that shortest paths are well-behaved even for deterministic generators\nthat otherwise would exhibit a misleading bias. Experimentally we show that our\napproach improves interpretability of learned representations both using\nstochastic and deterministic generators.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 20:57:58 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Arvanitidis", "Georgios", ""], ["Hauberg", "S\u00f8ren", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2008.00569", "submitter": "Ivana G\\'omez", "authors": "Mar\\'ia Florencia Acosta and Hugo Aimar and Ivana G\\'omez", "title": "On Frink's type metrization of weighted graphs", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.LG math.AP math.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the technique of the metrization theorem of uniformities with countable\nbases, in this note we provide, test and compare an explicit algorithm to\nproduce a metric $d(x,y)$ between the vertices $x$ and $y$ of an affinity\nweighted undirected graph.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 21:28:59 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Acosta", "Mar\u00eda Florencia", ""], ["Aimar", "Hugo", ""], ["G\u00f3mez", "Ivana", ""]]}, {"id": "2008.00582", "submitter": "Verena Haunschmid", "authors": "Verena Haunschmid, Ethan Manilow, Gerhard Widmer", "title": "audioLIME: Listenable Explanations Using Source Separation", "comments": "In The 13th International Workshop on Machine Learning and Music,\n  ECML-PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are successfully applied in a wide variety of\nmusic information retrieval (MIR) tasks but their predictions are usually not\ninterpretable. We propose audioLIME, a method based on Local Interpretable\nModel-agnostic Explanations (LIME) extended by a musical definition of\nlocality. The perturbations used in LIME are created by switching on/off\ncomponents extracted by source separation which makes our explanations\nlistenable. We validate audioLIME on two different music tagging systems and\nshow that it produces sensible explanations in situations where a competing\nmethod cannot.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 23:05:02 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 05:37:39 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2020 08:55:19 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Haunschmid", "Verena", ""], ["Manilow", "Ethan", ""], ["Widmer", "Gerhard", ""]]}, {"id": "2008.00614", "submitter": "Xingyu Lu", "authors": "Xingyu Lu, Kimin Lee, Pieter Abbeel, Stas Tiomkin", "title": "Dynamics Generalization via Information Bottleneck in Deep Reinforcement\n  Learning", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the significant progress of deep reinforcement learning (RL) in\nsolving sequential decision making problems, RL agents often overfit to\ntraining environments and struggle to adapt to new, unseen environments. This\nprevents robust applications of RL in real world situations, where system\ndynamics may deviate wildly from the training settings. In this work, our\nprimary contribution is to propose an information theoretic regularization\nobjective and an annealing-based optimization method to achieve better\ngeneralization ability in RL agents. We demonstrate the extreme generalization\nbenefits of our approach in different domains ranging from maze navigation to\nrobotic tasks; for the first time, we show that agents can generalize to test\nparameters more than 10 standard deviations away from the training parameter\ndistribution. This work provides a principled way to improve generalization in\nRL by gradually removing information that is redundant for task-solving; it\nopens doors for the systematic study of generalization from training to\nextremely different testing settings, focusing on the established connections\nbetween information theory and machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 02:24:20 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Lu", "Xingyu", ""], ["Lee", "Kimin", ""], ["Abbeel", "Pieter", ""], ["Tiomkin", "Stas", ""]]}, {"id": "2008.00616", "submitter": "Yun-Ning Hung", "authors": "Yun-Ning Hung and Alexander Lerch", "title": "Multitask learning for instrument activation aware music source\n  separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Music source separation is a core task in music information retrieval which\nhas seen a dramatic improvement in the past years. Nevertheless, most of the\nexisting systems focus exclusively on the problem of source separation itself\nand ignore the utilization of other~---possibly related---~MIR tasks which\ncould lead to additional quality gains. In this work, we propose a novel\nmultitask structure to investigate using instrument activation information to\nimprove source separation performance. Furthermore, we investigate our system\non six independent instruments, a more realistic scenario than the three\ninstruments included in the widely-used MUSDB dataset, by leveraging a\ncombination of the MedleyDB and Mixing Secrets datasets. The results show that\nour proposed multitask model outperforms the baseline Open-Unmix model on the\nmixture of Mixing Secrets and MedleyDB dataset while maintaining comparable\nperformance on the MUSDB dataset.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 02:35:00 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Hung", "Yun-Ning", ""], ["Lerch", "Alexander", ""]]}, {"id": "2008.00623", "submitter": "Sachin Mehta", "authors": "Sachin Mehta, Marjan Ghazvininejad, Srinivasan Iyer, Luke Zettlemoyer,\n  Hannaneh Hajishirzi", "title": "DeLighT: Deep and Light-weight Transformer", "comments": "Accepted at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a deep and light-weight transformer, DeLighT, that delivers\nsimilar or better performance than standard transformer-based models with\nsignificantly fewer parameters. DeLighT more efficiently allocates parameters\nboth (1) within each Transformer block using the DeLighT transformation, a deep\nand light-weight transformation, and (2) across blocks using block-wise\nscaling, which allows for shallower and narrower DeLighT blocks near the input\nand wider and deeper DeLighT blocks near the output. Overall, DeLighT networks\nare 2.5 to 4 times deeper than standard transformer models and yet have fewer\nparameters and operations. Experiments on benchmark machine translation and\nlanguage modeling tasks show that DeLighT matches or improves the performance\nof baseline Transformers with 2 to 3 times fewer parameters on average. Our\nsource code is available at: \\url{https://github.com/sacmehta/delight}\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 03:08:29 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 21:30:28 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Mehta", "Sachin", ""], ["Ghazvininejad", "Marjan", ""], ["Iyer", "Srinivasan", ""], ["Zettlemoyer", "Luke", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "2008.00638", "submitter": "Dibakar Gope", "authors": "Dibakar Gope, Jesse Beu, Matthew Mattina", "title": "High Throughput Matrix-Matrix Multiplication between Asymmetric\n  Bit-Width Operands", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.CV cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix multiplications between asymmetric bit-width operands, especially\nbetween 8- and 4-bit operands are likely to become a fundamental kernel of many\nimportant workloads including neural networks and machine learning. While\nexisting SIMD matrix multiplication instructions for symmetric bit-width\noperands can support operands of mixed precision by zero- or sign-extending the\nnarrow operand to match the size of the other operands, they cannot exploit the\nbenefit of narrow bit-width of one of the operands. We propose a new SIMD\nmatrix multiplication instruction that uses mixed precision on its inputs (8-\nand 4-bit operands) and accumulates product values into narrower 16-bit output\naccumulators, in turn allowing the SIMD operation at 128-bit vector width to\nprocess a greater number of data elements per instruction to improve processing\nthroughput and memory bandwidth utilization without increasing the register\nread- and write-port bandwidth in CPUs. The proposed asymmetric-operand-size\nSIMD instruction offers 2x improvement in throughput of matrix multiplication\nin comparison to throughput obtained using existing symmetric-operand-size\ninstructions while causing negligible (0.05%) overflow from 16-bit accumulators\nfor representative machine learning workloads. The asymmetric-operand-size\ninstruction not only can improve matrix multiplication throughput in CPUs, but\nalso can be effective to support multiply-and-accumulate (MAC) operation\nbetween 8- and 4-bit operands in state-of-the-art DNN hardware accelerators\n(e.g., systolic array microarchitecture in Google TPU, etc.) and offer similar\nimprovement in matrix multiply performance seamlessly without violating the\nvarious implementation constraints. We demonstrate how a systolic array\narchitecture designed for symmetric-operand-size instructions could be modified\nto support an asymmetric-operand-sized instruction.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 04:12:31 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Gope", "Dibakar", ""], ["Beu", "Jesse", ""], ["Mattina", "Matthew", ""]]}, {"id": "2008.00645", "submitter": "Zhenghang Cui", "authors": "Zhenghang Cui, Issei Sato", "title": "Active Classification with Uncertainty Comparison Queries", "comments": "Code and Dataset: https://github.com/zchenry/uncertainty-comparison", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noisy pairwise comparison feedback has been incorporated to improve the\noverall query complexity of interactively learning binary classifiers. The\n\\textit{positivity comparison oracle} is used to provide feedback on which is\nmore likely to be positive given a pair of data points. Because it is\nimpossible to infer accurate labels using this oracle alone \\textit{without\nknowing the classification threshold}, existing methods still rely on the\ntraditional \\textit{explicit labeling oracle}, which directly answers the label\ngiven a data point. Existing methods conduct sorting on all data points and use\nexplicit labeling oracle to find the classification threshold. The current\nmethods, however, have two drawbacks: (1) they needs unnecessary sorting for\nlabel inference; (2) quick sort is naively adapted to noisy feedback and\nnegatively affects practical performance. In order to avoid this inefficiency\nand acquire information of the classification threshold, we propose a new\npairwise comparison oracle concerning uncertainties. This oracle receives two\ndata points as input and answers which one has higher uncertainty. We then\npropose an efficient adaptive labeling algorithm using the proposed oracle and\nthe positivity comparison oracle. In addition, we also address the situation\nwhere the labeling budget is insufficient compared to the dataset size, which\ncan be dealt with by plugging the proposed algorithm into an active learning\nalgorithm. Furthermore, we confirm the feasibility of the proposed oracle and\nthe performance of the proposed algorithm theoretically and empirically.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 04:57:01 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 11:07:02 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Cui", "Zhenghang", ""], ["Sato", "Issei", ""]]}, {"id": "2008.00646", "submitter": "Sercan Arik", "authors": "Sercan O. Arik, Chun-Liang Li, Jinsung Yoon, Rajarishi Sinha, Arkady\n  Epshteyn, Long T. Le, Vikas Menon, Shashank Singh, Leyou Zhang, Nate Yoder,\n  Martin Nikoltchev, Yash Sonthalia, Hootan Nakhost, Elli Kanal and Tomas\n  Pfister", "title": "Interpretable Sequence Learning for COVID-19 Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach that integrates machine learning into\ncompartmental disease modeling to predict the progression of COVID-19. Our\nmodel is explainable by design as it explicitly shows how different\ncompartments evolve and it uses interpretable encoders to incorporate\ncovariates and improve performance. Explainability is valuable to ensure that\nthe model's forecasts are credible to epidemiologists and to instill confidence\nin end-users such as policy makers and healthcare institutions. Our model can\nbe applied at different geographic resolutions, and here we demonstrate it for\nstates and counties in the United States. We show that our model provides more\naccurate forecasts, in metrics averaged across the entire US, than\nstate-of-the-art alternatives, and that it provides qualitatively meaningful\nexplanatory insights. Lastly, we analyze the performance of our model for\ndifferent subgroups based on the subgroup distributions within the counties.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 05:02:57 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 16:48:42 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Arik", "Sercan O.", ""], ["Li", "Chun-Liang", ""], ["Yoon", "Jinsung", ""], ["Sinha", "Rajarishi", ""], ["Epshteyn", "Arkady", ""], ["Le", "Long T.", ""], ["Menon", "Vikas", ""], ["Singh", "Shashank", ""], ["Zhang", "Leyou", ""], ["Yoder", "Nate", ""], ["Nikoltchev", "Martin", ""], ["Sonthalia", "Yash", ""], ["Nakhost", "Hootan", ""], ["Kanal", "Elli", ""], ["Pfister", "Tomas", ""]]}, {"id": "2008.00665", "submitter": "Savvas Karatsiolis", "authors": "Savvas Karatsiolis and Andreas Kamilaris", "title": "The pursuit of beauty: Converting image labels to meaningful vectors", "comments": "20 pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A challenge of the computer vision community is to understand the semantics\nof an image, in order to allow image reconstruction based on existing\nhigh-level features or to better analyze (semi-)labelled datasets. Towards\naddressing this challenge, this paper introduces a method, called\nOcclusion-based Latent Representations (OLR), for converting image labels to\nmeaningful representations that capture a significant amount of data semantics.\nBesides being informational rich, these representations compose a disentangled\nlow-dimensional latent space where each image label is encoded into a separate\nvector. We evaluate the quality of these representations in a series of\nexperiments whose results suggest that the proposed model can capture data\nconcepts and discover data interrelations.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 06:33:11 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Karatsiolis", "Savvas", ""], ["Kamilaris", "Andreas", ""]]}, {"id": "2008.00679", "submitter": "Joewie Koh", "authors": "Joewie J. Koh, Guohui Ding, Christoffer Heckman, Lijun Chen,\n  Alessandro Roncone", "title": "Cooperative Control of Mobile Robots with Stackelberg Learning", "comments": "8 pages, 7 figures", "journal-ref": "Proceedings of the 2020 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS), 2020, pp. 7985-7992", "doi": "10.1109/IROS45743.2020.9341376", "report-no": null, "categories": "cs.RO cs.GT cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-robot cooperation requires agents to make decisions that are consistent\nwith the shared goal without disregarding action-specific preferences that\nmight arise from asymmetry in capabilities and individual objectives. To\naccomplish this goal, we propose a method named SLiCC: Stackelberg Learning in\nCooperative Control. SLiCC models the problem as a partially observable\nstochastic game composed of Stackelberg bimatrix games, and uses deep\nreinforcement learning to obtain the payoff matrices associated with these\ngames. Appropriate cooperative actions are then selected with the derived\nStackelberg equilibria. Using a bi-robot cooperative object transportation\nproblem, we validate the performance of SLiCC against centralized multi-agent\nQ-learning and demonstrate that SLiCC achieves better combined utility.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 07:21:51 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Koh", "Joewie J.", ""], ["Ding", "Guohui", ""], ["Heckman", "Christoffer", ""], ["Chen", "Lijun", ""], ["Roncone", "Alessandro", ""]]}, {"id": "2008.00682", "submitter": "Qiang Lyu", "authors": "Liyao Lu and Qiang Lyu", "title": "Discovering indicators of dark horse of soccer games by deep learning\n  from sequential trading data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is not surprise for machine learning models to provide decent prediction\naccuracy of soccer games outcomes based on various objective metrics. However,\nthe performance is not that decent in terms of predicting difficult and\nvaluable matches. A deep learning model is designed and trained on a real\nsequential trading data from the real prediction market, with the assumption\nthat such trading data contain critical latent information to determine the\ngame outcomes. A new loss function is proposed which biases the selection\ntoward matches with high investment return to train our model. Full\ninvestigation of 4669 top soccer league matches showed that our model traded\noff prediction accuracy for high value return due to a certain ability to\ndetect dark horses. A further try is conducted to depict some indicators\ndiscovered by our model for describing key features of big dark horses and\nregular hot horses.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 07:24:29 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 01:59:51 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Lu", "Liyao", ""], ["Lyu", "Qiang", ""]]}, {"id": "2008.00691", "submitter": "Brian Coyle", "authors": "Brian Coyle, Maxwell Henderson, Justin Chan Jin Le, Niraj Kumar, Marco\n  Paini, Elham Kashefi", "title": "Quantum versus Classical Generative Modelling in Finance", "comments": "17 Pages, 19 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding a concrete use case for quantum computers in the near term is still\nan open question, with machine learning typically touted as one of the first\nfields which will be impacted by quantum technologies. In this work, we\ninvestigate and compare the capabilities of quantum versus classical models for\nthe task of generative modelling in machine learning. We use a real world\nfinancial dataset consisting of correlated currency pairs and compare two\nmodels in their ability to learn the resulting distribution - a restricted\nBoltzmann machine, and a quantum circuit Born machine. We provide extensive\nnumerical results indicating that the simulated Born machine always at least\nmatches the performance of the Boltzmann machine in this task, and demonstrates\nsuperior performance as the model scales. We perform experiments on both\nsimulated and physical quantum chips using the Rigetti forest platform, and\nalso are able to partially train the largest instance to date of a quantum\ncircuit Born machine on quantum hardware. Finally, by studying the entanglement\ncapacity of the training Born machines, we find that entanglement typically\nplays a role in the problem instances which demonstrate an advantage over the\nBoltzmann machine.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 07:50:33 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Coyle", "Brian", ""], ["Henderson", "Maxwell", ""], ["Le", "Justin Chan Jin", ""], ["Kumar", "Niraj", ""], ["Paini", "Marco", ""], ["Kashefi", "Elham", ""]]}, {"id": "2008.00698", "submitter": "Hanlin Chen", "authors": "Hanlin Chen, Baochang Zhang, Song Xue, Xuan Gong, Hong Liu, Rongrong\n  Ji, David Doermann", "title": "Anti-Bandit Neural Architecture Search for Model Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (DCNNs) have dominated as the best\nperformers in machine learning, but can be challenged by adversarial attacks.\nIn this paper, we defend against adversarial attacks using neural architecture\nsearch (NAS) which is based on a comprehensive search of denoising blocks,\nweight-free operations, Gabor filters and convolutions. The resulting\nanti-bandit NAS (ABanditNAS) incorporates a new operation evaluation measure\nand search process based on the lower and upper confidence bounds (LCB and\nUCB). Unlike the conventional bandit algorithm using UCB for evaluation only,\nwe use UCB to abandon arms for search efficiency and LCB for a fair competition\nbetween arms. Extensive experiments demonstrate that ABanditNAS is faster than\nother NAS methods, while achieving an $8.73\\%$ improvement over prior arts on\nCIFAR-10 under PGD-$7$.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 07:59:39 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 08:33:48 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Chen", "Hanlin", ""], ["Zhang", "Baochang", ""], ["Xue", "Song", ""], ["Gong", "Xuan", ""], ["Liu", "Hong", ""], ["Ji", "Rongrong", ""], ["Doermann", "David", ""]]}, {"id": "2008.00720", "submitter": "Dominik Alfke", "authors": "Dominik Alfke, Martin Stoll", "title": "Pseudoinverse Graph Convolutional Networks: Fast Filters Tailored for\n  Large Eigengaps of Dense Graphs and Hypergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) have proven to be successful tools for\nsemi-supervised classification on graph-based datasets. We propose a new GCN\nvariant whose three-part filter space is targeted at dense graphs. Examples\ninclude Gaussian graphs for 3D point clouds with an increased focus on\nnon-local information, as well as hypergraphs based on categorical data. These\ngraphs differ from the common sparse benchmark graphs in terms of the spectral\nproperties of their graph Laplacian. Most notably we observe large eigengaps,\nwhich are unfavorable for popular existing GCN architectures. Our method\novercomes these issues by utilizing the pseudoinverse of the Laplacian. Another\nkey ingredient is a low-rank approximation of the convolutional matrix,\nensuring computational efficiency and increasing accuracy at the same time. We\noutline how the necessary eigeninformation can be computed efficiently in each\napplications and discuss the appropriate choice of the only metaparameter, the\napproximation rank. We finally showcase our method's performance regarding\nruntime and accuracy in various experiments with real-world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 08:48:41 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 10:36:37 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Alfke", "Dominik", ""], ["Stoll", "Martin", ""]]}, {"id": "2008.00727", "submitter": "Alykhan Tejani", "authors": "Dalin Guo, Sofia Ira Ktena, Ferenc Huszar, Pranay Kumar Myana, Wenzhe\n  Shi, Alykhan Tejani", "title": "Deep Bayesian Bandits: Exploring in Online Personalized Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems trained in a continuous learning fashion are plagued by\nthe feedback loop problem, also known as algorithmic bias. This causes a newly\ntrained model to act greedily and favor items that have already been engaged by\nusers. This behavior is particularly harmful in personalised ads\nrecommendations, as it can also cause new campaigns to remain unexplored.\nExploration aims to address this limitation by providing new information about\nthe environment, which encompasses user preference, and can lead to higher\nlong-term reward. In this work, we formulate a display advertising recommender\nas a contextual bandit and implement exploration techniques that require\nsampling from the posterior distribution of click-through-rates in a\ncomputationally tractable manner. Traditional large-scale deep learning models\ndo not provide uncertainty estimates by default. We approximate these\nuncertainty measurements of the predictions by employing a bootstrapped model\nwith multiple heads and dropout units. We benchmark a number of different\nmodels in an offline simulation environment using a publicly available dataset\nof user-ads engagements. We test our proposed deep Bayesian bandits algorithm\nin the offline simulation and online AB setting with large-scale production\ntraffic, where we demonstrate a positive gain of our exploration model.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 08:58:18 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Guo", "Dalin", ""], ["Ktena", "Sofia Ira", ""], ["Huszar", "Ferenc", ""], ["Myana", "Pranay Kumar", ""], ["Shi", "Wenzhe", ""], ["Tejani", "Alykhan", ""]]}, {"id": "2008.00741", "submitter": "Ivan Anokhin", "authors": "Ivan Anokhin, Dmitry Yarotsky", "title": "Low-loss connection of weight vectors: distribution-based approaches", "comments": "accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research shows that sublevel sets of the loss surfaces of\noverparameterized networks are connected, exactly or approximately. We describe\nand compare experimentally a panel of methods used to connect two low-loss\npoints by a low-loss curve on this surface. Our methods vary in accuracy and\ncomplexity. Most of our methods are based on \"macroscopic\" distributional\nassumptions, and some are insensitive to the detailed properties of the points\nto be connected. Some methods require a prior training of a \"global connection\nmodel\" which can then be applied to any pair of points. The accuracy of the\nmethod generally correlates with its complexity and sensitivity to the endpoint\ndetail.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 09:42:47 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Anokhin", "Ivan", ""], ["Yarotsky", "Dmitry", ""]]}, {"id": "2008.00742", "submitter": "L\\^e-Nguy\\^en Hoang", "authors": "El-Mahdi El-Mhamdi, Sadegh Farhadkhani, Rachid Guerraoui, Arsany\n  Guirguis, L\\^e Nguy\\^en Hoang, S\\'ebastien Rouault", "title": "Collaborative Learning in the Jungle", "comments": "34 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Byzantine collaborative learning, where $n$ nodes seek to\ncollectively learn from each others' local data. The data distribution may vary\nfrom one node to another. No node is trusted, and $f < n$ nodes can behave\narbitrarily. We prove that collaborative learning is equivalent to a new form\nof agreement, which we call averaging agreement. In this problem, nodes start\neach with an initial vector and seek to approximately agree on a common vector,\nwhich is close to the average of honest nodes' initial vectors. We present two\nasynchronous solutions to averaging agreement, each we prove optimal according\nto some dimension. The first, based on the minimum-diameter averaging, requires\n$ n \\geq 6f+1$, but achieves asymptotically the best-possible averaging\nconstant up to a multiplicative constant. The second, based on reliable\nbroadcast and coordinate-wise trimmed mean, achieves optimal Byzantine\nresilience, i.e., $n \\geq 3f+1$. Each of these algorithms induces an optimal\nByzantine collaborative learning protocol. In particular, our equivalence\nyields new impossibility theorems on what any collaborative learning algorithm\ncan achieve in adversarial and heterogeneous environments.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 09:44:07 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 09:56:27 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2020 16:30:24 GMT"}, {"version": "v4", "created": "Mon, 7 Jun 2021 15:05:52 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["El-Mhamdi", "El-Mahdi", ""], ["Farhadkhani", "Sadegh", ""], ["Guerraoui", "Rachid", ""], ["Guirguis", "Arsany", ""], ["Hoang", "L\u00ea Nguy\u00ean", ""], ["Rouault", "S\u00e9bastien", ""]]}, {"id": "2008.00748", "submitter": "Shuqiang Wang", "authors": "Wen Yu, Baiying Lei, Michael K.Ng, Albert C.Cheung, Yanyan Shen,\n  Shuqiang Wang", "title": "Tensorizing GAN with High-Order Pooling for Alzheimer's Disease\n  Assessment", "comments": "15 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is of great significance to apply deep learning for the early diagnosis of\nAlzheimer's Disease (AD). In this work, a novel tensorizing GAN with high-order\npooling is proposed to assess Mild Cognitive Impairment (MCI) and AD. By\ntensorizing a three-player cooperative game based framework, the proposed model\ncan benefit from the structural information of the brain. By incorporating the\nhigh-order pooling scheme into the classifier, the proposed model can make full\nuse of the second-order statistics of the holistic Magnetic Resonance Imaging\n(MRI) images. To the best of our knowledge, the proposed Tensor-train,\nHigh-pooling and Semi-supervised learning based GAN (THS-GAN) is the first work\nto deal with classification on MRI images for AD diagnosis. Extensive\nexperimental results on Alzheimer's Disease Neuroimaging Initiative (ADNI)\ndataset are reported to demonstrate that the proposed THS-GAN achieves superior\nperformance compared with existing methods, and to show that both tensor-train\nand high-order pooling can enhance classification performance. The\nvisualization of generated samples also shows that the proposed model can\ngenerate plausible samples for semi-supervised learning purpose.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 10:04:09 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Yu", "Wen", ""], ["Lei", "Baiying", ""], ["Ng", "Michael K.", ""], ["Cheung", "Albert C.", ""], ["Shen", "Yanyan", ""], ["Wang", "Shuqiang", ""]]}, {"id": "2008.00752", "submitter": "Liping Zhang", "authors": "Liping Zhang, Weijun Li, Lina Yu, Xiaoli Dong, Linjun Sun, Xin Ning,\n  Jian Xu, and Hong Qin", "title": "GmFace: A Mathematical Model for Face Image Representation Using\n  Multi-Gaussian", "comments": "12 pages, 12 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Establishing mathematical models is a ubiquitous and effective method to\nunderstand the objective world. Due to complex physiological structures and\ndynamic behaviors, mathematical representation of the human face is an\nespecially challenging task. A mathematical model for face image representation\ncalled GmFace is proposed in the form of a multi-Gaussian function in this\npaper. The model utilizes the advantages of two-dimensional Gaussian function\nwhich provides a symmetric bell surface with a shape that can be controlled by\nparameters. The GmNet is then designed using Gaussian functions as neurons,\nwith parameters that correspond to each of the parameters of GmFace in order to\ntransform the problem of GmFace parameter solving into a network optimization\nproblem of GmNet. The face modeling process can be described by the following\nsteps: (1) GmNet initialization; (2) feeding GmNet with face image(s); (3)\ntraining GmNet until convergence; (4) drawing out the parameters of GmNet (as\nthe same as GmFace); (5) recording the face model GmFace. Furthermore, using\nGmFace, several face image transformation operations can be realized\nmathematically through simple parameter computation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 10:11:10 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zhang", "Liping", ""], ["Li", "Weijun", ""], ["Yu", "Lina", ""], ["Dong", "Xiaoli", ""], ["Sun", "Linjun", ""], ["Ning", "Xin", ""], ["Xu", "Jian", ""], ["Qin", "Hong", ""]]}, {"id": "2008.00756", "submitter": "Rohit M A", "authors": "Rohit M. A., Preeti Rao", "title": "Structure and Automatic Segmentation of Dhrupad Vocal Bandish Audio", "comments": "Part of this work published in ISMIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A Dhrupad vocal concert comprises a composition section that is interspersed\nwith improvised episodes of increased rhythmic activity involving the\ninteraction between the vocals and the percussion. Tracking the changing\nrhythmic density, in relation to the underlying metric tempo of the piece, thus\nfacilitates the detection and labeling of the improvised sections in the\nconcert structure. This work concerns the automatic detection of the musically\nrelevant rhythmic densities as they change in time across the bandish\n(composition) performance. An annotated dataset of Dhrupad bandish concert\nsections is presented. We investigate a CNN-based system, trained to detect\nlocal tempo relationships, and follow it with temporal smoothing. We also\nemploy audio source separation as a pre-processing step to the detection of the\nindividual surface densities of the vocals and the percussion. This helps us\nobtain the complete musical description of the concert sections in terms of\ncapturing the changing rhythmic interaction of the two performers.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 10:16:42 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["A.", "Rohit M.", ""], ["Rao", "Preeti", ""]]}, {"id": "2008.00759", "submitter": "Marco Maggipinto", "authors": "Marco Maggipinto and Gian Antonio Susto and Pratik Chaudhari", "title": "Proximal Deterministic Policy Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces two simple techniques to improve off-policy\nReinforcement Learning (RL) algorithms. First, we formulate off-policy RL as a\nstochastic proximal point iteration. The target network plays the role of the\nvariable of optimization and the value network computes the proximal operator.\nSecond, we exploits the two value functions commonly employed in\nstate-of-the-art off-policy algorithms to provide an improved action value\nestimate through bootstrapping with limited increase of computational\nresources. Further, we demonstrate significant performance improvement over\nstate-of-the-art algorithms on standard continuous-control RL benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 10:19:59 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Maggipinto", "Marco", ""], ["Susto", "Gian Antonio", ""], ["Chaudhari", "Pratik", ""]]}, {"id": "2008.00760", "submitter": "Marco Maggipinto", "authors": "Marco Maggipinto and Matteo Terzi and Gian Antonio Susto", "title": "IntroVAC: Introspective Variational Classifiers for Learning\n  Interpretable Latent Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning useful representations of complex data has been the subject of\nextensive research for many years. With the diffusion of Deep Neural Networks,\nVariational Autoencoders have gained lots of attention since they provide an\nexplicit model of the data distribution based on an encoder/decoder\narchitecture which is able to both generate images and encode them in a\nlow-dimensional subspace. However, the latent space is not easily interpretable\nand the generation capabilities show some limitations since images typically\nlook blurry and lack details. In this paper, we propose the Introspective\nVariational Classifier (IntroVAC), a model that learns interpretable latent\nsubspaces by exploiting information from an additional label and provides\nimproved image quality thanks to an adversarial training strategy.We show that\nIntroVAC is able to learn meaningful directions in the latent space enabling\nfine-grained manipulation of image attributes. We validate our approach on the\nCelebA dataset.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 10:21:41 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 07:23:10 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Maggipinto", "Marco", ""], ["Terzi", "Matteo", ""], ["Susto", "Gian Antonio", ""]]}, {"id": "2008.00766", "submitter": "Timo Philipp Gros", "authors": "Timo P. Gros and Daniel H\\\"oller and J\\\"org Hoffmann and Verena Wolf", "title": "Tracking the Race Between Deep Reinforcement Learning and Imitation\n  Learning -- Extended Version", "comments": "Extended Version of the Conference Paper published in the Proceedings\n  of the 17th International Conference on Quantitative Evaluation of SysTems\n  (QEST)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based approaches for solving large sequential decision making\nproblems have become popular in recent years. The resulting agents perform\ndifferently and their characteristics depend on those of the underlying\nlearning approach. Here, we consider a benchmark planning problem from the\nreinforcement learning domain, the Racetrack, to investigate the properties of\nagents derived from different deep (reinforcement) learning approaches. We\ncompare the performance of deep supervised learning, in particular imitation\nlearning, to reinforcement learning for the Racetrack model. We find that\nimitation learning yields agents that follow more risky paths. In contrast, the\ndecisions of deep reinforcement learning are more foresighted, i.e., avoid\nstates in which fatal decisions are more likely. Our evaluations show that for\nthis sequential decision making problem, deep reinforcement learning performs\nbest in many aspects even though for imitation learning optimal decisions are\nconsidered.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 10:31:44 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Gros", "Timo P.", ""], ["H\u00f6ller", "Daniel", ""], ["Hoffmann", "J\u00f6rg", ""], ["Wolf", "Verena", ""]]}, {"id": "2008.00768", "submitter": "Tom\\'a\\v{s} Nekvinda", "authors": "Tom\\'a\\v{s} Nekvinda and Ond\\v{r}ej Du\\v{s}ek", "title": "One Model, Many Languages: Meta-learning for Multilingual Text-to-Speech", "comments": "Accepted to INTERSPEECH 2020; for the source files, see\n  https://github.com/Tomiinek/Multilingual_Text_to_Speech", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an approach to multilingual speech synthesis which uses the\nmeta-learning concept of contextual parameter generation and produces\nnatural-sounding multilingual speech using more languages and less training\ndata than previous approaches. Our model is based on Tacotron 2 with a fully\nconvolutional input text encoder whose weights are predicted by a separate\nparameter generator network. To boost voice cloning, the model uses an\nadversarial speaker classifier with a gradient reversal layer that removes\nspeaker-specific information from the encoder.\n  We arranged two experiments to compare our model with baselines using various\nlevels of cross-lingual parameter sharing, in order to evaluate: (1) stability\nand performance when training on low amounts of data, (2) pronunciation\naccuracy and voice quality of code-switching synthesis. For training, we used\nthe CSS10 dataset and our new small dataset based on Common Voice recordings in\nfive languages. Our model is shown to effectively share information across\nlanguages and according to a subjective evaluation test, it produces more\nnatural and accurate code-switching speech than the baselines.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 10:43:30 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Nekvinda", "Tom\u00e1\u0161", ""], ["Du\u0161ek", "Ond\u0159ej", ""]]}, {"id": "2008.00807", "submitter": "Christos Matsoukas", "authors": "Christos Matsoukas, Albert Bou I Hernandez, Yue Liu, Karin Dembrower,\n  Gisele Miranda, Emir Konuk, Johan Fredin Haslum, Athanasios Zouzos, Peter\n  Lindholm, Fredrik Strand, Kevin Smith", "title": "Adding Seemingly Uninformative Labels Helps in Low Data Regimes", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evidence suggests that networks trained on large datasets generalize well not\nsolely because of the numerous training examples, but also class diversity\nwhich encourages learning of enriched features. This raises the question of\nwhether this remains true when data is scarce - is there an advantage to\nlearning with additional labels in low-data regimes? In this work, we consider\na task that requires difficult-to-obtain expert annotations: tumor segmentation\nin mammography images. We show that, in low-data settings, performance can be\nimproved by complementing the expert annotations with seemingly uninformative\nlabels from non-expert annotators, turning the task into a multi-class problem.\nWe reveal that these gains increase when less expert data is available, and\nuncover several interesting properties through further studies. We demonstrate\nour findings on CSAW-S, a new dataset that we introduce here, and confirm them\non two public datasets.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 17:38:59 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 10:52:43 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Matsoukas", "Christos", ""], ["Hernandez", "Albert Bou I", ""], ["Liu", "Yue", ""], ["Dembrower", "Karin", ""], ["Miranda", "Gisele", ""], ["Konuk", "Emir", ""], ["Haslum", "Johan Fredin", ""], ["Zouzos", "Athanasios", ""], ["Lindholm", "Peter", ""], ["Strand", "Fredrik", ""], ["Smith", "Kevin", ""]]}, {"id": "2008.00809", "submitter": "Sumanth Chennupati", "authors": "Sumanth Chennupati, Sai Nooka, Shagan Sah, Raymond W Ptucha", "title": "Adaptive Hierarchical Decomposition of Large Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has recently demonstrated its ability to rival the human brain\nfor visual object recognition. As datasets get larger, a natural question to\nask is if existing deep learning architectures can be extended to handle the\n50+K classes thought to be perceptible by a typical human. Most deep learning\narchitectures concentrate on splitting diverse categories, while ignoring the\nsimilarities amongst them. This paper introduces a framework that automatically\nanalyzes and configures a family of smaller deep networks as a replacement to a\nsingular, larger network. Class similarities guide the creation of a family\nfrom course to fine classifiers which solve categorical problems more\neffectively than a single large classifier. The resulting smaller networks are\nhighly scalable, parallel and more practical to train, and achieve higher\nclassification accuracy. This paper also proposes a method to adaptively select\nthe configuration of the hierarchical family of classifiers using linkage\nstatistics from overall and sub-classification confusion matrices. Depending on\nthe number of classes and the complexity of the problem, a deep learning model\nis selected and the complexity is determined. Numerous experiments on network\nclasses, layers, and architecture configurations validate our results.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 21:04:50 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Chennupati", "Sumanth", ""], ["Nooka", "Sai", ""], ["Sah", "Shagan", ""], ["Ptucha", "Raymond W", ""]]}, {"id": "2008.00816", "submitter": "Shengbei Wang", "authors": "Weitao Yuan, Bofei Dong, Shengbei Wang, Masashi Unoki, and Wenwu Wang", "title": "Evolving Multi-Resolution Pooling CNN for Monaural Singing Voice\n  Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monaural Singing Voice Separation (MSVS) is a challenging task and has been\nstudied for decades. Deep neural networks (DNNs) are the current\nstate-of-the-art methods for MSVS. However, the existing DNNs are often\ndesigned manually, which is time-consuming and error-prone. In addition, the\nnetwork architectures are usually pre-defined, and not adapted to the training\ndata. To address these issues, we introduce a Neural Architecture Search (NAS)\nmethod to the structure design of DNNs for MSVS. Specifically, we propose a new\nmulti-resolution Convolutional Neural Network (CNN) framework for MSVS namely\nMulti-Resolution Pooling CNN (MRP-CNN), which uses various-size pooling\noperators to extract multi-resolution features. Based on the NAS, we then\ndevelop an evolving framework namely Evolving MRP-CNN (E-MRP-CNN), by\nautomatically searching the effective MRP-CNN structures using genetic\nalgorithms, optimized in terms of a single-objective considering only\nseparation performance, or multi-objective considering both the separation\nperformance and the model complexity. The multi-objective E-MRP-CNN gives a set\nof Pareto-optimal solutions, each providing a trade-off between separation\nperformance and model complexity. Quantitative and qualitative evaluations on\nthe MIR-1K and DSD100 datasets are used to demonstrate the advantages of the\nproposed framework over several recent baselines.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 12:09:42 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Yuan", "Weitao", ""], ["Dong", "Bofei", ""], ["Wang", "Shengbei", ""], ["Unoki", "Masashi", ""], ["Wang", "Wenwu", ""]]}, {"id": "2008.00821", "submitter": "Mohanad Abukmeil", "authors": "Mohanad Abukmeil and Gian Luca Marcialis", "title": "Experimental results on palmvein-based personal recognition by\n  multi-snapshot fusion of textural features", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we investigate multiple snapshot fusion of textural features\nfor palmvein recognition including identification and verification. Although\nthe literature proposed several approaches for palmvein recognition, the\npalmvein performance is still affected by identification and verification\nerrors. As well-known, palmveins are usually described by line-based methods\nwhich enhance the vein flow. This is claimed to be unique from person to\nperson. However, palmvein images are also characterized by texture that can be\npointed out by textural features, which relies on recent and efficient\nhand-crafted algorithms such as Local Binary Patterns, Local Phase\nQuantization, Local Tera Pattern, Local directional Pattern, and Binarized\nStatistical Image Features (LBP, LPQ, LTP, LDP and BSIF, respectively), among\nothers. Finally, they can be easily managed at feature-level fusion, when more\nthan one sample can be acquired for recognition. Therefore, multi-snapshot\nfusion can be adopted for exploiting these features complementarity. Our goal\nin this paper is to show that this is confirmed for palmvein recognition, thus\nallowing to achieve very high recognition rates on a well-known benchmark data\nset.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 11:34:46 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 12:00:52 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Abukmeil", "Mohanad", ""], ["Marcialis", "Gian Luca", ""]]}, {"id": "2008.00824", "submitter": "Ahnaf Lodhi", "authors": "Ahnaf Hannan Lodhi, Bar{\\i}\\c{s} Akg\\\"un, \\\"Oznur \\\"Ozkasap", "title": "State-of-the-art Techniques in Deep Edge Intelligence", "comments": "13 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The potential held by the gargantuan volumes of data being generated across\nnetworks worldwide has been truly unlocked by machine learning techniques and\nmore recently Deep Learning. The advantages offered by the latter have seen it\nrapidly becoming a framework of choice for various applications. However, the\ncentralization of computational resources and the need for data aggregation\nhave long been limiting factors in the democratization of Deep Learning\napplications. Edge Computing is an emerging paradigm that aims to utilize the\nhitherto untapped processing resources available at the network periphery. Edge\nIntelligence (EI) has quickly emerged as a powerful alternative to enable\nlearning using the concepts of Edge Computing. Deep Learning-based Edge\nIntelligence or Deep Edge Intelligence (DEI) lies in this rapidly evolving\ndomain. In this article, we provide an overview of the major constraints in\noperationalizing DEI. The major research avenues in DEI have been consolidated\nunder Federated Learning, Distributed Computation, Compression Schemes and\nConditional Computation. We also present some of the prevalent challenges and\nhighlight prospective research avenues.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 12:17:23 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 17:07:03 GMT"}, {"version": "v3", "created": "Thu, 24 Dec 2020 07:42:01 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Lodhi", "Ahnaf Hannan", ""], ["Akg\u00fcn", "Bar\u0131\u015f", ""], ["\u00d6zkasap", "\u00d6znur", ""]]}, {"id": "2008.00829", "submitter": "Abdul Mueed Hafiz Dr.", "authors": "Abdul Mueed Hafiz and Ghulam Mohiuddin Bhat", "title": "Deep Network Ensemble Learning applied to Image Classification using CNN\n  Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional machine learning approaches may fail to perform satisfactorily\nwhen dealing with complex data. In this context, the importance of data mining\nevolves w.r.t. building an efficient knowledge discovery and mining framework.\nEnsemble learning is aimed at integration of fusion, modeling and mining of\ndata into a unified model. However, traditional ensemble learning methods are\ncomplex and have optimization or tuning problems. In this paper, we propose a\nsimple, sequential, efficient, ensemble learning approach using multiple deep\nnetworks. The deep network used in the ensembles is ResNet50. The model draws\ninspiration from binary decision/classification trees. The proposed approach is\ncompared against the baseline viz. the single classifier approach i.e. using a\nsingle multiclass ResNet50 on the ImageNet and Natural Images datasets. Our\napproach outperforms the baseline on all experiments on the ImageNet dataset.\nCode is available in https://github.com/mueedhafiz1982/CNNTreeEnsemble.git\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 07:58:25 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Hafiz", "Abdul Mueed", ""], ["Bhat", "Ghulam Mohiuddin", ""]]}, {"id": "2008.00892", "submitter": "Shikun Liu", "authors": "Shikun Liu, Zhe Lin, Yilin Wang, Jianming Zhang, Federico Perazzi,\n  Edward Johns", "title": "Shape Adaptor: A Learnable Resizing Module", "comments": "Published at ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a novel resizing module for neural networks: shape adaptor, a\ndrop-in enhancement built on top of traditional resizing layers, such as\npooling, bilinear sampling, and strided convolution. Whilst traditional\nresizing layers have fixed and deterministic reshaping factors, our module\nallows for a learnable reshaping factor. Our implementation enables shape\nadaptors to be trained end-to-end without any additional supervision, through\nwhich network architectures can be optimised for each individual task, in a\nfully automated way. We performed experiments across seven image classification\ndatasets, and results show that by simply using a set of our shape adaptors\ninstead of the original resizing layers, performance increases consistently\nover human-designed networks, across all datasets. Additionally, we show the\neffectiveness of shape adaptors on two other applications: network compression\nand transfer learning. The source code is available at:\nhttps://github.com/lorenmt/shape-adaptor.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 14:15:52 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 13:10:50 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Liu", "Shikun", ""], ["Lin", "Zhe", ""], ["Wang", "Yilin", ""], ["Zhang", "Jianming", ""], ["Perazzi", "Federico", ""], ["Johns", "Edward", ""]]}, {"id": "2008.00930", "submitter": "YangQuan Chen Prof.", "authors": "Jairo Viola, YangQuan Chen and Jing Wang", "title": "FaultFace: Deep Convolutional Generative Adversarial Network (DCGAN)\n  based Ball-Bearing Failure Detection Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Failure detection is employed in the industry to improve system performance\nand reduce costs due to unexpected malfunction events. So, a good dataset of\nthe system is desirable for designing an automated failure detection system.\nHowever, industrial process datasets are unbalanced and contain little\ninformation about failure behavior due to the uniqueness of these events and\nthe high cost for running the system just to get information about the\nundesired behaviors. For this reason, performing correct training and\nvalidation of automated failure detection methods is challenging. This paper\nproposes a methodology called FaultFace for failure detection on Ball-Bearing\njoints for rotational shafts using deep learning techniques to create balanced\ndatasets. The FaultFace methodology uses 2D representations of vibration\nsignals denominated faceportraits obtained by time-frequency transformation\ntechniques. From the obtained faceportraits, a Deep Convolutional Generative\nAdversarial Network is employed to produce new faceportraits of the nominal and\nfailure behaviors to get a balanced dataset. A Convolutional Neural Network is\ntrained for fault detection employing the balanced dataset. The FaultFace\nmethodology is compared with other deep learning techniques to evaluate its\nperformance in for fault detection with unbalanced datasets. Obtained results\nshow that FaultFace methodology has a good performance for failure detection\nfor unbalanced datasets.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 06:37:53 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Viola", "Jairo", ""], ["Chen", "YangQuan", ""], ["Wang", "Jing", ""]]}, {"id": "2008.00937", "submitter": "Dimitrios Michael Manias", "authors": "Dimitrios Michael Manias and Abdallah Shami", "title": "The Need for Advanced Intelligence in NFV Management and Orchestration", "comments": "To Appear in IEEE Network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the constant demand for connectivity at an all-time high, Network\nService Providers (NSPs) are required to optimize their networks to cope with\nrising capital and operational expenditures required to meet the growing\nconnectivity demand. A solution to this challenge was presented through Network\nFunction Virtualization (NFV). As network complexity increases and futuristic\nnetworks take shape, NSPs are required to incorporate an increasing amount of\noperational efficiency into their NFV-enabled networks. One such technique is\nMachine Learning (ML), which has been applied to various entities in\nNFV-enabled networks, most notably in the NFV Orchestrator. While traditional\nML provides tremendous operational efficiencies, including real-time and\nhigh-volume data processing, challenges such as privacy, security, scalability,\ntransferability, and concept drift hinder its widespread implementation.\nThrough the adoption of Advanced Intelligence techniques such as Reinforcement\nLearning and Federated Learning, NSPs can leverage the benefits of traditional\nML while simultaneously addressing the major challenges traditionally\nassociated with it. This work presents the benefits of adopting these advanced\ntechniques, provides a list of potential use cases and research topics, and\nproposes a bottom-up micro-functionality approach to applying these methods of\nAdvanced Intelligence to NFV Management and Orchestration.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 15:17:42 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Manias", "Dimitrios Michael", ""], ["Shami", "Abdallah", ""]]}, {"id": "2008.00938", "submitter": "Aristide Baratin", "authors": "Aristide Baratin, Thomas George, C\\'esar Laurent, R Devon Hjelm,\n  Guillaume Lajoie, Pascal Vincent, Simon Lacoste-Julien", "title": "Implicit Regularization via Neural Feature Alignment", "comments": "AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We approach the problem of implicit regularization in deep learning from a\ngeometrical viewpoint. We highlight a regularization effect induced by a\ndynamical alignment of the neural tangent features introduced by Jacot et al,\nalong a small number of task-relevant directions. This can be interpreted as a\ncombined mechanism of feature selection and compression. By extrapolating a new\nanalysis of Rademacher complexity bounds for linear models, we motivate and\nstudy a heuristic complexity measure that captures this phenomenon, in terms of\nsequences of tangent kernel classes along optimization paths.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 15:18:07 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 17:04:22 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 00:57:56 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Baratin", "Aristide", ""], ["George", "Thomas", ""], ["Laurent", "C\u00e9sar", ""], ["Hjelm", "R Devon", ""], ["Lajoie", "Guillaume", ""], ["Vincent", "Pascal", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "2008.00942", "submitter": "Mingkui Tan", "authors": "Jiezhang Cao, Yong Guo, Qingyao Wu, Chunhua Shen, Junzhou Huang,\n  Mingkui Tan", "title": "Improving Generative Adversarial Networks with Local Coordinate Coding", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have shown remarkable success in\ngenerating realistic data from some predefined prior distribution (e.g.,\nGaussian noises). However, such prior distribution is often independent of real\ndata and thus may lose semantic information (e.g., geometric structure or\ncontent in images) of data. In practice, the semantic information might be\nrepresented by some latent distribution learned from data. However, such latent\ndistribution may incur difficulties in data sampling for GANs. In this paper,\nrather than sampling from the predefined prior distribution, we propose an\nLCCGAN model with local coordinate coding (LCC) to improve the performance of\ngenerating data. First, we propose an LCC sampling method in LCCGAN to sample\nmeaningful points from the latent manifold. With the LCC sampling method, we\ncan exploit the local information on the latent manifold and thus produce new\ndata with promising quality. Second, we propose an improved version, namely\nLCCGAN++, by introducing a higher-order term in the generator approximation.\nThis term is able to achieve better approximation and thus further improve the\nperformance. More critically, we derive the generalization bound for both\nLCCGAN and LCCGAN++ and prove that a low-dimensional input is sufficient to\nachieve good generalization performance. Extensive experiments on four\nbenchmark datasets demonstrate the superiority of the proposed method over\nexisting GANs.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 09:17:50 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Cao", "Jiezhang", ""], ["Guo", "Yong", ""], ["Wu", "Qingyao", ""], ["Shen", "Chunhua", ""], ["Huang", "Junzhou", ""], ["Tan", "Mingkui", ""]]}, {"id": "2008.00946", "submitter": "Etienne Goffinet Mr", "authors": "Etienne Goffinet, Anthony Coutant, Mustapha Lebbah, Hanane Azzag and\n  Lo\\\"ic Giraldi", "title": "Conditional Latent Block Model: a Multivariate Time Series Clustering\n  Approach for Autonomous Driving Validation", "comments": "17 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving systems validation remains one of the biggest challenges\ncar manufacturers must tackle in order to provide safe driverless cars. The\nhigh complexity stems from several factors: the multiplicity of vehicles,\nembedded systems, use cases, and the very high required level of reliability\nfor the driving system to be at least as safe as a human driver. In order to\ncircumvent these issues, large scale simulations reproducing this huge variety\nof physical conditions are intensively used to test driverless cars. Therefore,\nthe validation step produces a massive amount of data, including many\ntime-indexed ones, to be processed. In this context, building a structure in\nthe feature space is mandatory to interpret the various scenarios. In this\nwork, we propose a new co-clustering approach adapted to high-dimensional time\nseries analysis, that extends the standard model-based co-clustering. The\nFunCLBM model extends the recently proposed Functional Latent Block Model and\nallows to create a dependency structure between row and column clusters. This\nstructured partition acts as a feature selection method, that provides several\nclustering views of a dataset, while discriminating irrelevant features. In\nthis workflow, times series are projected onto a common interpolated\nlow-dimensional frequency space, which allows to optimize the projection basis.\nIn addition, FunCLBM refines the definition of each latent block by performing\nblock-wise dimension reduction and feature selection. We propose a SEM-Gibbs\nalgorithm to infer this model, as well as a dedicated criterion to select the\noptimal nested partition. Experiments on both simulated and real-case Renault\ndatasets shows the effectiveness of the proposed tools and the adequacy to our\nuse case.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 15:26:26 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Goffinet", "Etienne", ""], ["Coutant", "Anthony", ""], ["Lebbah", "Mustapha", ""], ["Azzag", "Hanane", ""], ["Giraldi", "Lo\u00efc", ""]]}, {"id": "2008.00948", "submitter": "Manuel Rebol", "authors": "Manuel Rebol, Patrick Kn\\\"obelreiter", "title": "Frame-To-Frame Consistent Semantic Segmentation", "comments": "ACVRW20", "journal-ref": null, "doi": "10.3217/978-3-85125-752-6-18", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we aim for temporally consistent semantic segmentation\nthroughout frames in a video. Many semantic segmentation algorithms process\nimages individually which leads to an inconsistent scene interpretation due to\nillumination changes, occlusions and other variations over time. To achieve a\ntemporally consistent prediction, we train a convolutional neural network (CNN)\nwhich propagates features through consecutive frames in a video using a\nconvolutional long short term memory (ConvLSTM) cell. Besides the temporal\nfeature propagation, we penalize inconsistencies in our loss function. We show\nin our experiments that the performance improves when utilizing video\ninformation compared to single frame prediction. The mean intersection over\nunion (mIoU) metric on the Cityscapes validation set increases from 45.2 % for\nthe single frames to 57.9 % for video data after implementing the ConvLSTM to\npropagate features trough time on the ESPNet. Most importantly, inconsistency\ndecreases from 4.5 % to 1.3 % which is a reduction by 71.1 %. Our results\nindicate that the added temporal information produces a frame-to-frame\nconsistent and more accurate image understanding compared to single frame\nprocessing. Code and videos are available at\nhttps://github.com/mrebol/f2f-consistent-semantic-segmentation\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 15:28:40 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 22:24:56 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2020 18:14:38 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Rebol", "Manuel", ""], ["Kn\u00f6belreiter", "Patrick", ""]]}, {"id": "2008.00966", "submitter": "Rahul Ramachandran", "authors": "Rahul Ramachandran", "title": "Using neural networks to predict icephobic performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.soft cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Icephobic surfaces inspired by superhydrophobic surfaces offer a passive\nsolution to the problem of icing. However, modeling icephobicity is challenging\nbecause some material features that aid superhydrophobicity can adversely\naffect the icephobic performance. This study presents a new approach based on\nartificial neural networks to model icephobicity. Artificial neural network\nmodels were developed to predict the icephobic performance of concrete. The\nmodels were trained on experimental data to predict the surface ice adhesion\nstrength and the coefficient of restitution (COR) of water droplet bouncing off\nthe surface under freezing conditions. The material and coating compositions,\nand environmental condition were used as the models' input variables. A\nmultilayer perceptron was trained to predict COR with a root mean squared error\nof 0.08, and a 90% confidence interval of [0.042, 0.151]. The model had a\ncoefficient of determination of 0.92 after deployment. Since ice adhesion\nstrength varied over a wide range of values for the samples, a mixture density\nnetwork was model was developed to learn the underlying relationship in the\nmultimodal data. Coefficient of determination for the model was 0.96. The\nrelative importance of the input variables in icephobic performance were\ncalculated using permutation importance. The developed models will be\nbeneficial to optimize icephobicity of concrete.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 05:37:06 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Ramachandran", "Rahul", ""]]}, {"id": "2008.00994", "submitter": "Sheng Zhou", "authors": "Ruichen Jiang, Sheng Zhou", "title": "Cluster-Based Cooperative Digital Over-the-Air Aggregation for Wireless\n  Federated Edge Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a federated learning system at the wireless edge that\nuses over-the-air computation (AirComp). In such a system, users transmit their\nmessages over a multi-access channel concurrently to achieve fast model\naggregation. Recently, an AirComp scheme based on digital modulation has been\nproposed featuring one-bit gradient quantization and truncated channel\ninversion at users and a majority-voting based decoder at the fusion center\n(FC). We propose an improved digital AirComp scheme to relax its requirements\non the transmitters, where users perform phase correction and transmit with\nfull power. To characterize the decoding failure probability at the FC, we\nintroduce the normalized detection signal-to-noise ratio (SNR), which can be\ninterpreted as the effective participation rate of users. To mitigate wireless\nfading, we further propose a cluster-based system and design the relay\nselection scheme based on the normalized detection SNR. By local data fusion\nwithin each cluster and relay selection, our scheme can fully exploit spatial\ndiversity to increase the effective number of voting users and accelerate model\nconvergence.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 16:29:52 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Jiang", "Ruichen", ""], ["Zhou", "Sheng", ""]]}, {"id": "2008.01003", "submitter": "Radu Tudor Ionescu", "authors": "Mariana-Iuliana Georgescu, Radu Tudor Ionescu", "title": "Teacher-Student Training and Triplet Loss for Facial Expression\n  Recognition under Occlusion", "comments": "Accepted at ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the task of facial expression recognition under\nstrong occlusion. We are particularly interested in cases where 50% of the face\nis occluded, e.g. when the subject wears a Virtual Reality (VR) headset. While\nprevious studies show that pre-training convolutional neural networks (CNNs) on\nfully-visible (non-occluded) faces improves the accuracy, we propose to employ\nknowledge distillation to achieve further improvements. First of all, we employ\nthe classic teacher-student training strategy, in which the teacher is a CNN\ntrained on fully-visible faces and the student is a CNN trained on occluded\nfaces. Second of all, we propose a new approach for knowledge distillation\nbased on triplet loss. During training, the goal is to reduce the distance\nbetween an anchor embedding, produced by a student CNN that takes occluded\nfaces as input, and a positive embedding (from the same class as the anchor),\nproduced by a teacher CNN trained on fully-visible faces, so that it becomes\nsmaller than the distance between the anchor and a negative embedding (from a\ndifferent class than the anchor), produced by the student CNN. Third of all, we\npropose to combine the distilled embeddings obtained through the classic\nteacher-student strategy and our novel teacher-student strategy based on\ntriplet loss into a single embedding vector. We conduct experiments on two\nbenchmarks, FER+ and AffectNet, with two CNN architectures, VGG-f and VGG-face,\nshowing that knowledge distillation can bring significant improvements over the\nstate-of-the-art methods designed for occluded faces in the VR setting.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 16:41:19 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 18:54:30 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Georgescu", "Mariana-Iuliana", ""], ["Ionescu", "Radu Tudor", ""]]}, {"id": "2008.01011", "submitter": "Felix Voigtlaender", "authors": "Philipp Grohs, Andreas Klotz, Felix Voigtlaender", "title": "Phase Transitions in Rate Distortion Theory and Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rate distortion theory is concerned with optimally encoding a given signal\nclass $\\mathcal{S}$ using a budget of $R$ bits, as $R\\to\\infty$. We say that\n$\\mathcal{S}$ can be compressed at rate $s$ if we can achieve an error of\n$\\mathcal{O}(R^{-s})$ for encoding $\\mathcal{S}$; the supremal compression rate\nis denoted $s^\\ast(\\mathcal{S})$. Given a fixed coding scheme, there usually\nare elements of $\\mathcal{S}$ that are compressed at a higher rate than\n$s^\\ast(\\mathcal{S})$ by the given coding scheme; we study the size of this set\nof signals. We show that for certain \"nice\" signal classes $\\mathcal{S}$, a\nphase transition occurs: We construct a probability measure $\\mathbb{P}$ on\n$\\mathcal{S}$ such that for every coding scheme $\\mathcal{C}$ and any $s\n>s^\\ast(\\mathcal{S})$, the set of signals encoded with error\n$\\mathcal{O}(R^{-s})$ by $\\mathcal{C}$ forms a $\\mathbb{P}$-null-set. In\nparticular our results apply to balls in Besov and Sobolev spaces that embed\ncompactly into $L^2(\\Omega)$ for a bounded Lipschitz domain $\\Omega$. As an\napplication, we show that several existing sharpness results concerning\nfunction approximation using deep neural networks are generically sharp.\n  We also provide quantitative and non-asymptotic bounds on the probability\nthat a random $f\\in\\mathcal{S}$ can be encoded to within accuracy $\\varepsilon$\nusing $R$ bits. This result is applied to the problem of approximately\nrepresenting $f\\in\\mathcal{S}$ to within accuracy $\\varepsilon$ by a\n(quantized) neural network that is constrained to have at most $W$ nonzero\nweights and is generated by an arbitrary \"learning\" procedure. We show that for\nany $s >s^\\ast(\\mathcal{S})$ there are constants $c,C$ such that, no matter how\nwe choose the \"learning\" procedure, the probability of success is bounded from\nabove by $\\min\\big\\{1,2^{C\\cdot W\\lceil\\log_2(1+W)\\rceil^2\n-c\\cdot\\varepsilon^{-1/s}}\\big\\}$.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 16:48:49 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Grohs", "Philipp", ""], ["Klotz", "Andreas", ""], ["Voigtlaender", "Felix", ""]]}, {"id": "2008.01036", "submitter": "Lin Chen", "authors": "Lin Chen, Yifei Min, Mikhail Belkin, Amin Karbasi", "title": "Multiple Descent: Design Your Own Generalization Curve", "comments": "Improved presentation of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the generalization loss of linear regression in variably\nparameterized families of models, both under-parameterized and\nover-parameterized. We show that the generalization curve can have an arbitrary\nnumber of peaks, and moreover, locations of those peaks can be explicitly\ncontrolled. Our results highlight the fact that both classical U-shaped\ngeneralization curve and the recently observed double descent curve are not\nintrinsic properties of the model family. Instead, their emergence is due to\nthe interaction between the properties of the data and the inductive biases of\nlearning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 17:22:21 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 16:38:35 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 17:25:39 GMT"}, {"version": "v4", "created": "Mon, 23 Nov 2020 18:06:02 GMT"}, {"version": "v5", "created": "Tue, 9 Feb 2021 00:45:00 GMT"}, {"version": "v6", "created": "Tue, 1 Jun 2021 17:03:22 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Chen", "Lin", ""], ["Min", "Yifei", ""], ["Belkin", "Mikhail", ""], ["Karbasi", "Amin", ""]]}, {"id": "2008.01040", "submitter": "Samuel Kaufman", "authors": "Samuel J. Kaufman, Phitchaya Mangpo Phothilimthana, Yanqi Zhou,\n  Charith Mendis, Sudip Roy, Amit Sabne, and Mike Burrows", "title": "A Learned Performance Model for Tensor Processing Units", "comments": "A version will appear in the Proceedings of the 4th MLSys Conference,\n  San Jose, CA, USA, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate hardware performance models are critical to efficient code\ngeneration. They can be used by compilers to make heuristic decisions, by\nsuperoptimizers as a minimization objective, or by autotuners to find an\noptimal configuration for a specific program. However, they are difficult to\ndevelop because contemporary processors are complex, and the recent\nproliferation of deep learning accelerators has increased the development\nburden. We demonstrate a method of learning performance models from a corpus of\ntensor computation graph programs for Tensor Processing Unit (TPU) instances.\nWe show that our learned model outperforms a heavily-optimized analytical\nperformance model on two tasks -- tile-size selection and operator fusion --\nand that it helps an autotuner discover faster programs in a setting where\naccess to TPUs is limited or expensive.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 17:24:52 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 04:49:15 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Kaufman", "Samuel J.", ""], ["Phothilimthana", "Phitchaya Mangpo", ""], ["Zhou", "Yanqi", ""], ["Mendis", "Charith", ""], ["Roy", "Sudip", ""], ["Sabne", "Amit", ""], ["Burrows", "Mike", ""]]}, {"id": "2008.01062", "submitter": "Jianhao Wang", "authors": "Jianhao Wang, Zhizhou Ren, Terry Liu, Yang Yu, Chongjie Zhang", "title": "QPLEX: Duplex Dueling Multi-Agent Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore value-based multi-agent reinforcement learning (MARL) in the\npopular paradigm of centralized training with decentralized execution (CTDE).\nCTDE has an important concept, Individual-Global-Max (IGM) principle, which\nrequires the consistency between joint and local action selections to support\nefficient local decision-making. However, in order to achieve scalability,\nexisting MARL methods either limit representation expressiveness of their value\nfunction classes or relax the IGM consistency, which may suffer from\ninstability risk or lead to poor performance. This paper presents a novel MARL\napproach, called duPLEX dueling multi-agent Q-learning (QPLEX), which takes a\nduplex dueling network architecture to factorize the joint value function. This\nduplex dueling structure encodes the IGM principle into the neural network\narchitecture and thus enables efficient value function learning. Theoretical\nanalysis shows that QPLEX achieves a complete IGM function class. Empirical\nexperiments on StarCraft II micromanagement tasks demonstrate that QPLEX\nsignificantly outperforms state-of-the-art baselines in both online and offline\ndata collection settings, and also reveal that QPLEX achieves high sample\nefficiency and can benefit from offline datasets without additional online\nexploration.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 17:52:09 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 14:13:20 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Wang", "Jianhao", ""], ["Ren", "Zhizhou", ""], ["Liu", "Terry", ""], ["Yu", "Yang", ""], ["Zhang", "Chongjie", ""]]}, {"id": "2008.01064", "submitter": "Qi Lei", "authors": "Jason D. Lee, Qi Lei, Nikunj Saunshi, Jiacheng Zhuo", "title": "Predicting What You Already Know Helps: Provable Self-Supervised\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised representation learning solves auxiliary prediction tasks\n(known as pretext tasks), that do not require labeled data, to learn semantic\nrepresentations. These pretext tasks are created solely using the input\nfeatures, such as predicting a missing image patch, recovering the color\nchannels of an image from context, or predicting missing words, yet predicting\nthis $known\\ $information helps in learning representations effective for\ndownstream prediction tasks. This paper posits a mechanism based on conditional\nindependence to formalize how solving certain pretext tasks can learn\nrepresentations that provably decreases the sample complexity of downstream\nsupervised tasks. Formally, we quantify how approximate independence between\nthe components of the pretext task (conditional on the label and latent\nvariables) allows us to learn representations that can solve the downstream\ntask with drastically reduced sample complexity by just training a linear layer\non top of the learned representation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 17:56:13 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Lee", "Jason D.", ""], ["Lei", "Qi", ""], ["Saunshi", "Nikunj", ""], ["Zhuo", "Jiacheng", ""]]}, {"id": "2008.01077", "submitter": "Pooyan Safari", "authors": "Pooyan Safari, Miquel India and Javier Hernando", "title": "Self-attention encoding and pooling for speaker recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computing power of mobile devices limits the end-user applications in\nterms of storage size, processing, memory and energy consumption. These\nlimitations motivate researchers for the design of more efficient deep models.\nOn the other hand, self-attention networks based on Transformer architecture\nhave attracted remarkable interests due to their high parallelization\ncapabilities and strong performance on a variety of Natural Language Processing\n(NLP) applications. Inspired by the Transformer, we propose a tandem\nSelf-Attention Encoding and Pooling (SAEP) mechanism to obtain a discriminative\nspeaker embedding given non-fixed length speech utterances. SAEP is a stack of\nidentical blocks solely relied on self-attention and position-wise feed-forward\nnetworks to create vector representation of speakers. This approach encodes\nshort-term speaker spectral features into speaker embeddings to be used in\ntext-independent speaker verification. We have evaluated this approach on both\nVoxCeleb1 & 2 datasets. The proposed architecture is able to outperform the\nbaseline x-vector, and shows competitive performance to some other benchmarks\nbased on convolutions, with a significant reduction in model size. It employs\n94%, 95%, and 73% less parameters compared to ResNet-34, ResNet-50, and\nx-vector, respectively. This indicates that the proposed fully attention based\narchitecture is more efficient in extracting time-invariant features from\nspeaker utterances.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 09:31:27 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Safari", "Pooyan", ""], ["India", "Miquel", ""], ["Hernando", "Javier", ""]]}, {"id": "2008.01078", "submitter": "Hendrik Schr\\\"oter", "authors": "Wei-Cheng Lai, Hendrik Schr\\\"oter", "title": "Ubicomp Digital 2020 -- Handwriting classification using a convolutional\n  recurrent network", "comments": "CRNN, Handwriting recognition, Ubicomp, Stabilo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Ubicomp Digital 2020 -- Time Series Classification Challenge from STABILO\nis a challenge about multi-variate time series classification. The data\ncollected from 100 volunteer writers, and contains 15 features measured with\nmultiple sensors on a pen. In this paper,we use a neural network to classify\nthe data into 52 classes, that is lower and upper cases of Arabic letters. The\nproposed architecture of the neural network a is CNN-LSTM network. It combines\nconvolutional neural network (CNN) for short term context with along short term\nmemory layer (LSTM) for also long term dependencies. We reached an accuracy of\n68% on our writer exclusive test set and64.6% on the blind challenge test set\nresulting in the second place.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 11:32:22 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Lai", "Wei-Cheng", ""], ["Schr\u00f6ter", "Hendrik", ""]]}, {"id": "2008.01124", "submitter": "Jamal Toutouh", "authors": "Jamal Toutouh, Erik Hemberg, and Una-May O'Reilly", "title": "Analyzing the Components of Distributed Coevolutionary GAN Training", "comments": "Accepted as a full paper in Sixteenth International Conference on\n  Parallel Problem Solving from Nature (PPSN XVI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed coevolutionary Generative Adversarial Network (GAN) training has\nempirically shown success in overcoming GAN training pathologies. This is\nmainly due to diversity maintenance in the populations of generators and\ndiscriminators during the training process. The method studied here coevolves\nsub-populations on each cell of a spatial grid organized into overlapping Moore\nneighborhoods. We investigate the impact on the performance of two algorithm\ncomponents that influence the diversity during coevolution: the\nperformance-based selection/replacement inside each sub-population and the\ncommunication through migration of solutions (networks) among overlapping\nneighborhoods. In experiments on MNIST dataset, we find that the combination of\nthese two components provides the best generative models. In addition,\nmigrating solutions without applying selection in the sub-populations achieves\ncompetitive results, while selection without communication between cells\nreduces performance.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 18:35:06 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Toutouh", "Jamal", ""], ["Hemberg", "Erik", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "2008.01132", "submitter": "Suyun Liu", "authors": "Suyun Liu and Luis Nunes Vicente", "title": "Accuracy and Fairness Trade-offs in Machine Learning: A Stochastic\n  Multi-Objective Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the application of machine learning to real-life decision-making systems,\ne.g., credit scoring and criminal justice, the prediction outcomes might\ndiscriminate against people with sensitive attributes, leading to unfairness.\nThe commonly used strategy in fair machine learning is to include fairness as a\nconstraint or a penalization term in the minimization of the prediction loss,\nwhich ultimately limits the information given to decision-makers. In this\npaper, we introduce a new approach to handle fairness by formulating a\nstochastic multi-objective optimization problem for which the corresponding\nPareto fronts uniquely and comprehensively define the accuracy-fairness\ntrade-offs. We have then applied a stochastic approximation-type method to\nefficiently obtain well-spread and accurate Pareto fronts, and by doing so we\ncan handle training data arriving in a streaming way.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 18:51:24 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 18:51:35 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Liu", "Suyun", ""], ["Vicente", "Luis Nunes", ""]]}, {"id": "2008.01133", "submitter": "Gabriel Machado", "authors": "Gabriel Machado, Edemir Ferreira, Keiller Nogueira, Hugo Oliveira,\n  Pedro Gama and Jefersson A. dos Santos", "title": "AiRound and CV-BrCT: Novel Multi-View Datasets for Scene Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is undeniable that aerial/satellite images can provide useful information\nfor a large variety of tasks. But, since these images are always looking from\nabove, some applications can benefit from complementary information provided by\nother perspective views of the scene, such as ground-level images. Despite a\nlarge number of public repositories for both georeferenced photographs and\naerial images, there is a lack of benchmark datasets that allow the development\nof approaches that exploit the benefits and complementarity of aerial/ground\nimagery. In this paper, we present two new publicly available datasets named\n\\thedataset~and CV-BrCT. The first one contains triplets of images from the\nsame geographic coordinate with different perspectives of view extracted from\nvarious places around the world. Each triplet is composed of an aerial RGB\nimage, a ground-level perspective image, and a Sentinel-2 sample. The second\ndataset contains pairs of aerial and street-level images extracted from\nsoutheast Brazil. We design an extensive set of experiments concerning\nmulti-view scene classification, using early and late fusion. Such experiments\nwere conducted to show that image classification can be enhanced using\nmulti-view data.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 18:55:46 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Machado", "Gabriel", ""], ["Ferreira", "Edemir", ""], ["Nogueira", "Keiller", ""], ["Oliveira", "Hugo", ""], ["Gama", "Pedro", ""], ["Santos", "Jefersson A. dos", ""]]}, {"id": "2008.01158", "submitter": "Fakrul Islam Tushar", "authors": "Fakrul Islam Tushar, Vincent M. D'Anniballe, Rui Hou, Maciej A.\n  Mazurowski, Wanyi Fu, Ehsan Samei, Geoffrey D. Rubin, Joseph Y. Lo", "title": "Multi-Disease Classification of 13,667 Body CT Scans Using Weakly\n  Supervised Deep Learning", "comments": "18 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background: Training deep learning classifiers typically requires massive\namounts of manual annotation. Weak supervision may leverage existing medical\ndata to classify multiple diseases and organ systems. Purpose: To design\nmulti-disease classifiers for body computed tomography (CT) scans using\nautomatically extracted labels from radiology text reports. Materials &\nMethods: This retrospective study deployed rule-based algorithms to extract\n19,255 disease labels from reports of 13,667 body CT scans of 12,092 subjects\nfor training. Using a 3D DenseVNet, three organ systems were segmented:\nlungs/pleura, liver/gallbladder, and kidneys/ureters. For each organ, a 3D\nconvolutional neural network classified normality versus four common diseases.\nTesting was performed on an additional 2,158 CT volumes relative to 2,875\nmanually derived reference labels. Results: Manual validation of the extracted\nlabels confirmed 91 to 99% accuracy. Performance using the receiver operating\ncharacteristic area under the curve (AUC) for lungs/pleura labels were as\nfollows: atelectasis 0.77 (95% CI: 0.74 to 0.81), nodule 0.65 (0.61 to 0.69),\nemphysema 0.89 (0.86 to 0.92), effusion 0.97 (0.96 to 0.98), and normal 0.89\n(0.87 to 0.91). For liver/gallbladder: stone 0.62 (0.56 to 0.67), lesion 0.73\n(0.69 to 0.77), dilation 0.87 (0.84 to 0.90), fatty 0.89 (0.86 to 0.92), and\nnormal 0.82 (0.78 to 0.85). For kidneys/ureters: stone 0.83 (0.79 to 0.87),\natrophy 0.92 (0.89 to 0.94), lesion 0.68 (0.64 to 0.72), cyst 0.70 (0.66 to\n0.73), and normal 0.79 (0.75 to 0.83). Conclusion: Weakly supervised deep\nlearning classifiers leveraged massive amounts of unannotated body CT data to\nclassify multiple organ systems and diverse diseases.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 19:55:53 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 14:25:08 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Tushar", "Fakrul Islam", ""], ["D'Anniballe", "Vincent M.", ""], ["Hou", "Rui", ""], ["Mazurowski", "Maciej A.", ""], ["Fu", "Wanyi", ""], ["Samei", "Ehsan", ""], ["Rubin", "Geoffrey D.", ""], ["Lo", "Joseph Y.", ""]]}, {"id": "2008.01160", "submitter": "Alexey Gritsenko", "authors": "Alexey A. Gritsenko, Tim Salimans, Rianne van den Berg, Jasper Snoek,\n  Nal Kalchbrenner", "title": "A Spectral Energy Distance for Parallel Speech Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech synthesis is an important practical generative modeling problem that\nhas seen great progress over the last few years, with likelihood-based\nautoregressive neural models now outperforming traditional concatenative\nsystems. A downside of such autoregressive models is that they require\nexecuting tens of thousands of sequential operations per second of generated\naudio, making them ill-suited for deployment on specialized deep learning\nhardware. Here, we propose a new learning method that allows us to train highly\nparallel models of speech, without requiring access to an analytical likelihood\nfunction. Our approach is based on a generalized energy distance between the\ndistributions of the generated and real audio. This spectral energy distance is\na proper scoring rule with respect to the distribution over\nmagnitude-spectrograms of the generated waveform audio and offers statistical\nconsistency guarantees. The distance can be calculated from minibatches without\nbias, and does not involve adversarial learning, yielding a stable and\nconsistent method for training implicit generative models. Empirically, we\nachieve state-of-the-art generation quality among implicit generative models,\nas judged by the recently-proposed cFDSD metric. When combining our method with\nadversarial techniques, we also improve upon the recently-proposed GAN-TTS\nmodel in terms of Mean Opinion Score as judged by trained human evaluators.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 19:56:04 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 11:44:08 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Gritsenko", "Alexey A.", ""], ["Salimans", "Tim", ""], ["Berg", "Rianne van den", ""], ["Snoek", "Jasper", ""], ["Kalchbrenner", "Nal", ""]]}, {"id": "2008.01169", "submitter": "Sayhi Yang", "authors": "Shanghui Yang, Mengxia Zhu, Jingyang Hou, Xuesong Lu", "title": "Deep Knowledge Tracing with Convolutions", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge tracing (KT) has recently been an active research area of\ncomputational pedagogy. The task is to model students mastery level of\nknowledge based on their responses to the questions in the past, as well as\npredict the probabilities that they correctly answer subsequent questions in\nthe future. A good KT model can not only make students timely aware of their\nknowledge states, but also help teachers develop better personalized teaching\nplans for students. KT tasks were historically solved using statistical\nmodeling methods such as Bayesian inference and factor analysis, but recent\nadvances in deep learning have led to the successive proposals that leverage\ndeep neural networks, including long short-term memory networks,\nmemory-augmented networks and self-attention networks. While those deep models\ndemonstrate superior performance over the traditional approaches, they all\nneglect more or less the impact on knowledge states of the most recent\nquestions answered by students. The forgetting curve theory states that human\nmemory retention declines over time, therefore knowledge states should be\nmostly affected by the recent questions. Based on this observation, we propose\na Convolutional Knowledge Tracing (CKT) model in this paper. In addition to\nmodeling the long-term effect of the entire question-answer sequence, CKT also\nstrengthens the short-term effect of recent questions using 3D convolutions,\nthereby effectively modeling the forgetting curve in the learning process.\nExtensive experiments show that CKT achieves the new state-of-the-art in\npredicting students performance compared with existing models. Using CKT, we\ngain 1.55 and 2.03 improvements in terms of AUC over DKT and DKVMN\nrespectively, on the ASSISTments2009 dataset. And on the ASSISTments2015\ndataset, the corresponding improvements are 1.01 and 1.96 respectively.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 15:24:51 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Yang", "Shanghui", ""], ["Zhu", "Mengxia", ""], ["Hou", "Jingyang", ""], ["Lu", "Xuesong", ""]]}, {"id": "2008.01170", "submitter": "Syed Afaq Ali Shah", "authors": "Devante Ayris, Kye Horbury, Blake Williams, Mitchell Blackney, Celine\n  Shi Hui See, Maleeha Imtiaz, Syed Afaq Ali Shah", "title": "Deep Learning Models for Early Detection and Prediction of the spread of\n  Novel Coronavirus (COVID-19)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SARS-CoV2, which causes coronavirus disease (COVID-19) is continuing to\nspread globally and has become a pandemic. People have lost their lives due to\nthe virus and the lack of counter measures in place. Given the increasing\ncaseload and uncertainty of spread, there is an urgent need to develop machine\nlearning techniques to predict the spread of COVID-19. Prediction of the spread\ncan allow counter measures and actions to be implemented to mitigate the spread\nof COVID-19. In this paper, we propose a deep learning technique, called Deep\nSequential Prediction Model (DSPM) and machine learning based Non-parametric\nRegression Model (NRM) to predict the spread of COVID-19. Our proposed models\nwere trained and tested on novel coronavirus 2019 dataset, which contains 19.53\nMillion confirmed cases of COVID-19. Our proposed models were evaluated by\nusing Mean Absolute Error and compared with baseline method. Our experimental\nresults, both quantitative and qualitative, demonstrate the superior prediction\nperformance of the proposed models.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 10:14:11 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 09:45:37 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Ayris", "Devante", ""], ["Horbury", "Kye", ""], ["Williams", "Blake", ""], ["Blackney", "Mitchell", ""], ["See", "Celine Shi Hui", ""], ["Imtiaz", "Maleeha", ""], ["Shah", "Syed Afaq Ali", ""]]}, {"id": "2008.01171", "submitter": "Ralf Gulde", "authors": "Ralf Gulde, Marc Tuscher, Akos Csiszar, Oliver Riedel and Alexander\n  Verl", "title": "Deep Reinforcement Learning using Cyclical Learning Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) methods often rely on the meticulous tuning\nof hyperparameters to successfully resolve problems. One of the most\ninfluential parameters in optimization procedures based on stochastic gradient\ndescent (SGD) is the learning rate. We investigate cyclical learning and\npropose a method for defining a general cyclical learning rate for various DRL\nproblems. In this paper we present a method for cyclical learning applied to\ncomplex DRL problems. Our experiments show that, utilizing cyclical learning\nachieves similar or even better results than highly tuned fixed learning rates.\nThis paper presents the first application of cyclical learning rates in DRL\nsettings and is a step towards overcoming manual hyperparameter tuning.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 10:06:02 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Gulde", "Ralf", ""], ["Tuscher", "Marc", ""], ["Csiszar", "Akos", ""], ["Riedel", "Oliver", ""], ["Verl", "Alexander", ""]]}, {"id": "2008.01173", "submitter": "Qi Liu", "authors": "Qi Liu, Tian Tan, Kai Yu", "title": "An Investigation on Deep Learning with Beta Stabilizer", "comments": "Accepted by ICSP-2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks (ANN) have been used in many applications such\nlike handwriting recognition and speech recognition. It is well-known that\nlearning rate is a crucial value in the training procedure for artificial\nneural networks. It is shown that the initial value of learning rate can\nconfoundedly affect the final result and this value is always set manually in\npractice. A new parameter called beta stabilizer has been introduced to reduce\nthe sensitivity of the initial learning rate. But this method has only been\nproposed for deep neural network (DNN) with sigmoid activation function. In\nthis paper we extended beta stabilizer to long short-term memory (LSTM) and\ninvestigated the effects of beta stabilizer parameters on different models,\nincluding LSTM and DNN with relu activation function. It is concluded that beta\nstabilizer parameters can reduce the sensitivity of learning rate with almost\nthe same performance on DNN with relu activation function and LSTM. However, it\nis shown that the effects of beta stabilizer on DNN with relu activation\nfunction and LSTM are fewer than the effects on DNN with sigmoid activation\nfunction.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 08:27:31 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Liu", "Qi", ""], ["Tan", "Tian", ""], ["Yu", "Kai", ""]]}, {"id": "2008.01175", "submitter": "Renato Cordeiro de Amorim", "authors": "Renato Cordeiro de Amorim and Carlos David Lopez Ruiz", "title": "Identifying meaningful clusters in malware data", "comments": null, "journal-ref": null, "doi": "10.1016/j.eswa.2021.114971", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Finding meaningful clusters in drive-by-download malware data is a\nparticularly difficult task. Malware data tends to contain overlapping clusters\nwith wide variations of cardinality. This happens because there can be\nconsiderable similarity between malware samples (some are even said to belong\nto the same family), and these tend to appear in bursts. Clustering algorithms\nare usually applied to normalised data sets. However, the process of\nnormalisation aims at setting features with different range values to have a\nsimilar contribution to the clustering. It does not favour more meaningful\nfeatures over those that are less meaningful, an effect one should perhaps\nexpect of the data pre-processing stage.\n  In this paper we introduce a method to deal precisely with the problem above.\nThis is an iterative data pre-processing method capable of aiding to increase\nthe separation between clusters. It does so by calculating the within-cluster\ndegree of relevance of each feature, and then it uses these as a data rescaling\nfactor. By repeating this until convergence our malware data was separated in\nclear clusters, leading to a higher average silhouette width.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 12:36:08 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["de Amorim", "Renato Cordeiro", ""], ["Ruiz", "Carlos David Lopez", ""]]}, {"id": "2008.01179", "submitter": "Kuan-Hui Lee", "authors": "Kuan-Hui Lee, Matthew Kliemann, Adrien Gaidon, Jie Li, Chao Fang,\n  Sudeep Pillai, Wolfram Burgard", "title": "PillarFlow: End-to-end Birds-eye-view Flow Estimation for Autonomous\n  Driving", "comments": "Accepted by IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In autonomous driving, accurately estimating the state of surrounding\nobstacles is critical for safe and robust path planning. However, this\nperception task is difficult, particularly for generic obstacles/objects, due\nto appearance and occlusion changes. To tackle this problem, we propose an\nend-to-end deep learning framework for LIDAR-based flow estimation in bird's\neye view (BeV). Our method takes consecutive point cloud pairs as input and\nproduces a 2-D BeV flow grid describing the dynamic state of each cell. The\nexperimental results show that the proposed method not only estimates 2-D BeV\nflow accurately but also improves tracking performance of both dynamic and\nstatic objects.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 20:36:28 GMT"}, {"version": "v2", "created": "Sun, 23 Aug 2020 00:22:05 GMT"}, {"version": "v3", "created": "Sat, 29 Aug 2020 13:35:09 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Lee", "Kuan-Hui", ""], ["Kliemann", "Matthew", ""], ["Gaidon", "Adrien", ""], ["Li", "Jie", ""], ["Fang", "Chao", ""], ["Pillai", "Sudeep", ""], ["Burgard", "Wolfram", ""]]}, {"id": "2008.01183", "submitter": "Qiaosong Wang", "authors": "Yu-Ting Chang, Qiaosong Wang, Wei-Chih Hung, Robinson Piramuthu,\n  Yi-Hsuan Tsai, Ming-Hsuan Yang", "title": "Weakly-Supervised Semantic Segmentation via Sub-category Exploration", "comments": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing weakly-supervised semantic segmentation methods using image-level\nannotations typically rely on initial responses to locate object regions.\nHowever, such response maps generated by the classification network usually\nfocus on discriminative object parts, due to the fact that the network does not\nneed the entire object for optimizing the objective function. To enforce the\nnetwork to pay attention to other parts of an object, we propose a simple yet\neffective approach that introduces a self-supervised task by exploiting the\nsub-category information. Specifically, we perform clustering on image features\nto generate pseudo sub-categories labels within each annotated parent class,\nand construct a sub-category objective to assign the network to a more\nchallenging task. By iteratively clustering image features, the training\nprocess does not limit itself to the most discriminative object parts, hence\nimproving the quality of the response maps. We conduct extensive analysis to\nvalidate the proposed method and show that our approach performs favorably\nagainst the state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 20:48:31 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Chang", "Yu-Ting", ""], ["Wang", "Qiaosong", ""], ["Hung", "Wei-Chih", ""], ["Piramuthu", "Robinson", ""], ["Tsai", "Yi-Hsuan", ""], ["Yang", "Ming-Hsuan", ""]]}, {"id": "2008.01184", "submitter": "Philipp Sibler", "authors": "Philipp Sibler, Yuanyuan Wang, Stefan Auer, Mohsin Ali, Xiao Xiang Zhu", "title": "Generative Adversarial Networks for Synthesizing InSAR Patches", "comments": "accepted in preliminary version for EUSAR2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have been employed with certain\nsuccess for image translation tasks between optical and real-valued SAR\nintensity imagery. Applications include aiding interpretability of SAR scenes\nwith their optical counterparts by artificial patch generation and automatic\nSAR-optical scene matching. The synthesis of artificial complex-valued InSAR\nimage stacks asks for, besides good perceptual quality, more stringent quality\nmetrics like phase noise and phase coherence. This paper provides a signal\nprocessing model of generative CNN structures, describes effects influencing\nthose quality metrics and presents a mapping scheme of complex-valued data to\ngiven CNN structures based on popular Deep Learning frameworks.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 20:51:01 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Sibler", "Philipp", ""], ["Wang", "Yuanyuan", ""], ["Auer", "Stefan", ""], ["Ali", "Mohsin", ""], ["Zhu", "Xiao Xiang", ""]]}, {"id": "2008.01190", "submitter": "SeungHeon Doh", "authors": "Seungheon Doh, Jongpil Lee, Tae Hong Park, Juhan Nam", "title": "Musical Word Embedding: Bridging the Gap between Listening Contexts and\n  Music", "comments": "Machine Learning for Media Discovery Workshop, International\n  Conference on Machine Learning (ICML), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding pioneered by Mikolov et al. is a staple technique for word\nrepresentations in natural language processing (NLP) research which has also\nfound popularity in music information retrieval tasks. Depending on the type of\ntext data for word embedding, however, vocabulary size and the degree of\nmusical pertinence can significantly vary. In this work, we (1) train the\ndistributed representation of words using combinations of both general text\ndata and music-specific data and (2) evaluate the system in terms of how they\nassociate listening contexts with musical compositions.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 06:42:45 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Doh", "Seungheon", ""], ["Lee", "Jongpil", ""], ["Park", "Tae Hong", ""], ["Nam", "Juhan", ""]]}, {"id": "2008.01191", "submitter": "Sadaqat Ur Rehman", "authors": "Sadaqat ur Rehman, Muhammad Waqas, Shanshan Tu, Anis Koubaa, Obaid ur\n  Rehman, Jawad Ahmad, Muhammad Hanif, Zhu Han", "title": "Deep Learning Techniques for Future Intelligent Cross-Media Retrieval", "comments": "arXiv admin note: text overlap with arXiv:1804.09539 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the advancement in technology and the expansion of broadcasting,\ncross-media retrieval has gained much attention. It plays a significant role in\nbig data applications and consists in searching and finding data from different\ntypes of media. In this paper, we provide a novel taxonomy according to the\nchallenges faced by multi-modal deep learning approaches in solving cross-media\nretrieval, namely: representation, alignment, and translation. These challenges\nare evaluated on deep learning (DL) based methods, which are categorized into\nfour main groups: 1) unsupervised methods, 2) supervised methods, 3) pairwise\nbased methods, and 4) rank based methods. Then, we present some well-known\ncross-media datasets used for retrieval, considering the importance of these\ndatasets in the context in of deep learning based cross-media retrieval\napproaches. Moreover, we also present an extensive review of the\nstate-of-the-art problems and its corresponding solutions for encouraging deep\nlearning in cross-media retrieval. The fundamental objective of this work is to\nexploit Deep Neural Networks (DNNs) for bridging the \"media gap\", and provide\nresearchers and developers with a better understanding of the underlying\nproblems and the potential solutions of deep learning assisted cross-media\nretrieval. To the best of our knowledge, this is the first comprehensive survey\nto address cross-media retrieval under deep learning methods.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 09:49:33 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Rehman", "Sadaqat ur", ""], ["Waqas", "Muhammad", ""], ["Tu", "Shanshan", ""], ["Koubaa", "Anis", ""], ["Rehman", "Obaid ur", ""], ["Ahmad", "Jawad", ""], ["Hanif", "Muhammad", ""], ["Han", "Zhu", ""]]}, {"id": "2008.01192", "submitter": "Kamal Berahmand", "authors": "Saman Forouzandeh, Mehrdad Rostami, Kamal Berahmand", "title": "Presentation of a Recommender System with Ensemble Learning and Graph\n  Embedding: A Case on MovieLens", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Information technology has spread widely, and extraordinarily large amounts\nof data have been made accessible to users, which has made it challenging to\nselect data that are in accordance with user needs. For the resolution of the\nabove issue, recommender systems have emerged, which much help users go through\nthe process of decision-making and selecting relevant data. A recommender\nsystem predicts users behavior to be capable of detecting their interests and\nneeds, and it often uses the classification technique for this purpose. It may\nnot be sufficiently accurate to employ individual classification, where not all\ncases can be examined, which makes the method inappropriate to specific\nproblems. In this research, group classification and the ensemble learning\ntechnique were used for increasing prediction accuracy in recommender systems.\nAnother issue that is raised here concerns user analysis. Given the large size\nof the data and a large number of users, the process of user needs analysis and\nprediction (using a graph in most cases, representing the relations between\nusers and their selected items) is complicated and cumbersome in recommender\nsystems. Graph embedding was also proposed for resolution of this issue, where\nall or part of user behavior can be simulated through the generation of several\nvectors, resolving the problem of user behavior analysis to a large extent\nwhile maintaining high efficiency. In this research, individuals most similar\nto the target user were classified using ensemble learning, fuzzy rules, and\nthe decision tree, and relevant recommendations were then made to each user\nwith a heterogeneous knowledge graph and embedding vectors. This study was\nperformed on the MovieLens datasets, and the obtained results indicated the\nhigh efficiency of the presented method.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 12:52:15 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Forouzandeh", "Saman", ""], ["Rostami", "Mehrdad", ""], ["Berahmand", "Kamal", ""]]}, {"id": "2008.01193", "submitter": "Bo Peng", "authors": "Zhiyun Ren, Bo Peng, Titus K. Schleyer and Xia Ning", "title": "Hybrid Collaborative Filtering Models for Clinical Search Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With increasing and extensive use of electronic health records, clinicians\nare often under time pressure when they need to retrieve important information\nefficiently among large amounts of patients' health records in clinics. While a\nsearch function can be a useful alternative to browsing through a patient's\nrecord, it is cumbersome for clinicians to search repeatedly for the same or\nsimilar information on similar patients. Under such circumstances, there is a\ncritical need to build effective recommender systems that can generate accurate\nsearch term recommendations for clinicians. In this manuscript, we developed a\nhybrid collaborative filtering model using patients' encounter and search term\ninformation to recommend the next search terms for clinicians to retrieve\nimportant information fast in clinics. For each patient, the model will\nrecommend terms that either have high co-occurrence frequencies with his/her\nmost recent ICD codes or are highly relevant to the most recent search terms on\nthis patient. We have conducted comprehensive experiments to evaluate the\nproposed model, and the experimental results demonstrate that our model can\noutperform all the state-of-the-art baseline methods for top-N search term\nrecommendation on different datasets.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 19:25:00 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Ren", "Zhiyun", ""], ["Peng", "Bo", ""], ["Schleyer", "Titus K.", ""], ["Ning", "Xia", ""]]}, {"id": "2008.01196", "submitter": "Jerome Darmont", "authors": "Abderrazek Azri (ERIC), C\\'ecile Favre (ERIC), Nouria Harbi (ERIC),\n  J\\'er\\^ome Darmont (ERIC)", "title": "Including Images into Message Veracity Assessment in Social Media", "comments": null, "journal-ref": "8th International Conference on Innovation and New Trends in\n  Information Technology (INTIS 2019), Dec 2019, Tangier, Morocco", "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extensive use of social media in the diffusion of information has also\nlaid a fertile ground for the spread of rumors, which could significantly\naffect the credibility of social media. An ever-increasing number of users post\nnews including, in addition to text, multimedia data such as images and videos.\nYet, such multimedia content is easily editable due to the broad availability\nof simple and effective image and video processing tools. The problem of\nassessing the veracity of social network posts has attracted a lot of attention\nfrom researchers in recent years. However, almost all previous works have\nfocused on analyzing textual contents to determine veracity, while visual\ncontents, and more particularly images, remains ignored or little exploited in\nthe literature. In this position paper, we propose a framework that explores\ntwo novel ways to assess the veracity of messages published on social networks\nby analyzing the credibility of both their textual and visual contents.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 08:42:17 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Azri", "Abderrazek", "", "ERIC"], ["Favre", "C\u00e9cile", "", "ERIC"], ["Harbi", "Nouria", "", "ERIC"], ["Darmont", "J\u00e9r\u00f4me", "", "ERIC"]]}, {"id": "2008.01197", "submitter": "Justin Lovelace", "authors": "Justin Lovelace, Nathan C. Hurley, Adrian D. Haimovich, Bobak J.\n  Mortazavi", "title": "Dynamically Extracting Outcome-Specific Problem Lists from Clinical\n  Notes with Guided Multi-Headed Attention", "comments": "To appear in the proceedings of the Machine Learning for Healthcare\n  Conference (MLHC) 2020. Accepted papers can be viewed at\n  https://www.mlforhc.org/accepted-papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Problem lists are intended to provide clinicians with a relevant summary of\npatient medical issues and are embedded in many electronic health record\nsystems. Despite their importance, problem lists are often cluttered with\nresolved or currently irrelevant conditions. In this work, we develop a novel\nend-to-end framework that first extracts diagnosis and procedure information\nfrom clinical notes and subsequently uses the extracted medical problems to\npredict patient outcomes. This framework is both more performant and more\ninterpretable than existing models used within the domain, achieving an AU-ROC\nof 0.710 for bounceback readmission and 0.869 for in-hospital mortality\noccurring after ICU discharge. We identify risk factors for both readmission\nand mortality outcomes and demonstrate that our framework can be used to\ndevelop dynamic problem lists that present clinical problems along with their\nquantitative importance. We conduct a qualitative user study with medical\nexperts and demonstrate that they view the lists produced by our framework\nfavorably and find them to be a more effective clinical decision support tool\nthan a strong baseline.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 21:03:50 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Lovelace", "Justin", ""], ["Hurley", "Nathan C.", ""], ["Haimovich", "Adrian D.", ""], ["Mortazavi", "Bobak J.", ""]]}, {"id": "2008.01201", "submitter": "Qiaosong Wang", "authors": "Yu-Ting Chang, Qiaosong Wang, Wei-Chih Hung, Robinson Piramuthu,\n  Yi-Hsuan Tsai, Ming-Hsuan Yang", "title": "Mixup-CAM: Weakly-supervised Semantic Segmentation via Uncertainty\n  Regularization", "comments": "Accepted at BMVC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Obtaining object response maps is one important step to achieve\nweakly-supervised semantic segmentation using image-level labels. However,\nexisting methods rely on the classification task, which could result in a\nresponse map only attending on discriminative object regions as the network\ndoes not need to see the entire object for optimizing the classification loss.\nTo tackle this issue, we propose a principled and end-to-end train-able\nframework to allow the network to pay attention to other parts of the object,\nwhile producing a more complete and uniform response map. Specifically, we\nintroduce the mixup data augmentation scheme into the classification network\nand design two uncertainty regularization terms to better interact with the\nmixup strategy. In experiments, we conduct extensive analysis to demonstrate\nthe proposed method and show favorable performance against state-of-the-art\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 21:19:08 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Chang", "Yu-Ting", ""], ["Wang", "Qiaosong", ""], ["Hung", "Wei-Chih", ""], ["Piramuthu", "Robinson", ""], ["Tsai", "Yi-Hsuan", ""], ["Yang", "Ming-Hsuan", ""]]}, {"id": "2008.01204", "submitter": "Ivan Papusha", "authors": "Ivan Papusha, Rosa Wu, Joshua Brul\\'e, Yanni Kouskoulas, Daniel Genin,\n  Aurora Schmidt", "title": "Incorrect by Construction: Fine Tuning Neural Networks for Guaranteed\n  Performance on Finite Sets of Examples", "comments": "Part of 3rd Workshop on Formal Methods for ML-Enabled Autonomous\n  Systems (FoMLAS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is great interest in using formal methods to guarantee the reliability\nof deep neural networks. However, these techniques may also be used to implant\ncarefully selected input-output pairs. We present initial results on a novel\ntechnique for using SMT solvers to fine tune the weights of a ReLU neural\nnetwork to guarantee outcomes on a finite set of particular examples. This\nprocedure can be used to ensure performance on key examples, but it could also\nbe used to insert difficult-to-find incorrect examples that trigger unexpected\nperformance. We demonstrate this approach by fine tuning an MNIST network to\nincorrectly classify a particular image and discuss the potential for the\napproach to compromise reliability of freely-shared machine learning models.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 21:29:53 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Papusha", "Ivan", ""], ["Wu", "Rosa", ""], ["Brul\u00e9", "Joshua", ""], ["Kouskoulas", "Yanni", ""], ["Genin", "Daniel", ""], ["Schmidt", "Aurora", ""]]}, {"id": "2008.01205", "submitter": "Zachary Robertson", "authors": "Zachary W. Robertson, Matthew R. Walter", "title": "Concurrent Training Improves the Performance of Behavioral Cloning from\n  Observation", "comments": "13 pages, 2 figures, Submitted to the 4th Conference on Robot\n  Learning (CoRL 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from demonstration is widely used as an efficient way for robots to\nacquire new skills. However, it typically requires that demonstrations provide\nfull access to the state and action sequences. In contrast, learning from\nobservation offers a way to utilize unlabeled demonstrations (e.g., video) to\nperform imitation learning. One approach to this is behavioral cloning from\nobservation (BCO). The original implementation of BCO proceeds by first\nlearning an inverse dynamics model and then using that model to estimate action\nlabels, thereby reducing the problem to behavioral cloning. However, existing\napproaches to BCO require a large number of initial interactions in the first\nstep. Here, we provide a novel theoretical analysis of BCO, introduce a\nmodification BCO*, and show that in the semi-supervised setting, BCO* can\nconcurrently improve both its estimate for the inverse dynamics model and the\nexpert policy. This result allows us to eliminate the dependence on initial\ninteractions and dramatically improve the sample complexity of BCO. We evaluate\nthe effectiveness of our algorithm through experiments on various benchmark\ndomains. The results demonstrate that concurrent training not only improves\nover the performance of BCO but also results in performance that is competitive\nwith state-of-the-art imitation learning methods such as GAIL and Value-Dice.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 21:30:28 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Robertson", "Zachary W.", ""], ["Walter", "Matthew R.", ""]]}, {"id": "2008.01212", "submitter": "Fernando Benjamin Perez Maurera", "authors": "Fernando Benjam\\'in P\\'erez Maurera, Maurizio Ferrari Dacrema, Lorenzo\n  Saule, Mario Scriminaci, Paolo Cremonesi", "title": "ContentWise Impressions: An Industrial Dataset with Impressions Included", "comments": "8 pages, 2 figures", "journal-ref": "Proceedings of the 29th ACM International Conference on\n  Information & Knowledge Management (CIKM 2020)", "doi": "10.1145/3340531.3412774", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we introduce the ContentWise Impressions dataset, a\ncollection of implicit interactions and impressions of movies and TV series\nfrom an Over-The-Top media service, which delivers its media contents over the\nInternet. The dataset is distinguished from other already available multimedia\nrecommendation datasets by the availability of impressions, i.e., the\nrecommendations shown to the user, its size, and by being open-source. We\ndescribe the data collection process, the preprocessing applied, its\ncharacteristics, and statistics when compared to other commonly used datasets.\nWe also highlight several possible use cases and research questions that can\nbenefit from the availability of user impressions in an open-source dataset.\nFurthermore, we release software tools to load and split the data, as well as\nexamples of how to use both user interactions and impressions in several common\nrecommendation algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 21:46:38 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 12:51:09 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Maurera", "Fernando Benjam\u00edn P\u00e9rez", ""], ["Dacrema", "Maurizio Ferrari", ""], ["Saule", "Lorenzo", ""], ["Scriminaci", "Mario", ""], ["Cremonesi", "Paolo", ""]]}, {"id": "2008.01214", "submitter": "Qian Wang", "authors": "Qian Wang, Toby P. Breckon", "title": "Generalized Zero-Shot Domain Adaptation via Coupled Conditional\n  Variational Autoencoders", "comments": "Durham University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation approaches aim to exploit useful information from the\nsource domain where supervised learning examples are easier to obtain to\naddress a learning problem in the target domain where there is no or limited\navailability of such examples. In classification problems, domain adaptation\nhas been studied under varying supervised, unsupervised and semi-supervised\nconditions. However, a common situation when the labelled samples are available\nfor a subset of target domain classes has been overlooked. In this paper, we\nformulate this particular domain adaptation problem within a generalized\nzero-shot learning framework by treating the labelled source domain samples as\nsemantic representations for zero-shot learning. For this particular problem,\nneither conventional domain adaptation approaches nor zero-shot learning\nalgorithms directly apply. To address this generalized zero-shot domain\nadaptation problem, we present a novel Coupled Conditional Variational\nAutoencoder (CCVAE) which can generate synthetic target domain features for\nunseen classes from their source domain counterparts. Extensive experiments\nhave been conducted on three domain adaptation datasets including a bespoke\nX-ray security checkpoint dataset to simulate a real-world application in\naviation security. The results demonstrate the effectiveness of our proposed\napproach both against established benchmarks and in terms of real-world\napplicability.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 21:48:50 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Wang", "Qian", ""], ["Breckon", "Toby P.", ""]]}, {"id": "2008.01217", "submitter": "Piotr Zielinski", "authors": "Satrajit Chatterjee, Piotr Zielinski", "title": "Making Coherence Out of Nothing At All: Measuring the Evolution of\n  Gradient Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a new metric ($m$-coherence) to experimentally study the alignment\nof per-example gradients during training. Intuitively, given a sample of size\n$m$, $m$-coherence is the number of examples in the sample that benefit from a\nsmall step along the gradient of any one example on average. We show that\ncompared to other commonly used metrics, $m$-coherence is more interpretable,\ncheaper to compute ($O(m)$ instead of $O(m^2)$) and mathematically cleaner. (We\nnote that $m$-coherence is closely connected to gradient diversity, a quantity\npreviously used in some theoretical bounds.) Using $m$-coherence, we study the\nevolution of alignment of per-example gradients in ResNet and Inception models\non ImageNet and several variants with label noise, particularly from the\nperspective of the recently proposed Coherent Gradients (CG) theory that\nprovides a simple, unified explanation for memorization and generalization\n[Chatterjee, ICLR 20]. Although we have several interesting takeaways, our most\nsurprising result concerns memorization. Naively, one might expect that when\ntraining with completely random labels, each example is fitted independently,\nand so $m$-coherence should be close to 1. However, this is not the case:\n$m$-coherence reaches much higher values during training (100s), indicating\nthat over-parameterized neural networks find common patterns even in scenarios\nwhere generalization is not possible. A detailed analysis of this phenomenon\nprovides both a deeper confirmation of CG, but at the same point puts into\nsharp relief what is missing from the theory in order to provide a complete\nexplanation of generalization in neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 21:51:24 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Chatterjee", "Satrajit", ""], ["Zielinski", "Piotr", ""]]}, {"id": "2008.01218", "submitter": "Qian Wang", "authors": "Qian Wang, Neelanjan Bhowmik, Toby P. Breckon", "title": "Multi-Class 3D Object Detection Within Volumetric 3D Computed Tomography\n  Baggage Security Screening Imagery", "comments": "Durham University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic detection of prohibited objects within passenger baggage is\nimportant for aviation security. X-ray Computed Tomography (CT) based 3D\nimaging is widely used in airports for aviation security screening whilst prior\nwork on automatic prohibited item detection focus primarily on 2D X-ray\nimagery. These works have proven the possibility of extending deep\nconvolutional neural networks (CNN) based automatic prohibited item detection\nfrom 2D X-ray imagery to volumetric 3D CT baggage security screening imagery.\nHowever, previous work on 3D object detection in baggage security screening\nimagery focused on the detection of one specific type of objects (e.g., either\n{\\it bottles} or {\\it handguns}). As a result, multiple models are needed if\nmore than one type of prohibited item is required to be detected in practice.\nIn this paper, we consider the detection of multiple object categories of\ninterest using one unified framework. To this end, we formulate a more\nchallenging multi-class 3D object detection problem within 3D CT imagery and\npropose a viable solution (3D RetinaNet) to tackle this problem. To enhance the\nperformance of detection we investigate a variety of strategies including data\naugmentation and varying backbone networks. Experimentation carried out to\nprovide both quantitative and qualitative evaluations of the proposed approach\nto multi-class 3D object detection within 3D CT baggage security screening\nimagery. Experimental results demonstrate the combination of the 3D RetinaNet\nand a series of favorable strategies can achieve a mean Average Precision (mAP)\nof 65.3\\% over five object classes (i.e. {\\it bottles, handguns, binoculars,\nglock frames, iPods}). The overall performance is affected by the poor\nperformance on {\\it glock frames} and {\\it iPods} due to the lack of data and\ntheir resemblance with the baggage clutter.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 21:54:14 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Wang", "Qian", ""], ["Bhowmik", "Neelanjan", ""], ["Breckon", "Toby P.", ""]]}, {"id": "2008.01219", "submitter": "Haoqiang Guo", "authors": "Haoqiang Guo, Lu Peng, Jian Zhang, Fang Qi, Lide Duan", "title": "Hardware Accelerator for Adversarial Attacks on Deep Learning Neural\n  Networks", "comments": "IGSC'2019 (https://shirazi21.wixsite.com/igsc2019archive) Best paper\n  award", "journal-ref": "2019 Tenth International Green and Sustainable Computing\n  Conference (IGSC)", "doi": "10.1109/IGSC48788.2019.8957192", "report-no": null, "categories": "eess.SP cs.AR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent studies identify that Deep learning Neural Networks (DNNs) are\nvulnerable to subtle perturbations, which are not perceptible to human visual\nsystem but can fool the DNN models and lead to wrong outputs. A class of\nadversarial attack network algorithms has been proposed to generate robust\nphysical perturbations under different circumstances. These algorithms are the\nfirst efforts to move forward secure deep learning by providing an avenue to\ntrain future defense networks, however, the intrinsic complexity of them\nprevents their broader usage.\n  In this paper, we propose the first hardware accelerator for adversarial\nattacks based on memristor crossbar arrays. Our design significantly improves\nthe throughput of a visual adversarial perturbation system, which can further\nimprove the robustness and security of future deep learning systems. Based on\nthe algorithm uniqueness, we propose four implementations for the adversarial\nattack accelerator ($A^3$) to improve the throughput, energy efficiency, and\ncomputational efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 21:55:41 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Guo", "Haoqiang", ""], ["Peng", "Lu", ""], ["Zhang", "Jian", ""], ["Qi", "Fang", ""], ["Duan", "Lide", ""]]}, {"id": "2008.01221", "submitter": "Xueyuan Zhao", "authors": "Xueyuan Zhao, Zhuoran Qi, Dario Pompili", "title": "Configuration Learning in Underwater Optical Links", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new research problem named configuration learning is described in this\nwork. A novel algorithm is proposed to address the configuration learning\nproblem. The configuration learning problem is defined to be the optimization\nof the Machine Learning (ML) classifier to maximize the ML performance metric\noptimizing the transmitter configuration in the signal processing/communication\nsystems. Specifically, this configuration learning problem is investigated in\nan underwater optical communication system with signal processing performance\nmetric of the physical-layer communication throughput. A novel algorithm is\nproposed to perform the configuration learning by alternating optimization of\nkey design parameters and switching between several Recurrent Neural Network\n(RNN) classifiers dependant on the learning objective. The proposed ML\nalgorithm is validated with the datasets of an underwater optical communication\nsystem and is compared with competing ML algorithms. Performance results\nindicate that the proposal outperforms the competing algorithms for binary and\nmulti-class configuration learning in underwater optical communication\ndatasets. The proposed configuration learning framework can be further\ninvestigated and applied to a broad range of topics in signal processing and\ncommunications.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 22:06:53 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Zhao", "Xueyuan", ""], ["Qi", "Zhuoran", ""], ["Pompili", "Dario", ""]]}, {"id": "2008.01245", "submitter": "Alexander Cloninger", "authors": "Alexander Cloninger, Hrushikesh Mhaskar", "title": "Cautious Active Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of classification of points sampled from an unknown\nprobability measure on a Euclidean space. We study the question of querying the\nclass label at a very small number of judiciously chosen points so as to be\nable to attach the appropriate class label to every point in the set. Our\napproach is to consider the unknown probability measure as a convex combination\nof the conditional probabilities for each class. Our technique involves the use\nof a highly localized kernel constructed from Hermite polynomials, in order to\ncreate a hierarchical estimate of the supports of the constituent probability\nmeasures. We do not need to make any assumptions on the nature of any of the\nprobability measures nor know in advance the number of classes involved. We\ngive theoretical guarantees measured by the $F$-score for our classification\nscheme. Examples include classification in hyper-spectral images and MNIST\nclassification.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 23:47:31 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 03:41:49 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Cloninger", "Alexander", ""], ["Mhaskar", "Hrushikesh", ""]]}, {"id": "2008.01251", "submitter": "Motohisa Fukuda", "authors": "Motohisa Fukuda, Takashi Okuno, Shinya Yuki", "title": "Central object segmentation by deep learning for fruits and other\n  roundish objects", "comments": "The version 2 contains a new section about the automatic processing\n  of time series photos. All the programs are available at\n  https://github.com/MotohisaFukuda/CROP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CROP (Central Roundish Object Painter), which identifies and\npaints the object at the center of an RGB image. Primarily CROP works for\nroundish fruits in various illumination conditions, but surprisingly, it could\nalso deal with images of other organic or inorganic materials, or ones by\noptical and electron microscopes, although CROP was trained solely by 172\nimages of fruits. The method involves image segmentation by deep learning, and\nthe architecture of the neural network is a deeper version of the original\nU-Net. This technique could provide us with a means of automatically collecting\nstatistical data of fruit growth in farms. As an example, we describe our\nexperiment of processing 510 time series photos automatically to collect the\ndata on the size and the position of the target fruit. Our trained neural\nnetwork CROP and the above automatic programs are available on GitHub with\nuser-friendly interface programs.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 00:13:40 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 12:34:06 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Fukuda", "Motohisa", ""], ["Okuno", "Takashi", ""], ["Yuki", "Shinya", ""]]}, {"id": "2008.01257", "submitter": "Sirui Song", "authors": "Sirui Song, Zefang Zong, Yong Li, Xue Liu, Yang Yu", "title": "Reinforced Epidemic Control: Saving Both Lives and Economy", "comments": "Accepted by KDD'20 \"AI For Covid-19\" Initiative", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saving lives or economy is a dilemma for epidemic control in most cities\nwhile smart-tracing technology raises people's privacy concerns. In this paper,\nwe propose a solution for the life-or-economy dilemma that does not require\nprivate data. We bypass the private-data requirement by suppressing epidemic\ntransmission through a dynamic control on inter-regional mobility that only\nrelies on Origin-Designation (OD) data. We develop DUal-objective\nReinforcement-Learning Epidemic Control Agent (DURLECA) to search\nmobility-control policies that can simultaneously minimize infection spread and\nmaximally retain mobility. DURLECA hires a novel graph neural network, namely\nFlow-GNN, to estimate the virus-transmission risk induced by urban mobility.\nThe estimated risk is used to support a reinforcement learning agent to\ngenerate mobility-control actions. The training of DURLECA is guided with a\nwell-constructed reward function, which captures the natural trade-off relation\nbetween epidemic control and mobility retaining. Besides, we design two\nexploration strategies to improve the agent's searching efficiency and help it\nget rid of local optimums. Extensive experimental results on a real-world OD\ndataset show that DURLECA is able to suppress infections at an extremely low\nlevel while retaining 76\\% of the mobility in the city. Our implementation is\navailable at https://github.com/anyleopeace/DURLECA/.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 00:44:54 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Song", "Sirui", ""], ["Zong", "Zefang", ""], ["Li", "Yong", ""], ["Liu", "Xue", ""], ["Yu", "Yang", ""]]}, {"id": "2008.01263", "submitter": "Yutaka Matsubara", "authors": "Akihisa Morikawa and Yutaka Matsubara", "title": "Safety design concepts for statistical machine learning components\n  toward accordance with functional safety standards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, curial incidents and accidents have been reported due to\nun-intended control caused by misjudgment of statistical machine learning\n(SML), which include deep learning. The international functional safety\nstandards for Electric/Electronic/Programmable (E/E/P) systems have been widely\nspread to improve safety. However, most of them do not recom-mended to use SML\nin safety critical systems so far. In practical the new concepts and methods\nare urgently required to enable SML to be safely used in safety critical\nsystems. In this paper, we organize five kinds of technical safety concepts\n(TSCs) for SML components toward accordance with functional safety standards.\nWe discuss not only quantitative evaluation criteria, but also development\nprocess based on XAI (eXplainable Artificial Intelligence) and Automotive SPICE\nto improve explainability and reliability in development phase. Fi-nally, we\nbriefly compare the TSCs in cost and difficulty, and expect to en-courage\nfurther discussion in many communities and domain.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 01:01:00 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Morikawa", "Akihisa", ""], ["Matsubara", "Yutaka", ""]]}, {"id": "2008.01291", "submitter": "Ke Chen", "authors": "Ke Chen, Cheng-i Wang, Taylor Berg-Kirkpatrick, Shlomo Dubnov", "title": "Music SketchNet: Controllable Music Generation via Factorized\n  Representations of Pitch and Rhythm", "comments": "8 pages, 8 figures, Proceedings of the 21st International Society for\n  Music Information Retrieval Conference, ISMIR 2020", "journal-ref": "21st International Society for Music Information Retrieval\n  Conference, ISMIR 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.MM cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Drawing an analogy with automatic image completion systems, we propose Music\nSketchNet, a neural network framework that allows users to specify partial\nmusical ideas guiding automatic music generation. We focus on generating the\nmissing measures in incomplete monophonic musical pieces, conditioned on\nsurrounding context, and optionally guided by user-specified pitch and rhythm\nsnippets. First, we introduce SketchVAE, a novel variational autoencoder that\nexplicitly factorizes rhythm and pitch contour to form the basis of our\nproposed model. Then we introduce two discriminative architectures,\nSketchInpainter and SketchConnector, that in conjunction perform the guided\nmusic completion, filling in representations for the missing measures\nconditioned on surrounding context and user-specified snippets. We evaluate\nSketchNet on a standard dataset of Irish folk music and compare with models\nfrom recent works. When used for music completion, our approach outperforms the\nstate-of-the-art both in terms of objective metrics and subjective listening\ntests. Finally, we demonstrate that our model can successfully incorporate\nuser-specified snippets during the generation process.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 02:49:57 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Chen", "Ke", ""], ["Wang", "Cheng-i", ""], ["Berg-Kirkpatrick", "Taylor", ""], ["Dubnov", "Shlomo", ""]]}, {"id": "2008.01296", "submitter": "Feihu Huang", "authors": "Feihu Huang, Songcan Chen, Heng Huang", "title": "Faster Stochastic Alternating Direction Method of Multipliers for\n  Nonconvex Optimization", "comments": "Published in ICML 2019, 43 pages. arXiv admin note: text overlap with\n  arXiv:1907.13463", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a faster stochastic alternating direction method of\nmultipliers (ADMM) for nonconvex optimization by using a new stochastic\npath-integrated differential estimator (SPIDER), called as SPIDER-ADMM.\nMoreover, we prove that the SPIDER-ADMM achieves a record-breaking incremental\nfirst-order oracle (IFO) complexity of $\\mathcal{O}(n+n^{1/2}\\epsilon^{-1})$\nfor finding an $\\epsilon$-approximate stationary point, which improves the\ndeterministic ADMM by a factor $\\mathcal{O}(n^{1/2})$, where $n$ denotes the\nsample size. As one of major contribution of this paper, we provide a new\ntheoretical analysis framework for nonconvex stochastic ADMM methods with\nproviding the optimal IFO complexity. Based on this new analysis framework, we\nstudy the unsolved optimal IFO complexity of the existing non-convex SVRG-ADMM\nand SAGA-ADMM methods, and prove they have the optimal IFO complexity of\n$\\mathcal{O}(n+n^{2/3}\\epsilon^{-1})$. Thus, the SPIDER-ADMM improves the\nexisting stochastic ADMM methods by a factor of $\\mathcal{O}(n^{1/6})$.\nMoreover, we extend SPIDER-ADMM to the online setting, and propose a faster\nonline SPIDER-ADMM. Our theoretical analysis shows that the online SPIDER-ADMM\nhas the IFO complexity of $\\mathcal{O}(\\epsilon^{-\\frac{3}{2}})$, which\nimproves the existing best results by a factor of\n$\\mathcal{O}(\\epsilon^{-\\frac{1}{2}})$. Finally, the experimental results on\nbenchmark datasets validate that the proposed algorithms have faster\nconvergence rate than the existing ADMM algorithms for nonconvex optimization.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 02:59:42 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 14:44:23 GMT"}, {"version": "v3", "created": "Mon, 10 Aug 2020 03:20:17 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Huang", "Feihu", ""], ["Chen", "Songcan", ""], ["Huang", "Heng", ""]]}, {"id": "2008.01300", "submitter": "Chengyu Wang", "authors": "Mengli Cheng, Chengyu Wang, Xu Hu, Jun Huang, Xiaobo Wang", "title": "Weakly Supervised Construction of ASR Systems with Massive Video Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building Automatic Speech Recognition (ASR) systems from scratch is\nsignificantly challenging, mostly due to the time-consuming and\nfinancially-expensive process of annotating a large amount of audio data with\ntranscripts. Although several unsupervised pre-training models have been\nproposed, applying such models directly might still be sub-optimal if more\nlabeled, training data could be obtained without a large cost. In this paper,\nwe present a weakly supervised framework for constructing ASR systems with\nmassive video data. As videos often contain human-speech audios aligned with\nsubtitles, we consider videos as an important knowledge source, and propose an\neffective approach to extract high-quality audios aligned with transcripts from\nvideos based on Optical Character Recognition (OCR). The underlying ASR model\ncan be fine-tuned to fit any domain-specific target training datasets after\nweakly supervised pre-training. Extensive experiments show that our framework\ncan easily produce state-of-the-art results on six public datasets for Mandarin\nspeech recognition.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 03:11:32 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 07:22:35 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Cheng", "Mengli", ""], ["Wang", "Chengyu", ""], ["Hu", "Xu", ""], ["Huang", "Jun", ""], ["Wang", "Xiaobo", ""]]}, {"id": "2008.01302", "submitter": "Teng Liu", "authors": "Teng Liu, Bing Huang, Xingyu Mu, Fuqing Zhao, Xiaolin Tang, Dongpu Cao", "title": "A Comparative Analysis of Deep Reinforcement Learning-enabled Freeway\n  Decision-making for Automated Vehicles", "comments": "11 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) is becoming a prevalent and powerful\nmethodology to address the artificial intelligent problems. Owing to its\ntremendous potentials in self-learning and self-improvement, DRL is broadly\nserviced in many research fields. This article conducted a comprehensive\ncomparison of multiple DRL approaches on the freeway decision-making problem\nfor autonomous vehicles. These techniques include the common deep Q learning\n(DQL), double DQL (DDQL), dueling DQL, and prioritized replay DQL. First, the\nreinforcement learning (RL) framework is introduced. As an extension, the\nimplementations of the above mentioned DRL methods are established\nmathematically. Then, the freeway driving scenario for the automated vehicles\nis constructed, wherein the decision-making problem is transferred as a control\noptimization problem. Finally, a series of simulation experiments are achieved\nto evaluate the control performance of these DRL-enabled decision-making\nstrategies. A comparative analysis is realized to connect the autonomous\ndriving results with the learning characteristics of these DRL techniques.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 03:21:34 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Liu", "Teng", ""], ["Huang", "Bing", ""], ["Mu", "Xingyu", ""], ["Zhao", "Fuqing", ""], ["Tang", "Xiaolin", ""], ["Cao", "Dongpu", ""]]}, {"id": "2008.01304", "submitter": "Naoki Hayashi", "authors": "Naoki Hayashi", "title": "The Exact Asymptotic Form of Bayesian Generalization Error in Latent\n  Dirichlet Allocation", "comments": "20 pages, 3 figures, 2 tables. Accepted at Neural Networks (Elsevier)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent Dirichlet allocation (LDA) obtains essential information from data by\nusing Bayesian inference. It is applied to knowledge discovery via dimension\nreducing and clustering in many fields. However, its generalization error had\nnot been yet clarified since it is a singular statistical model where there is\nno one-to-one mapping from parameters to probability distributions. In this\npaper, we give the exact asymptotic form of its generalization error and\nmarginal likelihood, by theoretical analysis of its learning coefficient using\nalgebraic geometry. The theoretical result shows that the Bayesian\ngeneralization error in LDA is expressed in terms of that in matrix\nfactorization and a penalty from the simplex restriction of LDA's parameter\nregion. A numerical experiment is consistent to the theoretical result.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 03:26:16 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 15:49:34 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Hayashi", "Naoki", ""]]}, {"id": "2008.01323", "submitter": "Pengqian Yu", "authors": "Xinhan Di, Pengqian Yu, Hong Zhu, Lei Cai, Qiuyan Sheng, Changyu Sun", "title": "Structural Plan of Indoor Scenes with Personalized Preferences", "comments": "Accepted by the 8th International Workshop on Assistive Computer\n  Vision and Robotics (ACVR) in Conjunction with ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an assistive model that supports professional\ninterior designers to produce industrial interior decoration solutions and to\nmeet the personalized preferences of the property owners. The proposed model is\nable to automatically produce the layout of objects of a particular indoor\nscene according to property owners' preferences. In particular, the model\nconsists of the extraction of abstract graph, conditional graph generation, and\nconditional scene instantiation. We provide an interior layout dataset that\ncontains real-world 11000 designs from professional designers. Our numerical\nresults on the dataset demonstrate the effectiveness of the proposed model\ncompared with the state-of-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 04:46:19 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 13:30:45 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Di", "Xinhan", ""], ["Yu", "Pengqian", ""], ["Zhu", "Hong", ""], ["Cai", "Lei", ""], ["Sheng", "Qiuyan", ""], ["Sun", "Changyu", ""]]}, {"id": "2008.01332", "submitter": "Eloise Berson", "authors": "Elo\\\"ise Berson, Catherine Soladi\\'e, Nicolas Stoiber", "title": "Real-Time Cleaning and Refinement of Facial Animation Signals", "comments": "ICGSP 2020: Proceedings of the 2020 The 4th International Conference\n  on Graphics and Signal Processing", "journal-ref": null, "doi": "10.1145/3406971.3406985", "report-no": null, "categories": "cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing demand for real-time animated 3D content in the\nentertainment industry and beyond, performance-based animation has garnered\ninterest among both academic and industrial communities. While recent solutions\nfor motion-capture animation have achieved impressive results, handmade\npost-processing is often needed, as the generated animations often contain\nartifacts. Existing real-time motion capture solutions have opted for standard\nsignal processing methods to strengthen temporal coherence of the resulting\nanimations and remove inaccuracies. While these methods produce smooth results,\nthey inherently filter-out part of the dynamics of facial motion, such as high\nfrequency transient movements. In this work, we propose a real-time animation\nrefining system that preserves -- or even restores -- the natural dynamics of\nfacial motions. To do so, we leverage an off-the-shelf recurrent neural network\narchitecture that learns proper facial dynamics patterns on clean animation\ndata. We parametrize our system using the temporal derivatives of the signal,\nenabling our network to process animations at any framerate. Qualitative\nresults show that our system is able to retrieve natural motion signals from\nnoisy or degraded input animation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 05:21:02 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Berson", "Elo\u00efse", ""], ["Soladi\u00e9", "Catherine", ""], ["Stoiber", "Nicolas", ""]]}, {"id": "2008.01334", "submitter": "Xin Wen", "authors": "Jie Shao, Xin Wen, Bingchen Zhao and Xiangyang Xue", "title": "Temporal Context Aggregation for Video Retrieval with Contrastive\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current research focus on Content-Based Video Retrieval requires\nhigher-level video representation describing the long-range semantic\ndependencies of relevant incidents, events, etc. However, existing methods\ncommonly process the frames of a video as individual images or short clips,\nmaking the modeling of long-range semantic dependencies difficult. In this\npaper, we propose TCA (Temporal Context Aggregation for Video Retrieval), a\nvideo representation learning framework that incorporates long-range temporal\ninformation between frame-level features using the self-attention mechanism. To\ntrain it on video retrieval datasets, we propose a supervised contrastive\nlearning method that performs automatic hard negative mining and utilizes the\nmemory bank mechanism to increase the capacity of negative samples. Extensive\nexperiments are conducted on multiple video retrieval tasks, such as\nCC_WEB_VIDEO, FIVR-200K, and EVVE. The proposed method shows a significant\nperformance advantage (~17% mAP on FIVR-200K) over state-of-the-art methods\nwith video-level features, and deliver competitive results with 22x faster\ninference time comparing with frame-level features.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 05:24:20 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 08:21:08 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Shao", "Jie", ""], ["Wen", "Xin", ""], ["Zhao", "Bingchen", ""], ["Xue", "Xiangyang", ""]]}, {"id": "2008.01340", "submitter": "Manish Bhattarai", "authors": "Manish Bhattarai, Gopinath Chennupati, Erik Skau, Raviteja Vangara,\n  Hirsto Djidjev, Boian Alexandrov", "title": "Distributed Non-Negative Tensor Train Decomposition", "comments": "Accepted to IEEE-HPEC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The era of exascale computing opens new venues for innovations and\ndiscoveries in many scientific, engineering, and commercial fields. However,\nwith the exaflops also come the extra-large high-dimensional data generated by\nhigh-performance computing. High-dimensional data is presented as\nmultidimensional arrays, aka tensors. The presence of latent (not directly\nobservable) structures in the tensor allows a unique representation and\ncompression of the data by classical tensor factorization techniques. However,\nthe classical tensor methods are not always stable or they can be exponential\nin their memory requirements, which makes them not suitable for\nhigh-dimensional tensors. Tensor train (TT) is a state-of-the-art tensor\nnetwork introduced for factorization of high-dimensional tensors. TT transforms\nthe initial high-dimensional tensor in a network of three-dimensional tensors\nthat requires only a linear storage. Many real-world data, such as, density,\ntemperature, population, probability, etc., are non-negative and for an easy\ninterpretation, the algorithms preserving non-negativity are preferred. Here,\nwe introduce a distributed non-negative tensor-train and demonstrate its\nscalability and the compression on synthetic and real-world big datasets.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 05:35:57 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Bhattarai", "Manish", ""], ["Chennupati", "Gopinath", ""], ["Skau", "Erik", ""], ["Vangara", "Raviteja", ""], ["Djidjev", "Hirsto", ""], ["Alexandrov", "Boian", ""]]}, {"id": "2008.01342", "submitter": "Yuwen Xiong", "authors": "Yuwen Xiong, Mengye Ren, Raquel Urtasun", "title": "LoCo: Local Contrastive Representation Learning", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural nets typically perform end-to-end backpropagation to learn the\nweights, a procedure that creates synchronization constraints in the weight\nupdate step across layers and is not biologically plausible. Recent advances in\nunsupervised contrastive representation learning point to the question of\nwhether a learning algorithm can also be made local, that is, the updates of\nlower layers do not directly depend on the computation of upper layers. While\nGreedy InfoMax separately learns each block with a local objective, we found\nthat it consistently hurts readout accuracy in state-of-the-art unsupervised\ncontrastive learning algorithms, possibly due to the greedy objective as well\nas gradient isolation. In this work, we discover that by overlapping local\nblocks stacking on top of each other, we effectively increase the decoder depth\nand allow upper blocks to implicitly send feedbacks to lower blocks. This\nsimple design closes the performance gap between local learning and end-to-end\ncontrastive learning algorithms for the first time. Aside from standard\nImageNet experiments, we also show results on complex downstream tasks such as\nobject detection and instance segmentation directly using readout features.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 05:41:29 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 08:54:06 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Xiong", "Yuwen", ""], ["Ren", "Mengye", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2008.01352", "submitter": "Jean-Yves Franceschi", "authors": "J\\'er\\'emie Don\\`a (MLIA), Jean-Yves Franceschi (MLIA), Sylvain\n  Lamprier (MLIA), Patrick Gallinari (MLIA)", "title": "PDE-Driven Spatiotemporal Disentanglement", "comments": null, "journal-ref": "The Ninth International Conference on Learning Representations,\n  International Conference on Representation Learning, May 2021, Vienne,\n  Austria", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent line of work in the machine learning community addresses the problem\nof predicting high-dimensional spatiotemporal phenomena by leveraging specific\ntools from the differential equations theory. Following this direction, we\npropose in this article a novel and general paradigm for this task based on a\nresolution method for partial differential equations: the separation of\nvariables. This inspiration allows us to introduce a dynamical interpretation\nof spatiotemporal disentanglement. It induces a principled model based on\nlearning disentangled spatial and temporal representations of a phenomenon to\naccurately predict future observations. We experimentally demonstrate the\nperformance and broad applicability of our method against prior\nstate-of-the-art models on physical and synthetic video datasets.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 06:10:30 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 09:18:31 GMT"}, {"version": "v3", "created": "Tue, 23 Mar 2021 09:44:40 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Don\u00e0", "J\u00e9r\u00e9mie", "", "MLIA"], ["Franceschi", "Jean-Yves", "", "MLIA"], ["Lamprier", "Sylvain", "", "MLIA"], ["Gallinari", "Patrick", "", "MLIA"]]}, {"id": "2008.01362", "submitter": "Jong Chul Ye", "authors": "Hyungjin Chung, Eunju Cha, Leonard Sunwoo, and Jong Chul Ye", "title": "Two-Stage Deep Learning for Accelerated 3D Time-of-Flight MRA without\n  Matched Training Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-of-flight magnetic resonance angiography (TOF-MRA) is one of the most\nwidely used non-contrast MR imaging methods to visualize blood vessels, but due\nto the 3-D volume acquisition highly accelerated acquisition is necessary.\nAccordingly, high quality reconstruction from undersampled TOF-MRA is an\nimportant research topic for deep learning. However, most existing deep\nlearning works require matched reference data for supervised training, which\nare often difficult to obtain. By extending the recent theoretical\nunderstanding of cycleGAN from the optimal transport theory, here we propose a\nnovel two-stage unsupervised deep learning approach, which is composed of the\nmulti-coil reconstruction network along the coronal plane followed by a\nmulti-planar refinement network along the axial plane. Specifically, the first\nnetwork is trained in the square-root of sum of squares (SSoS) domain to\nachieve high quality parallel image reconstruction, whereas the second\nrefinement network is designed to efficiently learn the characteristics of\nhighly-activated blood flow using double-headed max-pool discriminator.\nExtensive experiments demonstrate that the proposed learning process without\nmatched reference exceeds performance of state-of-the-art compressed sensing\n(CS)-based method and provides comparable or even better results than\nsupervised learning approaches.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 06:36:38 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Chung", "Hyungjin", ""], ["Cha", "Eunju", ""], ["Sunwoo", "Leonard", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2008.01370", "submitter": "Adrien Bitton", "authors": "Antoine Caillon, Adrien Bitton, Brice Gatinet, Philippe Esling", "title": "Timbre latent space: exploration and creative aspects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies show the ability of unsupervised models to learn invertible\naudio representations using Auto-Encoders. They enable high-quality sound\nsynthesis but a limited control since the latent spaces do not disentangle\ntimbre properties. The emergence of disentangled representations was studied in\nVariational Auto-Encoders (VAEs), and has been applied to audio. Using an\nadditional perceptual regularization can align such latent representation with\nthe previously established multi-dimensional timbre spaces, while allowing\ncontinuous inference and synthesis. Alternatively, some specific sound\nattributes can be learned as control variables while unsupervised dimensions\naccount for the remaining features. New possibilities for timbre manipulations\nare enabled with generative neural networks, although the exploration and the\ncreative use of their representations remain little. The following experiments\nare led in cooperation with two composers and propose new creative directions\nto explore latent sound synthesis of musical timbres, using specifically\ndesigned interfaces (Max/MSP, Pure Data) or mappings for descriptor-based\nsynthesis.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 07:08:04 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 13:20:40 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Caillon", "Antoine", ""], ["Bitton", "Adrien", ""], ["Gatinet", "Brice", ""], ["Esling", "Philippe", ""]]}, {"id": "2008.01375", "submitter": "Hongsong Yuan", "authors": "Fengnan Gao, Zongming Ma, Hongsong Yuan", "title": "Community detection in sparse latent space models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a simple community detection algorithm originated from\nstochastic blockmodel literature achieves consistency, and even optimality, for\na broad and flexible class of sparse latent space models. The class of models\nincludes latent eigenmodels (arXiv:0711.1146). The community detection\nalgorithm is based on spectral clustering followed by local refinement via\nnormalized edge counting.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 07:12:15 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Gao", "Fengnan", ""], ["Ma", "Zongming", ""], ["Yuan", "Hongsong", ""]]}, {"id": "2008.01377", "submitter": "Stefan Heid", "authors": "Stefan Heid, Marcel Wever, Eyke H\\\"ullermeier", "title": "Reliable Part-of-Speech Tagging of Historical Corpora through Set-Valued\n  Prediction", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Syntactic annotation of corpora in the form of part-of-speech (POS) tags is a\nkey requirement for both linguistic research and subsequent automated natural\nlanguage processing (NLP) tasks. This problem is commonly tackled using machine\nlearning methods, i.e., by training a POS tagger on a sufficiently large corpus\nof labeled data. While the problem of POS tagging can essentially be considered\nas solved for modern languages, historical corpora turn out to be much more\ndifficult, especially due to the lack of native speakers and sparsity of\ntraining data. Moreover, most texts have no sentences as we know them today,\nnor a common orthography. These irregularities render the task of automated POS\ntagging more difficult and error-prone. Under these circumstances, instead of\nforcing the POS tagger to predict and commit to a single tag, it should be\nenabled to express its uncertainty. In this paper, we consider POS tagging\nwithin the framework of set-valued prediction, which allows the POS tagger to\nexpress its uncertainty via predicting a set of candidate POS tags instead of\nguessing a single one. The goal is to guarantee a high confidence that the\ncorrect POS tag is included while keeping the number of candidates small. In\nour experimental study, we find that extending state-of-the-art POS taggers to\nset-valued prediction yields more precise and robust taggings, especially for\nunknown words, i.e., words not occurring in the training data.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 07:21:36 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 12:59:57 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Heid", "Stefan", ""], ["Wever", "Marcel", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2008.01380", "submitter": "Ata Mahjoubfar", "authors": "Te-Yuan Liu, Ata Mahjoubfar, Daniel Prusinski, Luis Stevens", "title": "Neuromorphic Computing for Content-based Image Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic computing mimics the neural activity of the brain through\nemulating spiking neural networks. In numerous machine learning tasks,\nneuromorphic chips are expected to provide superior solutions in terms of cost\nand power efficiency. Here, we explore the application of Loihi, a neuromorphic\ncomputing chip developed by Intel, for the computer vision task of image\nretrieval. We evaluated the functionalities and the performance metrics that\nare critical in context-based visual search and recommender systems using\ndeep-learning embeddings. Our results show that the neuromorphic solution is\nabout 3.2 times more energy-efficient compared with an Intel Core i7 CPU and\n12.5 times more energy-efficient compared with Nvidia T4 GPU for inference by a\nlightweight convolutional neural network without batching, while maintaining\nthe same level of matching accuracy. The study validates the longterm potential\nof neuromorphic computing in machine learning, as a complementary paradigm to\nthe existing Von Neumann architectures.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 07:34:07 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Liu", "Te-Yuan", ""], ["Mahjoubfar", "Ata", ""], ["Prusinski", "Daniel", ""], ["Stevens", "Luis", ""]]}, {"id": "2008.01389", "submitter": "Jogendra Nath Kundu", "authors": "Jogendra Nath Kundu, Rahul Mysore Venkatesh, Naveen Venkat, Ambareesh\n  Revanur, R. Venkatesh Babu", "title": "Class-Incremental Domain Adaptation", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a practical Domain Adaptation (DA) paradigm called\nClass-Incremental Domain Adaptation (CIDA). Existing DA methods tackle\ndomain-shift but are unsuitable for learning novel target-domain classes.\nMeanwhile, class-incremental (CI) methods enable learning of new classes in\nabsence of source training data but fail under a domain-shift without labeled\nsupervision. In this work, we effectively identify the limitations of these\napproaches in the CIDA paradigm. Motivated by theoretical and empirical\nobservations, we propose an effective method, inspired by prototypical\nnetworks, that enables classification of target samples into both shared and\nnovel (one-shot) target classes, even under a domain-shift. Our approach yields\nsuperior performance as compared to both DA and CI methods in the CIDA\nparadigm.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 07:55:03 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Kundu", "Jogendra Nath", ""], ["Venkatesh", "Rahul Mysore", ""], ["Venkat", "Naveen", ""], ["Revanur", "Ambareesh", ""], ["Babu", "R. Venkatesh", ""]]}, {"id": "2008.01393", "submitter": "Adrien Bitton", "authors": "Adrien Bitton, Philippe Esling, Tatsuya Harada", "title": "Neural Granular Sound Synthesis", "comments": "presented for ICMC 2021 (2020 postponed)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Granular sound synthesis is a popular audio generation technique based on\nrearranging sequences of small waveform windows. In order to control the\nsynthesis, all grains in a given corpus are analyzed through a set of acoustic\ndescriptors. This provides a representation reflecting some form of local\nsimilarities across the grains. However, the quality of this grain space is\nbound by that of the descriptors. Its traversal is not continuously invertible\nto signal and does not render any structured temporality.\n  We demonstrate that generative neural networks can implement granular\nsynthesis while alleviating most of its shortcomings. We efficiently replace\nits audio descriptor basis by a probabilistic latent space learned with a\nVariational Auto-Encoder. In this setting the learned grain space is\ninvertible, meaning that we can continuously synthesize sound when traversing\nits dimensions. It also implies that original grains are not stored for\nsynthesis. Another major advantage of our approach is to learn structured paths\ninside this latent space by training a higher-level temporal embedding over\narranged grain sequences.\n  The model can be applied to many types of libraries, including pitched notes\nor unpitched drums and environmental noises. We report experiments on the\ncommon granular synthesis processes as well as novel ones such as conditional\nsampling and morphing.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 08:08:00 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 16:16:05 GMT"}, {"version": "v3", "created": "Sat, 3 Jul 2021 17:26:15 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Bitton", "Adrien", ""], ["Esling", "Philippe", ""], ["Harada", "Tatsuya", ""]]}, {"id": "2008.01405", "submitter": "Hyungtae Lim", "authors": "Hyungtae Lim, Hyeonjae Gil and Hyun Myung", "title": "MSDPN: Monocular Depth Prediction with Partial Laser Observation using\n  Multi-stage Neural Networks", "comments": "8 pages, 8 figures, IEEE/RSJ Intelligent Robots and Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, a deep-learning-based multi-stage network architecture called\nMulti-Stage Depth Prediction Network (MSDPN) is proposed to predict a dense\ndepth map using a 2D LiDAR and a monocular camera. Our proposed network\nconsists of a multi-stage encoder-decoder architecture and Cross Stage Feature\nAggregation (CSFA). The proposed multi-stage encoder-decoder architecture\nalleviates the partial observation problem caused by the characteristics of a\n2D LiDAR, and CSFA prevents the multi-stage network from diluting the features\nand allows the network to learn the inter-spatial relationship between features\nbetter. Previous works use sub-sampled data from the ground truth as an input\nrather than actual 2D LiDAR data. In contrast, our approach trains the model\nand conducts experiments with a physically-collected 2D LiDAR dataset. To this\nend, we acquired our own dataset called KAIST RGBD-scan dataset and validated\nthe effectiveness and the robustness of MSDPN under realistic conditions. As\nverified experimentally, our network yields promising performance against\nstate-of-the-art methods. Additionally, we analyzed the performance of\ndifferent input methods and confirmed that the reference depth map is robust in\nuntrained scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 08:27:40 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Lim", "Hyungtae", ""], ["Gil", "Hyeonjae", ""], ["Myung", "Hyun", ""]]}, {"id": "2008.01411", "submitter": "Xi Li", "authors": "Hanbin Zhao, Hui Wang, Yongjian Fu, Fei Wu, Xi Li", "title": "Memory Efficient Class-Incremental Learning for Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the memory-resource-limited constraints, class-incremental learning\n(CIL) usually suffers from the \"catastrophic forgetting\" problem when updating\nthe joint classification model on the arrival of newly added classes. To cope\nwith the forgetting problem, many CIL methods transfer the knowledge of old\nclasses by preserving some exemplar samples into the size-constrained memory\nbuffer. To utilize the memory buffer more efficiently, we propose to keep more\nauxiliary low-fidelity exemplar samples rather than the original real\nhigh-fidelity exemplar samples. Such a memory-efficient exemplar preserving\nscheme makes the old-class knowledge transfer more effective. However, the\nlow-fidelity exemplar samples are often distributed in a different domain away\nfrom that of the original exemplar samples, that is, a domain shift. To\nalleviate this problem, we propose a duplet learning scheme that seeks to\nconstruct domain-compatible feature extractors and classifiers, which greatly\nnarrows down the above domain gap. As a result, these low-fidelity auxiliary\nexemplar samples have the ability to moderately replace the original exemplar\nsamples with a lower memory cost. In addition, we present a robust classifier\nadaptation scheme, which further refines the biased classifier (learned with\nthe samples containing distillation label knowledge about old classes) with the\nhelp of the samples of pure true class labels. Experimental results demonstrate\nthe effectiveness of this work against the state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 08:39:40 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 13:32:08 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Zhao", "Hanbin", ""], ["Wang", "Hui", ""], ["Fu", "Yongjian", ""], ["Wu", "Fei", ""], ["Li", "Xi", ""]]}, {"id": "2008.01425", "submitter": "Thijs Vogels", "authors": "Thijs Vogels and Sai Praneeth Karimireddy and Martin Jaggi", "title": "PowerGossip: Practical Low-Rank Communication Compression in\n  Decentralized Deep Learning", "comments": "To appear in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lossy gradient compression has become a practical tool to overcome the\ncommunication bottleneck in centrally coordinated distributed training of\nmachine learning models. However, algorithms for decentralized training with\ncompressed communication over arbitrary connected networks have been more\ncomplicated, requiring additional memory and hyperparameters. We introduce a\nsimple algorithm that directly compresses the model differences between\nneighboring workers using low-rank linear compressors applied on model\ndifferences. Inspired by the PowerSGD algorithm for centralized deep learning,\nthis algorithm uses power iteration steps to maximize the information\ntransferred per bit. We prove that our method requires no additional\nhyperparameters, converges faster than prior methods, and is asymptotically\nindependent of both the network and the compression. Out of the box, these\ncompressors perform on par with state-of-the-art tuned compression algorithms\nin a series of deep learning benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 09:14:52 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 15:07:50 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Vogels", "Thijs", ""], ["Karimireddy", "Sai Praneeth", ""], ["Jaggi", "Martin", ""]]}, {"id": "2008.01430", "submitter": "Enzo Tartaglione", "authors": "Enzo Tartaglione and Marco Grangetto", "title": "A non-discriminatory approach to ethical deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks perform state-of-the-art in an ever-growing number\nof tasks, nowadays they are used to solve an incredibly large variety of tasks.\nHowever, typical training strategies do not take into account lawful, ethical\nand discriminatory potential issues the trained ANN models could incur in. In\nthis work we propose NDR, a non-discriminatory regularization strategy to\nprevent the ANN model to solve the target task using some discriminatory\nfeatures like, for example, the ethnicity in an image classification task for\nhuman faces. In particular, a part of the ANN model is trained to hide the\ndiscriminatory information such that the rest of the network focuses in\nlearning the given learning task. Our experiments show that NDR can be\nexploited to achieve non-discriminatory models with both minimal computational\noverhead and performance loss.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 09:33:02 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Tartaglione", "Enzo", ""], ["Grangetto", "Marco", ""]]}, {"id": "2008.01438", "submitter": "Andrey Ignatov", "authors": "Dmitry Ignatov and Andrey Ignatov", "title": "Controlling Information Capacity of Binary Neural Network", "comments": null, "journal-ref": null, "doi": "10.1016/j.patrec.2020.07.033", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the growing popularity of deep learning technologies, high memory\nrequirements and power consumption are essentially limiting their application\nin mobile and IoT areas. While binary convolutional networks can alleviate\nthese problems, the limited bitwidth of weights is often leading to significant\ndegradation of prediction accuracy. In this paper, we present a method for\ntraining binary networks that maintains a stable predefined level of their\ninformation capacity throughout the training process by applying Shannon\nentropy based penalty to convolutional filters. The results of experiments\nconducted on SVHN, CIFAR and ImageNet datasets demonstrate that the proposed\napproach can statistically significantly improve the accuracy of binary\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 10:08:28 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Ignatov", "Dmitry", ""], ["Ignatov", "Andrey", ""]]}, {"id": "2008.01441", "submitter": "Robert Ridley", "authors": "Robert Ridley, Liang He, Xinyu Dai, Shujian Huang, Jiajun Chen", "title": "Prompt Agnostic Essay Scorer: A Domain Generalization Approach to\n  Cross-prompt Automated Essay Scoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-prompt automated essay scoring (AES) requires the system to use non\ntarget-prompt essays to award scores to a target-prompt essay. Since obtaining\na large quantity of pre-graded essays to a particular prompt is often difficult\nand unrealistic, the task of cross-prompt AES is vital for the development of\nreal-world AES systems, yet it remains an under-explored area of research.\nModels designed for prompt-specific AES rely heavily on prompt-specific\nknowledge and perform poorly in the cross-prompt setting, whereas current\napproaches to cross-prompt AES either require a certain quantity of labelled\ntarget-prompt essays or require a large quantity of unlabelled target-prompt\nessays to perform transfer learning in a multi-step manner. To address these\nissues, we introduce Prompt Agnostic Essay Scorer (PAES) for cross-prompt AES.\nOur method requires no access to labelled or unlabelled target-prompt data\nduring training and is a single-stage approach. PAES is easy to apply in\npractice and achieves state-of-the-art performance on the Automated Student\nAssessment Prize (ASAP) dataset.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 10:17:38 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Ridley", "Robert", ""], ["He", "Liang", ""], ["Dai", "Xinyu", ""], ["Huang", "Shujian", ""], ["Chen", "Jiajun", ""]]}, {"id": "2008.01454", "submitter": "Feng Liu", "authors": "Yiyang Zhang, Feng Liu, Zhen Fang, Bo Yuan, Guangquan Zhang, Jie Lu", "title": "Learning from a Complementary-label Source Domain: Theory and Algorithms", "comments": "arXiv admin note: text overlap with arXiv:2007.14612", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In unsupervised domain adaptation (UDA), a classifier for the target domain\nis trained with massive true-label data from the source domain and unlabeled\ndata from the target domain. However, collecting fully-true-label data in the\nsource domain is high-cost and sometimes impossible. Compared to the true\nlabels, a complementary label specifies a class that a pattern does not belong\nto, hence collecting complementary labels would be less laborious than\ncollecting true labels. Thus, in this paper, we propose a novel setting that\nthe source domain is composed of complementary-label data, and a theoretical\nbound for it is first proved. We consider two cases of this setting, one is\nthat the source domain only contains complementary-label data (completely\ncomplementary unsupervised domain adaptation, CC-UDA), and the other is that\nthe source domain has plenty of complementary-label data and a small amount of\ntrue-label data (partly complementary unsupervised domain adaptation, PC-UDA).\nTo this end, a complementary label adversarial network} (CLARINET) is proposed\nto solve CC-UDA and PC-UDA problems. CLARINET maintains two deep networks\nsimultaneously, where one focuses on classifying complementary-label source\ndata and the other takes care of source-to-target distributional adaptation.\nExperiments show that CLARINET significantly outperforms a series of competent\nbaselines on handwritten-digits-recognition and objects-recognition tasks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 10:49:35 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Zhang", "Yiyang", ""], ["Liu", "Feng", ""], ["Fang", "Zhen", ""], ["Yuan", "Bo", ""], ["Zhang", "Guangquan", ""], ["Lu", "Jie", ""]]}, {"id": "2008.01459", "submitter": "Li Wei", "authors": "Li Wei, Chongwen Huang, George C. Alexandropoulos, Senior Member,\n  IEEE, Chau Yuen, Senior Member, IEEE, Zhaoyang Zhang, Member, IEEE, and\n  M\\'erouane Debbah, Fellow, IEEE", "title": "Channel Estimation for RIS-Empowered Multi-User MISO Wireless\n  Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconfigurable Intelligent Surfaces (RISs) have been recently considered as\nan energy-efficient solution for future wireless networks due to their fast and\nlow-power configuration, which has increased potential in enabling massive\nconnectivity and low-latency communications. Accurate and low-overhead channel\nestimation in RIS-based systems is one of the most critical challenges due to\nthe usually large number of RIS unit elements and their distinctive hardware\nconstraints. In this paper, we focus on the downlink of a RIS-empowered\nmulti-user Multiple Input Single Output (MISO) downlink communication systems\nand propose a channel estimation framework based on the PARAllel FACtor\n(PARAFAC) decomposition to unfold the resulting cascaded channel model. We\npresent two iterative estimation algorithms for the channels between the base\nstation and RIS, as well as the channels between RIS and users. One is based on\nalternating least squares (ALS), while the other uses vector approximate\nmessage passing to iteratively reconstruct two unknown channels from the\nestimated vectors. To theoretically assess the performance of the ALS-based\nalgorithm, we derived its estimation Cram\\'er-Rao Bound (CRB). We also discuss\nthe achievable sum-rate computation with estimated channels and different\nprecoding schemes for the base station. Our extensive simulation results show\nthat our algorithms outperform benchmark schemes and that the ALS technique\nachieve the CRB. It is also demonstrated that the sum rate using the estimated\nchannels reached that of perfect channel estimation under various settings,\nthus, verifying the effectiveness and robustness of the proposed estimation\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 10:53:51 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Wei", "Li", ""], ["Huang", "Chongwen", ""], ["Alexandropoulos", "George C.", ""], ["Member", "Senior", ""], ["IEEE", "", ""], ["Yuen", "Chau", ""], ["Member", "Senior", ""], ["IEEE", "", ""], ["Zhang", "Zhaoyang", ""], ["Member", "", ""], ["IEEE", "", ""], ["Debbah", "M\u00e9rouane", ""], ["Fellow", "", ""], ["IEEE", "", ""]]}, {"id": "2008.01468", "submitter": "Kai Fabi", "authors": "Kai Fabi, Jonas Schneider", "title": "On Feature Relevance Uncertainty: A Monte Carlo Dropout Sampling\n  Approach", "comments": "18 pages, 15 figures", "journal-ref": null, "doi": "10.5281/zenodo.3970396", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding decisions made by neural networks is key for the deployment of\nintelligent systems in real world applications. However, the opaque decision\nmaking process of these systems is a disadvantage where interpretability is\nessential. Many feature-based explanation techniques have been introduced over\nthe last few years in the field of machine learning to better understand\ndecisions made by neural networks and have become an important component to\nverify their reasoning capabilities. However, existing methods do not allow\nstatements to be made about the uncertainty regarding a feature's relevance for\nthe prediction. In this paper, we introduce Monte Carlo Relevance Propagation\n(MCRP) for feature relevance uncertainty estimation. A simple but powerful\nmethod based on Monte Carlo estimation of the feature relevance distribution to\ncompute feature relevance uncertainty scores that allow a deeper understanding\nof a neural network's perception and reasoning.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 11:31:16 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Fabi", "Kai", ""], ["Schneider", "Jonas", ""]]}, {"id": "2008.01475", "submitter": "Lingxi Xie", "authors": "Lingxi Xie, Xin Chen, Kaifeng Bi, Longhui Wei, Yuhui Xu, Zhengsu Chen,\n  Lanfei Wang, An Xiao, Jianlong Chang, Xiaopeng Zhang, Qi Tian", "title": "Weight-Sharing Neural Architecture Search: A Battle to Shrink the\n  Optimization Gap", "comments": "24 pages, 3 figures, 2 tables, meta data updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) has attracted increasing attentions in both\nacademia and industry. In the early age, researchers mostly applied individual\nsearch methods which sample and evaluate the candidate architectures separately\nand thus incur heavy computational overheads. To alleviate the burden,\nweight-sharing methods were proposed in which exponentially many architectures\nshare weights in the same super-network, and the costly training procedure is\nperformed only once. These methods, though being much faster, often suffer the\nissue of instability. This paper provides a literature review on NAS, in\nparticular the weight-sharing methods, and points out that the major challenge\ncomes from the optimization gap between the super-network and the\nsub-architectures. From this perspective, we summarize existing approaches into\nseveral categories according to their efforts in bridging the gap, and analyze\nboth advantages and disadvantages of these methodologies. Finally, we share our\nopinions on the future directions of NAS and AutoML. Due to the expertise of\nthe authors, this paper mainly focuses on the application of NAS to computer\nvision problems and may bias towards the work in our group.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 11:57:03 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 03:30:13 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Xie", "Lingxi", ""], ["Chen", "Xin", ""], ["Bi", "Kaifeng", ""], ["Wei", "Longhui", ""], ["Xu", "Yuhui", ""], ["Chen", "Zhengsu", ""], ["Wang", "Lanfei", ""], ["Xiao", "An", ""], ["Chang", "Jianlong", ""], ["Zhang", "Xiaopeng", ""], ["Tian", "Qi", ""]]}, {"id": "2008.01487", "submitter": "Yacov Hel-Or", "authors": "Alon Oring and Zohar Yakhini and Yacov Hel-Or", "title": "Autoencoder Image Interpolation by Shaping the Latent Space", "comments": "Submitted Sept 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoders represent an effective approach for computing the underlying\nfactors characterizing datasets of different types. The latent representation\nof autoencoders have been studied in the context of enabling interpolation\nbetween data points by decoding convex combinations of latent vectors. This\ninterpolation, however, often leads to artifacts or produces unrealistic\nresults during reconstruction. We argue that these incongruities are due to the\nstructure of the latent space and because such naively interpolated latent\nvectors deviate from the data manifold. In this paper, we propose a\nregularization technique that shapes the latent representation to follow a\nmanifold that is consistent with the training images and that drives the\nmanifold to be smooth and locally convex. This regularization not only enables\nfaithful interpolation between data points, as we show herein, but can also be\nused as a general regularization technique to avoid overfitting or to produce\nnew samples for data augmentation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 12:32:54 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 02:03:08 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Oring", "Alon", ""], ["Yakhini", "Zohar", ""], ["Hel-Or", "Yacov", ""]]}, {"id": "2008.01503", "submitter": "Ming-Wei Li", "authors": "Ming-Wei Li, Qing-Yuan Jiang, Wu-Jun Li", "title": "Multiple Code Hashing for Efficient Image Retrieval", "comments": "12 pages, 9 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its low storage cost and fast query speed, hashing has been widely\nused in large-scale image retrieval tasks. Hash bucket search returns data\npoints within a given Hamming radius to each query, which can enable search at\na constant or sub-linear time cost. However, existing hashing methods cannot\nachieve satisfactory retrieval performance for hash bucket search in complex\nscenarios, since they learn only one hash code for each image. More\nspecifically, by using one hash code to represent one image, existing methods\nmight fail to put similar image pairs to the buckets with a small Hamming\ndistance to the query when the semantic information of images is complex. As a\nresult, a large number of hash buckets need to be visited for retrieving\nsimilar images, based on the learned codes. This will deteriorate the\nefficiency of hash bucket search. In this paper, we propose a novel hashing\nframework, called multiple code hashing (MCH), to improve the performance of\nhash bucket search. The main idea of MCH is to learn multiple hash codes for\neach image, with each code representing a different region of the image.\nFurthermore, we propose a deep reinforcement learning algorithm to learn the\nparameters in MCH. To the best of our knowledge, this is the first work that\nproposes to learn multiple hash codes for each image in image retrieval.\nExperiments demonstrate that MCH can achieve a significant improvement in hash\nbucket search, compared with existing methods that learn only one hash code for\neach image.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 13:18:19 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Li", "Ming-Wei", ""], ["Jiang", "Qing-Yuan", ""], ["Li", "Wu-Jun", ""]]}, {"id": "2008.01505", "submitter": "Charlie Dickens", "authors": "Charlie Dickens, Eric Meissner, Pablo G. Moreno, Tom Diethe", "title": "Interpretable Anomaly Detection with Mondrian P{\\'o}lya Forests on Data\n  Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection at scale is an extremely challenging problem of great\npracticality. When data is large and high-dimensional, it can be difficult to\ndetect which observations do not fit the expected behaviour. Recent work has\ncoalesced on variations of (random) $k$\\emph{d-trees} to summarise data for\nanomaly detection. However, these methods rely on ad-hoc score functions that\nare not easy to interpret, making it difficult to asses the severity of the\ndetected anomalies or select a reasonable threshold in the absence of labelled\nanomalies. To solve these issues, we contextualise these methods in a\nprobabilistic framework which we call the Mondrian \\Polya{} Forest for\nestimating the underlying probability density function generating the data and\nenabling greater interpretability than prior work. In addition, we develop a\nmemory efficient variant able to operate in the modern streaming environments.\nOur experiments show that these methods achieves state-of-the-art performance\nwhile providing statistically interpretable anomaly scores.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 13:19:07 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Dickens", "Charlie", ""], ["Meissner", "Eric", ""], ["Moreno", "Pablo G.", ""], ["Diethe", "Tom", ""]]}, {"id": "2008.01510", "submitter": "Enrico Fini", "authors": "Enrico Fini, St\\'ephane Lathuili\\`ere, Enver Sangineto, Moin Nabi,\n  Elisa Ricci", "title": "Online Continual Learning under Extreme Memory Constraints", "comments": "Accepted at ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual Learning (CL) aims to develop agents emulating the human ability to\nsequentially learn new tasks while being able to retain knowledge obtained from\npast experiences. In this paper, we introduce the novel problem of\nMemory-Constrained Online Continual Learning (MC-OCL) which imposes strict\nconstraints on the memory overhead that a possible algorithm can use to avoid\ncatastrophic forgetting. As most, if not all, previous CL methods violate these\nconstraints, we propose an algorithmic solution to MC-OCL: Batch-level\nDistillation (BLD), a regularization-based CL approach, which effectively\nbalances stability and plasticity in order to learn from data streams, while\npreserving the ability to solve old tasks through distillation. Our extensive\nexperimental evaluation, conducted on three publicly available benchmarks,\nempirically demonstrates that our approach successfully addresses the MC-OCL\nproblem and achieves comparable accuracy to prior distillation methods\nrequiring higher memory overhead.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 13:25:26 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 09:10:34 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Fini", "Enrico", ""], ["Lathuili\u00e8re", "St\u00e9phane", ""], ["Sangineto", "Enver", ""], ["Nabi", "Moin", ""], ["Ricci", "Elisa", ""]]}, {"id": "2008.01511", "submitter": "Adenilton Jos\\'e da Silva", "authors": "Israel F. Araujo, Daniel K. Park, Francesco Petruccione and Adenilton\n  J. da Silva", "title": "A divide-and-conquer algorithm for quantum state preparation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advantages in several fields of research and industry are expected with the\nrise of quantum computers. However, the computational cost to load classical\ndata in quantum computers can impose restrictions on possible quantum speedups.\nKnown algorithms to create arbitrary quantum states require quantum circuits\nwith depth O(N) to load an N-dimensional vector. Here, we show that it is\npossible to load an N-dimensional vector with a quantum circuit with\npolylogarithmic depth and entangled information in ancillary qubits. Results\nshow that we can efficiently load data in quantum devices using a\ndivide-and-conquer strategy to exchange computational time for space. We\ndemonstrate a proof of concept on a real quantum device and present two\napplications for quantum machine learning. We expect that this new loading\nstrategy allows the quantum speedup of tasks that require to load a significant\nvolume of information to quantum devices.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 13:26:07 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Araujo", "Israel F.", ""], ["Park", "Daniel K.", ""], ["Petruccione", "Francesco", ""], ["da Silva", "Adenilton J.", ""]]}, {"id": "2008.01515", "submitter": "Arthur Reys", "authors": "Arthur D. Reys, Danilo Silva, Daniel Severo, Saulo Pedro, Marcia M. de\n  Souza e S\\'a, Guilherme A. C. Salgado", "title": "Predicting Multiple ICD-10 Codes from Brazilian-Portuguese Clinical\n  Notes", "comments": "Accepted at BRACIS 2020", "journal-ref": null, "doi": "10.1007/978-3-030-61377-8_39", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ICD coding from electronic clinical records is a manual, time-consuming and\nexpensive process. Code assignment is, however, an important task for billing\npurposes and database organization. While many works have studied the problem\nof automated ICD coding from free text using machine learning techniques, most\nuse records in the English language, especially from the MIMIC-III public\ndataset. This work presents results for a dataset with Brazilian Portuguese\nclinical notes. We develop and optimize a Logistic Regression model, a\nConvolutional Neural Network (CNN), a Gated Recurrent Unit Neural Network and a\nCNN with Attention (CNN-Att) for prediction of diagnosis ICD codes. We also\nreport our results for the MIMIC-III dataset, which outperform previous work\namong models of the same families, as well as the state of the art. Compared to\nMIMIC-III, the Brazilian Portuguese dataset contains far fewer words per\ndocument, when only discharge summaries are used. We experiment concatenating\nadditional documents available in this dataset, achieving a great boost in\nperformance. The CNN-Att model achieves the best results on both datasets, with\nmicro-averaged F1 score of 0.537 on MIMIC-III and 0.485 on our dataset with\nadditional documents.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 22:12:26 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Reys", "Arthur D.", ""], ["Silva", "Danilo", ""], ["Severo", "Daniel", ""], ["Pedro", "Saulo", ""], ["S\u00e1", "Marcia M. de Souza e", ""], ["Salgado", "Guilherme A. C.", ""]]}, {"id": "2008.01524", "submitter": "Deepak Ravikumar", "authors": "Deepak Ravikumar, Sangamesh Kodge, Isha Garg, Kaushik Roy", "title": "TREND: Transferability based Robust ENsemble Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning models hold state-of-the-art performance in many fields, but\ntheir vulnerability to adversarial examples poses threat to their ubiquitous\ndeployment in practical settings. Additionally, adversarial inputs generated on\none classifier have been shown to transfer to other classifiers trained on\nsimilar data, which makes the attacks possible even if model parameters are not\nrevealed to the adversary. This property of transferability has not yet been\nsystematically studied, leading to a gap in our understanding of robustness of\nneural networks to adversarial inputs. In this work, we study the effect of\nnetwork architecture, initialization, optimizer, input, weight and activation\nquantization on transferability of adversarial samples. We also study the\neffect of different attacks on transferability. Our experiments reveal that\ntransferability is significantly hampered by input quantization and\narchitectural mismatch between source and target, is unaffected by\ninitialization but the choice of optimizer turns out to be critical. We observe\nthat transferability is architecture-dependent for both weight and activation\nquantized models. To quantify transferability, we use simple metric and\ndemonstrate the utility of the metric in designing a methodology to build\nensembles with improved adversarial robustness. When attacking ensembles we\nobserve that \"gradient domination\" by a single ensemble member model hampers\nexisting attacks. To combat this we propose a new state-of-the-art ensemble\nattack. We compare the proposed attack with existing attack techniques to show\nits effectiveness. Finally, we show that an ensemble consisting of carefully\nchosen diverse networks achieves better adversarial robustness than would\notherwise be possible with a single network.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 13:38:14 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 17:00:39 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Ravikumar", "Deepak", ""], ["Kodge", "Sangamesh", ""], ["Garg", "Isha", ""], ["Roy", "Kaushik", ""]]}, {"id": "2008.01527", "submitter": "Venkatasubramanian Viswanathan", "authors": "Alexander Bills and Shashank Sripad and William L. Fredericks and\n  Matthew Guttenberg and Devin Charles and Evan Frank and Venkatasubramanian\n  Viswanathan", "title": "Universal Battery Performance and Degradation Model for Electric\n  Aircraft", "comments": "38 pages, 5 figures, 8 pages of Supplementary information", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.app-ph cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Development of Urban Air Mobility (UAM) concepts has been primarily focused\non electric vertical takeoff and landing aircraft (eVTOLs), small aircraft\nwhich can land and takeoff vertically, and which are powered by rechargeable\n(typically lithium-ion) batteries. Design, analysis, and operation of eVTOLs\nrequires fast and accurate prediction of Li-ion battery performance throughout\nthe lifetime of the battery. eVTOL battery performance modeling must be\nparticularly accurate at high discharge rates to ensure accurate simulation of\nthe high power takeoff and landing portions of the flight. In this work, we\ngenerate a battery performance and thermal behavior dataset specific to eVTOL\nduty cycles. We use this dataset to develop a battery performance and\ndegradation model (Cellfit) which employs physics-informed machine learning in\nthe form of Universal Ordinary Differential Equations (U-ODE's) combined with\nan electrochemical cell model and degradation models which include solid\nelectrolyte interphase (SEI) growth, lithium plating, and charge loss. We show\nthat Cellfit with U-ODE's is better able to predict battery degradation than a\nmechanistic battery degradation model. We show that the improved accuracy of\nthe degradation model improves the accuracy of the performance model. We\nbelieve that Cellfit will prove to be a valuable tool for eVTOL designers.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 16:10:54 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 18:34:01 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Bills", "Alexander", ""], ["Sripad", "Shashank", ""], ["Fredericks", "William L.", ""], ["Guttenberg", "Matthew", ""], ["Charles", "Devin", ""], ["Frank", "Evan", ""], ["Viswanathan", "Venkatasubramanian", ""]]}, {"id": "2008.01531", "submitter": "Maren Awiszus", "authors": "Maren Awiszus, Frederik Schubert, Bodo Rosenhahn", "title": "TOAD-GAN: Coherent Style Level Generation from a Single Example", "comments": "7 pages, 7 figures. AAAI Conference on Artificial Intelligence and\n  Interactive Digital Entertainment (AIIDE) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present TOAD-GAN (Token-based One-shot Arbitrary Dimension\nGenerative Adversarial Network), a novel Procedural Content Generation (PCG)\nalgorithm that generates token-based video game levels. TOAD-GAN follows the\nSinGAN architecture and can be trained using only one example. We demonstrate\nits application for Super Mario Bros. levels and are able to generate new\nlevels of similar style in arbitrary sizes. We achieve state-of-the-art results\nin modeling the patterns of the training level and provide a comparison with\ndifferent baselines under several metrics. Additionally, we present an\nextension of the method that allows the user to control the generation process\nof certain token structures to ensure a coherent global level layout. We\nprovide this tool to the community to spur further research by publishing our\nsource code.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 13:44:50 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Awiszus", "Maren", ""], ["Schubert", "Frederik", ""], ["Rosenhahn", "Bodo", ""]]}, {"id": "2008.01536", "submitter": "Qiangang Jia", "authors": "Qiangang Jia, Zhaoyu Hu, Yiyan Li, Zheng Yan, Sijie Chen", "title": "GenCos' Behaviors Modeling Based on Q Learning Improved by Dichotomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Q learning is widely used to simulate the behaviors of generation companies\n(GenCos) in an electricity market. However, existing Q learning method usually\nrequires numerous iterations to converge, which is time-consuming and\ninefficient in practice. To enhance the calculation efficiency, a novel Q\nlearning algorithm improved by dichotomy is proposed in this paper. This method\nmodifies the update process of the Q table by dichotomizing the state space and\nthe action space step by step. Simulation results in a repeated Cournot game\nshow the effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 13:48:09 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Jia", "Qiangang", ""], ["Hu", "Zhaoyu", ""], ["Li", "Yiyan", ""], ["Yan", "Zheng", ""], ["Chen", "Sijie", ""]]}, {"id": "2008.01540", "submitter": "Vitaly Vanchurin", "authors": "Vitaly Vanchurin", "title": "The world as a neural network", "comments": "23 pages", "journal-ref": "Entropy 2020, 22, 1210", "doi": "10.3390/e22111210", "report-no": null, "categories": "physics.gen-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss a possibility that the entire universe on its most fundamental\nlevel is a neural network. We identify two different types of dynamical degrees\nof freedom: \"trainable\" variables (e.g. bias vector or weight matrix) and\n\"hidden\" variables (e.g. state vector of neurons). We first consider stochastic\nevolution of the trainable variables to argue that near equilibrium their\ndynamics is well approximated by Madelung equations (with free energy\nrepresenting the phase) and further away from the equilibrium by\nHamilton-Jacobi equations (with free energy representing the Hamilton's\nprincipal function). This shows that the trainable variables can indeed exhibit\nclassical and quantum behaviors with the state vector of neurons representing\nthe hidden variables. We then study stochastic evolution of the hidden\nvariables by considering $D$ non-interacting subsystems with average state\nvectors, $\\bar{\\bf x}^{1}$, ..., $\\bar{\\bf x}^{D}$ and an overall average state\nvector $\\bar{\\bf x}^{0}$. In the limit when the weight matrix is a permutation\nmatrix, the dynamics of $\\bar{\\bf x}^{\\mu}$ can be described in terms of\nrelativistic strings in an emergent $D+1$ dimensional Minkowski space-time. If\nthe subsystems are minimally interacting, with interactions described by a\nmetric tensor, then the emergent space-time becomes curved. We argue that the\nentropy production in such a system is a local function of the metric tensor\nwhich should be determined by the symmetries of the Onsager tensor. It turns\nout that a very simple and highly symmetric Onsager tensor leads to the entropy\nproduction described by the Einstein-Hilbert term. This shows that the learning\ndynamics of a neural network can indeed exhibit approximate behaviors described\nby both quantum mechanics and general relativity. We also discuss a possibility\nthat the two descriptions are holographic duals of each other.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 17:10:46 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Vanchurin", "Vitaly", ""]]}, {"id": "2008.01543", "submitter": "Joppe Wouts", "authors": "Joppe Valentijn Wouts", "title": "Text-based classification of interviews for mental health -- juxtaposing\n  the state of the art", "comments": "33 pages, 7 figures, belabBERT is available on\n  http://github.com/Joppewouts/belabBERT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, the state of the art for classification of psychiatric illness is\nbased on audio-based classification. This thesis aims to design and evaluate a\nstate of the art text classification network on this challenge. The hypothesis\nis that a well designed text-based approach poses a strong competition against\nthe state-of-the-art audio based approaches. Dutch natural language models are\nbeing limited by the scarcity of pre-trained monolingual NLP models, as a\nresult Dutch natural language models have a low capture of long range semantic\ndependencies over sentences. For this issue, this thesis presents belabBERT, a\nnew Dutch language model extending the RoBERTa[15] architecture. belabBERT is\ntrained on a large Dutch corpus (+32GB) of web crawled texts. After this thesis\nevaluates the strength of text-based classification, a brief exploration is\ndone, extending the framework to a hybrid text- and audio-based classification.\nThe goal of this hybrid framework is to show the principle of hybridisation\nwith a very basic audio-classification network. The overall goal is to create\nthe foundations for a hybrid psychiatric illness classification, by proving\nthat the new text-based classification is already a strong stand-alone\nsolution.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 16:19:30 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Wouts", "Joppe Valentijn", ""]]}, {"id": "2008.01544", "submitter": "Manoel Verissimo Dos Santos Neto Mvst", "authors": "Manoel Ver\\'issimo dos Santos Neto, Ayrton Denner da Silva Amaral,\n  N\\'adia F\\'elix Felipe da Silva, Anderson da Silva Soares", "title": "Deep Learning Brasil -- NLP at SemEval-2020 Task 9: Overview of\n  Sentiment Analysis of Code-Mixed Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a methodology to predict sentiment in code-mixed\ntweets (hindi-english). Our team called verissimo.manoel in CodaLab developed\nan approach based on an ensemble of four models (MultiFiT, BERT, ALBERT, and\nXLNET). The final classification algorithm was an ensemble of some predictions\nof all softmax values from these four models. This architecture was used and\nevaluated in the context of the SemEval 2020 challenge (task 9), and our system\ngot 72.7% on the F1 score.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 16:42:41 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Neto", "Manoel Ver\u00edssimo dos Santos", ""], ["Amaral", "Ayrton Denner da Silva", ""], ["da Silva", "N\u00e1dia F\u00e9lix Felipe", ""], ["Soares", "Anderson da Silva", ""]]}, {"id": "2008.01547", "submitter": "Shuai Zhang", "authors": "Shuai Zhang, Peng Zhang, Xindian Ma, Junqiu Wei, Ningning Wang, Qun\n  Liu", "title": "TensorCoder: Dimension-Wise Attention via Tensor Representation for\n  Natural Language Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer has been widely-used in many Natural Language Processing (NLP)\ntasks and the scaled dot-product attention between tokens is a core module of\nTransformer. This attention is a token-wise design and its complexity is\nquadratic to the length of sequence, limiting its application potential for\nlong sequence tasks. In this paper, we propose a dimension-wise attention\nmechanism based on which a novel language modeling approach (namely\nTensorCoder) can be developed. The dimension-wise attention can reduce the\nattention complexity from the original $O(N^2d)$ to $O(Nd^2)$, where $N$ is the\nlength of the sequence and $d$ is the dimensionality of head. We verify\nTensorCoder on two tasks including masked language modeling and neural machine\ntranslation. Compared with the original Transformer, TensorCoder not only\ngreatly reduces the calculation of the original model but also obtains improved\nperformance on masked language modeling task (in PTB dataset) and comparable\nperformance on machine translation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 13:42:02 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 11:25:49 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Zhang", "Shuai", ""], ["Zhang", "Peng", ""], ["Ma", "Xindian", ""], ["Wei", "Junqiu", ""], ["Wang", "Ningning", ""], ["Liu", "Qun", ""]]}, {"id": "2008.01548", "submitter": "Catherine Yeo", "authors": "Catherine Yeo and Alyssa Chen", "title": "Defining and Evaluating Fair Natural Language Generation", "comments": "7 pages, 2 figures, to be published in Proceedings of the The Fourth\n  Widening Natural Language Processing Workshop at ACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our work focuses on the biases that emerge in the natural language generation\n(NLG) task of sentence completion. In this paper, we introduce a framework of\nfairness for NLG followed by an evaluation of gender biases in two\nstate-of-the-art language models. Our analysis provides a theoretical\nformulation for biases in NLG and empirical evidence that existing language\ngeneration models embed gender bias.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 04:11:10 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Yeo", "Catherine", ""], ["Chen", "Alyssa", ""]]}, {"id": "2008.01551", "submitter": "Jekaterina Novikova Dr.", "authors": "Aparna Balagopalan, Benjamin Eyre, Frank Rudzicz, Jekaterina Novikova", "title": "To BERT or Not To BERT: Comparing Speech and Language-based Approaches\n  for Alzheimer's Disease Detection", "comments": "accepted to INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research related to automatically detecting Alzheimer's disease (AD) is\nimportant, given the high prevalence of AD and the high cost of traditional\nmethods. Since AD significantly affects the content and acoustics of\nspontaneous speech, natural language processing and machine learning provide\npromising techniques for reliably detecting AD. We compare and contrast the\nperformance of two such approaches for AD detection on the recent ADReSS\nchallenge dataset: 1) using domain knowledge-based hand-crafted features that\ncapture linguistic and acoustic phenomena, and 2) fine-tuning Bidirectional\nEncoder Representations from Transformer (BERT)-based sequence classification\nmodels. We also compare multiple feature-based regression models for a\nneuropsychological score task in the challenge. We observe that fine-tuned BERT\nmodels, given the relative importance of linguistics in cognitive impairment\ndetection, outperform feature-based approaches on the AD detection task.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 04:50:47 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Balagopalan", "Aparna", ""], ["Eyre", "Benjamin", ""], ["Rudzicz", "Frank", ""], ["Novikova", "Jekaterina", ""]]}, {"id": "2008.01553", "submitter": "Mingjin Zhang", "authors": "Lei Yang, Yanyan Lu, Jiannong Cao, Jiaming Huang, Mingjin Zhang", "title": "E-Tree Learning: A Novel Decentralized Model Learning Framework for Edge\n  AI", "comments": "IEEE Internet of Things Journal, 2020", "journal-ref": null, "doi": "10.1109/JIOT.2021.3052195", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, AI models are trained on the central cloud with data collected\nfrom end devices. This leads to high communication cost, long response time and\nprivacy concerns. Recently Edge empowered AI, namely Edge AI, has been proposed\nto support AI model learning and deployment at the network edge closer to the\ndata sources. Existing research including federated learning adopts a\ncentralized architecture for model learning where a central server aggregates\nthe model updates from the clients/workers. The centralized architecture has\ndrawbacks such as performance bottleneck, poor scalability and single point of\nfailure. In this paper, we propose a novel decentralized model learning\napproach, namely E-Tree, which makes use of a well-designed tree structure\nimposed on the edge devices. The tree structure and the locations and orders of\naggregation on the tree are optimally designed to improve the training\nconvergency and model accuracy. In particular, we design an efficient device\nclustering algorithm, named by KMA, for E-Tree by taking into account the data\ndistribution on the devices as well as the the network distance. Evaluation\nresults show E-Tree significantly outperforms the benchmark approaches such as\nfederated learning and Gossip learning under NonIID data in terms of model\naccuracy and convergency.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 13:59:29 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 05:15:24 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Yang", "Lei", ""], ["Lu", "Yanyan", ""], ["Cao", "Jiannong", ""], ["Huang", "Jiaming", ""], ["Zhang", "Mingjin", ""]]}, {"id": "2008.01558", "submitter": "Yanmin Gong", "authors": "Rui Hu and Yanmin Gong and Yuanxiong Guo", "title": "Federated Learning with Sparsification-Amplified Privacy and Adaptive\n  Optimization", "comments": "Accepted in IJCAI 2021, this is the full version with appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) enables distributed agents to collaboratively learn a\ncentralized model without sharing their raw data with each other. However, data\nlocality does not provide sufficient privacy protection, and it is desirable to\nfacilitate FL with rigorous differential privacy (DP) guarantee. Existing DP\nmechanisms would introduce random noise with magnitude proportional to the\nmodel size, which can be quite large in deep neural networks. In this paper, we\npropose a new FL framework with sparsification-amplified privacy. Our approach\nintegrates random sparsification with gradient perturbation on each agent to\namplify privacy guarantee. Since sparsification would increase the number of\ncommunication rounds required to achieve a certain target accuracy, which is\nunfavorable for DP guarantee, we further introduce acceleration techniques to\nhelp reduce the privacy cost. We rigorously analyze the convergence of our\napproach and utilize Renyi DP to tightly account the end-to-end DP guarantee.\nExtensive experiments on benchmark datasets validate that our approach\noutperforms previous differentially-private FL approaches in both privacy\nguarantee and communication efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 20:22:57 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 20:18:08 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Hu", "Rui", ""], ["Gong", "Yanmin", ""], ["Guo", "Yuanxiong", ""]]}, {"id": "2008.01559", "submitter": "Vikram Krishnamurthy", "authors": "Vikram Krishnamurthy and Kunal Pattanayak and Sandeep Gogineni and\n  Bosung Kang and Muralidhar Rangaswamy", "title": "Adversarial Radar Inference: Inverse Tracking, Identifying Cognition and\n  Designing Smart Interference", "comments": "arXiv admin note: substantial text overlap with arXiv:2002.10910", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers three inter-related adversarial inference problems\ninvolving cognitive radars. We first discuss inverse tracking of the radar to\nestimate the adversary's estimate of us based on the radar's actions and\ncalibrate the radar's sensing accuracy. Second, using revealed preference from\nmicroeconomics, we formulate a non-parametric test to identify if the cognitive\nradar is a constrained utility maximizer with signal processing constraints. We\nconsider two radar functionalities, namely, beam allocation and waveform\ndesign, with respect to which the cognitive radar is assumed to maximize its\nutility and construct a set-valued estimator for the radar's utility function.\nFinally, we discuss how to engineer interference at the physical layer level to\nconfuse the radar which forces it to change its transmit waveform. The levels\nof abstraction range from smart interference design based on Wiener filters (at\nthe pulse/waveform level), inverse Kalman filters at the tracking level and\nrevealed preferences for identifying utility maximization at the systems level.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 13:17:07 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 12:10:18 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Krishnamurthy", "Vikram", ""], ["Pattanayak", "Kunal", ""], ["Gogineni", "Sandeep", ""], ["Kang", "Bosung", ""], ["Rangaswamy", "Muralidhar", ""]]}, {"id": "2008.01560", "submitter": "Kostas Kolomvatsos", "authors": "Panagiotis Fountas, Kostas Kolomvatsos, Christos Anagnostopoulos", "title": "Data Synopses Management based on a Deep Learning Model", "comments": "arXiv admin note: substantial text overlap with arXiv:2007.12648", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pervasive computing involves the placement of processing services close to\nend users to support intelligent applications. With the advent of the Internet\nof Things (IoT) and the Edge Computing (EC), one can find room for placing\nservices at various points in the interconnection of the aforementioned\ninfrastructures. Of significant importance is the processing of the collected\ndata. Such a processing can be realized upon the EC nodes that exhibit\nincreased computational capabilities compared to IoT devices. An ecosystem of\nintelligent nodes is created at the EC giving the opportunity to support\ncooperative models. Nodes become the hosts of geo-distributed datasets\nformulated by the IoT devices reports. Upon the datasets, a number of\nqueries/tasks can be executed. Queries/tasks can be offloaded for performance\nreasons. However, an offloading action should be carefully designed being\nalways aligned with the data present to the hosting node. In this paper, we\npresent a model to support the cooperative aspect in the EC infrastructure. We\nargue on the delivery of data synopses to EC nodes making them capable to take\noffloading decisions fully aligned with data present at peers. Nodes exchange\ndata synopses to inform their peers. We propose a scheme that detects the\nappropriate time to distribute synopses trying to avoid the network overloading\nespecially when synopses are frequently extracted due to the high rates at\nwhich IoT devices report data to EC nodes. Our approach involves a Deep\nLearning model for learning the distribution of calculated synopses and\nestimate future trends. Upon these trends, we are able to find the appropriate\ntime to deliver synopses to peer nodes. We provide the description of the\nproposed mechanism and evaluate it based on real datasets. An extensive\nexperimentation upon various scenarios reveals the pros and cons of the\napproach by giving numerical results.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 12:04:21 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Fountas", "Panagiotis", ""], ["Kolomvatsos", "Kostas", ""], ["Anagnostopoulos", "Christos", ""]]}, {"id": "2008.01564", "submitter": "Bruce Lee", "authors": "Bruce W. Lee, Jason Hyung-Jong Lee", "title": "LXPER Index: a curriculum-specific text readability assessment model for\n  EFL students in Korea", "comments": "8 pages, 2 figures, 7 tables", "journal-ref": "International Journal of Advanced Computer Science and\n  Applications, 11(8), 2020", "doi": "10.14569/IJACSA.2020.0110801", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automatic readability assessment is one of the most important applications of\nNatural Language Processing (NLP) in education. Since automatic readability\nassessment allows the fast selection of appropriate reading material for\nreaders at all levels of proficiency, it can be particularly useful for the\nEnglish education of English as Foreign Language (EFL) students around the\nworld. Most readability assessment models are developed for the native readers\nof English and have low accuracy for texts in the non-native English Language\nTraining (ELT) curriculum. We introduce LXPER Index, which is a readability\nassessment model for non-native EFL readers in the ELT curriculum of Korea. Our\nexperiments show that our new model, trained with CoKEC-text (Text Corpus of\nthe Korean ELT Curriculum), significantly improves the accuracy of automatic\nreadability assessment for texts in the Korean ELT curriculum.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 11:55:03 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Lee", "Bruce W.", ""], ["Lee", "Jason Hyung-Jong", ""]]}, {"id": "2008.01566", "submitter": "Md Rafiqul Islam Rabin", "authors": "Md Rafiqul Islam Rabin, Nghi D. Q. Bui, Ke Wang, Yijun Yu, Lingxiao\n  Jiang, Mohammad Amin Alipour", "title": "On the Generalizability of Neural Program Models with respect to\n  Semantic-Preserving Program Transformations", "comments": "Information and Software Technology, IST Journal 2021, Elsevier.\n  arXiv admin note: substantial text overlap with arXiv:2004.07313", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the prevalence of publicly available source code repositories to train\ndeep neural network models, neural program models can do well in source code\nanalysis tasks such as predicting method names in given programs that cannot be\neasily done by traditional program analysis techniques. Although such neural\nprogram models have been tested on various existing datasets, the extent to\nwhich they generalize to unforeseen source code is largely unknown. Since it is\nvery challenging to test neural program models on all unforeseen programs, in\nthis paper, we propose to evaluate the generalizability of neural program\nmodels with respect to semantic-preserving transformations: a generalizable\nneural program model should perform equally well on programs that are of the\nsame semantics but of different lexical appearances and syntactical structures.\nWe compare the results of various neural program models for the method name\nprediction task on programs before and after automated semantic-preserving\ntransformations. We use three Java datasets of different sizes and three\nstate-of-the-art neural network models for code, namely code2vec, code2seq, and\nGGNN, to build nine such neural program models for evaluation. Our results show\nthat even with small semantically preserving changes to the programs, these\nneural program models often fail to generalize their performance. Our results\nalso suggest that neural program models based on data and control dependencies\nin programs generalize better than neural program models based only on abstract\nsyntax trees. On the positive side, we observe that as the size of the training\ndataset grows and diversifies the generalizability of correct predictions\nproduced by the neural program models can be improved too. Our results on the\ngeneralizability of neural program models provide insights to measure their\nlimitations and provide a stepping stone for their improvement.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 20:39:20 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 12:55:45 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 07:35:13 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Rabin", "Md Rafiqul Islam", ""], ["Bui", "Nghi D. Q.", ""], ["Wang", "Ke", ""], ["Yu", "Yijun", ""], ["Jiang", "Lingxiao", ""], ["Alipour", "Mohammad Amin", ""]]}, {"id": "2008.01571", "submitter": "Sabina Tomkins", "authors": "Sabina Tomkins, Peng Liao, Predrag Klasnja and Susan Murphy", "title": "IntelligentPooling: Practical Thompson Sampling for mHealth", "comments": "arXiv admin note: text overlap with arXiv:2002.09971", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mobile health (mHealth) smart devices deliver behavioral treatments\nrepeatedly over time to a user with the goal of helping the user adopt and\nmaintain healthy behaviors. Reinforcement learning appears ideal for learning\nhow to optimally make these sequential treatment decisions. However,\nsignificant challenges must be overcome before reinforcement learning can be\neffectively deployed in a mobile healthcare setting. In this work we are\nconcerned with the following challenges: 1) individuals who are in the same\ncontext can exhibit differential response to treatments 2) only a limited\namount of data is available for learning on any one individual, and 3)\nnon-stationary responses to treatment. To address these challenges we\ngeneralize Thompson-Sampling bandit algorithms to develop IntelligentPooling.\nIntelligentPooling learns personalized treatment policies thus addressing\nchallenge one. To address the second challenge, IntelligentPooling updates each\nuser's degree of personalization while making use of available data on other\nusers to speed up learning. Lastly, IntelligentPooling allows responsivity to\nvary as a function of a user's time since beginning treatment, thus addressing\nchallenge three. We show that IntelligentPooling achieves an average of 26%\nlower regret than state-of-the-art. We demonstrate the promise of this approach\nand its ability to learn from even a small group of users in a live clinical\ntrial.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 19:03:09 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 21:30:05 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Tomkins", "Sabina", ""], ["Liao", "Peng", ""], ["Klasnja", "Predrag", ""], ["Murphy", "Susan", ""]]}, {"id": "2008.01572", "submitter": "Abhishek Dubey", "authors": "Abhishek K Dubey and Alina Peluso and Jacob Hinkle and Devanshu\n  Agarawal and Zilong Tan", "title": "Model Reduction of Shallow CNN Model for Reliable Deployment of\n  Information Extraction from Medical Reports", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shallow Convolution Neural Network (CNN) is a time-tested tool for the\ninformation extraction from cancer pathology reports. Shallow CNN performs\ncompetitively on this task to other deep learning models including BERT, which\nholds the state-of-the-art for many NLP tasks. The main insight behind this\neccentric phenomenon is that the information extraction from cancer pathology\nreports require only a small number of domain-specific text segments to perform\nthe task, thus making the most of the texts and contexts excessive for the\ntask. Shallow CNN model is well-suited to identify these key short text\nsegments from the labeled training set; however, the identified text segments\nremain obscure to humans. In this study, we fill this gap by developing a model\nreduction tool to make a reliable connection between CNN filters and relevant\ntext segments by discarding the spurious connections. We reduce the complexity\nof shallow CNN representation by approximating it with a linear transformation\nof n-gram presence representation with a non-negativity and sparsity prior on\nthe transformation weights to obtain an interpretable model. Our approach\nbridge the gap between the conventionally perceived trade-off boundary between\naccuracy on the one side and explainability on the other by model reduction.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 16:41:08 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Dubey", "Abhishek K", ""], ["Peluso", "Alina", ""], ["Hinkle", "Jacob", ""], ["Agarawal", "Devanshu", ""], ["Tan", "Zilong", ""]]}, {"id": "2008.01593", "submitter": "Junchi Liang", "authors": "Junchi Liang and Abdeslam Boularias", "title": "Learning Transition Models with Time-delayed Causal Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an algorithm for discovering implicit and delayed\ncausal relations between events observed by a robot at arbitrary times, with\nthe objective of improving data-efficiency and interpretability of model-based\nreinforcement learning (RL) techniques. The proposed algorithm initially\npredicts observations with the Markov assumption, and incrementally introduces\nnew hidden variables to explain and reduce the stochasticity of the\nobservations. The hidden variables are memory units that keep track of\npertinent past events. Such events are systematically identified by their\ninformation gains. The learned transition and reward models are then used for\nplanning. Experiments on simulated and real robotic tasks show that this method\nsignificantly improves over current RL techniques.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 14:35:11 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Liang", "Junchi", ""], ["Boularias", "Abdeslam", ""]]}, {"id": "2008.01594", "submitter": "Haresh Karnan", "authors": "Siddharth Desai, Ishan Durugkar, Haresh Karnan, Garrett Warnell,\n  Josiah Hanna, Peter Stone", "title": "An Imitation from Observation Approach to Transfer Learning with\n  Dynamics Mismatch", "comments": null, "journal-ref": "Neural Information Processing Systems (NeurIPS 2020)", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the problem of transferring a policy learned in a source\nenvironment to a target environment with different dynamics, particularly in\nthe case where it is critical to reduce the amount of interaction with the\ntarget environment during learning. This problem is particularly important in\nsim-to-real transfer because simulators inevitably model real-world dynamics\nimperfectly. In this paper, we show that one existing solution to this transfer\nproblem - grounded action transformation - is closely related to the problem of\nimitation from observation (IfO): learning behaviors that mimic the\nobservations of behavior demonstrations. After establishing this relationship,\nwe hypothesize that recent state-of-the-art approaches from the IfO literature\ncan be effectively repurposed for grounded transfer learning.To validate our\nhypothesis we derive a new algorithm - generative adversarial reinforced action\ntransformation (GARAT) - based on adversarial imitation from observation\ntechniques. We run experiments in several domains with mismatched dynamics, and\nfind that agents trained with GARAT achieve higher returns in the target\nenvironment compared to existing black-box transfer methods\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 14:36:02 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 17:47:30 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 22:58:45 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Desai", "Siddharth", ""], ["Durugkar", "Ishan", ""], ["Karnan", "Haresh", ""], ["Warnell", "Garrett", ""], ["Hanna", "Josiah", ""], ["Stone", "Peter", ""]]}, {"id": "2008.01604", "submitter": "Mohammad Amin Nabian", "authors": "Mohammad Amin Nabian, Hadi Meidani", "title": "Adaptive Physics-Informed Neural Networks for Markov-Chain Monte Carlo", "comments": "arXiv admin note: text overlap with arXiv:1806.02957", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the Adaptive Physics-Informed Neural Networks\n(APINNs) for accurate and efficient simulation-free Bayesian parameter\nestimation via Markov-Chain Monte Carlo (MCMC). We specifically focus on a\nclass of parameter estimation problems for which computing the likelihood\nfunction requires solving a PDE. The proposed method consists of: (1)\nconstructing an offline PINN-UQ model as an approximation to the forward model;\nand (2) refining this approximate model on the fly using samples generated from\nthe MCMC sampler. The proposed APINN method constantly refines this approximate\nmodel on the fly and guarantees that the approximation error is always less\nthan a user-defined residual error threshold. We numerically demonstrate the\nperformance of the proposed APINN method in solving a parameter estimation\nproblem for a system governed by the Poisson equation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 15:25:10 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Nabian", "Mohammad Amin", ""], ["Meidani", "Hadi", ""]]}, {"id": "2008.01613", "submitter": "Haotian Li", "authors": "Haotian Li, Huan Wei, Yong Wang, Yangqiu Song, Huamin Qu", "title": "Peer-inspired Student Performance Prediction in Interactive Online\n  Question Pools with Graph Neural Network", "comments": "8 pages, 8 figures. Accepted at CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3412733", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Student performance prediction is critical to online education. It can\nbenefit many downstream tasks on online learning platforms, such as estimating\ndropout rates, facilitating strategic intervention, and enabling adaptive\nonline learning. Interactive online question pools provide students with\ninteresting interactive questions to practice their knowledge in online\neducation. However, little research has been done on student performance\nprediction in interactive online question pools. Existing work on student\nperformance prediction targets at online learning platforms with predefined\ncourse curriculum and accurate knowledge labels like MOOC platforms, but they\nare not able to fully model knowledge evolution of students in interactive\nonline question pools. In this paper, we propose a novel approach using Graph\nNeural Networks (GNNs) to achieve better student performance prediction in\ninteractive online question pools. Specifically, we model the relationship\nbetween students and questions using student interactions to construct the\nstudent-interaction-question network and further present a new GNN model,\ncalled R^2GCN, which intrinsically works for the heterogeneous networks, to\nachieve generalizable student performance prediction in interactive online\nquestion pools. We evaluate the effectiveness of our approach on a real-world\ndataset consisting of 104,113 mouse trajectories generated in the\nproblem-solving process of over 4000 students on 1631 questions. The experiment\nresults show that our approach can achieve a much higher accuracy of student\nperformance prediction than both traditional machine learning approaches and\nGNN models.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 14:55:32 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 07:47:01 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Li", "Haotian", ""], ["Wei", "Huan", ""], ["Wang", "Yong", ""], ["Song", "Yangqiu", ""], ["Qu", "Huamin", ""]]}, {"id": "2008.01615", "submitter": "Hamid Usefi", "authors": "Hanieh Marvi Khorasani, Hamid Usefi, and Lourdes Pe\\~na-Castillo", "title": "Detecting ulcerative colitis from colon samples using efficient feature\n  selection and machine learning", "comments": "Scientific Reports, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ulcerative colitis (UC) is one of the most common forms of inflammatory bowel\ndisease (IBD) characterized by inflammation of the mucosal layer of the colon.\nDiagnosis of UC is based on clinical symptoms, and then confirmed based on\nendoscopic, histologic and laboratory findings. Feature selection and machine\nlearning have been previously used for creating models to facilitate the\ndiagnosis of certain diseases. In this work, we used a recently developed\nfeature selection algorithm (DRPT) combined with a support vector machine (SVM)\nclassifier to generate a model to discriminate between healthy subjects and\nsubjects with UC based on the expression values of 32 genes in colon samples.\nWe validated our model with an independent gene expression dataset of colonic\nsamples from subjects in active and inactive periods of UC. Our model perfectly\ndetected all active cases and had an average precision of 0.62 in the inactive\ncases. Compared with results reported in previous studies and a model generated\nby a recently published software for biomarker discovery using machine learning\n(BioDiscML), our final model for detecting UC shows better performance in terms\nof average precision.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 14:56:45 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Khorasani", "Hanieh Marvi", ""], ["Usefi", "Hamid", ""], ["Pe\u00f1a-Castillo", "Lourdes", ""]]}, {"id": "2008.01641", "submitter": "Alexander Harri Bell-Thomas", "authors": "A. H. Bell-Thomas", "title": "Exploring Variational Deep Q Networks", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study provides both analysis and a refined, research-ready\nimplementation of Tang and Kucukelbir's Variational Deep Q Network, a novel\napproach to maximising the efficiency of exploration in complex learning\nenvironments using Variational Bayesian Inference. Alongside reference\nimplementations of both Traditional and Double Deep Q Networks, a small novel\ncontribution is presented - the Double Variational Deep Q Network, which\nincorporates improvements to increase the stability and robustness of\ninference-based learning. Finally, an evaluation and discussion of the\neffectiveness of these approaches is discussed in the wider context of Bayesian\nDeep Learning.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 15:36:31 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Bell-Thomas", "A. H.", ""]]}, {"id": "2008.01644", "submitter": "Mark Gluzman", "authors": "J. G. Dai and Mark Gluzman", "title": "Queueing Network Controls via Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel advanced policy gradient (APG) methods, such as Trust Region policy\noptimization and Proximal policy optimization (PPO), have become the dominant\nreinforcement learning algorithms because of their ease of implementation and\ngood practical performance. A conventional setup for notoriously difficult\nqueueing network control problems is a Markov decision problem (MDP) that has\nthree features: infinite state space, unbounded costs, and long-run average\ncost objective. We extend the theoretical framework of these APG methods for\nsuch MDP problems. The resulting PPO algorithm is tested on a parallel-server\nsystem and large-size multiclass queueing networks. The algorithm consistently\ngenerates control policies that outperform state-of-art heuristics in\nliterature in a variety of load conditions from light to heavy traffic. These\npolicies are demonstrated to be near-optimal when the optimal policy can be\ncomputed.\n  A key to the successes of our PPO algorithm is the use of three variance\nreduction techniques in estimating the relative value function via sampling.\nFirst, we use a discounted relative value function as an approximation of the\nrelative value function. Second, we propose regenerative simulation to estimate\nthe discounted relative value function. Finally, we incorporate the\napproximating martingale-process method into the regenerative estimator.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 01:02:57 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 01:32:14 GMT"}, {"version": "v3", "created": "Sun, 23 Aug 2020 15:50:32 GMT"}, {"version": "v4", "created": "Thu, 27 Aug 2020 16:36:27 GMT"}, {"version": "v5", "created": "Thu, 24 Sep 2020 21:38:21 GMT"}, {"version": "v6", "created": "Wed, 28 Apr 2021 21:42:53 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Dai", "J. G.", ""], ["Gluzman", "Mark", ""]]}, {"id": "2008.01645", "submitter": "Takanori Fujiwara", "authors": "Takanori Fujiwara, Shilpika, Naohisa Sakamoto, Jorji Nonaka, Keiji\n  Yamamoto, and Kwan-Liu Ma", "title": "A Visual Analytics Framework for Reviewing Multivariate Time-Series Data\n  with Dimensionality Reduction", "comments": "To appear in IEEE Transactions on Visualization and Computer Graphics\n  and IEEE VIS 2020 (VAST)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven problem solving in many real-world applications involves analysis\nof time-dependent multivariate data, for which dimensionality reduction (DR)\nmethods are often used to uncover the intrinsic structure and features of the\ndata. However, DR is usually applied to a subset of data that is either\nsingle-time-point multivariate or univariate time-series, resulting in the need\nto manually examine and correlate the DR results out of different data subsets.\nWhen the number of dimensions is large either in terms of the number of time\npoints or attributes, this manual task becomes too tedious and infeasible. In\nthis paper, we present MulTiDR, a new DR framework that enables processing of\ntime-dependent multivariate data as a whole to provide a comprehensive overview\nof the data. With the framework, we employ DR in two steps. When treating the\ninstances, time points, and attributes of the data as a 3D array, the first DR\nstep reduces the three axes of the array to two, and the second DR step\nvisualizes the data in a lower-dimensional space. In addition, by coupling with\na contrastive learning method and interactive visualizations, our framework\nenhances analysts' ability to interpret DR results. We demonstrate the\neffectiveness of our framework with four case studies using real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 04:22:43 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 00:37:25 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Fujiwara", "Takanori", ""], ["Shilpika", "", ""], ["Sakamoto", "Naohisa", ""], ["Nonaka", "Jorji", ""], ["Yamamoto", "Keiji", ""], ["Ma", "Kwan-Liu", ""]]}, {"id": "2008.01659", "submitter": "Alireza Abedin", "authors": "Alireza Abedin, Farbod Motlagh, Qinfeng Shi, Seyed Hamid Rezatofighi,\n  Damith Chinthana Ranasinghe", "title": "Towards Deep Clustering of Human Activities from Wearables", "comments": "Accepted at ISWC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our ability to exploit low-cost wearable sensing modalities for critical\nhuman behaviour and activity monitoring applications in health and wellness is\nreliant on supervised learning regimes; here, deep learning paradigms have\nproven extremely successful in learning activity representations from annotated\ndata. However, the costly work of gathering and annotating sensory activity\ndatasets is labor-intensive, time consuming and not scalable to large volumes\nof data. While existing unsupervised remedies of deep clustering leverage\nnetwork architectures and optimization objectives that are tailored for static\nimage datasets, deep architectures to uncover cluster structures from raw\nsequence data captured by on-body sensors remains largely unexplored. In this\npaper, we develop an unsupervised end-to-end learning strategy for the\nfundamental problem of human activity recognition (HAR) from wearables. Through\nextensive experiments, including comparisons with existing methods, we show the\neffectiveness of our approach to jointly learn unsupervised representations for\nsensory data and generate cluster assignments with strong semantic\ncorrespondence to distinct human activities.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 13:55:24 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 05:35:27 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Abedin", "Alireza", ""], ["Motlagh", "Farbod", ""], ["Shi", "Qinfeng", ""], ["Rezatofighi", "Seyed Hamid", ""], ["Ranasinghe", "Damith Chinthana", ""]]}, {"id": "2008.01663", "submitter": "Inaam Ilahi", "authors": "Inaam Ilahi, Hafiz Muhammad Abdullah Zia, Muhammad Ahtazaz Ahsan, Rauf\n  Tabassam, Armaghan Ahmed", "title": "Efficient Urdu Caption Generation using Attention based LSTM", "comments": "This a project report of Deep Learning subject taught at Information\n  Technology University, Lahore, Pakistan by Dr. Mohsen Ali", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advancements in deep learning have created many opportunities to solve\nreal-world problems that remained unsolved for more than a decade. Automatic\ncaption generation is a major research field, and the research community has\ndone a lot of work on it in most common languages like English. Urdu is the\nnational language of Pakistan and also much spoken and understood in the\nsub-continent region of Pakistan-India, and yet no work has been done for Urdu\nlanguage caption generation. Our research aims to fill this gap by developing\nan attention-based deep learning model using techniques of sequence modeling\nspecialized for the Urdu language. We have prepared a dataset in the Urdu\nlanguage by translating a subset of the \"Flickr8k\" dataset containing 700 'man'\nimages. We evaluate our proposed technique on this dataset and show that it can\nachieve a BLEU score of 0.83 in the Urdu language. We improve on the previous\nstate-of-the-art by using better CNN architectures and optimization techniques.\nFurthermore, we provide a discussion on how the generated captions can be made\ncorrect grammar-wise.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 17:22:33 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 09:32:28 GMT"}, {"version": "v3", "created": "Tue, 4 May 2021 11:01:09 GMT"}, {"version": "v4", "created": "Sat, 19 Jun 2021 15:31:55 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Ilahi", "Inaam", ""], ["Zia", "Hafiz Muhammad Abdullah", ""], ["Ahsan", "Muhammad Ahtazaz", ""], ["Tabassam", "Rauf", ""], ["Ahmed", "Armaghan", ""]]}, {"id": "2008.01664", "submitter": "Alastair Flynn Mr", "authors": "Alastair Flynn", "title": "Inducing game rules from varying quality game play", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  General Game Playing (GGP) is a framework in which an artificial intelligence\nprogram is required to play a variety of games successfully. It acts as a test\nbed for AI and motivator of research. The AI is given a random game description\nat runtime which it then plays. The framework includes repositories of game\nrules. The Inductive General Game Playing (IGGP) problem challenges machine\nlearning systems to learn these GGP game rules by watching the game being\nplayed. In other words, IGGP is the problem of inducing general game rules from\nspecific game observations. Inductive Logic Programming (ILP) has shown to be a\npromising approach to this problem though it has been demonstrated that it is\nstill a hard problem for ILP systems. Existing work on IGGP has always assumed\nthat the game player being observed makes random moves. This is not\nrepresentative of how a human learns to play a game. With random gameplay\nsituations that would normally be encountered when humans play are not present.\nTo address this limitation, we analyse the effect of using intelligent versus\nrandom gameplay traces as well as the effect of varying the number of traces in\nthe training set. We use Sancho, the 2014 GGP competition winner, to generate\nintelligent game traces for a large number of games. We then use the ILP\nsystems, Metagol, Aleph and ILASP to induce game rules from the traces. We\ntrain and test the systems on combinations of intelligent and random data\nincluding a mixture of both. We also vary the volume of training data. Our\nresults show that whilst some games were learned more effectively in some of\nthe experiments than others no overall trend was statistically significant. The\nimplications of this work are that varying the quality of training data as\ndescribed in this paper has strong effects on the accuracy of the learned game\nrules; however one solution does not work for all games.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 15:46:57 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Flynn", "Alastair", ""]]}, {"id": "2008.01670", "submitter": "Zhongfang Zhuang", "authors": "Zhongfang Zhuang, Chin-Chia Michael Yeh, Liang Wang, Wei Zhang,\n  Junpeng Wang", "title": "Multi-stream RNN for Merchant Transaction Prediction", "comments": "Accepted by KDD 2020 Workshop on Machine Learning in Finance", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, digital payment systems have significantly changed people's\nlifestyles. New challenges have surfaced in monitoring and guaranteeing the\nintegrity of payment processing systems. One important task is to predict the\nfuture transaction statistics of each merchant. These predictions can thus be\nused to steer other tasks, ranging from fraud detection to recommendation. This\nproblem is challenging as we need to predict not only multivariate time series\nbut also multi-steps into the future. In this work, we propose a multi-stream\nRNN model for multi-step merchant transaction predictions tailored to these\nrequirements. The proposed multi-stream RNN summarizes transaction data in\ndifferent granularity and makes predictions for multiple steps in the future.\nOur extensive experimental results have demonstrated that the proposed model is\ncapable of outperforming existing state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 01:20:48 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Zhuang", "Zhongfang", ""], ["Yeh", "Chin-Chia Michael", ""], ["Wang", "Liang", ""], ["Zhang", "Wei", ""], ["Wang", "Junpeng", ""]]}, {"id": "2008.01674", "submitter": "Janak Parmar", "authors": "Janak Parmar, Pritikana Das, Sanjaykumar Dave", "title": "A Machine Learning Approach for Modelling Parking Duration in Urban\n  Land-use", "comments": null, "journal-ref": "Physica A: Statistical Mechanics and its Applications, 2021", "doi": "10.1016/j.physa.2021.125873", "report-no": null, "categories": "stat.ML cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parking is an inevitable issue in the fast-growing developing countries.\nIncreasing number of vehicles require more and more urban land to be allocated\nfor parking. However, a little attention has been conferred to the parking\nissues in developing countries like India. This study proposes a model for\nanalysing the influence of car users' socioeconomic and travel characteristics\non parking duration. Specifically, artificial neural networks (ANNs) is\ndeployed to capture the interrelationship between driver characteristics and\nparking duration. ANNs are highly efficient in learning and recognizing\nconnections between parameters for best prediction of an outcome. Since,\nutility of ANNs has been critically limited due to its Black Box nature, the\nstudy involves the use of Garson algorithm and Local interpretable\nmodel-agnostic explanations (LIME) for model interpretations. LIME shows the\nprediction for any classification, by approximating it locally with the\ndeveloped interpretable model. This study is based on microdata collected\non-site through interview surveys considering two land-uses: office-business\nand market/shopping. Results revealed the higher probability of prediction\nthrough LIME and therefore, the methodology can be adopted ubiquitously.\nFurther, the policy implications are discussed based on the results for both\nland-uses. This unique study could lead to enhanced parking policy and\nmanagement to achieve the sustainability goals.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 16:05:59 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Parmar", "Janak", ""], ["Das", "Pritikana", ""], ["Dave", "Sanjaykumar", ""]]}, {"id": "2008.01677", "submitter": "Binhui Xie", "authors": "Shuang Li, Binhui Xie, Jiashu Wu, Ying Zhao, Chi Harold Liu, Zhengming\n  Ding", "title": "Simultaneous Semantic Alignment Network for Heterogeneous Domain\n  Adaptation", "comments": "Accepted at ACM MM 2020", "journal-ref": null, "doi": "10.1145/3394171.3413995", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous domain adaptation (HDA) transfers knowledge across source and\ntarget domains that present heterogeneities e.g., distinct domain distributions\nand difference in feature type or dimension. Most previous HDA methods tackle\nthis problem through learning a domain-invariant feature subspace to reduce the\ndiscrepancy between domains. However, the intrinsic semantic properties\ncontained in data are under-explored in such alignment strategy, which is also\nindispensable to achieve promising adaptability. In this paper, we propose a\nSimultaneous Semantic Alignment Network (SSAN) to simultaneously exploit\ncorrelations among categories and align the centroids for each category across\ndomains. In particular, we propose an implicit semantic correlation loss to\ntransfer the correlation knowledge of source categorical prediction\ndistributions to target domain. Meanwhile, by leveraging target pseudo-labels,\na robust triplet-centroid alignment mechanism is explicitly applied to align\nfeature representations for each category. Notably, a pseudo-label refinement\nprocedure with geometric similarity involved is introduced to enhance the\ntarget pseudo-label assignment accuracy. Comprehensive experiments on various\nHDA tasks across text-to-image, image-to-image and text-to-text successfully\nvalidate the superiority of our SSAN against state-of-the-art HDA methods. The\ncode is publicly available at https://github.com/BIT-DA/SSAN.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 16:20:37 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 03:04:20 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Li", "Shuang", ""], ["Xie", "Binhui", ""], ["Wu", "Jiashu", ""], ["Zhao", "Ying", ""], ["Liu", "Chi Harold", ""], ["Ding", "Zhengming", ""]]}, {"id": "2008.01679", "submitter": "Junqi Zhao", "authors": "Junqi Zhao and Esther Obonyo", "title": "Applying Incremental Deep Neural Networks-based Posture Recognition\n  Model for Injury Risk Assessment in Construction", "comments": "27 pages, journal manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring awkward postures is a proactive prevention for Musculoskeletal\nDisorders (MSDs)in construction. Machine Learning (ML) models have shown\npromising results for posture recognition from Wearable Sensors. However,\nfurther investigations are needed concerning: i) Incremental Learning (IL),\nwhere trained models adapt to learn new postures and control the forgetting of\nlearned postures; ii) MSDs assessment with recognized postures. This study\nproposed an incremental Convolutional Long Short-Term Memory (CLN) model,\ninvestigated effective IL strategies, and evaluated MSDs assessment using\nrecognized postures. Tests with nine workers showed the CLN model with shallow\nconvolutional layers achieved high recognition performance (F1 Score) under\npersonalized (0.87) and generalized (0.84) modeling. Generalized shallow CLN\nmodel under Many-to-One IL scheme can balance the adaptation (0.73) and\nforgetting of learnt subjects (0.74). MSDs assessment using postures recognized\nfrom incremental CLN model had minor difference with ground-truth, which\ndemonstrates the high potential for automated MSDs monitoring in construction.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 16:27:25 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Zhao", "Junqi", ""], ["Obonyo", "Esther", ""]]}, {"id": "2008.01683", "submitter": "Marco Scutari", "authors": "Laura Azzimonti, Giorgio Corani and Marco Scutari", "title": "A Bayesian Hierarchical Score for Structure Learning from Related Data\n  Sets", "comments": null, "journal-ref": "Proceedings of Machine Learning Research (138, PGM 2020), 5-16", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Score functions for learning the structure of Bayesian networks in the\nliterature assume that data are a homogeneous set of observations; whereas it\nis often the case that they comprise different related, but not homogeneous,\ndata sets collected in different ways. In this paper we propose a new Bayesian\nDirichlet score, which we call Bayesian Hierarchical Dirichlet (BHD). The\nproposed score is based on a hierarchical model that pools information across\ndata sets to learn a single encompassing network structure, while taking into\naccount the differences in their probabilistic structures. We derive a\nclosed-form expression for BHD using a variational approximation of the\nmarginal likelihood, we study the associated computational cost and we evaluate\nits performance using simulated data. We find that, when data comprise multiple\nrelated data sets, BHD outperforms the Bayesian Dirichlet equivalent uniform\n(BDeu) score in terms of reconstruction accuracy as measured by the Structural\nHamming distance, and that it is as accurate as BDeu when data are homogeneous.\nThis improvement is particularly clear when either the number of variables in\nthe network or the number of observations is large. Moreover, the estimated\nnetworks are sparser and therefore more interpretable than those obtained with\nBDeu thanks to a lower number of false positive arcs.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 16:41:05 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 16:25:21 GMT"}, {"version": "v3", "created": "Sat, 17 Jul 2021 16:32:29 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Azzimonti", "Laura", ""], ["Corani", "Giorgio", ""], ["Scutari", "Marco", ""]]}, {"id": "2008.01684", "submitter": "Christian B\\\"ohm", "authors": "Christian B\\\"ohm", "title": "Space-filling Curves for High-performance Data Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Space-filling curves like the Hilbert-curve, Peano-curve and Z-order map\nnatural or real numbers from a two or higher dimensional space to a one\ndimensional space preserving locality. They have numerous applications like\nsearch structures, computer graphics, numerical simulation, cryptographics and\ncan be used to make various algorithms cache-oblivious. In this paper, we\ndescribe some details of the Hilbert-curve. We define the Hilbert-curve in\nterms of a finite automaton of Mealy-type which determines from the\ntwo-dimensional coordinate space the Hilbert order value and vice versa in a\nlogarithmic number of steps. And we define a context-free grammar to generate\nthe whole curve in a time which is linear in the number of generated\ncoordinate/order value pairs, i.e. a constant time per coordinate pair or order\nvalue. We also review two different strategies which enable the generation of\ncurves without the usual restriction to square-like grids where the side-length\nis a power of two. Finally, we elaborate on a few applications, namely matrix\nmultiplication, Cholesky decomposition, the Floyd-Warshall algorithm, k-Means\nclustering, and the similarity join.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 16:41:16 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["B\u00f6hm", "Christian", ""]]}, {"id": "2008.01686", "submitter": "Assaf Ben-Yishai", "authors": "Assaf Ben-Yishai and Ofer Shayevitz", "title": "Simple Modulo can Significantly Outperform Deep Learning-based Deepcode", "comments": "Technical Report, 4 Pages, 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deepcode (H.Kim et al.2018) is a recently suggested Deep Learning-based\nscheme for communication over the AWGN channel with noisy feedback, claimed to\nbe superior to all previous schemes in the literature. Deepcode's use of\nnonlinear coding (via Deep Learning) has been inspired by known shortcomings\n(Y.-H. Kim et al 2007) of linear feedback schemes. In 2014, we presented a\nnonlinear feedback coding scheme based on a combination of the classical SK\nscheme and modulo-arithmetic, using a small number of elementary operations\nwithout any type of neural network. This Modulo-SK scheme has been omitted from\nthe performance comparisons made in the Deepcode paper, due to its use of\ncommon randomness (dither), and in a later version since it was incorrectly\ninterpreted as a variable-length coding scheme. However, the dither in\nModulo-SK was used only for the standard purpose of tractable performance\nanalysis, and is not required in practice. In this short note, we show that a\nfully-deterministic Modulo-SK (without dithering) can outperform Deepcode. For\nexample, to attain an error probability of 10^(-4) at rate 1/3 Modulo-SK\nrequires 3dB less feedback SNR than Deepcode. To attain an error probability of\n10^(-6) with noiseless feedback, Deepcode requires 150 rounds of communication,\nwhereas Modulo-SK requires only 15 rounds, even if the feedback is noisy (with\n27dB SNR).\n  We further address the numerical stability issues of the original SK scheme\nreported in the Deepcode paper, and explain how they can be avoided. We augment\nthis report with an online-available, fully-functional Matlab simulation for\nboth the classical and Modulo-SK schemes. Finally, note that Modulo-SK is by no\nmeans claimed to be the best possible solution; in particular, using deep\nlearning in conjunction with modulo-arithmetic might lead to better designs,\nand remains a fascinating direction for future research.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 16:43:26 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 16:58:35 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Ben-Yishai", "Assaf", ""], ["Shayevitz", "Ofer", ""]]}, {"id": "2008.01705", "submitter": "Mohammad Ghadir Khoshkholgh Dashtaki", "authors": "Mohammad G. Khoshkholgh and Halim Yanikomeroglu", "title": "Faded-Experience Trust Region Policy Optimization for Model-Free Power\n  Allocation in Interference Channel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient reinforcement learning techniques enable an agent to directly\nlearn an optimal action policy through the interactions with the environment.\nNevertheless, despite its advantages, it sometimes suffers from slow\nconvergence speed. Inspired by human decision making approach, we work toward\nenhancing its convergence speed by augmenting the agent to memorize and use the\nrecently learned policies. We apply our method to the trust-region policy\noptimization (TRPO), primarily developed for locomotion tasks, and propose\nfaded-experience (FE) TRPO. To substantiate its effectiveness, we adopt it to\nlearn continuous power control in an interference channel when only noisy\nlocation information of devices is available. Results indicate that with\nFE-TRPO it is possible to almost double the learning speed compared to TRPO.\nImportantly, our method neither increases the learning complexity nor imposes\nperformance loss.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 17:12:29 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Khoshkholgh", "Mohammad G.", ""], ["Yanikomeroglu", "Halim", ""]]}, {"id": "2008.01710", "submitter": "Saba Ahmadi", "authors": "Saba Ahmadi, Hedyeh Beyhaghi, Avrim Blum, Keziah Naggita", "title": "The Strategic Perceptron", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical Perceptron algorithm provides a simple and elegant procedure\nfor learning a linear classifier. In each step, the algorithm observes the\nsample's position and label and updates the current predictor accordingly if it\nmakes a mistake. However, in presence of strategic agents that desire to be\nclassified as positive and that are able to modify their position by a limited\namount, the classifier may not be able to observe the true position of agents\nbut rather a position where the agent pretends to be. Unlike the original\nsetting with perfect knowledge of positions, in this situation the Perceptron\nalgorithm fails to achieve its guarantees, and we illustrate examples with the\npredictor oscillating between two solutions forever, making an unbounded number\nof mistakes even though a perfect large-margin linear classifier exists. Our\nmain contribution is providing a modified Perceptron-style algorithm which\nmakes a bounded number of mistakes in presence of strategic agents with both\n$\\ell_2$ and weighted $\\ell_1$ manipulation costs. In our baseline model,\nknowledge of the manipulation costs (i.e., the extent to which an agent may\nmanipulate) is assumed. In our most general model, we relax this assumption and\nprovide an algorithm which learns and refines both the classifier and its cost\nestimates to achieve good mistake bounds even when manipulation costs are\nunknown.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 17:20:24 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 21:50:17 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Ahmadi", "Saba", ""], ["Beyhaghi", "Hedyeh", ""], ["Blum", "Avrim", ""], ["Naggita", "Keziah", ""]]}, {"id": "2008.01712", "submitter": "Gabriel Kalweit", "authors": "Gabriel Kalweit, Maria Huegle, Moritz Werling, Joschka Boedecker", "title": "Deep Inverse Q-learning with Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular Maximum Entropy Inverse Reinforcement Learning approaches require the\ncomputation of expected state visitation frequencies for the optimal policy\nunder an estimate of the reward function. This usually requires intermediate\nvalue estimation in the inner loop of the algorithm, slowing down convergence\nconsiderably. In this work, we introduce a novel class of algorithms that only\nneeds to solve the MDP underlying the demonstrated behavior once to recover the\nexpert policy. This is possible through a formulation that exploits a\nprobabilistic behavior assumption for the demonstrations within the structure\nof Q-learning. We propose Inverse Action-value Iteration which is able to fully\nrecover an underlying reward of an external agent in closed-form analytically.\nWe further provide an accompanying class of sampling-based variants which do\nnot depend on a model of the environment. We show how to extend this class of\nalgorithms to continuous state-spaces via function approximation and how to\nestimate a corresponding action-value function, leading to a policy as close as\npossible to the policy of the external agent, while optionally satisfying a\nlist of predefined hard constraints. We evaluate the resulting algorithms\ncalled Inverse Action-value Iteration, Inverse Q-learning and Deep Inverse\nQ-learning on the Objectworld benchmark, showing a speedup of up to several\norders of magnitude compared to (Deep) Max-Entropy algorithms. We further apply\nDeep Constrained Inverse Q-learning on the task of learning autonomous\nlane-changes in the open-source simulator SUMO achieving competent driving\nafter training on data corresponding to 30 minutes of demonstrations.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 17:21:51 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Kalweit", "Gabriel", ""], ["Huegle", "Maria", ""], ["Werling", "Moritz", ""], ["Boedecker", "Joschka", ""]]}, {"id": "2008.01722", "submitter": "Kevin Tian", "authors": "Jerry Li, Aaron Sidford, Kevin Tian, Huishuai Zhang", "title": "Well-Conditioned Methods for Ill-Conditioned Systems: Linear Regression\n  with Semi-Random Noise", "comments": "31 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical iterative algorithms for linear system solving and regression are\nbrittle to the condition number of the data matrix. Even a semi-random\nadversary, constrained to only give additional consistent information, can\narbitrarily hinder the resulting computational guarantees of existing solvers.\nWe show how to overcome this barrier by developing a framework which takes\nstate-of-the-art solvers and \"robustifies\" them to achieve comparable\nguarantees against a semi-random adversary. Given a matrix which contains an\n(unknown) well-conditioned submatrix, our methods obtain computational and\nstatistical guarantees as if the entire matrix was well-conditioned. We\ncomplement our theoretical results with preliminary experimental evidence,\nshowing that our methods are effective in practice.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 17:53:28 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Li", "Jerry", ""], ["Sidford", "Aaron", ""], ["Tian", "Kevin", ""], ["Zhang", "Huishuai", ""]]}, {"id": "2008.01724", "submitter": "Bingyan Wang", "authors": "Yuxin Chen, Jianqing Fan, Bingyan Wang, Yuling Yan", "title": "Convex and Nonconvex Optimization Are Both Minimax-Optimal for Noisy\n  Blind Deconvolution under Random Designs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the effectiveness of convex relaxation and nonconvex\noptimization in solving bilinear systems of equations under two different\ndesigns (i.e.$~$a sort of random Fourier design and Gaussian design). Despite\nthe wide applicability, the theoretical understanding about these two paradigms\nremains largely inadequate in the presence of random noise. The current paper\nmakes two contributions by demonstrating that: (1) a two-stage nonconvex\nalgorithm attains minimax-optimal accuracy within a logarithmic number of\niterations. (2) convex relaxation also achieves minimax-optimal statistical\naccuracy vis-\\`a-vis random noise. Both results significantly improve upon the\nstate-of-the-art theoretical guarantees.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 17:57:02 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 01:56:10 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Chen", "Yuxin", ""], ["Fan", "Jianqing", ""], ["Wang", "Bingyan", ""], ["Yan", "Yuling", ""]]}, {"id": "2008.01761", "submitter": "Siddhant Garg", "authors": "Siddhant Garg, Adarsh Kumar, Vibhor Goel, Yingyu Liang", "title": "Can Adversarial Weight Perturbations Inject Neural Backdoors?", "comments": "Accepted as a conference paper at CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3412130", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial machine learning has exposed several security hazards of neural\nmodels and has become an important research topic in recent times. Thus far,\nthe concept of an \"adversarial perturbation\" has exclusively been used with\nreference to the input space referring to a small, imperceptible change which\ncan cause a ML model to err. In this work we extend the idea of \"adversarial\nperturbations\" to the space of model weights, specifically to inject backdoors\nin trained DNNs, which exposes a security risk of using publicly available\ntrained models. Here, injecting a backdoor refers to obtaining a desired\noutcome from the model when a trigger pattern is added to the input, while\nretaining the original model predictions on a non-triggered input. From the\nperspective of an adversary, we characterize these adversarial perturbations to\nbe constrained within an $\\ell_{\\infty}$ norm around the original model\nweights. We introduce adversarial perturbations in the model weights using a\ncomposite loss on the predictions of the original model and the desired trigger\nthrough projected gradient descent. We empirically show that these adversarial\nweight perturbations exist universally across several computer vision and\nnatural language processing tasks. Our results show that backdoors can be\nsuccessfully injected with a very small average relative change in model weight\nvalues for several applications.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 18:26:13 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 04:58:59 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Garg", "Siddhant", ""], ["Kumar", "Adarsh", ""], ["Goel", "Vibhor", ""], ["Liang", "Yingyu", ""]]}, {"id": "2008.01766", "submitter": "Brenden Lake", "authors": "Brenden M. Lake and Gregory L. Murphy", "title": "Word meaning in minds and machines", "comments": "In press at Psychological Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machines have achieved a broad and growing set of linguistic competencies,\nthanks to recent progress in Natural Language Processing (NLP). Psychologists\nhave shown increasing interest in such models, comparing their output to\npsychological judgments such as similarity, association, priming, and\ncomprehension, raising the question of whether the models could serve as\npsychological theories. In this article, we compare how humans and machines\nrepresent the meaning of words. We argue that contemporary NLP systems are\nfairly successful models of human word similarity, but they fall short in many\nother respects. Current models are too strongly linked to the text-based\npatterns in large corpora, and too weakly linked to the desires, goals, and\nbeliefs that people express through words. Word meanings must also be grounded\nin perception and action and be capable of flexible combinations in ways that\ncurrent systems are not. We discuss more promising approaches to grounding NLP\nsystems and argue that they will be more successful with a more human-like,\nconceptual basis for word meaning.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 18:45:49 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 20:53:24 GMT"}, {"version": "v3", "created": "Sat, 17 Apr 2021 21:05:02 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Lake", "Brenden M.", ""], ["Murphy", "Gregory L.", ""]]}, {"id": "2008.01767", "submitter": "Luana Ruiz", "authors": "Luana Ruiz, Fernando Gama, Alejandro Ribeiro", "title": "Graph Neural Networks: Architectures, Stability and Transferability", "comments": "Accepted for publication in the Proceedings of the IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are information processing architectures for\nsignals supported on graphs. They are presented here as generalizations of\nconvolutional neural networks (CNNs) in which individual layers contain banks\nof graph convolutional filters instead of banks of classical convolutional\nfilters. Otherwise, GNNs operate as CNNs. Filters are composed with pointwise\nnonlinearities and stacked in layers. It is shown that GNN architectures\nexhibit equivariance to permutation and stability to graph deformations. These\nproperties help explain the good performance of GNNs that can be observed\nempirically. It is also shown that if graphs converge to a limit object, a\ngraphon, GNNs converge to a corresponding limit object, a graphon neural\nnetwork. This convergence justifies the transferability of GNNs across networks\nwith different number of nodes. Concepts are illustrated by the application of\nGNNs to recommendation systems, decentralized collaborative control, and\nwireless communication networks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 18:57:36 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 14:19:33 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 18:52:54 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Ruiz", "Luana", ""], ["Gama", "Fernando", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2008.01772", "submitter": "Ryan Pyle", "authors": "Justin Sahs, Ryan Pyle, Aneel Damaraju, Josue Ortega Caro, Onur\n  Tavaslioglu, Andy Lu, Ankit Patel", "title": "Shallow Univariate ReLu Networks as Splines: Initialization, Loss\n  Surface, Hessian, & Gradient Flow Dynamics", "comments": "14 pages, 4 figures in main text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the learning dynamics and inductive bias of neural networks\n(NNs) is hindered by the opacity of the relationship between NN parameters and\nthe function represented. We propose reparametrizing ReLU NNs as continuous\npiecewise linear splines. Using this spline lens, we study learning dynamics in\nshallow univariate ReLU NNs, finding unexpected insights and explanations for\nseveral perplexing phenomena. We develop a surprisingly simple and transparent\nview of the structure of the loss surface, including its critical and fixed\npoints, Hessian, and Hessian spectrum. We also show that standard weight\ninitializations yield very flat functions, and that this flatness, together\nwith overparametrization and the initial weight scale, is responsible for the\nstrength and type of implicit regularization, consistent with recent work\narXiv:1906.05827. Our implicit regularization results are complementary to\nrecent work arXiv:1906.07842, done independently, which showed that\ninitialization scale critically controls implicit regularization via a\nkernel-based argument. Our spline-based approach reproduces their key implicit\nregularization results but in a far more intuitive and transparent manner.\nGoing forward, our spline-based approach is likely to extend naturally to the\nmultivariate and deep settings, and will play a foundational role in efforts to\nunderstand neural networks. Videos of learning dynamics using a spline-based\nvisualization are available at http://shorturl.at/tFWZ2.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 19:19:49 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Sahs", "Justin", ""], ["Pyle", "Ryan", ""], ["Damaraju", "Aneel", ""], ["Caro", "Josue Ortega", ""], ["Tavaslioglu", "Onur", ""], ["Lu", "Andy", ""], ["Patel", "Ankit", ""]]}, {"id": "2008.01774", "submitter": "Yiqiu Shen", "authors": "Farah E. Shamout, Yiqiu Shen, Nan Wu, Aakash Kaku, Jungkyu Park, Taro\n  Makino, Stanis{\\l}aw Jastrz\\k{e}bski, Jan Witowski, Duo Wang, Ben Zhang,\n  Siddhant Dogra, Meng Cao, Narges Razavian, David Kudlowitz, Lea Azour,\n  William Moore, Yvonne W. Lui, Yindalon Aphinyanaphongs, Carlos\n  Fernandez-Granda, Krzysztof J. Geras", "title": "An artificial intelligence system for predicting the deterioration of\n  COVID-19 patients in the emergency department", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the coronavirus disease 2019 (COVID-19) pandemic, rapid and accurate\ntriage of patients at the emergency department is critical to inform\ndecision-making. We propose a data-driven approach for automatic prediction of\ndeterioration risk using a deep neural network that learns from chest X-ray\nimages and a gradient boosting model that learns from routine clinical\nvariables. Our AI prognosis system, trained using data from 3,661 patients,\nachieves an area under the receiver operating characteristic curve (AUC) of\n0.786 (95% CI: 0.745-0.830) when predicting deterioration within 96 hours. The\ndeep neural network extracts informative areas of chest X-ray images to assist\nclinicians in interpreting the predictions and performs comparably to two\nradiologists in a reader study. In order to verify performance in a real\nclinical setting, we silently deployed a preliminary version of the deep neural\nnetwork at New York University Langone Health during the first wave of the\npandemic, which produced accurate predictions in real-time. In summary, our\nfindings demonstrate the potential of the proposed system for assisting\nfront-line physicians in the triage of COVID-19 patients.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 19:20:31 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 02:36:36 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Shamout", "Farah E.", ""], ["Shen", "Yiqiu", ""], ["Wu", "Nan", ""], ["Kaku", "Aakash", ""], ["Park", "Jungkyu", ""], ["Makino", "Taro", ""], ["Jastrz\u0119bski", "Stanis\u0142aw", ""], ["Witowski", "Jan", ""], ["Wang", "Duo", ""], ["Zhang", "Ben", ""], ["Dogra", "Siddhant", ""], ["Cao", "Meng", ""], ["Razavian", "Narges", ""], ["Kudlowitz", "David", ""], ["Azour", "Lea", ""], ["Moore", "William", ""], ["Lui", "Yvonne W.", ""], ["Aphinyanaphongs", "Yindalon", ""], ["Fernandez-Granda", "Carlos", ""], ["Geras", "Krzysztof J.", ""]]}, {"id": "2008.01792", "submitter": "Elcin Huseyn", "authors": "Elcin Huseyn", "title": "Deep Learning Based Early Diagnostics of Parkinsons Disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.PL eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the world, about 7 to 10 million elderly people are suffering from\nParkinson's Disease (PD) disease. Parkinson's disease is a common neurological\ndegenerative disease, and its clinical characteristics are Tremors, rigidity,\nbradykinesia, and decreased autonomy. Its clinical manifestations are very\nsimilar to Multiple System Atrophy (MSA) disorders. Studies have shown that\npatients with Parkinson's disease often reach an irreparable situation when\ndiagnosed, so As Parkinson's disease can be distinguished from MSA disease and\nget an early diagnosis, people are constantly exploring new methods. With the\nadvent of the era of big data, deep learning has made major breakthroughs in\nimage recognition and classification. Therefore, this study proposes to use The\ndeep learning method to realize the diagnosis of Parkinson's disease, multiple\nsystem atrophy, and healthy people. This data source is from Istanbul\nUniversity Cerrahpasa Faculty of Medicine Hospital. The processing of the\noriginal magnetic resonance image (Magnetic Resonance Image, MRI) is guided by\nthe doctor of Istanbul University Cerrahpasa Faculty of Medicine Hospital. The\nfocus of this experiment is to improve the existing neural network so that it\ncan obtain good results in medical image recognition and diagnosis. An improved\nalgorithm was proposed based on the pathological characteristics of Parkinson's\ndisease, and good experimental results were obtained by comparing indicators\nsuch as model loss and accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 19:50:52 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Huseyn", "Elcin", ""]]}, {"id": "2008.01798", "submitter": "Yu Huang", "authors": "Yu Huang, Yufei Tang, Hanqi Zhuang, James VanZwieten, Laurent Cherubin", "title": "Physics-informed Tensor-train ConvLSTM for Volumetric Velocity\n  Forecasting", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the National Academies, a weekly forecast of velocity, vertical\nstructure, and duration of the Loop Current (LC) and its eddies is critical for\nunderstanding the oceanography and ecosystem, and for mitigating outcomes of\nanthropogenic and natural disasters in the Gulf of Mexico (GoM). However, this\nforecast is a challenging problem since the LC behaviour is dominated by\nlong-range spatial connections across multiple timescales. In this paper, we\nextend spatiotemporal predictive learning, showing its effectiveness beyond\nvideo prediction, to a 4D model, i.e., a novel Physics-informed Tensor-train\nConvLSTM (PITT-ConvLSTM) for temporal sequences of 3D geospatial data\nforecasting. Specifically, we propose 1) a novel 4D higher-order recurrent\nneural network with empirical orthogonal function analysis to capture the\nhidden uncorrelated patterns of each hierarchy, 2) a convolutional tensor-train\ndecomposition to capture higher-order space-time correlations, and 3) to\nincorporate prior physic knowledge that is provided from domain experts by\ninforming the learning in latent space. The advantage of our proposed method is\nclear: constrained by physical laws, it simultaneously learns good\nrepresentations for frame dependencies (both short-term and long-term\nhigh-level dependency) and inter-hierarchical relations within each time frame.\nExperiments on geospatial data collected from the GoM demonstrate that\nPITT-ConvLSTM outperforms the state-of-the-art methods in forecasting the\nvolumetric velocity of the LC and its eddies for a period of over one week.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 19:55:57 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Huang", "Yu", ""], ["Tang", "Yufei", ""], ["Zhuang", "Hanqi", ""], ["VanZwieten", "James", ""], ["Cherubin", "Laurent", ""]]}, {"id": "2008.01805", "submitter": "Yossi Arjevani", "authors": "Yossi Arjevani, Michael Field", "title": "Analytic Characterization of the Hessian in Shallow ReLU Models: A Tale\n  of Symmetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the optimization problem associated with fitting two-layers ReLU\nnetworks with respect to the squared loss, where labels are generated by a\ntarget network. We leverage the rich symmetry structure to analytically\ncharacterize the Hessian at various families of spurious minima in the natural\nregime where the number of inputs $d$ and the number of hidden neurons $k$ is\nfinite. In particular, we prove that for $d\\ge k$ standard Gaussian inputs: (a)\nof the $dk$ eigenvalues of the Hessian, $dk - O(d)$ concentrate near zero, (b)\n$\\Omega(d)$ of the eigenvalues grow linearly with $k$. Although this phenomenon\nof extremely skewed spectrum has been observed many times before, to our\nknowledge, this is the first time it has been established {rigorously}. Our\nanalytic approach uses techniques, new to the field, from symmetry breaking and\nrepresentation theory, and carries important implications for our ability to\nargue about statistical generalization through local curvature.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 20:08:35 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 22:53:35 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Arjevani", "Yossi", ""], ["Field", "Michael", ""]]}, {"id": "2008.01807", "submitter": "Riccardo Galanti", "authors": "Riccardo Galanti, Bernat Coma-Puig, Massimiliano de Leoni, Josep\n  Carmona, Nicol\\`o Navarin", "title": "Explainable Predictive Process Monitoring", "comments": "Galanti, R., Coma-Puig, B., de Leoni, M., Carmona, J., Navarin, N.:\n  Explainable Predictive Process Monitoring, the International Conference on\n  Process Mining (ICPM 2020), IEEE Computational Intelligence Society, 2020.\n  Article accepted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive Business Process Monitoring is becoming an essential aid for\norganizations, providing online operational support of their processes. This\npaper tackles the fundamental problem of equipping predictive business process\nmonitoring with explanation capabilities, so that not only the what but also\nthe why is reported when predicting generic KPIs like remaining time, or\nactivity execution. We use the game theory of Shapley Values to obtain robust\nexplanations of the predictions. The approach has been implemented and tested\non real-life benchmarks, showing for the first time how explanations can be\ngiven in the field of predictive business process monitoring.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 20:09:32 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 20:03:08 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Galanti", "Riccardo", ""], ["Coma-Puig", "Bernat", ""], ["de Leoni", "Massimiliano", ""], ["Carmona", "Josep", ""], ["Navarin", "Nicol\u00f2", ""]]}, {"id": "2008.01814", "submitter": "Blesson Varghese", "authors": "Francis McNamee and Schahram Dustadar and Peter Kilpatrick and Weisong\n  Shi and Ivor Spence and Blesson Varghese", "title": "A Case For Adaptive Deep Neural Networks in Edge Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge computing offers an additional layer of compute infrastructure closer to\nthe data source before raw data from privacy-sensitive and performance-critical\napplications is transferred to a cloud data center. Deep Neural Networks (DNNs)\nare one class of applications that are reported to benefit from collaboratively\ncomputing between the edge and the cloud. A DNN is partitioned such that\nspecific layers of the DNN are deployed onto the edge and the cloud to meet\nperformance and privacy objectives. However, there is limited understanding of:\n(a) whether and how evolving operational conditions (increased CPU and memory\nutilization at the edge or reduced data transfer rates between the edge and the\ncloud) affect the performance of already deployed DNNs, and (b) whether a new\npartition configuration is required to maximize performance. A DNN that adapts\nto changing operational conditions is referred to as an 'adaptive DNN'. This\npaper investigates whether there is a case for adaptive DNNs in edge computing\nby considering three questions: (i) Are DNNs sensitive to operational\nconditions? (ii) How sensitive are DNNs to operational conditions? (iii) Do\nindividual or a combination of operational conditions equally affect DNNs? (iv)\nIs DNN partitioning sensitive to hardware architectures on the cloud/edge? The\nexploration is carried out in the context of 8 pre-trained DNN models and the\nresults presented are from analyzing nearly 8 million data points. The results\nhighlight that network conditions affects DNN performance more than CPU or\nmemory related operational conditions. Repartitioning is noted to provide a\nperformance gain in a number of cases, but a specific trend was not noted in\nrelation to its correlation to the underlying hardware architecture.\nNonetheless, the need for adaptive DNNs is confirmed.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 20:23:50 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 14:27:36 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["McNamee", "Francis", ""], ["Dustadar", "Schahram", ""], ["Kilpatrick", "Peter", ""], ["Shi", "Weisong", ""], ["Spence", "Ivor", ""], ["Varghese", "Blesson", ""]]}, {"id": "2008.01818", "submitter": "Xiuyuan Cheng", "authors": "Xiuyuan Cheng, Zichen Miao, Qiang Qiu", "title": "Graph Convolution with Low-rank Learnable Local Filters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric variations like rotation, scaling, and viewpoint changes pose a\nsignificant challenge to visual understanding. One common solution is to\ndirectly model certain intrinsic structures, e.g., using landmarks. However, it\nthen becomes non-trivial to build effective deep models, especially when the\nunderlying non-Euclidean grid is irregular and coarse. Recent deep models using\ngraph convolutions provide an appropriate framework to handle such\nnon-Euclidean data, but many of them, particularly those based on global graph\nLaplacians, lack expressiveness to capture local features required for\nrepresentation of signals lying on the non-Euclidean grid. The current paper\nintroduces a new type of graph convolution with learnable low-rank local\nfilters, which is provably more expressive than previous spectral graph\nconvolution methods. The model also provides a unified framework for both\nspectral and spatial graph convolutions. To improve model robustness,\nregularization by local graph Laplacians is introduced. The representation\nstability against input graph data perturbation is theoretically proved, making\nuse of the graph filter locality and the local graph regularization.\nExperiments on spherical mesh data, real-world facial expression\nrecognition/skeleton-based action recognition data, and data with simulated\ngraph noise show the empirical advantage of the proposed model.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 20:34:59 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 17:07:57 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Cheng", "Xiuyuan", ""], ["Miao", "Zichen", ""], ["Qiu", "Qiang", ""]]}, {"id": "2008.01825", "submitter": "Eugene Vinitsky", "authors": "Eugene Vinitsky and Yuqing Du and Kanaad Parvate and Kathy Jang and\n  Pieter Abbeel and Alexandre Bayen", "title": "Robust Reinforcement Learning using Adversarial Populations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) is an effective tool for controller design but\ncan struggle with issues of robustness, failing catastrophically when the\nunderlying system dynamics are perturbed. The Robust RL formulation tackles\nthis by adding worst-case adversarial noise to the dynamics and constructing\nthe noise distribution as the solution to a zero-sum minimax game. However,\nexisting work on learning solutions to the Robust RL formulation has primarily\nfocused on training a single RL agent against a single adversary. In this work,\nwe demonstrate that using a single adversary does not consistently yield\nrobustness to dynamics variations under standard parametrizations of the\nadversary; the resulting policy is highly exploitable by new adversaries. We\npropose a population-based augmentation to the Robust RL formulation in which\nwe randomly initialize a population of adversaries and sample from the\npopulation uniformly during training. We empirically validate across robotics\nbenchmarks that the use of an adversarial population results in a more robust\npolicy that also improves out-of-distribution generalization. Finally, we\ndemonstrate that this approach provides comparable robustness and\ngeneralization as domain randomization on these benchmarks while avoiding a\nubiquitous domain randomization failure mode.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 20:57:32 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 22:41:54 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Vinitsky", "Eugene", ""], ["Du", "Yuqing", ""], ["Parvate", "Kanaad", ""], ["Jang", "Kathy", ""], ["Abbeel", "Pieter", ""], ["Bayen", "Alexandre", ""]]}, {"id": "2008.01839", "submitter": "Philip Schniter", "authors": "R\\'emi Gribonval and Antoine Chatalic and Nicolas Keriven and Vincent\n  Schellekens and Laurent Jacques and Philip Schniter", "title": "Sketching Datasets for Large-Scale Learning (long version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article considers \"compressive learning,\" an approach to large-scale\nmachine learning where datasets are massively compressed before learning (e.g.,\nclustering, classification, or regression) is performed. In particular, a\n\"sketch\" is first constructed by computing carefully chosen nonlinear random\nfeatures (e.g., random Fourier features) and averaging them over the whole\ndataset. Parameters are then learned from the sketch, without access to the\noriginal dataset. This article surveys the current state-of-the-art in\ncompressive learning, including the main concepts and algorithms, their\nconnections with established signal-processing methods, existing theoretical\nguarantees -- on both information preservation and privacy preservation, and\nimportant open problems.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 21:29:05 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 20:41:41 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 21:36:36 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Gribonval", "R\u00e9mi", ""], ["Chatalic", "Antoine", ""], ["Keriven", "Nicolas", ""], ["Schellekens", "Vincent", ""], ["Jacques", "Laurent", ""], ["Schniter", "Philip", ""]]}, {"id": "2008.01846", "submitter": "Ge Wang Dr.", "authors": "Weiwen Wu, Dianlin Hu, Wenxiang Cong, Hongming Shan, Shaoyu Wang,\n  Chuang Niu, Pingkun Yan, Hengyong Yu, Varut Vardhanabhuti, Ge Wang", "title": "Stabilizing Deep Tomographic Reconstruction Networks", "comments": "68 pages, 26 figures, 140 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tomographic image reconstruction with deep learning (DL) is an emerging field\nof applied artificial intelligence, but a recent landmark study reveals that\nseveral deep reconstruction networks are unstable for computed tomography (CT)\nand magnetic resonance imaging (MRI). Since deep reconstruction is now a\nmainstream approach to achieve better tomographic image quality, stabilizing\ndeep networks is an urgent challenge. Here we propose an Analytic Compressive\nIterative Deep (ACID) framework to address this challenge. Instead of only\nusing DL or compressed sensing, ACID consists of four modules: deep learning,\ncompressed sensing-inspired sparsity promotion, analytic mapping, and iterative\nrefinement. This paper shows the convergence and stability of ACID under a\nbounded error norm condition (a special case of the Lipschitz continuity),\nimproves deep reconstruction quality by stabilizing an unstable deep\nreconstruction network in the ACID framework, and demonstrates the power of\nACID in both stabilizing an unstable network and being resilient against\nadversarial attacks to the whole ACID workflow. In our experiments, ACID\neliminated all three kinds of instabilities and significantly improved image\nquality in the context of the aforementioned study on the instabilities,\ndemonstrating that data-driven reconstruction can be stabilized to outperform\nreconstruction using sparsity-regularized reconstruction alone. The mechanism\nof ACID is to synergize a deep reconstruction network trained on big data,\ncompressed sensing-based improvement with kernel awareness, and iterative\nrefinement to eliminate any data residual inconsistent with real data. We\nanticipate that this integrative closed-loop data-driven approach helps advance\ndeep tomographic image reconstruction methods into clinical applications.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 21:35:32 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 12:59:48 GMT"}, {"version": "v3", "created": "Sat, 23 Jan 2021 17:08:44 GMT"}, {"version": "v4", "created": "Thu, 4 Mar 2021 04:24:47 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Wu", "Weiwen", ""], ["Hu", "Dianlin", ""], ["Cong", "Wenxiang", ""], ["Shan", "Hongming", ""], ["Wang", "Shaoyu", ""], ["Niu", "Chuang", ""], ["Yan", "Pingkun", ""], ["Yu", "Hengyong", ""], ["Vardhanabhuti", "Varut", ""], ["Wang", "Ge", ""]]}, {"id": "2008.01855", "submitter": "Ron Korine", "authors": "Ron Korine and Danny Hendler", "title": "DAEMON: Dataset-Agnostic Explainable Malware Classification Using\n  Multi-Stage Feature Mining", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2021.3082173", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Numerous metamorphic and polymorphic malicious variants are generated\nautomatically on a daily basis by mutation engines that transform the code of a\nmalicious program while retaining its functionality, in order to evade\nsignature-based detection. These automatic processes have greatly increased the\nnumber of malware variants, deeming their fully-manual analysis impossible.\nMalware classification is the task of determining to which family a new\nmalicious variant belongs. Variants of the same malware family show similar\nbehavioral patterns. Thus, classifying newly discovered malicious programs and\napplications helps assess the risks they pose. Moreover, malware classification\nfacilitates determining which of the newly discovered variants should undergo\nmanual analysis by a security expert, in order to determine whether they belong\nto a new family (e.g., one whose members exploit a zero-day vulnerability) or\nare simply the result of a concept drift within a known malicious family. This\nmotivated intense research in recent years on devising high-accuracy automatic\ntools for malware classification. In this work, we present DAEMON - a novel\ndataset-agnostic malware classifier. A key property of DAEMON is that the type\nof features it uses and the manner in which they are mined facilitate\nunderstanding the distinctive behavior of malware families, making its\nclassification decisions explainable. We've optimized DAEMON using a\nlarge-scale dataset of x86 binaries, belonging to a mix of several malware\nfamilies targeting computers running Windows. We then re-trained it and applied\nit, without any algorithmic change, feature re-engineering or parameter tuning,\nto two other large-scale datasets of malicious Android applications consisting\nof numerous malware families. DAEMON obtained highly accurate classification\nresults on all datasets, establishing that it is also platform-agnostic.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 21:57:30 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 14:45:44 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Korine", "Ron", ""], ["Hendler", "Danny", ""]]}, {"id": "2008.01868", "submitter": "Hao-Ren Yao", "authors": "Hao-Ren Yao, Der-Chen Chang, Ophir Frieder, Wendy Huang, I-Chia Liang\n  and Chi-Feng Hung", "title": "Cross-Global Attention Graph Kernel Network Prediction of Drug\n  Prescription", "comments": "ACM-BCB 2020 (Full paper)", "journal-ref": "Proceedings of the 11th ACM International Conference on\n  Bioinformatics, Computational Biology and Health Informatics (BCB '20),\n  September 21-24, 2020, Virtual Event, USA", "doi": "10.1145/3388440.3412459", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end, interpretable, deep-learning architecture to learn\na graph kernel that predicts the outcome of chronic disease drug prescription.\nThis is achieved through a deep metric learning collaborative with a Support\nVector Machine objective using a graphical representation of Electronic Health\nRecords. We formulate the predictive model as a binary graph classification\nproblem with an adaptive learned graph kernel through novel cross-global\nattention node matching between patient graphs, simultaneously computing on\nmultiple graphs without training pair or triplet generation. Results using the\nTaiwanese National Health Insurance Research Database demonstrate that our\napproach outperforms current start-of-the-art models both in terms of accuracy\nand interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 22:36:46 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Yao", "Hao-Ren", ""], ["Chang", "Der-Chen", ""], ["Frieder", "Ophir", ""], ["Huang", "Wendy", ""], ["Liang", "I-Chia", ""], ["Hung", "Chi-Feng", ""]]}, {"id": "2008.01879", "submitter": "Avisek Naug", "authors": "Avisek Naug and Marcos Qui\\~nones-Grueiro and Gautam Biswas", "title": "A Relearning Approach to Reinforcement Learning for Control of Smart\n  Buildings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates that continual relearning of control policies using\nincremental deep reinforcement learning (RL) can improve policy learning for\nnon-stationary processes. We demonstrate this approach for a data-driven 'smart\nbuilding environment' that we use as a test-bed for developing HVAC controllers\nfor reducing energy consumption of large buildings on our university campus.\nThe non-stationarity in building operations and weather patterns makes it\nimperative to develop control strategies that are adaptive to changing\nconditions. On-policy RL algorithms, such as Proximal Policy Optimization (PPO)\nrepresent an approach for addressing this non-stationarity, but exploration on\nthe actual system is not an option for safety-critical systems. As an\nalternative, we develop an incremental RL technique that simultaneously reduces\nbuilding energy consumption without sacrificing overall comfort. We compare the\nperformance of our incremental RL controller to that of a static RL controller\nthat does not implement the relearning function. The performance of the static\ncontroller diminishes significantly over time, but the relearning controller\nadjusts to changing conditions while ensuring comfort and optimal energy\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 23:31:05 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Naug", "Avisek", ""], ["Qui\u00f1ones-Grueiro", "Marcos", ""], ["Biswas", "Gautam", ""]]}, {"id": "2008.01883", "submitter": "Masanori Koyama", "authors": "Masanori Koyama and Shoichiro Yamaguchi", "title": "When is invariance useful in an Out-of-Distribution Generalization\n  problem ?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of Out-of-Distribution (OOD) generalization problem is to train a\npredictor that generalizes on all environments. Popular approaches in this\nfield use the hypothesis that such a predictor shall be an \\textit{invariant\npredictor} that captures the mechanism that remains constant across\nenvironments. While these approaches have been experimentally successful in\nvarious case studies, there is still much room for the theoretical validation\nof this hypothesis. This paper presents a new set of theoretical conditions\nnecessary for an invariant predictor to achieve the OOD optimality. Our theory\nnot only applies to non-linear cases, but also generalizes the necessary\ncondition used in \\citet{rojas2018invariant}. We also derive Inter Gradient\nAlignment algorithm from our theory and demonstrate its competitiveness on\nMNIST-derived benchmark datasets as well as on two of the three\n\\textit{Invariance Unit Tests} proposed by \\citet{aubinlinear}.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 23:57:11 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 12:07:52 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 09:18:51 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Koyama", "Masanori", ""], ["Yamaguchi", "Shoichiro", ""]]}, {"id": "2008.01885", "submitter": "Zachary Baum", "authors": "Zachary M. C. Baum, Yipeng Hu, Dean C. Barratt", "title": "Multimodality Biomedical Image Registration using Free Point Transformer\n  Networks", "comments": "10 pages, 4 figures. Accepted for publication at International\n  Conference on Medical Image Computing and Computer Assisted Intervention\n  (MICCAI) workshop on Advances in Simplifying Medical UltraSound (ASMUS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a point-set registration algorithm based on a novel free point\ntransformer (FPT) network, designed for points extracted from multimodal\nbiomedical images for registration tasks, such as those frequently encountered\nin ultrasound-guided interventional procedures. FPT is constructed with a\nglobal feature extractor which accepts unordered source and target point-sets\nof variable size. The extracted features are conditioned by a shared multilayer\nperceptron point transformer module to predict a displacement vector for each\nsource point, transforming it into the target space. The point transformer\nmodule assumes no vicinity or smoothness in predicting spatial transformation\nand, together with the global feature extractor, is trained in a data-driven\nfashion with an unsupervised loss function. In a multimodal registration task\nusing prostate MR and sparsely acquired ultrasound images, FPT yields\ncomparable or improved results over other rigid and non-rigid registration\nmethods. This demonstrates the versatility of FPT to learn registration\ndirectly from real, clinical training data and to generalize to a challenging\ntask, such as the interventional application presented.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 00:13:04 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Baum", "Zachary M. C.", ""], ["Hu", "Yipeng", ""], ["Barratt", "Dean C.", ""]]}, {"id": "2008.01897", "submitter": "Hong-Gyu Jung", "authors": "Sin-Han Kang, Hong-Gyu Jung, Dong-Ok Won, Seong-Whan Lee", "title": "Counterfactual Explanation Based on Gradual Construction for Deep\n  Networks", "comments": "The first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand the black-box characteristics of deep networks, counterfactual\nexplanation that deduces not only the important features of an input space but\nalso how those features should be modified to classify input as a target class\nhas gained an increasing interest. The patterns that deep networks have learned\nfrom a training dataset can be grasped by observing the feature variation among\nvarious classes. However, current approaches perform the feature modification\nto increase the classification probability for the target class irrespective of\nthe internal characteristics of deep networks. This often leads to unclear\nexplanations that deviate from real-world data distributions. To address this\nproblem, we propose a counterfactual explanation method that exploits the\nstatistics learned from a training dataset. Especially, we gradually construct\nan explanation by iterating over masking and composition steps. The masking\nstep aims to select an important feature from the input data to be classified\nas a target class. Meanwhile, the composition step aims to optimize the\npreviously selected feature by ensuring that its output score is close to the\nlogit space of the training data that are classified as the target class.\nExperimental results show that our method produces human-friendly\ninterpretations on various classification datasets and verify that such\ninterpretations can be achieved with fewer feature modification.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 01:18:31 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Kang", "Sin-Han", ""], ["Jung", "Hong-Gyu", ""], ["Won", "Dong-Ok", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2008.01902", "submitter": "Aristotelis Papadopoulos", "authors": "Yihang Zhang, Aristotelis-Angelos Papadopoulos, Pengfei Chen, Faisal\n  Alasiri, Tianchen Yuan, Jin Zhou, Petros A. Ioannou", "title": "Integrated Traffic Simulation-Prediction System using Neural Networks\n  with Application to the Los Angeles International Airport Road Network", "comments": "19 pages. Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation networks are highly complex and the design of efficient\ntraffic management systems is difficult due to lack of adequate measured data\nand accurate predictions of the traffic states. Traffic simulation models can\ncapture the complex dynamics of transportation networks by using limited\navailable traffic data and can help central traffic authorities in their\ndecision-making, if appropriate input is fed into the simulator. In this paper,\nwe design an integrated simulation-prediction system which estimates the\nOrigin-Destination (OD) matrix of a road network using only flow rate\ninformation and predicts the behavior of the road network in different\nsimulation scenarios. The proposed system includes an optimization-based OD\nmatrix generation method, a Neural Network (NN) model trained to predict OD\nmatrices via the pattern of traffic flow and a microscopic traffic simulator\nwith a Dynamic Traffic Assignment (DTA) scheme to predict the behavior of the\ntransportation system. We test the proposed system on the road network of the\ncentral terminal area (CTA) of the Los Angeles International Airport (LAX),\nwhich demonstrates that the integrated traffic simulation-prediction system can\nbe used to simulate the effects of several real world scenarios such as lane\nclosures, curbside parking and other changes. The model is an effective tool\nfor learning the impact and possible benefits of changes in the network and for\nanalyzing scenarios at a very low cost without disrupting the network.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 01:41:10 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Zhang", "Yihang", ""], ["Papadopoulos", "Aristotelis-Angelos", ""], ["Chen", "Pengfei", ""], ["Alasiri", "Faisal", ""], ["Yuan", "Tianchen", ""], ["Zhou", "Jin", ""], ["Ioannou", "Petros A.", ""]]}, {"id": "2008.01913", "submitter": "Allen Z. Ren", "authors": "Allen Z. Ren, Sushant Veer, Anirudha Majumdar", "title": "Generalization Guarantees for Imitation Learning", "comments": "Presented at the Conference on Robot Learning (CoRL), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Control policies from imitation learning can often fail to generalize to\nnovel environments due to imperfect demonstrations or the inability of\nimitation learning algorithms to accurately infer the expert's policies. In\nthis paper, we present rigorous generalization guarantees for imitation\nlearning by leveraging the Probably Approximately Correct (PAC)-Bayes framework\nto provide upper bounds on the expected cost of policies in novel environments.\nWe propose a two-stage training method where a latent policy distribution is\nfirst embedded with multi-modal expert behavior using a conditional variational\nautoencoder, and then \"fine-tuned\" in new training environments to explicitly\noptimize the generalization bound. We demonstrate strong generalization bounds\nand their tightness relative to empirical performance in simulation for (i)\ngrasping diverse mugs, (ii) planar pushing with visual feedback, and (iii)\nvision-based indoor navigation, as well as through hardware experiments for the\ntwo manipulation tasks.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 03:04:13 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 06:35:17 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Ren", "Allen Z.", ""], ["Veer", "Sushant", ""], ["Majumdar", "Anirudha", ""]]}, {"id": "2008.01915", "submitter": "Liu Yang", "authors": "Liu Yang, Constantinos Daskalakis, George Em Karniadakis", "title": "Generative Ensemble Regression: Learning Particle Dynamics from\n  Observations of Ensembles with Physics-Informed Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for inferring the governing stochastic ordinary\ndifferential equations (SODEs) by observing particle ensembles at discrete and\nsparse time instants, i.e., multiple \"snapshots\". Particle coordinates at a\nsingle time instant, possibly noisy or truncated, are recorded in each snapshot\nbut are unpaired across the snapshots. By training a physics-informed\ngenerative model that generates \"fake\" sample paths, we aim to fit the observed\nparticle ensemble distributions with a curve in the probability measure space,\nwhich is induced from the inferred particle dynamics. We employ different\nmetrics to quantify the differences between distributions, e.g., the sliced\nWasserstein distances and the adversarial losses in generative adversarial\nnetworks (GANs). We refer to this method as generative \"ensemble-regression\"\n(GER), in analogy to the classic \"point-regression\", where we infer the\ndynamics by performing regression in the Euclidean space. We illustrate the GER\nby learning the drift and diffusion terms of particle ensembles governed by\nSODEs with Brownian motions and Levy processes up to 100 dimensions. We also\ndiscuss how to treat cases with noisy or truncated observations. Apart from\nsystems consisting of independent particles, we also tackle nonlocal\ninteracting particle systems with unknown interaction potential parameters by\nconstructing a physics-informed loss function. Finally, we investigate\nscenarios of paired observations and discuss how to reduce the dimensionality\nin such cases by proving a convergence theorem that provides theoretical\nsupport.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 03:06:40 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2021 02:06:01 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Yang", "Liu", ""], ["Daskalakis", "Constantinos", ""], ["Karniadakis", "George Em", ""]]}, {"id": "2008.01916", "submitter": "Dayong Ye", "authors": "Tianqing Zhu and Dayong Ye and Wei Wang and Wanlei Zhou and Philip S.\n  Yu", "title": "More Than Privacy: Applying Differential Privacy in Key Areas of\n  Artificial Intelligence", "comments": null, "journal-ref": "IEEE Tranactions on Knowledge and Data Engineering 2020", "doi": "10.1109/TKDE.2020.3014246", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) has attracted a great deal of attention in\nrecent years. However, alongside all its advancements, problems have also\nemerged, such as privacy violations, security issues and model fairness.\nDifferential privacy, as a promising mathematical model, has several attractive\nproperties that can help solve these problems, making it quite a valuable tool.\nFor this reason, differential privacy has been broadly applied in AI but to\ndate, no study has documented which differential privacy mechanisms can or have\nbeen leveraged to overcome its issues or the properties that make this\npossible. In this paper, we show that differential privacy can do more than\njust privacy preservation. It can also be used to improve security, stabilize\nlearning, build fair models, and impose composition in selected areas of AI.\nWith a focus on regular machine learning, distributed machine learning, deep\nlearning, and multi-agent systems, the purpose of this article is to deliver a\nnew view on many possibilities for improving AI performance with differential\nprivacy techniques.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 03:07:36 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Zhu", "Tianqing", ""], ["Ye", "Dayong", ""], ["Wang", "Wei", ""], ["Zhou", "Wanlei", ""], ["Yu", "Philip S.", ""]]}, {"id": "2008.01935", "submitter": "Chengbin Hou", "authors": "Chengbin Hou, Han Zhang, Shan He, Ke Tang", "title": "GloDyNE: Global Topology Preserving Dynamic Network Embedding", "comments": "Accepted by IEEE-TKDE", "journal-ref": null, "doi": "10.1109/TKDE.2020.3046511", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning low-dimensional topological representation of a network in dynamic\nenvironments is attracting much attention due to the time-evolving nature of\nmany real-world networks. The main and common objective of Dynamic Network\nEmbedding (DNE) is to efficiently update node embeddings while preserving\nnetwork topology at each time step. The idea of most existing DNE methods is to\ncapture the topological changes at or around the most affected nodes (instead\nof all nodes) and accordingly update node embeddings. Unfortunately, this kind\nof approximation, although can improve efficiency, cannot effectively preserve\nthe global topology of a dynamic network at each time step, due to not\nconsidering the inactive sub-networks that receive accumulated topological\nchanges propagated via the high-order proximity. To tackle this challenge, we\npropose a novel node selecting strategy to diversely select the representative\nnodes over a network, which is coordinated with a new incremental learning\nparadigm of Skip-Gram based embedding approach. The extensive experiments show\nGloDyNE, with a small fraction of nodes being selected, can already achieve the\nsuperior or comparable performance w.r.t. the state-of-the-art DNE methods in\nthree typical downstream tasks. Particularly, GloDyNE significantly outperforms\nother methods in the graph reconstruction task, which demonstrates its ability\nof global topology preservation. The source code is available at\nhttps://github.com/houchengbin/GloDyNE\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 05:10:15 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 17:03:38 GMT"}, {"version": "v3", "created": "Thu, 24 Dec 2020 03:25:14 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Hou", "Chengbin", ""], ["Zhang", "Han", ""], ["He", "Shan", ""], ["Tang", "Ke", ""]]}, {"id": "2008.01936", "submitter": "Kangxue Yin", "authors": "Kangxue Yin, Zhiqin Chen, Siddhartha Chaudhuri, Matthew Fisher,\n  Vladimir G. Kim, Hao Zhang", "title": "COALESCE: Component Assembly by Learning to Synthesize Connections", "comments": "20 pages: paper + supplementary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce COALESCE, the first data-driven framework for component-based\nshape assembly which employs deep learning to synthesize part connections. To\nhandle geometric and topological mismatches between parts, we remove the\nmismatched portions via erosion, and rely on a joint synthesis step, which is\nlearned from data, to fill the gap and arrive at a natural and plausible part\njoint. Given a set of input parts extracted from different objects, COALESCE\nautomatically aligns them and synthesizes plausible joints to connect the parts\ninto a coherent 3D object represented by a mesh. The joint synthesis network,\ndesigned to focus on joint regions, reconstructs the surface between the parts\nby predicting an implicit shape representation that agrees with existing parts,\nwhile generating a smooth and topologically meaningful connection. We employ\ntest-time optimization to further ensure that the synthesized joint region\nclosely aligns with the input parts to create realistic component assemblies\nfrom diverse input parts. We demonstrate that our method significantly\noutperforms prior approaches including baseline deep models for 3D shape\nsynthesis, as well as state-of-the-art methods for shape completion.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 05:12:06 GMT"}, {"version": "v2", "created": "Sun, 8 Nov 2020 08:11:55 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Yin", "Kangxue", ""], ["Chen", "Zhiqin", ""], ["Chaudhuri", "Siddhartha", ""], ["Fisher", "Matthew", ""], ["Kim", "Vladimir G.", ""], ["Zhang", "Hao", ""]]}, {"id": "2008.01942", "submitter": "Ke Wang", "authors": "Ke Wang, Siyuan Zhang, Junlan Chen, Fan Ren, Lei Xiao", "title": "A feature-supervised generative adversarial network for environmental\n  monitoring during hazy days", "comments": null, "journal-ref": "Science of the Total Environment (2020),748, 141445", "doi": "10.1016/j.scitotenv.2020.141445", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adverse haze weather condition has brought considerable difficulties in\nvision-based environmental applications. While, until now, most of the existing\nenvironmental monitoring studies are under ordinary conditions, and the studies\nof complex haze weather conditions have been ignored. Thence, this paper\nproposes a feature-supervised learning network based on generative adversarial\nnetworks (GAN) for environmental monitoring during hazy days. Its main idea is\nto train the model under the supervision of feature maps from the ground truth.\nFour key technical contributions are made in the paper. First, pairs of hazy\nand clean images are used as inputs to supervise the encoding process and\nobtain high-quality feature maps. Second, the basic GAN formulation is modified\nby introducing perception loss, style loss, and feature regularization loss to\ngenerate better results. Third, multi-scale images are applied as the input to\nenhance the performance of discriminator. Finally, a hazy remote sensing\ndataset is created for testing our dehazing method and environmental detection.\nExtensive experimental results show that the proposed method has achieved\nbetter performance than current state-of-the-art methods on both synthetic\ndatasets and real-world remote sensing images.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 05:27:15 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wang", "Ke", ""], ["Zhang", "Siyuan", ""], ["Chen", "Junlan", ""], ["Ren", "Fan", ""], ["Xiao", "Lei", ""]]}, {"id": "2008.01951", "submitter": "Hao-Wen Dong", "authors": "Hao-Wen Dong, Ke Chen, Julian McAuley, Taylor Berg-Kirkpatrick", "title": "MusPy: A Toolkit for Symbolic Music Generation", "comments": "Accepted by International Society for Music Information Retrieval\n  Conference (ISMIR), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present MusPy, an open source Python library for symbolic\nmusic generation. MusPy provides easy-to-use tools for essential components in\na music generation system, including dataset management, data I/O, data\npreprocessing and model evaluation. In order to showcase its potential, we\npresent statistical analysis of the eleven datasets currently supported by\nMusPy. Moreover, we conduct a cross-dataset generalizability experiment by\ntraining an autoregressive model on each dataset and measuring held-out\nlikelihood on the others---a process which is made easier by MusPy's dataset\nmanagement system. The results provide a map of domain overlap between various\ncommonly used datasets and show that some datasets contain more representative\ncross-genre samples than others. Along with the dataset analysis, these results\nmight serve as a guide for choosing datasets in future research. Source code\nand documentation are available at https://github.com/salu133445/muspy .\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 06:16:13 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Dong", "Hao-Wen", ""], ["Chen", "Ke", ""], ["McAuley", "Julian", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "2008.01967", "submitter": "Heye Zhang", "authors": "Jingyu Hao and Chengjia Wang and Heye Zhang and Guang Yang", "title": "Annealing Genetic GAN for Minority Oversampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key to overcome class imbalance problems is to capture the distribution\nof minority class accurately. Generative Adversarial Networks (GANs) have shown\nsome potentials to tackle class imbalance problems due to their capability of\nreproducing data distributions given ample training data samples. However, the\nscarce samples of one or more classes still pose a great challenge for GANs to\nlearn accurate distributions for the minority classes. In this work, we propose\nan Annealing Genetic GAN (AGGAN) method, which aims to reproduce the\ndistributions closest to the ones of the minority classes using only limited\ndata samples. Our AGGAN renovates the training of GANs as an evolutionary\nprocess that incorporates the mechanism of simulated annealing. In particular,\nthe generator uses different training strategies to generate multiple offspring\nand retain the best. Then, we use the Metropolis criterion in the simulated\nannealing to decide whether we should update the best offspring for the\ngenerator. As the Metropolis criterion allows a certain chance to accept the\nworse solutions, it enables our AGGAN steering away from the local optimum.\nAccording to both theoretical analysis and experimental studies on multiple\nimbalanced image datasets, we prove that the proposed training strategy can\nenable our AGGAN to reproduce the distributions of minority classes from scarce\nsamples and provide an effective and robust solution for the class imbalance\nproblem.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 07:19:47 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Hao", "Jingyu", ""], ["Wang", "Chengjia", ""], ["Zhang", "Heye", ""], ["Yang", "Guang", ""]]}, {"id": "2008.01972", "submitter": "Jason Fries", "authors": "Jason A. Fries, Ethan Steinberg, Saelig Khattar, Scott L. Fleming,\n  Jose Posada, Alison Callahan, Nigam H. Shah", "title": "Ontology-driven weak supervision for clinical entity classification in\n  electronic health records", "comments": null, "journal-ref": "Nature Communications 12.1 (2021): 1-11", "doi": "10.1038/s41467-021-22328-4", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the electronic health record, using clinical notes to identify entities\nsuch as disorders and their temporality (e.g. the order of an event relative to\na time index) can inform many important analyses. However, creating training\ndata for clinical entity tasks is time consuming and sharing labeled data is\nchallenging due to privacy concerns. The information needs of the COVID-19\npandemic highlight the need for agile methods of training machine learning\nmodels for clinical notes. We present Trove, a framework for weakly supervised\nentity classification using medical ontologies and expert-generated rules. Our\napproach, unlike hand-labeled notes, is easy to share and modify, while\noffering performance comparable to learning from manually labeled training\ndata. In this work, we validate our framework on six benchmark tasks and\ndemonstrate Trove's ability to analyze the records of patients visiting the\nemergency department at Stanford Health Care for COVID-19 presenting symptoms\nand risk factors.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 07:42:09 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 04:11:52 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Fries", "Jason A.", ""], ["Steinberg", "Ethan", ""], ["Khattar", "Saelig", ""], ["Fleming", "Scott L.", ""], ["Posada", "Jose", ""], ["Callahan", "Alison", ""], ["Shah", "Nigam H.", ""]]}, {"id": "2008.01973", "submitter": "Ahmad El Sallab Dr", "authors": "Abdullah Tarek Farag, Ahmed Raafat Abd El-Wahab, Mahmoud Nada, Mohamed\n  Yasser Abd El-Hakeem, Omar Sayed Mahmoud, Reem Khaled Rashwan and Ahmad El\n  Sallab", "title": "MultiCheXNet: A Multi-Task Learning Deep Network For Pneumonia-like\n  Diseases Diagnosis From X-ray Scans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MultiCheXNet, an end-to-end Multi-task learning model, that is\nable to take advantage of different X-rays data sets of Pneumonia-like diseases\nin one neural architecture, performing three tasks at the same time; diagnosis,\nsegmentation and localization. The common encoder in our architecture can\ncapture useful common features present in the different tasks. The common\nencoder has another advantage of efficient computations, which speeds up the\ninference time compared to separate models. The specialized decoders heads can\nthen capture the task-specific features. We employ teacher forcing to address\nthe issue of negative samples that hurt the segmentation and localization\nperformance. Finally,we employ transfer learning to fine tune the classifier on\nunseen pneumonia-like diseases. The MTL architecture can be trained on joint or\ndis-joint labeled data sets. The training of the architecture follows a\ncarefully designed protocol, that pre trains different sub-models on\nspecialized datasets, before being integrated in the joint MTL model. Our\nexperimental setup involves variety of data sets, where the baseline\nperformance of the 3 tasks is compared to the MTL architecture performance.\nMoreover, we evaluate the transfer learning mode to COVID-19 data set,both from\nindividual classifier model, and from MTL architecture classification head.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 07:45:24 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Farag", "Abdullah Tarek", ""], ["El-Wahab", "Ahmed Raafat Abd", ""], ["Nada", "Mahmoud", ""], ["El-Hakeem", "Mohamed Yasser Abd", ""], ["Mahmoud", "Omar Sayed", ""], ["Rashwan", "Reem Khaled", ""], ["Sallab", "Ahmad El", ""]]}, {"id": "2008.01976", "submitter": "Tuomas Oikarinen", "authors": "Tuomas Oikarinen, Tsui-Wei Weng, Luca Daniel", "title": "Robust Deep Reinforcement Learning through Adversarial Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks, including reinforcement learning agents, have been\nproven vulnerable to small adversarial changes in the input, thus making\ndeploying such networks in the real world problematic. In this paper, we\npropose RADIAL-RL, a method to train reinforcement learning agents with\nimproved robustness against any $l_p$-bounded adversarial attack. By simply\nminimizing an upper bound of the loss functions under worst case adversarial\nperturbation derived from efficient robustness verification methods, we\nsignificantly improve robustness of RL-agents trained on Atari-2600 games and\nshow that RADIAL-RL can beat state-of-the-art robust training algorithms when\nevaluated against PGD-attacks. We also propose a new evaluation method, Greedy\nWorst-Case Reward (GWC), for measuring attack agnostic robustness of RL agents.\nGWC can be evaluated efficiently and it serves as a good estimate of the reward\nunder the worst possible sequence of adversarial attacks; in particular, GWC\naccounts for the importance of each action and their temporal dependency,\nimproving upon previous approaches that only evaluate whether each single\naction can change under input perturbations. Our code is available at\nhttps://github.com/tuomaso/radial_rl.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 07:49:42 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Oikarinen", "Tuomas", ""], ["Weng", "Tsui-Wei", ""], ["Daniel", "Luca", ""]]}, {"id": "2008.01989", "submitter": "Sinan Yildirim", "authors": "Nurdan Kuru, \\c{S}. \\.Ilker Birbil, Mert Gurbuzbalaban, and Sinan\n  Yildirim", "title": "Differentially Private Accelerated Optimization Algorithms", "comments": "28 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two classes of differentially private optimization algorithms\nderived from the well-known accelerated first-order methods. The first\nalgorithm is inspired by Polyak's heavy ball method and employs a smoothing\napproach to decrease the accumulated noise on the gradient steps required for\ndifferential privacy. The second class of algorithms are based on Nesterov's\naccelerated gradient method and its recent multi-stage variant. We propose a\nnoise dividing mechanism for the iterations of Nesterov's method in order to\nimprove the error behavior of the algorithm. The convergence rate analyses are\nprovided for both the heavy ball and the Nesterov's accelerated gradient method\nwith the help of the dynamical system analysis techniques. Finally, we conclude\nwith our numerical experiments showing that the presented algorithms have\nadvantages over the well-known differentially private algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 08:23:01 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Kuru", "Nurdan", ""], ["Birbil", "\u015e. \u0130lker", ""], ["Gurbuzbalaban", "Mert", ""], ["Yildirim", "Sinan", ""]]}, {"id": "2008.01992", "submitter": "Ying Cui", "authors": "Ying Cui, Shuaichao Li, Wanqing Zhang", "title": "Jointly Sparse Signal Recovery and Support Recovery via Deep Learning\n  with Applications in MIMO-based Grant-Free Random Access", "comments": "16 pages, 12 figures, to appear in JSAC", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate jointly sparse signal recovery and jointly\nsparse support recovery in Multiple Measurement Vector (MMV) models for complex\nsignals, which arise in many applications in communications and signal\nprocessing. Recent key applications include channel estimation and device\nactivity detection in MIMO-based grant-free random access which is proposed to\nsupport massive machine-type communications (mMTC) for Internet of Things\n(IoT). Utilizing techniques in compressive sensing, optimization and deep\nlearning, we propose two model-driven approaches, based on the standard\nauto-encoder structure for real numbers. One is to jointly design the common\nmeasurement matrix and jointly sparse signal recovery method, and the other\naims to jointly design the common measurement matrix and jointly sparse support\nrecovery method. The proposed model-driven approaches can effectively utilize\nfeatures of sparsity patterns in designing common measurement matrices and\nadjusting model-driven decoders, and can greatly benefit from the underlying\nstate-of-the-art recovery methods with theoretical guarantee. Hence, the\nobtained common measurement matrices and recovery methods can significantly\noutperform the underlying advanced recovery methods. We conduct extensive\nnumerical results on channel estimation and device activity detection in\nMIMO-based grant-free random access. The numerical results show that the\nproposed approaches provide pilot sequences and channel estimation or device\nactivity detection methods which can achieve higher estimation or detection\naccuracy with shorter computation time than existing ones. Furthermore, the\nnumerical results explain how such gains are achieved via the proposed\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 08:26:16 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 06:53:16 GMT"}, {"version": "v3", "created": "Tue, 8 Sep 2020 07:10:01 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Cui", "Ying", ""], ["Li", "Shuaichao", ""], ["Zhang", "Wanqing", ""]]}, {"id": "2008.01994", "submitter": "Philip John Gorinski", "authors": "Yusheng Tian, Philip John Gorinski", "title": "Improving End-to-End Speech-to-Intent Classification with Reptile", "comments": "4 pages + 1 page references, 4 figures, 3 tables, 1 algorithm,\n  accepted for presentation at InterSpeech2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end spoken language understanding (SLU) systems have many advantages\nover conventional pipeline systems, but collecting in-domain speech data to\ntrain an end-to-end system is costly and time consuming. One question arises\nfrom this: how to train an end-to-end SLU with limited amounts of data? Many\nresearchers have explored approaches that make use of other related data\nresources, typically by pre-training parts of the model on high-resource speech\nrecognition. In this paper, we suggest improving the generalization performance\nof SLU models with a non-standard learning algorithm, Reptile. Though Reptile\nwas originally proposed for model-agnostic meta learning, we argue that it can\nalso be used to directly learn a target task and result in better\ngeneralization than conventional gradient descent. In this work, we employ\nReptile to the task of end-to-end spoken intent classification. Experiments on\nfour datasets of different languages and domains show improvement of intent\nprediction accuracy, both when Reptile is used alone and used in addition to\npre-training.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 08:32:15 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Tian", "Yusheng", ""], ["Gorinski", "Philip John", ""]]}, {"id": "2008.01995", "submitter": "Vladimir Puzyrev", "authors": "Vladimir Puzyrev and Chris Elders", "title": "Unsupervised seismic facies classification using deep convolutional\n  autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased size and complexity of seismic surveys, manual labeling of\nseismic facies has become a significant challenge. Application of automatic\nmethods for seismic facies interpretation could significantly reduce the manual\nlabor and subjectivity of a particular interpreter present in conventional\nmethods. A recently emerged group of methods is based on deep neural networks.\nThese approaches are data-driven and require large labeled datasets for network\ntraining. We apply a deep convolutional autoencoder for unsupervised seismic\nfacies classification, which does not require manually labeled examples. The\nfacies maps are generated by clustering the deep-feature vectors obtained from\nthe input data. Our method yields accurate results on real data and provides\nthem instantaneously. The proposed approach opens up possibilities to analyze\ngeological patterns in real time without human intervention.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 08:33:09 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Puzyrev", "Vladimir", ""], ["Elders", "Chris", ""]]}, {"id": "2008.01998", "submitter": "Valentin Li\\'evin", "authors": "Valentin Li\\'evin, Andrea Dittadi, Anders Christensen, Ole Winther", "title": "Optimal Variance Control of the Score Function Gradient Estimator for\n  Importance Weighted Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces novel results for the score function gradient estimator\nof the importance weighted variational bound (IWAE). We prove that in the limit\nof large $K$ (number of importance samples) one can choose the control variate\nsuch that the Signal-to-Noise ratio (SNR) of the estimator grows as $\\sqrt{K}$.\nThis is in contrast to the standard pathwise gradient estimator where the SNR\ndecreases as $1/\\sqrt{K}$. Based on our theoretical findings we develop a novel\ncontrol variate that extends on VIMCO. Empirically, for the training of both\ncontinuous and discrete generative models, the proposed method yields superior\nvariance reduction, resulting in an SNR for IWAE that increases with $K$\nwithout relying on the reparameterization trick. The novel estimator is\ncompetitive with state-of-the-art reparameterization-free gradient estimators\nsuch as Reweighted Wake-Sleep (RWS) and the thermodynamic variational objective\n(TVO) when training generative models.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 08:41:46 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 21:09:28 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Li\u00e9vin", "Valentin", ""], ["Dittadi", "Andrea", ""], ["Christensen", "Anders", ""], ["Winther", "Ole", ""]]}, {"id": "2008.02011", "submitter": "Bo-Yu Chen", "authors": "Bo-Yu Chen, Jordan B. L. Smith, Yi-Hsuan Yang", "title": "Neural Loop Combiner: Neural Network Models for Assessing the\n  Compatibility of Loops", "comments": "Accepted to the 21st International Society for Music Information\n  Retrieval Conference (ISMIR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Music producers who use loops may have access to thousands in loop libraries,\nbut finding ones that are compatible is a time-consuming process; we hope to\nreduce this burden with automation. State-of-the-art systems for estimating\ncompatibility, such as AutoMashUpper, are mostly rule-based and could be\nimproved on with machine learning. To train a model, we need a large set of\nloops with ground truth compatibility values. No such dataset exists, so we\nextract loops from existing music to obtain positive examples of compatible\nloops, and propose and compare various strategies for choosing negative\nexamples. For reproducibility, we curate data from the Free Music Archive.\nUsing this data, we investigate two types of model architectures for estimating\nthe compatibility of loops: one based on a Siamese network, and the other a\npure convolutional neural network (CNN). We conducted a user study in which\nparticipants rated the quality of the combinations suggested by each model, and\nfound the CNN to outperform the Siamese network. Both model-based approaches\noutperformed the rule-based one. We have opened source the code for building\nthe models and the dataset.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 09:16:50 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Chen", "Bo-Yu", ""], ["Smith", "Jordan B. L.", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "2008.02014", "submitter": "Yijiang Lian", "authors": "Yijiang Lian, Zhijie Chen, Xin Pei, Shuang Li, Yifei Wang, Yuefeng\n  Qiu, Zhiheng Zhang, Zhipeng Tao, Liang Yuan, Hanju Guan, Kefeng Zhang,\n  Zhigang Li, Xiaochun Liu", "title": "Optimizing AD Pruning of Sponsored Search with Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial sponsored search system (SSS) can be logically divided into three\nmodules: keywords matching, ad retrieving, and ranking. During ad retrieving,\nthe ad candidates grow exponentially. A query with high commercial value might\nretrieve a great deal of ad candidates such that the ranking module could not\nafford. Due to limited latency and computing resources, the candidates have to\nbe pruned earlier. Suppose we set a pruning line to cut SSS into two parts:\nupstream and downstream. The problem we are going to address is: how to pick\nout the best $K$ items from $N$ candidates provided by the upstream to maximize\nthe total system's revenue. Since the industrial downstream is very complicated\nand updated quickly, a crucial restriction in this problem is that the\nselection scheme should get adapted to the downstream. In this paper, we\npropose a novel model-free reinforcement learning approach to fixing this\nproblem. Our approach considers downstream as a black-box environment, and the\nagent sequentially selects items and finally feeds into the downstream, where\nrevenue would be estimated and used as a reward to improve the selection\npolicy. To the best of our knowledge, this is first time to consider the system\noptimization from a downstream adaption view. It is also the first time to use\nreinforcement learning techniques to tackle this problem. The idea has been\nsuccessfully realized in Baidu's sponsored search system, and online long time\nA/B test shows remarkable improvements on revenue.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 09:19:10 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Lian", "Yijiang", ""], ["Chen", "Zhijie", ""], ["Pei", "Xin", ""], ["Li", "Shuang", ""], ["Wang", "Yifei", ""], ["Qiu", "Yuefeng", ""], ["Zhang", "Zhiheng", ""], ["Tao", "Zhipeng", ""], ["Yuan", "Liang", ""], ["Guan", "Hanju", ""], ["Zhang", "Kefeng", ""], ["Li", "Zhigang", ""], ["Liu", "Xiaochun", ""]]}, {"id": "2008.02027", "submitter": "Yunpeng Li", "authors": "Yunpeng Li, Beat Gfeller, Marco Tagliasacchi, Dominik Roblek", "title": "Learning to Denoise Historical Music", "comments": "ISMIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an audio-to-audio neural network model that learns to denoise old\nmusic recordings. Our model internally converts its input into a time-frequency\nrepresentation by means of a short-time Fourier transform (STFT), and processes\nthe resulting complex spectrogram using a convolutional neural network. The\nnetwork is trained with both reconstruction and adversarial objectives on a\nsynthetic noisy music dataset, which is created by mixing clean music with real\nnoise samples extracted from quiet segments of old recordings. We evaluate our\nmethod quantitatively on held-out test examples of the synthetic dataset, and\nqualitatively by human rating on samples of actual historical recordings. Our\nresults show that the proposed method is effective in removing noise, while\npreserving the quality and details of the original music.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 10:05:44 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Li", "Yunpeng", ""], ["Gfeller", "Beat", ""], ["Tagliasacchi", "Marco", ""], ["Roblek", "Dominik", ""]]}, {"id": "2008.02030", "submitter": "Sebastian Guendel", "authors": "Sebastian Guendel, Arnaud Arindra Adiyoso Setio, Sasa Grbic, Andreas\n  Maier, Dorin Comaniciu", "title": "Extracting and Leveraging Nodule Features with Lung Inpainting for Local\n  Feature Augmentation", "comments": "Accepted at MICCAI MLMI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chest X-ray (CXR) is the most common examination for fast detection of\npulmonary abnormalities. Recently, automated algorithms have been developed to\nclassify multiple diseases and abnormalities in CXR scans. However, because of\nthe limited availability of scans containing nodules and the subtle properties\nof nodules in CXRs, state-of-the-art methods do not perform well on nodule\nclassification. To create additional data for the training process, standard\naugmentation techniques are applied. However, the variance introduced by these\nmethods are limited as the images are typically modified globally. In this\npaper, we propose a method for local feature augmentation by extracting local\nnodule features using a generative inpainting network. The network is applied\nto generate realistic, healthy tissue and structures in patches containing\nnodules. The nodules are entirely removed in the inpainted representation. The\nextraction of the nodule features is processed by subtraction of the inpainted\npatch from the nodule patch. With arbitrary displacement of the extracted\nnodules in the lung area across different CXR scans and further local\nmodifications during training, we significantly increase the nodule\nclassification performance and outperform state-of-the-art augmentation\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 10:13:41 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Guendel", "Sebastian", ""], ["Setio", "Arnaud Arindra Adiyoso", ""], ["Grbic", "Sasa", ""], ["Maier", "Andreas", ""], ["Comaniciu", "Dorin", ""]]}, {"id": "2008.02033", "submitter": "Jin Wang", "authors": "Jin Wang, Jia Hu, Geyong Min, Albert Y. Zomaya, Nektarios Georgalas", "title": "Fast Adaptive Task Offloading in Edge Computing based on Meta\n  Reinforcement Learning", "comments": "Accepted by IEEE Transaction on Parallel and Distributed Systems", "journal-ref": null, "doi": "10.1109/TPDS.2020.3014896", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-access edge computing (MEC) aims to extend cloud service to the network\nedge to reduce network traffic and service latency. A fundamental problem in\nMEC is how to efficiently offload heterogeneous tasks of mobile applications\nfrom user equipment (UE) to MEC hosts. Recently, many deep reinforcement\nlearning (DRL) based methods have been proposed to learn offloading policies\nthrough interacting with the MEC environment that consists of UE, wireless\nchannels, and MEC hosts. However, these methods have weak adaptability to new\nenvironments because they have low sample efficiency and need full retraining\nto learn updated policies for new environments. To overcome this weakness, we\npropose a task offloading method based on meta reinforcement learning, which\ncan adapt fast to new environments with a small number of gradient updates and\nsamples. We model mobile applications as Directed Acyclic Graphs (DAGs) and the\noffloading policy by a custom sequence-to-sequence (seq2seq) neural network. To\nefficiently train the seq2seq network, we propose a method that synergizes the\nfirst order approximation and clipped surrogate objective. The experimental\nresults demonstrate that this new offloading method can reduce the latency by\nup to 25% compared to three baselines while being able to adapt fast to new\nenvironments.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 10:16:25 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 09:15:59 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 11:05:41 GMT"}, {"version": "v4", "created": "Mon, 14 Sep 2020 14:58:59 GMT"}, {"version": "v5", "created": "Sat, 24 Oct 2020 10:04:20 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Wang", "Jin", ""], ["Hu", "Jia", ""], ["Min", "Geyong", ""], ["Zomaya", "Albert Y.", ""], ["Georgalas", "Nektarios", ""]]}, {"id": "2008.02043", "submitter": "Jonghwa Yim", "authors": "Jonghwa Yim, Sang Hwan Kim", "title": "Learning Boost by Exploiting the Auxiliary Task in Multi-task Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning two tasks in a single shared function has some benefits. Firstly by\nacquiring information from the second task, the shared function leverages\nuseful information that could have been neglected or underestimated in the\nfirst task. Secondly, it helps to generalize the function that can be learned\nusing generally applicable information for both tasks. To fully enjoy these\nbenefits, Multi-task Learning (MTL) has long been researched in various domains\nsuch as computer vision, language understanding, and speech synthesis. While\nMTL benefits from the positive transfer of information from multiple tasks, in\na real environment, tasks inevitably have a conflict between them during the\nlearning phase, called negative transfer. The negative transfer hampers\nfunction from achieving the optimality and degrades the performance. To solve\nthe problem of the task conflict, previous works only suggested partial\nsolutions that are not fundamental, but ad-hoc. A common approach is using a\nweighted sum of losses. The weights are adjusted to induce positive transfer.\nParadoxically, this kind of solution acknowledges the problem of negative\ntransfer and cannot remove it unless the weight of the task is set to zero.\nTherefore, these previous methods had limited success. In this paper, we\nintroduce a novel approach that can drive positive transfer and suppress\nnegative transfer by leveraging class-wise weights in the learning process. The\nweights act as an arbitrator of the fundamental unit of information to\ndetermine its positive or negative status to the main task.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 10:56:56 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Yim", "Jonghwa", ""], ["Kim", "Sang Hwan", ""]]}, {"id": "2008.02046", "submitter": "Peter Rousseeuw", "authors": "Joachim Schreurs, Iwein Vranckx, Mia Hubert, Johan A.K. Suykens, Peter\n  J. Rousseeuw", "title": "Outlier detection in non-elliptical data by kernel MRCD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimum regularized covariance determinant method (MRCD) is a robust\nestimator for multivariate location and scatter, which detects outliers by\nfitting a robust covariance matrix to the data. Its regularization ensures that\nthe covariance matrix is well-conditioned in any dimension. The MRCD assumes\nthat the non-outlying observations are roughly elliptically distributed, but\nmany datasets are not of that form. Moreover, the computation time of MRCD\nincreases substantially when the number of variables goes up, and nowadays\ndatasets with many variables are common. The proposed Kernel Minimum\nRegularized Covariance Determinant (KMRCD) estimator addresses both issues. It\nis not restricted to elliptical data because it implicitly computes the MRCD\nestimates in a kernel induced feature space. A fast algorithm is constructed\nthat starts from kernel-based initial estimates and exploits the kernel trick\nto speed up the subsequent computations. Based on the KMRCD estimates, a rule\nis proposed to flag outliers. The KMRCD algorithm performs well in simulations,\nand is illustrated on real-life data.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 11:09:08 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 22:23:14 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Schreurs", "Joachim", ""], ["Vranckx", "Iwein", ""], ["Hubert", "Mia", ""], ["Suykens", "Johan A. K.", ""], ["Rousseeuw", "Peter J.", ""]]}, {"id": "2008.02063", "submitter": "Amir Shirian", "authors": "A. Shirian, T. Guha", "title": "Compact Graph Architecture for Speech Emotion Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep graph approach to address the task of speech emotion\nrecognition. A compact, efficient and scalable way to represent data is in the\nform of graphs. Following the theory of graph signal processing, we propose to\nmodel speech signal as a cycle graph or a line graph. Such graph structure\nenables us to construct a Graph Convolution Network (GCN)-based architecture\nthat can perform an accurate graph convolution in contrast to the approximate\nconvolution used in standard GCNs. We evaluated the performance of our model\nfor speech emotion recognition on the popular IEMOCAP and MSP-IMPROV databases.\nOur model outperforms standard GCN and other relevant deep graph architectures\nindicating the effectiveness of our approach. When compared with existing\nspeech emotion recognition methods, our model achieves comparable performance\nto the state-of-the-art with significantly fewer learnable parameters (~30K)\nindicating its applicability in resource-constrained devices.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 12:09:09 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 12:42:52 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 14:08:11 GMT"}, {"version": "v4", "created": "Tue, 2 Feb 2021 10:34:47 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Shirian", "A.", ""], ["Guha", "T.", ""]]}, {"id": "2008.02066", "submitter": "Ozsel Kilinc", "authors": "Ozsel Kilinc, Giovanni Montana", "title": "Follow the Object: Curriculum Learning for Manipulation Tasks with\n  Imagined Goals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning robot manipulation through deep reinforcement learning in\nenvironments with sparse rewards is a challenging task. In this paper we\naddress this problem by introducing a notion of imaginary object goals. For a\ngiven manipulation task, the object of interest is first trained to reach a\ndesired target position on its own, without being manipulated, through\nphysically realistic simulations. The object policy is then leveraged to build\na predictive model of plausible object trajectories providing the robot with a\ncurriculum of incrementally more difficult object goals to reach during\ntraining. The proposed algorithm, Follow the Object (FO), has been evaluated on\n7 MuJoCo environments requiring increasing degree of exploration, and has\nachieved higher success rates compared to alternative algorithms. In\nparticularly challenging learning scenarios, e.g. where the object's initial\nand target positions are far apart, our approach can still learn a policy\nwhereas competing methods currently fail.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 12:19:14 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Kilinc", "Ozsel", ""], ["Montana", "Giovanni", ""]]}, {"id": "2008.02067", "submitter": "Homayoun Valafar", "authors": "Homayoun Valafar, Faramarz Valafar, Okan Ersoy", "title": "Parallel, Self Organizing, Consensus Neural Networks", "comments": "4 pages", "journal-ref": "Published in IEEE-IJCNN 1999 1225-1228", "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new neural network architecture (PSCNN) is developed to improve performance\nand speed of such networks. The architecture has all the advantages of the\nprevious models such as self-organization and possesses some other superior\ncharacteristics such as input parallelism and decision making based on\nconsensus. Due to the properties of this network, it was studied with respect\nto implementation on a Parallel Processor (Ncube Machine) as well as a regular\nsequential machine. The architecture self organizes its own modules in a way to\nmaximize performance. Since it is completely parallel, both recall and learning\nprocedures are very fast. The performance of the network was compared to the\nBackpropagation networks in problems of language perception, remote sensing and\nbinary logic (Exclusive-Or). PSCNN showed superior performance in all cases\nstudied.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 21:02:10 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Valafar", "Homayoun", ""], ["Valafar", "Faramarz", ""], ["Ersoy", "Okan", ""]]}, {"id": "2008.02069", "submitter": "Gabriel Meseguer-Brocal", "authors": "Gabriel Meseguer-Brocal, Rachel Bittner, Simon Durand and Brian Brost", "title": "Data Cleansing with Contrastive Learning for Vocal Note Event\n  Annotations", "comments": "21st International Society for Music Information Retrieval Conference\n  11-15 October 2020, Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Data cleansing is a well studied strategy for cleaning erroneous labels in\ndatasets, which has not yet been widely adopted in Music Information Retrieval.\nPreviously proposed data cleansing models do not consider structured (e.g. time\nvarying) labels, such as those common to music data. We propose a novel data\ncleansing model for time-varying, structured labels which exploits the local\nstructure of the labels, and demonstrate its usefulness for vocal note event\nannotations in music. %Our model is trained in a contrastive learning manner by\nautomatically creating local deformations of likely correct labels. Our model\nis trained in a contrastive learning manner by automatically contrasting likely\ncorrect labels pairs against local deformations of them. We demonstrate that\nthe accuracy of a transcription model improves greatly when trained using our\nproposed strategy compared with the accuracy when trained using the original\ndataset. Additionally we use our model to estimate the annotation error rates\nin the DALI dataset, and highlight other potential uses for this type of model.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 12:24:37 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 10:15:04 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 10:19:17 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Meseguer-Brocal", "Gabriel", ""], ["Bittner", "Rachel", ""], ["Durand", "Simon", ""], ["Brost", "Brian", ""]]}, {"id": "2008.02070", "submitter": "Gabriel Meseguer-Brocal", "authors": "Gabriel Meseguer-Brocal, Geoffroy Peeters", "title": "Content based singing voice source separation via strong conditioning\n  using aligned phonemes", "comments": "21st International Society for Music Information Retrieval Conference\n  11-15 October 2020, Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Informed source separation has recently gained renewed interest with the\nintroduction of neural networks and the availability of large multitrack\ndatasets containing both the mixture and the separated sources. These\napproaches use prior information about the target source to improve separation.\nHistorically, Music Information Retrieval researchers have focused primarily on\nscore-informed source separation, but more recent approaches explore\nlyrics-informed source separation. However, because of the lack of multitrack\ndatasets with time-aligned lyrics, models use weak conditioning with\nnon-aligned lyrics. In this paper, we present a multimodal multitrack dataset\nwith lyrics aligned in time at the word level with phonetic information as well\nas explore strong conditioning using the aligned phonemes. Our model follows a\nU-Net architecture and takes as input both the magnitude spectrogram of a\nmusical mixture and a matrix with aligned phonetic information. The phoneme\nmatrix is embedded to obtain the parameters that control Feature-wise Linear\nModulation (FiLM) layers. These layers condition the U-Net feature maps to\nadapt the separation process to the presence of different phonemes via affine\ntransformations. We show that phoneme conditioning can be successfully applied\nto improve singing voice source separation.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 12:25:24 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Meseguer-Brocal", "Gabriel", ""], ["Peeters", "Geoffroy", ""]]}, {"id": "2008.02072", "submitter": "Homayoun Valafar", "authors": "Faramarz Valafar, Homayoun Valafar", "title": "A Comparative study of Artificial Neural Networks Using Reinforcement\n  learning and Multidimensional Bayesian Classification Using Parzen Density\n  Estimation for Identification of GC-EIMS Spectra of Partially Methylated\n  Alditol Acetates", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": "Published in IEEE-ICAI 1999 554-558", "categories": "eess.SP cs.LG cs.NE q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study reports the development of a pattern recognition search engine for\na World Wide Web-based database of gas chromatography-electron impact mass\nspectra (GC-EIMS) of partially methylated Alditol Acetates (PMAAs). Here, we\nalso report comparative results for two pattern recognition techniques that\nwere employed for this study. The first technique is a statistical technique\nusing Bayesian classifiers and Parzen density estimators. The second technique\ninvolves an artificial neural network module trained with reinforcement\nlearning. We demonstrate here that both systems perform well in identifying\nspectra with small amounts of noise. Both system's performance degrades with\ndegrading signal-to-noise ratio (SNR). When dealing with partial spectra\n(missing data), the artificial neural network system performs better. The\ndeveloped system is implemented on the world wide web, and is intended to\nidentify PMAAs using submitted spectra of these molecules recorded on any\nGC-EIMS instrument. The system, therefore, is insensitive to instrument and\ncolumn dependent variations in GC-EIMS spectra.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 17:54:51 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Valafar", "Faramarz", ""], ["Valafar", "Homayoun", ""]]}, {"id": "2008.02076", "submitter": "Dou Yan Liu Goodman", "authors": "Dou Goodman, Hao Xin", "title": "Attacking and Defending Machine Learning Applications of Public Cloud", "comments": "arXiv admin note: text overlap with arXiv:1704.05051 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attack breaks the boundaries of traditional security defense. For\nadversarial attack and the characteristics of cloud services, we propose\nSecurity Development Lifecycle for Machine Learning applications, e.g., SDL for\nML. The SDL for ML helps developers build more secure software by reducing the\nnumber and severity of vulnerabilities in ML-as-a-service, while reducing\ndevelopment cost.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 14:00:31 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Goodman", "Dou", ""], ["Xin", "Hao", ""]]}, {"id": "2008.02087", "submitter": "Jiangwei Zhang", "authors": "Jiangwei Zhang, Li Zhang, Vigneshwaran Raveendran, Ziv Ben-Zuk, and\n  Leonard Lu", "title": "PriceAggregator: An Intelligent System for Hotel Price Fetching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the hotel price aggregation system - PriceAggregator,\ndeployed at Agoda, a global online travel agency for hotels, vacation rentals,\nflights and airport transfer. Agoda aggregates non-direct suppliers' hotel\nrooms to ensure that Agoda's customers always have the widest selection of\nhotels, room types and packages. As of today, Agoda aggregates millions of\nhotels. The major challenge is that each supplier only allows Agoda to fetch\nfor the hotel price with a limited amount of Queries Per Second (QPS). Due to\nthe sheer volume of Agoda's user search traffic, this limited amount of QPS is\nnever enough to cover all user searches. Inevitably, many user searches have to\nbe ignored. Hence, booking lost. To overcome the challenge, we built\nPriceAggregator. PriceAggregator intelligently determines when, how and what to\nsend to the suppliers to fetch for price. In this paper, we not only prove\nPriceAggregator is optimal theoretically but also demonstrate that\nPriceAggregator performs well in practice. PriceAggregator has been deployed in\nAgoda. Extensive online A/B experimentation have shown that PriceAggregator\nincreases Agoda's bookings significantly.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 01:28:25 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Zhang", "Jiangwei", ""], ["Zhang", "Li", ""], ["Raveendran", "Vigneshwaran", ""], ["Ben-Zuk", "Ziv", ""], ["Lu", "Leonard", ""]]}, {"id": "2008.02093", "submitter": "Duncan Tilley", "authors": "Duncan Tilley, Christopher W. Cleghorn, Kshitij Thorat, Roger Deane", "title": "Point Proposal Network: Accelerating Point Source Detection Through Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point source detection techniques are used to identify and localise point\nsources in radio astronomical surveys. With the development of the Square\nKilometre Array (SKA) telescope, survey images will see a massive increase in\nsize from Gigapixels to Terapixels. Point source detection has already proven\nto be a challenge in recent surveys performed by SKA pathfinder telescopes.\nThis paper proposes the Point Proposal Network (PPN): a point source detector\nthat utilises deep convolutional neural networks for fast source detection.\nResults measured on simulated MeerKAT images show that, although less precise\nwhen compared to leading alternative approaches, PPN performs source detection\nfaster and is able to scale to large images, unlike the alternative approaches.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 12:54:04 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 13:40:28 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Tilley", "Duncan", ""], ["Cleghorn", "Christopher W.", ""], ["Thorat", "Kshitij", ""], ["Deane", "Roger", ""]]}, {"id": "2008.02107", "submitter": "Gemma Roig", "authors": "Kshitij Dwivedi, Jiahui Huang, Radoslaw Martin Cichy, Gemma Roig", "title": "Duality Diagram Similarity: a generic framework for initialization\n  selection in task transfer learning", "comments": "accepted at ECCV 2020. Code available here:\n  https://github.com/cvai-repo/duality-diagram-similarity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we tackle an open research question in transfer learning,\nwhich is selecting a model initialization to achieve high performance on a new\ntask, given several pre-trained models. We propose a new highly efficient and\naccurate approach based on duality diagram similarity (DDS) between deep neural\nnetworks (DNNs). DDS is a generic framework to represent and compare data of\ndifferent feature dimensions. We validate our approach on the Taskonomy dataset\nby measuring the correspondence between actual transfer learning performance\nrankings on 17 taskonomy tasks and predicted rankings. Computing DDS based\nranking for $17\\times17$ transfers requires less than 2 minutes and shows a\nhigh correlation ($0.86$) with actual transfer learning rankings, outperforming\nstate-of-the-art methods by a large margin ($10\\%$) on the Taskonomy benchmark.\nWe also demonstrate the robustness of our model selection approach to a new\ntask, namely Pascal VOC semantic segmentation. Additionally, we show that our\nmethod can be applied to select the best layer locations within a DNN for\ntransfer learning on 2D, 3D and semantic tasks on NYUv2 and Pascal VOC\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 13:00:34 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Dwivedi", "Kshitij", ""], ["Huang", "Jiahui", ""], ["Cichy", "Radoslaw Martin", ""], ["Roig", "Gemma", ""]]}, {"id": "2008.02122", "submitter": "Jingxing Jiang", "authors": "Jingxing Jiang, Zhubin Wang, Fei Fang, Binqiang Zhao", "title": "TPG-DNN: A Method for User Intent Prediction Based on Total Probability\n  Formula and GRU Loss with Multi-task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The E-commerce platform has become the principal battleground where people\nsearch, browse and pay for whatever they want. Critical as is to improve the\nonline shopping experience for customers and merchants, how to find a proper\napproach for user intent prediction are paid great attention in both industry\nand academia. In this paper, we propose a novel user intent prediction model,\nTPG-DNN, to complete the challenging task, which is based on adaptive gated\nrecurrent unit (GRU) loss function with multi-task learning. We creatively use\nthe GRU structure and total probability formula as the loss function to model\nthe users' whole online purchase process. Besides, the multi-task weight\nadjustment mechanism can make the final loss function dynamically adjust the\nimportance between different tasks through data variance. According to the test\nresult of experiments conducted on Taobao daily and promotion data sets, the\nproposed model performs much better than existing click through rate (CTR)\nmodels. At present, the proposed user intent prediction model has been widely\nused for the coupon allocation, advertisement and recommendation on Taobao\nplatform, which greatly improve the user experience and shopping efficiency,\nand benefit the gross merchandise volume (GMV) promotion as well.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 13:25:53 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Jiang", "Jingxing", ""], ["Wang", "Zhubin", ""], ["Fang", "Fei", ""], ["Zhao", "Binqiang", ""]]}, {"id": "2008.02144", "submitter": "Seyedeh Fatemeh Razavi", "authors": "Seyedeh Fatemeh Razavi and Reshad Hosseini", "title": "FRMDN: Flow-based Recurrent Mixture Density Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Mixture Density Networks (RMDNs) are consisted of two main parts: a\nRecurrent Neural Network (RNN) and a Gaussian Mixture Model (GMM), in which a\nkind of RNN (almost LSTM) is used to find the parameters of a GMM in every time\nstep. While available RMDNs have been faced with different difficulties. The\nmost important of them is high$-$dimensional problems. Since estimating the\ncovariance matrix for the high$-$dimensional problems is more difficult, due to\nexisting correlation between dimensions and satisfying the positive definition\ncondition. Consequently, the available methods have usually used RMDN with a\ndiagonal covariance matrix for high$-$dimensional problems by supposing\nindependence among dimensions. Hence, in this paper with inspiring a common\napproach in the literature of GMM, we consider a tied configuration for each\nprecision matrix (inverse of the covariance matrix) in RMDN as $(\\(\\Sigma _k^{\n- 1} = U{D_k}U\\))$ to enrich GMM rather than considering a diagonal form for\nit. But due to simplicity, we assume $\\(U\\)$ be an Identity matrix and\n$\\(D_k\\)$ is a specific diagonal matrix for $\\(k^{th}\\)$ component. Until now,\nwe only have a diagonal matrix and it does not differ with available diagonal\nRMDNs. Besides, Flow$-$based neural networks are a new group of generative\nmodels that are able to transform a distribution to a simpler distribution and\nvice versa, through a sequence of invertible functions. Therefore, we applied a\ndiagonal GMM on transformed observations. At every time step, the next\nobservation, $\\({y_{t + 1}}\\)$, has been passed through a flow$-$based neural\nnetwork to obtain a much simpler distribution. Experimental results for a\nreinforcement learning problem verify the superiority of the proposed method to\nthe base$-$line method in terms of Negative Log$-$Likelihood (NLL) for RMDN and\nthe cumulative reward for a controller with fewer population size.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 14:05:37 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Razavi", "Seyedeh Fatemeh", ""], ["Hosseini", "Reshad", ""]]}, {"id": "2008.02150", "submitter": "Rula Amer M.Sc", "authors": "Rula Amer, Maayan Frid-Adar, Ophir Gozes, Jannette Nassar, Hayit\n  Greenspan", "title": "COVID-19 in CXR: from Detection and Severity Scoring to Patient Disease\n  Monitoring", "comments": "paper was accepted to JBHI IEEE journal", "journal-ref": "IEEE J Biomed Health Inform. 2021 Mar 26;PP", "doi": "10.1109/JBHI.2021.3069169", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we estimate the severity of pneumonia in COVID-19 patients and\nconduct a longitudinal study of disease progression. To achieve this goal, we\ndeveloped a deep learning model for simultaneous detection and segmentation of\npneumonia in chest Xray (CXR) images and generalized to COVID-19 pneumonia. The\nsegmentations were utilized to calculate a \"Pneumonia Ratio\" which indicates\nthe disease severity. The measurement of disease severity enables to build a\ndisease extent profile over time for hospitalized patients. To validate the\nmodel relevance to the patient monitoring task, we developed a validation\nstrategy which involves a synthesis of Digital Reconstructed Radiographs (DRRs\n- synthetic Xray) from serial CT scans; we then compared the disease\nprogression profiles that were generated from the DRRs to those that were\ngenerated from CT volumes.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 13:50:35 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 09:37:30 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Amer", "Rula", ""], ["Frid-Adar", "Maayan", ""], ["Gozes", "Ophir", ""], ["Nassar", "Jannette", ""], ["Greenspan", "Hayit", ""]]}, {"id": "2008.02159", "submitter": "Wanxin Jin", "authors": "Wanxin Jin, Todd D. Murphey, Dana Kuli\\'c, Neta Ezer, Shaoshuai Mou", "title": "Learning from Sparse Demonstrations", "comments": "Please find video demos at https://wanxinjin.github.io/posts/lfsd", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an approach which enables a robot to learn an objective\nfunction from sparse demonstrations of an expert. The demonstrations are given\nby a small number of sparse waypoints; the waypoints are desired outputs of the\nrobot's trajectory at certain time instances, sparsely located within a\ndemonstration time horizon. The duration of the expert's demonstration may be\ndifferent from the actual duration of the robot's execution. The proposed\nmethod enables to jointly learn an objective function and a time-warping\nfunction such that the robot's reproduced trajectory has minimal distance to\nthe sparse demonstration waypoints. Unlike existing inverse reinforcement\nlearning techniques, the proposed approach uses the differential Pontryagin's\nmaximum principle, which allows direct minimization of the distance between the\nrobot's trajectory and the sparse demonstration waypoints and enables\nsimultaneous learning of an objective function and a time-warping function. We\ndemonstrate the effectiveness of the proposed approach in various simulated\nscenarios. We apply the method to learn motion planning/control of a 6-DoF\nmaneuvering unmanned aerial vehicle (UAV) and a robot arm in environments with\nobstacles. The results show that a robot is able to learn a valid objective\nfunction to avoid obstacles with few demonstrated waypoints.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 14:25:39 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Jin", "Wanxin", ""], ["Murphey", "Todd D.", ""], ["Kuli\u0107", "Dana", ""], ["Ezer", "Neta", ""], ["Mou", "Shaoshuai", ""]]}, {"id": "2008.02171", "submitter": "Cedric Schockaert", "authors": "Cedric Schockaert", "title": "A Causal-based Framework for Multimodal Multivariate Time Series\n  Validation Enhanced by Unsupervised Deep Learning as an Enabler for Industry\n  4.0", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An advanced conceptual validation framework for multimodal multivariate time\nseries defines a multi-level contextual anomaly detection ranging from an\nunivariate context definition, to a multimodal abstract context representation\nlearnt by an Autoencoder from heterogeneous data (images, time series, sounds,\netc.) associated to an industrial process. Each level of the framework is\neither applicable to historical data and/or live data. The ultimate level is\nbased on causal discovery to identify causal relations in observational data in\norder to exclude biased data to train machine learning models and provide means\nto the domain expert to discover unknown causal relations in the underlying\nprocess represented by the data sample. A Long Short-Term Memory Autoencoder is\nsuccessfully evaluated on multivariate time series to validate the learnt\nrepresentation of abstract contexts associated to multiple assets of a blast\nfurnace. A research roadmap is identified to combine causal discovery and\nrepresentation learning as an enabler for unsupervised Root Cause Analysis\napplied to the process industry.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 14:48:02 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Schockaert", "Cedric", ""]]}, {"id": "2008.02186", "submitter": "Hossein Shahabadi Farahani", "authors": "Hossein Shahabadi Farahani, Alireza Fatehi, Alireza Nadali and Mahdi\n  Aliyari Shoorehdeli", "title": "A Novel Method For Designing Transferable Soft Sensors And Its\n  Application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a new approach is proposed for designing transferable soft\nsensors. Soft sensing is one of the significant applications of data-driven\nmethods in the condition monitoring of plants. While hard sensors can be easily\nused in various plants, soft sensors are confined to the specific plant they\nare designed for and cannot be used in a new plant or even used in some new\nworking conditions in the same plant. In this paper, a solution is proposed for\nthis underlying obstacle in data-driven condition monitoring systems.\nData-driven methods suffer from the fact that the distribution of the data by\nwhich the models are constructed may not be the same as the distribution of the\ndata to which the model will be applied. This ultimately leads to the decline\nof models accuracy. We proposed a new transfer learning (TL) based regression\nmethod, called Domain Adversarial Neural Network Regression (DANN-R), and\nemployed it for designing transferable soft sensors. We used data collected\nfrom the SCADA system of an industrial power plant to comprehensively\ninvestigate the functionality of the proposed method. The result reveals that\nthe proposed transferable soft sensor can successfully adapt to new plants.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 15:20:03 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 20:58:06 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Farahani", "Hossein Shahabadi", ""], ["Fatehi", "Alireza", ""], ["Nadali", "Alireza", ""], ["Shoorehdeli", "Mahdi Aliyari", ""]]}, {"id": "2008.02191", "submitter": "Siddharth Ancha", "authors": "Siddharth Ancha, Yaadhav Raaj, Peiyun Hu, Srinivasa G. Narasimhan,\n  David Held", "title": "Active Perception using Light Curtains for Autonomous Driving", "comments": "Published at the European Conference on Computer Vision (ECCV), 2020", "journal-ref": null, "doi": "10.1007/978-3-030-58558-7_44", "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most real-world 3D sensors such as LiDARs perform fixed scans of the entire\nenvironment, while being decoupled from the recognition system that processes\nthe sensor data. In this work, we propose a method for 3D object recognition\nusing light curtains, a resource-efficient controllable sensor that measures\ndepth at user-specified locations in the environment. Crucially, we propose\nusing prediction uncertainty of a deep learning based 3D point cloud detector\nto guide active perception. Given a neural network's uncertainty, we derive an\noptimization objective to place light curtains using the principle of\nmaximizing information gain. Then, we develop a novel and efficient\noptimization algorithm to maximize this objective by encoding the physical\nconstraints of the device into a constraint graph and optimizing with dynamic\nprogramming. We show how a 3D detector can be trained to detect objects in a\nscene by sequentially placing uncertainty-guided light curtains to successively\nimprove detection accuracy. Code and details can be found on the project\nwebpage: http://siddancha.github.io/projects/active-perception-light-curtains.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 15:38:18 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Ancha", "Siddharth", ""], ["Raaj", "Yaadhav", ""], ["Hu", "Peiyun", ""], ["Narasimhan", "Srinivasa G.", ""], ["Held", "David", ""]]}, {"id": "2008.02195", "submitter": "Alexandros-Apostolos Boulogeorgos", "authors": "Alexandros-Apostolos A. Boulogeorgos, Stylianos E. Trevlakis, Sotiris\n  A. Tegos, Vasilis K. Papanikolaou, and George K. Karagiannidis", "title": "Machine Learning in Nano-Scale Biomedical Engineering", "comments": "27 pages, 15 figures, 1 table, Journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.ET eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) empowers biomedical systems with the capability to\noptimize their performance through modeling of the available data extremely\nwell, without using strong assumptions about the modeled system. Especially in\nnano-scale biosystems, where the generated data sets are too vast and complex\nto mentally parse without computational assist, ML is instrumental in analyzing\nand extracting new insights, accelerating material and structure discoveries,\nand designing experience as well as supporting nano-scale communications and\nnetworks. However, despite these efforts, the use of ML in nano-scale\nbiomedical engineering remains still under-explored in certain areas and\nresearch challenges are still open in fields such as structure and material\ndesign and simulations, communications and signal processing, and bio-medicine\napplications. In this article, we review the existing research regarding the\nuse of ML in nano-scale biomedical engineering. In more detail, we first\nidentify and discuss the main challenges that can be formulated as ML problems.\nThese challenges are classified into the three aforementioned main categories.\nNext, we discuss the state of the art ML methodologies that are used to\ncountermeasure the aforementioned challenges. For each of the presented\nmethodologies, special emphasis is given to its principles, applications, and\nlimitations. Finally, we conclude the article with insightful discussions, that\nreveal research gaps and highlight possible future research directions.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 15:45:54 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 14:58:20 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Boulogeorgos", "Alexandros-Apostolos A.", ""], ["Trevlakis", "Stylianos E.", ""], ["Tegos", "Sotiris A.", ""], ["Papanikolaou", "Vasilis K.", ""], ["Karagiannidis", "George K.", ""]]}, {"id": "2008.02196", "submitter": "Peilun Wu", "authors": "Peilun Wu, Nour Moustafa, Shiyi Yang, Hui Guo", "title": "Densely Connected Residual Network for Attack Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High false alarm rate and low detection rate are the major sticking points\nfor unknown threat perception. To address the problems, in the paper, we\npresent a densely connected residual network (Densely-ResNet) for attack\nrecognition. Densely-ResNet is built with several basic residual units, where\neach of them consists of a series of Conv-GRU subnets by wide connections. Our\nevaluation shows that Densely-ResNet can accurately discover various unknown\nthreats that appear in edge, fog and cloud layers and simultaneously maintain a\nmuch lower false alarm rate than existing algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 15:50:22 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Wu", "Peilun", ""], ["Moustafa", "Nour", ""], ["Yang", "Shiyi", ""], ["Guo", "Hui", ""]]}, {"id": "2008.02200", "submitter": "Howard Heaton", "authors": "Howard Heaton, Samy Wu Fung, Alex Tong Lin, Stanley Osher, Wotao Yin", "title": "Wasserstein-based Projections with Applications to Inverse Problems", "comments": "Revised version uploaded on April 14, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse problems consist of recovering a signal from a collection of noisy\nmeasurements. These are typically cast as optimization problems, with classic\napproaches using a data fidelity term and an analytic regularizer that\nstabilizes recovery. Recent Plug-and-Play (PnP) works propose replacing the\noperator for analytic regularization in optimization methods by a data-driven\ndenoiser. These schemes obtain state of the art results, but at the cost of\nlimited theoretical guarantees. To bridge this gap, we present a new algorithm\nthat takes samples from the manifold of true data as input and outputs an\napproximation of the projection operator onto this manifold. Under standard\nassumptions, we prove this algorithm generates a learned operator, called\nWasserstein-based projection (WP), that approximates the true projection with\nhigh probability. Thus, WPs can be inserted into optimization methods in the\nsame manner as PnP, but now with theoretical guarantees. Provided numerical\nexamples show WPs obtain state of the art results for unsupervised PnP signal\nrecovery.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 15:58:55 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 17:29:35 GMT"}, {"version": "v3", "created": "Wed, 14 Apr 2021 16:25:43 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Heaton", "Howard", ""], ["Fung", "Samy Wu", ""], ["Lin", "Alex Tong", ""], ["Osher", "Stanley", ""], ["Yin", "Wotao", ""]]}, {"id": "2008.02211", "submitter": "Bo Shen", "authors": "Bo Shen, Zhenyu (James) Kong", "title": "Robust Tensor Principal Component Analysis: Exact Recovery via\n  Deterministic Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor, also known as multi-dimensional array, arises from many applications\nin signal processing, manufacturing processes, healthcare, among others. As one\nof the most popular methods in tensor literature, Robust tensor principal\ncomponent analysis (RTPCA) is a very effective tool to extract the low rank and\nsparse components in tensors. In this paper, a new method to analyze RTPCA is\nproposed based on the recently developed tensor-tensor product and tensor\nsingular value decomposition (t-SVD). Specifically, it aims to solve a convex\noptimization problem whose objective function is a weighted combination of the\ntensor nuclear norm and the l1-norm. In most of literature of RTPCA, the exact\nrecovery is built on the tensor incoherence conditions and the assumption of a\nuniform model on the sparse support. Unlike this conventional way, in this\npaper, without any assumption of randomness, the exact recovery can be achieved\nin a completely deterministic fashion by characterizing the tensor\nrank-sparsity incoherence, which is an uncertainty principle between the\nlow-rank tensor spaces and the pattern of sparse tensor.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 16:26:10 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Shen", "Bo", "", "James"], ["Zhenyu", "", "", "James"], ["Kong", "", ""]]}, {"id": "2008.02213", "submitter": "Tianyu Cui", "authors": "Tianyu Cui, Gang Xiong, Gaopeng Gou, Junzheng Shi and Wei Xia", "title": "6VecLM: Language Modeling in Vector Space for IPv6 Target Generation", "comments": "The paper has been accepted at the European Conference on Machine\n  Learning and Principles and Practice of Knowledge Discovery in Databases\n  (ECMLPKDD 2020) (https://ecmlpkdd2020.net/programme/accepted/#ADSTab)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast IPv6 scanning is challenging in the field of network measurement as it\nrequires exploring the whole IPv6 address space but limited by current\ncomputational power. Researchers propose to obtain possible active target\ncandidate sets to probe by algorithmically analyzing the active seed sets.\nHowever, IPv6 addresses lack semantic information and contain numerous\naddressing schemes, leading to the difficulty of designing effective\nalgorithms. In this paper, we introduce our approach 6VecLM to explore\nachieving such target generation algorithms. The architecture can map addresses\ninto a vector space to interpret semantic relationships and uses a Transformer\nnetwork to build IPv6 language models for predicting address sequence.\nExperiments indicate that our approach can perform semantic classification on\naddress space. By adding a new generation approach, our model possesses a\ncontrollable word innovation capability compared to conventional language\nmodels. The work outperformed the state-of-the-art target generation algorithms\non two active address datasets by reaching more quality candidate sets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 16:26:50 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Cui", "Tianyu", ""], ["Xiong", "Gang", ""], ["Gou", "Gaopeng", ""], ["Shi", "Junzheng", ""], ["Xia", "Wei", ""]]}, {"id": "2008.02216", "submitter": "Matej Petkovi\\'c", "authors": "Matej Petkovi\\'c, Bla\\v{z} \\v{S}krlj, Dragi Kocev, Nikola Simidjievski", "title": "Fuzzy Jaccard Index: A robust comparison of ordered lists", "comments": "29 pages, 30 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose Fuzzy Jaccard Index (FUJI) -- a scale-invariant score for\nassessment of the similarity between two ranked/ordered lists. FUJI improves\nupon the Jaccard index by incorporating a membership function which takes into\naccount the particular ranks, thus producing both more stable and more accurate\nsimilarity estimates. We provide theoretical insights into the properties of\nthe FUJI score as well as propose an efficient algorithm for computing it. We\nalso present empirical evidence of its performance on different synthetic\nscenarios. Finally, we demonstrate its utility in a typical machine learning\nsetting -- comparing feature ranking lists relevant to a given machine learning\ntask. In real-life, and in particular high-dimensional domains, where only a\nsmall percentage of the whole feature space might be relevant, a robust and\nconfident feature ranking leads to interpretable findings as well as efficient\ncomputation and good predictive performance. In such cases, FUJI correctly\ndistinguishes between existing feature ranking approaches, while being more\nrobust and efficient than the benchmark similarity scores.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 16:33:52 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Petkovi\u0107", "Matej", ""], ["\u0160krlj", "Bla\u017e", ""], ["Kocev", "Dragi", ""], ["Simidjievski", "Nikola", ""]]}, {"id": "2008.02217", "submitter": "Hubert Ramsauer", "authors": "Hubert Ramsauer, Bernhard Sch\\\"afl, Johannes Lehner, Philipp Seidl,\n  Michael Widrich, Thomas Adler, Lukas Gruber, Markus Holzleitner, Milena\n  Pavlovi\\'c, Geir Kjetil Sandve, Victor Greiff, David Kreil, Michael Kopp,\n  G\\\"unter Klambauer, Johannes Brandstetter, Sepp Hochreiter", "title": "Hopfield Networks is All You Need", "comments": "10 pages (+ appendix); 12 figures; Blog:\n  https://ml-jku.github.io/hopfield-layers/; GitHub:\n  https://github.com/ml-jku/hopfield-layers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a modern Hopfield network with continuous states and a\ncorresponding update rule. The new Hopfield network can store exponentially\n(with the dimension of the associative space) many patterns, retrieves the\npattern with one update, and has exponentially small retrieval errors. It has\nthree types of energy minima (fixed points of the update): (1) global fixed\npoint averaging over all patterns, (2) metastable states averaging over a\nsubset of patterns, and (3) fixed points which store a single pattern. The new\nupdate rule is equivalent to the attention mechanism used in transformers. This\nequivalence enables a characterization of the heads of transformer models.\nThese heads perform in the first layers preferably global averaging and in\nhigher layers partial averaging via metastable states. The new modern Hopfield\nnetwork can be integrated into deep learning architectures as layers to allow\nthe storage of and access to raw input data, intermediate results, or learned\nprototypes. These Hopfield layers enable new ways of deep learning, beyond\nfully-connected, convolutional, or recurrent networks, and provide pooling,\nmemory, association, and attention mechanisms. We demonstrate the broad\napplicability of the Hopfield layers across various domains. Hopfield layers\nimproved state-of-the-art on three out of four considered multiple instance\nlearning problems as well as on immune repertoire classification with several\nhundreds of thousands of instances. On the UCI benchmark collections of small\nclassification tasks, where deep learning methods typically struggle, Hopfield\nlayers yielded a new state-of-the-art when compared to different machine\nlearning methods. Finally, Hopfield layers achieved state-of-the-art on two\ndrug design datasets. The implementation is available at:\nhttps://github.com/ml-jku/hopfield-layers\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 17:52:37 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 14:16:15 GMT"}, {"version": "v3", "created": "Wed, 28 Apr 2021 07:24:49 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Ramsauer", "Hubert", ""], ["Sch\u00e4fl", "Bernhard", ""], ["Lehner", "Johannes", ""], ["Seidl", "Philipp", ""], ["Widrich", "Michael", ""], ["Adler", "Thomas", ""], ["Gruber", "Lukas", ""], ["Holzleitner", "Markus", ""], ["Pavlovi\u0107", "Milena", ""], ["Sandve", "Geir Kjetil", ""], ["Greiff", "Victor", ""], ["Kreil", "David", ""], ["Kopp", "Michael", ""], ["Klambauer", "G\u00fcnter", ""], ["Brandstetter", "Johannes", ""], ["Hochreiter", "Sepp", ""]]}, {"id": "2008.02218", "submitter": "Sirui Wang", "authors": "Qiong Wu, Adam Hare, Sirui Wang, Yuwei Tu, Zhenming Liu, Christopher\n  G. Brinton, Yanhua Li", "title": "BATS: A Spectral Biclustering Approach to Single Document Topic Modeling\n  and Segmentation", "comments": "28 pages", "journal-ref": "ACM Transactions on Intelligent Systems and Technology, 2021", "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing topic modeling and text segmentation methodologies generally require\nlarge datasets for training, limiting their capabilities when only small\ncollections of text are available. In this work, we reexamine the inter-related\nproblems of \"topic identification\" and \"text segmentation\" for sparse document\nlearning, when there is a single new text of interest. In developing a\nmethodology to handle single documents, we face two major challenges. First is\nsparse information: with access to only one document, we cannot train\ntraditional topic models or deep learning algorithms. Second is significant\nnoise: a considerable portion of words in any single document will produce only\nnoise and not help discern topics or segments. To tackle these issues, we\ndesign an unsupervised, computationally efficient methodology called BATS:\nBiclustering Approach to Topic modeling and Segmentation. BATS leverages three\nkey ideas to simultaneously identify topics and segment text: (i) a new\nmechanism that uses word order information to reduce sample complexity, (ii) a\nstatistically sound graph-based biclustering technique that identifies latent\nstructures of words and sentences, and (iii) a collection of effective\nheuristics that remove noise words and award important words to further improve\nperformance. Experiments on four datasets show that our approach outperforms\nseveral state-of-the-art baselines when considering topic coherence, topic\ndiversity, segmentation, and runtime comparison metrics.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 16:34:33 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 01:50:07 GMT"}, {"version": "v3", "created": "Tue, 25 May 2021 11:38:03 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Wu", "Qiong", ""], ["Hare", "Adam", ""], ["Wang", "Sirui", ""], ["Tu", "Yuwei", ""], ["Liu", "Zhenming", ""], ["Brinton", "Christopher G.", ""], ["Li", "Yanhua", ""]]}, {"id": "2008.02219", "submitter": "Raghavan Krishnan", "authors": "R. Krishnan, Prasanna Balaprakash", "title": "Meta Continual Learning via Dynamic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta continual learning algorithms seek to train a model when faced with\nsimilar tasks observed in a sequential manner. Despite promising methodological\nadvancements, there is a lack of theoretical frameworks that enable analysis of\nlearning challenges such as generalization and catastrophic forgetting. To that\nend, we develop a new theoretical approach for meta continual learning~(MCL)\nwhere we mathematically model the learning dynamics using dynamic programming,\nand we establish conditions of optimality for the MCL problem. Moreover, using\nthe theoretical framework, we derive a new dynamic-programming-based MCL method\nthat adopts stochastic-gradient-driven alternating optimization to balance\ngeneralization and catastrophic forgetting. We show that, on MCL benchmark data\nsets, our theoretically grounded method achieves accuracy better than or\ncomparable to that of existing state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 16:36:16 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 15:41:22 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Krishnan", "R.", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "2008.02254", "submitter": "Agostinho A. F. J\\'unior", "authors": "Janderson Ferreira (1), Agostinho A. F. J\\'unior (1), Yves M. Galv\\~ao\n  (1), Pablo Barros (2), Sergio Murilo Maciel Fernandes (1), Bruno J. T.\n  Fernandes (1) ((1) Universidade de Pernambuco - Escola Polit\\'ecnica de\n  Pernambuco, (2) Cognitive Architecture for Collaborative Technologies Unit -\n  Istituto Italiano di Tecnologia)", "title": "Performance Improvement of Path Planning algorithms with Deep Learning\n  Encoder Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, path planning algorithms are used in many daily tasks. They are\nrelevant to find the best route in traffic and make autonomous robots able to\nnavigate. The use of path planning presents some issues in large and dynamic\nenvironments. Large environments make these algorithms spend much time finding\nthe shortest path. On the other hand, dynamic environments request a new\nexecution of the algorithm each time a change occurs in the environment, and it\nincreases the execution time. The dimensionality reduction appears as a\nsolution to this problem, which in this context means removing useless paths\npresent in those environments. Most of the algorithms that reduce\ndimensionality are limited to the linear correlation of the input data.\nRecently, a Convolutional Neural Network (CNN) Encoder was used to overcome\nthis situation since it can use both linear and non-linear information to data\nreduction. This paper analyzes in-depth the performance to eliminate the\nuseless paths using this CNN Encoder model. To measure the mentioned model\nefficiency, we combined it with different path planning algorithms. Next, the\nfinal algorithms (combined and not combined) are checked in a database that is\ncomposed of five scenarios. Each scenario contains fixed and dynamic obstacles.\nTheir proposed model, the CNN Encoder, associated to other existent path\nplanning algorithms in the literature, was able to obtain a time decrease to\nfind the shortest path in comparison to all path planning algorithms analyzed.\nthe average decreased time was 54.43 %.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 17:34:31 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Ferreira", "Janderson", ""], ["J\u00fanior", "Agostinho A. F.", ""], ["Galv\u00e3o", "Yves M.", ""], ["Barros", "Pablo", ""], ["Fernandes", "Sergio Murilo Maciel", ""], ["Fernandes", "Bruno J. T.", ""]]}, {"id": "2008.02265", "submitter": "Haozhi Qi", "authors": "Haozhi Qi, Xiaolong Wang, Deepak Pathak, Yi Ma, Jitendra Malik", "title": "Learning Long-term Visual Dynamics with Region Proposal Interaction\n  Networks", "comments": "ICLR 2021; Code: https://github.com/HaozhiQi/RPIN Website:\n  https://haozhiqi.github.io/RPIN/ v5: update PHYRE results of each evaluation\n  fold", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning long-term dynamics models is the key to understanding physical\ncommon sense. Most existing approaches on learning dynamics from visual input\nsidestep long-term predictions by resorting to rapid re-planning with\nshort-term models. This not only requires such models to be super accurate but\nalso limits them only to tasks where an agent can continuously obtain feedback\nand take action at each step until completion. In this paper, we aim to\nleverage the ideas from success stories in visual recognition tasks to build\nobject representations that can capture inter-object and object-environment\ninteractions over a long-range. To this end, we propose Region Proposal\nInteraction Networks (RPIN), which reason about each object's trajectory in a\nlatent region-proposal feature space. Thanks to the simple yet effective object\nrepresentation, our approach outperforms prior methods by a significant margin\nboth in terms of prediction quality and their ability to plan for downstream\ntasks, and also generalize well to novel environments. Code, pre-trained\nmodels, and more visualization results are available at https://haozhi.io/RPIN.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 17:48:00 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 21:52:30 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 03:36:37 GMT"}, {"version": "v4", "created": "Thu, 1 Apr 2021 05:06:27 GMT"}, {"version": "v5", "created": "Fri, 2 Apr 2021 20:12:04 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Qi", "Haozhi", ""], ["Wang", "Xiaolong", ""], ["Pathak", "Deepak", ""], ["Ma", "Yi", ""], ["Malik", "Jitendra", ""]]}, {"id": "2008.02268", "submitter": "Daniel Duckworth", "authors": "Ricardo Martin-Brualla, Noha Radwan, Mehdi S. M. Sajjadi, Jonathan T.\n  Barron, Alexey Dosovitskiy, Daniel Duckworth", "title": "NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo\n  Collections", "comments": "Project website: https://nerf-w.github.io. Ricardo Martin-Brualla,\n  Noha Radwan, and Mehdi S. M. Sajjadi contributed equally to this work.\n  Updated with results for three additional scenes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a learning-based method for synthesizing novel views of complex\nscenes using only unstructured collections of in-the-wild photographs. We build\non Neural Radiance Fields (NeRF), which uses the weights of a multilayer\nperceptron to model the density and color of a scene as a function of 3D\ncoordinates. While NeRF works well on images of static subjects captured under\ncontrolled settings, it is incapable of modeling many ubiquitous, real-world\nphenomena in uncontrolled images, such as variable illumination or transient\noccluders. We introduce a series of extensions to NeRF to address these issues,\nthereby enabling accurate reconstructions from unstructured image collections\ntaken from the internet. We apply our system, dubbed NeRF-W, to internet photo\ncollections of famous landmarks, and demonstrate temporally consistent novel\nview renderings that are significantly closer to photorealism than the prior\nstate of the art.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 17:51:16 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 11:02:36 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 13:45:14 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Martin-Brualla", "Ricardo", ""], ["Radwan", "Noha", ""], ["Sajjadi", "Mehdi S. M.", ""], ["Barron", "Jonathan T.", ""], ["Dosovitskiy", "Alexey", ""], ["Duckworth", "Daniel", ""]]}, {"id": "2008.02275", "submitter": "Dan Hendrycks", "authors": "Dan Hendrycks and Collin Burns and Steven Basart and Andrew Critch and\n  Jerry Li and Dawn Song and Jacob Steinhardt", "title": "Aligning AI With Shared Human Values", "comments": "ICLR 2021; the ETHICS dataset is available at\n  https://github.com/hendrycks/ethics/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to assess a language model's knowledge of basic concepts of\nmorality. We introduce the ETHICS dataset, a new benchmark that spans concepts\nin justice, well-being, duties, virtues, and commonsense morality. Models\npredict widespread moral judgments about diverse text scenarios. This requires\nconnecting physical and social world knowledge to value judgements, a\ncapability that may enable us to steer chatbot outputs or eventually regularize\nopen-ended reinforcement learning agents. With the ETHICS dataset, we find that\ncurrent language models have a promising but incomplete ability to predict\nbasic human ethical judgements. Our work shows that progress can be made on\nmachine ethics today, and it provides a steppingstone toward AI that is aligned\nwith human values.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 17:59:16 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 06:02:59 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 18:57:47 GMT"}, {"version": "v4", "created": "Thu, 4 Mar 2021 21:47:22 GMT"}, {"version": "v5", "created": "Sat, 24 Jul 2021 04:40:33 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Hendrycks", "Dan", ""], ["Burns", "Collin", ""], ["Basart", "Steven", ""], ["Critch", "Andrew", ""], ["Li", "Jerry", ""], ["Song", "Dawn", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "2008.02312", "submitter": "Qingyong Hu", "authors": "Ruigang Fu, Qingyong Hu, Xiaohu Dong, Yulan Guo, Yinghui Gao, Biao Li", "title": "Axiom-based Grad-CAM: Towards Accurate Visualization and Explanation of\n  CNNs", "comments": "BMVC 2020 (Oral presentation). Code is avaliable at:\n  https://github.com/Fu0511/XGrad-CAM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  To have a better understanding and usage of Convolution Neural Networks\n(CNNs), the visualization and interpretation of CNNs has attracted increasing\nattention in recent years. In particular, several Class Activation Mapping\n(CAM) methods have been proposed to discover the connection between CNN's\ndecision and image regions. In spite of the reasonable visualization, lack of\nclear and sufficient theoretical support is the main limitation of these\nmethods. In this paper, we introduce two axioms -- Conservation and Sensitivity\n-- to the visualization paradigm of the CAM methods. Meanwhile, a dedicated\nAxiom-based Grad-CAM (XGrad-CAM) is proposed to satisfy these axioms as much as\npossible. Experiments demonstrate that XGrad-CAM is an enhanced version of\nGrad-CAM in terms of conservation and sensitivity. It is able to achieve better\nvisualization performance than Grad-CAM, while also be class-discriminative and\neasy-to-implement compared with Grad-CAM++ and Ablation-CAM. The code is\navailable at https://github.com/Fu0511/XGrad-CAM.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 18:42:33 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 10:47:39 GMT"}, {"version": "v3", "created": "Sat, 15 Aug 2020 06:38:53 GMT"}, {"version": "v4", "created": "Wed, 19 Aug 2020 06:04:28 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Fu", "Ruigang", ""], ["Hu", "Qingyong", ""], ["Dong", "Xiaohu", ""], ["Guo", "Yulan", ""], ["Gao", "Yinghui", ""], ["Li", "Biao", ""]]}, {"id": "2008.02320", "submitter": "Varun Mannam", "authors": "Varun Mannam, Yide Zhang, Xiaotong Yuan, Cara Ravasio and Scott S.\n  Howard", "title": "Machine learning for faster and smarter fluorescence lifetime imaging\n  microscopy", "comments": null, "journal-ref": null, "doi": "10.1088/2515-7647/abac1a", "report-no": "042005", "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fluorescence lifetime imaging microscopy (FLIM) is a powerful technique in\nbiomedical research that uses the fluorophore decay rate to provide additional\ncontrast in fluorescence microscopy. However, at present, the calculation,\nanalysis, and interpretation of FLIM is a complex, slow, and computationally\nexpensive process. Machine learning (ML) techniques are well suited to extract\nand interpret measurements from multi-dimensional FLIM data sets with\nsubstantial improvement in speed over conventional methods. In this topical\nreview, we first discuss the basics of FILM and ML. Second, we provide a\nsummary of lifetime extraction strategies using ML and its applications in\nclassifying and segmenting FILM images with higher accuracy compared to\nconventional methods. Finally, we discuss two potential directions to improve\nFLIM with ML with proof of concept demonstrations.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 18:59:36 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Mannam", "Varun", ""], ["Zhang", "Yide", ""], ["Yuan", "Xiaotong", ""], ["Ravasio", "Cara", ""], ["Howard", "Scott S.", ""]]}, {"id": "2008.02323", "submitter": "Saurabh Adya", "authors": "Saurabh Adya, Vineet Garg, Siddharth Sigtia, Pramod Simha, Chandra\n  Dhir", "title": "Hybrid Transformer/CTC Networks for Hardware Efficient Voice Triggering", "comments": "INTERSPEECH, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.HC cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the design of two-pass voice trigger detection systems. We focus\non the networks in the second pass that are used to re-score candidate segments\nobtained from the first-pass. Our baseline is an acoustic model(AM), with\nBiLSTM layers, trained by minimizing the CTC loss. We replace the BiLSTM layers\nwith self-attention layers. Results on internal evaluation sets show that\nself-attention networks yield better accuracy while requiring fewer parameters.\nWe add an auto-regressive decoder network on top of the self-attention layers\nand jointly minimize the CTC loss on the encoder and the cross-entropy loss on\nthe decoder. This design yields further improvements over the baseline. We\nretrain all the models above in a multi-task learning(MTL) setting, where one\nbranch of a shared network is trained as an AM, while the second branch\nclassifies the whole sequence to be true-trigger or not. Results demonstrate\nthat networks with self-attention layers yield $\\sim$60% relative reduction in\nfalse reject rates for a given false-alarm rate, while requiring 10% fewer\nparameters. When trained in the MTL setup, self-attention networks yield\nfurther accuracy improvements. On-device measurements show that we observe 70%\nrelative reduction in inference time. Additionally, the proposed network\narchitectures are $\\sim$5X faster to train.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 19:16:33 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Adya", "Saurabh", ""], ["Garg", "Vineet", ""], ["Sigtia", "Siddharth", ""], ["Simha", "Pramod", ""], ["Dhir", "Chandra", ""]]}, {"id": "2008.02327", "submitter": "MohammadNoor Injadat", "authors": "MohammadNoor Injadat, Fadi Salo, Ali Bou Nassif, Aleksander Essex,\n  Abdallah Shami", "title": "Bayesian Optimization with Machine Learning Algorithms Towards Anomaly\n  Detection", "comments": "6 pages, 7 Figures, 2 tables, Published in 2018 IEEE Global\n  Communications Conference (GLOBECOM)", "journal-ref": null, "doi": "10.1109/GLOCOM.2018.8647714", "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network attacks have been very prevalent as their rate is growing\ntremendously. Both organization and individuals are now concerned about their\nconfidentiality, integrity and availability of their critical information which\nare often impacted by network attacks. To that end, several previous machine\nlearning-based intrusion detection methods have been developed to secure\nnetwork infrastructure from such attacks. In this paper, an effective anomaly\ndetection framework is proposed utilizing Bayesian Optimization technique to\ntune the parameters of Support Vector Machine with Gaussian Kernel (SVM-RBF),\nRandom Forest (RF), and k-Nearest Neighbor (k-NN) algorithms. The performance\nof the considered algorithms is evaluated using the ISCX 2012 dataset.\nExperimental results show the effectiveness of the proposed framework in term\nof accuracy rate, precision, low-false alarm rate, and recall.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 19:29:35 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Injadat", "MohammadNoor", ""], ["Salo", "Fadi", ""], ["Nassif", "Ali Bou", ""], ["Essex", "Aleksander", ""], ["Shami", "Abdallah", ""]]}, {"id": "2008.02340", "submitter": "Zhengyang Wang", "authors": "Zhengyang Wang, Yaochen Xie, Shuiwang Ji", "title": "Global Voxel Transformer Networks for Augmented Microscopy", "comments": "Supplementary Material:\n  https://documentcloud.adobe.com/link/track?uri=urn:aaid:scds:US:9fcf9e0d-6ea2-470b-8a89-ed09ac634ef8", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in deep learning have led to remarkable success in augmented\nmicroscopy, enabling us to obtain high-quality microscope images without using\nexpensive microscopy hardware and sample preparation techniques. However,\ncurrent deep learning models for augmented microscopy are mostly U-Net based\nneural networks, thus sharing certain drawbacks that limit the performance. In\nthis work, we introduce global voxel transformer networks (GVTNets), an\nadvanced deep learning tool for augmented microscopy that overcomes intrinsic\nlimitations of the current U-Net based models and achieves improved\nperformance. GVTNets are built on global voxel transformer operators (GVTOs),\nwhich are able to aggregate global information, as opposed to local operators\nlike convolutions. We apply the proposed methods on existing datasets for three\ndifferent augmented microscopy tasks under various settings. The performance is\nsignificantly and consistently better than previous U-Net based approaches.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 20:11:15 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 16:45:20 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Wang", "Zhengyang", ""], ["Xie", "Yaochen", ""], ["Ji", "Shuiwang", ""]]}, {"id": "2008.02347", "submitter": "Subhadip Maji", "authors": "Subhadip Maji, Anudeep Srivatsav Appe, Raghav Bali, Veera Raghavendra\n  Chikka, Arijit Ghosh Chowdhury and Vamsi M Bhandaru", "title": "An Interpretable Deep Learning System for Automatically Scoring Request\n  for Proposals", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Managed Care system within Medicaid (US Healthcare) uses Request For\nProposals (RFP) to award contracts for various healthcare and related services.\nRFP responses are very detailed documents (hundreds of pages) submitted by\ncompeting organisations to win contracts. Subject matter expertise and domain\nknowledge play an important role in preparing RFP responses along with analysis\nof historical submissions. Automated analysis of these responses through\nNatural Language Processing (NLP) systems can reduce time and effort needed to\nexplore historical responses, and assisting in writing better responses. Our\nwork draws parallels between scoring RFPs and essay scoring models, while\nhighlighting new challenges and the need for interpretability. Typical scoring\nmodels focus on word level impacts to grade essays and other short write-ups.\nWe propose a novel Bi-LSTM based regression model, and provide deeper insight\ninto phrases which latently impact scoring of responses. We contend the merits\nof our proposed methodology using extensive quantitative experiments. We also\nqualitatively asses the impact of important phrases using human evaluators.\nFinally, we introduce a novel problem statement that can be used to further\nimprove the state of the art in NLP based automatic scoring systems.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 20:21:35 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Maji", "Subhadip", ""], ["Appe", "Anudeep Srivatsav", ""], ["Bali", "Raghav", ""], ["Chikka", "Veera Raghavendra", ""], ["Chowdhury", "Arijit Ghosh", ""], ["Bhandaru", "Vamsi M", ""]]}, {"id": "2008.02353", "submitter": "David Rogers", "authors": "David M. Rogers", "title": "Protein Conformational States: A First Principles Bayesian Method", "comments": "8 page article, 3 page SI, 4 figures", "journal-ref": null, "doi": "10.3390/e22111242", "report-no": null, "categories": "physics.comp-ph cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated identification of protein conformational states from simulation of\nan ensemble of structures is a hard problem because it requires teaching a\ncomputer to recognize shapes. We adapt the naive Bayes classifier from the\nmachine learning community for use on atom-to-atom pairwise contacts. The\nresult is an unsupervised learning algorithm that samples a `distribution' over\npotential classification schemes. We apply the classifier to a series of test\nstructures and one real protein, showing that it identifies the conformational\ntransition with > 95% accuracy in most cases. A nontrivial feature of our\nadaptation is a new connection to information entropy that allows us to vary\nthe level of structural detail without spoiling the categorization. This is\nconfirmed by comparing results as the number of atoms and time-samples are\nvaried over 1.5 orders of magnitude. Further, the method's derivation from\nBayesian analysis on the set of inter-atomic contacts makes it easy to\nunderstand and extend to more complex cases.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 20:35:54 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 21:52:36 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Rogers", "David M.", ""]]}, {"id": "2008.02354", "submitter": "Yukino Baba", "authors": "Yukino Baba, Jiyi Li, Hisashi Kashima", "title": "CrowDEA: Multi-view Idea Prioritization with Crowds", "comments": "Accepted in HCOMP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of ideas collected from crowds with regard to an open-ended\nquestion, how can we organize and prioritize them in order to determine the\npreferred ones based on preference comparisons by crowd evaluators? As there\nare diverse latent criteria for the value of an idea, multiple ideas can be\nconsidered as \"the best\". In addition, evaluators can have different preference\ncriteria, and their comparison results often disagree.\n  In this paper, we propose an analysis method for obtaining a subset of ideas,\nwhich we call frontier ideas, that are the best in terms of at least one latent\nevaluation criterion. We propose an approach, called CrowDEA, which estimates\nthe embeddings of the ideas in the multiple-criteria preference space, the best\nviewpoint for each idea, and preference criterion for each evaluator, to obtain\na set of frontier ideas. Experimental results using real datasets containing\nnumerous ideas or designs demonstrate that the proposed approach can\neffectively prioritize ideas from multiple viewpoints, thereby detecting\nfrontier ideas. The embeddings of ideas learned by the proposed approach\nprovide a visualization that facilitates observation of the frontier ideas. In\naddition, the proposed approach prioritizes ideas from a wider variety of\nviewpoints, whereas the baselines tend to use to the same viewpoints; it can\nalso handle various viewpoints and prioritize ideas in situations where only a\nlimited number of evaluators or labels are available.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 07:41:18 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 14:22:13 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Baba", "Yukino", ""], ["Li", "Jiyi", ""], ["Kashima", "Hisashi", ""]]}, {"id": "2008.02355", "submitter": "Prasanna Date", "authors": "Prasanna Date, Thomas Potok", "title": "Adiabatic Quantum Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in machine learning is the computational expense of\ntraining these models. Model training can be viewed as a form of optimization\nused to fit a machine learning model to a set of data, which can take up\nsignificant amount of time on classical computers. Adiabatic quantum computers\nhave been shown to excel at solving optimization problems, and therefore, we\nbelieve, present a promising alternative to improve machine learning training\ntimes. In this paper, we present an adiabatic quantum computing approach for\ntraining a linear regression model. In order to do this, we formulate the\nregression problem as a quadratic unconstrained binary optimization (QUBO)\nproblem. We analyze our quantum approach theoretically, test it on the D-Wave\n2000Q adiabatic quantum computer and compare its performance to a classical\napproach that uses the Scikit-learn library in Python. Our analysis shows that\nthe quantum approach attains up to 2.8x speedup over the classical approach on\nlarger datasets, and performs at par with the classical approach on the\nregression error metric.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 20:40:41 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Date", "Prasanna", ""], ["Potok", "Thomas", ""]]}, {"id": "2008.02366", "submitter": "Leszek Pecyna", "authors": "Leszek Pecyna, Angelo Cangelosi, Alessandro Di Nuovo", "title": "A robot that counts like a child: a developmental model of counting and\n  pointing", "comments": "28 pages, 13 figures. This is a pre-print of an article published in\n  Psychological Research. The final authenticated version is available online\n  at: https://doi.org/10.1007/s00426-020-01428-8", "journal-ref": "Psychological Research (2020)", "doi": "10.1007/s00426-020-01428-8", "report-no": null, "categories": "cs.LG cs.CV cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a novel neuro-robotics model capable of counting real items is\nintroduced. The model allows us to investigate the interaction between\nembodiment and numerical cognition. This is composed of a deep neural network\ncapable of image processing and sequential tasks performance, and a robotic\nplatform providing the embodiment - the iCub humanoid robot. The network is\ntrained using images from the robot's cameras and proprioceptive signals from\nits joints. The trained model is able to count a set of items and at the same\ntime points to them. We investigate the influence of pointing on the counting\nprocess and compare our results with those from studies with children. Several\ntraining approaches are presented in this paper all of them uses pre-training\nroutine allowing the network to gain the ability of pointing and number\nrecitation (from 1 to 10) prior to counting training. The impact of the counted\nset size and distance to the objects are investigated. The obtained results on\ncounting performance show similarities with those from human studies.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 21:06:27 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 23:48:30 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Pecyna", "Leszek", ""], ["Cangelosi", "Angelo", ""], ["Di Nuovo", "Alessandro", ""]]}, {"id": "2008.02369", "submitter": "Prasanna Date", "authors": "Prasanna Date, Davis Arthur, Lauren Pusey-Nazzaro", "title": "QUBO Formulations for Training Machine Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training machine learning models on classical computers is usually a time and\ncompute intensive process. With Moore's law coming to an end and ever\nincreasing demand for large-scale data analysis using machine learning, we must\nleverage non-conventional computing paradigms like quantum computing to train\nmachine learning models efficiently. Adiabatic quantum computers like the\nD-Wave 2000Q can approximately solve NP-hard optimization problems, such as the\nquadratic unconstrained binary optimization (QUBO), faster than classical\ncomputers. Since many machine learning problems are also NP-hard, we believe\nadiabatic quantum computers might be instrumental in training machine learning\nmodels efficiently in the post Moore's law era. In order to solve a problem on\nadiabatic quantum computers, it must be formulated as a QUBO problem, which is\na challenging task in itself. In this paper, we formulate the training problems\nof three machine learning models---linear regression, support vector machine\n(SVM) and equal-sized k-means clustering---as QUBO problems so that they can be\ntrained on adiabatic quantum computers efficiently. We also analyze the time\nand space complexities of our formulations and compare them to the\nstate-of-the-art classical algorithms for training these machine learning\nmodels. We show that the time and space complexities of our formulations are\nbetter (in the case of SVM and equal-sized k-means clustering) or equivalent\n(in case of linear regression) to their classical counterparts.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 21:16:05 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Date", "Prasanna", ""], ["Arthur", "Davis", ""], ["Pusey-Nazzaro", "Lauren", ""]]}, {"id": "2008.02386", "submitter": "Panagiotis Tsilifis", "authors": "Panagiotis Tsilifis, Piyush Pandita, Sayan Ghosh, Valeria Andreoli,\n  Thomas Vandeputte, Liping Wang", "title": "Bayesian learning of orthogonal embeddings for multi-fidelity Gaussian\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Bayesian approach to identify optimal transformations that map\nmodel input points to low dimensional latent variables. The \"projection\"\nmapping consists of an orthonormal matrix that is considered a priori unknown\nand needs to be inferred jointly with the GP parameters, conditioned on the\navailable training data. The proposed Bayesian inference scheme relies on a\ntwo-step iterative algorithm that samples from the marginal posteriors of the\nGP parameters and the projection matrix respectively, both using Markov Chain\nMonte Carlo (MCMC) sampling. In order to take into account the orthogonality\nconstraints imposed on the orthonormal projection matrix, a Geodesic Monte\nCarlo sampling algorithm is employed, that is suitable for exploiting\nprobability measures on manifolds. We extend the proposed framework to\nmulti-fidelity models using GPs including the scenarios of training multiple\noutputs together. We validate our framework on three synthetic problems with a\nknown lower-dimensional subspace. The benefits of our proposed framework, are\nillustrated on the computationally challenging three-dimensional aerodynamic\noptimization of a last-stage blade for an industrial gas turbine, where we\nstudy the effect of an 85-dimensional airfoil shape parameterization on two\noutput quantities of interest, specifically on the aerodynamic efficiency and\nthe degree of reaction.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 22:28:53 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Tsilifis", "Panagiotis", ""], ["Pandita", "Piyush", ""], ["Ghosh", "Sayan", ""], ["Andreoli", "Valeria", ""], ["Vandeputte", "Thomas", ""], ["Wang", "Liping", ""]]}, {"id": "2008.02389", "submitter": "N. Benjamin Erichson", "authors": "Alejandro F. Queiruga, N. Benjamin Erichson, Dane Taylor and Michael\n  W. Mahoney", "title": "Continuous-in-Depth Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has attempted to interpret residual networks (ResNets) as one\nstep of a forward Euler discretization of an ordinary differential equation,\nfocusing mainly on syntactic algebraic similarities between the two systems.\nDiscrete dynamical integrators of continuous dynamical systems, however, have a\nmuch richer structure. We first show that ResNets fail to be meaningful\ndynamical integrators in this richer sense. We then demonstrate that neural\nnetwork models can learn to represent continuous dynamical systems, with this\nricher structure and properties, by embedding them into higher-order numerical\nintegration schemes, such as the Runge Kutta schemes. Based on these insights,\nwe introduce ContinuousNet as a continuous-in-depth generalization of ResNet\narchitectures. ContinuousNets exhibit an invariance to the particular\ncomputational graph manifestation. That is, the continuous-in-depth model can\nbe evaluated with different discrete time step sizes, which changes the number\nof layers, and different numerical integration schemes, which changes the graph\nconnectivity. We show that this can be used to develop an incremental-in-depth\ntraining scheme that improves model quality, while significantly decreasing\ntraining time. We also show that, once trained, the number of units in the\ncomputational graph can even be decreased, for faster inference with\nlittle-to-no accuracy drop.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 22:54:09 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Queiruga", "Alejandro F.", ""], ["Erichson", "N. Benjamin", ""], ["Taylor", "Dane", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2008.02397", "submitter": "Mohammad Malekzadeh", "authors": "Mohammad Malekzadeh, Richard G. Clegg, Andrea Cavallaro, Hamed Haddadi", "title": "DANA: Dimension-Adaptive Neural Architecture for Multivariate Sensor\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion sensors embedded in wearable and mobile devices allow for dynamic\nselection of sensor streams and sampling rates, enabling useful applications,\ne.g. for power management or control of data sharing. While deep neural\nnetworks (DNNs) achieve competitive accuracy in sensor data classification,\ncurrent DNN architectures only process data coming from a fixed set of sensors\nwith a fixed sampling rate, and changes in the dimensions of their inputs cause\nconsiderable accuracy loss, unnecessary computations, or failure in operation.\nTo address this problem, we introduce a dimension-adaptive pooling (DAP) layer\nthat makes DNNs flexible and more robust to changes in sampling rate and in\nsensor availability. DAP operates on convolutional filter maps of variable\ndimensions and produces an input of fixed dimensions suitable for feedforward\nand recurrent layers. Further, we propose a dimension-adaptive training (DAT)\nprocedure for enabling DNNs that use DAP to better generalize over the set of\nfeasible data dimensions at inference time. DAT comprises the random selection\nof dimensions during the forward passes and optimization with accumulated\ngradients of several backward passes. Combining DAP and DAT, we show how to\ntransform existing non-adaptive DNNs into a Dimension-Adaptive Neural\nArchitecture (DANA), while keeping the same number of parameters. Compared to\nthe existing approaches, DANA provides better average classification accuracy\nover the range of possible data dimensions, and it does not need up-sampling or\nimputation, thus reduces unnecessary computations at inference time.\nExperimental results, on four benchmark real-world datasets of human activity\nrecognition as well as three synthetic datasets, show that DANA prevents\nsignificant losses in classification accuracy of the state-of-the-art DNNs and,\ncompared to baselines, it better captures correlated patterns in sensor data.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 23:42:03 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 12:50:40 GMT"}, {"version": "v3", "created": "Sun, 16 May 2021 12:47:31 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Malekzadeh", "Mohammad", ""], ["Clegg", "Richard G.", ""], ["Cavallaro", "Andrea", ""], ["Haddadi", "Hamed", ""]]}, {"id": "2008.02430", "submitter": "Xiao Ma", "authors": "Xiao Ma, Siwei Chen, David Hsu, Wee Sun Lee", "title": "Contrastive Variational Reinforcement Learning for Complex Observations", "comments": "CoRL 2020 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has achieved significant success in various\nrobot tasks: manipulation, navigation, etc. However, complex visual\nobservations in natural environments remains a major challenge. This paper\npresents Contrastive Variational Reinforcement Learning (CVRL), a model-based\nmethod that tackles complex visual observations in DRL. CVRL learns a\ncontrastive variational model by maximizing the mutual information between\nlatent states and observations discriminatively, through contrastive learning.\nIt avoids modeling the complex observation space unnecessarily, as the commonly\nused generative observation model often does, and is significantly more robust.\nCVRL achieves comparable performance with state-of-the-art model-based DRL\nmethods on standard Mujoco tasks. It significantly outperforms them on Natural\nMujoco tasks and a robot box-pushing task with complex observations, e.g.,\ndynamic shadows. The CVRL code is available publicly at\nhttps://github.com/Yusufma03/CVRL.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 02:25:51 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 07:35:00 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Ma", "Xiao", ""], ["Chen", "Siwei", ""], ["Hsu", "David", ""], ["Lee", "Wee Sun", ""]]}, {"id": "2008.02437", "submitter": "Yuetian Luo", "authors": "Yuetian Luo and Garvesh Raskutti and Ming Yuan and Anru R. Zhang", "title": "A Sharp Blockwise Tensor Perturbation Bound for Orthogonal Iteration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG cs.NA math.NA stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we develop novel perturbation bounds for the high-order\northogonal iteration (HOOI) [DLDMV00b]. Under mild regularity conditions, we\nestablish blockwise tensor perturbation bounds for HOOI with guarantees for\nboth tensor reconstruction in Hilbert-Schmidt norm $\\|\\widehat{\\bcT} - \\bcT\n\\|_{\\tHS}$ and mode-$k$ singular subspace estimation in Schatten-$q$ norm $\\|\n\\sin \\Theta (\\widehat{\\U}_k, \\U_k) \\|_q$ for any $q \\geq 1$. We show the upper\nbounds of mode-$k$ singular subspace estimation are unilateral and converge\nlinearly to a quantity characterized by blockwise errors of the perturbation\nand signal strength. For the tensor reconstruction error bound, we express the\nbound through a simple quantity $\\xi$, which depends only on perturbation and\nthe multilinear rank of the underlying signal. Rate matching deterministic\nlower bound for tensor reconstruction, which demonstrates the optimality of\nHOOI, is also provided. Furthermore, we prove that one-step HOOI (i.e., HOOI\nwith only a single iteration) is also optimal in terms of tensor reconstruction\nand can be used to lower the computational cost. The perturbation results are\nalso extended to the case that only partial modes of $\\bcT$ have low-rank\nstructure. We support our theoretical results by extensive numerical studies.\nFinally, we apply the novel perturbation bounds of HOOI on two applications,\ntensor denoising and tensor co-clustering, from machine learning and\nstatistics, which demonstrates the superiority of the new perturbation results.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 03:01:28 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 20:34:04 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Luo", "Yuetian", ""], ["Raskutti", "Garvesh", ""], ["Yuan", "Ming", ""], ["Zhang", "Anru R.", ""]]}, {"id": "2008.02447", "submitter": "Siddhant Garg", "authors": "Siddhant Garg, Yingyu Liang", "title": "Functional Regularization for Representation Learning: A Unified\n  Theoretical Perspective", "comments": "Accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised and self-supervised learning approaches have become a crucial\ntool to learn representations for downstream prediction tasks. While these\napproaches are widely used in practice and achieve impressive empirical gains,\ntheir theoretical understanding largely lags behind. Towards bridging this gap,\nwe present a unifying perspective where several such approaches can be viewed\nas imposing a regularization on the representation via a learnable function\nusing unlabeled data. We propose a discriminative theoretical framework for\nanalyzing the sample complexity of these approaches, which generalizes the\nframework of (Balcan and Blum, 2010) to allow learnable regularization\nfunctions. Our sample complexity bounds show that, with carefully chosen\nhypothesis classes to exploit the structure in the data, these learnable\nregularization functions can prune the hypothesis space, and help reduce the\namount of labeled data needed. We then provide two concrete examples of\nfunctional regularization, one using auto-encoders and the other using masked\nself-supervision, and apply our framework to quantify the reduction in the\nsample complexity bound of labeled data. We also provide complementary\nempirical results to support our analysis.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 04:06:04 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 15:30:19 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 00:54:57 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Garg", "Siddhant", ""], ["Liang", "Yingyu", ""]]}, {"id": "2008.02450", "submitter": "AprilPyone MaungMaung", "authors": "MaungMaung AprilPyone and Hitoshi Kiya", "title": "Training DNN Model with Secret Key for Model Protection", "comments": "to appear in 2020 IEEE 9th Global Conference on Consumer Electronics\n  (GCCE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a model protection method by using block-wise pixel\nshuffling with a secret key as a preprocessing technique to input images for\nthe first time. The protected model is built by training with such preprocessed\nimages. Experiment results show that the performance of the protected model is\nclose to that of non-protected models when the key is correct, while the\naccuracy is severely dropped when an incorrect key is given, and the proposed\nmodel protection is robust against not only brute-force attacks but also\nfine-tuning attacks, while maintaining almost the same performance accuracy as\nthat of using a non-protected model.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 04:25:59 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["AprilPyone", "MaungMaung", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "2008.02452", "submitter": "Dimitrios Dimitriadis", "authors": "Dimitrios Dimitriadis, Kenichi Kumatani, Robert Gmyr, Yashesh Gaur and\n  Sefik Emre Eskimez", "title": "Federated Transfer Learning with Dynamic Gradient Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, a Federated Learning (FL) simulation platform is introduced.\nThe target scenario is Acoustic Model training based on this platform. To our\nknowledge, this is the first attempt to apply FL techniques to Speech\nRecognition tasks due to the inherent complexity. The proposed FL platform can\nsupport different tasks based on the adopted modular design. As part of the\nplatform, a novel hierarchical optimization scheme and two gradient aggregation\nmethods are proposed, leading to almost an order of magnitude improvement in\ntraining convergence speed compared to other distributed or FL training\nalgorithms like BMUF and FedAvg. The hierarchical optimization offers\nadditional flexibility in the training pipeline besides the enhanced\nconvergence speed. On top of the hierarchical optimization, a dynamic gradient\naggregation algorithm is proposed, based on a data-driven weight inference.\nThis aggregation algorithm acts as a regularizer of the gradient quality.\nFinally, an unsupervised training pipeline tailored to FL is presented as a\nseparate training scenario. The experimental validation of the proposed system\nis based on two tasks: first, the LibriSpeech task showing a speed-up of 7x and\n6% Word Error Rate reduction (WERR) compared to the baseline results. The\nsecond task is based on session adaptation providing an improvement of 20% WERR\nover a competitive production-ready LAS model. The proposed Federated Learning\nsystem is shown to outperform the golden standard of distributed training in\nboth convergence speed and overall model performance.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 04:29:01 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Dimitriadis", "Dimitrios", ""], ["Kumatani", "Kenichi", ""], ["Gmyr", "Robert", ""], ["Gaur", "Yashesh", ""], ["Eskimez", "Sefik Emre", ""]]}, {"id": "2008.02454", "submitter": "Yash Bhalgat", "authors": "Yash Bhalgat, Yizhe Zhang, Jamie Lin, Fatih Porikli", "title": "Structured Convolutions for Efficient Neural Network Design", "comments": "Camera-ready for NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we tackle model efficiency by exploiting redundancy in the\n\\textit{implicit structure} of the building blocks of convolutional neural\nnetworks. We start our analysis by introducing a general definition of\nComposite Kernel structures that enable the execution of convolution operations\nin the form of efficient, scaled, sum-pooling components. As its special case,\nwe propose \\textit{Structured Convolutions} and show that these allow\ndecomposition of the convolution operation into a sum-pooling operation\nfollowed by a convolution with significantly lower complexity and fewer\nweights. We show how this decomposition can be applied to 2D and 3D kernels as\nwell as the fully-connected layers. Furthermore, we present a Structural\nRegularization loss that promotes neural network layers to leverage on this\ndesired structure in a way that, after training, they can be decomposed with\nnegligible performance loss. By applying our method to a wide range of CNN\narchitectures, we demonstrate \"structured\" versions of the ResNets that are up\nto 2$\\times$ smaller and a new Structured-MobileNetV2 that is more efficient\nwhile staying within an accuracy loss of 1% on ImageNet and CIFAR-10 datasets.\nWe also show similar structured versions of EfficientNet on ImageNet and HRNet\narchitecture for semantic segmentation on the Cityscapes dataset. Our method\nperforms equally well or superior in terms of the complexity reduction in\ncomparison to the existing tensor decomposition and channel pruning methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 04:38:38 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 04:41:55 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Bhalgat", "Yash", ""], ["Zhang", "Yizhe", ""], ["Lin", "Jamie", ""], ["Porikli", "Fatih", ""]]}, {"id": "2008.02464", "submitter": "Jiezhong Qiu", "authors": "Jiezhong Qiu, Chi Wang, Ben Liao, Richard Peng, Jie Tang", "title": "A Matrix Chernoff Bound for Markov Chains and Its Application to\n  Co-occurrence Matrices", "comments": "Accepted at NeurIPS'20, 25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a Chernoff-type bound for sums of matrix-valued random variables\nsampled via a regular (aperiodic and irreducible) finite Markov chain.\nSpecially, consider a random walk on a regular Markov chain and a Hermitian\nmatrix-valued function on its state space. Our result gives exponentially\ndecreasing bounds on the tail distributions of the extreme eigenvalues of the\nsample mean matrix. Our proof is based on the matrix expander (regular\nundirected graph) Chernoff bound [Garg et al. STOC '18] and scalar\nChernoff-Hoeffding bounds for Markov chains [Chung et al. STACS '12].\n  Our matrix Chernoff bound for Markov chains can be applied to analyze the\nbehavior of co-occurrence statistics for sequential data, which have been\ncommon and important data signals in machine learning. We show that given a\nregular Markov chain with $n$ states and mixing time $\\tau$, we need a\ntrajectory of length $O(\\tau (\\log{(n)}+\\log{(\\tau)})/\\epsilon^2)$ to achieve\nan estimator of the co-occurrence matrix with error bound $\\epsilon$. We\nconduct several experiments and the experimental results are consistent with\nthe exponentially fast convergence rate from theoretical analysis. Our result\ngives the first bound on the convergence rate of the co-occurrence matrix and\nthe first sample complexity analysis in graph representation learning.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 05:44:54 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 14:01:27 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Qiu", "Jiezhong", ""], ["Wang", "Chi", ""], ["Liao", "Ben", ""], ["Peng", "Richard", ""], ["Tang", "Jie", ""]]}, {"id": "2008.02467", "submitter": "Wei Liu", "authors": "Lior Lukov, Sanjay Chawla, Wei Liu, Brett Church, and Gaurav Pandey", "title": "Unravelling the Architecture of Membrane Proteins with Conditional\n  Random Fields", "comments": "See the originally compiled PDF of this paper at:\n  https://drive.google.com/file/d/1IYF52Wk8m96KIlrQHUVtEBdm0Kw3M40c", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we will show that the recently introduced graphical model:\nConditional Random Fields (CRF) provides a template to integrate micro-level\ninformation about biological entities into a mathematical model to understand\ntheir macro-level behavior. More specifically, we will apply the CRF model to\nan important classification problem in protein science, namely the secondary\nstructure prediction of proteins based on the observed primary structure. A\ncomparison on benchmark data sets against twenty-eight other methods shows that\nnot only does the CRF model lead to extremely accurate predictions but the\nmodular nature of the model and the freedom to integrate disparate, overlapping\nand non-independent sources of information, makes the model an extremely\nversatile tool to potentially solve many other problems in bioinformatics.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 05:57:20 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Lukov", "Lior", ""], ["Chawla", "Sanjay", ""], ["Liu", "Wei", ""], ["Church", "Brett", ""], ["Pandey", "Gaurav", ""]]}, {"id": "2008.02479", "submitter": "Mikkel Slot Nielsen", "authors": "Richard A. Davis and Mikkel S. Nielsen", "title": "Modeling of time series using random forests: theoretical developments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study asymptotic properties of random forests within the\nframework of nonlinear time series modeling. While random forests have been\nsuccessfully applied in various fields, the theoretical justification has not\nbeen considered for their use in a time series setting. Under mild conditions,\nwe prove a uniform concentration inequality for regression trees built on\nnonlinear autoregressive processes and, subsequently, we use this result to\nprove consistency for a large class of random forests. The results are\nsupported by various simulations.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 07:02:10 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Davis", "Richard A.", ""], ["Nielsen", "Mikkel S.", ""]]}, {"id": "2008.02480", "submitter": "Ching-Yu Chiu", "authors": "Ching-Yu Chiu, Wen-Yi Hsiao, Yin-Cheng Yeh, Yi-Hsuan Yang, Alvin\n  Wen-Yu Su", "title": "Mixing-Specific Data Augmentation Techniques for Improved Blind\n  Violin/Piano Source Separation", "comments": "Accepted to IEEE 22nd International Workshop on Multimedia Signal\n  Processing (MMSP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blind music source separation has been a popular and active subject of\nresearch in both the music information retrieval and signal processing\ncommunities. To counter the lack of available multi-track data for supervised\nmodel training, a data augmentation method that creates artificial mixtures by\ncombining tracks from different songs has been shown useful in recent works.\nFollowing this light, we examine further in this paper extended data\naugmentation methods that consider more sophisticated mixing settings employed\nin the modern music production routine, the relationship between the tracks to\nbe combined, and factors of silence. As a case study, we consider the\nseparation of violin and piano tracks in a violin piano ensemble, evaluating\nthe performance in terms of common metrics, namely SDR, SIR, and SAR. In\naddition to examining the effectiveness of these new data augmentation methods,\nwe also study the influence of the amount of training data. Our evaluation\nshows that the proposed mixing-specific data augmentation methods can help\nimprove the performance of a deep learning-based model for source separation,\nespecially in the case of small training data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 07:02:24 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Chiu", "Ching-Yu", ""], ["Hsiao", "Wen-Yi", ""], ["Yeh", "Yin-Cheng", ""], ["Yang", "Yi-Hsuan", ""], ["Su", "Alvin Wen-Yu", ""]]}, {"id": "2008.02481", "submitter": "Mohsen Karimi", "authors": "Mohsen Karimi and Fahimeh Arab", "title": "Machine Learning Based Framework for Estimation of Data Center Power\n  Using Acoustic Side Channel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data centers are high power consumers and the energy consumption of data\ncenters keeps on rising in spite of all the efforts for increasing the energy\nefficiency. The need for energy-awareness in data centers makes the use of\npower modeling and estimation to be still a big challenge due to huge amount of\nuncertainty in this area. In this paper, a machine learning based method is\nproposed to approximately estimate the amount of power consumption by using\nacoustic side channel caused by fan in the fan-based cooling system in the\nserver room. For doing so, frequency components of the acoustic signal,\nrecorded by a microphone in the server room, is extracted, pre-processed, and\nfed to a Multi-Layer Neural-Network as an estimator. The proposed method\nperformed well to estimate the power consumption, having more than 85 percent\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 07:03:22 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Karimi", "Mohsen", ""], ["Arab", "Fahimeh", ""]]}, {"id": "2008.02487", "submitter": "Iv\\'an L\\'opez-Espejo", "authors": "Santi Prieto, Alfonso Ortega, Iv\\'an L\\'opez-Espejo, Eduardo Lleida", "title": "Shouted Speech Compensation for Speaker Verification Robust to Vocal\n  Effort Conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.HC cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of speaker verification systems degrades when vocal effort\nconditions between enrollment and test (e.g., shouted vs. normal speech) are\ndifferent. This is a potential situation in non-cooperative speaker\nverification tasks. In this paper, we present a study on different methods for\nlinear compensation of embeddings making use of Gaussian mixture models to\ncluster shouted and normal speech domains. These compensation techniques are\nborrowed from the area of robustness for automatic speech recognition and, in\nthis work, we apply them to compensate the mismatch between shouted and normal\nconditions in speaker verification. Before compensation, shouted condition is\nautomatically detected by means of logistic regression. The process is\ncomputationally light and it is performed in the back-end of an x-vector\nsystem. Experimental results show that applying the proposed approach in the\npresence of vocal effort mismatch yields up to 13.8% equal error rate relative\nimprovement with respect to a system that applies neither shouted speech\ndetection nor compensation.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 07:25:57 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Prieto", "Santi", ""], ["Ortega", "Alfonso", ""], ["L\u00f3pez-Espejo", "Iv\u00e1n", ""], ["Lleida", "Eduardo", ""]]}, {"id": "2008.02491", "submitter": "Borjan Geshkovski", "authors": "Carlos Esteve, Borjan Geshkovski, Dario Pighin, Enrique Zuazua", "title": "Large-time asymptotics in deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the neural ODE perspective of supervised learning and study the\nimpact of the final time $T$ (which may indicate the depth of a corresponding\nResNet) in training. For the classical $L^2$--regularized empirical risk\nminimization problem, whenever the neural ODE dynamics are homogeneous with\nrespect to the parameters, we show that the training error is at most of the\norder $\\mathcal{O}\\left(\\frac{1}{T}\\right)$. Furthermore, if the loss inducing\nthe empirical risk attains its minimum, the optimal parameters converge to\nminimal $L^2$--norm parameters which interpolate the dataset. By a natural\nscaling between $T$ and the regularization hyperparameter $\\lambda$ we obtain\nthe same results when $\\lambda\\searrow0$ and $T$ is fixed. This allows us to\nstipulate generalization properties in the overparametrized regime, now seen\nfrom the large depth, neural ODE perspective. To enhance the polynomial decay,\ninspired by turnpike theory in optimal control, we propose a learning problem\nwith an additional integral regularization term of the neural ODE trajectory\nover $[0,T]$. In the setting of $\\ell^p$--distance losses, we prove that both\nthe training error and the optimal parameters are at most of the order\n$\\mathcal{O}\\left(e^{-\\mu t}\\right)$ in any $t\\in[0,T]$. The aforementioned\nstability estimates are also shown for continuous space-time neural networks,\ntaking the form of nonlinear integro-differential equations. By using a\ntime-dependent moving grid for discretizing the spatial variable, we\ndemonstrate that these equations provide a framework for addressing ResNets\nwith variable widths.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 07:33:17 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 20:37:39 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Esteve", "Carlos", ""], ["Geshkovski", "Borjan", ""], ["Pighin", "Dario", ""], ["Zuazua", "Enrique", ""]]}, {"id": "2008.02492", "submitter": "Meng-Jiun Chiou", "authors": "Meng-Jiun Chiou, Zhenguang Liu, Yifang Yin, Anan Liu, Roger Zimmermann", "title": "Zero-Shot Multi-View Indoor Localization via Graph Location Networks", "comments": "Accepted at ACM MM 2020. 10 pages, 7 figures. Code and datasets\n  available at\n  https://github.com/coldmanck/zero-shot-indoor-localization-release", "journal-ref": "Proceedings of the 28th ACM International Conference on\n  Multimedia, 2020", "doi": "10.1145/3394171.3413856", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indoor localization is a fundamental problem in location-based applications.\nCurrent approaches to this problem typically rely on Radio Frequency\ntechnology, which requires not only supporting infrastructures but human\nefforts to measure and calibrate the signal. Moreover, data collection for all\nlocations is indispensable in existing methods, which in turn hinders their\nlarge-scale deployment. In this paper, we propose a novel neural network based\narchitecture Graph Location Networks (GLN) to perform infrastructure-free,\nmulti-view image based indoor localization. GLN makes location predictions\nbased on robust location representations extracted from images through\nmessage-passing networks. Furthermore, we introduce a novel zero-shot indoor\nlocalization setting and tackle it by extending the proposed GLN to a dedicated\nzero-shot version, which exploits a novel mechanism Map2Vec to train\nlocation-aware embeddings and make predictions on novel unseen locations. Our\nextensive experiments show that the proposed approach outperforms\nstate-of-the-art methods in the standard setting, and achieves promising\naccuracy even in the zero-shot setting where data for half of the locations are\nnot available. The source code and datasets are publicly available at\nhttps://github.com/coldmanck/zero-shot-indoor-localization-release.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 07:36:55 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Chiou", "Meng-Jiun", ""], ["Liu", "Zhenguang", ""], ["Yin", "Yifang", ""], ["Liu", "Anan", ""], ["Zimmermann", "Roger", ""]]}, {"id": "2008.02516", "submitter": "Jinglin Liu", "authors": "Jinglin Liu, Yi Ren, Zhou Zhao, Chen Zhang, Baoxing Huai, Nicholas\n  Jing Yuan", "title": "FastLR: Non-Autoregressive Lipreading Model with Integrate-and-Fire", "comments": "Accepted by ACM MM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.CV cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lipreading is an impressive technique and there has been a definite\nimprovement of accuracy in recent years. However, existing methods for\nlipreading mainly build on autoregressive (AR) model, which generate target\ntokens one by one and suffer from high inference latency. To breakthrough this\nconstraint, we propose FastLR, a non-autoregressive (NAR) lipreading model\nwhich generates all target tokens simultaneously. NAR lipreading is a\nchallenging task that has many difficulties: 1) the discrepancy of sequence\nlengths between source and target makes it difficult to estimate the length of\nthe output sequence; 2) the conditionally independent behavior of NAR\ngeneration lacks the correlation across time which leads to a poor\napproximation of target distribution; 3) the feature representation ability of\nencoder can be weak due to lack of effective alignment mechanism; and 4) the\nremoval of AR language model exacerbates the inherent ambiguity problem of\nlipreading. Thus, in this paper, we introduce three methods to reduce the gap\nbetween FastLR and AR model: 1) to address challenges 1 and 2, we leverage\nintegrate-and-fire (I\\&F) module to model the correspondence between source\nvideo frames and output text sequence. 2) To tackle challenge 3, we add an\nauxiliary connectionist temporal classification (CTC) decoder to the top of the\nencoder and optimize it with extra CTC loss. We also add an auxiliary\nautoregressive decoder to help the feature extraction of encoder. 3) To\novercome challenge 4, we propose a novel Noisy Parallel Decoding (NPD) for I\\&F\nand bring Byte-Pair Encoding (BPE) into lipreading. Our experiments exhibit\nthat FastLR achieves the speedup up to 10.97$\\times$ comparing with\nstate-of-the-art lipreading model with slight WER absolute increase of 1.5\\%\nand 5.5\\% on GRID and LRS2 lipreading datasets respectively, which demonstrates\nthe effectiveness of our proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 08:28:56 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 12:17:54 GMT"}, {"version": "v3", "created": "Mon, 18 Jan 2021 05:04:54 GMT"}, {"version": "v4", "created": "Mon, 15 Mar 2021 07:23:19 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Liu", "Jinglin", ""], ["Ren", "Yi", ""], ["Zhao", "Zhou", ""], ["Zhang", "Chen", ""], ["Huai", "Baoxing", ""], ["Yuan", "Nicholas Jing", ""]]}, {"id": "2008.02528", "submitter": "Marco Schreyer", "authors": "Marco Schreyer, Timur Sattarov, Anita Gierbl, Bernd Reimer and Damian\n  Borth", "title": "Learning Sampling in Financial Statement Audits using Vector Quantised\n  Autoencoder Neural Networks", "comments": "8 pages, 5 figures, 3 tables, to appear in Proceedings of the ACM's\n  International Conference on AI in Finance (ICAIF'20), this paper is the\n  initial accepted version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The audit of financial statements is designed to collect reasonable assurance\nthat an issued statement is free from material misstatement 'true and fair\npresentation'. International audit standards require the assessment of a\nstatements' underlying accounting relevant transactions referred to as 'journal\nentries' to detect potential misstatements. To efficiently audit the increasing\nquantities of such entries, auditors regularly conduct a sample-based\nassessment referred to as 'audit sampling'. However, the task of audit sampling\nis often conducted early in the overall audit process. Often at a stage, in\nwhich an auditor might be unaware of all generative factors and their dynamics\nthat resulted in the journal entries in-scope of the audit. To overcome this\nchallenge, we propose the application of Vector Quantised-Variational\nAutoencoder (VQ-VAE) neural networks. We demonstrate, based on two real-world\ncity payment datasets, that such artificial neural networks are capable of\nlearning a quantised representation of accounting data. We show that the\nlearned quantisation uncovers (i) the latent factors of variation and (ii) can\nbe utilised as a highly representative audit sample in financial statement\naudits.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 09:02:02 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Schreyer", "Marco", ""], ["Sattarov", "Timur", ""], ["Gierbl", "Anita", ""], ["Reimer", "Bernd", ""], ["Borth", "Damian", ""]]}, {"id": "2008.02545", "submitter": "Timo Klock", "authors": "Alexander Cloninger and Timo Klock", "title": "A deep network construction that adapts to intrinsic dimensionality\n  beyond the domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximation of two-layer compositions $f(x) = g(\\phi(x))$ via\ndeep networks with ReLU activation, where $\\phi$ is a geometrically intuitive,\ndimensionality reducing feature map. We focus on two intuitive and practically\nrelevant choices for $\\phi$: the projection onto a low-dimensional embedded\nsubmanifold and a distance to a collection of low-dimensional sets. We achieve\nnear optimal approximation rates, which depend only on the complexity of the\ndimensionality reducing map $\\phi$ rather than the ambient dimension. Since\n$\\phi$ encapsulates all nonlinear features that are material to the function\n$f$, this suggests that deep nets are faithful to an intrinsic dimension\ngoverned by $f$ rather than the complexity of the domain of $f$. In particular,\nthe prevalent assumption of approximating functions on low-dimensional\nmanifolds can be significantly relaxed using functions of type $f(x) =\ng(\\phi(x))$ with $\\phi$ representing an orthogonal projection onto the same\nmanifold.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 09:50:29 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 10:24:45 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 09:05:48 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Cloninger", "Alexander", ""], ["Klock", "Timo", ""]]}, {"id": "2008.02546", "submitter": "Ye Bi", "authors": "Bo Huang, Ye Bi, Zhenyu Wu, Jianming Wang, Jing Xiao", "title": "UBER-GNN: A User-Based Embeddings Recommendation based on Graph Neural\n  Networks", "comments": "6 pages, accepted by CIKM 2019 GRLA workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of session-based recommendation aims to predict user next actions\nbased on session histories. Previous methods models session histories into\nsequences and estimate user latent features by RNN and GNN methods to make\nrecommendations. However under massive-scale and complicated financial\nrecommendation scenarios with both virtual and real commodities , such methods\nare not sufficient to represent accurate user latent features and neglect the\nlong-term characteristics of users. To take long-term preference and dynamic\ninterests into account, we propose a novel method, i.e. User-Based Embeddings\nRecommendation with Graph Neural Network, UBER-GNN for brevity. UBER-GNN takes\nadvantage of structured data to generate longterm user preferences, and\ntransfers session sequences into graphs to generate graph-based dynamic\ninterests. The final user latent feature is then represented as the composition\nof the long-term preferences and the dynamic interests using attention\nmechanism. Extensive experiments conducted on real Ping An scenario show that\nUBER-GNN outperforms the state-of-the-art session-based recommendation methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 09:54:03 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Huang", "Bo", ""], ["Bi", "Ye", ""], ["Wu", "Zhenyu", ""], ["Wang", "Jianming", ""], ["Xiao", "Jing", ""]]}, {"id": "2008.02577", "submitter": "Kathrin Blagec", "authors": "Kathrin Blagec, Georg Dorffner, Milad Moradi, Matthias Samwald", "title": "A critical analysis of metrics used for measuring progress in artificial\n  intelligence", "comments": "26 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparing model performances on benchmark datasets is an integral part of\nmeasuring and driving progress in artificial intelligence. A model's\nperformance on a benchmark dataset is commonly assessed based on a single or a\nsmall set of performance metrics. While this enables quick comparisons, it may\nalso entail the risk of inadequately reflecting model performance if the metric\ndoes not sufficiently cover all performance characteristics. Currently, it is\nunknown to what extent this might impact current benchmarking efforts. To\naddress this question, we analysed the current landscape of performance metrics\nbased on data covering 3867 machine learning model performance results from the\nweb-based open platform 'Papers with Code'. Our results suggest that the large\nmajority of metrics currently used to evaluate classification AI benchmark\ntasks have properties that may result in an inadequate reflection of a\nclassifiers' performance, especially when used with imbalanced datasets. While\nalternative metrics that address problematic properties have been proposed,\nthey are currently rarely applied as performance metrics in benchmarking tasks.\nFinally, we noticed that the reporting of metrics was partly inconsistent and\npartly unspecific, which may lead to ambiguities when comparing model\nperformances.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 11:14:37 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Blagec", "Kathrin", ""], ["Dorffner", "Georg", ""], ["Moradi", "Milad", ""], ["Samwald", "Matthias", ""]]}, {"id": "2008.02593", "submitter": "Thanh Nguyen", "authors": "Thanh Nguyen-Duc, He Zhao, Jianfei Cai and Dinh Phung", "title": "MED-TEX: Transferring and Explaining Knowledge with Less Data from\n  Pretrained Medical Imaging Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network based image classification methods usually require a\nlarge amount of training data and lack interpretability, which are critical in\nthe medical imaging domain. In this paper, we develop a novel knowledge\ndistillation and model interpretation framework for medical image\nclassification that jointly solves the above two issues. Specifically, to\naddress the data-hungry issue, we propose to learn a small student model with\nless data by distilling knowledge only from a cumbersome pretrained teacher\nmodel. To interpret the teacher model as well as assisting the learning of the\nstudent, an explainer module is introduced to highlight the regions of an input\nmedical image that are important for the predictions of the teacher model.\nFurthermore, the joint framework is trained by a principled way derived from\nthe information-theoretic perspective. Our framework performance is\ndemonstrated by the comprehensive experiments on the knowledge distillation and\nmodel interpretation tasks compared to state-of-the-art methods on a fundus\ndisease dataset.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 11:50:32 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Nguyen-Duc", "Thanh", ""], ["Zhao", "He", ""], ["Cai", "Jianfei", ""], ["Phung", "Dinh", ""]]}, {"id": "2008.02598", "submitter": "Ron Dorfman", "authors": "Ron Dorfman, Idan Shenfeld, Aviv Tamar", "title": "Offline Meta Learning of Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following instance of the Offline Meta Reinforcement Learning\n(OMRL) problem: given the complete training logs of $N$ conventional RL agents,\ntrained on $N$ different tasks, design a meta-agent that can quickly maximize\nreward in a new, unseen task from the same task distribution. In particular,\nwhile each conventional RL agent explored and exploited its own different task,\nthe meta-agent must identify regularities in the data that lead to effective\nexploration/exploitation in the unseen task. Here, we take a Bayesian RL (BRL)\nview, and seek to learn a Bayes-optimal policy from the offline data. Building\non the recent VariBAD BRL approach, we develop an off-policy BRL method that\nlearns to plan an exploration strategy based on an adaptive neural belief\nestimate. However, learning to infer such a belief from offline data brings a\nnew identifiability issue we term MDP ambiguity. We characterize the problem,\nand suggest resolutions via data collection and modification procedures.\nFinally, we evaluate our framework on a diverse set of domains, including\ndifficult sparse reward tasks, and demonstrate learning of effective\nexploration behavior that is qualitatively different from the exploration used\nby any RL agent in the data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 12:09:18 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 10:48:55 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2021 08:17:23 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Dorfman", "Ron", ""], ["Shenfeld", "Idan", ""], ["Tamar", "Aviv", ""]]}, {"id": "2008.02608", "submitter": "Jihong Park", "authors": "Jihong Park, Sumudu Samarakoon, Anis Elgabli, Joongheon Kim, Mehdi\n  Bennis, Seong-Lyun Kim, M\\'erouane Debbah", "title": "Communication-Efficient and Distributed Learning Over Wireless Networks:\n  Principles and Applications", "comments": "20 pages, 14 figures; This article has been submitted to IEEE for\n  possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) is a promising enabler for the fifth generation (5G)\ncommunication systems and beyond. By imbuing intelligence into the network\nedge, edge nodes can proactively carry out decision-making, and thereby react\nto local environmental changes and disturbances while experiencing zero\ncommunication latency. To achieve this goal, it is essential to cater for high\nML inference accuracy at scale under time-varying channel and network dynamics,\nby continuously exchanging fresh data and ML model updates in a distributed\nway. Taming this new kind of data traffic boils down to improving the\ncommunication efficiency of distributed learning by optimizing communication\npayload types, transmission techniques, and scheduling, as well as ML\narchitectures, algorithms, and data processing methods. To this end, this\narticle aims to provide a holistic overview of relevant communication and ML\nprinciples, and thereby present communication-efficient and distributed\nlearning frameworks with selected use cases.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 12:37:14 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Park", "Jihong", ""], ["Samarakoon", "Sumudu", ""], ["Elgabli", "Anis", ""], ["Kim", "Joongheon", ""], ["Bennis", "Mehdi", ""], ["Kim", "Seong-Lyun", ""], ["Debbah", "M\u00e9rouane", ""]]}, {"id": "2008.02616", "submitter": "Jan Blumenkamp", "authors": "Jan Blumenkamp, Amanda Prorok", "title": "The Emergence of Adversarial Communication in Multi-Agent Reinforcement\n  Learning", "comments": "Accepted to Conference on Robot Learning (CoRL) 2020. Camera-ready\n  version incorporating rebuttal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world problems require the coordination of multiple autonomous\nagents. Recent work has shown the promise of Graph Neural Networks (GNNs) to\nlearn explicit communication strategies that enable complex multi-agent\ncoordination. These works use models of cooperative multi-agent systems whereby\nagents strive to achieve a shared global goal. When considering agents with\nself-interested local objectives, the standard design choice is to model these\nas separate learning systems (albeit sharing the same environment). Such a\ndesign choice, however, precludes the existence of a single, differentiable\ncommunication channel, and consequently prohibits the learning of inter-agent\ncommunication strategies. In this work, we address this gap by presenting a\nlearning model that accommodates individual non-shared rewards and a\ndifferentiable communication channel that is common among all agents. We focus\non the case where agents have self-interested objectives, and develop a\nlearning algorithm that elicits the emergence of adversarial communications. We\nperform experiments on multi-agent coverage and path planning problems, and\nemploy a post-hoc interpretability technique to visualize the messages that\nagents communicate to each other. We show how a single self-interested agent is\ncapable of learning highly manipulative communication strategies that allows it\nto significantly outperform a cooperative team of agents.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 12:48:08 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 18:01:46 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Blumenkamp", "Jan", ""], ["Prorok", "Amanda", ""]]}, {"id": "2008.02622", "submitter": "Wouter van Heeswijk PhD", "authors": "W.J.A. van Heeswijk", "title": "A Gentle Lecture Note on Filtrations in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This note aims to provide a basic intuition on the concept of filtrations as\nused in the context of reinforcement learning (RL). Filtrations are often used\nto formally define RL problems, yet their implications might not be eminent for\nthose without a background in measure theory. Essentially, a filtration is a\nconstruct that captures partial knowledge up to time $t$, without revealing any\nfuture information that has already been simulated, yet not revealed to the\ndecision-maker. We illustrate this with simple examples from the finance domain\non both discrete and continuous outcome spaces. Furthermore, we show that the\nnotion of filtration is not needed, as basing decisions solely on the current\nproblem state (which is possible due to the Markovian property) suffices to\neliminate future knowledge from the decision-making process.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 12:55:39 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["van Heeswijk", "W. J. A.", ""]]}, {"id": "2008.02627", "submitter": "Francesco Verdoja", "authors": "Francesco Verdoja, Ville Kyrki", "title": "Notes on the Behavior of MC Dropout", "comments": "Presented at the ICML 2021 Workshop on \"Uncertainty and Robustness in\n  Deep Learning\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the various options to estimate uncertainty in deep neural networks,\nMonte-Carlo dropout is widely popular for its simplicity and effectiveness.\nHowever the quality of the uncertainty estimated through this method varies and\nchoices in architecture design and in training procedures have to be carefully\nconsidered and tested to obtain satisfactory results. In this paper we present\na study offering a different point of view on the behavior of Monte-Carlo\ndropout, which enables us to observe a few interesting properties of the\ntechnique to keep in mind when considering its use for uncertainty estimation.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 13:09:03 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 10:40:32 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Verdoja", "Francesco", ""], ["Kyrki", "Ville", ""]]}, {"id": "2008.02641", "submitter": "Benjamin Coleman", "authors": "Louis Abraham, Gary Becigneul, Benjamin Coleman, Bernhard Scholkopf,\n  Anshumali Shrivastava, Alexander Smola", "title": "Bloom Origami Assays: Practical Group Testing", "comments": "arXiv admin note: text overlap with arXiv:2005.06413", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem usually referred to as group testing in the context of\nCOVID-19. Given n samples collected from patients, how should we select and\ntest mixtures of samples to maximize information and minimize the number of\ntests? Group testing is a well-studied problem with several appealing\nsolutions, but recent biological studies impose practical constraints for\nCOVID-19 that are incompatible with traditional methods. Furthermore, existing\nmethods use unnecessarily restrictive solutions, which were devised for\nsettings with more memory and compute constraints than the problem at hand.\nThis results in poor utility. In the new setting, we obtain strong solutions\nfor small values of n using evolutionary strategies. We then develop a new\nmethod combining Bloom filters with belief propagation to scale to larger\nvalues of n (more than 100) with good empirical results. We also present a more\naccurate decoding algorithm that is tailored for specific COVID-19 settings.\nThis work demonstrates the practical gap between dedicated algorithms and\nwell-known generic solutions. Our efforts results in a new and practical\nmultiplex method yielding strong empirical performance without mixing more than\na chosen number of patients into the same probe. Finally, we briefly discuss\nadaptive methods, casting them into the framework of adaptive sub-modularity.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 19:31:41 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Abraham", "Louis", ""], ["Becigneul", "Gary", ""], ["Coleman", "Benjamin", ""], ["Scholkopf", "Bernhard", ""], ["Shrivastava", "Anshumali", ""], ["Smola", "Alexander", ""]]}, {"id": "2008.02648", "submitter": "Xueya Zhang", "authors": "Xueya Zhang and Tong Zhang and Xiaobin Hong and Zhen Cui and Jian Yang", "title": "Graph Wasserstein Correlation Analysis for Movie Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Movie graphs play an important role to bridge heterogenous modalities of\nvideos and texts in human-centric retrieval. In this work, we propose Graph\nWasserstein Correlation Analysis (GWCA) to deal with the core issue therein,\ni.e, cross heterogeneous graph comparison. Spectral graph filtering is\nintroduced to encode graph signals, which are then embedded as probability\ndistributions in a Wasserstein space, called graph Wasserstein metric learning.\nSuch a seamless integration of graph signal filtering together with metric\nlearning results in a surprise consistency on both learning processes, in which\nthe goal of metric learning is just to optimize signal filters or vice versa.\nFurther, we derive the solution of the graph comparison model as a classic\ngeneralized eigenvalue decomposition problem, which has an exactly closed-form\nsolution. Finally, GWCA together with movie/text graphs generation are unified\ninto the framework of movie retrieval to evaluate our proposed method.\nExtensive experiments on MovieGrpahs dataset demonstrate the effectiveness of\nour GWCA as well as the entire framework.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 13:30:47 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Zhang", "Xueya", ""], ["Zhang", "Tong", ""], ["Hong", "Xiaobin", ""], ["Cui", "Zhen", ""], ["Yang", "Jian", ""]]}, {"id": "2008.02651", "submitter": "Rogier Van Dalen", "authors": "Filip Granqvist, Matt Seigel, Rogier van Dalen, \\'Aine Cahill, Stephen\n  Shum, Matthias Paulik", "title": "Improving on-device speaker verification using federated learning with\n  privacy", "comments": "To appear in proceedings of INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information on speaker characteristics can be useful as side information in\nimproving speaker recognition accuracy. However, such information is often\nprivate. This paper investigates how privacy-preserving learning can improve a\nspeaker verification system, by enabling the use of privacy-sensitive speaker\ndata to train an auxiliary classification model that predicts vocal\ncharacteristics of speakers. In particular, this paper explores the utility\nachieved by approaches which combine different federated learning and\ndifferential privacy mechanisms. These approaches make it possible to train a\ncentral model while protecting user privacy, with users' data remaining on\ntheir devices. Furthermore, they make learning on a large population of\nspeakers possible, ensuring good coverage of speaker characteristics when\ntraining a model. The auxiliary model described here uses features extracted\nfrom phrases which trigger a speaker verification system. From these features,\nthe model predicts speaker characteristic labels considered useful as side\ninformation. The knowledge of the auxiliary model is distilled into a speaker\nverification system using multi-task learning, with the side information labels\npredicted by this auxiliary model being the additional task. This approach\nresults in a 6% relative improvement in equal error rate over a baseline\nsystem.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 13:37:14 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Granqvist", "Filip", ""], ["Seigel", "Matt", ""], ["van Dalen", "Rogier", ""], ["Cahill", "\u00c1ine", ""], ["Shum", "Stephen", ""], ["Paulik", "Matthias", ""]]}, {"id": "2008.02663", "submitter": "Kasun Bandara", "authors": "Kasun Bandara, Hansika Hewamalage, Yuan-Hao Liu, Yanfei Kang,\n  Christoph Bergmeir", "title": "Improving the Accuracy of Global Forecasting Models using Time Series\n  Data Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting models that are trained across sets of many time series, known as\nGlobal Forecasting Models (GFM), have shown recently promising results in\nforecasting competitions and real-world applications, outperforming many\nstate-of-the-art univariate forecasting techniques. In most cases, GFMs are\nimplemented using deep neural networks, and in particular Recurrent Neural\nNetworks (RNN), which require a sufficient amount of time series to estimate\ntheir numerous model parameters. However, many time series databases have only\na limited number of time series. In this study, we propose a novel, data\naugmentation based forecasting framework that is capable of improving the\nbaseline accuracy of the GFM models in less data-abundant settings. We use\nthree time series augmentation techniques: GRATIS, moving block bootstrap\n(MBB), and dynamic time warping barycentric averaging (DBA) to synthetically\ngenerate a collection of time series. The knowledge acquired from these\naugmented time series is then transferred to the original dataset using two\ndifferent approaches: the pooled approach and the transfer learning approach.\nWhen building GFMs, in the pooled approach, we train a model on the augmented\ntime series alongside the original time series dataset, whereas in the transfer\nlearning approach, we adapt a pre-trained model to the new dataset. In our\nevaluation on competition and real-world time series datasets, our proposed\nvariants can significantly improve the baseline accuracy of GFM models and\noutperform state-of-the-art univariate forecasting methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 13:52:20 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Bandara", "Kasun", ""], ["Hewamalage", "Hansika", ""], ["Liu", "Yuan-Hao", ""], ["Kang", "Yanfei", ""], ["Bergmeir", "Christoph", ""]]}, {"id": "2008.02667", "submitter": "Aritra Banerjee", "authors": "Aritra Banerjee", "title": "Machine Learning for Health: Personalized Models for Forecasting of\n  Alzheimer Disease Progression", "comments": "51 pages, 25 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis the aim is to work on optimizing the modern machine learning\nmodels for personalized forecasting of Alzheimer Disease (AD) Progression from\nclinical trial data. The data comes from the TADPOLE challenge, which is one of\nthe largest publicly available datasets for AD research (ADNI dataset). The\ngoal of the project is to develop machine learning models that can be used to\nperform personalized forecasts of the participants cognitive changes (e.g.,\nADAS-Cog13 scores) over the time period of 6,12, 18 and 24 months in the future\nand the change in Clinical Status (CS) i.e., whether a person will convert to\nAD within 2 years or not. This is important for informing current clinical\ntrials and better design of future clinical trials for AD. We will work with\npersonalized Gaussian processes as machine learning models to predict\nADAS-Cog13 score and Cox model along with a classifier to predict the\nconversion in a patient within 2 years.This project is done with the\ncollaboration with researchers from the MIT MediaLab.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 17:33:22 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Banerjee", "Aritra", ""]]}, {"id": "2008.02669", "submitter": "Mohammad Ghadir Khoshkholgh Dashtaki", "authors": "Mohammad G. Khoshkholgh and Halim Yanikomeroglu", "title": "Learning Power Control from a Fixed Batch of Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.IT cs.LG cs.SY eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address how to exploit power control data, gathered from a monitored\nenvironment, for performing power control in an unexplored environment. We\nadopt offline deep reinforcement learning, whereby the agent learns the policy\nto produce the transmission powers solely by using the data. Experiments\ndemonstrate that despite discrepancies between the monitored and unexplored\nenvironments, the agent successfully learns the power control very quickly,\neven if the objective functions in the monitored and unexplored environments\nare dissimilar. About one third of the collected data is sufficient to be of\nhigh-quality and the rest can be from any sub-optimal algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 01:00:21 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Khoshkholgh", "Mohammad G.", ""], ["Yanikomeroglu", "Halim", ""]]}, {"id": "2008.02672", "submitter": "Alex Gorodetsky", "authors": "Alex Gorodetsky and John D. Jakeman and Gianluca Geraci", "title": "MFNets: Learning network representations for multifidelity surrogate\n  modeling", "comments": "21 pages,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an approach for constructing multifidelity surrogate\nmodels to simultaneously represent, and learn representations of, multiple\ninformation sources. The approach formulates a network of surrogate models\nwhose relationships are defined via localized scalings and shifts. The network\ncan have general structure, and can represent a significantly greater variety\nof modeling relationships than the hierarchical/recursive networks used in the\ncurrent state of the art. We show empirically that this flexibility achieves\ngreatest gains in the low-data regime, where the network structure must more\nefficiently leverage the connections between data sources to yield accurate\npredictions. We demonstrate our approach on four examples ranging from\nsynthetic to physics-based simulation models. For the numerical test cases\nadopted here, we obtained an order-of-magnitude reduction in errors compared to\nmultifidelity hierarchical and single-fidelity approaches.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 16:21:33 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Gorodetsky", "Alex", ""], ["Jakeman", "John D.", ""], ["Geraci", "Gianluca", ""]]}, {"id": "2008.02676", "submitter": "Yang Li", "authors": "Yang Li, Haidong Yi, Christopher M. Bender, Siyuan Shan, Junier B.\n  Oliva", "title": "Exchangeable Neural ODE for Set Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning over an instance composed of a set of vectors, like a point cloud,\nrequires that one accounts for intra-set dependent features among elements.\nHowever, since such instances are unordered, the elements' features should\nremain unchanged when the input's order is permuted. This property, permutation\nequivariance, is a challenging constraint for most neural architectures. While\nrecent work has proposed global pooling and attention-based solutions, these\nmay be limited in the way that intradependencies are captured in practice. In\nthis work we propose a more general formulation to achieve permutation\nequivariance through ordinary differential equations (ODE). Our proposed\nmodule, Exchangeable Neural ODE (ExNODE), can be seamlessly applied for both\ndiscriminative and generative tasks. We also extend set modeling in the\ntemporal dimension and propose a VAE based model for temporal set modeling.\nExtensive experiments demonstrate the efficacy of our method over strong\nbaselines.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 14:11:36 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Li", "Yang", ""], ["Yi", "Haidong", ""], ["Bender", "Christopher M.", ""], ["Shan", "Siyuan", ""], ["Oliva", "Junier B.", ""]]}, {"id": "2008.02686", "submitter": "Liangfa Wei", "authors": "Liangfa Wei, Jie Zhang, Junfeng Hou and Lirong Dai", "title": "Attentive Fusion Enhanced Audio-Visual Encoding for Transformer Based\n  Robust Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.MM cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio-visual information fusion enables a performance improvement in speech\nrecognition performed in complex acoustic scenarios, e.g., noisy environments.\nIt is required to explore an effective audio-visual fusion strategy for\naudiovisual alignment and modality reliability. Different from the previous\nend-to-end approaches where the audio-visual fusion is performed after encoding\neach modality, in this paper we propose to integrate an attentive fusion block\ninto the encoding process. It is shown that the proposed audio-visual fusion\nmethod in the encoder module can enrich audio-visual representations, as the\nrelevance between the two modalities is leveraged. In line with the\ntransformer-based architecture, we implement the embedded fusion block using a\nmulti-head attention based audiovisual fusion with one-way or two-way\ninteractions. The proposed method can sufficiently combine the two streams and\nweaken the over-reliance on the audio modality. Experiments on the LRS3-TED\ndataset demonstrate that the proposed method can increase the recognition rate\nby 0.55%, 4.51% and 4.61% on average under the clean, seen and unseen noise\nconditions, respectively, compared to the state-of-the-art approach.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 14:39:07 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Wei", "Liangfa", ""], ["Zhang", "Jie", ""], ["Hou", "Junfeng", ""], ["Dai", "Lirong", ""]]}, {"id": "2008.02689", "submitter": "Tam\\'as Gr\\'osz", "authors": "Tam\\'as Gr\\'osz, Mittul Singh, Sudarsana Reddy Kadiri, Hemant\n  Kathania, Mikko Kurimo", "title": "Aalto's End-to-End DNN systems for the INTERSPEECH 2020 Computational\n  Paralinguistics Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  End-to-end neural network models (E2E) have shown significant performance\nbenefits on different INTERSPEECH ComParE tasks. Prior work has applied either\na single instance of an E2E model for a task or the same E2E architecture for\ndifferent tasks. However, applying a single model is unstable or using the same\narchitecture under-utilizes task-specific information. On ComParE 2020 tasks,\nwe investigate applying an ensemble of E2E models for robust performance and\ndeveloping task-specific modifications for each task. ComParE 2020 introduces\nthree sub-challenges: the breathing sub-challenge to predict the output of a\nrespiratory belt worn by a patient while speaking, the elderly sub-challenge to\nestimate the elderly speaker's arousal and valence levels and the mask\nsub-challenge to classify if the speaker is wearing a mask or not. On each of\nthese tasks, an ensemble outperforms the single E2E model. On the breathing\nsub-challenge, we study the impact of multi-loss strategies on task\nperformance. On the elderly sub-challenge, predicting the valence and arousal\nlevels prompts us to investigate multi-task training and implement data\nsampling strategies to handle class imbalance. On the mask sub-challenge, using\nan E2E system without feature engineering is competitive to feature-engineered\nbaselines and provides substantial gains when combined with feature-engineered\nbaselines.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 14:45:10 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Gr\u00f3sz", "Tam\u00e1s", ""], ["Singh", "Mittul", ""], ["Kadiri", "Sudarsana Reddy", ""], ["Kathania", "Hemant", ""], ["Kurimo", "Mikko", ""]]}, {"id": "2008.02699", "submitter": "Yutong Xie", "authors": "Yutong Xie, Jianpeng Zhang, Zhibin Liao, Chunhua Shen, Johan Verjans,\n  Yong Xia", "title": "Pairwise Relation Learning for Semi-supervised Gland Segmentation", "comments": "Accepted by MICCAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Accurate and automated gland segmentation on histology tissue images is an\nessential but challenging task in the computer-aided diagnosis of\nadenocarcinoma. Despite their prevalence, deep learning models always require a\nmyriad number of densely annotated training images, which are difficult to\nobtain due to extensive labor and associated expert costs related to histology\nimage annotations. In this paper, we propose the pairwise relation-based\nsemi-supervised (PRS^2) model for gland segmentation on histology images. This\nmodel consists of a segmentation network (S-Net) and a pairwise relation\nnetwork (PR-Net). The S-Net is trained on labeled data for segmentation, and\nPR-Net is trained on both labeled and unlabeled data in an unsupervised way to\nenhance its image representation ability via exploiting the semantic\nconsistency between each pair of images in the feature space. Since both\nnetworks share their encoders, the image representation ability learned by\nPR-Net can be transferred to S-Net to improve its segmentation performance. We\nalso design the object-level Dice loss to address the issues caused by touching\nglands and combine it with other two loss functions for S-Net. We evaluated our\nmodel against five recent methods on the GlaS dataset and three recent methods\non the CRAG dataset. Our results not only demonstrate the effectiveness of the\nproposed PR-Net and object-level Dice loss, but also indicate that our PRS^2\nmodel achieves the state-of-the-art gland segmentation performance on both\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 15:02:38 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Xie", "Yutong", ""], ["Zhang", "Jianpeng", ""], ["Liao", "Zhibin", ""], ["Shen", "Chunhua", ""], ["Verjans", "Johan", ""], ["Xia", "Yong", ""]]}, {"id": "2008.02714", "submitter": "Yuan Yao", "authors": "Yuan Yao, Xutao Li, Yu Zhang, and Yunming Ye", "title": "Multi-source Heterogeneous Domain Adaptation with Conditional Weighting\n  Adversarial Network", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous domain adaptation (HDA) tackles the learning of cross-domain\nsamples with both different probability distributions and feature\nrepresentations. Most of existing HDA studies focus on the single-source\nscenario. In reality, however, it is not uncommon to obtain samples from\nmultiple heterogeneous domains. In this paper, we study the multi-source\nheterogeneous domain adaptation problem, and propose a Conditional Weighting\nAdversarial Network (CWAN) to address it. The proposed CWAN adversarially\nlearns a feature transformer, a label classifier, and a domain discriminator.\nTo quantify the importance of different source domains, CWAN introduces a\nsophisticated conditional weighting scheme to calculate the weights of the\nsource domains according to the conditional distribution divergence between the\nsource and target domains. Different from existing weighting schemes, the\nproposed conditional weighting scheme not only weights the source domains but\nalso implicitly aligns the conditional distributions during the optimization\nprocess. Experimental results clearly demonstrate that the proposed CWAN\nperforms much better than several state-of-the-art methods on three real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 15:31:44 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Yao", "Yuan", ""], ["Li", "Xutao", ""], ["Zhang", "Yu", ""], ["Ye", "Yunming", ""]]}, {"id": "2008.02731", "submitter": "Siddharth Srivastava", "authors": "Ayush Khaneja, Siddharth Srivastava, Astha Rai, A S Cheema, P K\n  Srivastava", "title": "Analysing Risk of Coronary Heart Disease through Discriminative Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of data mining, machine learning and artificial intelligence\ntechniques in the field of diagnostics is not a new concept, and these\ntechniques have been very successfully applied in a variety of applications,\nespecially in dermatology and cancer research. But, in the case of medical\nproblems that involve tests resulting in true or false (binary classification),\nthe data generally has a class imbalance with samples majorly belonging to one\nclass (ex: a patient undergoes a regular test and the results are false). Such\ndisparity in data causes problems when trying to model predictive systems on\nthe data. In critical applications like diagnostics, this class imbalance\ncannot be overlooked and must be given extra attention. In our research, we\ndepict how we can handle this class imbalance through neural networks using a\ndiscriminative model and contrastive loss using a Siamese neural network\nstructure. Such a model does not work on a probability-based approach to\nclassify samples into labels. Instead it uses a distance-based approach to\ndifferentiate between samples classified under different labels. The code is\navailable at https://tinyurl.com/DiscriminativeCHD/\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 06:30:00 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Khaneja", "Ayush", ""], ["Srivastava", "Siddharth", ""], ["Rai", "Astha", ""], ["Cheema", "A S", ""], ["Srivastava", "P K", ""]]}, {"id": "2008.02734", "submitter": "Christopher Tralie", "authors": "Christopher Tralie, Elizabeth Dempsey", "title": "Exact, Parallelizable Dynamic Time Warping Alignment with Linear Memory", "comments": "12 Pages, 6 Figures, 1 Table, ISMIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG cs.MM eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio alignment is a fundamental preprocessing step in many MIR pipelines.\nFor two audio clips with M and N frames, respectively, the most popular\napproach, dynamic time warping (DTW), has O(MN) requirements in both memory and\ncomputation, which is prohibitive for frame-level alignments at reasonable\nrates. To address this, a variety of memory efficient algorithms exist to\napproximate the optimal alignment under the DTW cost. To our knowledge,\nhowever, no exact algorithms exist that are guaranteed to break the quadratic\nmemory barrier. In this work, we present a divide and conquer algorithm that\ncomputes the exact globally optimal DTW alignment using O(M+N) memory. Its\nruntime is still O(MN), trading off memory for a 2x increase in computation.\nHowever, the algorithm can be parallelized up to a factor of min(M, N) with the\nsame memory constraints, so it can still run more efficiently than the textbook\nversion with an adequate GPU. We use our algorithm to compute exact alignments\non a collection of orchestral music, which we use as ground truth to benchmark\nthe alignment accuracy of several popular approximate alignment schemes at\nscales that were not previously possible.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 15:00:33 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Tralie", "Christopher", ""], ["Dempsey", "Elizabeth", ""]]}, {"id": "2008.02736", "submitter": "Dhrubasish Sarkar Prof.", "authors": "Dhrubasish Sarkar", "title": "Recommending Influenceable Targets based on Influence Propagation\n  through Activity Behaviors in Online Social Media", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online Social Media (OSM) is a platform through which the users present\nthemselves to the connected world by means of messaging, posting, reacting,\ntagging, and sharing on different contents with also other social activities.\nNowadays, it has a vast impact on various aspects of the industry, business and\nsociety along with on users life. In an OSN platform, reaching the target users\nis one of the primary focus for most of the businesses and other organizations.\nIdentification and recommendation of influenceable targets help to capture the\nappropriate audience efficiently and effectively. In this paper, an effective\nmodel has been discussed in egocentric OSN by incorporating an efficient\ninfluence measured Recommendation System in order to generate a list of top\nmost influenceable target users among all connected network members for any\nspecific social network user. Firstly the list of interacted network members\nhas been updated based on all activities. On which the interacted network\nmembers with most similar activities have been recommended based on the\nspecific influence category with sentiment type. After that, the top most\ninfluenceable network members in the basis of the required amount among those\nupdated list of interacted network members have been identified with proper\nranking by analyzing the similarity and frequency of their activity contents\nwith respect to the activity contents of the main user. Through these two\ncontinuous stages, an effective list of top influenceable targets of the main\nuser has been distinguished from the egocentric view of any social network.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 20:53:20 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Sarkar", "Dhrubasish", ""]]}, {"id": "2008.02754", "submitter": "Xavier Ferrer Aran", "authors": "Xavier Ferrer, Tom van Nuenen, Jose M. Such, Natalia Criado", "title": "Discovering and Categorising Language Biases in Reddit", "comments": "Author's copy of the paper accepted at the International AAAI\n  Conference on Web and Social Media (ICWSM 2021)", "journal-ref": "International AAAI Conference on Web and Social Media (ICWSM 2021)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a data-driven approach using word embeddings to discover and\ncategorise language biases on the discussion platform Reddit. As spaces for\nisolated user communities, platforms such as Reddit are increasingly connected\nto issues of racism, sexism and other forms of discrimination. Hence, there is\na need to monitor the language of these groups. One of the most promising AI\napproaches to trace linguistic biases in large textual datasets involves word\nembeddings, which transform text into high-dimensional dense vectors and\ncapture semantic relations between words. Yet, previous studies require\npredefined sets of potential biases to study, e.g., whether gender is more or\nless associated with particular types of jobs. This makes these approaches\nunfit to deal with smaller and community-centric datasets such as those on\nReddit, which contain smaller vocabularies and slang, as well as biases that\nmay be particular to that community. This paper proposes a data-driven approach\nto automatically discover language biases encoded in the vocabulary of online\ndiscourse communities on Reddit. In our approach, protected attributes are\nconnected to evaluative words found in the data, which are then categorised\nthrough a semantic analysis system. We verify the effectiveness of our method\nby comparing the biases we discover in the Google News dataset with those found\nin previous literature. We then successfully discover gender bias, religion\nbias, and ethnic bias in different Reddit communities. We conclude by\ndiscussing potential application scenarios and limitations of this data-driven\nbias discovery method.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 16:42:10 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 18:38:21 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Ferrer", "Xavier", ""], ["van Nuenen", "Tom", ""], ["Such", "Jose M.", ""], ["Criado", "Natalia", ""]]}, {"id": "2008.02775", "submitter": "Elizaveta Kharlova", "authors": "Elizaveta Kharlova, Daniel May, Petr Musilek (University of Alberta)", "title": "Forecasting Photovoltaic Power Production using a Deep Learning Sequence\n  to Sequence Model with Attention", "comments": "2020 International Joint Conference on Neural Networks (IJCNN),\n  Glasgow, United Kingdom, 2020, pp. 1-7", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207573", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rising penetration levels of (residential) photovoltaic (PV) power as\ndistributed energy resource pose a number of challenges to the electricity\ninfrastructure. High quality, general tools to provide accurate forecasts of\npower production are urgently needed. In this article, we propose a supervised\ndeep learning model for end-to-end forecasting of PV power production. The\nproposed model is based on two seminal concepts that led to significant\nperformance improvements of deep learning approaches in other sequence-related\nfields, but not yet in the area of time series prediction: the sequence to\nsequence architecture and attention mechanism as a context generator. The\nproposed model leverages numerical weather predictions and high-resolution\nhistorical measurements to forecast a binned probability distribution over the\nprognostic time intervals, rather than the expected values of the prognostic\nvariable. This design offers significant performance improvements compared to\ncommon baseline approaches, such as fully connected neural networks and\none-block long short-term memory architectures. Using normalized root mean\nsquare error based forecast skill score as a performance indicator, the\nproposed approach is compared to other models. The results show that the new\ndesign performs at or above the current state of the art of PV power\nforecasting.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 17:20:08 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 19:23:29 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Kharlova", "Elizaveta", "", "University of Alberta"], ["May", "Daniel", "", "University of Alberta"], ["Musilek", "Petr", "", "University of Alberta"]]}, {"id": "2008.02778", "submitter": "Omar Delarosa", "authors": "Omar Delarosa, Hang Dong, Mindy Ruan, Ahmed Khalifa, Julian Togelius", "title": "Mixed-Initiative Level Design with RL Brush", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces RL Brush, a level-editing tool for tile-based games\ndesigned for mixed-initiative co-creation. The tool uses\nreinforcement-learning-based models to augment manual human level-design\nthrough the addition of AI-generated suggestions. Here, we apply RL Brush to\ndesigning levels for the classic puzzle game Sokoban. We put the tool online\nand tested it in 39 different sessions. The results show that users using the\nAI suggestions stay around longer and their created levels on average are more\nplayable and more complex than without.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 17:25:14 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 23:27:39 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 20:18:28 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Delarosa", "Omar", ""], ["Dong", "Hang", ""], ["Ruan", "Mindy", ""], ["Khalifa", "Ahmed", ""], ["Togelius", "Julian", ""]]}, {"id": "2008.02790", "submitter": "Evan Liu", "authors": "Evan Zheran Liu, Aditi Raghunathan, Percy Liang, Chelsea Finn", "title": "Decoupling Exploration and Exploitation for Meta-Reinforcement Learning\n  without Sacrifices", "comments": "International Conference on Machine Learning (ICML), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of meta-reinforcement learning (meta-RL) is to build agents that can\nquickly learn new tasks by leveraging prior experience on related tasks.\nLearning a new task often requires both exploring to gather task-relevant\ninformation and exploiting this information to solve the task. In principle,\noptimal exploration and exploitation can be learned end-to-end by simply\nmaximizing task performance. However, such meta-RL approaches struggle with\nlocal optima due to a chicken-and-egg problem: learning to explore requires\ngood exploitation to gauge the exploration's utility, but learning to exploit\nrequires information gathered via exploration. Optimizing separate objectives\nfor exploration and exploitation can avoid this problem, but prior meta-RL\nexploration objectives yield suboptimal policies that gather information\nirrelevant to the task. We alleviate both concerns by constructing an\nexploitation objective that automatically identifies task-relevant information\nand an exploration objective to recover only this information. This avoids\nlocal optima in end-to-end training, without sacrificing optimal exploration.\nEmpirically, DREAM substantially outperforms existing approaches on complex\nmeta-RL problems, such as sparse-reward 3D visual navigation. Videos of DREAM:\nhttps://ezliu.github.io/dream/\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 17:57:36 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 18:54:30 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 17:53:14 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Liu", "Evan Zheran", ""], ["Raghunathan", "Aditi", ""], ["Liang", "Percy", ""], ["Finn", "Chelsea", ""]]}, {"id": "2008.02792", "submitter": "Davis Rempe", "authors": "Davis Rempe, Tolga Birdal, Yongheng Zhao, Zan Gojcic, Srinath Sridhar,\n  Leonidas J. Guibas", "title": "CaSPR: Learning Canonical Spatiotemporal Point Cloud Representations", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose CaSPR, a method to learn object-centric Canonical Spatiotemporal\nPoint Cloud Representations of dynamically moving or evolving objects. Our goal\nis to enable information aggregation over time and the interrogation of object\nstate at any spatiotemporal neighborhood in the past, observed or not.\nDifferent from previous work, CaSPR learns representations that support\nspacetime continuity, are robust to variable and irregularly spacetime-sampled\npoint clouds, and generalize to unseen object instances. Our approach divides\nthe problem into two subtasks. First, we explicitly encode time by mapping an\ninput point cloud sequence to a spatiotemporally-canonicalized object space. We\nthen leverage this canonicalization to learn a spatiotemporal latent\nrepresentation using neural ordinary differential equations and a generative\nmodel of dynamically evolving shapes using continuous normalizing flows. We\ndemonstrate the effectiveness of our method on several applications including\nshape reconstruction, camera pose estimation, continuous spatiotemporal\nsequence reconstruction, and correspondence estimation from irregularly or\nintermittently sampled observations.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 17:58:48 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 19:00:31 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Rempe", "Davis", ""], ["Birdal", "Tolga", ""], ["Zhao", "Yongheng", ""], ["Gojcic", "Zan", ""], ["Sridhar", "Srinath", ""], ["Guibas", "Leonidas J.", ""]]}, {"id": "2008.02830", "submitter": "Adam Polyak", "authors": "Adam Polyak, Lior Wolf, Yossi Adi, Yaniv Taigman", "title": "Unsupervised Cross-Domain Singing Voice Conversion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a wav-to-wav generative model for the task of singing voice\nconversion from any identity. Our method utilizes both an acoustic model,\ntrained for the task of automatic speech recognition, together with melody\nextracted features to drive a waveform-based generator. The proposed generative\narchitecture is invariant to the speaker's identity and can be trained to\ngenerate target singers from unlabeled training data, using either speech or\nsinging sources. The model is optimized in an end-to-end fashion without any\nmanual supervision, such as lyrics, musical notes or parallel samples. The\nproposed approach is fully-convolutional and can generate audio in real-time.\nExperiments show that our method significantly outperforms the baseline methods\nwhile generating convincingly better audio samples than alternative attempts.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 18:29:11 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Polyak", "Adam", ""], ["Wolf", "Lior", ""], ["Adi", "Yossi", ""], ["Taigman", "Yaniv", ""]]}, {"id": "2008.02837", "submitter": "Preslav Nakov", "authors": "Anton Chernyavskiy, Dmitry Ilvovsky, Preslav Nakov", "title": "aschern at SemEval-2020 Task 11: It Takes Three to Tango: RoBERTa, CRF,\n  and Transfer Learning", "comments": "propaganda, persuasion, disinformation, fake news", "journal-ref": "SemEval-2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our system for SemEval-2020 Task 11 on Detection of Propaganda\nTechniques in News Articles. We developed ensemble models using RoBERTa-based\nneural architectures, additional CRF layers, transfer learning between the two\nsubtasks, and advanced post-processing to handle the multi-label nature of the\ntask, the consistency between nested spans, repetitions, and labels from\nsimilar spans in training. We achieved sizable improvements over baseline\nfine-tuned RoBERTa models, and the official evaluation ranked our system 3rd\n(almost tied with the 2nd) out of 36 teams on the span identification subtask\nwith an F1 score of 0.491, and 2nd (almost tied with the 1st) out of 31 teams\non the technique classification subtask with an F1 score of 0.62.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 18:45:25 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Chernyavskiy", "Anton", ""], ["Ilvovsky", "Dmitry", ""], ["Nakov", "Preslav", ""]]}, {"id": "2008.02839", "submitter": "Subhadip Mukherjee", "authors": "Subhadip Mukherjee, S\\\"oren Dittmer, Zakhar Shumaylov, Sebastian Lunz,\n  Ozan \\\"Oktem, and Carola-Bibiane Sch\\\"onlieb", "title": "Learned convex regularizers for inverse problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the variational reconstruction framework for inverse problems and\npropose to learn a data-adaptive input-convex neural network (ICNN) as the\nregularization functional. The ICNN-based convex regularizer is trained\nadversarially to discern ground-truth images from unregularized\nreconstructions. Convexity of the regularizer is desirable since (i) one can\nestablish analytical convergence guarantees for the corresponding variational\nreconstruction problem and (ii) devise efficient and provable algorithms for\nreconstruction. In particular, we show that the optimal solution to the\nvariational problem converges to the ground-truth if the penalty parameter\ndecays sub-linearly with respect to the norm of the noise. Further, we prove\nthe existence of a sub-gradient-based algorithm that leads to a monotonically\ndecreasing error in the parameter space with iterations. To demonstrate the\nperformance of our approach for solving inverse problems, we consider the tasks\nof deblurring natural images and reconstructing images in computed tomography\n(CT), and show that the proposed convex regularizer is at least competitive\nwith and sometimes superior to state-of-the-art data-driven techniques for\ninverse problems.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 18:58:35 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 18:56:30 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Mukherjee", "Subhadip", ""], ["Dittmer", "S\u00f6ren", ""], ["Shumaylov", "Zakhar", ""], ["Lunz", "Sebastian", ""], ["\u00d6ktem", "Ozan", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""]]}, {"id": "2008.02840", "submitter": "Siddharth Reddy", "authors": "Siddharth Reddy, Sergey Levine, Anca D. Dragan", "title": "Assisted Perception: Optimizing Observations to Communicate State", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to help users estimate the state of the world in tasks like robotic\nteleoperation and navigation with visual impairments, where users may have\nsystematic biases that lead to suboptimal behavior: they might struggle to\nprocess observations from multiple sensors simultaneously, receive delayed\nobservations, or overestimate distances to obstacles. While we cannot directly\nchange the user's internal beliefs or their internal state estimation process,\nour insight is that we can still assist them by modifying the user's\nobservations. Instead of showing the user their true observations, we\nsynthesize new observations that lead to more accurate internal state estimates\nwhen processed by the user. We refer to this method as assistive state\nestimation (ASE): an automated assistant uses the true observations to infer\nthe state of the world, then generates a modified observation for the user to\nconsume (e.g., through an augmented reality interface), and optimizes the\nmodification to induce the user's new beliefs to match the assistant's current\nbeliefs. We evaluate ASE in a user study with 12 participants who each perform\nfour tasks: two tasks with known user biases -- bandwidth-limited image\nclassification and a driving video game with observation delay -- and two with\nunknown biases that our method has to learn -- guided 2D navigation and a lunar\nlander teleoperation video game. A different assistance strategy emerges in\neach domain, such as quickly revealing informative pixels to speed up image\nclassification, using a dynamics model to undo observation delay in driving,\nidentifying nearby landmarks for navigation, and exaggerating a visual\nindicator of tilt in the lander game. The results show that ASE substantially\nimproves the task performance of users with bandwidth constraints, observation\ndelay, and other unknown biases.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 19:08:05 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Reddy", "Siddharth", ""], ["Levine", "Sergey", ""], ["Dragan", "Anca D.", ""]]}, {"id": "2008.02852", "submitter": "Andrew Miller", "authors": "Andrew C. Miller and Nicholas J. Foti and Emily Fox", "title": "Learning Insulin-Glucose Dynamics in the Wild", "comments": "Machine Learning for Healthcare 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new model of insulin-glucose dynamics for forecasting blood\nglucose in type 1 diabetics. We augment an existing biomedical model by\nintroducing time-varying dynamics driven by a machine learning sequence model.\nOur model maintains a physiologically plausible inductive bias and clinically\ninterpretable parameters -- e.g., insulin sensitivity -- while inheriting the\nflexibility of modern pattern recognition algorithms. Critical to modeling\nsuccess are the flexible, but structured representations of subject variability\nwith a sequence model. In contrast, less constrained models like the LSTM fail\nto provide reliable or physiologically plausible forecasts. We conduct an\nextensive empirical study. We show that allowing biomedical model dynamics to\nvary in time improves forecasting at long time horizons, up to six hours, and\nproduces forecasts consistent with the physiological effects of insulin and\ncarbohydrates.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 19:47:00 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Miller", "Andrew C.", ""], ["Foti", "Nicholas J.", ""], ["Fox", "Emily", ""]]}, {"id": "2008.02856", "submitter": "Kushal Chakrabarti", "authors": "Kushal Chakrabarti, Nirupam Gupta, Nikhil Chopra", "title": "Iterative Pre-Conditioning for Expediting the Gradient-Descent Method:\n  The Distributed Linear Least-Squares Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the multi-agent linear least-squares problem in a\nserver-agent network. In this problem, the system comprises multiple agents,\neach having a set of local data points, that are connected to a server. The\ngoal for the agents is to compute a linear mathematical model that optimally\nfits the collective data points held by all the agents, without sharing their\nindividual local data points. This goal can be achieved, in principle, using\nthe server-agent variant of the traditional iterative gradient-descent method.\nThe gradient-descent method converges linearly to a solution, and its rate of\nconvergence is lower bounded by the conditioning of the agents' collective data\npoints. If the data points are ill-conditioned, the gradient-descent method may\nrequire a large number of iterations to converge.\n  We propose an iterative pre-conditioning technique that mitigates the\ndeleterious effect of the conditioning of data points on the rate of\nconvergence of the gradient-descent method. We rigorously show that the\nresulting pre-conditioned gradient-descent method, with the proposed iterative\npre-conditioning, achieves superlinear convergence when the least-squares\nproblem has a unique solution. In general, the convergence is linear with\nimproved rate of convergence in comparison to the traditional gradient-descent\nmethod and the state-of-the-art accelerated gradient-descent methods. We\nfurther illustrate the improved rate of convergence of our proposed algorithm\nthrough experiments on different real-world least-squares problems in both\nnoise-free and noisy computation environment.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 20:01:18 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Chakrabarti", "Kushal", ""], ["Gupta", "Nirupam", ""], ["Chopra", "Nikhil", ""]]}, {"id": "2008.02863", "submitter": "Homayoon Beigi", "authors": "Sitong Zhou and Homayoon Beigi", "title": "A Transfer Learning Method for Speech Emotion Recognition from Automatic\n  Speech Recognition", "comments": "4 pages, 3 tables and 1 figure", "journal-ref": null, "doi": null, "report-no": "RTI-20200330-01", "categories": "eess.AS cs.HC cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a transfer learning method in speech emotion recognition\nbased on a Time-Delay Neural Network (TDNN) architecture. A major challenge in\nthe current speech-based emotion detection research is data scarcity. The\nproposed method resolves this problem by applying transfer learning techniques\nin order to leverage data from the automatic speech recognition (ASR) task for\nwhich ample data is available. Our experiments also show the advantage of\nspeaker-class adaptation modeling techniques by adopting identity-vector\n(i-vector) based features in addition to standard Mel-Frequency Cepstral\nCoefficient (MFCC) features.[1] We show the transfer learning models\nsignificantly outperform the other methods without pretraining on ASR. The\nexperiments performed on the publicly available IEMOCAP dataset which provides\n12 hours of motional speech data. The transfer learning was initialized by\nusing the Ted-Lium v.2 speech dataset providing 207 hours of audio with the\ncorresponding transcripts. We achieve the highest significantly higher accuracy\nwhen compared to state-of-the-art, using five-fold cross validation. Using only\nspeech, we obtain an accuracy 71.7% for anger, excitement, sadness, and\nneutrality emotion content.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 20:37:22 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 18:56:24 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Zhou", "Sitong", ""], ["Beigi", "Homayoon", ""]]}, {"id": "2008.02866", "submitter": "Faraz Hussain", "authors": "Edward Verenich, Alvaro Velasquez, Nazar Khan and Faraz Hussain", "title": "Improving Explainability of Image Classification in Scenarios with Class\n  Overlap: Application to COVID-19 and Pneumonia", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trust in predictions made by machine learning models is increased if the\nmodel generalizes well on previously unseen samples and when inference is\naccompanied by cogent explanations of the reasoning behind predictions. In the\nimage classification domain, generalization can be assessed through accuracy,\nsensitivity, and specificity. Explainability can be assessed by how well the\nmodel localizes the object of interest within an image. However, both\ngeneralization and explainability through localization are degraded in\nscenarios with significant overlap between classes. We propose a method based\non binary expert networks that enhances the explainability of image\nclassifications through better localization by mitigating the model uncertainty\ninduced by class overlap. Our technique performs discriminative localization on\nimages that contain features with significant class overlap, without explicitly\ntraining for localization. Our method is particularly promising in real-world\nclass overlap scenarios, such as COVID-19 and pneumonia, where expertly labeled\ndata for localization is not readily available. This can be useful for early,\nrapid, and trustworthy screening for COVID-19.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 20:47:36 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 21:20:02 GMT"}, {"version": "v3", "created": "Sun, 16 Aug 2020 01:33:25 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Verenich", "Edward", ""], ["Velasquez", "Alvaro", ""], ["Khan", "Nazar", ""], ["Hussain", "Faraz", ""]]}, {"id": "2008.02871", "submitter": "Yang Bai", "authors": "Yang Bai, Yu Guan, Wan-Fai Ng", "title": "Fatigue Assessment using ECG and Actigraphy Sensors", "comments": "accepted by ISWC 2020", "journal-ref": null, "doi": "10.1145/3410531.3414308", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fatigue is one of the key factors in the loss of work efficiency and\nhealth-related quality of life, and most fatigue assessment methods were based\non self-reporting, which may suffer from many factors such as recall bias. To\naddress this issue, we developed an automated system using wearable sensing and\nmachine learning techniques for objective fatigue assessment. ECG/Actigraphy\ndata were collected from subjects in free-living environments. Preprocessing\nand feature engineering methods were applied, before interpretable solution and\ndeep learning solution were introduced. Specifically, for interpretable\nsolution, we proposed a feature selection approach which can select less\ncorrelated and high informative features for better understanding system's\ndecision-making process. For deep learning solution, we used state-of-the-art\nself-attention model, based on which we further proposed a consistency\nself-attention (CSA) mechanism for fatigue assessment. Extensive experiments\nwere conducted, and very promising results were achieved.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 21:04:33 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 15:15:56 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Bai", "Yang", ""], ["Guan", "Yu", ""], ["Ng", "Wan-Fai", ""]]}, {"id": "2008.02878", "submitter": "Vassilina Nikoulina", "authors": "Alexandre B\\'erard, Zae Myung Kim, Vassilina Nikoulina, Eunjeong L.\n  Park, Matthias Gall\\'e", "title": "A Multilingual Neural Machine Translation Model for Biomedical Data", "comments": "https://github.com/naver/covid19-nmt", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We release a multilingual neural machine translation model, which can be used\nto translate text in the biomedical domain. The model can translate from 5\nlanguages (French, German, Italian, Korean and Spanish) into English. It is\ntrained with large amounts of generic and biomedical data, using domain tags.\nOur benchmarks show that it performs near state-of-the-art both on news\n(generic domain) and biomedical test sets, and that it outperforms the existing\npublicly released models. We believe that this release will help the\nlarge-scale multilingual analysis of the digital content of the COVID-19 crisis\nand of its effects on society, economy, and healthcare policies.\n  We also release a test set of biomedical text for Korean-English. It consists\nof 758 sentences from official guidelines and recent papers, all about\nCOVID-19.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 21:26:43 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["B\u00e9rard", "Alexandre", ""], ["Kim", "Zae Myung", ""], ["Nikoulina", "Vassilina", ""], ["Park", "Eunjeong L.", ""], ["Gall\u00e9", "Matthias", ""]]}, {"id": "2008.02880", "submitter": "Yannick Le Cacheux", "authors": "Yannick Le Cacheux, Adrian Popescu, Herv\\'e Le Borgne", "title": "Webly Supervised Semantic Embeddings for Large Scale Zero-Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot learning (ZSL) makes object recognition in images possible in\nabsence of visual training data for a part of the classes from a dataset. When\nthe number of classes is large, classes are usually represented by semantic\nclass prototypes learned automatically from unannotated text collections. This\ntypically leads to much lower performances than with manually designed semantic\nprototypes such as attributes. While most ZSL works focus on the visual aspect\nand reuse standard semantic prototypes learned from generic text collections,\nwe focus on the problem of semantic class prototype design for large scale ZSL.\nMore specifically, we investigate the use of noisy textual metadata associated\nto photos as text collections, as we hypothesize they are likely to provide\nmore plausible semantic embeddings for visual classes if exploited\nappropriately. We thus make use of a source-based voting strategy to improve\nthe robustness of semantic prototypes. Evaluation on the large scale ImageNet\ndataset shows a significant improvement in ZSL performances over two strong\nbaselines, and over usual semantic embeddings used in previous works. We show\nthat this improvement is obtained for several embedding methods, leading to\nstate of the art results when one uses automatically created visual and text\nfeatures.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 21:33:44 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Cacheux", "Yannick Le", ""], ["Popescu", "Adrian", ""], ["Borgne", "Herv\u00e9 Le", ""]]}, {"id": "2008.02883", "submitter": "Kaiwen Wu", "authors": "Kaiwen Wu and Allen Houze Wang and Yaoliang Yu", "title": "Stronger and Faster Wasserstein Adversarial Attacks", "comments": "30 pages, accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep models, while being extremely flexible and accurate, are surprisingly\nvulnerable to \"small, imperceptible\" perturbations known as adversarial\nattacks. While the majority of existing attacks focus on measuring\nperturbations under the $\\ell_p$ metric, Wasserstein distance, which takes\ngeometry in pixel space into account, has long been known to be a suitable\nmetric for measuring image quality and has recently risen as a compelling\nalternative to the $\\ell_p$ metric in adversarial attacks. However,\nconstructing an effective attack under the Wasserstein metric is\ncomputationally much more challenging and calls for better optimization\nalgorithms. We address this gap in two ways: (a) we develop an exact yet\nefficient projection operator to enable a stronger projected gradient attack;\n(b) we show that the Frank-Wolfe method equipped with a suitable linear\nminimization oracle works extremely fast under Wasserstein constraints. Our\nalgorithms not only converge faster but also generate much stronger attacks.\nFor instance, we decrease the accuracy of a residual network on CIFAR-10 to\n$3.4\\%$ within a Wasserstein perturbation ball of radius $0.005$, in contrast\nto $65.6\\%$ using the previous Wasserstein attack based on an\n\\emph{approximate} projection operator. Furthermore, employing our stronger\nattacks in adversarial training significantly improves the robustness of\nadversarially trained models.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 21:36:12 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Wu", "Kaiwen", ""], ["Wang", "Allen Houze", ""], ["Yu", "Yaoliang", ""]]}, {"id": "2008.02890", "submitter": "Mohammad-Parsa Hosseini", "authors": "Madison Beary, Alex Hadsell, Ryan Messersmith, Mohammad-Parsa Hosseini", "title": "Diagnosis of Autism in Children using Facial Analysis and Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a deep learning model to classify children as\neither healthy or potentially autistic with 94.6% accuracy using Deep Learning.\nAutistic patients struggle with social skills, repetitive behaviors, and\ncommunication, both verbal and nonverbal. Although the disease is considered to\nbe genetic, the highest rates of accurate diagnosis occur when the child is\ntested on behavioral characteristics and facial features. Patients have a\ncommon pattern of distinct facial deformities, allowing researchers to analyze\nonly an image of the child to determine if the child has the disease. While\nthere are other techniques and models used for facial analysis and autism\nclassification on their own, our proposal bridges these two ideas allowing\nclassification in a cheaper, more efficient method. Our deep learning model\nuses MobileNet and two dense layers in order to perform feature extraction and\nimage classification. The model is trained and tested using 3,014 images,\nevenly split between children with autism and children without it. 90% of the\ndata is used for training, and 10% is used for testing. Based on our accuracy,\nwe propose that the diagnosis of autism can be done effectively using only a\npicture. Additionally, there may be other diseases that are similarly\ndiagnosable.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 22:15:20 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Beary", "Madison", ""], ["Hadsell", "Alex", ""], ["Messersmith", "Ryan", ""], ["Hosseini", "Mohammad-Parsa", ""]]}, {"id": "2008.02891", "submitter": "Sebastian Grimberg", "authors": "Sebastian Grimberg, Charbel Farhat, Radek Tezaur, Charbel Bou-Mosleh", "title": "Mesh sampling and weighting for the hyperreduction of nonlinear\n  Petrov-Galerkin reduced-order models with local reduced-order bases", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The energy-conserving sampling and weighting (ECSW) method is a\nhyperreduction method originally developed for accelerating the performance of\nGalerkin projection-based reduced-order models (PROMs) associated with\nlarge-scale finite element models, when the underlying projected operators need\nto be frequently recomputed as in parametric and/or nonlinear problems. In this\npaper, this hyperreduction method is extended to Petrov-Galerkin PROMs where\nthe underlying high-dimensional models can be associated with arbitrary finite\nelement, finite volume, and finite difference semi-discretization methods. Its\nscope is also extended to cover local PROMs based on piecewise-affine\napproximation subspaces, such as those designed for mitigating the Kolmogorov\n$n$-width barrier issue associated with convection-dominated flow problems. The\nresulting ECSW method is shown in this paper to be robust and accurate. In\nparticular, its offline phase is shown to be fast and parallelizable, and the\npotential of its online phase for large-scale applications of industrial\nrelevance is demonstrated for turbulent flow problems with $O(10^7)$ and\n$O(10^8)$ degrees of freedom. For such problems, the online part of the ECSW\nmethod proposed in this paper for Petrov-Galerkin PROMs is shown to enable\nwall-clock time and CPU time speedup factors of several orders of magnitude\nwhile delivering exceptional accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 22:20:29 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Grimberg", "Sebastian", ""], ["Farhat", "Charbel", ""], ["Tezaur", "Radek", ""], ["Bou-Mosleh", "Charbel", ""]]}, {"id": "2008.02897", "submitter": "Abhinav Mehrotra", "authors": "Abhinav Mehrotra, {\\L}ukasz Dudziak, Jinsu Yeo, Young-yoon Lee,\n  Ravichander Vipperla, Mohamed S. Abdelfattah, Sourav Bhattacharya, Samin\n  Ishtiaq, Alberto Gil C. P. Ramos, SangJeong Lee, Daehyun Kim, Nicholas D.\n  Lane", "title": "Iterative Compression of End-to-End ASR Model using AutoML", "comments": null, "journal-ref": "INTERSPEECH 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing demand for on-device Automatic Speech Recognition (ASR) systems\nhas resulted in renewed interests in developing automatic model compression\ntechniques. Past research have shown that AutoML-based Low Rank Factorization\n(LRF) technique, when applied to an end-to-end Encoder-Attention-Decoder style\nASR model, can achieve a speedup of up to 3.7x, outperforming laborious manual\nrank-selection approaches. However, we show that current AutoML-based search\ntechniques only work up to a certain compression level, beyond which they fail\nto produce compressed models with acceptable word error rates (WER). In this\nwork, we propose an iterative AutoML-based LRF approach that achieves over 5x\ncompression without degrading the WER, thereby advancing the state-of-the-art\nin ASR compression.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 22:33:10 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mehrotra", "Abhinav", ""], ["Dudziak", "\u0141ukasz", ""], ["Yeo", "Jinsu", ""], ["Lee", "Young-yoon", ""], ["Vipperla", "Ravichander", ""], ["Abdelfattah", "Mohamed S.", ""], ["Bhattacharya", "Sourav", ""], ["Ishtiaq", "Samin", ""], ["Ramos", "Alberto Gil C. P.", ""], ["Lee", "SangJeong", ""], ["Kim", "Daehyun", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "2008.02900", "submitter": "Mohammad-Parsa Hosseini", "authors": "Chelsea Villanueva, Joshua Vincent, Alexander Slowinski,\n  Mohammad-Parsa Hosseini", "title": "Respiratory Sound Classification Using Long-Short Term Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing a reliable sound detection and recognition system offers many\nbenefits and has many useful applications in different industries. This paper\nexamines the difficulties that exist when attempting to perform sound\nclassification as it relates to respiratory disease classification. Some\nmethods which have been employed such as independent component analysis and\nblind source separation are examined. Finally, an examination on the use of\ndeep learning and long short-term memory networks is performed in order to\nidentify how such a task can be implemented.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 23:11:57 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Villanueva", "Chelsea", ""], ["Vincent", "Joshua", ""], ["Slowinski", "Alexander", ""], ["Hosseini", "Mohammad-Parsa", ""]]}, {"id": "2008.02901", "submitter": "Zhu Li", "authors": "Zhu Li, Weijie Su, Dino Sejdinovic", "title": "Benign Overfitting and Noisy Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning often operates in the regime where the number of\nparameters is much higher than the number of data points, with zero training\nloss and yet good generalization, thereby contradicting the classical\nbias-variance trade-off. This \\textit{benign overfitting} phenomenon has\nrecently been characterized using so called \\textit{double descent} curves\nwhere the risk undergoes another descent (in addition to the classical U-shaped\nlearning curve when the number of parameters is small) as we increase the\nnumber of parameters beyond a certain threshold. In this paper, we examine the\nconditions under which \\textit{Benign Overfitting} occurs in the random feature\n(RF) models, i.e. in a two-layer neural network with fixed first layer weights.\nWe adopt a new view of random feature and show that \\textit{benign overfitting}\narises due to the noise which resides in such features (the noise may already\nbe present in the data and propagate to the features or it may be added by the\nuser to the features directly) and plays an important implicit regularization\nrole in the phenomenon.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 23:30:43 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 19:59:39 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Li", "Zhu", ""], ["Su", "Weijie", ""], ["Sejdinovic", "Dino", ""]]}, {"id": "2008.02908", "submitter": "Abdelkareem Jaradat", "authors": "Abdelkareem Jaradat, Hanan Lutfiyya, Anwar Haque", "title": "Demand Response For Residential Uses: A Data Analytics Approach", "comments": "6 pages, 8 figures, IEEE World Forum on Internet of Things 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Smart Grid environment, the advent of intelligent measuring devices\nfacilitates monitoring appliance electricity consumption. This data can be used\nin applying Demand Response (DR) in residential houses through data analytics,\nand developing data mining techniques. In this research, we introduce a smart\nsystem foundation that is applied to user's disaggregated power consumption\ndata. This system encourages the users to apply DR by changing their behaviour\nof using heavier operation modes to lighter modes, and by encouraging users to\nshift their usages to off-peak hours. First, we apply Cross Correlation (XCORR)\nto detect times of the occurrences when an appliance is being used. We then use\nThe Dynamic Time Warping (DTW) to recognize the operation mode used.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 00:06:38 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Jaradat", "Abdelkareem", ""], ["Lutfiyya", "Hanan", ""], ["Haque", "Anwar", ""]]}, {"id": "2008.02919", "submitter": "Afsaneh Doryab", "authors": "Momin M. Malik, Afsaneh Doryab, Michael Merrill, J\\\"urgen Pfeffer,\n  Anind K. Dey", "title": "Can Smartphone Co-locations Detect Friendship? It Depends How You Model\n  It", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a study to detect friendship, its strength, and its change from\nsmartphone location data collectedamong members of a fraternity. We extract a\nrich set of co-location features and build classifiers that detectfriendships\nand close friendship at 30% above a random baseline. We design cross-validation\nschema to testour model performance in specific application settings, finding\nit robust to seeing new dyads and to temporalvariance.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 00:55:10 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 19:14:31 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2020 02:15:13 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Malik", "Momin M.", ""], ["Doryab", "Afsaneh", ""], ["Merrill", "Michael", ""], ["Pfeffer", "J\u00fcrgen", ""], ["Dey", "Anind K.", ""]]}, {"id": "2008.02930", "submitter": "Ellie Chio", "authors": "Tao Wu, Ellie Ka-In Chio, Heng-Tze Cheng, Yu Du, Steffen Rendle, Dima\n  Kuzmin, Ritesh Agarwal, Li Zhang, John Anderson, Sarvjeet Singh, Tushar\n  Chandra, Ed H. Chi, Wen Li, Ankit Kumar, Xiang Ma, Alex Soares, Nitin Jindal,\n  Pei Cao", "title": "Zero-Shot Heterogeneous Transfer Learning from Recommender Systems to\n  Cold-Start Search Retrieval", "comments": "Accepted at CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3412752", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent advances in neural information retrieval models, which predict\ntop-K items given a query, learn directly from a large training set of (query,\nitem) pairs. However, they are often insufficient when there are many\npreviously unseen (query, item) combinations, often referred to as the cold\nstart problem. Furthermore, the search system can be biased towards items that\nare frequently shown to a query previously, also known as the 'rich get richer'\n(a.k.a. feedback loop) problem. In light of these problems, we observed that\nmost online content platforms have both a search and a recommender system that,\nwhile having heterogeneous input spaces, can be connected through their common\noutput item space and a shared semantic representation. In this paper, we\npropose a new Zero-Shot Heterogeneous Transfer Learning framework that\ntransfers learned knowledge from the recommender system component to improve\nthe search component of a content platform. First, it learns representations of\nitems and their natural-language features by predicting (item, item)\ncorrelation graphs derived from the recommender system as an auxiliary task.\nThen, the learned representations are transferred to solve the target search\nretrieval task, performing query-to-item prediction without having seen any\n(query, item) pairs in training. We conduct online and offline experiments on\none of the world's largest search and recommender systems from Google, and\npresent the results and lessons learned. We demonstrate that the proposed\napproach can achieve high performance on offline search retrieval tasks, and\nmore importantly, achieved significant improvements on relevance and user\ninteractions over the highly-optimized production system in online experiments.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 01:22:56 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 00:16:40 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Wu", "Tao", ""], ["Chio", "Ellie Ka-In", ""], ["Cheng", "Heng-Tze", ""], ["Du", "Yu", ""], ["Rendle", "Steffen", ""], ["Kuzmin", "Dima", ""], ["Agarwal", "Ritesh", ""], ["Zhang", "Li", ""], ["Anderson", "John", ""], ["Singh", "Sarvjeet", ""], ["Chandra", "Tushar", ""], ["Chi", "Ed H.", ""], ["Li", "Wen", ""], ["Kumar", "Ankit", ""], ["Ma", "Xiang", ""], ["Soares", "Alex", ""], ["Jindal", "Nitin", ""], ["Cao", "Pei", ""]]}, {"id": "2008.02938", "submitter": "Chenglizhao Chen", "authors": "Zhenyu Wu, Shuai Li, Chenglizhao Chen, Aimin Hao, Hong Qin", "title": "A Deeper Look at Salient Object Detection: Bi-stream Network with a\n  Small Training Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared with the conventional hand-crafted approaches, the deep learning\nbased methods have achieved tremendous performance improvements by training\nexquisitely crafted fancy networks over large-scale training sets. However, do\nwe really need large-scale training set for salient object detection (SOD)? In\nthis paper, we provide a deeper insight into the interrelationship between the\nSOD performances and the training sets. To alleviate the conventional demands\nfor large-scale training data, we provide a feasible way to construct a novel\nsmall-scale training set, which only contains 4K images. Moreover, we propose a\nnovel bi-stream network to take full advantage of our proposed small training\nset, which is consisted of two feature backbones with different structures,\nachieving complementary semantical saliency fusion via the proposed gate\ncontrol unit. To our best knowledge, this is the first attempt to use a\nsmall-scale training set to outperform state-of-the-art models which are\ntrained on large-scale training sets; nevertheless, our method can still\nachieve the leading state-of-the-art performance on five benchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 01:24:33 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Wu", "Zhenyu", ""], ["Li", "Shuai", ""], ["Chen", "Chenglizhao", ""], ["Hao", "Aimin", ""], ["Qin", "Hong", ""]]}, {"id": "2008.02950", "submitter": "Kentaro Mitsui", "authors": "Kentaro Mitsui, Tomoki Koriyama, Hiroshi Saruwatari", "title": "Multi-speaker Text-to-speech Synthesis Using Deep Gaussian Processes", "comments": "5 pages, accepted for INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Multi-speaker speech synthesis is a technique for modeling multiple speakers'\nvoices with a single model. Although many approaches using deep neural networks\n(DNNs) have been proposed, DNNs are prone to overfitting when the amount of\ntraining data is limited. We propose a framework for multi-speaker speech\nsynthesis using deep Gaussian processes (DGPs); a DGP is a deep architecture of\nBayesian kernel regressions and thus robust to overfitting. In this framework,\nspeaker information is fed to duration/acoustic models using speaker codes. We\nalso examine the use of deep Gaussian process latent variable models (DGPLVMs).\nIn this approach, the representation of each speaker is learned simultaneously\nwith other model parameters, and therefore the similarity or dissimilarity of\nspeakers is considered efficiently. We experimentally evaluated two situations\nto investigate the effectiveness of the proposed methods. In one situation, the\namount of data from each speaker is balanced (speaker-balanced), and in the\nother, the data from certain speakers are limited (speaker-imbalanced).\nSubjective and objective evaluation results showed that both the DGP and DGPLVM\nsynthesize multi-speaker speech more effective than a DNN in the\nspeaker-balanced situation. We also found that the DGPLVM outperforms the DGP\nsignificantly in the speaker-imbalanced situation.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 02:03:27 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Mitsui", "Kentaro", ""], ["Koriyama", "Tomoki", ""], ["Saruwatari", "Hiroshi", ""]]}, {"id": "2008.02952", "submitter": "Sohini Roychowdhury", "authors": "Sohini Roychowdhury", "title": "Few Shot Learning Framework to Reduce Inter-observer Variability in\n  Medical Images", "comments": "8 pages, 8 figures, 4 tables", "journal-ref": "ICPR 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most computer aided pathology detection systems rely on large volumes of\nquality annotated data to aid diagnostics and follow up procedures. However,\nquality assuring large volumes of annotated medical image data can be\nsubjective and expensive. In this work we present a novel standardization\nframework that implements three few-shot learning (FSL) models that can be\niteratively trained by atmost 5 images per 3D stack to generate multiple\nregional proposals (RPs) per test image. These FSL models include a novel\nparallel echo state network (ParESN) framework and an augmented U-net model.\nAdditionally, we propose a novel target label selection algorithm (TLSA) that\nmeasures relative agreeability between RPs and the manually annotated target\nlabels to detect the \"best\" quality annotation per image. Using the FSL models,\nour system achieves 0.28-0.64 Dice coefficient across vendor image stacks for\nintra-retinal cyst segmentation. Additionally, the TLSA is capable of\nautomatically classifying high quality target labels from their noisy\ncounterparts for 60-97% of the images while ensuring manual supervision on\nremaining images. Also, the proposed framework with ParESN model minimizes\nmanual annotation checking to 12-28% of the total number of images. The TLSA\nmetrics further provide confidence scores for the automated annotation quality\nassurance. Thus, the proposed framework is flexible to extensions for quality\nimage annotation curation of other image stacks as well.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 02:05:51 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Roychowdhury", "Sohini", ""]]}, {"id": "2008.02953", "submitter": "Yoonho Lee", "authors": "Yoonho Lee, Juho Lee, Sung Ju Hwang, Eunho Yang, Seungjin Choi", "title": "Neural Complexity Measures", "comments": "Published in Thirty-fourth Conference on Neural Information\n  Processing Systems (NeurIPS 2020) Code is available at\n  https://github.com/yoonholee/neural-complexity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While various complexity measures for deep neural networks exist, specifying\nan appropriate measure capable of predicting and explaining generalization in\ndeep networks has proven challenging. We propose Neural Complexity (NC), a\nmeta-learning framework for predicting generalization. Our model learns a\nscalar complexity measure through interactions with many heterogeneous tasks in\na data-driven way. The trained NC model can be added to the standard training\nloss to regularize any task learner in a standard supervised learning scenario.\nWe contrast NC's approach against existing manually-designed complexity\nmeasures and other meta-learning models, and we validate NC's performance on\nmultiple regression and classification tasks\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 02:12:10 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 07:06:55 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Lee", "Yoonho", ""], ["Lee", "Juho", ""], ["Hwang", "Sung Ju", ""], ["Yang", "Eunho", ""], ["Choi", "Seungjin", ""]]}, {"id": "2008.02954", "submitter": "Wenjun Qiu", "authors": "Wenjun Qiu and David Lie", "title": "Deep Active Learning with Crowdsourcing Data for Privacy Policy\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy policies are statements that notify users of the services' data\npractices. However, few users are willing to read through policy texts due to\nthe length and complexity. While automated tools based on machine learning\nexist for privacy policy analysis, to achieve high classification accuracy,\nclassifiers need to be trained on a large labeled dataset. Most existing policy\ncorpora are labeled by skilled human annotators, requiring significant amount\nof labor hours and effort. In this paper, we leverage active learning and\ncrowdsourcing techniques to develop an automated classification tool named\nCalpric (Crowdsourcing Active Learning PRIvacy Policy Classifier), which is\nable to perform annotation equivalent to those done by skilled human annotators\nwith high accuracy while minimizing the labeling cost. Specifically, active\nlearning allows classifiers to proactively select the most informative segments\nto be labeled. On average, our model is able to achieve the same F1 score using\nonly 62% of the original labeling effort. Calpric's use of active learning also\naddresses naturally occurring class imbalance in unlabeled privacy policy\ndatasets as there are many more statements stating the collection of private\ninformation than stating the absence of collection. By selecting samples from\nthe minority class for labeling, Calpric automatically creates a more balanced\ntraining set.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 02:13:31 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Qiu", "Wenjun", ""], ["Lie", "David", ""]]}, {"id": "2008.02956", "submitter": "Yoonho Lee", "authors": "Juho Lee, Yoonho Lee, Jungtaek Kim, Eunho Yang, Sung Ju Hwang, Yee\n  Whye Teh", "title": "Bootstrapping Neural Processes", "comments": "Published in Thirty-fourth Conference on Neural Information\n  Processing Systems (NeurIPS 2020) Code is available at\n  https://github.com/juho-lee/bnp", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike in the traditional statistical modeling for which a user typically\nhand-specify a prior, Neural Processes (NPs) implicitly define a broad class of\nstochastic processes with neural networks. Given a data stream, NP learns a\nstochastic process that best describes the data. While this \"data-driven\" way\nof learning stochastic processes has proven to handle various types of data,\nNPs still rely on an assumption that uncertainty in stochastic processes is\nmodeled by a single latent variable, which potentially limits the flexibility.\nTo this end, we propose the Boostrapping Neural Process (BNP), a novel\nextension of the NP family using the bootstrap. The bootstrap is a classical\ndata-driven technique for estimating uncertainty, which allows BNP to learn the\nstochasticity in NPs without assuming a particular form. We demonstrate the\nefficacy of BNP on various types of data and its robustness in the presence of\nmodel-data mismatch.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 02:23:34 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 04:06:35 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Lee", "Juho", ""], ["Lee", "Yoonho", ""], ["Kim", "Jungtaek", ""], ["Yang", "Eunho", ""], ["Hwang", "Sung Ju", ""], ["Teh", "Yee Whye", ""]]}, {"id": "2008.02957", "submitter": "Heyi Li", "authors": "Heyi Li, Dongdong Chen, William H. Nailon, Mike E. Davies, and David\n  Laurenson", "title": "Dual Convolutional Neural Networks for Breast Mass Segmentation and\n  Diagnosis in Mammography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNNs) have emerged as a new paradigm for\nMammogram diagnosis. Contemporary CNN-based computer-aided-diagnosis (CAD) for\nbreast cancer directly extract latent features from input mammogram image and\nignore the importance of morphological features. In this paper, we introduce a\nnovel deep learning framework for mammogram image processing, which computes\nmass segmentation and simultaneously predict diagnosis results. Specifically,\nour method is constructed in a dual-path architecture that solves the mapping\nin a dual-problem manner, with an additional consideration of important shape\nand boundary knowledge. One path called the Locality Preserving Learner (LPL),\nis devoted to hierarchically extracting and exploiting intrinsic features of\nthe input. Whereas the other path, called the Conditional Graph Learner (CGL)\nfocuses on generating geometrical features via modeling pixel-wise image to\nmask correlations. By integrating the two learners, both the semantics and\nstructure are well preserved and the component learning paths in return\ncomplement each other, contributing an improvement to the mass segmentation and\ncancer classification problem at the same time. We evaluated our method on two\nmost used public mammography datasets, DDSM and INbreast. Experimental results\nshow that DualCoreNet achieves the best mammography segmentation and\nclassification simultaneously, outperforming recent state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 02:23:36 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 22:04:11 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Li", "Heyi", ""], ["Chen", "Dongdong", ""], ["Nailon", "William H.", ""], ["Davies", "Mike E.", ""], ["Laurenson", "David", ""]]}, {"id": "2008.02961", "submitter": "Gia Ngo", "authors": "Gia H. Ngo, Meenakshi Khosla, Keith Jamison, Amy Kuceyeski, Mert R.\n  Sabuncu", "title": "From Connectomic to Task-evoked Fingerprints: Individualized Prediction\n  of Task Contrasts from Resting-state Functional Connectivity", "comments": "Accepted to MICCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resting-state functional MRI (rsfMRI) yields functional connectomes that can\nserve as cognitive fingerprints of individuals. Connectomic fingerprints have\nproven useful in many machine learning tasks, such as predicting\nsubject-specific behavioral traits or task-evoked activity. In this work, we\npropose a surface-based convolutional neural network (BrainSurfCNN) model to\npredict individual task contrasts from their resting-state fingerprints. We\nintroduce a reconstructive-contrastive loss that enforces subject-specificity\nof model outputs while minimizing predictive error. The proposed approach\nsignificantly improves the accuracy of predicted contrasts over a\nwell-established baseline. Furthermore, BrainSurfCNN's prediction also\nsurpasses test-retest benchmark in a subject identification task.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 02:44:16 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Ngo", "Gia H.", ""], ["Khosla", "Meenakshi", ""], ["Jamison", "Keith", ""], ["Kuceyeski", "Amy", ""], ["Sabuncu", "Mert R.", ""]]}, {"id": "2008.02964", "submitter": "Tian Lan", "authors": "Tian Lan, Xian-Ling Mao, Wei Wei, Heyan Huang", "title": "Which Kind Is Better in Open-domain Multi-turn Dialog,Hierarchical or\n  Non-hierarchical Models? An Empirical Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, open-domain generative dialog systems have attracted considerable\nattention in academia and industry. Despite the success of single-turn dialog\ngeneration, multi-turn dialog generation is still a big challenge. So far,\nthere are two kinds of models for open-domain multi-turn dialog generation:\nhierarchical and non-hierarchical models. Recently, some works have shown that\nthe hierarchical models are better than non-hierarchical models under their\nexperimental settings; meanwhile, some works also demonstrate the opposite\nconclusion. Due to the lack of adequate comparisons, it's not clear which kind\nof models are better in open-domain multi-turn dialog generation. Thus, in this\npaper, we will measure systematically nearly all representative hierarchical\nand non-hierarchical models over the same experimental settings to check which\nkind is better. Through extensive experiments, we have the following three\nimportant conclusions: (1) Nearly all hierarchical models are worse than\nnon-hierarchical models in open-domain multi-turn dialog generation, except for\nthe HRAN model. Through further analysis, the excellent performance of HRAN\nmainly depends on its word-level attention mechanism; (2) The performance of\nother hierarchical models will also obtain a great improvement if integrating\nthe word-level attention mechanism into these models. The modified hierarchical\nmodels even significantly outperform the non-hierarchical models; (3) The\nreason why the word-level attention mechanism is so powerful for hierarchical\nmodels is because it can leverage context information more effectively,\nespecially the fine-grained information. Besides, we have implemented all of\nthe models and already released the codes.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 02:54:55 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Lan", "Tian", ""], ["Mao", "Xian-Ling", ""], ["Wei", "Wei", ""], ["Huang", "Heyan", ""]]}, {"id": "2008.02965", "submitter": "Ziquan Liu", "authors": "Ziquan Liu, Yufei Cui, Antoni B. Chan", "title": "Improve Generalization and Robustness of Neural Networks via Weight\n  Scale Shifting Invariant Regularizations", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using weight decay to penalize the L2 norms of weights in neural networks has\nbeen a standard training practice to regularize the complexity of networks. In\nthis paper, we show that a family of regularizers, including weight decay, is\nineffective at penalizing the intrinsic norms of weights for networks with\npositively homogeneous activation functions, such as linear, ReLU and\nmax-pooling functions. As a result of homogeneity, functions specified by the\nnetworks are invariant to the shifting of weight scales between layers. The\nineffective regularizers are sensitive to such shifting and thus poorly\nregularize the model capacity, leading to overfitting. To address this\nshortcoming, we propose an improved regularizer that is invariant to weight\nscale shifting and thus effectively constrains the intrinsic norm of a neural\nnetwork. The derived regularizer is an upper bound for the input gradient of\nthe network so minimizing the improved regularizer also benefits the\nadversarial robustness. Residual connections are also considered and we show\nthat our regularizer also forms an upper bound to input gradients of such a\nresidual network. We demonstrate the efficacy of our proposed regularizer on\nvarious datasets and neural network architectures at improving generalization\nand adversarial robustness.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 02:55:28 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Liu", "Ziquan", ""], ["Cui", "Yufei", ""], ["Chan", "Antoni B.", ""]]}, {"id": "2008.02966", "submitter": "Chenglizhao Chen", "authors": "Chenglizhao Chen, Jia Song, Chong Peng, Guodong Wang, Yuming Fang", "title": "A Novel Video Salient Object Detection Method via Semi-supervised Motion\n  Quality Perception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous video salient object detection (VSOD) approaches have mainly focused\non designing fancy networks to achieve their performance improvements. However,\nwith the slow-down in development of deep learning techniques recently, it may\nbecome more and more difficult to anticipate another breakthrough via fancy\nnetworks solely. To this end, this paper proposes a universal learning scheme\nto get a further 3\\% performance improvement for all state-of-the-art (SOTA)\nmethods. The major highlight of our method is that we resort the \"motion\nquality\"---a brand new concept, to select a sub-group of video frames from the\noriginal testing set to construct a new training set. The selected frames in\nthis new training set should all contain high-quality motions, in which the\nsalient objects will have large probability to be successfully detected by the\n\"target SOTA method\"---the one we want to improve. Consequently, we can achieve\na significant performance improvement by using this new training set to start a\nnew round of network training. During this new round training, the VSOD results\nof the target SOTA method will be applied as the pseudo training objectives.\nOur novel learning scheme is simple yet effective, and its semi-supervised\nmethodology may have large potential to inspire the VSOD community in the\nfuture.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 02:58:51 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Chen", "Chenglizhao", ""], ["Song", "Jia", ""], ["Peng", "Chong", ""], ["Wang", "Guodong", ""], ["Fang", "Yuming", ""]]}, {"id": "2008.02973", "submitter": "Chenglizhao Chen", "authors": "Chenglizhao Chen, Guotao Wang, Chong Peng, Dingwen Zhang, Yuming Fang,\n  and Hong Qin", "title": "Exploring Rich and Efficient Spatial Temporal Interactions for Real Time\n  Video Salient Object Detection", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2021.3068644", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current main stream methods formulate their video saliency mainly from\ntwo independent venues, i.e., the spatial and temporal branches. As a\ncomplementary component, the main task for the temporal branch is to\nintermittently focus the spatial branch on those regions with salient\nmovements. In this way, even though the overall video saliency quality is\nheavily dependent on its spatial branch, however, the performance of the\ntemporal branch still matter. Thus, the key factor to improve the overall video\nsaliency is how to further boost the performance of these branches efficiently.\nIn this paper, we propose a novel spatiotemporal network to achieve such\nimprovement in a full interactive fashion. We integrate a lightweight temporal\nmodel into the spatial branch to coarsely locate those spatially salient\nregions which are correlated with trustworthy salient movements. Meanwhile, the\nspatial branch itself is able to recurrently refine the temporal model in a\nmulti-scale manner. In this way, both the spatial and temporal branches are\nable to interact with each other, achieving the mutual performance improvement.\nOur method is easy to implement yet effective, achieving high quality video\nsaliency detection in real-time speed with 50 FPS.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 03:24:04 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Chen", "Chenglizhao", ""], ["Wang", "Guotao", ""], ["Peng", "Chong", ""], ["Zhang", "Dingwen", ""], ["Fang", "Yuming", ""], ["Qin", "Hong", ""]]}, {"id": "2008.02974", "submitter": "Wentao Ouyang", "authors": "Wentao Ouyang, Xiuwu Zhang, Lei Zhao, Jinmei Luo, Yu Zhang, Heng Zou,\n  Zhaojie Liu, Yanlong Du", "title": "MiNet: Mixed Interest Network for Cross-Domain Click-Through Rate\n  Prediction", "comments": "CIKM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Click-through rate (CTR) prediction is a critical task in online advertising\nsystems. Existing works mainly address the single-domain CTR prediction problem\nand model aspects such as feature interaction, user behavior history and\ncontextual information. Nevertheless, ads are usually displayed with natural\ncontent, which offers an opportunity for cross-domain CTR prediction. In this\npaper, we address this problem and leverage auxiliary data from a source domain\nto improve the CTR prediction performance of a target domain. Our study is\nbased on UC Toutiao (a news feed service integrated with the UC Browser App,\nserving hundreds of millions of users daily), where the source domain is the\nnews and the target domain is the ad. In order to effectively leverage news\ndata for predicting CTRs of ads, we propose the Mixed Interest Network (MiNet)\nwhich jointly models three types of user interest: 1) long-term interest across\ndomains, 2) short-term interest from the source domain and 3) short-term\ninterest in the target domain. MiNet contains two levels of attentions, where\nthe item-level attention can adaptively distill useful information from clicked\nnews / ads and the interest-level attention can adaptively fuse different\ninterest representations. Offline experiments show that MiNet outperforms\nseveral state-of-the-art methods for CTR prediction. We have deployed MiNet in\nUC Toutiao and the A/B test results show that the online CTR is also improved\nsubstantially. MiNet now serves the main ad traffic in UC Toutiao.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 03:27:38 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Ouyang", "Wentao", ""], ["Zhang", "Xiuwu", ""], ["Zhao", "Lei", ""], ["Luo", "Jinmei", ""], ["Zhang", "Yu", ""], ["Zou", "Heng", ""], ["Liu", "Zhaojie", ""], ["Du", "Yanlong", ""]]}, {"id": "2008.02995", "submitter": "Jingyi Zhang", "authors": "Jingyi Zhang, Wenxuan Zhong, Ping Ma", "title": "A Review on Modern Computational Optimal Transport Methods with\n  Applications in Biomedical Research", "comments": "22 pages, 7 figures, book chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport has been one of the most exciting subjects in mathematics,\nstarting from the 18th century. As a powerful tool to transport between two\nprobability measures, optimal transport methods have been reinvigorated\nnowadays in a remarkable proliferation of modern data science applications. To\nmeet the big data challenges, various computational tools have been developed\nin the recent decade to accelerate the computation for optimal transport\nmethods. In this review, we present some cutting-edge computational optimal\ntransport methods with a focus on the regularization-based methods and the\nprojection-based methods. We discuss their real-world applications in\nbiomedical research.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 05:33:54 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 09:29:51 GMT"}, {"version": "v3", "created": "Thu, 20 May 2021 09:39:21 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Zhang", "Jingyi", ""], ["Zhong", "Wenxuan", ""], ["Ma", "Ping", ""]]}, {"id": "2008.02999", "submitter": "Philipp V. Rouast", "authors": "Philipp V. Rouast and Marc T. P. Adam", "title": "Single-stage intake gesture detection using CTC loss and extended prefix\n  beam search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate detection of individual intake gestures is a key step towards\nautomatic dietary monitoring. Both inertial sensor data of wrist movements and\nvideo data depicting the upper body have been used for this purpose. The most\nadvanced approaches to date use a two-stage approach, in which (i) frame-level\nintake probabilities are learned from the sensor data using a deep neural\nnetwork, and then (ii) sparse intake events are detected by finding the maxima\nof the frame-level probabilities. In this study, we propose a single-stage\napproach which directly decodes the probabilities learned from sensor data into\nsparse intake detections. This is achieved by weakly supervised training using\nConnectionist Temporal Classification (CTC) loss, and decoding using a novel\nextended prefix beam search decoding algorithm. Benefits of this approach\ninclude (i) end-to-end training for detections, (ii) simplified timing\nrequirements for intake gesture labels, and (iii) improved detection\nperformance compared to existing approaches. Across two separate datasets, we\nachieve relative $F_1$ score improvements between 1.9% and 6.2% over the\ntwo-stage approach for intake detection and eating/drinking detection tasks,\nfor both video and inertial sensors.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 06:04:25 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 01:05:45 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Rouast", "Philipp V.", ""], ["Adam", "Marc T. P.", ""]]}, {"id": "2008.03006", "submitter": "Jason Altschuler", "authors": "Jason M. Altschuler and Enric Boix-Adsera", "title": "Polynomial-time algorithms for Multimarginal Optimal Transport problems\n  with decomposable structure", "comments": "38 pages, 8 figures. Improved exposition. For clarity, the hardness\n  results in Section 6 of v1 have been moved to the separate paper \"Hardness\n  Results for Multimarginal Optimal Transport problems\"; the current drafts of\n  these papers have no overlapping results. Title updated for clarity", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimarginal Optimal Transport (MOT) has recently attracted significant\ninterest due to applications in machine learning, statistics, and the sciences.\nHowever, in most applications, the success of MOT is severely limited by a lack\nof efficient algorithms. Indeed, in general, MOT requires exponential time in\nthe number of marginals k and their support sizes n.\n  This paper develops a general theory about \"structural properties\" that make\nMOT solvable in poly(n,k) time. We identify two such properties:\ndecomposability of the cost into either (i) local and simple global\ninteractions; or (ii) low-rank and sparse components. These two structures\nencompass many--if not most--current applications of MOT.\n  In addition to providing the first poly(n,k)-time algorithms for a wide range\nof MOT problems, our results also provide better algorithms for MOT problems\nthat are already known to be tractable: Our algorithms compute solutions which\nare exact and sparse. (Previous algorithms can do neither.) We demonstrate our\nresults theoretically and numerically on popular applications in machine\nlearning, statistics, and fluid dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 06:24:22 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 01:38:51 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Altschuler", "Jason M.", ""], ["Boix-Adsera", "Enric", ""]]}, {"id": "2008.03008", "submitter": "Bayu Adhi Nugroho", "authors": "Bayu A. Nugroho", "title": "An Aggregate Method for Thorax Diseases Classification", "comments": "code available: https://github.com/bayu-ladom-ipok/weOpen", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common problem found in real-word medical image classification is the\ninherent imbalance of the positive and negative patterns in the dataset where\npositive patterns are usually rare. Moreover, in the classification of multiple\nclasses with neural network, a training pattern is treated as a positive\npattern in one output node and negative in all the remaining output nodes. In\nthis paper, the weights of a training pattern in the loss function are designed\nbased not only on the number of the training patterns in the class but also on\nthe different nodes where one of them treats this training pattern as positive\nand the others treat it as negative. We propose a combined approach of weights\ncalculation algorithm for deep network training and the training optimization\nfrom the state-of-the-art deep network architecture for thorax diseases\nclassification problem. Experimental results on the Chest X-Ray image dataset\ndemonstrate that this new weighting scheme improves classification\nperformances, also the training optimization from the EfficientNet improves the\nperformance furthermore. We compare the aggregate method with several\nperformances from the previous study of thorax diseases classifications to\nprovide the fair comparisons against the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 06:36:07 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 03:12:57 GMT"}, {"version": "v3", "created": "Wed, 12 Aug 2020 03:15:53 GMT"}, {"version": "v4", "created": "Thu, 12 Nov 2020 07:15:33 GMT"}, {"version": "v5", "created": "Thu, 24 Dec 2020 12:35:14 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Nugroho", "Bayu A.", ""]]}, {"id": "2008.03033", "submitter": "Timo Dimitriadis", "authors": "Timo Dimitriadis, Tilmann Gneiting, Alexander I. Jordan", "title": "Evaluating probabilistic classifiers: Reliability diagrams and score\n  decompositions revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A probability forecast or probabilistic classifier is reliable or calibrated\nif the predicted probabilities are matched by ex post observed frequencies, as\nexamined visually in reliability diagrams. The classical binning and counting\napproach to plotting reliability diagrams has been hampered by a lack of\nstability under unavoidable, ad hoc implementation decisions. Here we introduce\nthe CORP approach, which generates provably statistically Consistent, Optimally\nbinned, and Reproducible reliability diagrams in an automated way. CORP is\nbased on non-parametric isotonic regression and implemented via the\nPool-adjacent-violators (PAV) algorithm - essentially, the CORP reliability\ndiagram shows the graph of the PAV- (re)calibrated forecast probabilities. The\nCORP approach allows for uncertainty quantification via either resampling\ntechniques or asymptotic theory, furnishes a new numerical measure of\nmiscalibration, and provides a CORP based Brier score decomposition that\ngeneralizes to any proper scoring rule. We anticipate that judicious uses of\nthe PAV algorithm yield improved tools for diagnostics and inference for a very\nwide range of statistical and machine learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 08:22:26 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Dimitriadis", "Timo", ""], ["Gneiting", "Tilmann", ""], ["Jordan", "Alexander I.", ""]]}, {"id": "2008.03038", "submitter": "Subhro Ghosh", "authors": "Subhroshekhar Ghosh, Krishnakumar Balasubramanian, Xiaochuan Yang", "title": "Fractal Gaussian Networks: A sparse random graph model based on Gaussian\n  Multiplicative Chaos", "comments": "Part of this work has been accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel stochastic network model, called Fractal Gaussian Network\n(FGN), that embodies well-defined and analytically tractable fractal\nstructures. Such fractal structures have been empirically observed in diverse\napplications. FGNs interpolate continuously between the popular purely random\ngeometric graphs (a.k.a. the Poisson Boolean network), and random graphs with\nincreasingly fractal behavior. In fact, they form a parametric family of sparse\nrandom geometric graphs that are parametrized by a fractality parameter $\\nu$\nwhich governs the strength of the fractal structure. FGNs are driven by the\nlatent spatial geometry of Gaussian Multiplicative Chaos (GMC), a canonical\nmodel of fractality in its own right. We asymptotically characterize the\nexpected number of edges and triangle in FGNs. We then examine the natural\nquestion of detecting the presence of fractality and the problem of parameter\nestimation based on observed network data, in addition to fundamental\nproperties of the FGN as a random graph model. We also explore fractality in\ncommunity structures by unveiling a natural stochastic block model in the\nsetting of FGNs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 08:37:36 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Ghosh", "Subhroshekhar", ""], ["Balasubramanian", "Krishnakumar", ""], ["Yang", "Xiaochuan", ""]]}, {"id": "2008.03039", "submitter": "Nicolas Cofre", "authors": "Nicolas Cofre", "title": "A boosted outlier detection method based on the spectrum of the\n  Laplacian matrix of a graph", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores a new outlier detection algorithm based on the spectrum\nof the Laplacian matrix of a graph. Taking advantage of boosting together with\nsparse-data based learners. The sparcity of the Laplacian matrix significantly\ndecreases the computational burden, enabling a spectrum based outlier detection\nmethod to be applied to larger datasets compared to spectral clustering. The\nmethod is competitive on synthetic datasets with commonly used outlier\ndetection algorithms like Isolation Forest and Local Outlier Factor.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 08:37:56 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 10:47:16 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Cofre", "Nicolas", ""]]}, {"id": "2008.03069", "submitter": "Thomas Uriot Tu", "authors": "Thomas Uriot, Dario Izzo, Lu\\'is F. Sim{\\~o}es, Rasit Abay, Nils\n  Einecke, Sven Rebhan, Jose Martinez-Heras, Francesca Letizia, Jan Siminski,\n  Klaus Merz", "title": "Spacecraft Collision Avoidance Challenge: design and results of a\n  machine learning competition", "comments": "Pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spacecraft collision avoidance procedures have become an essential part of\nsatellite operations. Complex and constantly updated estimates of the collision\nrisk between orbiting objects inform the various operators who can then plan\nrisk mitigation measures. Such measures could be aided by the development of\nsuitable machine learning models predicting, for example, the evolution of the\ncollision risk in time. In an attempt to study this opportunity, the European\nSpace Agency released, in October 2019, a large curated dataset containing\ninformation about close approach events, in the form of Conjunction Data\nMessages (CDMs), collected from 2015 to 2019. This dataset was used in the\nSpacecraft Collision Avoidance Challenge, a machine learning competition where\nparticipants had to build models to predict the final collision risk between\norbiting objects. This paper describes the design and results of the\ncompetition and discusses the challenges and lessons learned when applying\nmachine learning methods to this problem domain.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 10:05:20 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 12:30:31 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Uriot", "Thomas", ""], ["Izzo", "Dario", ""], ["Sim{\u00f5}es", "Lu\u00eds F.", ""], ["Abay", "Rasit", ""], ["Einecke", "Nils", ""], ["Rebhan", "Sven", ""], ["Martinez-Heras", "Jose", ""], ["Letizia", "Francesca", ""], ["Siminski", "Jan", ""], ["Merz", "Klaus", ""]]}, {"id": "2008.03071", "submitter": "Pourya Shamsolmoali", "authors": "Masoumeh Zareapoor, Pourya Shamsolmoali, Jie Yang", "title": "Oversampling Adversarial Network for Class-Imbalanced Fault Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The collected data from industrial machines are often imbalanced, which poses\na negative effect on learning algorithms. However, this problem becomes more\nchallenging for a mixed type of data or while there is overlapping between\nclasses. Class-imbalance problem requires a robust learning system which can\ntimely predict and classify the data. We propose a new adversarial network for\nsimultaneous classification and fault detection. In particular, we restore the\nbalance in the imbalanced dataset by generating faulty samples from the\nproposed mixture of data distribution. We designed the discriminator of our\nmodel to handle the generated faulty samples to prevent outlier and\noverfitting. We empirically demonstrate that; (i) the discriminator trained\nwith a generator to generates samples from a mixture of normal and faulty data\ndistribution which can be considered as a fault detector; (ii), the quality of\nthe generated faulty samples outperforms the other synthetic resampling\ntechniques. Experimental results show that the proposed model performs well\nwhen comparing to other fault diagnosis methods across several evaluation\nmetrics; in particular, coalescing of generative adversarial network (GAN) and\nfeature matching function is effective at recognizing faulty samples.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 10:12:07 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Zareapoor", "Masoumeh", ""], ["Shamsolmoali", "Pourya", ""], ["Yang", "Jie", ""]]}, {"id": "2008.03072", "submitter": "Philip Sperl", "authors": "Philip Sperl and Konstantin B\\\"ottinger", "title": "Optimizing Information Loss Towards Robust Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Networks (NNs) are vulnerable to adversarial examples. Such inputs\ndiffer only slightly from their benign counterparts yet provoke\nmisclassifications of the attacked NNs. The required perturbations to craft the\nexamples are often negligible and even human imperceptible. To protect deep\nlearning-based systems from such attacks, several countermeasures have been\nproposed with adversarial training still being considered the most effective.\nHere, NNs are iteratively retrained using adversarial examples forming a\ncomputational expensive and time consuming process often leading to a\nperformance decrease. To overcome the downsides of adversarial training while\nstill providing a high level of security, we present a new training approach we\ncall \\textit{entropic retraining}. Based on an information-theoretic-inspired\nanalysis, entropic retraining mimics the effects of adversarial training\nwithout the need of the laborious generation of adversarial examples. We\nempirically show that entropic retraining leads to a significant increase in\nNNs' security and robustness while only relying on the given original data.\nWith our prototype implementation we validate and show the effectiveness of our\napproach for various NN architectures and data sets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 10:12:31 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 14:28:06 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Sperl", "Philip", ""], ["B\u00f6ttinger", "Konstantin", ""]]}, {"id": "2008.03082", "submitter": "Jing Gu", "authors": "Jing Gu, Qingyang Wu, Zhou Yu", "title": "Perception Score, A Learned Metric for Open-ended Text Generation\n  Evaluation", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic evaluation for open-ended natural language generation tasks remains\na challenge. Existing metrics such as BLEU show a low correlation with human\njudgment. We propose a novel and powerful learning-based evaluation metric:\nPerception Score. The method measures the overall quality of the generation and\nscores holistically instead of only focusing on one evaluation criteria, such\nas word overlapping. Moreover, it also shows the amount of uncertainty about\nits evaluation result. By connecting the uncertainty, Perception Score gives a\nmore accurate evaluation for the generation system. Perception Score provides\nstate-of-the-art results on two conditional generation tasks and two\nunconditional generation tasks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 10:48:40 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 23:25:52 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Gu", "Jing", ""], ["Wu", "Qingyang", ""], ["Yu", "Zhou", ""]]}, {"id": "2008.03096", "submitter": "Devang S Ram Mohan", "authors": "Devang S Ram Mohan, Raphael Lenain, Lorenzo Foglianti, Tian Huey Teh,\n  Marlene Staib, Alexandra Torresquintero, Jiameng Gao", "title": "Incremental Text to Speech for Neural Sequence-to-Sequence Models using\n  Reinforcement Learning", "comments": "To be published in Interspeech 2020. 5 pages, 4 figures", "journal-ref": null, "doi": "10.21437/Interspeech.2020-1822", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern approaches to text to speech require the entire input character\nsequence to be processed before any audio is synthesised. This latency limits\nthe suitability of such models for time-sensitive tasks like simultaneous\ninterpretation. Interleaving the action of reading a character with that of\nsynthesising audio reduces this latency. However, the order of this sequence of\ninterleaved actions varies across sentences, which raises the question of how\nthe actions should be chosen. We propose a reinforcement learning based\nframework to train an agent to make this decision. We compare our performance\nagainst that of deterministic, rule-based systems. Our results demonstrate that\nour agent successfully balances the trade-off between the latency of audio\ngeneration and the quality of synthesised audio. More broadly, we show that\nneural sequence-to-sequence models can be adapted to run in an incremental\nmanner.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 11:48:05 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Mohan", "Devang S Ram", ""], ["Lenain", "Raphael", ""], ["Foglianti", "Lorenzo", ""], ["Teh", "Tian Huey", ""], ["Staib", "Marlene", ""], ["Torresquintero", "Alexandra", ""], ["Gao", "Jiameng", ""]]}, {"id": "2008.03107", "submitter": "Qian Lou", "authors": "Qian Lou and Sarath Janga and Lei Jiang", "title": "Helix: Algorithm/Architecture Co-design for Accelerating Nanopore Genome\n  Base-calling", "comments": "12 pages, 26 figures, The 29th International Conference on Parallel\n  Architectures and Compilation Techniques (PACT'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nanopore genome sequencing is the key to enabling personalized medicine,\nglobal food security, and virus surveillance. The state-of-the-art base-callers\nadopt deep neural networks (DNNs) to translate electrical signals generated by\nnanopore sequencers to digital DNA symbols. A DNN-based base-caller consumes\n$44.5\\%$ of total execution time of a nanopore sequencing pipeline. However, it\nis difficult to quantize a base-caller and build a power-efficient\nprocessing-in-memory (PIM) to run the quantized base-caller. In this paper, we\npropose a novel algorithm/architecture co-designed PIM, Helix, to\npower-efficiently and accurately accelerate nanopore base-calling. From\nalgorithm perspective, we present systematic error aware training to minimize\nthe number of systematic errors in a quantized base-caller. From architecture\nperspective, we propose a low-power SOT-MRAM-based ADC array to process\nanalog-to-digital conversion operations and improve power efficiency of prior\nDNN PIMs. Moreover, we revised a traditional NVM-based dot-product engine to\naccelerate CTC decoding operations, and create a SOT-MRAM binary comparator\narray to process read voting. Compared to state-of-the-art PIMs, Helix improves\nbase-calling throughput by $6\\times$, throughput per Watt by $11.9\\times$ and\nper $mm^2$ by $7.5\\times$ without degrading base-calling accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 22:17:19 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Lou", "Qian", ""], ["Janga", "Sarath", ""], ["Jiang", "Lei", ""]]}, {"id": "2008.03110", "submitter": "Matthias Stierle", "authors": "Matthias Stierle, Sven Weinzierl, Maximilian Harl, Martin Matzner", "title": "A Technique for Determining Relevance Scores of Process Activities using\n  Graph-based Neural Networks", "comments": null, "journal-ref": "Decision Support Systems, 2021", "doi": "10.1016/j.dss.2021.113511", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Process models generated through process mining depict the as-is state of a\nprocess. Through annotations with metrics such as the frequency or duration of\nactivities, these models provide generic information to the process analyst. To\nimprove business processes with respect to performance measures, process\nanalysts require further guidance from the process model. In this study, we\ndesign Graph Relevance Miner (GRM), a technique based on graph neural networks,\nto determine the relevance scores for process activities with respect to\nperformance measures. Annotating process models with such relevance scores\nfacilitates a problem-focused analysis of the business process, placing these\nproblems at the centre of the analysis. We quantitatively evaluate the\npredictive quality of our technique using four datasets from different domains,\nto demonstrate the faithfulness of the relevance scores. Furthermore, we\npresent the results of a case study, which highlight the utility of the\ntechnique for organisations. Our work has important implications both for\nresearch and business applications, because process model-based analyses\nfeature shortcomings that need to be urgently addressed to realise successful\nprocess mining at an enterprise level.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 12:15:30 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 08:57:52 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Stierle", "Matthias", ""], ["Weinzierl", "Sven", ""], ["Harl", "Maximilian", ""], ["Matzner", "Martin", ""]]}, {"id": "2008.03111", "submitter": "Sungeun Hong", "authors": "Youngeun Kim, Sungeun Hong, Seunghan Yang, Sungil Kang, Yunho Jeon,\n  Jiwon Kim", "title": "Associative Partial Domain Adaptation", "comments": "8 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial Adaptation (PDA) addresses a practical scenario in which the target\ndomain contains only a subset of classes in the source domain. While PDA should\ntake into account both class-level and sample-level to mitigate negative\ntransfer, current approaches mostly rely on only one of them. In this paper, we\npropose a novel approach to fully exploit multi-level associations that can\narise in PDA. Our Associative Partial Domain Adaptation (APDA) utilizes\nintra-domain association to actively select out non-trivial anomaly samples in\neach source-private class that sample-level weighting cannot handle.\nAdditionally, our method considers inter-domain association to encourage\npositive transfer by mapping between nearby target samples and source samples\nwith high label-commonness. For this, we exploit feature propagation in a\nproposed label space consisting of source ground-truth labels and target\nprobabilistic labels. We further propose a geometric guidance loss based on the\nlabel commonness of each source class to encourage positive transfer. Our APDA\nconsistently achieves state-of-the-art performance across public datasets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 12:15:38 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Kim", "Youngeun", ""], ["Hong", "Sungeun", ""], ["Yang", "Seunghan", ""], ["Kang", "Sungil", ""], ["Jeon", "Yunho", ""], ["Kim", "Jiwon", ""]]}, {"id": "2008.03127", "submitter": "Mathieu Seurin", "authors": "Mathieu Seurin, Florian Strub, Philippe Preux, and Olivier Pietquin", "title": "A Machine of Few Words -- Interactive Speaker Recognition with\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker recognition is a well known and studied task in the speech processing\ndomain. It has many applications, either for security or speaker adaptation of\npersonal devices. In this paper, we present a new paradigm for automatic\nspeaker recognition that we call Interactive Speaker Recognition (ISR). In this\nparadigm, the recognition system aims to incrementally build a representation\nof the speakers by requesting personalized utterances to be spoken in contrast\nto the standard text-dependent or text-independent schemes. To do so, we cast\nthe speaker recognition task into a sequential decision-making problem that we\nsolve with Reinforcement Learning. Using a standard dataset, we show that our\nmethod achieves excellent performance while using little speech signal amounts.\nThis method could also be applied as an utterance selection mechanism for\nbuilding speech synthesis systems.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 12:44:08 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Seurin", "Mathieu", ""], ["Strub", "Florian", ""], ["Preux", "Philippe", ""], ["Pietquin", "Olivier", ""]]}, {"id": "2008.03130", "submitter": "Caglar Demir", "authors": "Caglar Demir and Axel-Cyrille Ngonga Ngomo", "title": "Convolutional Complex Knowledge Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of learning continuous vector\nrepresentations of knowledge graphs for predicting missing links. We present a\nnew approach called ConEx, which infers missing links by leveraging the\ncomposition of a 2D convolution with a Hermitian inner product of\ncomplex-valued embedding vectors. We evaluate ConEx against state-of-the-art\napproaches on the WN18RR, FB15K-237, KINSHIP and UMLS benchmark datasets. Our\nexperimental results show that ConEx achieves a performance superior to that of\nstate-of-the-art approaches such as RotatE, QuatE and TuckER on the link\nprediction task on all datasets while requiring at least 8 times fewer\nparameters. We ensure the reproducibility of our results by providing an\nopen-source implementation which includes the training, evaluation scripts\nalong with pre-trained models at https://github.com/conex-kge/ConEx.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 12:49:01 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 11:57:04 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 12:25:01 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Demir", "Caglar", ""], ["Ngomo", "Axel-Cyrille Ngonga", ""]]}, {"id": "2008.03132", "submitter": "Oliver Schulz", "authors": "Oliver Schulz and Frederik Beaujean and Allen Caldwell and Cornelius\n  Grunwald and Vasyl Hafych and Kevin Kr\\\"oninger and Salvatore La Cagnina and\n  Lars R\\\"ohrig and Lolian Shtembari", "title": "BAT.jl -- A Julia-based tool for Bayesian inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO astro-ph.IM cs.LG hep-ex physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the development of a multi-purpose software for Bayesian\nstatistical inference, BAT.jl, written in the Julia language. The major design\nconsiderations and implemented algorithms are summarized here, together with a\ntest suite that ensures the proper functioning of the algorithms. We also give\nan extended example from the realm of physics that demonstrates the\nfunctionalities of BAT.jl.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 12:55:52 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Schulz", "Oliver", ""], ["Beaujean", "Frederik", ""], ["Caldwell", "Allen", ""], ["Grunwald", "Cornelius", ""], ["Hafych", "Vasyl", ""], ["Kr\u00f6ninger", "Kevin", ""], ["La Cagnina", "Salvatore", ""], ["R\u00f6hrig", "Lars", ""], ["Shtembari", "Lolian", ""]]}, {"id": "2008.03143", "submitter": "Hiroki Ito", "authors": "Hiroki Ito, Yuma Kinoshita, Hitoshi Kiya", "title": "Image Transformation Network for Privacy-Preserving Deep Neural Networks\n  and Its Security Evaluation", "comments": "To appear in 2020 IEEE 9th Global Conference on Consumer Electronics\n  (GCCE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a transformation network for generating visually-protected images\nfor privacy-preserving DNNs. The proposed transformation network is trained by\nusing a plain image dataset so that plain images are transformed into visually\nprotected ones. Conventional perceptual encryption methods have a weak\nvisual-protection performance and some accuracy degradation in image\nclassification. In contrast, the proposed network enables us not only to\nstrongly protect visual information but also to maintain the image\nclassification accuracy that using plain images achieves. In an image\nclassification experiment, the proposed network is demonstrated to strongly\nprotect visual information on plain images without any performance degradation\nunder the use of CIFAR datasets. In addition, it is shown that the visually\nprotected images are robust against a DNN-based attack, called inverse\ntransformation network attack (ITN-Attack) in an experiment.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 12:58:45 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Ito", "Hiroki", ""], ["Kinoshita", "Yuma", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "2008.03156", "submitter": "Armen Aghajanyan", "authors": "Armen Aghajanyan, Akshat Shrivastava, Anchit Gupta, Naman Goyal, Luke\n  Zettlemoyer, Sonal Gupta", "title": "Better Fine-Tuning by Reducing Representational Collapse", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although widely adopted, existing approaches for fine-tuning pre-trained\nlanguage models have been shown to be unstable across hyper-parameter settings,\nmotivating recent work on trust region methods. In this paper, we present a\nsimplified and efficient method rooted in trust region theory that replaces\npreviously used adversarial objectives with parametric noise (sampling from\neither a normal or uniform distribution), thereby discouraging representation\nchange during fine-tuning when possible without hurting performance. We also\nintroduce a new analysis to motivate the use of trust region methods more\ngenerally, by studying representational collapse; the degradation of\ngeneralizable representations from pre-trained models as they are fine-tuned\nfor a specific end task. Extensive experiments show that our fine-tuning method\nmatches or exceeds the performance of previous trust region methods on a range\nof understanding and generation tasks (including DailyMail/CNN, Gigaword,\nReddit TIFU, and the GLUE benchmark), while also being much faster. We also\nshow that it is less prone to representation collapse; the pre-trained models\nmaintain more generalizable representations every time they are fine-tuned.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 02:13:16 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Aghajanyan", "Armen", ""], ["Shrivastava", "Akshat", ""], ["Gupta", "Anchit", ""], ["Goyal", "Naman", ""], ["Zettlemoyer", "Luke", ""], ["Gupta", "Sonal", ""]]}, {"id": "2008.03157", "submitter": "Shady E. Ahmed", "authors": "Shady Ahmed, Suraj Pawar, Omer San, Adil Rasheed, Mandar Tabib", "title": "A nudged hybrid analysis and modeling approach for realtime wake-vortex\n  transport and decay prediction", "comments": "arXiv admin note: substantial text overlap with arXiv:2005.14246", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We put forth a long short-term memory (LSTM) nudging framework for the\nenhancement of reduced order models (ROMs) of fluid flows utilizing noisy\nmeasurements for air traffic improvements. Toward emerging applications of\ndigital twins in aviation, the proposed approach allows for constructing a\nrealtime predictive tool for wake-vortex transport and decay systems. We build\non the fact that in realistic application, there are uncertainties in initial\nand boundary conditions, model parameters, as well as measurements. Moreover,\nconventional nonlinear ROMs based on Galerkin projection (GROMs) suffer from\nimperfection and solution instabilities, especially for advection-dominated\nflows with slow decay in the Kolmogorov width. In the presented LSTM nudging\n(LSTM-N) approach, we fuse forecasts from a combination of imperfect GROM and\nuncertain state estimates, with sparse Eulerian sensor measurements to provide\nmore reliable predictions in a dynamical data assimilation framework. We\nillustrate our concept by solving a two-dimensional vorticity transport\nequation. We investigate the effects of measurements noise and state estimate\nuncertainty on the performance of the LSTM-N behavior. We also demonstrate that\nit can sufficiently handle different levels of temporal and spatial measurement\nsparsity, and offer a huge potential in developing next-generation digital twin\ntechnologies.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 23:47:15 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 15:11:40 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Ahmed", "Shady", ""], ["Pawar", "Suraj", ""], ["San", "Omer", ""], ["Rasheed", "Adil", ""], ["Tabib", "Mandar", ""]]}, {"id": "2008.03175", "submitter": "Tomoyuki Obuchi", "authors": "Kao Hayashi, Tomoyuki Obuchi, Yoshiyuki Kabashima", "title": "Reconstructing Sparse Signals via Greedy Monte-Carlo Search", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": "10.7566/JPSJ.89.124802", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Monte-Carlo-based method for reconstructing sparse signals in\nthe formulation of sparse linear regression in a high-dimensional setting. The\nbasic idea of this algorithm is to explicitly select variables or covariates to\nrepresent a given data vector or responses and accept randomly generated\nupdates of that selection if and only if the energy or cost function decreases.\nThis algorithm is called the greedy Monte-Carlo (GMC) search algorithm. Its\nperformance is examined via numerical experiments, which suggests that in the\nnoiseless case, GMC can achieve perfect reconstruction in undersampling\nsituations of a reasonable level: it can outperform the $\\ell_1$ relaxation but\ndoes not reach the algorithmic limit of MC-based methods theoretically\nclarified by an earlier analysis. The necessary computational time is also\nexamined and compared with that of an algorithm using simulated annealing.\nAdditionally, experiments on the noisy case are conducted on synthetic datasets\nand on a real-world dataset, supporting the practicality of GMC.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 13:36:57 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 03:24:43 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 09:05:13 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Hayashi", "Kao", ""], ["Obuchi", "Tomoyuki", ""], ["Kabashima", "Yoshiyuki", ""]]}, {"id": "2008.03194", "submitter": "Lijun Sun Mr", "authors": "Xinyu Chen, Yixian Chen, Nicolas Saunier, Lijun Sun", "title": "Scalable Low-Rank Tensor Learning for Spatiotemporal Traffic Data\n  Imputation", "comments": null, "journal-ref": "Transportation Research Part C Emerging Technologies (2021)\n  129:103226", "doi": "10.1016/j.trc.2021.103226", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing value problem in spatiotemporal traffic data has long been a\nchallenging topic, in particular for large-scale and high-dimensional data with\ncomplex missing mechanisms and diverse degrees of missingness. Recent studies\nbased on tensor nuclear norm have demonstrated the superiority of tensor\nlearning in imputation tasks by effectively characterizing the complex\ncorrelations/dependencies in spatiotemporal data. However, despite the\npromising results, these approaches do not scale well to large data tensors. In\nthis paper, we focus on addressing the missing data imputation problem for\nlarge-scale spatiotemporal traffic data. To achieve both high accuracy and\nefficiency, we develop a scalable tensor learning model -- Low-Tubal-Rank\nSmoothing Tensor Completion (LSTC-Tubal) -- based on the existing framework of\nLow-Rank Tensor Completion, which is well-suited for spatiotemporal traffic\ndata that is characterized by multidimensional structure of location$\\times$\ntime of day $\\times$ day. In particular, the proposed LSTC-Tubal model involves\na scalable tensor nuclear norm minimization scheme by integrating linear\nunitary transformation. Therefore, tensor nuclear norm minimization can be\nsolved by singular value thresholding on the transformed matrix of each day\nwhile the day-to-day correlation can be effectively preserved by the unitary\ntransform matrix. We compare LSTC-Tubal with state-of-the-art baseline models,\nand find that LSTC-Tubal can achieve competitive accuracy with a significantly\nlower computational cost. In addition, the LSTC-Tubal will also benefit other\ntasks in modeling large-scale spatiotemporal traffic data, such as\nnetwork-level traffic forecasting.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 14:19:07 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 12:58:48 GMT"}, {"version": "v3", "created": "Sat, 12 Jun 2021 17:19:07 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Chen", "Xinyu", ""], ["Chen", "Yixian", ""], ["Saunier", "Nicolas", ""], ["Sun", "Lijun", ""]]}, {"id": "2008.03205", "submitter": "Aakarsh Malhotra", "authors": "Aakarsh Malhotra, Surbhi Mittal, Puspita Majumdar, Saheb Chhabra,\n  Kartik Thakral, Mayank Vatsa, Richa Singh, Santanu Chaudhury, Ashwin Pudrod,\n  Anjali Agrawal", "title": "Multi-Task Driven Explainable Diagnosis of COVID-19 using Chest X-ray\n  Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With increasing number of COVID-19 cases globally, all the countries are\nramping up the testing numbers. While the RT-PCR kits are available in\nsufficient quantity in several countries, others are facing challenges with\nlimited availability of testing kits and processing centers in remote areas.\nThis has motivated researchers to find alternate methods of testing which are\nreliable, easily accessible and faster. Chest X-Ray is one of the modalities\nthat is gaining acceptance as a screening modality. Towards this direction, the\npaper has two primary contributions. Firstly, we present the COVID-19\nMulti-Task Network which is an automated end-to-end network for COVID-19\nscreening. The proposed network not only predicts whether the CXR has COVID-19\nfeatures present or not, it also performs semantic segmentation of the regions\nof interest to make the model explainable. Secondly, with the help of medical\nprofessionals, we manually annotate the lung regions of 9000 frontal chest\nradiographs taken from ChestXray-14, CheXpert and a consolidated COVID-19\ndataset. Further, 200 chest radiographs pertaining to COVID-19 patients are\nalso annotated for semantic segmentation. This database will be released to the\nresearch community.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 12:52:23 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Malhotra", "Aakarsh", ""], ["Mittal", "Surbhi", ""], ["Majumdar", "Puspita", ""], ["Chhabra", "Saheb", ""], ["Thakral", "Kartik", ""], ["Vatsa", "Mayank", ""], ["Singh", "Richa", ""], ["Chaudhury", "Santanu", ""], ["Pudrod", "Ashwin", ""], ["Agrawal", "Anjali", ""]]}, {"id": "2008.03209", "submitter": "Sina D\\\"aubener", "authors": "Sina D\\\"aubener and Asja Fischer", "title": "Investigating maximum likelihood based training of infinite mixtures for\n  uncertainty quantification", "comments": null, "journal-ref": "Presented at the uncertainty workshop of ECML PKDD 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty quantification in neural networks gained a lot of attention in\nthe past years. The most popular approaches, Bayesian neural networks (BNNs),\nMonte Carlo dropout, and deep ensembles have one thing in common: they are all\nbased on some kind of mixture model. While the BNNs build infinite mixture\nmodels and are derived via variational inference, the latter two build finite\nmixtures trained with the maximum likelihood method. In this work we\ninvestigate the effect of training an infinite mixture distribution with the\nmaximum likelihood method instead of variational inference. We find that the\nproposed objective leads to stochastic networks with an increased predictive\nvariance, which improves uncertainty based identification of\nmiss-classification and robustness against adversarial attacks in comparison to\na standard BNN with equivalent network structure. The new model also displays\nhigher entropy on out-of-distribution data.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 14:55:53 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 15:57:13 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["D\u00e4ubener", "Sina", ""], ["Fischer", "Asja", ""]]}, {"id": "2008.03221", "submitter": "Zsigmond Benk\\H{o}", "authors": "Zsigmond Benk\\H{o}, Marcell Stippinger, Roberta Rehus, Attila Bencze,\n  D\\'aniel Fab\\'o, Bogl\\'arka Hajnal, Lor\\'and Er\\H{o}ss, Andr\\'as Telcs,\n  Zolt\\'an Somogyv\\'ari", "title": "Manifold-adaptive dimension estimation revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data dimensionality informs us about data complexity and sets limit on the\nstructure of successful signal processing pipelines. In this work we revisit\nand improve the manifold-adaptive Farahmand-Szepesv\\'ari-Audibert (FSA)\ndimension estimator, making it one of the best nearest neighbor-based dimension\nestimators available. We compute the probability density function of local FSA\nestimates, if the local manifold density is uniform. Based on the probability\ndensity function, we propose to use the median of local estimates as a basic\nglobal measure of intrinsic dimensionality, and we demonstrate the advantages\nof this asymptotically unbiased estimator over the previously proposed\nstatistics: the mode and the mean. Additionally, from the probability density\nfunction, we derive the maximum likelihood formula for global intrinsic\ndimensionality, if i.i.d. holds. We tackle edge and finite-sample effects with\nan exponential correction formula, calibrated on hypercube datasets. We compare\nthe performance of the corrected-median-FSA estimator with kNN estimators:\nmaximum likelihood (ML, Levina-Bickel) and two implementations of DANCo (R and\nmatlab). We show that corrected-median-FSA estimator beats the ML estimator and\nit is on equal footing with DANCo for standard synthetic benchmarks according\nto mean percentage error and error rate metrics. With the median-FSA algorithm,\nwe reveal diverse changes in the neural dynamics while resting state and during\nepileptic seizures. We identify brain areas with lower-dimensional dynamics\nthat are possible causal sources and candidates for being seizure onset zones.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 15:27:26 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 10:04:22 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Benk\u0151", "Zsigmond", ""], ["Stippinger", "Marcell", ""], ["Rehus", "Roberta", ""], ["Bencze", "Attila", ""], ["Fab\u00f3", "D\u00e1niel", ""], ["Hajnal", "Bogl\u00e1rka", ""], ["Er\u0151ss", "Lor\u00e1nd", ""], ["Telcs", "Andr\u00e1s", ""], ["Somogyv\u00e1ri", "Zolt\u00e1n", ""]]}, {"id": "2008.03226", "submitter": "Ryan-Rhys Griffiths", "authors": "Aditya R. Thawani, Ryan-Rhys Griffiths, Arian Jamasb, Anthony\n  Bourached, Penelope Jones, William McCorkindale, Alexander A. Aldrick, Alpha\n  A. Lee", "title": "The Photoswitch Dataset: A Molecular Machine Learning Benchmark for the\n  Advancement of Synthetic Chemistry", "comments": "Prior version accepted to the 2020 ICLR Workshop on Fundamental\n  Science in the Era of AI. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The space of synthesizable molecules is greater than $10^{60}$, meaning only\na vanishingly small fraction of these molecules have ever been realized in the\nlab. In order to prioritize which regions of this space to explore next,\nsynthetic chemists need access to accurate molecular property predictions.\nWhile great advances in molecular machine learning have been made, there is a\ndearth of benchmarks featuring properties that are useful for the synthetic\nchemist. Focussing directly on the needs of the synthetic chemist, we introduce\nthe Photoswitch Dataset, a new benchmark for molecular machine learning where\nimprovements in model performance can be immediately observed in the throughput\nof promising molecules synthesized in the lab. Photoswitches are a versatile\nclass of molecule for medical and renewable energy applications where a\nmolecule's efficacy is governed by its electronic transition wavelengths. We\ndemonstrate superior performance in predicting these wavelengths compared to\nboth time-dependent density functional theory (TD-DFT), the incumbent first\nprinciples quantum mechanical approach, as well as a panel of human experts.\nOur baseline models are currently being deployed in the lab as part of the\ndecision process for candidate synthesis. It is our hope that this benchmark\ncan drive real discoveries in photoswitch chemistry and that future benchmarks\ncan be introduced to pivot learning algorithm development to benefit more\nexpansive areas of synthetic chemistry.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 20:59:03 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Thawani", "Aditya R.", ""], ["Griffiths", "Ryan-Rhys", ""], ["Jamasb", "Arian", ""], ["Bourached", "Anthony", ""], ["Jones", "Penelope", ""], ["McCorkindale", "William", ""], ["Aldrick", "Alexander A.", ""], ["Lee", "Alpha A.", ""]]}, {"id": "2008.03229", "submitter": "Mingxuan Li", "authors": "Mingxuan Li, Michael L. Littman", "title": "Towards Sample Efficient Agents through Algorithmic Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose and explore Deep Graph Value Network (DeepGV) as a\npromising method to work around sample complexity in deep\nreinforcement-learning agents using a message-passing mechanism. The main idea\nis that the agent should be guided by structured non-neural-network algorithms\nlike dynamic programming. According to recent advances in algorithmic\nalignment, neural networks with structured computation procedures can be\ntrained efficiently. We demonstrate the potential of graph neural network in\nsupporting sample efficient learning by showing that Deep Graph Value Network\ncan outperform unstructured baselines by a large margin in solving the Markov\nDecision Process (MDP). We believe this would open up a new avenue for\nstructured agent design. See\nhttps://github.com/drmeerkat/Deep-Graph-Value-Network for the code.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 15:44:32 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 15:55:33 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 11:31:00 GMT"}, {"version": "v4", "created": "Mon, 7 Dec 2020 14:19:22 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Li", "Mingxuan", ""], ["Littman", "Michael L.", ""]]}, {"id": "2008.03230", "submitter": "Shohreh Deldari", "authors": "Shohreh Deldari, Daniel V. Smith, Amin Sadri, Flora D. Salim", "title": "ESPRESSO: Entropy and ShaPe awaRe timE-Series SegmentatiOn for\n  processing heterogeneous sensor data", "comments": "23 pages, 11 figures, accepted at IMWUT Volume(4) issue(3)", "journal-ref": null, "doi": "10.1145/3411832", "report-no": null, "categories": "cs.LG cs.CV cs.DB cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting informative and meaningful temporal segments from high-dimensional\nwearable sensor data, smart devices, or IoT data is a vital preprocessing step\nin applications such as Human Activity Recognition (HAR), trajectory\nprediction, gesture recognition, and lifelogging. In this paper, we propose\nESPRESSO (Entropy and ShaPe awaRe timE-Series SegmentatiOn), a hybrid\nsegmentation model for multi-dimensional time-series that is formulated to\nexploit the entropy and temporal shape properties of time-series. ESPRESSO\ndiffers from existing methods that focus upon particular statistical or\ntemporal properties of time-series exclusively. As part of model development, a\nnovel temporal representation of time-series $WCAC$ was introduced along with a\ngreedy search approach that estimate segments based upon the entropy metric.\nESPRESSO was shown to offer superior performance to four state-of-the-art\nmethods across seven public datasets of wearable and wear-free sensing. In\naddition, we undertake a deeper investigation of these datasets to understand\nhow ESPRESSO and its constituent methods perform with respect to different\ndataset characteristics. Finally, we provide two interesting case-studies to\nshow how applying ESPRESSO can assist in inferring daily activity routines and\nthe emotional state of humans.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 10:41:20 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Deldari", "Shohreh", ""], ["Smith", "Daniel V.", ""], ["Sadri", "Amin", ""], ["Salim", "Flora D.", ""]]}, {"id": "2008.03235", "submitter": "Thibaud Rahier", "authors": "Thibaud Rahier, Am\\'elie H\\'eliou, Matthieu Martin, Christophe\n  Renaudin and Eustache Diemert", "title": "Individual Treatment Prescription Effect Estimation in a Low Compliance\n  Setting", "comments": "28 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individual Treatment Effect (ITE) estimation is an extensively researched\nproblem, with applications in various domains. We model the case where there\nexists heterogeneous non-compliance to a randomly assigned treatment, a typical\nsituation in health (because of non-compliance to prescription) or digital\nadvertising (because of competition and ad blockers for instance). The lower\nthe compliance, the more the effect of treatment prescription, or individual\nprescription effect (IPE), signal fades away and becomes hard to estimate. We\npropose a new approach for the estimation of the IPE that takes advantage of\nobserved compliance information to prevent signal fading. Using the Structural\nCausal Model framework and do-calculus, we define a general mediated causal\neffect setting and propose a corresponding estimator which consistently\nrecovers the IPE with asymptotic variance guarantees. Finally, we conduct\nexperiments on both synthetic and real-world datasets that highlight the\nbenefit of the approach, which consistently improves state-of-the-art in low\ncompliance settings\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 15:53:00 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 15:30:12 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Rahier", "Thibaud", ""], ["H\u00e9liou", "Am\u00e9lie", ""], ["Martin", "Matthieu", ""], ["Renaudin", "Christophe", ""], ["Diemert", "Eustache", ""]]}, {"id": "2008.03240", "submitter": "Shahnawaz Ahmed", "authors": "Shahnawaz Ahmed, Carlos S\\'anchez Mu\\~noz, Franco Nori, Anton Frisk\n  Kockum", "title": "Quantum State Tomography with Conditional Generative Adversarial\n  Networks", "comments": "5 pages, 5 figures, code will be available at\n  https://github.com/quantshah/qst-cgan; v2: minor updates; see also the\n  companion paper arXiv:2012.02185", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum state tomography (QST) is a challenging task in intermediate-scale\nquantum devices. Here, we apply conditional generative adversarial networks\n(CGANs) to QST. In the CGAN framework, two duelling neural networks, a\ngenerator and a discriminator, learn multi-modal models from data. We augment a\nCGAN with custom neural-network layers that enable conversion of output from\nany standard neural network into a physical density matrix. To reconstruct the\ndensity matrix, the generator and discriminator networks train each other on\ndata using standard gradient-based methods. We demonstrate that our QST-CGAN\nreconstructs optical quantum states with high fidelity orders of magnitude\nfaster, and from less data, than a standard maximum-likelihood method. We also\nshow that the QST-CGAN can reconstruct a quantum state in a single evaluation\nof the generator network if it has been pre-trained on similar quantum states.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 15:58:50 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 18:14:37 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Ahmed", "Shahnawaz", ""], ["Mu\u00f1oz", "Carlos S\u00e1nchez", ""], ["Nori", "Franco", ""], ["Kockum", "Anton Frisk", ""]]}, {"id": "2008.03260", "submitter": "Anshumali Shrivastava", "authors": "Nicholas Meisburger, Anshumali Shrivastava", "title": "Distributed Tera-Scale Similarity Search with MPI: Provably Efficient\n  Similarity Search over billions without a Single Distance Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SLASH (Sketched LocAlity Sensitive Hashing), an MPI (Message\nPassing Interface) based distributed system for approximate similarity search\nover terabyte scale datasets. SLASH provides a multi-node implementation of the\npopular LSH (locality sensitive hashing) algorithm, which is generally\nimplemented on a single machine. We show how we can append the LSH algorithm\nwith heavy hitters sketches to provably solve the (high) similarity search\nproblem without a single distance computation. Overall, we mathematically show\nthat, under realistic data assumptions, we can identify the near-neighbor of a\ngiven query $q$ in sub-linear ($ \\ll O(n)$) number of simple sketch aggregation\noperations only. To make such a system practical, we offer a novel design and\nsketching solution to reduce the inter-machine communication overheads\nexponentially. In a direct comparison on comparable hardware, SLASH is more\nthan 10000x faster than the popular LSH package in PySpark. PySpark is a\nwidely-adopted distributed implementation of the LSH algorithm for large\ndatasets and is deployed in commercial platforms. In the end, we show how our\nsystem scale to Tera-scale Criteo dataset with more than 4 billion samples.\nSLASH can index this 2.3 terabyte data over 20 nodes in under an hour, with\nquery times in a fraction of milliseconds. To the best of our knowledge, there\nis no open-source system that can index and perform a similarity search on\nCriteo with a commodity cluster.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 18:15:36 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 22:48:52 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Meisburger", "Nicholas", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "2008.03273", "submitter": "Kyriakos Polymenakos", "authors": "Kyriakos Polymenakos, Nikitas Rontsis, Alessandro Abate and Stephen\n  Roberts", "title": "SafePILCO: a software tool for safe and data-efficient policy synthesis", "comments": "Shorter Version published as a software tool demonstration at QEST\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SafePILCO is a software tool for safe and data-efficient policy search with\nreinforcement learning. It extends the known PILCO algorithm, originally\nwritten in MATLAB, to support safe learning. We provide a Python implementation\nand leverage existing libraries that allow the codebase to remain short and\nmodular, which is appropriate for wider use by the verification, reinforcement\nlearning, and control communities.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 17:17:30 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Polymenakos", "Kyriakos", ""], ["Rontsis", "Nikitas", ""], ["Abate", "Alessandro", ""], ["Roberts", "Stephen", ""]]}, {"id": "2008.03274", "submitter": "Amirreza Shirani", "authors": "Amirreza Shirani, Franck Dernoncourt, Nedim Lipka, Paul Asente, Jose\n  Echevarria and Thamar Solorio", "title": "SemEval-2020 Task 10: Emphasis Selection for Written Text in Visual\n  Media", "comments": "Accepted at Proceedings of 14th International Workshop on Semantic\n  Evaluation (SemEval-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present the main findings and compare the results of\nSemEval-2020 Task 10, Emphasis Selection for Written Text in Visual Media. The\ngoal of this shared task is to design automatic methods for emphasis selection,\ni.e. choosing candidates for emphasis in textual content to enable automated\ndesign assistance in authoring. The main focus is on short text instances for\nsocial media, with a variety of examples, from social media posts to\ninspirational quotes. Participants were asked to model emphasis using plain\ntext with no additional context from the user or other design considerations.\nSemEval-2020 Emphasis Selection shared task attracted 197 participants in the\nearly phase and a total of 31 teams made submissions to this task. The\nhighest-ranked submission achieved 0.823 Matchm score. The analysis of systems\nsubmitted to the task indicates that BERT and RoBERTa were the most common\nchoice of pre-trained models used, and part of speech tag (POS) was the most\nuseful feature. Full results can be found on the task's website.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 17:24:53 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Shirani", "Amirreza", ""], ["Dernoncourt", "Franck", ""], ["Lipka", "Nedim", ""], ["Asente", "Paul", ""], ["Echevarria", "Jose", ""], ["Solorio", "Thamar", ""]]}, {"id": "2008.03297", "submitter": "MohammadNoor Injadat", "authors": "MohammadNoor Injadat, Abdallah Moubayed, Ali Bou Nassif, Abdallah\n  Shami", "title": "Multi-Stage Optimized Machine Learning Framework for Network Intrusion\n  Detection", "comments": "14 Pages, 13 Figures, 4 tables, Published IEEE Transactions on\n  Network and Service Management ( Early Access )", "journal-ref": "Electronic ISSN: 1932-4537", "doi": "10.1109/TNSM.2020.3014929", "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-security garnered significant attention due to the increased dependency\nof individuals and organizations on the Internet and their concern about the\nsecurity and privacy of their online activities. Several previous machine\nlearning (ML)-based network intrusion detection systems (NIDSs) have been\ndeveloped to protect against malicious online behavior. This paper proposes a\nnovel multi-stage optimized ML-based NIDS framework that reduces computational\ncomplexity while maintaining its detection performance. This work studies the\nimpact of oversampling techniques on the models' training sample size and\ndetermines the minimal suitable training sample size. Furthermore, it compares\nbetween two feature selection techniques, information gain and\ncorrelation-based, and explores their effect on detection performance and time\ncomplexity. Moreover, different ML hyper-parameter optimization techniques are\ninvestigated to enhance the NIDS's performance. The performance of the proposed\nframework is evaluated using two recent intrusion detection datasets, the\nCICIDS 2017 and the UNSW-NB 2015 datasets. Experimental results show that the\nproposed model significantly reduces the required training sample size (up to\n74%) and feature set size (up to 50%). Moreover, the model performance is\nenhanced with hyper-parameter optimization with detection accuracies over 99%\nfor both datasets, outperforming recent literature works by 1-2% higher\naccuracy and 1-2% lower false alarm rate.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 03:18:00 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Injadat", "MohammadNoor", ""], ["Moubayed", "Abdallah", ""], ["Nassif", "Ali Bou", ""], ["Shami", "Abdallah", ""]]}, {"id": "2008.03309", "submitter": "Rodrigo Carrasco-Davis", "authors": "Rodrigo Carrasco-Davis, Esteban Reyes, Camilo Valenzuela, Francisco\n  F\\\"orster, Pablo A. Est\\'evez, Giuliano Pignata, Franz E. Bauer, Ignacio\n  Reyes, Paula S\\'anchez-S\\'aez, Guillermo Cabrera-Vives, Susana Eyheramendy,\n  M\\'arcio Catelan, Javier Arredondo, Ernesto Castillo-Navarrete, Diego\n  Rodr\\'iguez-Mancini, Daniela Ruz-Mieres, Alberto Moya, Luis\n  Sabatini-Gacit\\'ua, Crist\\'obal Sep\\'ulveda-Cobo, Ashish A. Mahabal, Javier\n  Silva-Farf\\'an, Ernesto Camacho-I\\~niquez and Llu\\'is Galbany", "title": "Alert Classification for the ALeRCE Broker System: The Real-time Stamp\n  Classifier", "comments": "Submitted to AAS on Jun 30th. Comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.HE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a real-time stamp classifier of astronomical events for the ALeRCE\n(Automatic Learning for the Rapid Classification of Events) broker. The\nclassifier is based on a convolutional neural network, trained on alerts\ningested from the Zwicky Transient Facility (ZTF). Using only the\n\\textit{science, reference} and \\textit{difference} images of the first\ndetection as inputs, along with the metadata of the alert as features, the\nclassifier is able to correctly classify alerts from active galactic nuclei,\nsupernovae (SNe), variable stars, asteroids and bogus classes, with high\naccuracy ($\\sim$94\\%) in a balanced test set. In order to find and analyze SN\ncandidates selected by our classifier from the ZTF alert stream, we designed\nand deployed a visualization tool called SN Hunter, where relevant information\nabout each possible SN is displayed for the experts to choose among candidates\nto report to the Transient Name Server database. From June 26th 2019 to\nFebruary 28th 2021, we have reported 6846 SN candidates to date (11.8\ncandidates per day on average), of which 971 have been confirmed\nspectroscopically. Our ability to report objects using only a single detection\nmeans that 70\\% of the reported SNe occurred within one day after the first\ndetection. ALeRCE has only reported candidates not otherwise detected or\nselected by other groups, therefore adding new early transients to the bulk of\nobjects available for early follow-up. Our work represents an important\nmilestone toward rapid alert classifications with the next generation of large\netendue telescopes, such as the Vera C. Rubin Observatory.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 18:00:01 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 20:30:38 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Carrasco-Davis", "Rodrigo", ""], ["Reyes", "Esteban", ""], ["Valenzuela", "Camilo", ""], ["F\u00f6rster", "Francisco", ""], ["Est\u00e9vez", "Pablo A.", ""], ["Pignata", "Giuliano", ""], ["Bauer", "Franz E.", ""], ["Reyes", "Ignacio", ""], ["S\u00e1nchez-S\u00e1ez", "Paula", ""], ["Cabrera-Vives", "Guillermo", ""], ["Eyheramendy", "Susana", ""], ["Catelan", "M\u00e1rcio", ""], ["Arredondo", "Javier", ""], ["Castillo-Navarrete", "Ernesto", ""], ["Rodr\u00edguez-Mancini", "Diego", ""], ["Ruz-Mieres", "Daniela", ""], ["Moya", "Alberto", ""], ["Sabatini-Gacit\u00faa", "Luis", ""], ["Sep\u00falveda-Cobo", "Crist\u00f3bal", ""], ["Mahabal", "Ashish A.", ""], ["Silva-Farf\u00e1n", "Javier", ""], ["Camacho-I\u00f1iquez", "Ernesto", ""], ["Galbany", "Llu\u00eds", ""]]}, {"id": "2008.03323", "submitter": "Xavier Amatriain", "authors": "Anitha Kannan, Richard Chen, Vignesh Venkataraman, Geoffrey J. Tso,\n  Xavier Amatriain", "title": "COVID-19 in differential diagnosis of online symptom assessments", "comments": "Accepted at the Machine Learning for Health (ML4H) at NeurIPS 2020 -\n  Extended Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has magnified an already existing trend of people\nlooking for healthcare solutions online. One class of solutions are symptom\ncheckers, which have become very popular in the context of COVID-19.\nTraditional symptom checkers, however, are based on manually curated expert\nsystems that are inflexible and hard to modify, especially in a quickly\nchanging situation like the one we are facing today. That is why all COVID-19\nexisting solutions are manual symptom checkers that can only estimate the\nprobability of this disease and cannot contemplate alternative hypothesis or\ncome up with a differential diagnosis. While machine learning offers an\nalternative, the lack of reliable data does not make it easy to apply to\nCOVID-19 either. In this paper we present an approach that combines the\nstrengths of traditional AI expert systems and novel deep learning models. In\ndoing so we can leverage prior knowledge as well as any amount of existing data\nto quickly derive models that best adapt to the current state of the world and\nlatest scientific knowledge. We use the approach to train a COVID-19 aware\ndifferential diagnosis model that can be used for medical decision support both\nfor doctors or patients. We show that our approach is able to accurately model\nnew incoming data about COVID-19 while still preserving accuracy on conditions\nthat had been modeled in the past. While our approach shows evident and clear\nadvantages for an extreme situation like the one we are currently facing, we\nalso show that its flexibility generalizes beyond this concrete, but very\nimportant, example.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 18:10:42 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 22:34:44 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 22:13:39 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Kannan", "Anitha", ""], ["Chen", "Richard", ""], ["Venkataraman", "Vignesh", ""], ["Tso", "Geoffrey J.", ""], ["Amatriain", "Xavier", ""]]}, {"id": "2008.03326", "submitter": "Marco Mondelli", "authors": "Marco Mondelli, Christos Thrampoulidis and Ramji Venkataramanan", "title": "Optimal Combination of Linear and Spectral Estimators for Generalized\n  Linear Models", "comments": "49 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of recovering an unknown signal $\\boldsymbol x$ given\nmeasurements obtained from a generalized linear model with a Gaussian sensing\nmatrix. Two popular solutions are based on a linear estimator $\\hat{\\boldsymbol\nx}^{\\rm L}$ and a spectral estimator $\\hat{\\boldsymbol x}^{\\rm s}$. The former\nis a data-dependent linear combination of the columns of the measurement\nmatrix, and its analysis is quite simple. The latter is the principal\neigenvector of a data-dependent matrix, and a recent line of work has studied\nits performance. In this paper, we show how to optimally combine\n$\\hat{\\boldsymbol x}^{\\rm L}$ and $\\hat{\\boldsymbol x}^{\\rm s}$. At the heart\nof our analysis is the exact characterization of the joint empirical\ndistribution of $(\\boldsymbol x, \\hat{\\boldsymbol x}^{\\rm L}, \\hat{\\boldsymbol\nx}^{\\rm s})$ in the high-dimensional limit. This allows us to compute the\nBayes-optimal combination of $\\hat{\\boldsymbol x}^{\\rm L}$ and\n$\\hat{\\boldsymbol x}^{\\rm s}$, given the limiting distribution of the signal\n$\\boldsymbol x$. When the distribution of the signal is Gaussian, then the\nBayes-optimal combination has the form $\\theta\\hat{\\boldsymbol x}^{\\rm\nL}+\\hat{\\boldsymbol x}^{\\rm s}$ and we derive the optimal combination\ncoefficient. In order to establish the limiting distribution of $(\\boldsymbol\nx, \\hat{\\boldsymbol x}^{\\rm L}, \\hat{\\boldsymbol x}^{\\rm s})$, we design and\nanalyze an Approximate Message Passing (AMP) algorithm whose iterates give\n$\\hat{\\boldsymbol x}^{\\rm L}$ and approach $\\hat{\\boldsymbol x}^{\\rm s}$.\nNumerical simulations demonstrate the improvement of the proposed combination\nwith respect to the two methods considered separately.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 18:20:05 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 14:24:56 GMT"}, {"version": "v3", "created": "Fri, 25 Jun 2021 07:15:43 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Mondelli", "Marco", ""], ["Thrampoulidis", "Christos", ""], ["Venkataramanan", "Ramji", ""]]}, {"id": "2008.03352", "submitter": "Bowen Li", "authors": "Bowen Li, Ke Yan, Dar-In Tai, Yuankai Huo, Le Lu, Jing Xiao, Adam P.\n  Harrison", "title": "Reliable Liver Fibrosis Assessment from Ultrasound using Global\n  Hetero-Image Fusion and View-Specific Parameterization", "comments": "10 pages, MICCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrasound (US) is a critical modality for diagnosing liver fibrosis.\nUnfortunately, assessment is very subjective, motivating automated approaches.\nWe introduce a principled deep convolutional neural network (CNN) workflow that\nincorporates several innovations. First, to avoid overfitting on non-relevant\nimage features, we force the network to focus on a clinical region of interest\n(ROI), encompassing the liver parenchyma and upper border. Second, we introduce\nglobal heteroimage fusion (GHIF), which allows the CNN to fuse features from\nany arbitrary number of images in a study, increasing its versatility and\nflexibility. Finally, we use 'style'-based view-specific parameterization (VSP)\nto tailor the CNN processing for different viewpoints of the liver, while\nkeeping the majority of parameters the same across views. Experiments on a\ndataset of 610 patient studies (6979 images) demonstrate that our pipeline can\ncontribute roughly 7% and 22% improvements in partial area under the curve and\nrecall at 90% precision, respectively, over conventional classifiers,\nvalidating our approach to this crucial problem.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 19:50:15 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Li", "Bowen", ""], ["Yan", "Ke", ""], ["Tai", "Dar-In", ""], ["Huo", "Yuankai", ""], ["Lu", "Le", ""], ["Xiao", "Jing", ""], ["Harrison", "Adam P.", ""]]}, {"id": "2008.03356", "submitter": "Anna Solovyova", "authors": "A.Solovyova, I.Solovyov", "title": "X-Ray bone abnormalities detection using MURA dataset", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce the deep network trained on the MURA dataset from the Stanford\nUniversity released in 2017. Our system is able to detect bone abnormalities on\nthe radiographs and visualise such zones. We found that our solution has the\naccuracy comparable to the best results that have been achieved by other\ndevelopment teams that used MURA dataset, in particular the overall Kappa score\nthat was achieved by our team is about 0.942 on the wrist, 0.862 on the hand\nand o.735 on the shoulder (compared to the best available results to this\nmoment on the official web-site 0.931, 0.851 and 0.729 accordingly). However,\ndespite the good results there are a lot of directions for the future\nenhancement of the proposed technology. We see a big potential in the further\ndevelopment computer aided systems (CAD) for the radiographs as the one that\nwill help practical specialists diagnose bone fractures as well as bone\noncology cases faster and with the higher accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 19:58:56 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Solovyova", "A.", ""], ["Solovyov", "I.", ""]]}, {"id": "2008.03359", "submitter": "Homayoon Beigi", "authors": "Lin Ai and Shih-Ying Jeng and Homayoon Beigi", "title": "A New Approach to Accent Recognition and Conversion for Mandarin Chinese", "comments": "11 pages, 7 figures, and 10 tables", "journal-ref": null, "doi": null, "report-no": "RTI-20200218-01", "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two new approaches to accent classification and conversion are presented and\nexplored, respectively. The first topic is Chinese accent\nclassification/recognition. The second topic is the use of encoder-decoder\nmodels for end-to-end Chinese accent conversion, where the classifier in the\nfirst topic is used for the training of the accent converter encoder-decoder\nmodel. Experiments using different features and model are performed for accent\nrecognition. These features include MFCCs and spectrograms. The classifier\nmodels were TDNN and 1D-CNN. On the MAGICDATA dataset with 5 classes of\naccents, the TDNN classifier trained on MFCC features achieved a test accuracy\nof 54% and a test F1 score of 0.54 while the 1D-CNN classifier trained on\nspectrograms achieve a test accuracy of 62% and a test F1 score of 0.62. A\nprototype of an end-to-end accent converter model is also presented. The\nconverter model comprises of an encoder and a decoder. The encoder model\nconverts an accented input into an accent-neutral form. The decoder model\nconverts an accent-neutral form to an accented form with the specified accent\nassigned by the input accent label. The converter prototype preserves the tone\nand foregoes the details in the output audio. An encoder-decoder structure\ndemonstrates the potential of being an effective accent converter. A proposal\nfor future improvements is also presented to address the issue of lost details\nin the decoder output.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 20:06:33 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Ai", "Lin", ""], ["Jeng", "Shih-Ying", ""], ["Beigi", "Homayoon", ""]]}, {"id": "2008.03364", "submitter": "Xuanqing Liu", "authors": "Jiachen Zhong, Xuanqing Liu, Cho-Jui Hsieh", "title": "Improving the Speed and Quality of GAN by Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GAN) have shown remarkable results in image\ngeneration tasks. High fidelity class-conditional GAN methods often rely on\nstabilization techniques by constraining the global Lipschitz continuity. Such\nregularization leads to less expressive models and slower convergence speed;\nother techniques, such as the large batch training, require unconventional\ncomputing power and are not widely accessible. In this paper, we develop an\nefficient algorithm, namely FastGAN (Free AdverSarial Training), to improve the\nspeed and quality of GAN training based on the adversarial training technique.\nWe benchmark our method on CIFAR10, a subset of ImageNet, and the full ImageNet\ndatasets. We choose strong baselines such as SNGAN and SAGAN; the results\ndemonstrate that our training algorithm can achieve better generation quality\n(in terms of the Inception score and Frechet Inception distance) with less\noverall training time. Most notably, our training algorithm brings ImageNet\ntraining to the broader public by requiring 2-4 GPUs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 20:21:31 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Zhong", "Jiachen", ""], ["Liu", "Xuanqing", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2008.03367", "submitter": "Matthew Perez", "authors": "Matthew Perez, Wenyu Jin, Duc Le, Noelle Carlozzi, Praveen Dayalu,\n  Angela Roberts, Emily Mower Provost", "title": "Classification of Huntington Disease using Acoustic and Lexical Features", "comments": "4 pages", "journal-ref": null, "doi": "10.21437/Interspeech.2018-2029", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech is a critical biomarker for Huntington Disease (HD), with changes in\nspeech increasing in severity as the disease progresses. Speech analyses are\ncurrently conducted using either transcriptions created manually by trained\nprofessionals or using global rating scales. Manual transcription is both\nexpensive and time-consuming and global rating scales may lack sufficient\nsensitivity and fidelity. Ultimately, what is needed is an unobtrusive measure\nthat can cheaply and continuously track disease progression. We present first\nsteps towards the development of such a system, demonstrating the ability to\nautomatically differentiate between healthy controls and individuals with HD\nusing speech cues. The results provide evidence that objective analyses can be\nused to support clinical diagnoses, moving towards the tracking of\nsymptomatology outside of laboratory and clinical environments.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 20:32:01 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Perez", "Matthew", ""], ["Jin", "Wenyu", ""], ["Le", "Duc", ""], ["Carlozzi", "Noelle", ""], ["Dayalu", "Praveen", ""], ["Roberts", "Angela", ""], ["Provost", "Emily Mower", ""]]}, {"id": "2008.03368", "submitter": "Hamid Usefi", "authors": "Hamid Usefi", "title": "Clustering, multicollinearity, and singular vectors", "comments": "Comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $A$ be a matrix with its pseudo-matrix $A^{\\dagger}$ and set\n$S=I-A^{\\dagger}A$. We prove that, after re-ordering the columns of $A$, the\nmatrix $S$ has a block-diagonal form where each block corresponds to a set of\nlinearly dependent columns. This allows us to identify redundant columns in\n$A$. We explore some applications in supervised and unsupervised learning,\nspecially feature selection, clustering, and sensitivity of solutions of least\nsquares solutions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 20:32:34 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Usefi", "Hamid", ""]]}, {"id": "2008.03371", "submitter": "Ang Li", "authors": "Ang Li, Jingwei Sun, Binghui Wang, Lin Duan, Sicheng Li, Yiran Chen,\n  Hai Li", "title": "LotteryFL: Personalized and Communication-Efficient Federated Learning\n  with Lottery Ticket Hypothesis on Non-IID Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a popular distributed machine learning paradigm with\nenhanced privacy. Its primary goal is learning a global model that offers good\nperformance for the participants as many as possible. The technology is rapidly\nadvancing with many unsolved challenges, among which statistical heterogeneity\n(i.e., non-IID) and communication efficiency are two critical ones that hinder\nthe development of federated learning. In this work, we propose LotteryFL -- a\npersonalized and communication-efficient federated learning framework via\nexploiting the Lottery Ticket hypothesis. In LotteryFL, each client learns a\nlottery ticket network (i.e., a subnetwork of the base model) by applying the\nLottery Ticket hypothesis, and only these lottery networks will be communicated\nbetween the server and clients. Rather than learning a shared global model in\nclassic federated learning, each client learns a personalized model via\nLotteryFL; the communication cost can be significantly reduced due to the\ncompact size of lottery networks. To support the training and evaluation of our\nframework, we construct non-IID datasets based on MNIST, CIFAR-10 and EMNIST by\ntaking feature distribution skew, label distribution skew and quantity skew\ninto consideration. Experiments on these non-IID datasets demonstrate that\nLotteryFL significantly outperforms existing solutions in terms of\npersonalization and communication cost.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 20:45:12 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Li", "Ang", ""], ["Sun", "Jingwei", ""], ["Wang", "Binghui", ""], ["Duan", "Lin", ""], ["Li", "Sicheng", ""], ["Chen", "Yiran", ""], ["Li", "Hai", ""]]}, {"id": "2008.03382", "submitter": "Ramiro Casal", "authors": "Ramiro Casal, Leandro E. Di Persia, Gast\\'on Schlotthauer", "title": "Classifying sleep-wake stages through recurrent neural networks using\n  pulse oximetry signals", "comments": "12 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The regulation of the autonomic nervous system changes with the sleep stages\ncausing variations in the physiological variables. We exploit these changes\nwith the aim of classifying the sleep stages in awake or asleep using pulse\noximeter signals. We applied a recurrent neural network to heart rate and\nperipheral oxygen saturation signals to classify the sleep stage every 30\nseconds. The network architecture consists of two stacked layers of\nbidirectional gated recurrent units (GRUs) and a softmax layer to classify the\noutput. In this paper, we used 5000 patients from the Sleep Heart Health Study\ndataset. 2500 patients were used to train the network, and two subsets of 1250\nwere used to validate and test the trained models. In the test stage, the best\nresult obtained was 90.13% accuracy, 94.13% sensitivity, 80.26% specificity,\n92.05% precision, and 84.68% negative predictive value. Further, the Cohen's\nKappa coefficient was 0.74 and the average absolute error percentage to the\nactual sleep time was 8.9%. The performance of the proposed network is\ncomparable with the state-of-the-art algorithms when they use much more\ninformative signals (except those with EEG).\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 21:43:46 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Casal", "Ramiro", ""], ["Di Persia", "Leandro E.", ""], ["Schlotthauer", "Gast\u00f3n", ""]]}, {"id": "2008.03388", "submitter": "Max Morrison", "authors": "Max Morrison, Zeyu Jin, Justin Salamon, Nicholas J. Bryan, Gautham J.\n  Mysore", "title": "Controllable Neural Prosody Synthesis", "comments": "To appear in proceedings of INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech synthesis has recently seen significant improvements in fidelity,\ndriven by the advent of neural vocoders and neural prosody generators. However,\nthese systems lack intuitive user controls over prosody, making them unable to\nrectify prosody errors (e.g., misplaced emphases and contextually inappropriate\nemotions) or generate prosodies with diverse speaker excitement levels and\nemotions. We address these limitations with a user-controllable, context-aware\nneural prosody generator. Given a real or synthesized speech recording, our\nmodel allows a user to input prosody constraints for certain time frames and\ngenerates the remaining time frames from input text and contextual prosody. We\nalso propose a pitch-shifting neural vocoder to modify input speech to match\nthe synthesized prosody. Through objective and subjective evaluations we show\nthat we can successfully incorporate user control into our prosody generation\nmodel without sacrificing the overall naturalness of the synthesized speech.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 22:11:58 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 19:34:47 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Morrison", "Max", ""], ["Jin", "Zeyu", ""], ["Salamon", "Justin", ""], ["Bryan", "Nicholas J.", ""], ["Mysore", "Gautham J.", ""]]}, {"id": "2008.03392", "submitter": "Kefei Liu", "authors": "Kefei Liu, Qi Long, Li Shen", "title": "Grouping effects of sparse CCA models in variable selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sparse canonical correlation analysis (SCCA) is a bi-multivariate\nassociation model that finds sparse linear combinations of two sets of\nvariables that are maximally correlated with each other. In addition to the\nstandard SCCA model, a simplified SCCA criterion which maixmizes the\ncross-covariance between a pair of canonical variables instead of their\ncross-correlation, is widely used in the literature due to its computational\nsimplicity. However, the behaviors/properties of the solutions of these two\nmodels remain unknown in theory. In this paper, we analyze the grouping effect\nof the standard and simplified SCCA models in variable selection. In\nhigh-dimensional settings, the variables often form groups with high\nwithin-group correlation and low between-group correlation. Our theoretical\nanalysis shows that for grouped variable selection, the simplified SCCA jointly\nselects or deselects a group of variables together, while the standard SCCA\nrandomly selects a few dominant variables from each relevant group of\ncorrelated variables. Empirical results on synthetic data and real imaging\ngenetics data verify the finding of our theoretical analysis.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 22:27:31 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Liu", "Kefei", ""], ["Long", "Qi", ""], ["Shen", "Li", ""]]}, {"id": "2008.03397", "submitter": "Lana Yeganova", "authors": "Lana Yeganova, Rezarta Islamaj, Qingyu Chen, Robert Leaman, Alexis\n  Allot, Chin-Hsuan Wei, Donald C. Comeau, Won Kim, Yifan Peng, W. John Wilbur,\n  Zhiyong Lu", "title": "Navigating the landscape of COVID-19 research through literature\n  analysis: A bird's eye view", "comments": "10 pages, 8 Figures, Submitted to KDD 2020 Health Day", "journal-ref": "KDD 2020 Health Day: AI for COVID, August 23-27, 2020, Virtual\n  Conference, CA, US", "doi": null, "report-no": null, "categories": "cs.DL cs.DB cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timely access to accurate scientific literature in the battle with the\nongoing COVID-19 pandemic is critical. This unprecedented public health risk\nhas motivated research towards understanding the disease in general,\nidentifying drugs to treat the disease, developing potential vaccines, etc.\nThis has given rise to a rapidly growing body of literature that doubles in\nnumber of publications every 20 days as of May 2020. Providing medical\nprofessionals with means to quickly analyze the literature and discover growing\nareas of knowledge is necessary for addressing their question and information\nneeds.\n  In this study we analyze the LitCovid collection, 13,369 COVID-19 related\narticles found in PubMed as of May 15th, 2020 with the purpose of examining the\nlandscape of literature and presenting it in a format that facilitates\ninformation navigation and understanding. We do that by applying\nstate-of-the-art named entity recognition, classification, clustering and other\nNLP techniques. By applying NER tools, we capture relevant bioentities (such as\ndiseases, internal body organs, etc.) and assess the strength of their\nrelationship with COVID-19 by the extent they are discussed in the corpus. We\nalso collect a variety of symptoms and co-morbidities discussed in reference to\nCOVID-19. Our clustering algorithm identifies topics represented by groups of\nrelated terms, and computes clusters corresponding to documents associated with\nthe topic terms. Among the topics we observe several that persist through the\nduration of multiple weeks and have numerous associated documents, as well\nseveral that appear as emerging topics with fewer documents. All the tools and\ndata are publicly available, and this framework can be applied to any\nliterature collection. Taken together, these analyses produce a comprehensive,\nsynthesized view of COVID-19 research to facilitate knowledge discovery from\nliterature.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 23:39:29 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 21:01:27 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Yeganova", "Lana", ""], ["Islamaj", "Rezarta", ""], ["Chen", "Qingyu", ""], ["Leaman", "Robert", ""], ["Allot", "Alexis", ""], ["Wei", "Chin-Hsuan", ""], ["Comeau", "Donald C.", ""], ["Kim", "Won", ""], ["Peng", "Yifan", ""], ["Wilbur", "W. John", ""], ["Lu", "Zhiyong", ""]]}, {"id": "2008.03399", "submitter": "Yongquan Fu", "authors": "Yongquan Fu", "title": "Nystr\\\"om Approximation with Nonnegative Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the needs of estimating the proximity clustering with partial\ndistance measurements from vantage points or landmarks for remote networked\nsystems, we show that the proximity clustering problem can be effectively\nformulated as the Nystr\\\"om approximation problem, which solves the kernel\nK-means clustering problem in the complex space. We implement the Nystr\\\"om\napproximation based on a landmark based Nonnegative Matrix Factorization (NMF)\nprocess. Evaluation results show that the proposed method finds nearly optimal\nclustering quality on both synthetic and real-world data sets as we vary the\nrange of parameter choices and network conditions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 23:52:59 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Fu", "Yongquan", ""]]}, {"id": "2008.03400", "submitter": "Hideitsu Hino", "authors": "Keishi Sando and Hideitsu Hino", "title": "Modal Principal Component Analysis", "comments": "33 pages, 5 figures. to appear in Neural Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is a widely used method for data\nprocessing, such as for dimension reduction and visualization. Standard PCA is\nknown to be sensitive to outliers, and thus, various robust PCA methods have\nbeen proposed. It has been shown that the robustness of many statistical\nmethods can be improved using mode estimation instead of mean estimation,\nbecause mode estimation is not significantly affected by the presence of\noutliers. Thus, this study proposes a modal principal component analysis\n(MPCA), which is a robust PCA method based on mode estimation. The proposed\nmethod finds the minor component by estimating the mode of the projected data\npoints. As theoretical contribution, probabilistic convergence property,\ninfluence function, finite-sample breakdown point and its lower bound for the\nproposed MPCA are derived. The experimental results show that the proposed\nmethod has advantages over the conventional methods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 23:59:05 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Sando", "Keishi", ""], ["Hino", "Hideitsu", ""]]}, {"id": "2008.03408", "submitter": "Bo Wang", "authors": "Bo Wang, Yue Wu, Niall Taylor, Terry Lyons, Maria Liakata, Alejo J\n  Nevado-Holgado, Kate E A Saunders", "title": "Learning to Detect Bipolar Disorder and Borderline Personality Disorder\n  with Language and Speech in Non-Clinical Interviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bipolar disorder (BD) and borderline personality disorder (BPD) are both\nchronic psychiatric disorders. However, their overlapping symptoms and common\ncomorbidity make it challenging for the clinicians to distinguish the two\nconditions on the basis of a clinical interview. In this work, we first present\na new multi-modal dataset containing interviews involving individuals with BD\nor BPD being interviewed about a non-clinical topic . We investigate the\nautomatic detection of the two conditions, and demonstrate a good linear\nclassifier that can be learnt using a down-selected set of features from the\ndifferent aspects of the interviews and a novel approach of summarising these\nfeatures. Finally, we find that different sets of features characterise BD and\nBPD, thus providing insights into the difference between the automatic\nscreening of the two conditions.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 00:48:59 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 04:23:15 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wang", "Bo", ""], ["Wu", "Yue", ""], ["Taylor", "Niall", ""], ["Lyons", "Terry", ""], ["Liakata", "Maria", ""], ["Nevado-Holgado", "Alejo J", ""], ["Saunders", "Kate E A", ""]]}, {"id": "2008.03411", "submitter": "Wei Wang", "authors": "Wei Wang, Lin Cheng, Yanjie Zhu, Dong Liang", "title": "Exploring the parameter reusability of CNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent times, using small data to train networks has become a hot topic in\nthe field of deep learning. Reusing pre-trained parameters is one of the most\nimportant strategies to address the issue of semi-supervised and transfer\nlearning. However, the fundamental reason for the success of these methods is\nstill unclear. In this paper, we propose a solution that can not only judge\nwhether a given network is reusable or not based on the performance of reusing\nconvolution kernels but also judge which layers' parameters of the given\nnetwork can be reused, based on the performance of reusing corresponding\nparameters and, ultimately, judge whether those parameters are reusable or not\nin a target task based on the root mean square error (RMSE) of the\ncorresponding convolution kernels. Specifically, we define that the success of\na CNN's parameter reuse depends upon two conditions: first, the network is a\nreusable network; and second, the RMSE between the convolution kernels from the\nsource domain and target domain is small enough. The experimental results\ndemonstrate that the performance of reused parameters applied to target tasks,\nwhen these conditions are met, is significantly improved.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 01:23:22 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 04:23:25 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Wang", "Wei", ""], ["Cheng", "Lin", ""], ["Zhu", "Yanjie", ""], ["Liang", "Dong", ""]]}, {"id": "2008.03412", "submitter": "Iacopo Masi", "authors": "Iacopo Masi, Aditya Killekar, Royston Marian Mascarenhas, Shenoy\n  Pratik Gurudatt, Wael AbdAlmageed", "title": "Two-branch Recurrent Network for Isolating Deepfakes in Videos", "comments": "To appear in the 16th European Conference on Computer Vision ECCV\n  2020 (added link to our demo and to the video presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current spike of hyper-realistic faces artificially generated using\ndeepfakes calls for media forensics solutions that are tailored to video\nstreams and work reliably with a low false alarm rate at the video level. We\npresent a method for deepfake detection based on a two-branch network structure\nthat isolates digitally manipulated faces by learning to amplify artifacts\nwhile suppressing the high-level face content. Unlike current methods that\nextract spatial frequencies as a preprocessing step, we propose a two-branch\nstructure: one branch propagates the original information, while the other\nbranch suppresses the face content yet amplifies multi-band frequencies using a\nLaplacian of Gaussian (LoG) as a bottleneck layer. To better isolate\nmanipulated faces, we derive a novel cost function that, unlike regular\nclassification, compresses the variability of natural faces and pushes away the\nunrealistic facial samples in the feature space. Our two novel components show\npromising results on the FaceForensics++, Celeb-DF, and Facebook's DFDC preview\nbenchmarks, when compared to prior work. We then offer a full, detailed\nablation study of our network architecture and cost function. Finally, although\nthe bar is still high to get very remarkable figures at a very low false alarm\nrate, our study shows that we can achieve good video-level performance when\ncross-testing in terms of video-level AUC.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 01:38:56 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 02:35:55 GMT"}, {"version": "v3", "created": "Fri, 4 Sep 2020 01:03:55 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Masi", "Iacopo", ""], ["Killekar", "Aditya", ""], ["Mascarenhas", "Royston Marian", ""], ["Gurudatt", "Shenoy Pratik", ""], ["AbdAlmageed", "Wael", ""]]}, {"id": "2008.03414", "submitter": "Wei Wang", "authors": "Wei Wang", "title": "Using UNet and PSPNet to explore the reusability principle of CNN\n  parameters", "comments": "arXiv admin note: substantial text overlap with arXiv:2008.03411", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to reduce the requirement on training dataset size is a hot topic in deep\nlearning community. One straightforward way is to reuse some pre-trained\nparameters. Some previous work like Deep transfer learning reuse the model\nparameters trained for the first task as the starting point for the second\ntask, and semi-supervised learning is trained upon a combination of labeled and\nunlabeled data. However, the fundamental reason of the success of these methods\nis unclear. In this paper, the reusability of parameters in each layer of a\ndeep convolutional neural network is experimentally quantified by using a\nnetwork to do segmentation and auto-encoder task. This paper proves that\nnetwork parameters can be reused for two reasons: first, the network features\nare general; Second, there is little difference between the pre-trained\nparameters and the ideal network parameters. Through the use of parameter\nreplacement and comparison, we demonstrate that reusability is different in\nBN(Batch Normalization)[7] layer and Convolution layer and some observations:\n(1)Running mean and running variance plays an important role than Weight and\nBias in BN layer.(2)The weight and bias can be reused in BN layers.( 3) The\nnetwork is very sensitive to the weight of convolutional layer.(4) The bias in\nConvolution layers are not sensitive, and it can be reused directly.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 01:51:08 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Wang", "Wei", ""]]}, {"id": "2008.03415", "submitter": "Shubhanshu Mishra", "authors": "Shubhanshu Mishra, Sijun He, Luca Belli", "title": "Assessing Demographic Bias in Named Entity Recognition", "comments": "Presented at the AKBC Workshop on Bias in Automatic Knowledge Graph\n  Construction, 2020 (arXiv:2007.11659)", "journal-ref": null, "doi": null, "report-no": "REPORT-NO:KGBias/2020/02", "categories": "cs.CL cs.CY cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Named Entity Recognition (NER) is often the first step towards automated\nKnowledge Base (KB) generation from raw text. In this work, we assess the bias\nin various Named Entity Recognition (NER) systems for English across different\ndemographic groups with synthetically generated corpora. Our analysis reveals\nthat models perform better at identifying names from specific demographic\ngroups across two datasets. We also identify that debiased embeddings do not\nhelp in resolving this issue. Finally, we observe that character-based\ncontextualized word representation models such as ELMo results in the least\nbias across demographics. Our work can shed light on potential biases in\nautomated KB generation due to systematic exclusion of named entities belonging\nto certain demographics.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 02:01:25 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mishra", "Shubhanshu", ""], ["He", "Sijun", ""], ["Belli", "Luca", ""]]}, {"id": "2008.03424", "submitter": "Xingwen Zhang", "authors": "Xingwen Zhang and Shuang Yang", "title": "Learning (Re-)Starting Solutions for Vehicle Routing Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge in solving a combinatorial optimization problem is how to\nguide the agent (i.e., solver) to efficiently explore the enormous search\nspace. Conventional approaches often rely on enumeration (e.g., exhaustive,\nrandom, or tabu search) or have to restrict the exploration to rather limited\nregions (e.g., a single path as in iterative algorithms). In this paper, we\nshow it is possible to use machine learning to speedup the exploration. In\nparticular, a value network is trained to evaluate solution candidates, which\nprovides a useful structure (i.e., an approximate value surface) over the\nsearch space; this value network is then used to screen solutions to help a\nblack-box optimization agent to initialize or restart so as to navigate through\nthe search space towards desirable solutions. Experiments demonstrate that the\nproposed ``Learn to Restart'' algorithm achieves promising results in solving\nCapacitated Vehicle Routing Problems (CVRPs).\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 02:53:09 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Zhang", "Xingwen", ""], ["Yang", "Shuang", ""]]}, {"id": "2008.03425", "submitter": "Leda Sar{\\i}", "authors": "Leda Sar{\\i} and Mark Hasegawa-Johnson", "title": "Deep F-measure Maximization for End-to-End Speech Understanding", "comments": "Interspeech 2020 submission (Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken language understanding (SLU) datasets, like many other machine\nlearning datasets, usually suffer from the label imbalance problem. Label\nimbalance usually causes the learned model to replicate similar biases at the\noutput which raises the issue of unfairness to the minority classes in the\ndataset. In this work, we approach the fairness problem by maximizing the\nF-measure instead of accuracy in neural network model training. We propose a\ndifferentiable approximation to the F-measure and train the network with this\nobjective using standard backpropagation. We perform experiments on two\nstandard fairness datasets, Adult, and Communities and Crime, and also on\nspeech-to-intent detection on the ATIS dataset and speech-to-image concept\nclassification on the Speech-COCO dataset. In all four of these tasks,\nF-measure maximization results in improved micro-F1 scores, with absolute\nimprovements of up to 8% absolute, as compared to models trained with the\ncross-entropy loss function. In the two multi-class SLU tasks, the proposed\napproach significantly improves class coverage, i.e., the number of classes\nwith positive recall.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 03:02:27 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Sar\u0131", "Leda", ""], ["Hasegawa-Johnson", "Mark", ""]]}, {"id": "2008.03433", "submitter": "John Halloran", "authors": "John T. Halloran and David M. Rocke", "title": "GPU-Accelerated Primal Learning for Extremely Fast Large-Scale\n  Classification", "comments": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most efficient methods to solve L2-regularized primal problems,\nsuch as logistic regression and linear support vector machine (SVM)\nclassification, is the widely used trust region Newton algorithm, TRON. While\nTRON has recently been shown to enjoy substantial speedups on shared-memory\nmulti-core systems, exploiting graphical processing units (GPUs) to speed up\nthe method is significantly more difficult, owing to the highly complex and\nheavily sequential nature of the algorithm. In this work, we show that using\njudicious GPU-optimization principles, TRON training time for different losses\nand feature representations may be drastically reduced. For sparse feature\nsets, we show that using GPUs to train logistic regression classifiers in\nLIBLINEAR is up to an order-of-magnitude faster than solely using\nmultithreading. For dense feature sets--which impose far more stringent memory\nconstraints--we show that GPUs substantially reduce the lengthy SVM learning\ntimes required for state-of-the-art proteomics analysis, leading to dramatic\nimprovements over recently proposed speedups. Furthermore, we show how GPU\nspeedups may be mixed with multithreading to enable such speedups when the\ndataset is too large for GPU memory requirements; on a massive dense proteomics\ndataset of nearly a quarter-billion data instances, these mixed-architecture\nspeedups reduce SVM analysis time from over half a week to less than a single\nday while using limited GPU memory.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 03:40:27 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 03:16:07 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Halloran", "John T.", ""], ["Rocke", "David M.", ""]]}, {"id": "2008.03435", "submitter": "Yuhao Huang", "authors": "Wang Jian, Miao Juzheng, Yang Xin, Li Rui, Zhou Guangquan, Huang\n  Yuhao, Lin Zehui, Xue Wufeng, Jia Xiaohong, Zhou Jianqiao, Huang Ruobing, Ni\n  Dong", "title": "Auto-weighting for Breast Cancer Classification in Multimodal Ultrasound", "comments": "Early Accepted by MICCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast cancer is the most common invasive cancer in women. Besides the\nprimary B-mode ultrasound screening, sonographers have explored the inclusion\nof Doppler, strain and shear-wave elasticity imaging to advance the diagnosis.\nHowever, recognizing useful patterns in all types of images and weighing up the\nsignificance of each modality can elude less-experienced clinicians. In this\npaper, we explore, for the first time, an automatic way to combine the four\ntypes of ultrasonography to discriminate between benign and malignant breast\nnodules. A novel multimodal network is proposed, along with promising\nlearnability and simplicity to improve classification accuracy. The key is\nusing a weight-sharing strategy to encourage interactions between modalities\nand adopting an additional cross-modalities objective to integrate global\ninformation. In contrast to hardcoding the weights of each modality in the\nmodel, we embed it in a Reinforcement Learning framework to learn this\nweighting in an end-to-end manner. Thus the model is trained to seek the\noptimal multimodal combination without handcrafted heuristics. The proposed\nframework is evaluated on a dataset contains 1616 set of multimodal images.\nResults showed that the model scored a high classification accuracy of 95.4%,\nwhich indicates the efficiency of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 03:42:00 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Jian", "Wang", ""], ["Juzheng", "Miao", ""], ["Xin", "Yang", ""], ["Rui", "Li", ""], ["Guangquan", "Zhou", ""], ["Yuhao", "Huang", ""], ["Zehui", "Lin", ""], ["Wufeng", "Xue", ""], ["Xiaohong", "Jia", ""], ["Jianqiao", "Zhou", ""], ["Ruobing", "Huang", ""], ["Dong", "Ni", ""]]}, {"id": "2008.03440", "submitter": "Bowen Jiang", "authors": "Bowen Jiang, Maohao Shen", "title": "Dimensionality Reduction via Diffusion Map Improved with Supervised\n  Linear Projection", "comments": "This paper is accepted to be published in the 27th IEEE International\n  Conference on Image Processing (ICIP 2020). Two authors contribute equally to\n  the work", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When performing classification tasks, raw high dimensional features often\ncontain redundant information, and lead to increased computational complexity\nand overfitting. In this paper, we assume the data samples lie on a single\nunderlying smooth manifold, and define intra-class and inter-class similarities\nusing pairwise local kernel distances. We aim to find a linear projection to\nmaximize the intra-class similarities and minimize the inter-class similarities\nsimultaneously, so that the projected low dimensional data has optimized\npairwise distances based on the label information, which is more suitable for a\nDiffusion Map to do further dimensionality reduction. Numerical experiments on\nseveral benchmark datasets show that our proposed approaches are able to\nextract low dimensional discriminate features that could help us achieve higher\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 04:26:07 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Jiang", "Bowen", ""], ["Shen", "Maohao", ""]]}, {"id": "2008.03450", "submitter": "Karishma Sharma", "authors": "Karishma Sharma, Xinran He, Sungyong Seo, Yan Liu", "title": "Network Inference from a Mixture of Diffusion Models for Fake News\n  Mitigation", "comments": null, "journal-ref": "Fifteenth international AAAI conference on web and social media\n  (ICWSM 2021)", "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dissemination of fake news intended to deceive people, influence public\nopinion and manipulate social outcomes, has become a pressing problem on social\nmedia. Moreover, information sharing on social media facilitates diffusion of\nviral information cascades. In this work, we focus on understanding and\nleveraging diffusion dynamics of false and legitimate contents in order to\nfacilitate network interventions for fake news mitigation. We analyze\nreal-world Twitter datasets comprising fake and true news cascades, to\nunderstand differences in diffusion dynamics and user behaviours with regards\nto fake and true contents. Based on the analysis, we model the diffusion as a\nmixture of Independent Cascade models (MIC) with parameters $\\theta_T,\n\\theta_F$ over the social network graph; and derive unsupervised inference\ntechniques for parameter estimation of the diffusion mixture model from\nobserved, unlabeled cascades. Users influential in the propagation of true and\nfake contents are identified using the inferred diffusion dynamics.\nCharacteristics of the identified influential users reveal positive correlation\nbetween influential users identified for fake news and their relative\nappearance in fake news cascades. Identified influential users tend to be\nrelated to topics of more viral information cascades than less viral ones; and\nidentified fake news influential users have relatively fewer counts of direct\nfollowers, compared to the true news influential users. Intervention analysis\non nodes and edges demonstrates capacity of the inferred diffusion dynamics in\nsupporting network interventions for mitigation.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 05:59:25 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Sharma", "Karishma", ""], ["He", "Xinran", ""], ["Seo", "Sungyong", ""], ["Liu", "Yan", ""]]}, {"id": "2008.03452", "submitter": "Shiying Li", "authors": "Akram Aldroubi, Shiying Li, Gustavo K. Rohde", "title": "Partitioning signal classes using transport transforms for data analysis\n  and machine learning", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A relatively new set of transport-based transforms (CDT, R-CDT, LOT) have\nshown their strength and great potential in various image and data processing\ntasks such as parametric signal estimation, classification, cancer detection\namong many others. It is hence worthwhile to elucidate some of the mathematical\nproperties that explain the successes of these transforms when they are used as\ntools in data analysis, signal processing or data classification. In\nparticular, we give conditions under which classes of signals that are created\nby algebraic generative models are transformed into convex sets by the\ntransport transforms. Such convexification of the classes simplify the\nclassification and other data analysis and processing problems when viewed in\nthe transform domain. More specifically, we study the extent and limitation of\nthe convexification ability of these transforms under an algebraic generative\nmodeling framework. We hope that this paper will serve as an introduction to\nthese transforms and will encourage mathematicians and other researchers to\nfurther explore the theoretical underpinnings and algorithmic tools that will\nhelp understand the successes of these transforms and lay the groundwork for\nfurther successful applications.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 06:12:10 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 12:48:08 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Aldroubi", "Akram", ""], ["Li", "Shiying", ""], ["Rohde", "Gustavo K.", ""]]}, {"id": "2008.03454", "submitter": "Daniel Fryer Mr", "authors": "Daniel Fryer, Hien Nguyen, Pascal Castellazzi", "title": "$k$-means on Positive Definite Matrices, and an Application to\n  Clustering in Radar Image Sequences", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We state theoretical properties for $k$-means clustering of Symmetric\nPositive Definite (SPD) matrices, in a non-Euclidean space, that provides a\nnatural and favourable representation of these data. We then provide a novel\napplication for this method, to time-series clustering of pixels in a sequence\nof Synthetic Aperture Radar images, via their finite-lag autocovariance\nmatrices.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 06:21:43 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 03:11:48 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Fryer", "Daniel", ""], ["Nguyen", "Hien", ""], ["Castellazzi", "Pascal", ""]]}, {"id": "2008.03455", "submitter": "Zhang Yunlong", "authors": "Yunlong Zhang, Changxing Jing, Huangxing Lin, Chaoqi Chen, Yue Huang,\n  Xinghao Ding, Yang Zou", "title": "Hard Class Rectification for Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation (DA) aims to transfer knowledge from a label-rich and\nrelated domain (source domain) to a label-scare domain (target domain).\nPseudo-labeling has recently been widely explored and used in DA. However, this\nline of research is still confined to the inaccuracy of pseudo-labels. In this\npaper, we reveal an interesting observation that the target samples belonging\nto the classes with larger domain shift are easier to be misclassified compared\nwith the other classes. These classes are called hard class, which deteriorates\nthe performance of DA and restricts the applications of DA. We propose a novel\nframework, called Hard Class Rectification Pseudo-labeling (HCRPL), to\nalleviate the hard class problem from two aspects. First, as is difficult to\nidentify the target samples as hard class, we propose a simple yet effective\nscheme, named Adaptive Prediction Calibration (APC), to calibrate the\npredictions of the target samples according to the difficulty degree for each\nclass. Second, we further consider that the predictions of target samples\nbelonging to the hard class are vulnerable to perturbations. To prevent these\nsamples to be misclassified easily, we introduce Temporal-Ensembling (TE) and\nSelf-Ensembling (SE) to obtain consistent predictions. The proposed method is\nevaluated in both unsupervised domain adaptation (UDA) and semi-supervised\ndomain adaptation (SSDA). The experimental results on several real-world\ncross-domain benchmarks, including ImageCLEF, Office-31 and Office-Home,\nsubstantiates the superiority of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 06:21:58 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 00:03:55 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Zhang", "Yunlong", ""], ["Jing", "Changxing", ""], ["Lin", "Huangxing", ""], ["Chen", "Chaoqi", ""], ["Huang", "Yue", ""], ["Ding", "Xinghao", ""], ["Zou", "Yang", ""]]}, {"id": "2008.03464", "submitter": "Aravind P R", "authors": "Rahul T P, P R Aravind, Ranjith C, Usamath Nechiyil, Nandakumar\n  Paramparambath", "title": "Audio Spoofing Verification using Deep Convolutional Neural Networks by\n  Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Automatic Speaker Verification systems are gaining popularity these days;\nspoofing attacks are of prime concern as they make these systems vulnerable.\nSome spoofing attacks like Replay attacks are easier to implement but are very\nhard to detect thus creating the need for suitable countermeasures. In this\npaper, we propose a speech classifier based on deep-convolutional neural\nnetwork to detect spoofing attacks. Our proposed methodology uses acoustic\ntime-frequency representation of power spectral densities on Mel frequency\nscale (Mel-spectrogram), via deep residual learning (an adaptation of ResNet-34\narchitecture). Using a single model system, we have achieved an equal error\nrate (EER) of 0.9056% on the development and 5.32% on the evaluation dataset of\nlogical access scenario and an equal error rate (EER) of 5.87% on the\ndevelopment and 5.74% on the evaluation dataset of physical access scenario of\nASVspoof 2019.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 07:14:40 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["P", "Rahul T", ""], ["Aravind", "P R", ""], ["C", "Ranjith", ""], ["Nechiyil", "Usamath", ""], ["Paramparambath", "Nandakumar", ""]]}, {"id": "2008.03473", "submitter": "Perla Mayo", "authors": "Perla Mayo, Oktay Karaku\\c{s}, Robin Holmes and Alin Achim", "title": "Representation Learning via Cauchy Convolutional Sparse Coding", "comments": "19 pages, 9 figures, journal draft", "journal-ref": null, "doi": "10.1109/ACCESS.2021.3096643", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In representation learning, Convolutional Sparse Coding (CSC) enables\nunsupervised learning of features by jointly optimising both an \\(\\ell_2\\)-norm\nfidelity term and a sparsity enforcing penalty. This work investigates using a\nregularisation term derived from an assumed Cauchy prior for the coefficients\nof the feature maps of a CSC generative model. The sparsity penalty term\nresulting from this prior is solved via its proximal operator, which is then\napplied iteratively, element-wise, on the coefficients of the feature maps to\noptimise the CSC cost function. The performance of the proposed Iterative\nCauchy Thresholding (ICT) algorithm in reconstructing natural images is\ncompared against the common choice of \\(\\ell_1\\)-norm optimised via soft and\nhard thresholding. ICT outperforms IHT and IST in most of these reconstruction\nexperiments across various datasets, with an average PSNR of up to 11.30 and\n7.04 above ISTA and IHT respectively.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 08:21:44 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Mayo", "Perla", ""], ["Karaku\u015f", "Oktay", ""], ["Holmes", "Robin", ""], ["Achim", "Alin", ""]]}, {"id": "2008.03483", "submitter": "Shuqiang Wang", "authors": "Shengye Hu, Baiying Lei, Yong Wang, Zhiguang Feng, Yanyan Shen,\n  Shuqiang Wang", "title": "Bidirectional Mapping Generative Adversarial Networks for Brain MR to\n  PET Synthesis", "comments": "12pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fusing multi-modality medical images, such as MR and PET, can provide various\nanatomical or functional information about human body. But PET data is always\nunavailable due to different reasons such as cost, radiation, or other\nlimitations. In this paper, we propose a 3D end-to-end synthesis network,\ncalled Bidirectional Mapping Generative Adversarial Networks (BMGAN), where\nimage contexts and latent vector are effectively used and jointly optimized for\nbrain MR-to-PET synthesis. Concretely, a bidirectional mapping mechanism is\ndesigned to embed the semantic information of PET images into the high\ndimensional latent space. And the 3D DenseU-Net generator architecture and the\nextensive objective functions are further utilized to improve the visual\nquality of synthetic results. The most appealing part is that the proposed\nmethod can synthesize the perceptually realistic PET images while preserving\nthe diverse brain structures of different subjects. Experimental results\ndemonstrate that the performance of the proposed method outperforms other\ncompetitive cross-modality synthesis methods in terms of quantitative measures,\nqualitative displays, and classification evaluation.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 09:27:48 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Hu", "Shengye", ""], ["Lei", "Baiying", ""], ["Wang", "Yong", ""], ["Feng", "Zhiguang", ""], ["Shen", "Yanyan", ""], ["Wang", "Shuqiang", ""]]}, {"id": "2008.03493", "submitter": "R\\'emi Eyraud", "authors": "Philipp O. Tsvetkov, R\\'emi Eyraud, St\\'ephane Ayache, Anton A.\n  Bougaev, Soazig Malesinski, Hamed Benazha, Svetlana Gorokhova, Christophe\n  Buffat, Caroline Dehais, Marc Sanson, Franck Bielle, Dominique\n  Figarella-Branger, Olivier Chinot, Emeline Tabouret, Fran\\c{c}ois Devred", "title": "An AI-powered blood test to detect cancer using nanoDSF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel cancer diagnostic method based on plasma denaturation\nprofiles obtained by a non-conventional use of Differential Scanning\nFluorimetry. We show that 84 glioma patients and 63 healthy controls can be\nautomatically classified using denaturation profiles with the help of machine\nlearning algorithms with 92% accuracy. Proposed high throughput workflow can be\napplied to any type of cancer and could become a powerful pan-cancer diagnostic\nand monitoring tool from a simple blood test.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 11:20:53 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Tsvetkov", "Philipp O.", ""], ["Eyraud", "R\u00e9mi", ""], ["Ayache", "St\u00e9phane", ""], ["Bougaev", "Anton A.", ""], ["Malesinski", "Soazig", ""], ["Benazha", "Hamed", ""], ["Gorokhova", "Svetlana", ""], ["Buffat", "Christophe", ""], ["Dehais", "Caroline", ""], ["Sanson", "Marc", ""], ["Bielle", "Franck", ""], ["Figarella-Branger", "Dominique", ""], ["Chinot", "Olivier", ""], ["Tabouret", "Emeline", ""], ["Devred", "Fran\u00e7ois", ""]]}, {"id": "2008.03501", "submitter": "Ilona Kulikovskikh", "authors": "Ilona Kulikovskikh and Tarzan Legovi\\'c", "title": "Why to \"grow\" and \"harvest\" deep learning models?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current expectations from training deep learning models with gradient-based\nmethods include: 1) transparency; 2) high convergence rates; 3) high inductive\nbiases. While the state-of-art methods with adaptive learning rate schedules\nare fast, they still fail to meet the other two requirements. We suggest\nreconsidering neural network models in terms of single-species population\ndynamics where adaptation comes naturally from open-ended processes of \"growth\"\nand \"harvesting\". We show that the stochastic gradient descent (SGD) with two\nbalanced pre-defined values of per capita growth and harvesting rates\noutperform the most common adaptive gradient methods in all of the three\nrequirements.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 11:55:24 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Kulikovskikh", "Ilona", ""], ["Legovi\u0107", "Tarzan", ""]]}, {"id": "2008.03507", "submitter": "Anurag Chowdhury", "authors": "Anurag Chowdhury, Austin Cozzo, Arun Ross", "title": "JukeBox: A Multilingual Singer Recognition Dataset", "comments": "INTERSPEECH 2020 (To Appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A text-independent speaker recognition system relies on successfully encoding\nspeech factors such as vocal pitch, intensity, and timbre to achieve good\nperformance. A majority of such systems are trained and evaluated using spoken\nvoice or everyday conversational voice data. Spoken voice, however, exhibits a\nlimited range of possible speaker dynamics, thus constraining the utility of\nthe derived speaker recognition models. Singing voice, on the other hand,\ncovers a broader range of vocal and ambient factors and can, therefore, be used\nto evaluate the robustness of a speaker recognition system. However, a majority\nof existing speaker recognition datasets only focus on the spoken voice. In\ncomparison, there is a significant shortage of labeled singing voice data\nsuitable for speaker recognition research. To address this issue, we assemble\n\\textit{JukeBox} - a speaker recognition dataset with multilingual singing\nvoice audio annotated with singer identity, gender, and language labels. We use\nthe current state-of-the-art methods to demonstrate the difficulty of\nperforming speaker recognition on singing voice using models trained on spoken\nvoice alone. We also evaluate the effect of gender and language on speaker\nrecognition performance, both in spoken and singing voice data. The complete\n\\textit{JukeBox} dataset can be accessed at\nhttp://iprobe.cse.msu.edu/datasets/jukebox.html.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 12:22:51 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Chowdhury", "Anurag", ""], ["Cozzo", "Austin", ""], ["Ross", "Arun", ""]]}, {"id": "2008.03519", "submitter": "Lucas Tian", "authors": "Lucas Y. Tian, Kevin Ellis, Marta Kryven, Joshua B. Tenenbaum", "title": "Learning abstract structure for drawing by efficient motor program\n  induction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans flexibly solve new problems that differ qualitatively from those they\nwere trained on. This ability to generalize is supported by learned concepts\nthat capture structure common across different problems. Here we develop a\nnaturalistic drawing task to study how humans rapidly acquire structured prior\nknowledge. The task requires drawing visual objects that share underlying\nstructure, based on a set of composable geometric rules. We show that people\nspontaneously learn abstract drawing procedures that support generalization,\nand propose a model of how learners can discover these reusable drawing\nprograms. Trained in the same setting as humans, and constrained to produce\nefficient motor actions, this model discovers new drawing routines that\ntransfer to test objects and resemble learned features of human sequences.\nThese results suggest that two principles guiding motor program induction in\nthe model - abstraction (general programs that ignore object-specific details)\nand compositionality (recombining previously learned programs) - are key for\nexplaining how humans learn structured internal representations that guide\nflexible reasoning and learning.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 13:31:14 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Tian", "Lucas Y.", ""], ["Ellis", "Kevin", ""], ["Kryven", "Marta", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "2008.03522", "submitter": "Rohit Keshari", "authors": "Rohit Keshari, Soumyadeep Ghosh, Saheb Chhabra, Mayank Vatsa, Richa\n  Singh", "title": "Unravelling Small Sample Size Problems in the Deep Learning World", "comments": "3 figures, 2 tables, accepted in BigMM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth and success of deep learning approaches can be attributed to two\nmajor factors: availability of hardware resources and availability of large\nnumber of training samples. For problems with large training databases, deep\nlearning models have achieved superlative performances. However, there are a\nlot of \\textit{small sample size or $S^3$} problems for which it is not\nfeasible to collect large training databases. It has been observed that deep\nlearning models do not generalize well on $S^3$ problems and specialized\nsolutions are required. In this paper, we first present a review of deep\nlearning algorithms for small sample size problems in which the algorithms are\nsegregated according to the space in which they operate, i.e. input space,\nmodel space, and feature space. Secondly, we present Dynamic Attention Pooling\napproach which focuses on extracting global information from the most\ndiscriminative sub-part of the feature map. The performance of the proposed\ndynamic attention pooling is analyzed with state-of-the-art ResNet model on\nrelatively small publicly available datasets such as SVHN, C10, C100, and\nTinyImageNet.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 13:35:49 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Keshari", "Rohit", ""], ["Ghosh", "Soumyadeep", ""], ["Chhabra", "Saheb", ""], ["Vatsa", "Mayank", ""], ["Singh", "Richa", ""]]}, {"id": "2008.03523", "submitter": "Blesson Varghese", "authors": "Luke Lockhart and Paul Harvey and Pierre Imai and Peter Willis and\n  Blesson Varghese", "title": "Scission: Performance-driven and Context-aware Cloud-Edge Distribution\n  of Deep Neural Networks", "comments": "Accepted to IEEE/ACM UCC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partitioning and distributing deep neural networks (DNNs) across end-devices,\nedge resources and the cloud has a potential twofold advantage: preserving\nprivacy of the input data, and reducing the ingress bandwidth demand beyond the\nedge. However, for a given DNN, identifying the optimal partition configuration\nfor distributing the DNN that maximizes performance is a significant challenge.\nThis is because the combination of potential target hardware resources that\nmaximizes performance and the sequence of layers of the DNN that should be\ndistributed across the target resources needs to be determined, while\naccounting for user-defined objectives/constraints for partitioning. This paper\npresents Scission, a tool for automated benchmarking of DNNs on a given set of\ntarget device, edge and cloud resources for determining optimal partitions that\nmaximize DNN performance. The decision-making approach is context-aware by\ncapitalizing on hardware capabilities of the target resources, their locality,\nthe characteristics of DNN layers, and the network condition. Experimental\nstudies are carried out on 18 DNNs. The decisions made by Scission cannot be\nmanually made by a human given the complexity and the number of dimensions\naffecting the search space. The benchmarking overheads of Scission allow for\nresponding to operational changes periodically rather than in real-time.\nScission is available for public download at\nhttps://github.com/qub-blesson/Scission.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 13:39:57 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 19:45:55 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Lockhart", "Luke", ""], ["Harvey", "Paul", ""], ["Imai", "Pierre", ""], ["Willis", "Peter", ""], ["Varghese", "Blesson", ""]]}, {"id": "2008.03525", "submitter": "Oleg Arenz", "authors": "Oleg Arenz and Gerhard Neumann", "title": "Non-Adversarial Imitation Learning and its Connections to Adversarial\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.RO math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern methods for imitation learning and inverse reinforcement\nlearning, such as GAIL or AIRL, are based on an adversarial formulation. These\nmethods apply GANs to match the expert's distribution over states and actions\nwith the implicit state-action distribution induced by the agent's policy.\nHowever, by framing imitation learning as a saddle point problem, adversarial\nmethods can suffer from unstable optimization, and convergence can only be\nshown for small policy updates. We address these problems by proposing a\nframework for non-adversarial imitation learning. The resulting algorithms are\nsimilar to their adversarial counterparts and, thus, provide insights for\nadversarial imitation learning methods. Most notably, we show that AIRL is an\ninstance of our non-adversarial formulation, which enables us to greatly\nsimplify its derivations and obtain stronger convergence guarantees. We also\nshow that our non-adversarial formulation can be used to derive novel\nalgorithms by presenting a method for offline imitation learning that is\ninspired by the recent ValueDice algorithm, but does not rely on small policy\nupdates for convergence. In our simulated robot experiments, our offline method\nfor non-adversarial imitation learning seems to perform best when using many\nupdates for policy and discriminator at each iteration and outperforms\nbehavioral cloning and ValueDice.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 13:43:06 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Arenz", "Oleg", ""], ["Neumann", "Gerhard", ""]]}, {"id": "2008.03529", "submitter": "Zhiwen Zuo", "authors": "Zhiwen Zuo, Lei Zhao, Zhizhong Wang, Haibo Chen, Ailin Li, Qijiang Xu,\n  Wei Xing, Dongming Lu", "title": "Multimodal Image-to-Image Translation via Mutual Information Estimation\n  and Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal image-to-image translation (I2IT) aims to learn a conditional\ndistribution that explores multiple possible images in the target domain given\nan input image in the source domain. Conditional generative adversarial\nnetworks (cGANs) are often adopted for modeling such a conditional\ndistribution. However, cGANs are prone to ignore the latent code and learn a\nunimodal distribution in conditional image synthesis, which is also known as\nthe mode collapse issue of GANs. To solve the problem, we propose a simple yet\neffective method that explicitly estimates and maximizes the mutual information\nbetween the latent code and the output image in cGANs by using a deep mutual\ninformation neural estimator in this paper. Maximizing the mutual information\nstrengthens the statistical dependency between the latent code and the output\nimage, which prevents the generator from ignoring the latent code and\nencourages cGANs to fully utilize the latent code for synthesizing diverse\nresults. Our method not only provides a new perspective from information theory\nto improve diversity for I2IT but also achieves disentanglement between the\nsource domain content and the target domain style for free.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 14:09:23 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 15:34:46 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2020 08:29:29 GMT"}, {"version": "v4", "created": "Mon, 31 Aug 2020 04:08:50 GMT"}, {"version": "v5", "created": "Tue, 1 Sep 2020 10:49:43 GMT"}, {"version": "v6", "created": "Sun, 6 Sep 2020 04:17:36 GMT"}, {"version": "v7", "created": "Sat, 8 May 2021 14:15:56 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zuo", "Zhiwen", ""], ["Zhao", "Lei", ""], ["Wang", "Zhizhong", ""], ["Chen", "Haibo", ""], ["Li", "Ailin", ""], ["Xu", "Qijiang", ""], ["Xing", "Wei", ""], ["Lu", "Dongming", ""]]}, {"id": "2008.03530", "submitter": "Ali ALsaeedi Ali H.Alsaeedi", "authors": "Ali Hakem Alsaeedi, Adil L. Albukhnefis, Dhiah Al-Shammary, Muntasir\n  Al-Asfoor", "title": "Extended Particle Swarm Optimization (EPSO) for Feature Selection of\n  High Dimensional Biomedical Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper proposes a novel Extended Particle Swarm Optimization model (EPSO)\nthat potentially enhances the search process of PSO for optimization problem.\nEvidently, gene expression profiles are significantly important measurement\nfactor in molecular biology that is used in medical diagnosis of cancer types.\nThe challenge to certain classification methodologies for gene expression\nprofiles lies in the thousands of features recorded for each sample. A modified\nWrapper feature selection model is applied with the aim of addressing the gene\nclassification challenge by replacing its randomness approach with EPSO and PSO\nrespectively. EPSO is initializing the random size of the population and\ndividing them into two groups in order to promote the exploration and reduce\nthe probability of falling in stagnation. Experimentally, EPSO has required\nless processing time to select the optimal features (average of 62.14 sec) than\nPSO (average of 95.72 sec). Furthermore, EPSO accuracy has provided better\nclassification results (start from 54% to 100%) than PSO (start from 52% to\n96%).\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 14:09:44 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Alsaeedi", "Ali Hakem", ""], ["Albukhnefis", "Adil L.", ""], ["Al-Shammary", "Dhiah", ""], ["Al-Asfoor", "Muntasir", ""]]}, {"id": "2008.03534", "submitter": "Raphael Gautier", "authors": "Raphael Gautier, Piyush Pandita, Sayan Ghosh, Dimitri Mavris", "title": "A Fully Bayesian Gradient-Free Supervised Dimension Reduction Method\n  using Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern day engineering problems are ubiquitously characterized by\nsophisticated computer codes that map parameters or inputs to an underlying\nphysical process. In other situations, experimental setups are used to model\nthe physical process in a laboratory, ensuring high precision while being\ncostly in materials and logistics. In both scenarios, only limited amount of\ndata can be generated by querying the expensive information source at a finite\nnumber of inputs or designs. This problem is compounded further in the presence\nof a high-dimensional input space. State-of-the-art parameter space dimension\nreduction methods, such as active subspace, aim to identify a subspace of the\noriginal input space that is sufficient to explain the output response. These\nmethods are restricted by their reliance on gradient evaluations or copious\ndata, making them inadequate to expensive problems without direct access to\ngradients. The proposed methodology is gradient-free and fully Bayesian, as it\nquantifies uncertainty in both the low-dimensional subspace and the surrogate\nmodel parameters. This enables a full quantification of epistemic uncertainty\nand robustness to limited data availability. It is validated on multiple\ndatasets from engineering and science and compared to two other\nstate-of-the-art methods based on four aspects: a) recovery of the active\nsubspace, b) deterministic prediction accuracy, c) probabilistic prediction\naccuracy, and d) training time. The comparison shows that the proposed method\nimproves the active subspace recovery and predictive accuracy, in both the\ndeterministic and probabilistic sense, when only few model observations are\navailable for training, at the cost of increased training time.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 14:24:25 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 14:59:07 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Gautier", "Raphael", ""], ["Pandita", "Piyush", ""], ["Ghosh", "Sayan", ""], ["Mavris", "Dimitri", ""]]}, {"id": "2008.03539", "submitter": "Ioannis Kansizoglou", "authors": "Ioannis Kansizoglou, Nicholas Santavas, Loukas Bampis and Antonios\n  Gasteratos", "title": "HASeparator: Hyperplane-Assisted Softmax", "comments": "Submitted to IEEE ICMLA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Efficient feature learning with Convolutional Neural Networks (CNNs)\nconstitutes an increasingly imperative property since several challenging tasks\nof computer vision tend to require cascade schemes and modalities fusion.\nFeature learning aims at CNN models capable of extracting embeddings,\nexhibiting high discrimination among the different classes, as well as\nintra-class compactness. In this paper, a novel approach is introduced that has\nseparator, which focuses on an effective hyperplane-based segregation of the\nclasses instead of the common class centers separation scheme. Accordingly, an\ninnovatory separator, namely the Hyperplane-Assisted Softmax separator\n(HASeparator), is proposed that demonstrates superior discrimination\ncapabilities, as evaluated on popular image classification benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 15:24:56 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Kansizoglou", "Ioannis", ""], ["Santavas", "Nicholas", ""], ["Bampis", "Loukas", ""], ["Gasteratos", "Antonios", ""]]}, {"id": "2008.03543", "submitter": "Kamal Berahmand", "authors": "Mehrdad Rostami, Kamal Berahmand, Saman Forouzandeh", "title": "A Novel Community Detection Based Genetic Algorithm for Feature\n  Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The selection of features is an essential data preprocessing stage in data\nmining. The core principle of feature selection seems to be to pick a subset of\npossible features by excluding features with almost no predictive information\nas well as highly associated redundant features. In the past several years, a\nvariety of meta-heuristic methods were introduced to eliminate redundant and\nirrelevant features as much as possible from high-dimensional datasets. Among\nthe main disadvantages of present meta-heuristic based approaches is that they\nare often neglecting the correlation between a set of selected features. In\nthis article, for the purpose of feature selection, the authors propose a\ngenetic algorithm based on community detection, which functions in three steps.\nThe feature similarities are calculated in the first step. The features are\nclassified by community detection algorithms into clusters throughout the\nsecond step. In the third step, features are picked by a genetic algorithm with\na new community-based repair operation. Nine benchmark classification problems\nwere analyzed in terms of the performance of the presented approach. Also, the\nauthors have compared the efficiency of the proposed approach with the findings\nfrom four available algorithms for feature selection. The findings indicate\nthat the new approach continuously yields improved classification accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 15:39:30 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Rostami", "Mehrdad", ""], ["Berahmand", "Kamal", ""], ["Forouzandeh", "Saman", ""]]}, {"id": "2008.03545", "submitter": "Tipawan Silwattananusarn", "authors": "Tipawan Silwattananusarn and Pachisa Kulkanjanapiban", "title": "Mining and Analyzing Patron's Book-Loan Data and University Data to\n  Understand Library Use Patterns", "comments": "22 pages, 9 figures", "journal-ref": "International Journal of Information Science and Management,\n  Vol.18 No.2.(2020)", "doi": null, "report-no": null, "categories": "cs.CY cs.DB cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The purpose of this paper is to study the patron's usage behavior in an\nacademic library. This study investigates on pattern of patron's books\nborrowing in Khunying Long Athakravisunthorn Learning Resources Center, Prince\nof Songkla University that influence patron's academic achievement during on\nacademic year 2015-2018. The study collected and analyzed data from the\nlibraries, registrar, and human resources. The students' performance data was\nobtained from PSU Student Information System and the rest from ALIST library\ninformation system. WEKA was used as the data mining tool employing data mining\ntechniques of association rules and clustering. All data sets were mined and\nanalyzed to identify characteristics of the patron's book borrowing, to\ndiscover the association rules of patron's interest, and to analyze the\nrelationships between academic library use and undergraduate students'\nachievement. The results reveal patterns of patron's book loan behavior,\npatterns of book usage, patterns of interest rules with respect to patron's\ninterest in book borrowing, and patterns of relationships between patron's\nborrowing and their grade. The ability to clearly identify and describe library\npatron's behavior pattern can help library in managing resources and services\nmore effectively. This study provides a sample model as guideline or campus\npartnerships and for future collaborations that will take advantage of the\nacademic library information and data mining to improve library management and\nlibrary services.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 15:46:50 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Silwattananusarn", "Tipawan", ""], ["Kulkanjanapiban", "Pachisa", ""]]}, {"id": "2008.03546", "submitter": "Anyi Rao", "authors": "Jiangyue Xia, Anyi Rao, Qingqiu Huang, Linning Xu, Jiangtao Wen, Dahua\n  Lin", "title": "Online Multi-modal Person Search in Videos", "comments": "ECCV2020. Project page:\n  http://movienet.site/projects/eccv20onlineperson.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of searching certain people in videos has seen increasing potential\nin real-world applications, such as video organization and editing. Most\nexisting approaches are devised to work in an offline manner, where identities\ncan only be inferred after an entire video is examined. This working manner\nprecludes such methods from being applied to online services or those\napplications that require real-time responses. In this paper, we propose an\nonline person search framework, which can recognize people in a video on the\nfly. This framework maintains a multimodal memory bank at its heart as the\nbasis for person recognition, and updates it dynamically with a policy obtained\nby reinforcement learning. Our experiments on a large movie dataset show that\nthe proposed method is effective, not only achieving remarkable improvements\nover online schemes but also outperforming offline methods.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 15:48:32 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Xia", "Jiangyue", ""], ["Rao", "Anyi", ""], ["Huang", "Qingqiu", ""], ["Xu", "Linning", ""], ["Wen", "Jiangtao", ""], ["Lin", "Dahua", ""]]}, {"id": "2008.03548", "submitter": "Anyi Rao", "authors": "Anyi Rao, Jiaze Wang, Linning Xu, Xuekun Jiang, Qingqiu Huang, Bolei\n  Zhou, Dahua Lin", "title": "A Unified Framework for Shot Type Classification Based on Subject\n  Centric Lens", "comments": "ECCV2020. Project page: https://anyirao.com/projects/ShotType.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shots are key narrative elements of various videos, e.g. movies, TV series,\nand user-generated videos that are thriving over the Internet. The types of\nshots greatly influence how the underlying ideas, emotions, and messages are\nexpressed. The technique to analyze shot types is important to the\nunderstanding of videos, which has seen increasing demand in real-world\napplications in this era. Classifying shot type is challenging due to the\nadditional information required beyond the video content, such as the spatial\ncomposition of a frame and camera movement. To address these issues, we propose\na learning framework Subject Guidance Network (SGNet) for shot type\nrecognition. SGNet separates the subject and background of a shot into two\nstreams, serving as separate guidance maps for scale and movement type\nclassification respectively. To facilitate shot type analysis and model\nevaluations, we build a large-scale dataset MovieShots, which contains 46K\nshots from 7K movie trailers with annotations of their scale and movement\ntypes. Experiments show that our framework is able to recognize these two\nattributes of shot accurately, outperforming all the previous methods.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 15:49:40 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Rao", "Anyi", ""], ["Wang", "Jiaze", ""], ["Xu", "Linning", ""], ["Jiang", "Xuekun", ""], ["Huang", "Qingqiu", ""], ["Zhou", "Bolei", ""], ["Lin", "Dahua", ""]]}, {"id": "2008.03549", "submitter": "Italos de Souza", "authors": "Italos Estilon de Souza and Alexandre Xavier Falc\\~ao", "title": "Learning CNN filters from user-drawn image markers for coconut-tree\n  image classification", "comments": null, "journal-ref": null, "doi": "10.1109/LGRS.2020.3020098", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying species of trees in aerial images is essential for land-use\nclassification, plantation monitoring, and impact assessment of natural\ndisasters. The manual identification of trees in aerial images is tedious,\ncostly, and error-prone, so automatic classification methods are necessary.\nConvolutional Neural Network (CNN) models have well succeeded in image\nclassification applications from different domains. However, CNN models usually\nrequire intensive manual annotation to create large training sets. One may\nconceptually divide a CNN into convolutional layers for feature extraction and\nfully connected layers for feature space reduction and classification. We\npresent a method that needs a minimal set of user-selected images to train the\nCNN's feature extractor, reducing the number of required images to train the\nfully connected layers. The method learns the filters of each convolutional\nlayer from user-drawn markers in image regions that discriminate classes,\nallowing better user control and understanding of the training process. It does\nnot rely on optimization based on backpropagation, and we demonstrate its\nadvantages on the binary classification of coconut-tree aerial images against\none of the most popular CNN models.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 15:50:23 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 23:02:43 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["de Souza", "Italos Estilon", ""], ["Falc\u00e3o", "Alexandre Xavier", ""]]}, {"id": "2008.03559", "submitter": "Sean Meyn", "authors": "Prashant G. Mehta and Sean P. Meyn", "title": "Convex Q-Learning, Part 1: Deterministic Optimal Control", "comments": "This pre-print is written in a tutorial style so it is accessible to\n  new-comers. It will be a part of a handout for upcoming short courses on RL.\n  A more compact version suitable for journal submission is in preparation", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that the extension of Watkins' algorithm to general function\napproximation settings is challenging: does the projected Bellman equation have\na solution? If so, is the solution useful in the sense of generating a good\npolicy? And, if the preceding questions are answered in the affirmative, is the\nalgorithm consistent? These questions are unanswered even in the special case\nof Q-function approximations that are linear in the parameter. The challenge\nseems paradoxical, given the long history of convex analytic approaches to\ndynamic programming. The paper begins with a brief survey of linear programming\napproaches to optimal control, leading to a particular over parameterization\nthat lends itself to applications in reinforcement learning. The main\nconclusions are summarized as follows:\n  (i) The new class of convex Q-learning algorithms is introduced based on the\nconvex relaxation of the Bellman equation. Convergence is established under\ngeneral conditions, including a linear function approximation for the\nQ-function.\n  (ii) A batch implementation appears similar to the famed DQN algorithm (one\nengine behind AlphaZero). It is shown that in fact the algorithms are very\ndifferent: while convex Q-learning solves a convex program that approximates\nthe Bellman equation, theory for DQN is no stronger than for Watkins' algorithm\nwith function approximation: (a) it is shown that both seek solutions to the\nsame fixed point equation, and (b) the ODE approximations for the two\nalgorithms coincide, and little is known about the stability of this ODE.\n  These results are obtained for deterministic nonlinear systems with total\ncost criterion. Many extensions are proposed, including kernel implementation,\nand extension to MDP models.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 17:17:42 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mehta", "Prashant G.", ""], ["Meyn", "Sean P.", ""]]}, {"id": "2008.03560", "submitter": "Cihan \\\"Ong\\\"un", "authors": "Cihan \\\"Ong\\\"un, Alptekin Temizel", "title": "LPMNet: Latent Part Modification and Generation for 3D Point Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on latent modification and generation of 3D point\ncloud object models with respect to their semantic parts. Different to the\nexisting methods which use separate networks for part generation and assembly,\nwe propose a single end-to-end Autoencoder model that can handle generation and\nmodification of both semantic parts, and global shapes. The proposed method\nsupports part exchange between 3D point cloud models and composition by\ndifferent parts to form new models by directly editing latent representations.\nThis holistic approach does not need part-based training to learn part\nrepresentations and does not introduce any extra loss besides the standard\nreconstruction loss. The experiments demonstrate the robustness of the proposed\nmethod with different object categories and varying number of points. The\nmethod can generate new models by integration of generative models such as GANs\nand VAEs and can work with unannotated point clouds by integration of a\nsegmentation module.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 17:24:37 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 12:41:37 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 15:44:08 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["\u00d6ng\u00fcn", "Cihan", ""], ["Temizel", "Alptekin", ""]]}, {"id": "2008.03582", "submitter": "Anand Ramakrishnan", "authors": "Anand Ramakrishnan, Warren B.Jackson and Kent Evans", "title": "Error Autocorrelation Objective Function for Improved System Modeling", "comments": "7 pages, 3 Figures, 8 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning models are trained to minimize the error between the model's\noutput and the actual values. The typical cost function, the Mean Squared Error\n(MSE), arises from maximizing the log-likelihood of additive independent,\nidentically distributed Gaussian noise. However, minimizing MSE fails to\nminimize the residuals' cross-correlations, leading to over-fitting and poor\nextrapolation of the model outside the training set (generalization). In this\npaper, we introduce a \"whitening\" cost function, the Ljung-Box statistic, which\nnot only minimizes the error but also minimizes the correlations between\nerrors, ensuring that the fits enforce compatibility with an independent and\nidentically distributed (i.i.d) gaussian noise model. The results show\nsignificant improvement in generalization for recurrent neural networks (RNNs)\n(1d) and image autoencoders (2d). Specifically, we look at both temporal\ncorrelations for system-id in simulated and actual mechanical systems. We also\nlook at spatial correlation in vision autoencoders to demonstrate that the\nwhitening objective functions lead to much better extrapolation--a property\nvery desirable for reliable control systems.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 19:20:32 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 15:34:38 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Ramakrishnan", "Anand", ""], ["Jackson", "Warren B.", ""], ["Evans", "Kent", ""]]}, {"id": "2008.03590", "submitter": "Alexey Sholokhov", "authors": "Alexey Sholokhov, Tomi Kinnunen, Ville Vestman, Kong Aik Lee", "title": "Extrapolating false alarm rates in automatic speaker verification", "comments": "Accepted for publication to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speaker verification (ASV) vendors and corpus providers would both\nbenefit from tools to reliably extrapolate performance metrics for large\nspeaker populations without collecting new speakers. We address false alarm\nrate extrapolation under a worst-case model whereby an adversary identifies the\nclosest impostor for a given target speaker from a large population. Our models\nare generative and allow sampling new speakers. The models are formulated in\nthe ASV detection score space to facilitate analysis of arbitrary ASV systems.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 20:31:57 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Sholokhov", "Alexey", ""], ["Kinnunen", "Tomi", ""], ["Vestman", "Ville", ""], ["Lee", "Kong Aik", ""]]}, {"id": "2008.03592", "submitter": "Sefik Emre Eskimez", "authors": "Sefik Emre Eskimez, You Zhang, Zhiyao Duan", "title": "Speech Driven Talking Face Generation from a Single Image and an Emotion\n  Condition", "comments": "Accepted to IEEE Transactions on Multimedia", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual emotion expression plays an important role in audiovisual speech\ncommunication. In this work, we propose a novel approach to rendering visual\nemotion expression in speech-driven talking face generation. Specifically, we\ndesign an end-to-end talking face generation system that takes a speech\nutterance, a single face image, and a categorical emotion label as input to\nrender a talking face video synchronized with the speech and expressing the\nconditioned emotion. Objective evaluation on image quality, audiovisual\nsynchronization, and visual emotion expression shows that the proposed system\noutperforms a state-of-the-art baseline system. Subjective evaluation of visual\nemotion expression and video realness also demonstrates the superiority of the\nproposed system. Furthermore, we conduct a human emotion recognition pilot\nstudy using generated videos with mismatched emotions among the audio and\nvisual modalities. Results show that humans respond to the visual modality more\nsignificantly than the audio modality on this task.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 20:46:31 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 22:45:01 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Eskimez", "Sefik Emre", ""], ["Zhang", "You", ""], ["Duan", "Zhiyao", ""]]}, {"id": "2008.03596", "submitter": "Manuel W\\\"uthrich", "authors": "Manuel W\\\"uthrich, Felix Widmaier, Felix Grimminger, Joel Akpo, Shruti\n  Joshi, Vaibhav Agrawal, Bilal Hammoud, Majid Khadiv, Miroslav Bogdanovic,\n  Vincent Berenz, Julian Viereck, Maximilien Naveau, Ludovic Righetti, Bernhard\n  Sch\\\"olkopf, Stefan Bauer", "title": "TriFinger: An Open-Source Robot for Learning Dexterity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dexterous object manipulation remains an open problem in robotics, despite\nthe rapid progress in machine learning during the past decade. We argue that a\nhindrance is the high cost of experimentation on real systems, in terms of both\ntime and money. We address this problem by proposing an open-source robotic\nplatform which can safely operate without human supervision. The hardware is\ninexpensive (about \\SI{5000}[\\$]{}) yet highly dynamic, robust, and capable of\ncomplex interaction with external objects. The software operates at 1-kilohertz\nand performs safety checks to prevent the hardware from breaking. The\neasy-to-use front-end (in C++ and Python) is suitable for real-time control as\nwell as deep reinforcement learning. In addition, the software framework is\nlargely robot-agnostic and can hence be used independently of the hardware\nproposed herein. Finally, we illustrate the potential of the proposed platform\nthrough a number of experiments, including real-time optimal control, deep\nreinforcement learning from scratch, throwing, and writing.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 20:54:30 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 20:00:13 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["W\u00fcthrich", "Manuel", ""], ["Widmaier", "Felix", ""], ["Grimminger", "Felix", ""], ["Akpo", "Joel", ""], ["Joshi", "Shruti", ""], ["Agrawal", "Vaibhav", ""], ["Hammoud", "Bilal", ""], ["Khadiv", "Majid", ""], ["Bogdanovic", "Miroslav", ""], ["Berenz", "Vincent", ""], ["Viereck", "Julian", ""], ["Naveau", "Maximilien", ""], ["Righetti", "Ludovic", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Bauer", "Stefan", ""]]}, {"id": "2008.03601", "submitter": "Yutaro Iiyama", "authors": "Yutaro Iiyama, Gianluca Cerminara, Abhijay Gupta, Jan Kieseler,\n  Vladimir Loncar, Maurizio Pierini, Shah Rukh Qasim, Marcel Rieger, Sioni\n  Summers, Gerrit Van Onsem, Kinga Wozniak, Jennifer Ngadiuba, Giuseppe Di\n  Guglielmo, Javier Duarte, Philip Harris, Dylan Rankin, Sergo Jindariani, Mia\n  Liu, Kevin Pedro, Nhan Tran, Edward Kreinar, Zhenbin Wu", "title": "Distance-Weighted Graph Neural Networks on FPGAs for Real-Time Particle\n  Reconstruction in High Energy Physics", "comments": "15 pages, 4 figures", "journal-ref": "Frontiers in Big Data 3 (2021) 44", "doi": "10.3389/fdata.2020.598927", "report-no": "FERMILAB-PUB-20-405-E-SCD", "categories": "physics.ins-det cs.LG hep-ex", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph neural networks have been shown to achieve excellent performance for\nseveral crucial tasks in particle physics, such as charged particle tracking,\njet tagging, and clustering. An important domain for the application of these\nnetworks is the FGPA-based first layer of real-time data filtering at the CERN\nLarge Hadron Collider, which has strict latency and resource constraints. We\ndiscuss how to design distance-weighted graph networks that can be executed\nwith a latency of less than 1$\\mu\\mathrm{s}$ on an FPGA. To do so, we consider\na representative task associated to particle reconstruction and identification\nin a next-generation calorimeter operating at a particle collider. We use a\ngraph network architecture developed for such purposes, and apply additional\nsimplifications to match the computing constraints of Level-1 trigger systems,\nincluding weight quantization. Using the $\\mathtt{hls4ml}$ library, we convert\nthe compressed models into firmware to be implemented on an FPGA. Performance\nof the synthesized models is presented both in terms of inference accuracy and\nresource usage.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 21:26:31 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 01:41:56 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Iiyama", "Yutaro", ""], ["Cerminara", "Gianluca", ""], ["Gupta", "Abhijay", ""], ["Kieseler", "Jan", ""], ["Loncar", "Vladimir", ""], ["Pierini", "Maurizio", ""], ["Qasim", "Shah Rukh", ""], ["Rieger", "Marcel", ""], ["Summers", "Sioni", ""], ["Van Onsem", "Gerrit", ""], ["Wozniak", "Kinga", ""], ["Ngadiuba", "Jennifer", ""], ["Di Guglielmo", "Giuseppe", ""], ["Duarte", "Javier", ""], ["Harris", "Philip", ""], ["Rankin", "Dylan", ""], ["Jindariani", "Sergo", ""], ["Liu", "Mia", ""], ["Pedro", "Kevin", ""], ["Tran", "Nhan", ""], ["Kreinar", "Edward", ""], ["Wu", "Zhenbin", ""]]}, {"id": "2008.03606", "submitter": "Sai Praneeth Karimireddy", "authors": "Sai Praneeth Karimireddy, Martin Jaggi, Satyen Kale, Mehryar Mohri,\n  Sashank J. Reddi, Sebastian U. Stich, Ananda Theertha Suresh", "title": "Mime: Mimicking Centralized Stochastic Algorithms in Federated Learning", "comments": "Version 2 provides stronger theoretical results and more thorough\n  experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a challenging setting for optimization due to the\nheterogeneity of the data across different clients which gives rise to the\nclient drift phenomenon. In fact, obtaining an algorithm for FL which is\nuniformly better than simple centralized training has been a major open problem\nthus far. In this work, we propose a general algorithmic framework, Mime, which\ni) mitigates client drift and ii) adapts arbitrary centralized optimization\nalgorithms such as momentum and Adam to the cross-device federated learning\nsetting. Mime uses a combination of control-variates and server-level\nstatistics (e.g. momentum) at every client-update step to ensure that each\nlocal update mimics that of the centralized method run on iid data. We prove a\nreduction result showing that Mime can translate the convergence of a generic\nalgorithm in the centralized setting into convergence in the federated setting.\nFurther, we show that when combined with momentum based variance reduction,\nMime is provably faster than any centralized method--the first such result. We\nalso perform a thorough experimental exploration of Mime's performance on real\nworld datasets.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 21:55:07 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 08:14:57 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Karimireddy", "Sai Praneeth", ""], ["Jaggi", "Martin", ""], ["Kale", "Satyen", ""], ["Mohri", "Mehryar", ""], ["Reddi", "Sashank J.", ""], ["Stich", "Sebastian U.", ""], ["Suresh", "Ananda Theertha", ""]]}, {"id": "2008.03609", "submitter": "Linhai Ma", "authors": "Linhai Ma, Liang Liang", "title": "Enhance CNN Robustness Against Noises for Classification of 12-Lead ECG\n  with Variable Length", "comments": "This paper is accepted by 19TH IEEE International Conference on\n  Machine Learning and Applications (ICMLA2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrocardiogram (ECG) is the most widely used diagnostic tool to monitor\nthe condition of the cardiovascular system. Deep neural networks (DNNs), have\nbeen developed in many research labs for automatic interpretation of ECG\nsignals to identify potential abnormalities in patient hearts. Studies have\nshown that given a sufficiently large amount of data, the classification\naccuracy of DNNs could reach human-expert cardiologist level. However, despite\nof the excellent performance in classification accuracy, it has been shown that\nDNNs are highly vulnerable to adversarial noises which are subtle changes in\ninput of a DNN and lead to a wrong class-label prediction with a high\nconfidence. Thus, it is challenging and essential to improve robustness of DNNs\nagainst adversarial noises for ECG signal classification, a life-critical\napplication. In this work, we designed a CNN for classification of 12-lead ECG\nsignals with variable length, and we applied three defense methods to improve\nrobustness of this CNN for this classification task. The ECG data in this study\nis very challenging because the sample size is limited, and the length of each\nECG recording varies in a large range. The evaluation results show that our\ncustomized CNN reached satisfying F1 score and average accuracy, comparable to\nthe top-6 entries in the CPSC2018 ECG classification challenge, and the defense\nmethods enhanced robustness of our CNN against adversarial noises and white\nnoises, with a minimal reduction in accuracy on clean data.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 22:21:24 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 21:04:46 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 20:04:38 GMT"}, {"version": "v4", "created": "Mon, 30 Nov 2020 20:09:42 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Ma", "Linhai", ""], ["Liang", "Liang", ""]]}, {"id": "2008.03615", "submitter": "Vijay Ravi", "authors": "Vijay Ravi, Ruchao Fan, Amber Afshan, Huanhua Lu and Abeer Alwan", "title": "Exploring the Use of an Unsupervised Autoregressive Model as a Shared\n  Encoder for Text-Dependent Speaker Verification", "comments": "Accepted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel way of addressing text-dependent automatic\nspeaker verification (TD-ASV) by using a shared-encoder with task-specific\ndecoders. An autoregressive predictive coding (APC) encoder is pre-trained in\nan unsupervised manner using both out-of-domain (LibriSpeech, VoxCeleb) and\nin-domain (DeepMine) unlabeled datasets to learn generic, high-level feature\nrepresentation that encapsulates speaker and phonetic content. Two\ntask-specific decoders were trained using labeled datasets to classify speakers\n(SID) and phrases (PID). Speaker embeddings extracted from the SID decoder were\nscored using a PLDA. SID and PID systems were fused at the score level. There\nis a 51.9% relative improvement in minDCF for our system compared to the fully\nsupervised x-vector baseline on the cross-lingual DeepMine dataset. However,\nthe i-vector/HMM method outperformed the proposed APC encoder-decoder system. A\nfusion of the x-vector/PLDA baseline and the SID/PLDA scores prior to PID\nfusion further improved performance by 15% indicating complementarity of the\nproposed approach to the x-vector system. We show that the proposed approach\ncan leverage from large, unlabeled, data-rich domains, and learn speech\npatterns independent of downstream tasks. Such a system can provide competitive\nperformance in domain-mismatched scenarios where test data is from data-scarce\ndomains.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 22:47:10 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Ravi", "Vijay", ""], ["Fan", "Ruchao", ""], ["Afshan", "Amber", ""], ["Lu", "Huanhua", ""], ["Alwan", "Abeer", ""]]}, {"id": "2008.03616", "submitter": "Amber Afshan", "authors": "Amber Afshan, Jinxi Guo, Soo Jin Park, Vijay Ravi, Alan McCree, and\n  Abeer Alwan", "title": "Variable frame rate-based data augmentation to handle speaking-style\n  variability for automatic speaker verification", "comments": "Accepted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effects of speaking-style variability on automatic speaker verification\nwere investigated using the UCLA Speaker Variability database which comprises\nmultiple speaking styles per speaker. An x-vector/PLDA (probabilistic linear\ndiscriminant analysis) system was trained with the SRE and Switchboard\ndatabases with standard augmentation techniques and evaluated with utterances\nfrom the UCLA database. The equal error rate (EER) was low when enrollment and\ntest utterances were of the same style (e.g., 0.98% and 0.57% for read and\nconversational speech, respectively), but it increased substantially when\nstyles were mismatched between enrollment and test utterances. For instance,\nwhen enrolled with conversation utterances, the EER increased to 3.03%, 2.96%\nand 22.12% when tested on read, narrative, and pet-directed speech,\nrespectively. To reduce the effect of style mismatch, we propose an\nentropy-based variable frame rate technique to artificially generate\nstyle-normalized representations for PLDA adaptation. The proposed system\nsignificantly improved performance. In the aforementioned conditions, the EERs\nimproved to 2.69% (conversation -- read), 2.27% (conversation -- narrative),\nand 18.75% (pet-directed -- read). Overall, the proposed technique performed\ncomparably to multi-style PLDA adaptation without the need for training data in\ndifferent speaking styles per speaker.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 22:47:12 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Afshan", "Amber", ""], ["Guo", "Jinxi", ""], ["Park", "Soo Jin", ""], ["Ravi", "Vijay", ""], ["McCree", "Alan", ""], ["Alwan", "Abeer", ""]]}, {"id": "2008.03617", "submitter": "Amber Afshan", "authors": "Amber Afshan, Jody Kreiman, and Abeer Alwan", "title": "Speaker discrimination in humans and machines: Effects of speaking style\n  variability", "comments": "Accepted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Does speaking style variation affect humans' ability to distinguish\nindividuals from their voices? How do humans compare with automatic systems\ndesigned to discriminate between voices? In this paper, we attempt to answer\nthese questions by comparing human and machine speaker discrimination\nperformance for read speech versus casual conversations. Thirty listeners were\nasked to perform a same versus different speaker task. Their performance was\ncompared to a state-of-the-art x-vector/PLDA-based automatic speaker\nverification system. Results showed that both humans and machines performed\nbetter with style-matched stimuli, and human performance was better when\nlisteners were native speakers of American English. Native listeners performed\nbetter than machines in the style-matched conditions (EERs of 6.96% versus\n14.35% for read speech, and 15.12% versus 19.87%, for conversations), but for\nstyle-mismatched conditions, there was no significant difference between native\nlisteners and machines. In all conditions, fusing human responses with machine\nresults showed improvements compared to each alone, suggesting that humans and\nmachines have different approaches to speaker discrimination tasks. Differences\nin the approaches were further confirmed by examining results for individual\nspeakers which showed that the perception of distinct and confused speakers\ndiffered between human listeners and machines.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 22:59:46 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Afshan", "Amber", ""], ["Kreiman", "Jody", ""], ["Alwan", "Abeer", ""]]}, {"id": "2008.03626", "submitter": "Loc Tran H", "authors": "Loc Hoang Tran, Linh Hoang Tran", "title": "Directed hypergraph neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To deal with irregular data structure, graph convolution neural networks have\nbeen developed by a lot of data scientists. However, data scientists just have\nconcentrated primarily on developing deep neural network method for un-directed\ngraph. In this paper, we will present the novel neural network method for\ndirected hypergraph. In the other words, we will develop not only the novel\ndirected hypergraph neural network method but also the novel directed\nhypergraph based semi-supervised learning method. These methods are employed to\nsolve the node classification task. The two datasets that are used in the\nexperiments are the cora and the citeseer datasets. Among the classic directed\ngraph based semi-supervised learning method, the novel directed hypergraph\nbased semi-supervised learning method, the novel directed hypergraph neural\nnetwork method that are utilized to solve this node classification task, we\nrecognize that the novel directed hypergraph neural network achieves the\nhighest accuracies.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 01:39:52 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Tran", "Loc Hoang", ""], ["Tran", "Linh Hoang", ""]]}, {"id": "2008.03637", "submitter": "Feng Xia", "authors": "Lei Wang, Jing Ren, Bo Xu, Jianxin Li, Wei Luo, Feng Xia", "title": "MODEL: Motif-based Deep Feature Learning for Link Prediction", "comments": "14 pages, 7 figures", "journal-ref": "IEEE Transactions on Computational Social Systems, 7(2): 503-516,\n  April 2020", "doi": "10.1109/TCSS.2019.2962819", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction plays an important role in network analysis and applications.\nRecently, approaches for link prediction have evolved from traditional\nsimilarity-based algorithms into embedding-based algorithms. However, most\nexisting approaches fail to exploit the fact that real-world networks are\ndifferent from random networks. In particular, real-world networks are known to\ncontain motifs, natural network building blocks reflecting the underlying\nnetwork-generating processes. In this paper, we propose a novel embedding\nalgorithm that incorporates network motifs to capture higher-order structures\nin the network. To evaluate its effectiveness for link prediction, experiments\nwere conducted on three types of networks: social networks, biological\nnetworks, and academic networks. The results demonstrate that our algorithm\noutperforms both the traditional similarity-based algorithms by 20% and the\nstate-of-the-art embedding-based algorithms by 19%.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 03:39:28 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Wang", "Lei", ""], ["Ren", "Jing", ""], ["Xu", "Bo", ""], ["Li", "Jianxin", ""], ["Luo", "Wei", ""], ["Xia", "Feng", ""]]}, {"id": "2008.03638", "submitter": "Feng Xia", "authors": "Hayat Dino Bedru, Shuo Yu, Xinru Xiao, Da Zhang, Liangtian Wan, He\n  Guo, Feng Xia", "title": "Big Networks: A Survey", "comments": "69 pages, 4 figures", "journal-ref": "Computer Science Review, Volume 37, August 2020, 100247", "doi": "10.1016/j.cosrev.2020.100247", "report-no": null, "categories": "cs.SI cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A network is a typical expressive form of representing complex systems in\nterms of vertices and links, in which the pattern of interactions amongst\ncomponents of the network is intricate. The network can be static that does not\nchange over time or dynamic that evolves through time. The complication of\nnetwork analysis is different under the new circumstance of network size\nexplosive increasing. In this paper, we introduce a new network science concept\ncalled big network. Big networks are generally in large-scale with a\ncomplicated and higher-order inner structure. This paper proposes a guideline\nframework that gives an insight into the major topics in the area of network\nscience from the viewpoint of a big network. We first introduce the structural\ncharacteristics of big networks from three levels, which are micro-level,\nmeso-level, and macro-level. We then discuss some state-of-the-art advanced\ntopics of big network analysis. Big network models and related approaches,\nincluding ranking methods, partition approaches, as well as network embedding\nalgorithms are systematically introduced. Some typical applications in big\nnetworks are then reviewed, such as community detection, link prediction,\nrecommendation, etc. Moreover, we also pinpoint some critical open issues that\nneed to be investigated further.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 03:40:20 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Bedru", "Hayat Dino", ""], ["Yu", "Shuo", ""], ["Xiao", "Xinru", ""], ["Zhang", "Da", ""], ["Wan", "Liangtian", ""], ["Guo", "He", ""], ["Xia", "Feng", ""]]}, {"id": "2008.03639", "submitter": "Feng Xia", "authors": "Feng Xia, Jiaying Liu, Hansong Nie, Yonghao Fu, Liangtian Wan,\n  Xiangjie Kong", "title": "Random Walks: A Review of Algorithms and Applications", "comments": "13 pages, 4 figures", "journal-ref": "IEEE Transactions on Emerging Topics in Computational\n  Intelligence, 4(2): 95-107, April 2020", "doi": "10.1109/TETCI.2019.2952908", "report-no": null, "categories": "cs.SI cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A random walk is known as a random process which describes a path including a\nsuccession of random steps in the mathematical space. It has increasingly been\npopular in various disciplines such as mathematics and computer science.\nFurthermore, in quantum mechanics, quantum walks can be regarded as quantum\nanalogues of classical random walks. Classical random walks and quantum walks\ncan be used to calculate the proximity between nodes and extract the topology\nin the network. Various random walk related models can be applied in different\nfields, which is of great significance to downstream tasks such as link\nprediction, recommendation, computer vision, semi-supervised learning, and\nnetwork embedding. In this paper, we aim to provide a comprehensive review of\nclassical random walks and quantum walks. We first review the knowledge of\nclassical random walks and quantum walks, including basic concepts and some\ntypical algorithms. We also compare the algorithms based on quantum walks and\nclassical random walks from the perspective of time complexity. Then we\nintroduce their applications in the field of computer science. Finally we\ndiscuss the open issues from the perspectives of efficiency, main-memory\nvolume, and computing time of existing algorithms. This study aims to\ncontribute to this growing area of research by exploring random walks and\nquantum walks together.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 03:41:56 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Xia", "Feng", ""], ["Liu", "Jiaying", ""], ["Nie", "Hansong", ""], ["Fu", "Yonghao", ""], ["Wan", "Liangtian", ""], ["Kong", "Xiangjie", ""]]}, {"id": "2008.03650", "submitter": "Khashayar Gatmiry", "authors": "Khashayar Gatmiry (1), Maryam Aliakbarpour (1), Stefanie Jegelka (1)\n  ((1) Massachusetts Institute of Technology)", "title": "Testing Determinantal Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determinantal point processes (DPPs) are popular probabilistic models of\ndiversity. In this paper, we investigate DPPs from a new perspective: property\ntesting of distributions. Given sample access to an unknown distribution $q$\nover the subsets of a ground set, we aim to distinguish whether $q$ is a DPP\ndistribution, or $\\epsilon$-far from all DPP distributions in\n$\\ell_1$-distance. In this work, we propose the first algorithm for testing\nDPPs. Furthermore, we establish a matching lower bound on the sample complexity\nof DPP testing. This lower bound also extends to showing a new hardness result\nfor the problem of testing the more general class of log-submodular\ndistributions.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 04:45:16 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Gatmiry", "Khashayar", "", "Massachusetts Institute of Technology"], ["Aliakbarpour", "Maryam", "", "Massachusetts Institute of Technology"], ["Jegelka", "Stefanie", "", "Massachusetts Institute of Technology"]]}, {"id": "2008.03654", "submitter": "Feng Xia", "authors": "Jin Xu, Shuo Yu, Ke Sun, Jing Ren, Ivan Lee, Shirui Pan, Feng Xia", "title": "Multivariate Relations Aggregation Learning in Social Networks", "comments": "11 pages, 6 figures", "journal-ref": "ACM/IEEE Joint Conference on Digital Libraries (JCDL 2020), Wuhan,\n  China, August 1 - 5, 2020", "doi": "10.1145/3383583.3398518", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate relations are general in various types of networks, such as\nbiological networks, social networks, transportation networks, and academic\nnetworks. Due to the principle of ternary closures and the trend of group\nformation, the multivariate relationships in social networks are complex and\nrich. Therefore, in graph learning tasks of social networks, the identification\nand utilization of multivariate relationship information are more important.\nExisting graph learning methods are based on the neighborhood information\ndiffusion mechanism, which often leads to partial omission or even lack of\nmultivariate relationship information, and ultimately affects the accuracy and\nexecution efficiency of the task. To address these challenges, this paper\nproposes the multivariate relationship aggregation learning (MORE) method,\nwhich can effectively capture the multivariate relationship information in the\nnetwork environment. By aggregating node attribute features and structural\nfeatures, MORE achieves higher accuracy and faster convergence speed. We\nconducted experiments on one citation network and five social networks. The\nexperimental results show that the MORE model has higher accuracy than the GCN\n(Graph Convolutional Network) model in node classification tasks, and can\nsignificantly reduce time cost.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 04:58:38 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Xu", "Jin", ""], ["Yu", "Shuo", ""], ["Sun", "Ke", ""], ["Ren", "Jing", ""], ["Lee", "Ivan", ""], ["Pan", "Shirui", ""], ["Xia", "Feng", ""]]}, {"id": "2008.03655", "submitter": "Tejas Bhojraj", "authors": "Lanston Hau Man Chu, Tejas Bhojraj, Rui Huang", "title": "Global Optimum Search in Quantum Deep Learning", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to solve machine learning optimization problem by using\nquantum circuit. Two approaches, namely the average approach and the Partial\nSwap Test Cut-off method (PSTC) was proposed to search for the global\nminimum/maximum of two different objective functions. The current cost is\n$O(\\sqrt{|\\Theta|} N)$, but there is potential to improve PSTC further to\n$O(\\sqrt{|\\Theta|} \\cdot sublinear \\ N)$ by enhancing the checking process.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 05:01:44 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Chu", "Lanston Hau Man", ""], ["Bhojraj", "Tejas", ""], ["Huang", "Rui", ""]]}, {"id": "2008.03658", "submitter": "Nitin Rathi", "authors": "Nitin Rathi, Kaushik Roy", "title": "DIET-SNN: Direct Input Encoding With Leakage and Threshold Optimization\n  in Deep Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bio-inspired spiking neural networks (SNNs), operating with asynchronous\nbinary signals (or spikes) distributed over time, can potentially lead to\ngreater computational efficiency on event-driven hardware. The state-of-the-art\nSNNs suffer from high inference latency, resulting from inefficient input\nencoding, and sub-optimal settings of the neuron parameters (firing threshold,\nand membrane leak). We propose DIET-SNN, a low-latency deep spiking network\nthat is trained with gradient descent to optimize the membrane leak and the\nfiring threshold along with other network parameters (weights). The membrane\nleak and threshold for each layer of the SNN are optimized with end-to-end\nbackpropagation to achieve competitive accuracy at reduced latency. The analog\npixel values of an image are directly applied to the input layer of DIET-SNN\nwithout the need to convert to spike-train. The first convolutional layer is\ntrained to convert inputs into spikes where leaky-integrate-and-fire (LIF)\nneurons integrate the weighted inputs and generate an output spike when the\nmembrane potential crosses the trained firing threshold. The trained membrane\nleak controls the flow of input information and attenuates irrelevant inputs to\nincrease the activation sparsity in the convolutional and dense layers of the\nnetwork. The reduced latency combined with high activation sparsity provides\nlarge improvements in computational efficiency. We evaluate DIET-SNN on image\nclassification tasks from CIFAR and ImageNet datasets on VGG and ResNet\narchitectures. We achieve top-1 accuracy of 69% with 5 timesteps (inference\nlatency) on the ImageNet dataset with 12x less compute energy than an\nequivalent standard ANN. Additionally, DIET-SNN performs 20-500x faster\ninference compared to other state-of-the-art SNN models.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 05:07:17 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 23:14:39 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 02:55:31 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Rathi", "Nitin", ""], ["Roy", "Kaushik", ""]]}, {"id": "2008.03662", "submitter": "Anjin Liu", "authors": "Anjin Liu, Jie Lu, Guangquan Zhang", "title": "Concept Drift Detection: Dealing with MissingValues via Fuzzy Distance\n  Estimations", "comments": "Accepted by IEEE Transactions on Fuzzy Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In data streams, the data distribution of arriving observations at different\ntime points may change - a phenomenon called concept drift. While detecting\nconcept drift is a relatively mature area of study, solutions to the\nuncertainty introduced by observations with missing values have only been\nstudied in isolation. No one has yet explored whether or how these solutions\nmight impact drift detection performance. We, however, believe that data\nimputation methods may actually increase uncertainty in the data rather than\nreducing it. We also conjecture that imputation can introduce bias into the\nprocess of estimating distribution changes during drift detection, which can\nmake it more difficult to train a learning model. Our idea is to focus on\nestimating the distance between observations rather than estimating the missing\nvalues, and to define membership functions that allocate observations to\nhistogram bins according to the estimation errors. Our solution comprises a\nnovel masked distance learning (MDL) algorithm to reduce the cumulative errors\ncaused by iteratively estimating each missing value in an observation and a\nfuzzy-weighted frequency (FWF) method for identifying discrepancies in the data\ndistribution. The concept drift detection algorithm proposed in this paper is a\nsingular and unified algorithm that can handle missing values, but not an\nimputation algorithm combined with a concept drift detection algorithm.\nExperiments on both synthetic and real-world data sets demonstrate the\nadvantages of this method and show its robustness in detecting drift in data\nwith missing values. These findings reveal that missing values exert a profound\nimpact on concept drift detection, but using fuzzy set theory to model\nobservations can produce more reliable results than imputation.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 05:25:46 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Liu", "Anjin", ""], ["Lu", "Jie", ""], ["Zhang", "Guangquan", ""]]}, {"id": "2008.03667", "submitter": "Shijie Zhu", "authors": "Shijie Zhu, Jianxin Li, Hao Peng, Senzhang Wang and Lifang He", "title": "Adversarial Directed Graph Embedding", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Node representation learning for directed graphs is critically important to\nfacilitate many graph mining tasks. To capture the directed edges between\nnodes, existing methods mostly learn two embedding vectors for each node,\nsource vector and target vector. However, these methods learn the source and\ntarget vectors separately. For the node with very low indegree or outdegree,\nthe corresponding target vector or source vector cannot be effectively learned.\nIn this paper, we propose a novel Directed Graph embedding framework based on\nGenerative Adversarial Network, called DGGAN. The main idea is to use\nadversarial mechanisms to deploy a discriminator and two generators that\njointly learn each node's source and target vectors. For a given node, the two\ngenerators are trained to generate its fake target and source neighbor nodes\nfrom the same underlying distribution, and the discriminator aims to\ndistinguish whether a neighbor node is real or fake. The two generators are\nformulated into a unified framework and could mutually reinforce each other to\nlearn more robust source and target vectors. Extensive experiments show that\nDGGAN consistently and significantly outperforms existing state-of-the-art\nmethods across multiple graph mining tasks on directed graphs.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 06:10:11 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 09:33:56 GMT"}, {"version": "v3", "created": "Mon, 24 May 2021 17:22:27 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Zhu", "Shijie", ""], ["Li", "Jianxin", ""], ["Peng", "Hao", ""], ["Wang", "Senzhang", ""], ["He", "Lifang", ""]]}, {"id": "2008.03677", "submitter": "Mohammad Hashemi", "authors": "Mohammad J. Hashemi, Eric Keller", "title": "Enhancing Robustness Against Adversarial Examples in Network Intrusion\n  Detection Systems", "comments": "Submitted to 6th IEEE Conference on Network Functions Virtualization\n  and Software Defined Networks (IEEE NFV-SDN 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increase of cyber attacks in both the numbers and varieties in recent\nyears demands to build a more sophisticated network intrusion detection system\n(NIDS). These NIDS perform better when they can monitor all the traffic\ntraversing through the network like when being deployed on a Software-Defined\nNetwork (SDN). Because of the inability to detect zero-day attacks,\nsignature-based NIDS which were traditionally used for detecting malicious\ntraffic are beginning to get replaced by anomaly-based NIDS built on neural\nnetworks. However, recently it has been shown that such NIDS have their own\ndrawback namely being vulnerable to the adversarial example attack. Moreover,\nthey were mostly evaluated on the old datasets which don't represent the\nvariety of attacks network systems might face these days. In this paper, we\npresent Reconstruction from Partial Observation (RePO) as a new mechanism to\nbuild an NIDS with the help of denoising autoencoders capable of detecting\ndifferent types of network attacks in a low false alert setting with an\nenhanced robustness against adversarial example attack. Our evaluation\nconducted on a dataset with a variety of network attacks shows denoising\nautoencoders can improve detection of malicious traffic by up to 29% in a\nnormal setting and by up to 45% in an adversarial setting compared to other\nrecently proposed anomaly detectors.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 07:04:06 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Hashemi", "Mohammad J.", ""], ["Keller", "Eric", ""]]}, {"id": "2008.03687", "submitter": "Jin Xu", "authors": "Jin Xu, Xu Tan, Yi Ren, Tao Qin, Jian Li, Sheng Zhao, Tie-Yan Liu", "title": "LRSpeech: Extremely Low-Resource Speech Synthesis and Recognition", "comments": null, "journal-ref": "KDD 2020", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech synthesis (text to speech, TTS) and recognition (automatic speech\nrecognition, ASR) are important speech tasks, and require a large amount of\ntext and speech pairs for model training. However, there are more than 6,000\nlanguages in the world and most languages are lack of speech training data,\nwhich poses significant challenges when building TTS and ASR systems for\nextremely low-resource languages. In this paper, we develop LRSpeech, a TTS and\nASR system under the extremely low-resource setting, which can support rare\nlanguages with low data cost. LRSpeech consists of three key techniques: 1)\npre-training on rich-resource languages and fine-tuning on low-resource\nlanguages; 2) dual transformation between TTS and ASR to iteratively boost the\naccuracy of each other; 3) knowledge distillation to customize the TTS model on\na high-quality target-speaker voice and improve the ASR model on multiple\nvoices. We conduct experiments on an experimental language (English) and a\ntruly low-resource language (Lithuanian) to verify the effectiveness of\nLRSpeech. Experimental results show that LRSpeech 1) achieves high quality for\nTTS in terms of both intelligibility (more than 98% intelligibility rate) and\nnaturalness (above 3.5 mean opinion score (MOS)) of the synthesized speech,\nwhich satisfy the requirements for industrial deployment, 2) achieves promising\nrecognition accuracy for ASR, and 3) last but not least, uses extremely\nlow-resource training data. We also conduct comprehensive analyses on LRSpeech\nwith different amounts of data resources, and provide valuable insights and\nguidances for industrial deployment. We are currently deploying LRSpeech into a\ncommercialized cloud speech service to support TTS on more rare languages.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 08:16:33 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Xu", "Jin", ""], ["Tan", "Xu", ""], ["Ren", "Yi", ""], ["Qin", "Tao", ""], ["Li", "Jian", ""], ["Zhao", "Sheng", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2008.03694", "submitter": "Jiang Yue Dr.", "authors": "Jiang Yue, Weisong Wen, Jing Han, and Li-Ta Hsu", "title": "LiDAR Data Enrichment Using Deep Learning Based on High-Resolution\n  Image: An Approach to Achieve High-Performance LiDAR SLAM Using Low-cost\n  LiDAR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LiDAR-based SLAM algorithms are extensively studied to providing robust and\naccurate positioning for autonomous driving vehicles (ADV) in the past decades.\nSatisfactory performance can be obtained using high-grade 3D LiDAR with 64\nchannels, which can provide dense point clouds. Unfortunately, the high price\nsignificantly prevents its extensive commercialization in ADV. The\ncost-effective 3D LiDAR with 16 channels is a promising replacement. However,\nonly limited and sparse point clouds can be provided by the 16 channels LiDAR,\nwhich cannot guarantee sufficient positioning accuracy for ADV in challenging\ndynamic environments. The high-resolution image from the low-cost camera can\nprovide ample information about the surroundings. However, the explicit depth\ninformation is not available from the image. Inspired by the complementariness\nof 3D LiDAR and camera, this paper proposes to make use of the high-resolution\nimages from a camera to enrich the raw 3D point clouds from the low-cost 16\nchannels LiDAR based on a state-of-the-art deep learning algorithm. An ERFNet\nis firstly employed to segment the image with the aid of the raw sparse 3D\npoint clouds. Meanwhile, the sparse convolutional neural network is employed to\npredict the dense point clouds based on raw sparse 3D point clouds. Then, the\npredicted dense point clouds are fused with the segmentation outputs from\nERFnet using a novel multi-layer convolutional neural network to refine the\npredicted 3D point clouds. Finally, the enriched point clouds are employed to\nperform LiDAR SLAM based on the state-of-the-art normal distribution transform\n(NDT). We tested our approach on the re-edited KITTI datasets: (1)the sparse 3D\npoint clouds are significantly enriched with a mean square error of 1.1m MSE.\n(2)the map generated from the LiDAR SLAM is denser which includes more details\nwithout significant accuracy loss.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 09:20:47 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Yue", "Jiang", ""], ["Wen", "Weisong", ""], ["Han", "Jing", ""], ["Hsu", "Li-Ta", ""]]}, {"id": "2008.03703", "submitter": "Vitaly Feldman", "authors": "Vitaly Feldman and Chiyuan Zhang", "title": "What Neural Networks Memorize and Why: Discovering the Long Tail via\n  Influence Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms are well-known to have a propensity for fitting the\ntraining data very well and often fit even outliers and mislabeled data points.\nSuch fitting requires memorization of training data labels, a phenomenon that\nhas attracted significant research interest but has not been given a compelling\nexplanation so far. A recent work of Feldman (2019) proposes a theoretical\nexplanation for this phenomenon based on a combination of two insights. First,\nnatural image and data distributions are (informally) known to be long-tailed,\nthat is have a significant fraction of rare and atypical examples. Second, in a\nsimple theoretical model such memorization is necessary for achieving\nclose-to-optimal generalization error when the data distribution is\nlong-tailed. However, no direct empirical evidence for this explanation or even\nan approach for obtaining such evidence were given.\n  In this work we design experiments to test the key ideas in this theory. The\nexperiments require estimation of the influence of each training example on the\naccuracy at each test example as well as memorization values of training\nexamples. Estimating these quantities directly is computationally prohibitive\nbut we show that closely-related subsampled influence and memorization values\ncan be estimated much more efficiently. Our experiments demonstrate the\nsignificant benefits of memorization for generalization on several standard\nbenchmarks. They also provide quantitative and visually compelling evidence for\nthe theory put forth in (Feldman, 2019).\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 10:12:28 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Feldman", "Vitaly", ""], ["Zhang", "Chiyuan", ""]]}, {"id": "2008.03707", "submitter": "Li Xia", "authors": "Li Xia", "title": "Risk-Sensitive Markov Decision Processes with Combined Metrics of Mean\n  and Variance", "comments": "43 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the optimization problem of an infinite stage\ndiscrete time Markov decision process (MDP) with a long-run average metric\nconsidering both mean and variance of rewards together. Such performance metric\nis important since the mean indicates average returns and the variance\nindicates risk or fairness. However, the variance metric couples the rewards at\nall stages, the traditional dynamic programming is inapplicable as the\nprinciple of time consistency fails. We study this problem from a new\nperspective called the sensitivity-based optimization theory. A performance\ndifference formula is derived and it can quantify the difference of the\nmean-variance combined metrics of MDPs under any two different policies. The\ndifference formula can be utilized to generate new policies with strictly\nimproved mean-variance performance. A necessary condition of the optimal policy\nand the optimality of deterministic policies are derived. We further develop an\niterative algorithm with a form of policy iteration, which is proved to\nconverge to local optima both in the mixed and randomized policy space.\nSpecially, when the mean reward is constant in policies, the algorithm is\nguaranteed to converge to the global optimum. Finally, we apply our approach to\nstudy the fluctuation reduction of wind power in an energy storage system,\nwhich demonstrates the potential applicability of our optimization method.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 10:35:35 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Xia", "Li", ""]]}, {"id": "2008.03709", "submitter": "Xiaosen Wang", "authors": "Xiaosen Wang, Yichen Yang, Yihe Deng, Kun He", "title": "Adversarial Training with Fast Gradient Projection Method against\n  Synonym Substitution based Text Attacks", "comments": "Accepted by AAAI 2021, code is available at\n  https://github.com/JHL-HUST/FGPM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is the most empirically successful approach in improving\nthe robustness of deep neural networks for image classification.For text\nclassification, however, existing synonym substitution based adversarial\nattacks are effective but not efficient to be incorporated into practical text\nadversarial training. Gradient-based attacks, which are very efficient for\nimages, are hard to be implemented for synonym substitution based text attacks\ndue to the lexical, grammatical and semantic constraints and the discrete text\ninput space. Thereby, we propose a fast text adversarial attack method called\nFast Gradient Projection Method (FGPM) based on synonym substitution, which is\nabout 20 times faster than existing text attack methods and could achieve\nsimilar attack performance. We then incorporate FGPM with adversarial training\nand propose a text defense method called Adversarial Training with FGPM\nenhanced by Logit pairing (ATFL). Experiments show that ATFL could\nsignificantly improve the model robustness and block the transferability of\nadversarial examples.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 11:02:06 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 14:59:24 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 06:51:01 GMT"}, {"version": "v4", "created": "Wed, 16 Dec 2020 03:01:25 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Wang", "Xiaosen", ""], ["Yang", "Yichen", ""], ["Deng", "Yihe", ""], ["He", "Kun", ""]]}, {"id": "2008.03710", "submitter": "Yeunju Choi", "authors": "Yeunju Choi, Youngmoon Jung, Hoirin Kim", "title": "Deep MOS Predictor for Synthetic Speech Using Cluster-Based Modeling", "comments": "5 pages, 1 figure, accepted to Interspeech 2020", "journal-ref": "Proc. Interspeech 2020, pp. 1743-1747", "doi": "10.21437/Interspeech.2020-2111", "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has made impressive progress in speech synthesis and\nvoice conversion, the assessment of the synthesized speech is still carried out\nby human participants. Several recent papers have proposed deep-learning-based\nassessment models and shown the potential to automate the speech quality\nassessment. To improve the previously proposed assessment model, MOSNet, we\npropose three models using cluster-based modeling methods: using a global\nquality token (GQT) layer, using an Encoding Layer, and using both of them. We\nperform experiments using the evaluation results of the Voice Conversion\nChallenge 2018 to predict the mean opinion score of synthesized speech and\nsimilarity score between synthesized speech and reference speech. The results\nshow that the GQT layer helps to predict human assessment better by\nautomatically learning the useful quality tokens for the task and that the\nEncoding Layer helps to utilize frame-level scores more precisely.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 11:14:19 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Choi", "Yeunju", ""], ["Jung", "Youngmoon", ""], ["Kim", "Hoirin", ""]]}, {"id": "2008.03712", "submitter": "Liangyu Zhang", "authors": "Jiadong Liang, Liangyu Zhang, Cheng Zhang and Zhihua Zhang", "title": "Intervention Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel approach for stabilizing the training\nprocess of Generative Adversarial Networks as well as alleviating the mode\ncollapse problem. The main idea is to introduce a regularization term that we\ncall intervention loss into the objective. We refer to the resulting generative\nmodel as Intervention Generative Adversarial Networks (IVGAN). By perturbing\nthe latent representations of real images obtained from an auxiliary encoder\nnetwork with Gaussian invariant interventions and penalizing the dissimilarity\nof the distributions of the resulting generated images, the intervention loss\nprovides more informative gradient for the generator, significantly improving\nGAN's training stability. We demonstrate the effectiveness and efficiency of\nour methods via solid theoretical analysis and thorough evaluation on standard\nreal-world datasets as well as the stacked MNIST dataset.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 11:51:54 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Liang", "Jiadong", ""], ["Zhang", "Liangyu", ""], ["Zhang", "Cheng", ""], ["Zhang", "Zhihua", ""]]}, {"id": "2008.03720", "submitter": "Jongpil Lee", "authors": "Jongpil Lee, Nicholas J. Bryan, Justin Salamon, Zeyu Jin, Juhan Nam", "title": "Disentangled Multidimensional Metric Learning for Music Similarity", "comments": "Accepted for publication at the 45th International Conference on\n  Acoustics, Speech, and Signal Processing (ICASSP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music similarity search is useful for a variety of creative tasks such as\nreplacing one music recording with another recording with a similar \"feel\", a\ncommon task in video editing. For this task, it is typically necessary to\ndefine a similarity metric to compare one recording to another. Music\nsimilarity, however, is hard to define and depends on multiple simultaneous\nnotions of similarity (i.e. genre, mood, instrument, tempo). While prior work\nignore this issue, we embrace this idea and introduce the concept of\nmultidimensional similarity and unify both global and specialized similarity\nmetrics into a single, semantically disentangled multidimensional similarity\nmetric. To do so, we adapt a variant of deep metric learning called conditional\nsimilarity networks to the audio domain and extend it using track-based\ninformation to control the specificity of our model. We evaluate our method and\nshow that our single, multidimensional model outperforms both specialized\nsimilarity spaces and alternative baselines. We also run a user-study and show\nthat our approach is favored by human annotators as well.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 13:04:25 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 21:54:00 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Lee", "Jongpil", ""], ["Bryan", "Nicholas J.", ""], ["Salamon", "Justin", ""], ["Jin", "Zeyu", ""], ["Nam", "Juhan", ""]]}, {"id": "2008.03729", "submitter": "Jongpil Lee", "authors": "Jongpil Lee, Nicholas J. Bryan, Justin Salamon, Zeyu Jin, Juhan Nam", "title": "Metric Learning vs Classification for Disentangled Music Representation\n  Learning", "comments": "Accepted for publication at the 21st International Society for Music\n  Information Retrieval Conference (ISMIR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep representation learning offers a powerful paradigm for mapping input\ndata onto an organized embedding space and is useful for many music information\nretrieval tasks. Two central methods for representation learning include deep\nmetric learning and classification, both having the same goal of learning a\nrepresentation that can generalize well across tasks. Along with\ngeneralization, the emerging concept of disentangled representations is also of\ngreat interest, where multiple semantic concepts (e.g., genre, mood,\ninstrumentation) are learned jointly but remain separable in the learned\nrepresentation space. In this paper we present a single representation learning\nframework that elucidates the relationship between metric learning,\nclassification, and disentanglement in a holistic manner. For this, we (1)\noutline past work on the relationship between metric learning and\nclassification, (2) extend this relationship to multi-label data by exploring\nthree different learning approaches and their disentangled versions, and (3)\nevaluate all models on four tasks (training time, similarity retrieval,\nauto-tagging, and triplet prediction). We find that classification-based models\nare generally advantageous for training time, similarity retrieval, and\nauto-tagging, while deep metric learning exhibits better performance for\ntriplet-prediction. Finally, we show that our proposed approach yields\nstate-of-the-art results for music auto-tagging.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 13:53:12 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 21:46:52 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Lee", "Jongpil", ""], ["Bryan", "Nicholas J.", ""], ["Salamon", "Justin", ""], ["Jin", "Zeyu", ""], ["Nam", "Juhan", ""]]}, {"id": "2008.03776", "submitter": "Zhi Huang", "authors": "Zhi Huang, Paul Salama, Wei Shao, Jie Zhang, Kun Huang", "title": "Low-Rank Reorganization via Proportional Hazards Non-negative Matrix\n  Factorization Unveils Survival Associated Gene Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the central goals in precision health is the understanding and\ninterpretation of high-dimensional biological data to identify genes and\nmarkers associated with disease initiation, development, and outcomes. Though\nsignificant effort has been committed to harness gene expression data for\nmultiple analyses while accounting for time-to-event modeling by including\nsurvival times, many traditional analyses have focused separately on\nnon-negative matrix factorization (NMF) of the gene expression data matrix and\nsurvival regression with Cox proportional hazards model. In this work, Cox\nproportional hazards regression is integrated with NMF by imposing survival\nconstraints. This is accomplished by jointly optimizing the Frobenius norm and\npartial log likelihood for events such as death or relapse. Simulation results\non synthetic data demonstrated the superiority of the proposed method, when\ncompared to other algorithms, in finding survival associated gene clusters. In\naddition, using human cancer gene expression data, the proposed technique can\nunravel critical clusters of cancer genes. The discovered gene clusters reflect\nrich biological implications and can help identify survival-related biomarkers.\nTowards the goal of precision health and cancer treatments, the proposed\nalgorithm can help understand and interpret high-dimensional heterogeneous\ngenomics data with accurate identification of survival-associated gene\nclusters.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 17:59:30 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 07:52:45 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Huang", "Zhi", ""], ["Salama", "Paul", ""], ["Shao", "Wei", ""], ["Zhang", "Jie", ""], ["Huang", "Kun", ""]]}, {"id": "2008.03787", "submitter": "Ahmed Qureshi", "authors": "Ahmed H. Qureshi, Jiangeng Dong, Austin Choe, and Michael C. Yip", "title": "Neural Manipulation Planning on Constraint Manifolds", "comments": "This is the preprint version of the paper published at IEEE Robotics\n  and Automation Letters 2020", "journal-ref": "in IEEE Robotics and Automation Letters, vol. 5, no. 4, pp.\n  6089-6096, Oct. 2020", "doi": "10.1109/LRA.2020.3010220", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of task constraints imposes a significant challenge to motion\nplanning. Despite all recent advancements, existing algorithms are still\ncomputationally expensive for most planning problems. In this paper, we present\nConstrained Motion Planning Networks (CoMPNet), the first neural planner for\nmultimodal kinematic constraints. Our approach comprises the following\ncomponents: i) constraint and environment perception encoders; ii) neural robot\nconfiguration generator that outputs configurations on/near the constraint\nmanifold(s), and iii) a bidirectional planning algorithm that takes the\ngenerated configurations to create a feasible robot motion trajectory. We show\nthat CoMPNet solves practical motion planning tasks involving both\nunconstrained and constrained problems. Furthermore, it generalizes to new\nunseen locations of the objects, i.e., not seen during training, in the given\nenvironments with high success rates. When compared to the state-of-the-art\nconstrained motion planning algorithms, CoMPNet outperforms by order of\nmagnitude improvement in computational speed with a significantly lower\nvariance.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 18:58:10 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Qureshi", "Ahmed H.", ""], ["Dong", "Jiangeng", ""], ["Choe", "Austin", ""], ["Yip", "Michael C.", ""]]}, {"id": "2008.03790", "submitter": "Christin Jose", "authors": "Christin Jose, Yuriy Mishchenko, Thibaud Senechal, Anish Shah, Alex\n  Escott, Shiv Vitaladevuni", "title": "Accurate Detection of Wake Word Start and End Using a CNN", "comments": "Proceedings of INTERSPEECH", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small footprint embedded devices require keyword spotters (KWS) with small\nmodel size and detection latency for enabling voice assistants. Such a keyword\nis often referred to as \\textit{wake word} as it is used to wake up voice\nassistant enabled devices. Together with wake word detection, accurate\nestimation of wake word endpoints (start and end) is an important task of KWS.\nIn this paper, we propose two new methods for detecting the endpoints of wake\nwords in neural KWS that use single-stage word-level neural networks. Our\nresults show that the new techniques give superior accuracy for detecting wake\nwords' endpoints of up to 50 msec standard error versus human annotations, on\npar with the conventional Acoustic Model plus HMM forced alignment. To our\nknowledge, this is the first study of wake word endpoints detection methods for\nsingle-stage neural KWS.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 19:02:41 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Jose", "Christin", ""], ["Mishchenko", "Yuriy", ""], ["Senechal", "Thibaud", ""], ["Shah", "Anish", ""], ["Escott", "Alex", ""], ["Vitaladevuni", "Shiv", ""]]}, {"id": "2008.03800", "submitter": "Rui Qian", "authors": "Rui Qian, Tianjian Meng, Boqing Gong, Ming-Hsuan Yang, Huisheng Wang,\n  Serge Belongie, Yin Cui", "title": "Spatiotemporal Contrastive Video Representation Learning", "comments": "CVPR2021 Camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a self-supervised Contrastive Video Representation Learning (CVRL)\nmethod to learn spatiotemporal visual representations from unlabeled videos.\nOur representations are learned using a contrastive loss, where two augmented\nclips from the same short video are pulled together in the embedding space,\nwhile clips from different videos are pushed away. We study what makes for good\ndata augmentations for video self-supervised learning and find that both\nspatial and temporal information are crucial. We carefully design data\naugmentations involving spatial and temporal cues. Concretely, we propose a\ntemporally consistent spatial augmentation method to impose strong spatial\naugmentations on each frame of the video while maintaining the temporal\nconsistency across frames. We also propose a sampling-based temporal\naugmentation method to avoid overly enforcing invariance on clips that are\ndistant in time. On Kinetics-600, a linear classifier trained on the\nrepresentations learned by CVRL achieves 70.4% top-1 accuracy with a\n3D-ResNet-50 (R3D-50) backbone, outperforming ImageNet supervised pre-training\nby 15.7% and SimCLR unsupervised pre-training by 18.8% using the same inflated\nR3D-50. The performance of CVRL can be further improved to 72.9% with a larger\nR3D-152 (2x filters) backbone, significantly closing the gap between\nunsupervised and supervised video representation learning. Our code and models\nwill be available at\nhttps://github.com/tensorflow/models/tree/master/official/.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 19:58:45 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 23:27:25 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 18:07:27 GMT"}, {"version": "v4", "created": "Mon, 5 Apr 2021 19:51:20 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Qian", "Rui", ""], ["Meng", "Tianjian", ""], ["Gong", "Boqing", ""], ["Yang", "Ming-Hsuan", ""], ["Wang", "Huisheng", ""], ["Belongie", "Serge", ""], ["Cui", "Yin", ""]]}, {"id": "2008.03802", "submitter": "Jan Vainer", "authors": "Jan Vainer, Ond\\v{r}ej Du\\v{s}ek", "title": "SpeedySpeech: Efficient Neural Speech Synthesis", "comments": "5 pages, 3 figures, Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recent neural sequence-to-sequence models have greatly improved the\nquality of speech synthesis, there has not been a system capable of fast\ntraining, fast inference and high-quality audio synthesis at the same time. We\npropose a student-teacher network capable of high-quality faster-than-real-time\nspectrogram synthesis, with low requirements on computational resources and\nfast training time. We show that self-attention layers are not necessary for\ngeneration of high quality audio. We utilize simple convolutional blocks with\nresidual connections in both student and teacher networks and use only a single\nattention layer in the teacher model. Coupled with a MelGAN vocoder, our\nmodel's voice quality was rated significantly higher than Tacotron 2. Our model\ncan be efficiently trained on a single GPU and can run in real time even on a\nCPU. We provide both our source code and audio samples in our GitHub\nrepository.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 20:00:57 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Vainer", "Jan", ""], ["Du\u0161ek", "Ond\u0159ej", ""]]}, {"id": "2008.03813", "submitter": "Xudong Wang", "authors": "Xudong Wang, Ziwei Liu, Stella X. Yu", "title": "Unsupervised Feature Learning by Cross-Level Instance-Group\n  Discrimination", "comments": "Accepted at CVPR 2021; Project page:\n  http://people.eecs.berkeley.edu/~xdwang/projects/CLD/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised feature learning has made great strides with contrastive\nlearning based on instance discrimination and invariant mapping, as benchmarked\non curated class-balanced datasets. However, natural data could be highly\ncorrelated and long-tail distributed. Natural between-instance similarity\nconflicts with the presumed instance distinction, causing unstable training and\npoor performance.\n  Our idea is to discover and integrate between-instance similarity into\ncontrastive learning, not directly by instance grouping, but by cross-level\ndiscrimination (CLD) between instances and local instance groups. While\ninvariant mapping of each instance is imposed by attraction within its\naugmented views, between-instance similarity could emerge from common repulsion\nagainst instance groups.\n  Our batch-wise and cross-view comparisons also greatly improve the\npositive/negative sample ratio of contrastive learning and achieve better\ninvariant mapping. To effect both grouping and discrimination objectives, we\nimpose them on features separately derived from a shared representation. In\naddition, we propose normalized projection heads and unsupervised\nhyper-parameter tuning for the first time.\n  Our extensive experimentation demonstrates that CLD is a lean and powerful\nadd-on to existing methods such as NPID, MoCo, InfoMin, and BYOL on highly\ncorrelated, long-tail, or balanced datasets. It not only achieves new\nstate-of-the-art on self-supervision, semi-supervision, and transfer learning\nbenchmarks, but also beats MoCo v2 and SimCLR on every reported performance\nattained with a much larger compute. CLD effectively brings unsupervised\nlearning closer to natural data and real-world applications. Our code is\npublicly available at: https://github.com/frank-xwang/CLD-UnsupervisedLearning.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 21:13:13 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 00:00:23 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 08:16:51 GMT"}, {"version": "v4", "created": "Thu, 3 Dec 2020 06:43:35 GMT"}, {"version": "v5", "created": "Sun, 16 May 2021 03:11:23 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Wang", "Xudong", ""], ["Liu", "Ziwei", ""], ["Yu", "Stella X.", ""]]}, {"id": "2008.03820", "submitter": "Pengsheng Ji", "authors": "Zhe Wang, Yingbin Liang and Pengsheng Ji", "title": "Spectral Algorithms for Community Detection in Directed Networks", "comments": "Journal of Machine Learning Research 2020, to appear", "journal-ref": "Journal of Machine Learning Research 2020. (153):1-45,", "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection in large social networks is affected by degree\nheterogeneity of nodes. The D-SCORE algorithm for directed networks was\nintroduced to reduce this effect by taking the element-wise ratios of the\nsingular vectors of the adjacency matrix before clustering. Meaningful results\nwere obtained for the statistician citation network, but rigorous analysis on\nits performance was missing. First, this paper establishes theoretical\nguarantee for this algorithm and its variants for the directed degree-corrected\nblock model (Directed-DCBM). Second, this paper provides significant\nimprovements for the original D-SCORE algorithms by attaching the nodes outside\nof the community cores using the information of the original network instead of\nthe singular vectors.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 21:43:32 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wang", "Zhe", ""], ["Liang", "Yingbin", ""], ["Ji", "Pengsheng", ""]]}, {"id": "2008.03825", "submitter": "Manie Tadayon", "authors": "Manie Tadayon, Greg Pottie", "title": "Comparative Analysis of the Hidden Markov Model and LSTM: A Simulative\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series and sequential data have gained significant attention recently\nsince many real-world processes in various domains such as finance, education,\nbiology, and engineering can be modeled as time series. Although many\nalgorithms and methods such as the Kalman filter, hidden Markov model, and long\nshort term memory (LSTM) are proposed to make inferences and predictions for\nthe data, their usage significantly depends on the application, type of the\nproblem, available data, and sufficient accuracy or loss. In this paper, we\ncompare the supervised and unsupervised hidden Markov model to LSTM in terms of\nthe amount of data needed for training, complexity, and forecasting accuracy.\nMoreover, we propose various techniques to discretize the observations and\nconvert the problem to a discrete hidden Markov model under stationary and\nnon-stationary situations. Our results indicate that even an unsupervised\nhidden Markov model can outperform LSTM when a massive amount of labeled data\nis not available. Furthermore, we show that the hidden Markov model can still\nbe an effective method to process the sequence data even when the first-order\nMarkov assumption is not satisfied.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 22:13:10 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Tadayon", "Manie", ""], ["Pottie", "Greg", ""]]}, {"id": "2008.03843", "submitter": "Ahmed Ramzy", "authors": "Ahmed Ramzy and Ahmed Elazab", "title": "Question Identification in Arabic Language Using Emotional Based\n  Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growth of content on social media networks, enterprises and services\nproviders have become interested in identifying the questions of their\ncustomers. Tracking these questions become very challenging with the growth of\ntext that grows directly proportional to the increase of Arabic users thus\nmaking it very difficult to be tracked manually. By automatic identifying the\nquestions seeking answers on the social media networks and defining their\ncategory, we can automatically answer them by finding an existing answer or\neven routing them to those responsible for answering those questions in the\ncustomer service. This will result in saving the time and the effort and\nenhancing the customer feedback and improving the business. In this paper, we\nhave implemented a binary classifier to classify Arabic text to either question\nseeking answer or not. We have added emotional based features to the state of\nthe art features. Experimental evaluation has done and showed that these\nemotional features have improved the accuracy of the classifier.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 00:18:32 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Ramzy", "Ahmed", ""], ["Elazab", "Ahmed", ""]]}, {"id": "2008.03864", "submitter": "Jing Zhang", "authors": "Jing Zhang and Yang Cao and Zheng-Jun Zha and Dacheng Tao", "title": "Nighttime Dehazing with a Synthetic Benchmark", "comments": "ACM MM 2020. Both the dataset and source code will be available at\n  \\url{https://github.com/chaimi2013/3R}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing the visibility of nighttime hazy images is challenging because of\nuneven illumination from active artificial light sources and haze\nabsorbing/scattering. The absence of large-scale benchmark datasets hampers\nprogress in this area. To address this issue, we propose a novel synthetic\nmethod called 3R to simulate nighttime hazy images from daytime clear images,\nwhich first reconstructs the scene geometry, then simulates the light rays and\nobject reflectance, and finally renders the haze effects. Based on it, we\ngenerate realistic nighttime hazy images by sampling real-world light colors\nfrom a prior empirical distribution. Experiments on the synthetic benchmark\nshow that the degrading factors jointly reduce the image quality. To address\nthis issue, we propose an optimal-scale maximum reflectance prior to\ndisentangle the color correction from haze removal and address them\nsequentially. Besides, we also devise a simple but effective learning-based\nbaseline which has an encoder-decoder structure based on the MobileNet-v2\nbackbone. Experiment results demonstrate their superiority over\nstate-of-the-art methods in terms of both image quality and runtime. Both the\ndataset and source code will be available at https://github.com/chaimi2013/3R.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 02:16:46 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 05:45:11 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 00:41:38 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Zhang", "Jing", ""], ["Cao", "Yang", ""], ["Zha", "Zheng-Jun", ""], ["Tao", "Dacheng", ""]]}, {"id": "2008.03869", "submitter": "Hossein Estiri", "authors": "Hossein Estiri, Zachary H. Strasser, Shawn N. Murphy", "title": "Individualized Prediction of COVID-19 Adverse outcomes with MLHO", "comments": null, "journal-ref": null, "doi": "10.1038/s41598-021-84781-x", "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed MLHO (pronounced as melo), an end-to-end Machine Learning\nframework that leverages iterative feature and algorithm selection to predict\nHealth Outcomes. MLHO implements iterative sequential representation mining,\nand feature and model selection, for predicting the patient-level risk of\nhospitalization, ICU admission, need for mechanical ventilation, and death. It\nbases this prediction on data from patients' past medical records (before their\nCOVID-19 infection). MLHO's architecture enables a parallel and\noutcome-oriented model calibration, in which different statistical learning\nalgorithms and vectors of features are simultaneously tested to improve the\nprediction of health outcomes. Using clinical and demographic data from a large\ncohort of over 13,000 COVID-19-positive patients, we modeled the four adverse\noutcomes utilizing about 600 features representing patients' pre-COVID health\nrecords and demographics. The mean AUC ROC for mortality prediction was 0.91,\nwhile the prediction performance ranged between 0.80 and 0.81 for the ICU,\nhospitalization, and ventilation. We broadly describe the clusters of features\nthat were utilized in modeling and their relative influence for predicting each\noutcome. Our results demonstrated that while demographic variables (namely age)\nare important predictors of adverse outcomes after a COVID-19 infection, the\nincorporation of the past clinical records are vital for a reliable prediction\nmodel. As the COVID-19 pandemic unfolds around the world, adaptable and\ninterpretable machine learning frameworks (like MLHO) are crucial to improve\nour readiness for confronting the potential future waves of COVID-19, as well\nas other novel infectious diseases that may emerge.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 02:44:52 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 14:55:52 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Estiri", "Hossein", ""], ["Strasser", "Zachary H.", ""], ["Murphy", "Shawn N.", ""]]}, {"id": "2008.03875", "submitter": "Juncheng Liu Dr", "authors": "Juncheng Liu, Steven Mills, Brendan McCane", "title": "RocNet: Recursive Octree Network for Efficient 3D Deep Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a deep recursive octree network for the compression of 3D voxel\ndata. Our network compresses a voxel grid of any size down to a very small\nlatent space in an autoencoder-like network. We show results for compressing\n32, 64 and 128 grids down to just 80 floats in the latent space. We demonstrate\nthe effectiveness and efficiency of our proposed method on several publicly\navailable datasets with three experiments: 3D shape classification, 3D shape\nreconstruction, and shape generation. Experimental results show that our\nalgorithm maintains accuracy while consuming less memory with shorter training\ntimes compared to existing methods, especially in 3D reconstruction tasks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 03:02:10 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Liu", "Juncheng", ""], ["Mills", "Steven", ""], ["McCane", "Brendan", ""]]}, {"id": "2008.03880", "submitter": "Boris Ivanovic", "authors": "Boris Ivanovic, Karen Leung, Edward Schmerling, Marco Pavone", "title": "Multimodal Deep Generative Models for Trajectory Prediction: A\n  Conditional Variational Autoencoder Approach", "comments": "8 pages, 3 figures, 2 tables. IEEE Robotics and Automation Letters\n  (RA-L), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human behavior prediction models enable robots to anticipate how humans may\nreact to their actions, and hence are instrumental to devising safe and\nproactive robot planning algorithms. However, modeling complex interaction\ndynamics and capturing the possibility of many possible outcomes in such\ninteractive settings is very challenging, which has recently prompted the study\nof several different approaches. In this work, we provide a self-contained\ntutorial on a conditional variational autoencoder (CVAE) approach to human\nbehavior prediction which, at its core, can produce a multimodal probability\ndistribution over future human trajectories conditioned on past interactions\nand candidate robot future actions. Specifically, the goals of this tutorial\npaper are to review and build a taxonomy of state-of-the-art methods in human\nbehavior prediction, from physics-based to purely data-driven methods, provide\na rigorous yet easily accessible description of a data-driven, CVAE-based\napproach, highlight important design characteristics that make this an\nattractive model to use in the context of model-based planning for human-robot\ninteractions, and provide important design considerations when using this class\nof models.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 03:18:27 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 00:13:47 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Ivanovic", "Boris", ""], ["Leung", "Karen", ""], ["Schmerling", "Edward", ""], ["Pavone", "Marco", ""]]}, {"id": "2008.03897", "submitter": "Po-Heng Chen", "authors": "Po-Heng Chen, Zhao-Xu Luo, Zu-Kuan Huang, Chun Yang, Kuan-Wen Chen", "title": "IF-Net: An Illumination-invariant Feature Network", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature descriptor matching is a critical step is many computer vision\napplications such as image stitching, image retrieval and visual localization.\nHowever, it is often affected by many practical factors which will degrade its\nperformance. Among these factors, illumination variations are the most\ninfluential one, and especially no previous descriptor learning works focus on\ndealing with this problem. In this paper, we propose IF-Net, aimed to generate\na robust and generic descriptor under crucial illumination changes conditions.\nWe find out not only the kind of training data important but also the order it\nis presented. To this end, we investigate several dataset scheduling methods\nand propose a separation training scheme to improve the matching accuracy.\nFurther, we propose a ROI loss and hard-positive mining strategy along with the\ntraining scheme, which can strengthen the ability of generated descriptor\ndealing with large illumination change conditions. We evaluate our approach on\npublic patch matching benchmark and achieve the best results compared with\nseveral state-of-the-arts methods. To show the practicality, we further\nevaluate IF-Net on the task of visual localization under large illumination\nchanges scenes, and achieves the best localization accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 04:32:32 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Chen", "Po-Heng", ""], ["Luo", "Zhao-Xu", ""], ["Huang", "Zu-Kuan", ""], ["Yang", "Chun", ""], ["Chen", "Kuan-Wen", ""]]}, {"id": "2008.03901", "submitter": "Fanghui Xue", "authors": "Fanghui Xue, Yingyong Qi, Jack Xin", "title": "RARTS: a Relaxed Architecture Search Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentiable architecture search (DARTS) is an effective method for\ndata-driven neural network design based on solving a bilevel optimization\nproblem. In this paper, we formulate a single level alternative and a relaxed\narchitecture search (RARTS) method that utilizes training and validation\ndatasets in architecture learning without involving mixed second derivatives of\nthe corresponding loss functions. Through weight/architecture variable\nsplitting and Gauss-Seidel iterations, the core algorithm outperforms DARTS\nsignificantly in accuracy and search efficiency, as shown in both a solvable\nmodel and CIFAR-10 based architecture search. Our model continues to\nout-perform DARTS upon transfer to ImageNet and is on par with recent variants\nof DARTS even though our innovation is purely on the training algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 04:55:51 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Xue", "Fanghui", ""], ["Qi", "Yingyong", ""], ["Xin", "Jack", ""]]}, {"id": "2008.03911", "submitter": "Weijie Fu", "authors": "Meng Wang, Weijie Fu, Xiangnan He, Shijie Hao, Xindong Wu", "title": "A Survey on Large-scale Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning can provide deep insights into data, allowing machines to\nmake high-quality predictions and having been widely used in real-world\napplications, such as text mining, visual classification, and recommender\nsystems. However, most sophisticated machine learning approaches suffer from\nhuge time costs when operating on large-scale data. This issue calls for the\nneed of {Large-scale Machine Learning} (LML), which aims to learn patterns from\nbig data with comparable performance efficiently. In this paper, we offer a\nsystematic survey on existing LML methods to provide a blueprint for the future\ndevelopments of this area. We first divide these LML methods according to the\nways of improving the scalability: 1) model simplification on computational\ncomplexities, 2) optimization approximation on computational efficiency, and 3)\ncomputation parallelism on computational capabilities. Then we categorize the\nmethods in each perspective according to their targeted scenarios and introduce\nrepresentative methods in line with intrinsic strategies. Lastly, we analyze\ntheir limitations and discuss potential directions as well as open issues that\nare promising to address in the future.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 06:07:52 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Wang", "Meng", ""], ["Fu", "Weijie", ""], ["He", "Xiangnan", ""], ["Hao", "Shijie", ""], ["Wu", "Xindong", ""]]}, {"id": "2008.03920", "submitter": "Houman Owhadi", "authors": "Houman Owhadi", "title": "Do ideas have shape? Plato's theory of forms as the continuous limit of\n  artificial neural networks", "comments": "56 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that ResNets converge, in the infinite depth limit, to a\ngeneralization of image registration algorithms. In this generalization, images\nare replaced by abstractions (ideas) living in high dimensional RKHS spaces,\nand material points are replaced by data points. Whereas computational anatomy\naligns images via deformations of the material space, this generalization\naligns ideas by via transformations of their RKHS. This identification of\nResNets as idea registration algorithms has several remarkable consequences.\nThe search for good architectures can be reduced to that of good kernels, and\nwe show that the composition of idea registration blocks with reduced\nequivariant multi-channel kernels (introduced here) recovers and generalizes\nCNNs to arbitrary spaces and groups of transformations. Minimizers of $L_2$\nregularized ResNets satisfy a discrete least action principle implying the near\npreservation of the norm of weights and biases across layers. The parameters of\ntrained ResNets can be identified as solutions of an autonomous Hamiltonian\nsystem defined by the activation function and the architecture of the ANN.\nMomenta variables provide a sparse representation of the parameters of a\nResNet. The registration regularization strategy provides a provably robust\nalternative to Dropout for ANNs. Pointwise RKHS error estimates lead to\ndeterministic error estimates for ANNs.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 06:46:43 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 15:55:24 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Owhadi", "Houman", ""]]}, {"id": "2008.03936", "submitter": "Moritz Firsching", "authors": "Thomas Fischbacher and Iulia M. Comsa and Krzysztof Potempa and Moritz\n  Firsching and Luca Versari and Jyrki Alakuijala", "title": "Intelligent Matrix Exponentiation", "comments": "20 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.RT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel machine learning architecture that uses the exponential of\na single input-dependent matrix as its only nonlinearity. The mathematical\nsimplicity of this architecture allows a detailed analysis of its behaviour,\nproviding robustness guarantees via Lipschitz bounds. Despite its simplicity, a\nsingle matrix exponential layer already provides universal approximation\nproperties and can learn fundamental functions of the input, such as periodic\nfunctions or multivariate polynomials. This architecture outperforms other\ngeneral-purpose architectures on benchmark problems, including CIFAR-10, using\nsubstantially fewer parameters.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 07:49:01 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Fischbacher", "Thomas", ""], ["Comsa", "Iulia M.", ""], ["Potempa", "Krzysztof", ""], ["Firsching", "Moritz", ""], ["Versari", "Luca", ""], ["Alakuijala", "Jyrki", ""]]}, {"id": "2008.03937", "submitter": "Matej Petkovi\\'c", "authors": "Matej Petkovi\\'c, Sa\\v{s}o D\\v{z}eroski, Dragi Kocev", "title": "Feature Ranking for Semi-supervised Learning", "comments": "Submitted to: Special Issue on Discovery Science of the Machine\n  Learning Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The data made available for analysis are becoming more and more complex along\nseveral directions: high dimensionality, number of examples and the amount of\nlabels per example. This poses a variety of challenges for the existing machine\nlearning methods: coping with dataset with a large number of examples that are\ndescribed in a high-dimensional space and not all examples have labels\nprovided. For example, when investigating the toxicity of chemical compounds\nthere are a lot of compounds available, that can be described with information\nrich high-dimensional representations, but not all of the compounds have\ninformation on their toxicity. To address these challenges, we propose\nsemi-supervised learning of feature ranking. The feature rankings are learned\nin the context of classification and regression as well as in the context of\nstructured output prediction (multi-label classification, hierarchical\nmulti-label classification and multi-target regression). To the best of our\nknowledge, this is the first work that treats the task of feature ranking\nwithin the semi-supervised structured output prediction context. More\nspecifically, we propose two approaches that are based on tree ensembles and\nthe Relief family of algorithms. The extensive evaluation across 38 benchmark\ndatasets reveals the following: Random Forests perform the best for the\nclassification-like tasks, while for the regression-like tasks Extra-PCTs\nperform the best, Random Forests are the most efficient method considering\ninduction times across all tasks, and semi-supervised feature rankings\noutperform their supervised counterpart across a majority of the datasets from\nthe different tasks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 07:50:50 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Petkovi\u0107", "Matej", ""], ["D\u017eeroski", "Sa\u0161o", ""], ["Kocev", "Dragi", ""]]}, {"id": "2008.03959", "submitter": "Nadav Merlis", "authors": "Nadav Merlis, Shie Mannor", "title": "Lenient Regret for Multi-Armed Bandits", "comments": "Accepted to AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Multi-Armed Bandit (MAB) problem, where an agent sequentially\nchooses actions and observes rewards for the actions it took. While the\nmajority of algorithms try to minimize the regret, i.e., the cumulative\ndifference between the reward of the best action and the agent's action, this\ncriterion might lead to undesirable results. For example, in large problems, or\nwhen the interaction with the environment is brief, finding an optimal arm is\ninfeasible, and regret-minimizing algorithms tend to over-explore. To overcome\nthis issue, algorithms for such settings should instead focus on playing\nnear-optimal arms. To this end, we suggest a new, more lenient, regret\ncriterion that ignores suboptimality gaps smaller than some $\\epsilon$. We then\npresent a variant of the Thompson Sampling (TS) algorithm, called\n$\\epsilon$-TS, and prove its asymptotic optimality in terms of the lenient\nregret. Importantly, we show that when the mean of the optimal arm is high\nenough, the lenient regret of $\\epsilon$-TS is bounded by a constant. Finally,\nwe show that $\\epsilon$-TS can be applied to improve the performance when the\nagent knows a lower bound of the suboptimality gaps.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 08:30:52 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 07:45:54 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 13:15:49 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Merlis", "Nadav", ""], ["Mannor", "Shie", ""]]}, {"id": "2008.03961", "submitter": "Yexu Zhou", "authors": "Yexu Zhou, Yuting Gao, Yiran Huang, Michael Hefenbrock, Till Riedel,\n  and Michael Beigl", "title": "Automatic Remaining Useful Life Estimation Framework with Embedded\n  Convolutional LSTM as the Backbone", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An essential task in predictive maintenance is the prediction of the\nRemaining Useful Life (RUL) through the analysis of multivariate time series.\nUsing the sliding window method, Convolutional Neural Network (CNN) and\nconventional Recurrent Neural Network (RNN) approaches have produced impressive\nresults on this matter, due to their ability to learn optimized features.\nHowever, sequence information is only partially modeled by CNN approaches. Due\nto the flatten mechanism in conventional RNNs, like Long Short Term Memories\n(LSTM), the temporal information within the window is not fully preserved. To\nexploit the multi-level temporal information, many approaches are proposed\nwhich combine CNN and RNN models. In this work, we propose a new LSTM variant\ncalled embedded convolutional LSTM (ECLSTM). In ECLSTM a group of different 1D\nconvolutions is embedded into the LSTM structure. Through this, the temporal\ninformation is preserved between and within windows. Since the hyper-parameters\nof models require careful tuning, we also propose an automated prediction\nframework based on the Bayesian optimization with hyperband optimizer, which\nallows for efficient optimization of the network architecture. Finally, we show\nthe superiority of our proposed ECLSTM approach over the state-of-the-art\napproaches on several widely used benchmark data sets for RUL Estimation.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 08:34:20 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Zhou", "Yexu", ""], ["Gao", "Yuting", ""], ["Huang", "Yiran", ""], ["Hefenbrock", "Michael", ""], ["Riedel", "Till", ""], ["Beigl", "Michael", ""]]}, {"id": "2008.03964", "submitter": "Swaroop Mishra", "authors": "Swaroop Mishra, Anjana Arunkumar, Bhavdeep Sachdeva, Chris Bryan and\n  Chitta Baral", "title": "DQI: A Guide to Benchmark Evaluation", "comments": "ICML UDL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A `state of the art' model A surpasses humans in a benchmark B, but fails on\nsimilar benchmarks C, D, and E. What does B have that the other benchmarks do\nnot? Recent research provides the answer: spurious bias. However, developing A\nto solve benchmarks B through E does not guarantee that it will solve future\nbenchmarks. To progress towards a model that `truly learns' an underlying task,\nwe need to quantify the differences between successive benchmarks, as opposed\nto existing binary and black-box approaches. We propose a novel approach to\nsolve this underexplored task of quantifying benchmark quality by debuting a\ndata quality metric: DQI.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 08:38:55 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mishra", "Swaroop", ""], ["Arunkumar", "Anjana", ""], ["Sachdeva", "Bhavdeep", ""], ["Bryan", "Chris", ""], ["Baral", "Chitta", ""]]}, {"id": "2008.03982", "submitter": "Lei Shi", "authors": "Lei Shi, Alexandra Cristea, Ahmad Alamri, Armando M. Toda, Wilk\n  Oliveira", "title": "Social Interactions Clustering MOOC Students: An Exploratory Study", "comments": "The 20th IEEE International Conference on Advanced Learning\n  Technologies (ICALT2020), page 172-174", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  An exploratory study on social interactions of MOOC students in FutureLearn\nwas conducted, to answer \"how can we cluster students based on their social\ninteractions?\" Comments were categorized based on how students interacted with\nthem, e.g., how a student's comment received replies from peers. Statistical\nmodelling and machine learning were used to analyze comment categorization,\nresulting in 3 strong and stable clusters.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 09:32:38 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Shi", "Lei", ""], ["Cristea", "Alexandra", ""], ["Alamri", "Ahmad", ""], ["Toda", "Armando M.", ""], ["Oliveira", "Wilk", ""]]}, {"id": "2008.03985", "submitter": "Steffen Bruns", "authors": "Steffen Bruns, Jelmer M. Wolterink, Richard A.P. Takx, Robbert W. van\n  Hamersvelt, Dominika Such\\'a, Max A. Viergever, Tim Leiner, Ivana I\\v{s}gum", "title": "Deep Learning from Dual-Energy Information for Whole-Heart Segmentation\n  in Dual-Energy and Single-Energy Non-Contrast-Enhanced Cardiac CT", "comments": null, "journal-ref": null, "doi": "10.1002/mp.14451", "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning-based whole-heart segmentation in coronary CT angiography\n(CCTA) allows the extraction of quantitative imaging measures for\ncardiovascular risk prediction. Automatic extraction of these measures in\npatients undergoing only non-contrast-enhanced CT (NCCT) scanning would be\nvaluable. In this work, we leverage information provided by a dual-layer\ndetector CT scanner to obtain a reference standard in virtual non-contrast\n(VNC) CT images mimicking NCCT images, and train a 3D convolutional neural\nnetwork (CNN) for the segmentation of VNC as well as NCCT images.\nContrast-enhanced acquisitions on a dual-layer detector CT scanner were\nreconstructed into a CCTA and a perfectly aligned VNC image. In each CCTA\nimage, manual reference segmentations of the left ventricular (LV) myocardium,\nLV cavity, right ventricle, left atrium, right atrium, ascending aorta, and\npulmonary artery trunk were obtained and propagated to the corresponding VNC\nimage. These VNC images and reference segmentations were used to train 3D CNNs\nfor automatic segmentation in either VNC images or NCCT images. Automatic\nsegmentations in VNC images showed good agreement with reference segmentations,\nwith an average Dice similarity coefficient of 0.897 \\pm 0.034 and an average\nsymmetric surface distance of 1.42 \\pm 0.45 mm. Volume differences [95%\nconfidence interval] between automatic NCCT and reference CCTA segmentations\nwere -19 [-67; 30] mL for LV myocardium, -25 [-78; 29] mL for LV cavity, -29\n[-73; 14] mL for right ventricle, -20 [-62; 21] mL for left atrium, and -19\n[-73; 34] mL for right atrium, respectively. In 214 (74%) NCCT images from an\nindependent multi-vendor multi-center set, two observers agreed that the\nautomatic segmentation was mostly accurate or better. This method might enable\nquantification of additional cardiac measures from NCCT images for improved\ncardiovascular risk prediction.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 09:35:23 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Bruns", "Steffen", ""], ["Wolterink", "Jelmer M.", ""], ["Takx", "Richard A. P.", ""], ["van Hamersvelt", "Robbert W.", ""], ["Such\u00e1", "Dominika", ""], ["Viergever", "Max A.", ""], ["Leiner", "Tim", ""], ["I\u0161gum", "Ivana", ""]]}, {"id": "2008.03989", "submitter": "Alexander Tarakanov", "authors": "Alexander Tarakanov, Ahmed H. Elsheikh", "title": "Optimal Bayesian experimental design for subsurface flow problems", "comments": "30 pages, 9 figures. Published in Computer Methods in Applied\n  Mechanics and Engineering", "journal-ref": "Computer Methods in Applied Mechanics and Engineering, Volume 370,\n  2020, 113208, ISSN 0045-7825", "doi": "10.1016/j.cma.2020.113208", "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal Bayesian design techniques provide an estimate for the best\nparameters of an experiment in order to maximize the value of measurements\nprior to the actual collection of data. In other words, these techniques\nexplore the space of possible observations and determine an experimental setup\nthat produces maximum information about the system parameters on average.\nGenerally, optimal Bayesian design formulations result in multiple\nhigh-dimensional integrals that are difficult to evaluate without incurring\nsignificant computational costs as each integration point corresponds to\nsolving a coupled system of partial differential equations. In the present\nwork, we propose a novel approach for development of polynomial chaos expansion\n(PCE) surrogate model for the design utility function. In particular, we\ndemonstrate how the orthogonality of PCE basis polynomials can be utilized in\norder to replace the expensive integration over the space of possible\nobservations by direct construction of PCE approximation for the expected\ninformation gain. This novel technique enables the derivation of a reasonable\nquality response surface for the targeted objective function with a\ncomputational budget comparable to several single-point evaluations. Therefore,\nthe proposed technique reduces dramatically the overall cost of optimal\nBayesian experimental design. We evaluate this alternative formulation\nutilizing PCE on few numerical test cases with various levels of complexity to\nillustrate the computational advantages of the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 09:42:59 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Tarakanov", "Alexander", ""], ["Elsheikh", "Ahmed H.", ""]]}, {"id": "2008.03997", "submitter": "Stylianos Venieris", "authors": "Stefanos Laskaridis, Stylianos I. Venieris, Hyeji Kim and Nicholas D.\n  Lane", "title": "HAPI: Hardware-Aware Progressive Inference", "comments": "Accepted at the 39th International Conference on Computer-Aided\n  Design (ICCAD), 2020", "journal-ref": null, "doi": "10.1145/3400302.3415698", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have recently become the\nstate-of-the-art in a diversity of AI tasks. Despite their popularity, CNN\ninference still comes at a high computational cost. A growing body of work aims\nto alleviate this by exploiting the difference in the classification difficulty\namong samples and early-exiting at different stages of the network.\nNevertheless, existing studies on early exiting have primarily focused on the\ntraining scheme, without considering the use-case requirements or the\ndeployment platform. This work presents HAPI, a novel methodology for\ngenerating high-performance early-exit networks by co-optimising the placement\nof intermediate exits together with the early-exit strategy at inference time.\nFurthermore, we propose an efficient design space exploration algorithm which\nenables the faster traversal of a large number of alternative architectures and\ngenerates the highest-performing design, tailored to the use-case requirements\nand target hardware. Quantitative evaluation shows that our system consistently\noutperforms alternative search mechanisms and state-of-the-art early-exit\nschemes across various latency budgets. Moreover, it pushes further the\nperformance of highly optimised hand-crafted early-exit CNNs, delivering up to\n5.11x speedup over lightweight models on imposed latency-driven SLAs for\nembedded devices.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 09:55:18 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Laskaridis", "Stefanos", ""], ["Venieris", "Stylianos I.", ""], ["Kim", "Hyeji", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "2008.04005", "submitter": "Emilio Maddalena", "authors": "Emilio T. Maddalena, Paul Scharnhorst, Colin N. Jones", "title": "Deterministic error bounds for kernel-based learning techniques under\n  bounded noise", "comments": "18 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reconstructing a function from a finite set of\nnoise-corrupted samples. Two kernel algorithms are analyzed, namely kernel\nridge regression and $\\varepsilon$-support vector regression. By assuming the\nground-truth function belongs to the reproducing kernel Hilbert space of the\nchosen kernel, and the measurement noise affecting the dataset is bounded, we\nadopt an approximation theory viewpoint to establish \\textit{deterministic},\nfinite-sample error bounds for the two models. Finally, we discuss their\nconnection with Gaussian processes and two numerical examples are provided. In\nestablishing our inequalities, we hope to help bring the fields of\nnon-parametric kernel learning and system identification for robust control\ncloser to each other.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 10:16:00 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 19:45:50 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Maddalena", "Emilio T.", ""], ["Scharnhorst", "Paul", ""], ["Jones", "Colin N.", ""]]}, {"id": "2008.04007", "submitter": "Ashith Babu Dr.", "authors": "RB Ashith Shyam, Zhou Hao, Umberto Montanaro, Gerhard Neumann", "title": "Imitation Learning for Autonomous Trajectory Learning of Robot Arms in\n  Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work adds on to the on-going efforts to provide more autonomy to space\nrobots. Here the concept of programming by demonstration or imitation learning\nis used for trajectory planning of manipulators mounted on small spacecraft.\nFor greater autonomy in future space missions and minimal human intervention\nthrough ground control, a robot arm having 7-Degrees of Freedom (DoF) is\nenvisaged for carrying out multiple tasks like debris removal, on-orbit\nservicing and assembly. Since actual hardware implementation of microgravity\nenvironment is extremely expensive, the demonstration data for trajectory\nlearning is generated using a model predictive controller (MPC) in a physics\nbased simulator. The data is then encoded compactly by Probabilistic Movement\nPrimitives (ProMPs). This offline trajectory learning allows faster\nreproductions and also avoids any computationally expensive optimizations after\ndeployment in a space environment. It is shown that the probabilistic\ndistribution can be used to generate trajectories to previously unseen\nsituations by conditioning the distribution. The motion of the robot (or\nmanipulator) arm induces reaction forces on the spacecraft hub and hence its\nattitude changes prompting the Attitude Determination and Control System (ADCS)\nto take large corrective action that drains energy out of the system. By having\na robot arm with redundant DoF helps in finding several possible trajectories\nfrom the same start to the same target. This allows the ProMP trajectory\ngenerator to sample out the trajectory which is obstacle free as well as having\nminimal attitudinal disturbances thereby reducing the load on ADCS.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 10:18:04 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Shyam", "RB Ashith", ""], ["Hao", "Zhou", ""], ["Montanaro", "Umberto", ""], ["Neumann", "Gerhard", ""]]}, {"id": "2008.04042", "submitter": "Ahmed Frikha", "authors": "Ahmed Frikha, Denis Krompa{\\ss} and Volker Tresp", "title": "ARCADe: A Rapid Continual Anomaly Detector", "comments": "Accepted at ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although continual learning and anomaly detection have separately been\nwell-studied in previous works, their intersection remains rather unexplored.\nThe present work addresses a learning scenario where a model has to\nincrementally learn a sequence of anomaly detection tasks, i.e. tasks from\nwhich only examples from the normal (majority) class are available for\ntraining. We define this novel learning problem of continual anomaly detection\n(CAD) and formulate it as a meta-learning problem. Moreover, we propose A Rapid\nContinual Anomaly Detector (ARCADe), an approach to train neural networks to be\nrobust against the major challenges of this new learning problem, namely\ncatastrophic forgetting and overfitting to the majority class. The results of\nour experiments on three datasets show that, in the CAD problem setting, ARCADe\nsubstantially outperforms baselines from the continual learning and anomaly\ndetection literature. Finally, we provide deeper insights into the learning\nstrategy yielded by the proposed meta-learning algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 11:59:32 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 17:34:02 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Frikha", "Ahmed", ""], ["Krompa\u00df", "Denis", ""], ["Tresp", "Volker", ""]]}, {"id": "2008.04057", "submitter": "Matthew Ciolino", "authors": "David Noever, Matt Ciolino and Josh Kalin", "title": "The Chess Transformer: Mastering Play using Generative Language Models", "comments": "7 Pages, 6 Figures, AAAI Format, AAAI 21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.GT cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work demonstrates that natural language transformers can support more\ngeneric strategic modeling, particularly for text-archived games. In addition\nto learning natural language skills, the abstract transformer architecture can\ngenerate meaningful moves on a chessboard. With further fine-tuning, the\ntransformer learns complex gameplay by training on 2.8 million chess games in\nPortable Game Notation. After 30,000 training steps, OpenAI's Generative\nPre-trained Transformer (GPT-2) optimizes weights for 774 million parameters.\nThis fine-tuned Chess Transformer generates plausible strategies and displays\ngame formations identifiable as classic openings, such as English or the Slav\nExchange. Finally, in live play, the novel model demonstrates a\nhuman-to-transformer interface that correctly filters illegal moves and\nprovides a novel method to challenge the transformer's chess strategies. We\nanticipate future work will build on this transformer's promise, particularly\nin other strategy games where features can capture the underlying complex rule\nsyntax from simple but expressive player annotations.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 18:04:36 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 13:38:42 GMT"}, {"version": "v3", "created": "Wed, 12 Aug 2020 20:05:54 GMT"}, {"version": "v4", "created": "Fri, 21 Aug 2020 17:31:29 GMT"}, {"version": "v5", "created": "Fri, 18 Sep 2020 17:12:52 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Noever", "David", ""], ["Ciolino", "Matt", ""], ["Kalin", "Josh", ""]]}, {"id": "2008.04059", "submitter": "Jie Chen", "authors": "Linwei Hu, Jie Chen, Joel Vaughan, Hanyu Yang, Kelly Wang, Agus\n  Sudjianto, Vijayan N. Nair", "title": "Supervised Machine Learning Techniques: An Overview with Applications to\n  Banking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides an overview of Supervised Machine Learning (SML) with a\nfocus on applications to banking. The SML techniques covered include Bagging\n(Random Forest or RF), Boosting (Gradient Boosting Machine or GBM) and Neural\nNetworks (NNs). We begin with an introduction to ML tasks and techniques. This\nis followed by a description of: i) tree-based ensemble algorithms including\nBagging with RF and Boosting with GBMs, ii) Feedforward NNs, iii) a discussion\nof hyper-parameter optimization techniques, and iv) machine learning\ninterpretability. The paper concludes with a comparison of the features of\ndifferent ML algorithms. Examples taken from credit risk modeling in banking\nare used throughout the paper to illustrate the techniques and interpret the\nresults of the algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 23:39:52 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Hu", "Linwei", ""], ["Chen", "Jie", ""], ["Vaughan", "Joel", ""], ["Yang", "Hanyu", ""], ["Wang", "Kelly", ""], ["Sudjianto", "Agus", ""], ["Nair", "Vijayan N.", ""]]}, {"id": "2008.04060", "submitter": "Mohsen Shahhosseini", "authors": "Mohsen Shahhosseini, Guiping Hu, Sotirios V. Archontoulis, Isaiah\n  Huber", "title": "Coupling Machine Learning and Crop Modeling Improves Crop Yield\n  Prediction in the US Corn Belt", "comments": null, "journal-ref": null, "doi": "10.1038/s41598-020-80820-1", "report-no": null, "categories": "q-bio.QM cs.LG q-bio.PE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This study investigates whether coupling crop modeling and machine learning\n(ML) improves corn yield predictions in the US Corn Belt. The main objectives\nare to explore whether a hybrid approach (crop modeling + ML) would result in\nbetter predictions, investigate which combinations of hybrid models provide the\nmost accurate predictions, and determine the features from the crop modeling\nthat are most effective to be integrated with ML for corn yield prediction.\nFive ML models (linear regression, LASSO, LightGBM, random forest, and XGBoost)\nand six ensemble models have been designed to address the research question.\nThe results suggest that adding simulation crop model variables (APSIM) as\ninput features to ML models can decrease yield prediction root mean squared\nerror (RMSE) from 7 to 20%. Furthermore, we investigated partial inclusion of\nAPSIM features in the ML prediction models and we found soil moisture related\nAPSIM variables are most influential on the ML predictions followed by\ncrop-related and phenology-related variables. Finally, based on feature\nimportance measure, it has been observed that simulated APSIM average drought\nstress and average water table depth during the growing season are the most\nimportant APSIM inputs to ML. This result indicates that weather information\nalone is not sufficient and ML models need more hydrological inputs to make\nimproved yield predictions.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 16:22:44 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 19:50:58 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Shahhosseini", "Mohsen", ""], ["Hu", "Guiping", ""], ["Archontoulis", "Sotirios V.", ""], ["Huber", "Isaiah", ""]]}, {"id": "2008.04063", "submitter": "Yanbo Xu", "authors": "Shenda Hong, Yanbo Xu, Alind Khare, Satria Priambada, Kevin Maher,\n  Alaa Aljiffry, Jimeng Sun and Alexey Tumanov", "title": "HOLMES: Health OnLine Model Ensemble Serving for Deep Learning Models in\n  Intensive Care Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have achieved expert-level performance in healthcare\nwith an exclusive focus on training accurate models. However, in many clinical\nenvironments such as intensive care unit (ICU), real-time model serving is\nequally if not more important than accuracy, because in ICU patient care is\nsimultaneously more urgent and more expensive. Clinical decisions and their\ntimeliness, therefore, directly affect both the patient outcome and the cost of\ncare. To make timely decisions, we argue the underlying serving system must be\nlatency-aware. To compound the challenge, health analytic applications often\nrequire a combination of models instead of a single model, to better specialize\nindividual models for different targets, multi-modal data, different prediction\nwindows, and potentially personalized predictions. To address these challenges,\nwe propose HOLMES-an online model ensemble serving framework for healthcare\napplications. HOLMES dynamically identifies the best performing set of models\nto ensemble for highest accuracy, while also satisfying sub-second latency\nconstraints on end-to-end prediction. We demonstrate that HOLMES is able to\nnavigate the accuracy/latency tradeoff efficiently, compose the ensemble, and\nserve the model ensemble pipeline, scaling to simultaneously streaming data\nfrom 100 patients, each producing waveform data at 250~Hz. HOLMES outperforms\nthe conventional offline batch-processed inference for the same clinical task\nin terms of accuracy and latency (by order of magnitude). HOLMES is tested on\nrisk prediction task on pediatric cardio ICU data with above 95% prediction\naccuracy and sub-second latency on 64-bed simulation.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 12:38:46 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Hong", "Shenda", ""], ["Xu", "Yanbo", ""], ["Khare", "Alind", ""], ["Priambada", "Satria", ""], ["Maher", "Kevin", ""], ["Aljiffry", "Alaa", ""], ["Sun", "Jimeng", ""], ["Tumanov", "Alexey", ""]]}, {"id": "2008.04068", "submitter": "Param Vir Singh", "authors": "Runshan Fu, Yan Huang and Param Vir Singh", "title": "Crowd, Lending, Machine, and Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data and machine learning (ML) algorithms are key drivers of many fintech\ninnovations. While it may be obvious that replacing humans with machine would\nincrease efficiency, it is not clear whether and where machines can make better\ndecisions than humans. We answer this question in the context of crowd lending,\nwhere decisions are traditionally made by a crowd of investors. Using data from\nProsper.com, we show that a reasonably sophisticated ML algorithm predicts\nlisting default probability more accurately than crowd investors. The dominance\nof the machine over the crowd is more pronounced for highly risky listings. We\nthen use the machine to make investment decisions, and find that the machine\nbenefits not only the lenders but also the borrowers. When machine prediction\nis used to select loans, it leads to a higher rate of return for investors and\nmore funding opportunities for borrowers with few alternative funding options.\nWe also find suggestive evidence that the machine is biased in gender and race\neven when it does not use gender and race information as input. We propose a\ngeneral and effective \"debasing\" method that can be applied to any prediction\nfocused ML applications, and demonstrate its use in our context. We show that\nthe debiased ML algorithm, which suffers from lower prediction accuracy, still\nleads to better investment decisions compared with the crowd. These results\nindicate that ML can help crowd lending platforms better fulfill the promise of\nproviding access to financial resources to otherwise underserved individuals\nand ensure fairness in the allocation of these resources.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 01:26:00 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Fu", "Runshan", ""], ["Huang", "Yan", ""], ["Singh", "Param Vir", ""]]}, {"id": "2008.04072", "submitter": "Gabriel Mersy", "authors": "Gabriel Mersy, Vincent Santore, Isaac Rand, Corrine Kleinman, Grant\n  Wilson, Jason Bonsall, Tyler Edwards", "title": "A Comparison of Machine Learning Algorithms Applied to American\n  Legislature Polarization", "comments": "6 pages, to be presented at IEEE 21st International Conference on\n  Information Reuse and Integration for Data Science (IRI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a novel approach to the measurement of American state legislature\npolarization with an experimental comparison of three different machine\nlearning algorithms. Our approach strictly relies on public data sources and\nopen source software. The results suggest that artificial neural network\nregression has the best outcome compared to both support vector machine and\nordinary least squares regression in the prediction of both state House and\nstate Senate legislature polarization. In addition to the technical outcomes of\nour study, broader implications are assessed as a means of highlighting the\nimportance of accessible information for the higher purpose of promoting civic\nresponsibility.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 22:28:26 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mersy", "Gabriel", ""], ["Santore", "Vincent", ""], ["Rand", "Isaac", ""], ["Kleinman", "Corrine", ""], ["Wilson", "Grant", ""], ["Bonsall", "Jason", ""], ["Edwards", "Tyler", ""]]}, {"id": "2008.04088", "submitter": "Luc Le Magoarou", "authors": "Taha Yassine (IRT b-com, Hypermedia), Luc Le Magoarou (IRT b-com,\n  Hypermedia)", "title": "mpNet: variable depth unfolded neural network for massive MIMO channel\n  estimation", "comments": "arXiv admin note: text overlap with arXiv:2004.14615", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive MIMO communication systems have a huge potential both in terms of\ndata rate and energy efficiency, although channel estimation becomes\nchallenging for a large number of antennas. Using a physical model allows to\nease the problem by injecting a priori information based on the physics of\npropagation. However, such a model rests on simplifying assumptions and\nrequires to know precisely the configuration of the system, which is\nunrealistic in practice. In this paper we present mpNet, an unfolded neural\nnetwork specifically designed for massive MIMO channel estimation. It is\ntrained online in an unsupervised way. Moreover, mpNet is computationally\nefficient and automatically adapts its depth to the SNR. The method we propose\nadds flexibility to physical channel models by allowing a base station to\nautomatically correct its channel estimation algorithm based on incoming data,\nwithout the need for a separate offline training phase. It is applied to\nrealistic millimeter wave channels and shows great performance, achieving a\nchannel estimation error almost as low as one would get with a perfectly\ncalibrated system. It also allows incident detection and automatic correction,\nmaking the base station resilient and able to automatically adapt to changes in\nits environment.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 12:23:44 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 11:44:11 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Yassine", "Taha", "", "IRT b-com, Hypermedia"], ["Magoarou", "Luc Le", "", "IRT b-com,\n  Hypermedia"]]}, {"id": "2008.04094", "submitter": "Alex Serban", "authors": "Alex Serban, Erik Poll, Joost Visser", "title": "Adversarial Examples on Object Recognition: A Comprehensive Survey", "comments": "Published in ACM CSUR. arXiv admin note: text overlap with\n  arXiv:1810.01185", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks are at the forefront of machine learning research.\nHowever, despite achieving impressive performance on complex tasks, they can be\nvery sensitive: Small perturbations of inputs can be sufficient to induce\nincorrect behavior. Such perturbations, called adversarial examples, are\nintentionally designed to test the network's sensitivity to distribution\ndrifts. Given their surprisingly small size, a wide body of literature\nconjectures on their existence and how this phenomenon can be mitigated. In\nthis article we discuss the impact of adversarial examples on security, safety,\nand robustness of neural networks. We start by introducing the hypotheses\nbehind their existence, the methods used to construct or protect against them,\nand the capacity to transfer adversarial examples between different machine\nlearning models. Altogether, the goal is to provide a comprehensive and\nself-contained survey of this growing field of research.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 08:51:21 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 09:53:48 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Serban", "Alex", ""], ["Poll", "Erik", ""], ["Visser", "Joost", ""]]}, {"id": "2008.04103", "submitter": "Kamal Berahmand", "authors": "Mehrdad Rostami, Kamal Berahmand, Saman Forouzandeh", "title": "Review of Swarm Intelligence-based Feature Selection Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In the past decades, the rapid growth of computer and database technologies\nhas led to the rapid growth of large-scale datasets. On the other hand, data\nmining applications with high dimensional datasets that require high speed and\naccuracy are rapidly increasing. An important issue with these applications is\nthe curse of dimensionality, where the number of features is much higher than\nthe number of patterns. One of the dimensionality reduction approaches is\nfeature selection that can increase the accuracy of the data mining task and\nreduce its computational complexity. The feature selection method aims at\nselecting a subset of features with the lowest inner similarity and highest\nrelevancy to the target class. It reduces the dimensionality of the data by\neliminating irrelevant, redundant, or noisy data. In this paper, a comparative\nanalysis of different feature selection methods is presented, and a general\ncategorization of these methods is performed. Moreover, in this paper,\nstate-of-the-art swarm intelligence are studied, and the recent feature\nselection methods based on these algorithms are reviewed. Furthermore, the\nstrengths and weaknesses of the different studied swarm intelligence-based\nfeature selection methods are evaluated.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 05:18:58 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Rostami", "Mehrdad", ""], ["Berahmand", "Kamal", ""], ["Forouzandeh", "Saman", ""]]}, {"id": "2008.04105", "submitter": "Dagnachew Azene Temesgene", "authors": "Dagnachew Azene Temesgene, Marco Miozzo, Deniz G\\\"und\\\"uz and Paolo\n  Dini", "title": "Distributed Deep Reinforcement Learning for Functional Split Control in\n  Energy Harvesting Virtualized Small Cells", "comments": "Submitted to IEEE transaction on sustainable computing. arXiv admin\n  note: text overlap with arXiv:1906.05735", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To meet the growing quest for enhanced network capacity, mobile network\noperators (MNOs) are deploying dense infrastructures of small cells. This, in\nturn, increases the power consumption of mobile networks, thus impacting the\nenvironment. As a result, we have seen a recent trend of powering mobile\nnetworks with harvested ambient energy to achieve both environmental and cost\nbenefits. In this paper, we consider a network of virtualized small cells\n(vSCs) powered by energy harvesters and equipped with rechargeable batteries,\nwhich can opportunistically offload baseband (BB) functions to a grid-connected\nedge server depending on their energy availability. We formulate the\ncorresponding grid energy and traffic drop rate minimization problem, and\npropose a distributed deep reinforcement learning (DDRL) solution. Coordination\namong vSCs is enabled via the exchange of battery state information. The\nevaluation of the network performance in terms of grid energy consumption and\ntraffic drop rate confirms that enabling coordination among the vSCs via\nknowledge exchange achieves a performance close to the optimal. Numerical\nresults also confirm that the proposed DDRL solution provides higher network\nperformance, better adaptation to the changing environment, and higher cost\nsavings with respect to a tabular multi-agent reinforcement learning (MRL)\nsolution used as a benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 12:27:01 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Temesgene", "Dagnachew Azene", ""], ["Miozzo", "Marco", ""], ["G\u00fcnd\u00fcz", "Deniz", ""], ["Dini", "Paolo", ""]]}, {"id": "2008.04107", "submitter": "Marlene Staib", "authors": "Marlene Staib (1), Tian Huey Teh (1), Alexandra Torresquintero (1),\n  Devang S Ram Mohan (1), Lorenzo Foglianti (1), Raphael Lenain (2), Jiameng\n  Gao (1) ((1) Papercup Technologies Ltd., (2) Novoic)", "title": "Phonological Features for 0-shot Multilingual Speech Synthesis", "comments": "5 pages, to be presented at INTERSPEECH 2020", "journal-ref": null, "doi": "10.21437/Interspeech.2020-1821", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code-switching---the intra-utterance use of multiple languages---is prevalent\nacross the world. Within text-to-speech (TTS), multilingual models have been\nfound to enable code-switching. By modifying the linguistic input to\nsequence-to-sequence TTS, we show that code-switching is possible for languages\nunseen during training, even within monolingual models. We use a small set of\nphonological features derived from the International Phonetic Alphabet (IPA),\nsuch as vowel height and frontness, consonant place and manner. This allows the\nmodel topology to stay unchanged for different languages, and enables new,\npreviously unseen feature combinations to be interpreted by the model. We show\nthat this allows us to generate intelligible, code-switched speech in a new\nlanguage at test time, including the approximation of sounds never seen in\ntraining.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 18:25:18 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Staib", "Marlene", "", "Papercup Technologies Ltd"], ["Teh", "Tian Huey", "", "Papercup Technologies Ltd"], ["Torresquintero", "Alexandra", "", "Papercup Technologies Ltd"], ["Mohan", "Devang S Ram", "", "Papercup Technologies Ltd"], ["Foglianti", "Lorenzo", "", "Papercup Technologies Ltd"], ["Lenain", "Raphael", "", "Novoic"], ["Gao", "Jiameng", "", "Papercup Technologies Ltd"]]}, {"id": "2008.04109", "submitter": "Abdul Mueed Hafiz Dr.", "authors": "Abdul Mueed Hafiz and Ghulam Mohiuddin Bhat", "title": "Deep Q-Network Based Multi-agent Reinforcement Learning with Binary\n  Action Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Q-Network (DQN) based multi-agent systems (MAS) for reinforcement\nlearning (RL) use various schemes where in the agents have to learn and\ncommunicate. The learning is however specific to each agent and communication\nmay be satisfactorily designed for the agents. As more complex Deep QNetworks\ncome to the fore, the overall complexity of the multi-agent system increases\nleading to issues like difficulty in training, need for higher resources and\nmore training time, difficulty in fine-tuning, etc. To address these issues we\npropose a simple but efficient DQN based MAS for RL which uses shared state and\nrewards, but agent-specific actions, for updation of the experience replay pool\nof the DQNs, where each agent is a DQN. The benefits of the approach are\noverall simplicity, faster convergence and better performance as compared to\nconventional DQN based approaches. It should be noted that the method can be\nextended to any DQN. As such we use simple DQN and DDQN (Double Q-learning)\nrespectively on three separate tasks i.e. Cartpole-v1 (OpenAI Gym environment)\n, LunarLander-v2 (OpenAI Gym environment) and Maze Traversal (customized\nenvironment). The proposed approach outperforms the baseline on these tasks by\ndecent margins respectively.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 15:16:05 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Hafiz", "Abdul Mueed", ""], ["Bhat", "Ghulam Mohiuddin", ""]]}, {"id": "2008.04113", "submitter": "Abigail Goldsteen", "authors": "Abigail Goldsteen, Gilad Ezov, Ron Shmelkin, Micha Moffie, Ariel\n  Farkash", "title": "Data Minimization for GDPR Compliance in Machine Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The EU General Data Protection Regulation (GDPR) mandates the principle of\ndata minimization, which requires that only data necessary to fulfill a certain\npurpose be collected. However, it can often be difficult to determine the\nminimal amount of data required, especially in complex machine learning models\nsuch as neural networks. We present a first-of-a-kind method to reduce the\namount of personal data needed to perform predictions with a machine learning\nmodel, by removing or generalizing some of the input features. Our method makes\nuse of the knowledge encoded within the model to produce a generalization that\nhas little to no impact on its accuracy. This enables the creators and users of\nmachine learning models to acheive data minimization, in a provable manner.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 08:21:15 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Goldsteen", "Abigail", ""], ["Ezov", "Gilad", ""], ["Shmelkin", "Ron", ""], ["Moffie", "Micha", ""], ["Farkash", "Ariel", ""]]}, {"id": "2008.04137", "submitter": "Abhishek Singh", "authors": "Iker Ceballos, Vivek Sharma, Eduardo Mugica, Abhishek Singh, Alberto\n  Roman, Praneeth Vepakomma, Ramesh Raskar", "title": "SplitNN-driven Vertical Partitioning", "comments": "First version, please provide feedback", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce SplitNN-driven Vertical Partitioning, a\nconfiguration of a distributed deep learning method called SplitNN to\nfacilitate learning from vertically distributed features. SplitNN does not\nshare raw data or model details with collaborating institutions. The proposed\nconfiguration allows training among institutions holding diverse sources of\ndata without the need of complex encryption algorithms or secure computation\nprotocols. We evaluate several configurations to merge the outputs of the split\nmodels, and compare performance and resource efficiency. The method is flexible\nand allows many different configurations to tackle the specific challenges\nposed by vertically split datasets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 17:41:42 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Ceballos", "Iker", ""], ["Sharma", "Vivek", ""], ["Mugica", "Eduardo", ""], ["Singh", "Abhishek", ""], ["Roman", "Alberto", ""], ["Vepakomma", "Praneeth", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2008.04152", "submitter": "Mehdi Moradi", "authors": "Sandesh Ghimire, Satyananda Kashyap, Joy T. Wu, Alexandros Karargyris,\n  Mehdi Moradi", "title": "Learning Invariant Feature Representation to Improve Generalization\n  across Chest X-ray Datasets", "comments": "Accepted to Machine Learning in Medical Imaging (MLMI 2020), in\n  conjunction with MICCAI 2020, Oct. 4, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chest radiography is the most common medical image examination for screening\nand diagnosis in hospitals. Automatic interpretation of chest X-rays at the\nlevel of an entry-level radiologist can greatly benefit work prioritization and\nassist in analyzing a larger population. Subsequently, several datasets and\ndeep learning-based solutions have been proposed to identify diseases based on\nchest X-ray images. However, these methods are shown to be vulnerable to shift\nin the source of data: a deep learning model performing well when tested on the\nsame dataset as training data, starts to perform poorly when it is tested on a\ndataset from a different source. In this work, we address this challenge of\ngeneralization to a new source by forcing the network to learn a\nsource-invariant representation. By employing an adversarial training strategy,\nwe show that a network can be forced to learn a source-invariant\nrepresentation. Through pneumonia-classification experiments on multi-source\nchest X-ray datasets, we show that this algorithm helps in improving\nclassification accuracy on a new source of X-ray dataset.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 07:41:15 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Ghimire", "Sandesh", ""], ["Kashyap", "Satyananda", ""], ["Wu", "Joy T.", ""], ["Karargyris", "Alexandros", ""], ["Moradi", "Mehdi", ""]]}, {"id": "2008.04157", "submitter": "Chenglizhao Chen", "authors": "Xuehao Wang, Shuai Li, Chenglizhao Chen, Aimin Hao, Hong Qin", "title": "Knowing Depth Quality In Advance: A Depth Quality Assessment Method For\n  RGB-D Salient Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous RGB-D salient object detection (SOD) methods have widely adopted\ndeep learning tools to automatically strike a trade-off between RGB and D\n(depth), whose key rationale is to take full advantage of their complementary\nnature, aiming for a much-improved SOD performance than that of using either of\nthem solely. However, such fully automatic fusions may not always be helpful\nfor the SOD task because the D quality itself usually varies from scene to\nscene. It may easily lead to a suboptimal fusion result if the D quality is not\nconsidered beforehand. Moreover, as an objective factor, the D quality has long\nbeen overlooked by previous work. As a result, it is becoming a clear\nperformance bottleneck. Thus, we propose a simple yet effective scheme to\nmeasure D quality in advance, the key idea of which is to devise a series of\nfeatures in accordance with the common attributes of high-quality D regions. To\nbe more concrete, we conduct D quality assessments for each image region,\nfollowing a multi-scale methodology that includes low-level edge consistency,\nmid-level regional uncertainty and high-level model variance. All these\ncomponents will be computed independently and then be assembled with RGB and D\nfeatures, applied as implicit indicators, to guide the selective fusion.\nCompared with the state-of-the-art fusion schemes, our method can achieve a\nmore reasonable fusion status between RGB and D. Specifically, the proposed D\nquality measurement method achieves steady performance improvements for almost\n2.0\\% in general.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 10:52:52 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Wang", "Xuehao", ""], ["Li", "Shuai", ""], ["Chen", "Chenglizhao", ""], ["Hao", "Aimin", ""], ["Qin", "Hong", ""]]}, {"id": "2008.04158", "submitter": "Chenglizhao Chen", "authors": "Zhenyu Wu, Shuai Li, Chenglizhao Chen, Aimin Hao, Hong Qin", "title": "Recursive Multi-model Complementary Deep Fusion forRobust Salient Object\n  Detection via Parallel Sub Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully convolutional networks have shown outstanding performance in the\nsalient object detection (SOD) field. The state-of-the-art (SOTA) methods have\na tendency to become deeper and more complex, which easily homogenize their\nlearned deep features, resulting in a clear performance bottleneck. In sharp\ncontrast to the conventional ``deeper'' schemes, this paper proposes a\n``wider'' network architecture which consists of parallel sub networks with\ntotally different network architectures. In this way, those deep features\nobtained via these two sub networks will exhibit large diversity, which will\nhave large potential to be able to complement with each other. However, a large\ndiversity may easily lead to the feature conflictions, thus we use the dense\nshort-connections to enable a recursively interaction between the parallel sub\nnetworks, pursuing an optimal complementary status between multi-model deep\nfeatures. Finally, all these complementary multi-model deep features will be\nselectively fused to make high-performance salient object detections. Extensive\nexperiments on several famous benchmarks clearly demonstrate the superior\nperformance, good generalization, and powerful learning ability of the proposed\nwider framework.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 10:39:11 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Wu", "Zhenyu", ""], ["Li", "Shuai", ""], ["Chen", "Chenglizhao", ""], ["Hao", "Aimin", ""], ["Qin", "Hong", ""]]}, {"id": "2008.04159", "submitter": "Chenglizhao Chen", "authors": "Chenglizhao Chen, Jipeng Wei, Chong Peng, Hong Qin", "title": "Depth Quality Aware Salient Object Detection", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2021.3052069", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existing fusion based RGB-D salient object detection methods usually\nadopt the bi-stream structure to strike the fusion trade-off between RGB and\ndepth (D). The D quality usually varies from scene to scene, while the SOTA\nbi-stream approaches are depth quality unaware, which easily result in\nsubstantial difficulties in achieving complementary fusion status between RGB\nand D, leading to poor fusion results in facing of low-quality D. Thus, this\npaper attempts to integrate a novel depth quality aware subnet into the classic\nbi-stream structure, aiming to assess the depth quality before conducting the\nselective RGB-D fusion. Compared with the SOTA bi-stream methods, the major\nhighlight of our method is its ability to lessen the importance of those\nlow-quality, no-contribution, or even negative-contribution D regions during\nthe RGB-D fusion, achieving a much improved complementary status between RGB\nand D.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 09:54:39 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Chen", "Chenglizhao", ""], ["Wei", "Jipeng", ""], ["Peng", "Chong", ""], ["Qin", "Hong", ""]]}, {"id": "2008.04168", "submitter": "Fabian Timm", "authors": "Di Feng and Lars Rosenbaum and Fabian Timm and Klaus Dietmayer", "title": "Labels Are Not Perfect: Improving Probabilistic Object Detection via\n  Label Uncertainty", "comments": "A shorter version of this work is to appear at the Workshop on\n  Perception for Autonomous Driving, 16th European Conference on Computer\n  Vision (ECCV) 2020. Video to this work https://youtu.be/m05HnYietSk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable uncertainty estimation is crucial for robust object detection in\nautonomous driving. However, previous works on probabilistic object detection\neither learn predictive probability for bounding box regression in an\nun-supervised manner, or use simple heuristics to do uncertainty\nregularization. This leads to unstable training or suboptimal detection\nperformance. In this work, we leverage our previously proposed method for\nestimating uncertainty inherent in ground truth bounding box parameters (which\nwe call label uncertainty) to improve the detection accuracy of a probabilistic\nLiDAR-based object detector. Experimental results on the KITTI dataset show\nthat our method surpasses both the baseline model and the models based on\nsimple heuristics by up to 3.6% in terms of Average Precision.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 14:49:49 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Feng", "Di", ""], ["Rosenbaum", "Lars", ""], ["Timm", "Fabian", ""], ["Dietmayer", "Klaus", ""]]}, {"id": "2008.04175", "submitter": "Jonas Rauber", "authors": "Jonas Rauber, Matthias Bethge, Wieland Brendel", "title": "EagerPy: Writing Code That Works Natively with PyTorch, TensorFlow, JAX,\n  and NumPy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EagerPy is a Python framework that lets you write code that automatically\nworks natively with PyTorch, TensorFlow, JAX, and NumPy. Library developers no\nlonger need to choose between supporting just one of these frameworks or\nreimplementing the library for each framework and dealing with code\nduplication. Users of such libraries can more easily switch frameworks without\nbeing locked in by a specific 3rd party library. Beyond multi-framework\nsupport, EagerPy also brings comprehensive type annotations and consistent\nsupport for method chaining to any framework. The latest documentation is\navailable online at https://eagerpy.jonasrauber.de and the code can be found on\nGitHub at https://github.com/jonasrauber/eagerpy.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 14:57:41 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Rauber", "Jonas", ""], ["Bethge", "Matthias", ""], ["Brendel", "Wieland", ""]]}, {"id": "2008.04195", "submitter": "Usman Khan", "authors": "Ran Xin, Usman A. Khan, and Soummya Kar", "title": "An improved convergence analysis for decentralized online stochastic\n  non-convex optimization", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2021.3062553", "report-no": null, "categories": "math.OC cs.LG cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study decentralized online stochastic non-convex\noptimization over a network of nodes. Integrating a technique called gradient\ntracking in decentralized stochastic gradient descent, we show that the\nresulting algorithm, GT-DSGD, enjoys certain desirable characteristics towards\nminimizing a sum of smooth non-convex functions. In particular, for general\nsmooth non-convex functions, we establish non-asymptotic characterizations of\nGT-DSGD and derive the conditions under which it achieves network-independent\nperformances that match the centralized minibatch SGD. In contrast, the\nexisting results suggest that GT-DSGD is always network-dependent and is\ntherefore strictly worse than the centralized minibatch SGD. When the global\nnon-convex function additionally satisfies the Polyak-Lojasiewics (PL)\ncondition, we establish the linear convergence of GT-DSGD up to a steady-state\nerror with appropriate constant step-sizes. Moreover, under stochastic\napproximation step-sizes, we establish, for the first time, the optimal global\nsublinear convergence rate on almost every sample path, in addition to the\nasymptotically optimal sublinear rate in expectation. Since strongly convex\nfunctions are a special case of the functions satisfying the PL condition, our\nresults are not only immediately applicable but also improve the currently\nknown best convergence rates and their dependence on problem parameters.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 15:29:13 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 02:20:10 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Xin", "Ran", ""], ["Khan", "Usman A.", ""], ["Kar", "Soummya", ""]]}, {"id": "2008.04203", "submitter": "Gunnar Mein", "authors": "Gunnar Mein, Kevin Hartman, Andrew Morris", "title": "FireBERT: Hardening BERT-based classifiers against adversarial attack", "comments": "8 pages, 10 figures, code available at:\n  https://github.com/FireBERT-author/FireBERT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present FireBERT, a set of three proof-of-concept NLP classifiers hardened\nagainst TextFooler-style word-perturbation by producing diverse alternatives to\noriginal samples. In one approach, we co-tune BERT against the training data\nand synthetic adversarial samples. In a second approach, we generate the\nsynthetic samples at evaluation time through substitution of words and\nperturbation of embedding vectors. The diversified evaluation results are then\ncombined by voting. A third approach replaces evaluation-time word substitution\nwith perturbation of embedding vectors. We evaluate FireBERT for MNLI and IMDB\nMovie Review datasets, in the original and on adversarial examples generated by\nTextFooler. We also test whether TextFooler is less successful in creating new\nadversarial samples when manipulating FireBERT, compared to working on\nunhardened classifiers. We show that it is possible to improve the accuracy of\nBERT-based models in the face of adversarial attacks without significantly\nreducing the accuracy for regular benchmark samples. We present co-tuning with\na synthetic data generator as a highly effective method to protect against 95%\nof pre-manufactured adversarial samples while maintaining 98% of original\nbenchmark performance. We also demonstrate evaluation-time perturbation as a\npromising direction for further research, restoring accuracy up to 75% of\nbenchmark performance for pre-made adversarials, and up to 65% (from a baseline\nof 75% orig. / 12% attack) under active attack by TextFooler.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 15:43:28 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mein", "Gunnar", ""], ["Hartman", "Kevin", ""], ["Morris", "Andrew", ""]]}, {"id": "2008.04208", "submitter": "Seyed Mohammad Mahdi Heidarpoor Yazdi", "authors": "Seyed Mohammad Mahdi Heidarpoor Yazdi, Abdolhossein Abbassian", "title": "Working Memory for Online Memory Binding Tasks: A Hybrid Model", "comments": "23 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Working Memory is the brain module that holds and manipulates information\nonline. In this work, we design a hybrid model in which a simple feed-forward\nnetwork is coupled to a balanced random network via a read-write vector called\nthe interface vector. Three cases and their results are discussed similar to\nthe n-back task called, first-order memory binding task, generalized\nfirst-order memory task, and second-order memory binding task. The important\nresult is that our dual-component model of working memory shows good\nperformance with learning restricted to the feed-forward component only. Here\nwe take advantage of the random network property without learning. Finally, a\nmore complex memory binding task called, a cue-based memory binding task, is\nintroduced in which a cue is given as input representing a binding relation\nthat prompts the network to choose the useful chunk of memory. To our\nknowledge, this is the first time that random networks as a flexible memory is\nshown to play an important role in online binding tasks. We may interpret our\nresults as a candidate model of working memory in which the feed-forward\nnetwork learns to interact with the temporary storage random network as an\nattentional-controlling executive system.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 14:06:07 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 08:33:38 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Yazdi", "Seyed Mohammad Mahdi Heidarpoor", ""], ["Abbassian", "Abdolhossein", ""]]}, {"id": "2008.04210", "submitter": "Oluwasegun Ayokunle Somefun", "authors": "Oluwasegun A. Somefun, Kayode Akingbade and Folasade Dahunsi", "title": "From the logistic-sigmoid to nlogistic-sigmoid: modelling the COVID-19\n  pandemic growth", "comments": "applied to a real-world phenomenon. 11 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Real-world growth processes, such as epidemic growth, are inherently noisy,\nuncertain and often involve multiple growth phases. The logistic-sigmoid\nfunction has been suggested and applied in the domain of modelling such growth\nprocesses. However, existing definitions are limiting, as they do not consider\ngrowth as restricted in two-dimension. Additionally, as the number of growth\nphases increase, the modelling and estimation of logistic parameters becomes\nmore cumbersome, requiring more complex tools and analysis. To remedy this, we\nintroduce the nlogistic-sigmoid function as a compact, unified modern\ndefinition of logistic growth for modelling such real-world growth phenomena.\nAlso, we introduce two characteristic metrics of the logistic-sigmoid curve\nthat can give more robust projections on the state of the growth process in\neach dimension. Specifically, we apply this function to modelling the daily\nWorld Health Organization published COVID-19 time-series data of infection and\ndeath cases of the world and countries of the world to date. Our results\ndemonstrate statistically significant goodness of fit greater than or equal to\n99% for affected countries of the world exhibiting patterns of either single or\nmultiple stages of the ongoing COVID-19 outbreak, such as the USA.\nConsequently, this modern logistic definition and its metrics, as a machine\nlearning tool, can help to provide clearer and more robust monitoring and\nquantification of the ongoing pandemic growth process.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 15:33:48 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 16:02:44 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 02:25:53 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Somefun", "Oluwasegun A.", ""], ["Akingbade", "Kayode", ""], ["Dahunsi", "Folasade", ""]]}, {"id": "2008.04212", "submitter": "Risto Miikkulainen", "authors": "Risto Miikkulainen", "title": "Creative AI Through Evolutionary Computation: Principles and Examples", "comments": "This is an extended version of arXiv:1901.03775", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main power of artificial intelligence is not in modeling what we already\nknow, but in creating solutions that are new. Such solutions exist in extremely\nlarge, high-dimensional, and complex search spaces. Population-based search\ntechniques, i.e. variants of evolutionary computation, are well suited to\nfinding them. These techniques make it possible to find creative solutions to\npractical problems in the real world, making creative AI through evolutionary\ncomputation the likely \"next deep learning.\"\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 19:53:39 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 02:16:35 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 02:10:27 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Miikkulainen", "Risto", ""]]}, {"id": "2008.04213", "submitter": "Yuan Sun", "authors": "Yuan Sun, Sheng Wang, Yunzhuang Shen, Xiaodong Li, Andreas T. Ernst,\n  and Michael Kirley", "title": "Boosting Ant Colony Optimization via Solution Prediction and Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces an enhanced meta-heuristic (ML-ACO) that combines\nmachine learning (ML) and ant colony optimization (ACO) to solve combinatorial\noptimization problems. To illustrate the underlying mechanism of our enhanced\nalgorithm, we start by describing a test problem -- the orienteering problem --\nused to demonstrate the efficacy of ML-ACO. In this problem, the objective is\nto find a route that visits a subset of vertices in a graph within a time\nbudget to maximize the collected score. In the first phase of our ML-ACO\nalgorithm, an ML model is trained using a set of small problem instances where\nthe optimal solution is known. Specifically, classification models are used to\nclassify an edge as being part of the optimal route, or not, using\nproblem-specific features and statistical measures. We have tested several\nclassification models including graph neural networks, logistic regression and\nsupport vector machines. The trained model is then used to predict the\nprobability that an edge in the graph of a test problem instance belongs to the\ncorresponding optimal route. In the second phase, we incorporate the predicted\nprobabilities into the ACO component of our algorithm. Here, the probability\nvalues bias sampling towards favoring those predicted high-quality edges when\nconstructing feasible routes. We empirically show that ML-ACO generates results\nthat are significantly better than the standard ACO algorithm, especially when\nthe computational budget is limited. Furthermore, we show our algorithm is\nrobust in the sense that (a) its overall performance is not sensitive to any\nparticular classification model, and (b) it generalizes well to large and\nreal-world problem instances. Our approach integrating ML with a meta-heuristic\nis generic and can be applied to a wide range of combinatorial optimization\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 13:03:37 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Sun", "Yuan", ""], ["Wang", "Sheng", ""], ["Shen", "Yunzhuang", ""], ["Li", "Xiaodong", ""], ["Ernst", "Andreas T.", ""], ["Kirley", "Michael", ""]]}, {"id": "2008.04216", "submitter": "Issa Annamoradnejad", "authors": "Jafar Habibi, Amir Fazelinia, Issa Annamoradnejad", "title": "Using Experts' Opinions in Machine Learning Tasks", "comments": "6 pages, 1 table, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In machine learning tasks, especially in the tasks of prediction, scientists\ntend to rely solely on available historical data and disregard unproven\ninsights, such as experts' opinions, polls, and betting odds. In this paper, we\npropose a general three-step framework for utilizing experts' insights in\nmachine learning tasks and build four concrete models for a sports game\nprediction case study. For the case study, we have chosen the task of\npredicting NCAA Men's Basketball games, which has been the focus of a group of\nKaggle competitions in recent years. Results highly suggest that the good\nperformance and high scores of the past models are a result of chance, and not\nbecause of a good-performing and stable model. Furthermore, our proposed models\ncan achieve more steady results with lower log loss average (best at 0.489)\ncompared to the top solutions of the 2019 competition (>0.503), and reach the\ntop 1%, 10% and 1% in the 2017, 2018 and 2019 leaderboards, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 15:48:49 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 10:44:40 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Habibi", "Jafar", ""], ["Fazelinia", "Amir", ""], ["Annamoradnejad", "Issa", ""]]}, {"id": "2008.04222", "submitter": "Bertrand Georgeot", "authors": "S. Bompas, B. Georgeot and D. Gu\\'ery-Odelin", "title": "Accuracy of neural networks for the simulation of chaotic dynamics:\n  precision of training data vs precision of the algorithm", "comments": "10 pages, 15 figures, additonal data provided, published version", "journal-ref": "Chaos 30, 113118 (2020)", "doi": "10.1063/5.0021264", "report-no": null, "categories": "cs.NE cs.LG nlin.CD physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the influence of precision of the data and the algorithm for the\nsimulation of chaotic dynamics by neural networks techniques. For this purpose,\nwe simulate the Lorenz system with different precisions using three different\nneural network techniques adapted to time series, namely reservoir computing\n(using ESN), LSTM and TCN, for both short and long time predictions, and assess\ntheir efficiency and accuracy. Our results show that the ESN network is better\nat predicting accurately the dynamics of the system, and that in all cases the\nprecision of the algorithm is more important than the precision of the training\ndata for the accuracy of the predictions. This result gives support to the idea\nthat neural networks can perform time-series predictions in many practical\napplications for which data are necessarily of limited precision, in line with\nrecent results. It also suggests that for a given set of data the reliability\nof the predictions can be significantly improved by using a network with higher\nprecision than the one of the data.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 17:25:37 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 16:03:25 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Bompas", "S.", ""], ["Georgeot", "B.", ""], ["Gu\u00e9ry-Odelin", "D.", ""]]}, {"id": "2008.04245", "submitter": "Alexander Wong", "authors": "Alexander Wong, Mahmoud Famouri, Maya Pavlova, and Siddharth Surana", "title": "TinySpeech: Attention Condensers for Deep Speech Recognition Neural\n  Networks on Edge Devices", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in deep learning have led to state-of-the-art performance across a\nmultitude of speech recognition tasks. Nevertheless, the widespread deployment\nof deep neural networks for on-device speech recognition remains a challenge,\nparticularly in edge scenarios where the memory and computing resources are\nhighly constrained (e.g., low-power embedded devices) or where the memory and\ncomputing budget dedicated to speech recognition is low (e.g., mobile devices\nperforming numerous tasks besides speech recognition). In this study, we\nintroduce the concept of attention condensers for building low-footprint,\nhighly-efficient deep neural networks for on-device speech recognition on the\nedge. An attention condenser is a self-attention mechanism that learns and\nproduces a condensed embedding characterizing joint local and cross-channel\nactivation relationships, and performs selective attention accordingly. To\nillustrate its efficacy, we introduce TinySpeech, low-precision deep neural\nnetworks comprising largely of attention condensers tailored for on-device\nspeech recognition using a machine-driven design exploration strategy, with one\ntailored specifically with microcontroller operation constraints. Experimental\nresults on the Google Speech Commands benchmark dataset for limited-vocabulary\nspeech recognition showed that TinySpeech networks achieved significantly lower\narchitectural complexity (as much as $507\\times$ fewer parameters), lower\ncomputational complexity (as much as $48\\times$ fewer multiply-add operations),\nand lower storage requirements (as much as $2028\\times$ lower weight memory\nrequirements) when compared to previous work. These results not only\ndemonstrate the efficacy of attention condensers for building highly efficient\nnetworks for on-device speech recognition, but also illuminate its potential\nfor accelerating deep learning on the edge and empowering TinyML applications.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 16:34:52 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 01:37:04 GMT"}, {"version": "v3", "created": "Sun, 16 Aug 2020 14:46:10 GMT"}, {"version": "v4", "created": "Sun, 23 Aug 2020 00:28:33 GMT"}, {"version": "v5", "created": "Tue, 22 Sep 2020 04:07:50 GMT"}, {"version": "v6", "created": "Mon, 12 Oct 2020 19:07:39 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Wong", "Alexander", ""], ["Famouri", "Mahmoud", ""], ["Pavlova", "Maya", ""], ["Surana", "Siddharth", ""]]}, {"id": "2008.04254", "submitter": "Baifeng Shi", "authors": "Baifeng Shi, Dinghuai Zhang, Qi Dai, Zhanxing Zhu, Yadong Mu, Jingdong\n  Wang", "title": "Informative Dropout for Robust Representation Learning: A Shape-bias\n  Perspective", "comments": "Accepted to ICML2020. Code is available at\n  https://github.com/bfshi/InfoDrop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) are known to rely more on local texture\nrather than global shape when making decisions. Recent work also indicates a\nclose relationship between CNN's texture-bias and its robustness against\ndistribution shift, adversarial perturbation, random corruption, etc. In this\nwork, we attempt at improving various kinds of robustness universally by\nalleviating CNN's texture bias. With inspiration from the human visual system,\nwe propose a light-weight model-agnostic method, namely Informative Dropout\n(InfoDrop), to improve interpretability and reduce texture bias. Specifically,\nwe discriminate texture from shape based on local self-information in an image,\nand adopt a Dropout-like algorithm to decorrelate the model output from the\nlocal texture. Through extensive experiments, we observe enhanced robustness\nunder various scenarios (domain generalization, few-shot classification, image\ncorruption, and adversarial perturbation). To the best of our knowledge, this\nwork is one of the earliest attempts to improve different kinds of robustness\nin a unified model, shedding new light on the relationship between shape-bias\nand robustness, also on new approaches to trustworthy machine learning\nalgorithms. Code is available at https://github.com/bfshi/InfoDrop.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 16:52:24 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Shi", "Baifeng", ""], ["Zhang", "Dinghuai", ""], ["Dai", "Qi", ""], ["Zhu", "Zhanxing", ""], ["Mu", "Yadong", ""], ["Wang", "Jingdong", ""]]}, {"id": "2008.04267", "submitter": "Suyash Gupta", "authors": "Maxime Cauchois, Suyash Gupta, Alnur Ali and John C. Duchi", "title": "Robust Validation: Confident Predictions Even When Distributions Shift", "comments": "35 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the traditional viewpoint in machine learning and statistics assumes\ntraining and testing samples come from the same population, practice belies\nthis fiction. One strategy---coming from robust statistics and\noptimization---is thus to build a model robust to distributional perturbations.\nIn this paper, we take a different approach to describe procedures for robust\npredictive inference, where a model provides uncertainty estimates on its\npredictions rather than point predictions. We present a method that produces\nprediction sets (almost exactly) giving the right coverage level for any test\ndistribution in an $f$-divergence ball around the training population. The\nmethod, based on conformal inference, achieves (nearly) valid coverage in\nfinite samples, under only the condition that the training data be\nexchangeable. An essential component of our methodology is to estimate the\namount of expected future data shift and build robustness to it; we develop\nestimators and prove their consistency for protection and validity of\nuncertainty estimates under shifts. By experimenting on several large-scale\nbenchmark datasets, including Recht et al.'s CIFAR-v4 and ImageNet-V2 datasets,\nwe provide complementary empirical results that highlight the importance of\nrobust predictive validity.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 17:09:16 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Cauchois", "Maxime", ""], ["Gupta", "Suyash", ""], ["Ali", "Alnur", ""], ["Duchi", "John C.", ""]]}, {"id": "2008.04270", "submitter": "Dustin Mixon", "authors": "Dustin G. Mixon, Kaiying Xie", "title": "Sketching semidefinite programs for faster clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many clustering problems enjoy solutions by semidefinite programming.\nTheoretical results in this vein frequently consider data with a planted\nclustering and a notion of signal strength such that the semidefinite program\nexactly recovers the planted clustering when the signal strength is\nsufficiently large. In practice, semidefinite programs are notoriously slow,\nand so speedups are welcome. In this paper, we show how to sketch a popular\nsemidefinite relaxation of a graph clustering problem known as minimum\nbisection, and our analysis supports a meta-claim that the clustering task is\nless computationally burdensome when there is more signal.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 17:10:29 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mixon", "Dustin G.", ""], ["Xie", "Kaiying", ""]]}, {"id": "2008.04278", "submitter": "Dustin Mixon", "authors": "Jameson Cahill, Dustin G. Mixon, Hans Parshall", "title": "Lie PCA: Density estimation for symmetric manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an extension to local principal component analysis for learning\nsymmetric manifolds. In particular, we use a spectral method to approximate the\nLie algebra corresponding to the symmetry group of the underlying manifold. We\nderive the sample complexity of our method for a variety of manifolds before\napplying it to various data sets for improved density estimation.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 17:19:57 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 20:15:39 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Cahill", "Jameson", ""], ["Mixon", "Dustin G.", ""], ["Parshall", "Hans", ""]]}, {"id": "2008.04293", "submitter": "Hoda Eldardiry", "authors": "Milad Afzalan, Farrokh Jazizadeh, and Hoda Eldardiry", "title": "Two-stage building energy consumption clustering based on temporal and\n  peak demand patterns", "comments": "8 pages, 12 figures, submitted to IEEE Transactions on Smart Grid", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing smart meter data to understand energy consumption patterns helps\nutilities and energy providers perform customized demand response operations.\nExisting energy consumption segmentation techniques use assumptions that could\nresult in reduced quality of clusters in representing their members. We address\nthis limitation by introducing a two-stage clustering method that more\naccurately captures load shape temporal patterns and peak demands. In the first\nstage, load shapes are clustered by allowing a large number of clusters to\naccurately capture variations in energy use patterns and cluster centroids are\nextracted by accounting for shape misalignments. In the second stage, clusters\nof similar centroid and power magnitude range are merged by using Dynamic Time\nWarping. We used three datasets consisting of ~250 households (~15000 profiles)\nto demonstrate the performance improvement, compared to baseline methods, and\ndiscuss the impact on energy management.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 17:42:48 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 18:11:26 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Afzalan", "Milad", ""], ["Jazizadeh", "Farrokh", ""], ["Eldardiry", "Hoda", ""]]}, {"id": "2008.04374", "submitter": "Preslav Nakov", "authors": "Preslav Nakov", "title": "Can We Spot the \"Fake News\" Before It Was Even Written?", "comments": "Fake News, Disinformation, Media Bias, Propaganda, Infodemic,\n  COVID-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the recent proliferation of disinformation online, there has been also\ngrowing research interest in automatically debunking rumors, false claims, and\n\"fake news.\" A number of fact-checking initiatives have been launched so far,\nboth manual and automatic, but the whole enterprise remains in a state of\ncrisis: by the time a claim is finally fact-checked, it could have reached\nmillions of users, and the harm caused could hardly be undone. An arguably more\npromising direction is to focus on fact-checking entire news outlets, which can\nbe done in advance. Then, we could fact-check the news before it was even\nwritten: by checking how trustworthy the outlets that published it is. We\ndescribe how we do this in the Tanbih news aggregator, which makes readers\naware of what they are reading. In particular, we develop media profiles that\nshow the general factuality of reporting, the degree of propagandistic content,\nhyper-partisanship, leading political ideology, general frame of reporting, and\nstance with respect to various claims and topics.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 19:21:06 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Nakov", "Preslav", ""]]}, {"id": "2008.04377", "submitter": "Asaf Shabtai", "authors": "Hodaya Binyamini, Ron Bitton, Masaki Inokuchi, Tomohiko Yagyu, Yuval\n  Elovici, Asaf Shabtai", "title": "An Automated, End-to-End Framework for Modeling Attacks From\n  Vulnerability Descriptions", "comments": "16 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attack graphs are one of the main techniques used to automate the risk\nassessment process. In order to derive a relevant attack graph, up-to-date\ninformation on known attack techniques should be represented as interaction\nrules. Designing and creating new interaction rules is not a trivial task and\ncurrently performed manually by security experts. However, since the number of\nnew security vulnerabilities and attack techniques continuously and rapidly\ngrows, there is a need to frequently update the rule set of attack graph tools\nwith new attack techniques to ensure that the set of interaction rules is\nalways up-to-date. We present a novel, end-to-end, automated framework for\nmodeling new attack techniques from textual description of a security\nvulnerability. Given a description of a security vulnerability, the proposed\nframework first extracts the relevant attack entities required to model the\nattack, completes missing information on the vulnerability, and derives a new\ninteraction rule that models the attack; this new rule is integrated within\nMulVAL attack graph tool. The proposed framework implements a novel pipeline\nthat includes a dedicated cybersecurity linguistic model trained on the the NVD\nrepository, a recurrent neural network model used for attack entity extraction,\na logistic regression model used for completing the missing information, and a\nnovel machine learning-based approach for automatically modeling the attacks as\nMulVAL's interaction rule. We evaluated the performance of each of the\nindividual algorithms, as well as the complete framework and demonstrated its\neffectiveness.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 19:27:34 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Binyamini", "Hodaya", ""], ["Bitton", "Ron", ""], ["Inokuchi", "Masaki", ""], ["Yagyu", "Tomohiko", ""], ["Elovici", "Yuval", ""], ["Shabtai", "Asaf", ""]]}, {"id": "2008.04379", "submitter": "Sanchu Han", "authors": "Sanchu Han", "title": "A Survey and Insights on Deployments of the Connected and Autonomous\n  Vehicles in US", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CV/ITS (Connected Vehicle, Intelligent Transportation System) and AV/ADS\n(Autonomous Vehicle, Automated Driving System) have been emerging for the sake\nof saving people lives, improving traffic efficiency and helping the\nenvironment for decades. There are separate efforts led respectively by USDOT\nwith state DOTs for CV, and private sectors through market driven approach from\nstart-ups and technology companies for AV. By CV/ITS effort there are 97\ndeployments of V2X communications utilizing the 5.9 GHz band, 18,877 vehicles\nwith aftermarket V2X communications devices, and 8,098 infrastructure V2X\ndevices installed at the roadsides. However, CV/ITS still cannot be massively\ndeployed in US markets due to lack of regulations, dedicated wireless spectrum\nbands, sustainable financial & business models with mature supply chain, etc.\nIn the other side, technology-driven AV market has been much slower than\nexpected mainly because of immaturity of AI technology to handle different\ncomplex driving scenarios in a cost effective way. In this paper, we first\npresent these two parallel journeys focusing on the deployments including\noperating models, scenarios and applications, evaluations and lessons learning.\nThen, come up with recommendations to a cooperative CAV approach driving a more\nfeasible, safer, affordable and cost effective transportation, but require a\ngreat industry collaboration from Automotive, Transportation. ICT and Cloud.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 19:35:51 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Han", "Sanchu", ""]]}, {"id": "2008.04381", "submitter": "Hao Tang", "authors": "Hao Tang, Song Bai, Philip H.S. Torr, Nicu Sebe", "title": "Bipartite Graph Reasoning GANs for Person Image Generation", "comments": "13 pages, 6 figures, accepted to BMVC 2020 as an oral paper, fix\n  typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel Bipartite Graph Reasoning GAN (BiGraphGAN) for the\nchallenging person image generation task. The proposed graph generator mainly\nconsists of two novel blocks that aim to model the pose-to-pose and\npose-to-image relations, respectively. Specifically, the proposed Bipartite\nGraph Reasoning (BGR) block aims to reason the crossing long-range relations\nbetween the source pose and the target pose in a bipartite graph, which\nmitigates some challenges caused by pose deformation. Moreover, we propose a\nnew Interaction-and-Aggregation (IA) block to effectively update and enhance\nthe feature representation capability of both person's shape and appearance in\nan interactive way. Experiments on two challenging and public datasets, i.e.,\nMarket-1501 and DeepFashion, show the effectiveness of the proposed BiGraphGAN\nin terms of objective quantitative scores and subjective visual realness. The\nsource code and trained models are available at\nhttps://github.com/Ha0Tang/BiGraphGAN.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 19:37:10 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 22:01:35 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Tang", "Hao", ""], ["Bai", "Song", ""], ["Torr", "Philip H. S.", ""], ["Sebe", "Nicu", ""]]}, {"id": "2008.04387", "submitter": "Karthik Devarajan", "authors": "Majid Asadi, Karthik Devarajan, Nader Ebrahimi, Ehsan Soofi, Lauren\n  Spirko-Burns", "title": "Probability Link Models with Symmetric Information Divergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper introduces link functions for transforming one probability\ndistribution to another such that the Kullback-Leibler and R\\'enyi divergences\nbetween the two distributions are symmetric. Two general classes of link models\nare proposed. The first model links two survival functions and is applicable to\nmodels such as the proportional odds and change point, which are used in\nsurvival analysis and reliability modeling. A prototype application involving\nthe proportional odds model demonstrates advantages of symmetric divergence\nmeasures over asymmetric measures for assessing the efficacy of features and\nfor model averaging purposes. The advantages include providing unique ranks for\nmodels and unique information weights for model averaging with one-half as much\ncomputation requirement of asymmetric divergences. The second model links two\ncumulative probability distribution functions. This model produces a\ngeneralized location model which are continuous counterparts of the binary\nprobability models such as probit and logit models. Examples include the\ngeneralized probit and logit models which have appeared in the survival\nanalysis literature, and a generalized Laplace model and a generalized\nStudent-$t$ model, which are survival time models corresponding to the\nrespective binary probability models. Lastly, extensions to symmetric\ndivergence between survival functions and conditions for copula dependence\ninformation are presented.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 19:49:51 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Asadi", "Majid", ""], ["Devarajan", "Karthik", ""], ["Ebrahimi", "Nader", ""], ["Soofi", "Ehsan", ""], ["Spirko-Burns", "Lauren", ""]]}, {"id": "2008.04388", "submitter": "Grgur Kova\\v{c}", "authors": "Grgur Kova\\v{c}, Adrien Laversanne-Finot, Pierre-Yves Oudeyer", "title": "GRIMGEP: Learning Progress for Robust Goal Sampling in Visual Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing agents, capable of learning autonomously a wide range of skills is\ncritical in order to increase the scope of reinforcement learning. It will both\nincrease the diversity of learned skills and reduce the burden of manually\ndesigning reward functions for each skill. Self-supervised agents, setting\ntheir own goals, and trying to maximize the diversity of those goals have shown\ngreat promise towards this end. However, a currently known limitation of agents\ntrying to maximize the diversity of sampled goals is that they tend to get\nattracted to noise or more generally to parts of the environments that cannot\nbe controlled (distractors). When agents have access to predefined goal\nfeatures or expert knowledge, absolute Learning Progress (ALP) provides a way\nto distinguish between regions that can be controlled and those that cannot.\nHowever, those methods often fall short when the agents are only provided with\nraw sensory inputs such as images. In this work we extend those concepts to\nunsupervised image-based goal exploration. We propose a framework that allows\nagents to autonomously identify and ignore noisy distracting regions while\nsearching for novelty in the learnable regions to both improve overall\nperformance and avoid catastrophic forgetting. Our framework can be combined\nwith any state-of-the-art novelty seeking goal exploration approaches. We\nconstruct a rich 3D image based environment with distractors. Experiments on\nthis environment show that agents using our framework successfully identify\ninteresting regions of the environment, resulting in drastically improved\nperformances. The source code is available at\nhttps://sites.google.com/view/grimgep.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 19:50:06 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 11:54:09 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Kova\u010d", "Grgur", ""], ["Laversanne-Finot", "Adrien", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2008.04391", "submitter": "Guillaume Alain", "authors": "Guillaume Alain, Maxime Chevalier-Boisvert, Frederic Osterrath, Remi\n  Piche-Taillefer", "title": "DeepDrummer : Generating Drum Loops using Deep Learning and a Human in\n  the Loop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DeepDrummer is a drum loop generation tool that uses active learning to learn\nthe preferences (or current artistic intentions) of a human user from a small\nnumber of interactions. The principal goal of this tool is to enable an\nefficient exploration of new musical ideas. We train a deep neural network\nclassifier on audio data and show how it can be used as the core component of a\nsystem that generates drum loops based on few prior beliefs as to how these\nloops should be structured.\n  We aim to build a system that can converge to meaningful results even with a\nlimited number of interactions with the user. This property enables our method\nto be used from a cold start situation (no pre-existing dataset), or starting\nfrom a collection of audio samples provided by the user. In a proof of concept\nstudy with 25 participants, we empirically demonstrate that DeepDrummer is able\nto converge towards the preference of our subjects after a small number of\ninteractions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 20:04:15 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 21:09:23 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Alain", "Guillaume", ""], ["Chevalier-Boisvert", "Maxime", ""], ["Osterrath", "Frederic", ""], ["Piche-Taillefer", "Remi", ""]]}, {"id": "2008.04393", "submitter": "Hoo Chang Shin", "authors": "Hoo-Chang Shin, Alvin Ihsani, Swetha Mandava, Sharath Turuvekere\n  Sreenivas, Christopher Forster, Jiook Cha and Alzheimer's Disease\n  Neuroimaging Initiative", "title": "GANBERT: Generative Adversarial Networks with Bidirectional Encoder\n  Representations from Transformers for MRI to PET synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthesizing medical images, such as PET, is a challenging task due to the\nfact that the intensity range is much wider and denser than those in\nphotographs and digital renderings and are often heavily biased toward zero.\nAbove all, intensity values in PET have absolute significance, and are used to\ncompute parameters that are reproducible across the population. Yet, usually\nmuch manual adjustment has to be made in pre-/post- processing when\nsynthesizing PET images, because its intensity ranges can vary a lot, e.g.,\nbetween -100 to 1000 in floating point values. To overcome these challenges, we\nadopt the Bidirectional Encoder Representations from Transformers (BERT)\nalgorithm that has had great success in natural language processing (NLP),\nwhere wide-range floating point intensity values are represented as integers\nranging between 0 to 10000 that resemble a dictionary of natural language\nvocabularies. BERT is then trained to predict a proportion of masked values\nimages, where its \"next sentence prediction (NSP)\" acts as GAN discriminator.\nOur proposed approach, is able to generate PET images from MRI images in wide\nintensity range, with no manual adjustments in pre-/post- processing. It is a\nmethod that can scale and ready to deploy.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 20:07:33 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Shin", "Hoo-Chang", ""], ["Ihsani", "Alvin", ""], ["Mandava", "Swetha", ""], ["Sreenivas", "Sharath Turuvekere", ""], ["Forster", "Christopher", ""], ["Cha", "Jiook", ""], ["Initiative", "Alzheimer's Disease Neuroimaging", ""]]}, {"id": "2008.04396", "submitter": "Hoo Chang Shin", "authors": "Hoo-Chang Shin, Alvin Ihsani, Ziyue Xu, Swetha Mandava, Sharath\n  Turuvekere Sreenivas, Christopher Forster, Jiook Cha, and Alzheimer's Disease\n  Neuroimaging Initiative", "title": "GANDALF: Generative Adversarial Networks with Discriminator-Adaptive\n  Loss Fine-tuning for Alzheimer's Disease Diagnosis from MRI", "comments": "Accepted for publication at the MICCAI 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Positron Emission Tomography (PET) is now regarded as the gold standard for\nthe diagnosis of Alzheimer's Disease (AD). However, PET imaging can be\nprohibitive in terms of cost and planning, and is also among the imaging\ntechniques with the highest dosage of radiation. Magnetic Resonance Imaging\n(MRI), in contrast, is more widely available and provides more flexibility when\nsetting the desired image resolution. Unfortunately, the diagnosis of AD using\nMRI is difficult due to the very subtle physiological differences between\nhealthy and AD subjects visible on MRI. As a result, many attempts have been\nmade to synthesize PET images from MR images using generative adversarial\nnetworks (GANs) in the interest of enabling the diagnosis of AD from MR.\nExisting work on PET synthesis from MRI has largely focused on Conditional\nGANs, where MR images are used to generate PET images and subsequently used for\nAD diagnosis. There is no end-to-end training goal. This paper proposes an\nalternative approach to the aforementioned, where AD diagnosis is incorporated\nin the GAN training objective to achieve the best AD classification\nperformance. Different GAN lossesare fine-tuned based on the discriminator\nperformance, and the overall training is stabilized. The proposed network\narchitecture and training regime show state-of-the-art performance for three-\nand four- class AD classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 20:09:35 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Shin", "Hoo-Chang", ""], ["Ihsani", "Alvin", ""], ["Xu", "Ziyue", ""], ["Mandava", "Swetha", ""], ["Sreenivas", "Sharath Turuvekere", ""], ["Forster", "Christopher", ""], ["Cha", "Jiook", ""], ["Initiative", "Alzheimer's Disease Neuroimaging", ""]]}, {"id": "2008.04403", "submitter": "Ibrahim Ahmed", "authors": "Ibrahim Ahmed, Hamed Khorasgani, Gautam Biswas", "title": "Comparison of Model Predictive and Reinforcement Learning Methods for\n  Fault Tolerant Control", "comments": "Published in IFAC SAFEPROCESS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A desirable property in fault-tolerant controllers is adaptability to system\nchanges as they evolve during systems operations. An adaptive controller does\nnot require optimal control policies to be enumerated for possible faults.\nInstead it can approximate one in real-time. We present two adaptive\nfault-tolerant control schemes for a discrete time system based on hierarchical\nreinforcement learning. We compare their performance against a model predictive\ncontroller in presence of sensor noise and persistent faults. The controllers\nare tested on a fuel tank model of a C-130 plane. Our experiments demonstrate\nthat reinforcement learning-based controllers perform more robustly than model\npredictive controllers under faults, partially observable system models, and\nvarying sensor noise levels.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 20:22:15 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Ahmed", "Ibrahim", ""], ["Khorasgani", "Hamed", ""], ["Biswas", "Gautam", ""]]}, {"id": "2008.04407", "submitter": "Ibrahim Ahmed", "authors": "Ibrahim Ahmed, Marcos Qui\\~nones-Grueiro, Gautam Biswas", "title": "Fault-Tolerant Control of Degrading Systems with On-Policy Reinforcement\n  Learning", "comments": "Published in IFAC World Congress 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel adaptive reinforcement learning control approach for fault\ntolerant control of degrading systems that is not preceded by a fault detection\nand diagnosis step. Therefore, \\textit{a priori} knowledge of faults that may\noccur in the system is not required. The adaptive scheme combines online and\noffline learning of the on-policy control method to improve exploration and\nsample efficiency, while guaranteeing stable learning. The offline learning\nphase is performed using a data-driven model of the system, which is frequently\nupdated to track the system's operating conditions. We conduct experiments on\nan aircraft fuel transfer system to demonstrate the effectiveness of our\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 20:42:59 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Ahmed", "Ibrahim", ""], ["Qui\u00f1ones-Grueiro", "Marcos", ""], ["Biswas", "Gautam", ""]]}, {"id": "2008.04419", "submitter": "Prasanna Date", "authors": "Davis Arthur, Prasanna Date", "title": "Balanced k-Means Clustering on an Adiabatic Quantum Computer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adiabatic quantum computers are a promising platform for approximately\nsolving challenging optimization problems. We present a quantum approach to\nsolving the balanced $k$-means clustering training problem on the D-Wave 2000Q\nadiabatic quantum computer. Existing classical approaches scale poorly for\nlarge datasets and only guarantee a locally optimal solution. We show that our\nquantum approach better targets the global solution of the training problem,\nwhile achieving better theoretic scalability on large datasets. We test our\nquantum approach on a number of small problems, and observe clustering\nperformance similar to the best classical algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 21:15:47 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Arthur", "Davis", ""], ["Date", "Prasanna", ""]]}, {"id": "2008.04448", "submitter": "Athar Kharal", "authors": "Athar Kharal", "title": "Explainable Artificial Intelligence Based Fault Diagnosis and Insight\n  Harvesting for Steel Plates Manufacturing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of Industry 4.0, Data Science and Explainable Artificial\nIntelligence (XAI) has received considerable intrest in recent literature.\nHowever, the entry threshold into XAI, in terms of computer coding and the\nrequisite mathematical apparatus, is really high. For fault diagnosis of steel\nplates, this work reports on a methodology of incorporating XAI based insights\ninto the Data Science process of development of high precision classifier.\nUsing Synthetic Minority Oversampling Technique (SMOTE) and notion of medoids,\ninsights from XAI tools viz. Ceteris Peribus profiles, Partial Dependence and\nBreakdown profiles have been harvested. Additionally, insights in the form of\nIF-THEN rules have also been extracted from an optimized Random Forest and\nAssociation Rule Mining. Incorporating all the insights into a single ensemble\nclassifier, a 10 fold cross validated performance of 94% has been achieved. In\nsum total, this work makes three main contributions viz.: methodology based\nupon utilization of medoids and SMOTE, of gleaning insights and incorporating\ninto model development process. Secondly the insights themselves are\ncontribution, as they benefit the human experts of steel manufacturing\nindustry, and thirdly a high precision fault diagnosis classifier has been\ndeveloped.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 23:04:21 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Kharal", "Athar", ""]]}, {"id": "2008.04449", "submitter": "Rosario Cammarota", "authors": "Rosario Cammarota, Matthias Schunter, Anand Rajan, Fabian Boemer,\n  \\'Agnes Kiss, Amos Treiber, Christian Weinert, Thomas Schneider, Emmanuel\n  Stapf, Ahmad-Reza Sadeghi, Daniel Demmler, Huili Chen, Siam Umar Hussain,\n  Sadegh Riazi, Farinaz Koushanfar, Saransh Gupta, Tajan Simunic Rosing,\n  Kamalika Chaudhuri, Hamid Nejatollahi, Nikil Dutt, Mohsen Imani, Kim Laine,\n  Anuj Dubey, Aydin Aysu, Fateme Sadat Hosseini, Chengmo Yang, Eric Wallace,\n  Pamela Norton", "title": "Trustworthy AI Inference Systems: An Industry Research View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.AR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we provide an industry research view for approaching the\ndesign, deployment, and operation of trustworthy Artificial Intelligence (AI)\ninference systems. Such systems provide customers with timely, informed, and\ncustomized inferences to aid their decision, while at the same time utilizing\nappropriate security protection mechanisms for AI models. Additionally, such\nsystems should also use Privacy-Enhancing Technologies (PETs) to protect\ncustomers' data at any time.\n  To approach the subject, we start by introducing trends in AI inference\nsystems. We continue by elaborating on the relationship between Intellectual\nProperty (IP) and private data protection in such systems. Regarding the\nprotection mechanisms, we survey the security and privacy building blocks\ninstrumental in designing, building, deploying, and operating private AI\ninference systems. For example, we highlight opportunities and challenges in AI\nsystems using trusted execution environments combined with more recent advances\nin cryptographic techniques to protect data in use. Finally, we outline areas\nof further development that require the global collective attention of\nindustry, academia, and government researchers to sustain the operation of\ntrustworthy AI inference systems.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 23:05:55 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Cammarota", "Rosario", ""], ["Schunter", "Matthias", ""], ["Rajan", "Anand", ""], ["Boemer", "Fabian", ""], ["Kiss", "\u00c1gnes", ""], ["Treiber", "Amos", ""], ["Weinert", "Christian", ""], ["Schneider", "Thomas", ""], ["Stapf", "Emmanuel", ""], ["Sadeghi", "Ahmad-Reza", ""], ["Demmler", "Daniel", ""], ["Chen", "Huili", ""], ["Hussain", "Siam Umar", ""], ["Riazi", "Sadegh", ""], ["Koushanfar", "Farinaz", ""], ["Gupta", "Saransh", ""], ["Rosing", "Tajan Simunic", ""], ["Chaudhuri", "Kamalika", ""], ["Nejatollahi", "Hamid", ""], ["Dutt", "Nikil", ""], ["Imani", "Mohsen", ""], ["Laine", "Kim", ""], ["Dubey", "Anuj", ""], ["Aysu", "Aydin", ""], ["Hosseini", "Fateme Sadat", ""], ["Yang", "Chengmo", ""], ["Wallace", "Eric", ""], ["Norton", "Pamela", ""]]}, {"id": "2008.04452", "submitter": "Erdem B{\\i}y{\\i}k", "authors": "Zheqing Zhu, Erdem B{\\i}y{\\i}k, Dorsa Sadigh", "title": "Multi-Agent Safe Planning with Gaussian Processes", "comments": "9 pages, 5 figures. Published at IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS) 2020", "journal-ref": null, "doi": "10.1109/IROS45743.2020.9341169", "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent safe systems have become an increasingly important area of study\nas we can now easily have multiple AI-powered systems operating together. In\nsuch settings, we need to ensure the safety of not only each individual agent,\nbut also the overall system. In this paper, we introduce a novel multi-agent\nsafe learning algorithm that enables decentralized safe navigation when there\nare multiple different agents in the environment. This algorithm makes mild\nassumptions about other agents and is trained in a decentralized fashion, i.e.\nwith very little prior knowledge about other agents' policies. Experiments show\nour algorithm performs well with the robots running other algorithms when\noptimizing various objectives.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 23:09:05 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Zhu", "Zheqing", ""], ["B\u0131y\u0131k", "Erdem", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "2008.04470", "submitter": "M. Umut Isik", "authors": "Umut Isik, Ritwik Giri, Neerad Phansalkar, Jean-Marc Valin, Karim\n  Helwani, Arvindh Krishnaswamy", "title": "PoCoNet: Better Speech Enhancement with Frequency-Positional Embeddings,\n  Semi-Supervised Conversational Data, and Biased Loss", "comments": "5 pages, 3 figures, INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.NE cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network applications generally benefit from larger-sized models, but\nfor current speech enhancement models, larger scale networks often suffer from\ndecreased robustness to the variety of real-world use cases beyond what is\nencountered in training data. We introduce several innovations that lead to\nbetter large neural networks for speech enhancement. The novel PoCoNet\narchitecture is a convolutional neural network that, with the use of\nfrequency-positional embeddings, is able to more efficiently build\nfrequency-dependent features in the early layers. A semi-supervised method\nhelps increase the amount of conversational training data by pre-enhancing\nnoisy datasets, improving performance on real recordings. A new loss function\nbiased towards preserving speech quality helps the optimization better match\nhuman perceptual opinions on speech quality. Ablation experiments and objective\nand human opinion metrics show the benefits of the proposed improvements.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 01:24:45 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Isik", "Umut", ""], ["Giri", "Ritwik", ""], ["Phansalkar", "Neerad", ""], ["Valin", "Jean-Marc", ""], ["Helwani", "Karim", ""], ["Krishnaswamy", "Arvindh", ""]]}, {"id": "2008.04473", "submitter": "Yu-Min Chung", "authors": "Whitney K. Huang, Yu-Min Chung, Yu-Bo Wang, Jeff E. Mandel, and\n  Hau-Tieng Wu", "title": "Airflow recovery from thoracic and abdominal movements using\n  Synchrosqueezing Transform and Locally Stationary Gaussian Process Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Airflow signal encodes rich information about respiratory system. While the\ngold standard for measuring airflow is to use a spirometer with an occlusive\nseal, this is not practical for ambulatory monitoring of patients. Advances in\nsensor technology have made measurement of motion of the thorax and abdomen\nfeasible with small inexpensive devices, but estimation of airflow from these\ntime series is challenging. We propose to use the nonlinear-type time-frequency\nanalysis tool, synchrosqueezing transform, to properly represent the thoracic\nand abdominal movement signals as the features, which are used to recover the\nairflow by the locally stationary Gaussian process. We show that, using a\ndataset that contains respiratory signals under normal sleep conditions, an\naccurate prediction can be achieved by fitting the proposed model in the\nfeature space both in the intra- and inter-subject setups. We also apply our\nmethod to a more challenging case, where subjects under general anesthesia\nunderwent transitions from pressure support to unassisted ventilation to\nfurther demonstrate the utility of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 01:37:38 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Huang", "Whitney K.", ""], ["Chung", "Yu-Min", ""], ["Wang", "Yu-Bo", ""], ["Mandel", "Jeff E.", ""], ["Wu", "Hau-Tieng", ""]]}, {"id": "2008.04481", "submitter": "Xi Chen", "authors": "Xi Chen and Songyang Zhang and Dandan Song and Peng Ouyang and Shouyi\n  Yin", "title": "Transformer with Bidirectional Decoder for Speech Recognition", "comments": "Accepted by InterSpeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attention-based models have made tremendous progress on end-to-end automatic\nspeech recognition(ASR) recently. However, the conventional transformer-based\napproaches usually generate the sequence results token by token from left to\nright, leaving the right-to-left contexts unexploited. In this work, we\nintroduce a bidirectional speech transformer to utilize the different\ndirectional contexts simultaneously. Specifically, the outputs of our proposed\ntransformer include a left-to-right target, and a right-to-left target. In\ninference stage, we use the introduced bidirectional beam search method, which\ncan not only generate left-to-right candidates but also generate right-to-left\ncandidates, and determine the best hypothesis by the score.\n  To demonstrate our proposed speech transformer with a bidirectional\ndecoder(STBD), we conduct extensive experiments on the AISHELL-1 dataset. The\nresults of experiments show that STBD achieves a 3.6\\% relative CER\nreduction(CERR) over the unidirectional speech transformer baseline. Besides,\nthe strongest model in this paper called STBD-Big can achieve 6.64\\% CER on the\ntest set, without language model rescoring and any extra data augmentation\nstrategies.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 02:12:42 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Chen", "Xi", ""], ["Zhang", "Songyang", ""], ["Song", "Dandan", ""], ["Ouyang", "Peng", ""], ["Yin", "Shouyi", ""]]}, {"id": "2008.04489", "submitter": "Jack Goetz", "authors": "Jack Goetz, Ambuj Tewari", "title": "Federated Learning via Synthetic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning allows for the training of a model using data on multiple\nclients without the clients transmitting that raw data. However the standard\nmethod is to transmit model parameters (or updates), which for modern neural\nnetworks can be on the scale of millions of parameters, inflicting significant\ncomputational costs on the clients. We propose a method for federated learning\nwhere instead of transmitting a gradient update back to the server, we instead\ntransmit a small amount of synthetic `data'. We describe the procedure and show\nsome experimental results suggesting this procedure has potential, providing\nmore than an order of magnitude reduction in communication costs with minimal\nmodel degradation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 02:41:12 GMT"}, {"version": "v2", "created": "Sat, 26 Sep 2020 17:54:35 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Goetz", "Jack", ""], ["Tewari", "Ambuj", ""]]}, {"id": "2008.04495", "submitter": "Jinyuan Jia", "authors": "Jinyuan Jia and Xiaoyu Cao and Neil Zhenqiang Gong", "title": "Intrinsic Certified Robustness of Bagging against Data Poisoning Attacks", "comments": "Accepted by AAAI'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In a \\emph{data poisoning attack}, an attacker modifies, deletes, and/or\ninserts some training examples to corrupt the learnt machine learning model.\n\\emph{Bootstrap Aggregating (bagging)} is a well-known ensemble learning\nmethod, which trains multiple base models on random subsamples of a training\ndataset using a base learning algorithm and uses majority vote to predict\nlabels of testing examples. We prove the intrinsic certified robustness of\nbagging against data poisoning attacks. Specifically, we show that bagging with\nan arbitrary base learning algorithm provably predicts the same label for a\ntesting example when the number of modified, deleted, and/or inserted training\nexamples is bounded by a threshold. Moreover, we show that our derived\nthreshold is tight if no assumptions on the base learning algorithm are made.\nWe evaluate our method on MNIST and CIFAR10. For instance, our method achieves\na certified accuracy of $91.1\\%$ on MNIST when arbitrarily modifying, deleting,\nand/or inserting 100 training examples. Code is available at:\n\\url{https://github.com/jjy1994/BaggingCertifyDataPoisoning}.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 03:12:42 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 01:48:26 GMT"}, {"version": "v3", "created": "Fri, 4 Sep 2020 00:42:43 GMT"}, {"version": "v4", "created": "Wed, 23 Sep 2020 18:49:26 GMT"}, {"version": "v5", "created": "Mon, 5 Oct 2020 20:41:55 GMT"}, {"version": "v6", "created": "Tue, 8 Dec 2020 16:17:16 GMT"}, {"version": "v7", "created": "Wed, 9 Dec 2020 21:44:40 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Jia", "Jinyuan", ""], ["Cao", "Xiaoyu", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "2008.04500", "submitter": "Jingyi Wang", "authors": "Jiahao Ding and Jingyi Wang and Guannan Liang and Jinbo Bi and Miao\n  Pan", "title": "Towards Plausible Differentially Private ADMM Based Distributed Machine\n  Learning", "comments": "Comments: Accepted for publication in CIKM'20", "journal-ref": null, "doi": "10.1145/3340531.3411860", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Alternating Direction Method of Multipliers (ADMM) and its distributed\nversion have been widely used in machine learning. In the iterations of ADMM,\nmodel updates using local private data and model exchanges among agents impose\ncritical privacy concerns. Despite some pioneering works to relieve such\nconcerns, differentially private ADMM still confronts many research challenges.\nFor example, the guarantee of differential privacy (DP) relies on the premise\nthat the optimality of each local problem can be perfectly attained in each\nADMM iteration, which may never happen in practice. The model trained by DP\nADMM may have low prediction accuracy. In this paper, we address these concerns\nby proposing a novel (Improved) Plausible differentially Private ADMM\nalgorithm, called PP-ADMM and IPP-ADMM. In PP-ADMM, each agent approximately\nsolves a perturbed optimization problem that is formulated from its local\nprivate data in an iteration, and then perturbs the approximate solution with\nGaussian noise to provide the DP guarantee. To further improve the model\naccuracy and convergence, an improved version IPP-ADMM adopts sparse vector\ntechnique (SVT) to determine if an agent should update its neighbors with the\ncurrent perturbed solution. The agent calculates the difference of the current\nsolution from that in the last iteration, and if the difference is larger than\na threshold, it passes the solution to neighbors; or otherwise the solution\nwill be discarded. Moreover, we propose to track the total privacy loss under\nthe zero-concentrated DP (zCDP) and provide a generalization performance\nanalysis. Experiments on real-world datasets demonstrate that under the same\nprivacy guarantee, the proposed algorithms are superior to the state of the art\nin terms of model accuracy and convergence rate.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 03:40:55 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Ding", "Jiahao", ""], ["Wang", "Jingyi", ""], ["Liang", "Guannan", ""], ["Bi", "Jinbo", ""], ["Pan", "Miao", ""]]}, {"id": "2008.04504", "submitter": "Li Jiacheng", "authors": "Jiacheng Li, Siliang Tang, Juncheng Li, Jun Xiao, Fei Wu, Shiliang Pu,\n  Yueting Zhuang", "title": "Topic Adaptation and Prototype Encoding for Few-Shot Visual Storytelling", "comments": "ACM Multimedia 2020", "journal-ref": null, "doi": "10.1145/3394171.3413886", "report-no": null, "categories": "cs.CL cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Storytelling~(VIST) is a task to tell a narrative story about a\ncertain topic according to the given photo stream. The existing studies focus\non designing complex models, which rely on a huge amount of human-annotated\ndata. However, the annotation of VIST is extremely costly and many topics\ncannot be covered in the training dataset due to the long-tail topic\ndistribution. In this paper, we focus on enhancing the generalization ability\nof the VIST model by considering the few-shot setting. Inspired by the way\nhumans tell a story, we propose a topic adaptive storyteller to model the\nability of inter-topic generalization. In practice, we apply the gradient-based\nmeta-learning algorithm on multi-modal seq2seq models to endow the model the\nability to adapt quickly from topic to topic. Besides, We further propose a\nprototype encoding structure to model the ability of intra-topic derivation.\nSpecifically, we encode and restore the few training story text to serve as a\nreference to guide the generation at inference time. Experimental results show\nthat topic adaptation and prototype encoding structure mutually bring benefit\nto the few-shot model on BLEU and METEOR metric. The further case study shows\nthat the stories generated after few-shot adaptation are more relative and\nexpressive.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 03:55:11 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Li", "Jiacheng", ""], ["Tang", "Siliang", ""], ["Li", "Juncheng", ""], ["Xiao", "Jun", ""], ["Wu", "Fei", ""], ["Pu", "Shiliang", ""], ["Zhuang", "Yueting", ""]]}, {"id": "2008.04510", "submitter": "Han Zhao", "authors": "Han Zhao, Junjie Hu, Andrej Risteski", "title": "On Learning Language-Invariant Representations for Universal Machine\n  Translation", "comments": "Appeared in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of universal machine translation is to learn to translate between\nany pair of languages, given a corpus of paired translated documents for\n\\emph{a small subset} of all pairs of languages. Despite impressive empirical\nresults and an increasing interest in massively multilingual models,\ntheoretical analysis on translation errors made by such universal machine\ntranslation models is only nascent. In this paper, we formally prove certain\nimpossibilities of this endeavour in general, as well as prove positive results\nin the presence of additional (but natural) structure of data.\n  For the former, we derive a lower bound on the translation error in the\nmany-to-many translation setting, which shows that any algorithm aiming to\nlearn shared sentence representations among multiple language pairs has to make\na large translation error on at least one of the translation tasks, if no\nassumption on the structure of the languages is made. For the latter, we show\nthat if the paired documents in the corpus follow a natural\n\\emph{encoder-decoder} generative process, we can expect a natural notion of\n``generalization'': a linear number of language pairs, rather than quadratic,\nsuffices to learn a good representation. Our theory also explains what kinds of\nconnection graphs between pairs of languages are better suited: ones with\nlonger paths result in worse sample complexity in terms of the total number of\ndocuments per language pair needed. We believe our theoretical insights and\nimplications contribute to the future algorithmic design of universal machine\ntranslation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 04:45:33 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Zhao", "Han", ""], ["Hu", "Junjie", ""], ["Risteski", "Andrej", ""]]}, {"id": "2008.04527", "submitter": "Shreyas Ramoji", "authors": "Shreyas Ramoji, Prashant Krishnan, Sriram Ganapathy", "title": "Neural PLDA Modeling for End-to-End Speaker Verification", "comments": "Accepted in Interspeech 2020. GitHub Implementation Repos:\n  https://github.com/iiscleap/E2E-NPLDA and\n  https://github.com/iiscleap/NeuralPlda", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning models have made significant advances in supervised\nclassification problems, the application of these models for out-of-set\nverification tasks like speaker recognition has been limited to deriving\nfeature embeddings. The state-of-the-art x-vector PLDA based speaker\nverification systems use a generative model based on probabilistic linear\ndiscriminant analysis (PLDA) for computing the verification score. Recently, we\nhad proposed a neural network approach for backend modeling in speaker\nverification called the neural PLDA (NPLDA) where the likelihood ratio score of\nthe generative PLDA model is posed as a discriminative similarity function and\nthe learnable parameters of the score function are optimized using a\nverification cost. In this paper, we extend this work to achieve joint\noptimization of the embedding neural network (x-vector network) with the NPLDA\nnetwork in an end-to-end (E2E) fashion. This proposed end-to-end model is\noptimized directly from the acoustic features with a verification cost function\nand during testing, the model directly outputs the likelihood ratio score. With\nvarious experiments using the NIST speaker recognition evaluation (SRE) 2018\nand 2019 datasets, we show that the proposed E2E model improves significantly\nover the x-vector PLDA baseline speaker verification system.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 05:54:54 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Ramoji", "Shreyas", ""], ["Krishnan", "Prashant", ""], ["Ganapathy", "Sriram", ""]]}, {"id": "2008.04538", "submitter": "Kenta Nagura", "authors": "Kenta Nagura, Song Bian and Takashi Sato", "title": "FedNNNN: Norm-Normalized Neural Network Aggregation for Fast and\n  Accurate Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a distributed learning protocol in which a server\nneeds to aggregate a set of models learned some independent clients to proceed\nthe learning process. At present, model averaging, known as FedAvg, is one of\nthe most widely adapted aggregation techniques. However, it is known to yield\nthe models with degraded prediction accuracy and slow convergence. In this\nwork, we find out that averaging models from different clients significantly\ndiminishes the norm of the update vectors, resulting in slow learning rate and\nlow prediction accuracy. Therefore, we propose a new aggregation method called\nFedNNNN. Instead of simple model averaging, we adjust the norm of the update\nvector and introduce momentum control techniques to improve the aggregation\neffectiveness of FL. As a demonstration, we evaluate FedNNNN on multiple\ndatasets and scenarios with different neural network models, and observe up to\n5.4% accuracy improvement.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 06:21:15 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Nagura", "Kenta", ""], ["Bian", "Song", ""], ["Sato", "Takashi", ""]]}, {"id": "2008.04542", "submitter": "Cui Chenggang", "authors": "Chenggang Cui, Nan Yan, Chuanlin Zhang", "title": "An Intelligent Control Strategy for buck DC-DC Converter via Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As a typical switching power supply, the DC-DC converter has been widely\napplied in DC microgrid. Due to the variation of renewable energy generation,\nresearch and design of DC-DC converter control algorithm with outstanding\ndynamic characteristics has significant theoretical and practical application\nvalue. To mitigate the bus voltage stability issue in DC microgrid, an\ninnovative intelligent control strategy for buck DC-DC converter with constant\npower loads (CPLs) via deep reinforcement learning algorithm is constructed for\nthe first time. In this article, a Markov Decision Process (MDP) model and the\ndeep Q network (DQN) algorithm are defined for DC-DC converter. A model-free\nbased deep reinforcement learning (DRL) control strategy is appropriately\ndesigned to adjust the agent-environment interaction through the\nrewards/penalties mechanism towards achieving converge to nominal voltage. The\nagent makes approximate decisions by extracting the high-dimensional feature of\ncomplex power systems without any prior knowledge. Eventually, the simulation\ncomparison results demonstrate that the proposed controller has stronger\nself-learning and self-optimization capabilities under the different scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 06:38:53 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Cui", "Chenggang", ""], ["Yan", "Nan", ""], ["Zhang", "Chuanlin", ""]]}, {"id": "2008.04548", "submitter": "Haonan Lu", "authors": "Haonan Lu, Hailin Hu", "title": "DensE: An Enhanced Non-Abelian Group Representation for Knowledge Graph\n  Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing the composition patterns of relations is a vital task in knowledge\ngraph completion. It also serves as a fundamental step towards multi-hop\nreasoning over learned knowledge. Previously, rotation-based translational\nmethods, e.g., RotatE, have been developed to model composite relations using\nthe product of a series of complex-valued diagonal matrices. However, RotatE\nmakes several oversimplified assumptions on the composition patterns, forcing\nthe relations to be commutative, independent from entities and fixed in scale.\nTo tackle this problem, we have developed a novel knowledge graph embedding\nmethod, named DensE, to provide sufficient modeling capacity for complex\ncomposition patterns. In particular, our method decomposes each relation into\nan SO(3) group-based rotation operator and a scaling operator in the three\ndimensional (3-D) Euclidean space. The advantages of our method are twofold:\n(1) For composite relations, the corresponding diagonal relation matrices can\nbe non-commutative and related with entity embeddings; (2) It extends the\nconcept of RotatE to a more expressive setting with lower model complexity and\npreserves the direct geometrical interpretations, which reveals how relations\nwith distinct patterns (i.e., symmetry/anti-symmetry, inversion and\ncomposition) are modeled. Experimental results on multiple benchmark knowledge\ngraphs show that DensE outperforms the current state-of-the-art models for\nmissing link prediction, especially on composite relations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 06:45:50 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Lu", "Haonan", ""], ["Hu", "Hailin", ""]]}, {"id": "2008.04555", "submitter": "Andi Han", "authors": "Andi Han, Junbin Gao", "title": "Riemannian stochastic recursive momentum method for non-convex\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a stochastic recursive momentum method for Riemannian non-convex\noptimization that achieves a near-optimal complexity of\n$\\tilde{\\mathcal{O}}(\\epsilon^{-3})$ to find $\\epsilon$-approximate solution\nwith one sample. That is, our method requires $\\mathcal{O}(1)$ gradient\nevaluations per iteration and does not require restarting with a large batch\ngradient, which is commonly used to obtain the faster rate. Extensive\nexperiment results demonstrate the superiority of our proposed algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 07:05:58 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Han", "Andi", ""], ["Gao", "Junbin", ""]]}, {"id": "2008.04563", "submitter": "Masahiro Sato", "authors": "Masahiro Sato, Sho Takemori, Janmajay Singh, Tomoko Ohkuma", "title": "Unbiased Learning for the Causal Effect of Recommendation", "comments": "accepted at RecSys 2020, updated several experiments", "journal-ref": null, "doi": "10.1145/3383313.3412261", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing users' positive interactions, such as purchases or clicks, is an\nimportant objective of recommender systems. Recommenders typically aim to\nselect items that users will interact with. If the recommended items are\npurchased, an increase in sales is expected. However, the items could have been\npurchased even without recommendation. Thus, we want to recommend items that\nresults in purchases caused by recommendation. This can be formulated as a\nranking problem in terms of the causal effect. Despite its importance, this\nproblem has not been well explored in the related research. It is challenging\nbecause the ground truth of causal effect is unobservable, and estimating the\ncausal effect is prone to the bias arising from currently deployed\nrecommenders. This paper proposes an unbiased learning framework for the causal\neffect of recommendation. Based on the inverse propensity scoring technique,\nthe proposed framework first constructs unbiased estimators for ranking\nmetrics. Then, it conducts empirical risk minimization on the estimators with\npropensity capping, which reduces variance under finite training samples. Based\non the framework, we develop an unbiased learning method for the causal effect\nextension of a ranking metric. We theoretically analyze the unbiasedness of the\nproposed method and empirically demonstrate that the proposed method\noutperforms other biased learning methods in various settings.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 07:30:44 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 04:34:11 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2020 11:15:39 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Sato", "Masahiro", ""], ["Takemori", "Sho", ""], ["Singh", "Janmajay", ""], ["Ohkuma", "Tomoko", ""]]}, {"id": "2008.04567", "submitter": "Yongchao Liu", "authors": "Yongchao Liu, Yue Jin, Yong Chen, Teng Teng, Hang Ou, Rui Zhao, Yao\n  Zhang", "title": "Woodpecker-DL: Accelerating Deep Neural Networks via Hardware-Aware\n  Multifaceted Optimizations", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accelerating deep model training and inference is crucial in practice.\nExisting deep learning frameworks usually concentrate on optimizing training\nspeed and pay fewer attentions to inference-specific optimizations. Actually,\nmodel inference differs from training in terms of computation, e.g. parameters\nare refreshed each gradient update step during training, but kept invariant\nduring inference. These special characteristics of model inference open new\nopportunities for its optimization. In this paper, we propose a hardware-aware\noptimization framework, namely Woodpecker-DL (WPK), to accelerate inference by\ntaking advantage of multiple joint optimizations from the perspectives of graph\noptimization, automated searches, domain-specific language (DSL) compiler\ntechniques and system-level exploration. In WPK, we investigated two new\nautomated search approaches based on genetic algorithm and reinforcement\nlearning, respectively, to hunt the best operator code configurations targeting\nspecific hardware. A customized DSL compiler is further attached to these\nsearch algorithms to generate efficient codes. To create an optimized inference\nplan, WPK systematically explores high-speed operator implementations from\nthird-party libraries besides our automatically generated codes and singles out\nthe best implementation per operator for use. Extensive experiments\ndemonstrated that on a Tesla P100 GPU, we can achieve the maximum speedup of\n5.40 over cuDNN and 1.63 over TVM on individual convolution operators, and run\nup to 1.18 times faster than TensorRT for end-to-end model inference.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 07:50:34 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Liu", "Yongchao", ""], ["Jin", "Yue", ""], ["Chen", "Yong", ""], ["Teng", "Teng", ""], ["Ou", "Hang", ""], ["Zhao", "Rui", ""], ["Zhang", "Yao", ""]]}, {"id": "2008.04572", "submitter": "Megha Srivastava", "authors": "Megha Srivastava, Besmira Nushi, Ece Kamar, Shital Shah, Eric Horvitz", "title": "An Empirical Analysis of Backward Compatibility in Machine Learning\n  Systems", "comments": "KDD 2020, 9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications of machine learning (ML), updates are performed with the\ngoal of enhancing model performance. However, current practices for updating\nmodels rely solely on isolated, aggregate performance analyses, overlooking\nimportant dependencies, expectations, and needs in real-world deployments. We\nconsider how updates, intended to improve ML models, can introduce new errors\nthat can significantly affect downstream systems and users. For example,\nupdates in models used in cloud-based classification services, such as image\nrecognition, can cause unexpected erroneous behavior in systems that make calls\nto the services. Prior work has shown the importance of \"backward\ncompatibility\" for maintaining human trust. We study challenges with backward\ncompatibility across different ML architectures and datasets, focusing on\ncommon settings including data shifts with structured noise and ML employed in\ninferential pipelines. Our results show that (i) compatibility issues arise\neven without data shift due to optimization stochasticity, (ii) training on\nlarge-scale noisy datasets often results in significant decreases in backward\ncompatibility even when model accuracy increases, and (iii) distributions of\nincompatible points align with noise bias, motivating the need for\ncompatibility aware de-noising and robustness methods.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 08:10:58 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Srivastava", "Megha", ""], ["Nushi", "Besmira", ""], ["Kamar", "Ece", ""], ["Shah", "Shital", ""], ["Horvitz", "Eric", ""]]}, {"id": "2008.04574", "submitter": "Ravichander Vipperla", "authors": "Ravichander Vipperla, Sangjun Park, Kihyun Choo, Samin Ishtiaq,\n  Kyoungbo Min, Sourav Bhattacharya, Abhinav Mehrotra, Alberto Gil C. P. Ramos\n  and Nicholas D. Lane", "title": "Bunched LPCNet : Vocoder for Low-cost Neural Text-To-Speech Systems", "comments": "Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  LPCNet is an efficient vocoder that combines linear prediction and deep\nneural network modules to keep the computational complexity low. In this work,\nwe present two techniques to further reduce it's complexity, aiming for a\nlow-cost LPCNet vocoder-based neural Text-to-Speech (TTS) System. These\ntechniques are: 1) Sample-bunching, which allows LPCNet to generate more than\none audio sample per inference; and 2) Bit-bunching, which reduces the\ncomputations in the final layer of LPCNet. With the proposed bunching\ntechniques, LPCNet, in conjunction with a Deep Convolutional TTS (DCTTS)\nacoustic model, shows a 2.19x improvement over the baseline run-time when\nrunning on a mobile device, with a less than 0.1 decrease in TTS mean opinion\nscore (MOS).\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 08:15:45 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Vipperla", "Ravichander", ""], ["Park", "Sangjun", ""], ["Choo", "Kihyun", ""], ["Ishtiaq", "Samin", ""], ["Min", "Kyoungbo", ""], ["Bhattacharya", "Sourav", ""], ["Mehrotra", "Abhinav", ""], ["Ramos", "Alberto Gil C. P.", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "2008.04575", "submitter": "Peter Meltzer", "authors": "Peter Meltzer, Marcelo Daniel Gutierrez Mallea and Peter J. Bentley", "title": "PiNet: Attention Pooling for Graph Classification", "comments": "4 pages, 3 figures 1 table", "journal-ref": "Neural Information Processing Systems (NIPS): Graph Representation\n  Learning Workshop 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose PiNet, a generalised differentiable attention-based pooling\nmechanism for utilising graph convolution operations for graph level\nclassification. We demonstrate high sample efficiency and superior performance\nover other graph neural networks in distinguishing isomorphic graph classes, as\nwell as competitive results with state of the art methods on standard\nchemo-informatics datasets.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 08:17:14 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Meltzer", "Peter", ""], ["Mallea", "Marcelo Daniel Gutierrez", ""], ["Bentley", "Peter J.", ""]]}, {"id": "2008.04589", "submitter": "Daniel Tanneberg", "authors": "Leon Keller, Daniel Tanneberg, Svenja Stark, Jan Peters", "title": "Model-Based Quality-Diversity Search for Efficient Robot Learning", "comments": "IEEE/RSJ International Conference on Intelligent Robots and Systems\n  (IROS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent progress in robot learning, it still remains a challenge to\nprogram a robot to deal with open-ended object manipulation tasks. One approach\nthat was recently used to autonomously generate a repertoire of diverse skills\nis a novelty based Quality-Diversity~(QD) algorithm. However, as most\nevolutionary algorithms, QD suffers from sample-inefficiency and, thus, it is\nchallenging to apply it in real-world scenarios. This paper tackles this\nproblem by integrating a neural network that predicts the behavior of the\nperturbed parameters into a novelty based QD algorithm. In the proposed\nModel-based Quality-Diversity search (M-QD), the network is trained\nconcurrently to the repertoire and is used to avoid executing unpromising\nactions in the novelty search process. Furthermore, it is used to adapt the\nskills of the final repertoire in order to generalize the skills to different\nscenarios. Our experiments show that enhancing a QD algorithm with such a\nforward model improves the sample-efficiency and performance of the\nevolutionary process and the skill adaptation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 09:02:18 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Keller", "Leon", ""], ["Tanneberg", "Daniel", ""], ["Stark", "Svenja", ""], ["Peters", "Jan", ""]]}, {"id": "2008.04590", "submitter": "Steffen Illium", "authors": "Steffen Illium, Robert M\\\"uller, Andreas Sedlmeier and Claudia\n  Linnhoff-Popien", "title": "Surgical Mask Detection with Convolutional Neural Networks and Data\n  Augmentations on Spectrograms", "comments": "5 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CV cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many fields of research, labeled datasets are hard to acquire. This is\nwhere data augmentation promises to overcome the lack of training data in the\ncontext of neural network engineering and classification tasks. The idea here\nis to reduce model over-fitting to the feature distribution of a small\nunder-descriptive training dataset. We try to evaluate such data augmentation\ntechniques to gather insights in the performance boost they provide for several\nconvolutional neural networks on mel-spectrogram representations of audio data.\nWe show the impact of data augmentation on the binary classification task of\nsurgical mask detection in samples of human voice (ComParE Challenge 2020).\nAlso we consider four varying architectures to account for augmentation\nrobustness. Results show that most of the baselines given by ComParE are\noutperformed.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 09:02:47 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Illium", "Steffen", ""], ["M\u00fcller", "Robert", ""], ["Sedlmeier", "Andreas", ""], ["Linnhoff-Popien", "Claudia", ""]]}, {"id": "2008.04612", "submitter": "Yehuda Afek Prof", "authors": "Shahar Azulay, Lior Raz, Amir Globerson, Tomer Koren, Yehuda Afek", "title": "Holdout SGD: Byzantine Tolerant Federated Learning", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a new distributed Byzantine tolerant federated learning\nalgorithm, HoldOut SGD, for Stochastic Gradient Descent (SGD) optimization.\nHoldOut SGD uses the well known machine learning technique of holdout\nestimation, in a distributed fashion, in order to select parameter updates that\nare likely to lead to models with low loss values. This makes it more effective\nat discarding Byzantine workers inputs than existing methods that eliminate\noutliers in the parameter-space of the learned model. HoldOut SGD first\nrandomly selects a set of workers that use their private data in order to\npropose gradient updates. Next, a voting committee of workers is randomly\nselected, and each voter uses its private data as holdout data, in order to\nselect the best proposals via a voting scheme. We propose two possible\nmechanisms for the coordination of workers in the distributed computation of\nHoldOut SGD. The first uses a truthful central server and corresponds to the\ntypical setting of current federated learning. The second is fully distributed\nand requires no central server, paving the way to fully decentralized federated\nlearning. The fully distributed version implements HoldOut SGD via ideas from\nthe blockchain domain, and specifically the Algorand committee selection and\nconsensus processes. We provide formal guarantees for the HoldOut SGD process\nin terms of its convergence to the optimal model, and its level of resilience\nto the fraction of Byzantine workers. Empirical evaluation shows that HoldOut\nSGD is Byzantine-resilient and efficiently converges to an effectual model for\ndeep-learning tasks, as long as the total number of participating workers is\nlarge and the fraction of Byzantine workers is less than half (<1/3 for the\nfully distributed variant).\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 10:16:37 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Azulay", "Shahar", ""], ["Raz", "Lior", ""], ["Globerson", "Amir", ""], ["Koren", "Tomer", ""], ["Afek", "Yehuda", ""]]}, {"id": "2008.04636", "submitter": "Anna Glazkova", "authors": "Anna Glazkova", "title": "A Comparison of Synthetic Oversampling Methods for Multi-class Text\n  Classification", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The authors compared oversampling methods for the problem of multi-class\ntopic classification. The SMOTE algorithm underlies one of the most popular\noversampling methods. It consists in choosing two examples of a minority class\nand generating a new example based on them. In the paper, the authors compared\nthe basic SMOTE method with its two modifications (Borderline SMOTE and ADASYN)\nand random oversampling technique on the example of one of text classification\ntasks. The paper discusses the k-nearest neighbor algorithm, the support vector\nmachine algorithm and three types of neural networks (feedforward network, long\nshort-term memory (LSTM) and bidirectional LSTM). The authors combine these\nmachine learning algorithms with different text representations and compared\nsynthetic oversampling methods. In most cases, the use of oversampling\ntechniques can significantly improve the quality of classification. The authors\nconclude that for this task, the quality of the KNN and SVM algorithms is more\ninfluenced by class imbalance than neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 11:41:53 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Glazkova", "Anna", ""]]}, {"id": "2008.04646", "submitter": "Willi Menapace", "authors": "Willi Menapace, St\\'ephane Lathuili\\`ere and Elisa Ricci", "title": "Learning to Cluster under Domain Shift", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While unsupervised domain adaptation methods based on deep architectures have\nachieved remarkable success in many computer vision tasks, they rely on a\nstrong assumption, i.e. labeled source data must be available. In this work we\novercome this assumption and we address the problem of transferring knowledge\nfrom a source to a target domain when both source and target data have no\nannotations. Inspired by recent works on deep clustering, our approach\nleverages information from data gathered from multiple source domains to build\na domain-agnostic clustering model which is then refined at inference time when\ntarget data become available. Specifically, at training time we propose to\noptimize a novel information-theoretic loss which, coupled with\ndomain-alignment layers, ensures that our model learns to correctly discover\nsemantic labels while discarding domain-specific features. Importantly, our\narchitecture design ensures that at inference time the resulting source model\ncan be effectively adapted to the target domain without having access to source\ndata, thanks to feature alignment and self-supervision. We evaluate the\nproposed approach in a variety of settings, considering several domain\nadaptation benchmarks and we show that our method is able to automatically\ndiscover relevant semantic information even in presence of few target samples\nand yields state-of-the-art results on multiple domain adaptation benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 12:03:01 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Menapace", "Willi", ""], ["Lathuili\u00e8re", "St\u00e9phane", ""], ["Ricci", "Elisa", ""]]}, {"id": "2008.04662", "submitter": "Yang Yang", "authors": "Yang Yang, Zhen-Qiang Sun, Hui Xiong, Jian Yang", "title": "S2OSC: A Holistic Semi-Supervised Approach for Open Set Classification", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open set classification (OSC) tackles the problem of determining whether the\ndata are in-class or out-of-class during inference, when only provided with a\nset of in-class examples at training time. Traditional OSC methods usually\ntrain discriminative or generative models with in-class data, then utilize the\npre-trained models to classify test data directly. However, these methods\nalways suffer from embedding confusion problem, i.e., partial out-of-class\ninstances are mixed with in-class ones of similar semantics, making it\ndifficult to classify. To solve this problem, we unify semi-supervised learning\nto develop a novel OSC algorithm, S2OSC, that incorporates out-of-class\ninstances filtering and model re-training in a transductive manner. In detail,\ngiven a pool of newly coming test data, S2OSC firstly filters distinct\nout-of-class instances using the pre-trained model, and annotates super-class\nfor them. Then, S2OSC trains a holistic classification model by combing\nin-class and out-of-class labeled data and remaining unlabeled test data in\nsemi-supervised paradigm, which also integrates pre-trained model for knowledge\ndistillation to further separate mixed instances. Despite its simplicity, the\nexperimental results show that S2OSC achieves state-of-the-art performance\nacross a variety of OSC tasks, including 85.4% of F1 on CIFAR-10 with only 300\npseudo-labels. We also demonstrate how S2OSC can be expanded to incremental OSC\nsetting effectively with streaming data.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 12:26:00 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Yang", "Yang", ""], ["Sun", "Zhen-Qiang", ""], ["Xiong", "Hui", ""], ["Yang", "Jian", ""]]}, {"id": "2008.04679", "submitter": "Brian Groenke", "authors": "Brian Groenke, Luke Madaus, Claire Monteleoni", "title": "ClimAlign: Unsupervised statistical downscaling of climate variables via\n  normalizing flows", "comments": "8 pages, submitted as journal paper to the 10th International\n  Conference on Climate Informatics (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Downscaling is a landmark task in climate science and meteorology in which\nthe goal is to use coarse scale, spatio-temporal data to infer values at finer\nscales. Statistical downscaling aims to approximate this task using statistical\npatterns gleaned from an existing dataset of downscaled values, often obtained\nfrom observations or physical models. In this work, we investigate the\napplication of deep latent variable learning to the task of statistical\ndownscaling. We present ClimAlign, a novel method for unsupervised, generative\ndownscaling using adaptations of recent work in normalizing flows for\nvariational inference. We evaluate the viability of our method using several\ndifferent metrics on two datasets consisting of daily temperature and\nprecipitation values gridded at low (1 degree latitude/longitude) and high (1/4\nand 1/8 degree) resolutions. We show that our method achieves comparable\npredictive performance to existing supervised statistical downscaling methods\nwhile simultaneously allowing for both conditional and unconditional sampling\nfrom the joint distribution over high and low resolution spatial fields. We\nprovide publicly accessible implementations of our method, as well as the\nbaselines used for comparison, on GitHub.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 13:01:53 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Groenke", "Brian", ""], ["Madaus", "Luke", ""], ["Monteleoni", "Claire", ""]]}, {"id": "2008.04699", "submitter": "Shuo Liu", "authors": "Nirupam Gupta, Shuo Liu and Nitin H. Vaidya", "title": "Byzantine Fault-Tolerant Distributed Machine Learning Using Stochastic\n  Gradient Descent (SGD) and Norm-Based Comparative Gradient Elimination (CGE)", "comments": "The report includes 52 pages, and 16 figures. Extension of our prior\n  work on Byzantine fault-tolerant distribution optimization (arXiv:1903.08752\n  and doi:10.1145/3382734.3405748) to Byzantine fault-tolerant distributed\n  machine learning; Updated to the full version of workshop paper in DSN-DSML\n  '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the Byzantine fault-tolerance problem in distributed\nstochastic gradient descent (D-SGD) method - a popular algorithm for\ndistributed multi-agent machine learning. In this problem, each agent samples\ndata points independently from a certain data-generating distribution. In the\nfault-free case, the D-SGD method allows all the agents to learn a mathematical\nmodel best fitting the data collectively sampled by all agents. We consider the\ncase when a fraction of agents may be Byzantine faulty. Such faulty agents may\nnot follow a prescribed algorithm correctly, and may render traditional D-SGD\nmethod ineffective by sharing arbitrary incorrect stochastic gradients. We\npropose a norm-based gradient-filter, named comparative gradient elimination\n(CGE), that robustifies the D-SGD method against Byzantine agents. We show that\nthe CGE gradient-filter guarantees fault-tolerance against a bounded fraction\nof Byzantine agents under standard stochastic assumptions, and is\ncomputationally simpler compared to many existing gradient-filters such as\nmulti-KRUM, geometric median-of-means, and the spectral filters. We empirically\nshow, by simulating distributed learning on neural networks, that the\nfault-tolerance of CGE is comparable to that of existing gradient-filters. We\nalso empirically show that exponential averaging of stochastic gradients\nimproves the fault-tolerance of a generic gradient-filter.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 13:51:16 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 00:56:13 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Gupta", "Nirupam", ""], ["Liu", "Shuo", ""], ["Vaidya", "Nitin H.", ""]]}, {"id": "2008.04712", "submitter": "Niklas Funk", "authors": "Niklas Funk, Dominik Baumann, Vincent Berenz, Sebastian Trimpe", "title": "Learning Event-triggered Control from Data through Joint Optimization", "comments": null, "journal-ref": null, "doi": "10.1016/j.ifacsc.2021.100144", "report-no": null, "categories": "eess.SY cs.LG cs.RO cs.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present a framework for model-free learning of event-triggered control\nstrategies. Event-triggered methods aim to achieve high control performance\nwhile only closing the feedback loop when needed. This enables resource\nsavings, e.g., network bandwidth if control commands are sent via communication\nnetworks, as in networked control systems. Event-triggered controllers consist\nof a communication policy, determining when to communicate, and a control\npolicy, deciding what to communicate. It is essential to jointly optimize the\ntwo policies since individual optimization does not necessarily yield the\noverall optimal solution. To address this need for joint optimization, we\npropose a novel algorithm based on hierarchical reinforcement learning. The\nresulting algorithm is shown to accomplish high-performance control in line\nwith resource savings and scales seamlessly to nonlinear and high-dimensional\nsystems. The method's applicability to real-world scenarios is demonstrated\nthrough experiments on a six degrees of freedom real-time controlled\nmanipulator. Further, we propose an approach towards evaluating the stability\nof the learned neural network policies.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 14:15:38 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 08:22:42 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 08:05:58 GMT"}, {"version": "v4", "created": "Fri, 23 Apr 2021 07:19:10 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Funk", "Niklas", ""], ["Baumann", "Dominik", ""], ["Berenz", "Vincent", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "2008.04733", "submitter": "Zheng Zhao", "authors": "Zheng Zhao and Muhammad Emzir and Simo S\\\"arkk\\\"a", "title": "Deep State-Space Gaussian Processes", "comments": "Submitted to Statistics and Computing. The code will be revealed at\n  https://github.com/zgbkdlm/SS-DGP upon acceptance", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with a state-space approach to deep Gaussian process\n(DGP) regression. We construct the DGP by hierarchically putting transformed\nGaussian process (GP) priors on the length scales and magnitudes of the next\nlevel of Gaussian processes in the hierarchy. The idea of the state-space\napproach is to represent the DGP as a non-linear hierarchical system of linear\nstochastic differential equations (SDEs), where each SDE corresponds to a\nconditional GP. The DGP regression problem then becomes a state estimation\nproblem, and we can estimate the state efficiently with sequential methods by\nusing the Markov property of the state-space DGP. The computational complexity\nscales linearly with respect to the number of measurements. Based on this, we\nformulate state-space MAP as well as Bayesian filtering and smoothing solutions\nto the DGP regression problem. We demonstrate the performance of the proposed\nmodels and methods on synthetic non-stationary signals and apply the\nstate-space DGP to detection of the gravitational waves from LIGO measurements.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 14:50:07 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Zhao", "Zheng", ""], ["Emzir", "Muhammad", ""], ["S\u00e4rkk\u00e4", "Simo", ""]]}, {"id": "2008.04734", "submitter": "Xinyu Zhang", "authors": "Xinyu Zhang", "title": "Error Bounds for Generalized Group Sparsity", "comments": "23 pages, 2 figures. arXiv admin note: text overlap with\n  arXiv:2006.06172", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high-dimensional statistical inference, sparsity regularizations have\nshown advantages in consistency and convergence rates for coefficient\nestimation. We consider a generalized version of Sparse-Group Lasso which\ncaptures both element-wise sparsity and group-wise sparsity simultaneously. We\nstate one universal theorem which is proved to obtain results on consistency\nand convergence rates for different forms of double sparsity regularization.\nThe universality of the results lies in an generalization of various\nconvergence rates for single regularization cases such as LASSO and group LASSO\nand also double regularization cases such as sparse-group LASSO. Our analysis\nidentifies a generalized norm of $\\epsilon$-norm, which provides a dual\nformulation for our double sparsity regularization.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 03:52:05 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Zhang", "Xinyu", ""]]}, {"id": "2008.04751", "submitter": "Xiaofeng Liu", "authors": "Xiaofeng Liu, Yimeng Zhang, Xiongchang Liu, Song Bai, Site Li, Jane\n  You", "title": "Reinforced Wasserstein Training for Severity-Aware Semantic Segmentation\n  in Autonomous Driving", "comments": "Accepted to IEEE Transactions on Intelligent Transportation Systems\n  (T-ITS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.PF cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic segmentation is important for many real-world systems, e.g.,\nautonomous vehicles, which predict the class of each pixel. Recently, deep\nnetworks achieved significant progress w.r.t. the mean Intersection-over Union\n(mIoU) with the cross-entropy loss. However, the cross-entropy loss can\nessentially ignore the difference of severity for an autonomous car with\ndifferent wrong prediction mistakes. For example, predicting the car to the\nroad is much more servery than recognize it as the bus. Targeting for this\ndifficulty, we develop a Wasserstein training framework to explore the\ninter-class correlation by defining its ground metric as misclassification\nseverity. The ground metric of Wasserstein distance can be pre-defined\nfollowing the experience on a specific task. From the optimization perspective,\nwe further propose to set the ground metric as an increasing function of the\npre-defined ground metric. Furthermore, an adaptively learning scheme of the\nground matrix is proposed to utilize the high-fidelity CARLA simulator.\nSpecifically, we follow a reinforcement alternative learning scheme. The\nexperiments on both CamVid and Cityscapes datasets evidenced the effectiveness\nof our Wasserstein loss. The SegNet, ENet, FCN and Deeplab networks can be\nadapted following a plug-in manner. We achieve significant improvements on the\npredefined important classes, and much longer continuous playtime in our\nsimulator.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 15:00:41 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Liu", "Xiaofeng", ""], ["Zhang", "Yimeng", ""], ["Liu", "Xiongchang", ""], ["Bai", "Song", ""], ["Li", "Site", ""], ["You", "Jane", ""]]}, {"id": "2008.04757", "submitter": "Alexander Hudson", "authors": "Alexander Hudson and Shaogang Gong", "title": "Transfer Learning for Protein Structure Classification at Low Resolution", "comments": "9 pages excluding references and appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structure determination is key to understanding protein function at a\nmolecular level. Whilst significant advances have been made in predicting\nstructure and function from amino acid sequence, researchers must still rely on\nexpensive, time-consuming analytical methods to visualise detailed protein\nconformation. In this study, we demonstrate that it is possible to make\naccurate ($\\geq$80%) predictions of protein class and architecture from\nstructures determined at low ($>$3A) resolution, using a deep convolutional\nneural network trained on high-resolution ($\\leq$3A) structures represented as\n2D matrices. Thus, we provide proof of concept for high-speed, low-cost protein\nstructure classification at low resolution, and a basis for extension to\nprediction of function. We investigate the impact of the input representation\non classification performance, showing that side-chain information may not be\nnecessary for fine-grained structure predictions. Finally, we confirm that\nhigh-resolution, low-resolution and NMR-determined structures inhabit a common\nfeature space, and thus provide a theoretical foundation for boosting with\nsingle-image super-resolution.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 15:01:32 GMT"}, {"version": "v2", "created": "Sun, 16 Aug 2020 16:51:55 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2020 07:21:30 GMT"}, {"version": "v4", "created": "Mon, 31 Aug 2020 17:02:33 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Hudson", "Alexander", ""], ["Gong", "Shaogang", ""]]}, {"id": "2008.04790", "submitter": "Maximilien Dreveton", "authors": "Konstantin Avrachenkov, Maximilien Dreveton, Lasse Leskel\\\"a", "title": "Estimation of Static Community Memberships from Temporal Network Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article studies the estimation of static community memberships from\ntemporally correlated pair interactions represented by an $N$-by-$N$-by-$T$\ntensor where $N$ is the number of nodes and $T$ is the length of the time\nhorizon. We present several estimation algorithms, both offline and online,\nwhich fully utilise the temporal nature of the observed data. As an\ninformation-theoretic benchmark, we study data sets generated by a dynamic\nstochastic block model, and derive fundamental information criteria for the\nrecoverability of the community memberships as $N \\to \\infty$ both for bounded\nand diverging $T$. These results show that (i) even a small increase in $T$ may\nhave a big impact on the recoverability of community memberships, (ii)\nconsistent recovery is possible even for very sparse data (e.g. bounded average\ndegree) when $T$ is large enough. We analyse the accuracy of the proposed\nestimation algorithms under various assumptions on data sparsity and\nidentifiability, and prove that an efficient online algorithm is strongly\nconsistent up to the information-theoretic threshold under suitable\ninitialisation. Numerical experiments show that even a poor initial estimate\n(e.g., blind random guess) of the community assignment leads to high accuracy\nafter a small number of iterations, and remarkably so also in very sparse\nregimes.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 15:33:59 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 15:31:33 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Avrachenkov", "Konstantin", ""], ["Dreveton", "Maximilien", ""], ["Leskel\u00e4", "Lasse", ""]]}, {"id": "2008.04808", "submitter": "Jonathan Alush-Aben", "authors": "Jonathan Alush-Aben, Linor Ackerman-Schraier, Tomer Weiss, Sanketh\n  Vedula, Ortal Senouf and Alex Bronstein", "title": "3D FLAT: Feasible Learned Acquisition Trajectories for Accelerated MRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic Resonance Imaging (MRI) has long been considered to be among the\ngold standards of today's diagnostic imaging. The most significant drawback of\nMRI is long acquisition times, prohibiting its use in standard practice for\nsome applications. Compressed sensing (CS) proposes to subsample the k-space\n(the Fourier domain dual to the physical space of spatial coordinates) leading\nto significantly accelerated acquisition. However, the benefit of compressed\nsensing has not been fully exploited; most of the sampling densities obtained\nthrough CS do not produce a trajectory that obeys the stringent constraints of\nthe MRI machine imposed in practice. Inspired by recent success of deep\nlearning based approaches for image reconstruction and ideas from computational\nimaging on learning-based design of imaging systems, we introduce 3D FLAT, a\nnovel protocol for data-driven design of 3D non-Cartesian accelerated\ntrajectories in MRI. Our proposal leverages the entire 3D k-space to\nsimultaneously learn a physically feasible acquisition trajectory with a\nreconstruction method. Experimental results, performed as a proof-of-concept,\nsuggest that 3D FLAT achieves higher image quality for a given readout time\ncompared to standard trajectories such as radial, stack-of-stars, or 2D learned\ntrajectories (trajectories that evolve only in the 2D plane while fully\nsampling along the third dimension). Furthermore, we demonstrate evidence\nsupporting the significant benefit of performing MRI acquisitions using\nnon-Cartesian 3D trajectories over 2D non-Cartesian trajectories acquired\nslice-wise.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 16:03:51 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Alush-Aben", "Jonathan", ""], ["Ackerman-Schraier", "Linor", ""], ["Weiss", "Tomer", ""], ["Vedula", "Sanketh", ""], ["Senouf", "Ortal", ""], ["Bronstein", "Alex", ""]]}, {"id": "2008.04815", "submitter": "Md. Milon Islam Islam", "authors": "Md. Milon Islam, Fakhri Karray, Reda Alhajj, Jia Zeng", "title": "A Review on Deep Learning Techniques for the Diagnosis of Novel\n  Coronavirus (COVID-19)", "comments": "18 pages, 2 figures, 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Novel coronavirus (COVID-19) outbreak, has raised a calamitous situation all\nover the world and has become one of the most acute and severe ailments in the\npast hundred years. The prevalence rate of COVID-19 is rapidly rising every day\nthroughout the globe. Although no vaccines for this pandemic have been\ndiscovered yet, deep learning techniques proved themselves to be a powerful\ntool in the arsenal used by clinicians for the automatic diagnosis of COVID-19.\nThis paper aims to overview the recently developed systems based on deep\nlearning techniques using different medical imaging modalities like Computer\nTomography (CT) and X-ray. This review specifically discusses the systems\ndeveloped for COVID-19 diagnosis using deep learning techniques and provides\ninsights on well-known data sets used to train these networks. It also\nhighlights the data partitioning techniques and various performance measures\ndeveloped by researchers in this field. A taxonomy is drawn to categorize the\nrecent works for proper insight. Finally, we conclude by addressing the\nchallenges associated with the use of deep learning methods for COVID-19\ndetection and probable future trends in this research area. This paper is\nintended to provide experts (medical or otherwise) and technicians with new\ninsights into the ways deep learning techniques are used in this regard and how\nthey potentially further works in combatting the outbreak of COVID-19.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 02:37:50 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Islam", "Md. Milon", ""], ["Karray", "Fakhri", ""], ["Alhajj", "Reda", ""], ["Zeng", "Jia", ""]]}, {"id": "2008.04820", "submitter": "Sopan Khosla", "authors": "Sopan Khosla, Rishabh Joshi, Ritam Dutt, Alan W Black, Yulia Tsvetkov", "title": "LTIatCMU at SemEval-2020 Task 11: Incorporating Multi-Level Features for\n  Multi-Granular Propaganda Span Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we describe our submission for the task of Propaganda Span\nIdentification in news articles. We introduce a BERT-BiLSTM based span-level\npropaganda classification model that identifies which token spans within the\nsentence are indicative of propaganda. The \"multi-granular\" model incorporates\nlinguistic knowledge at various levels of text granularity, including word,\nsentence and document level syntactic, semantic and pragmatic affect features,\nwhich significantly improve model performance, compared to its\nlanguage-agnostic variant. To facilitate better representation learning, we\nalso collect a corpus of 10k news articles, and use it for fine-tuning the\nmodel. The final model is a majority-voting ensemble which learns different\npropaganda class boundaries by leveraging different subsets of incorporated\nknowledge and attains $4^{th}$ position on the test leaderboard. Our final\nmodel and code is released at https://github.com/sopu/PropagandaSemEval2020.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 16:14:47 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 15:14:18 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Khosla", "Sopan", ""], ["Joshi", "Rishabh", ""], ["Dutt", "Ritam", ""], ["Black", "Alan W", ""], ["Tsvetkov", "Yulia", ""]]}, {"id": "2008.04847", "submitter": "Hadi Meidani", "authors": "Amir Kazemi and Hadi Meidani", "title": "IGANI: Iterative Generative Adversarial Networks for Imputation with\n  Application to Traffic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing use of sensor data in intelligent transportation systems calls for\naccurate imputation algorithms that can enable reliable traffic management in\nthe occasional absence of data. As one of the effective imputation approaches,\ngenerative adversarial networks (GANs) are implicit generative models that can\nbe used for data imputation, which is formulated as an unsupervised learning\nproblem. This work introduces a novel iterative GAN architecture, called\nIterative Generative Adversarial Networks for Imputation (IGANI), for data\nimputation. IGANI imputes data in two steps and maintains the invertibility of\nthe generative imputer, which will be shown to be a sufficient condition for\nthe convergence of the proposed GAN-based imputation. The performance of our\nproposed method is evaluated on (1) the imputation of traffic speed data\ncollected in the city of Guangzhou in China, and the training of short-term\ntraffic prediction models using imputed data, and (2) the imputation of\nmulti-variable traffic data of highways in Portland-Vancouver metropolitan\nregion which includes volume, occupancy, and speed with different missing rates\nfor each of them. It is shown that our proposed algorithm mostly produces more\naccurate results compared to those of previous GAN-based imputation\narchitectures.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 16:46:02 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 19:47:56 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 16:37:58 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Kazemi", "Amir", ""], ["Meidani", "Hadi", ""]]}, {"id": "2008.04848", "submitter": "Gengxing Wang", "authors": "Gengxing Wang, Jiahuan Zhou, Ying Wu", "title": "Exposing Deep-faked Videos by Anomalous Co-motion Pattern Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent deep learning based video synthesis approaches, in particular with\napplications that can forge identities such as \"DeepFake\", have raised great\nsecurity concerns. Therefore, corresponding deep forensic methods are proposed\nto tackle this problem. However, existing methods are either based on\nunexplainable deep networks which greatly degrades the principal\ninterpretability factor to media forensic, or rely on fragile image statistics\nsuch as noise pattern, which in real-world scenarios can be easily deteriorated\nby data compression. In this paper, we propose an fully-interpretable video\nforensic method that is designed specifically to expose deep-faked videos. To\nenhance generalizability on videos with various content, we model the temporal\nmotion of multiple specific spatial locations in the videos to extract a robust\nand reliable representation, called Co-Motion Pattern. Such kind of conjoint\npattern is mined across local motion features which is independent of the video\ncontents so that the instance-wise variation can also be largely alleviated.\nMore importantly, our proposed co-motion pattern possesses both superior\ninterpretability and sufficient robustness against data compression for\ndeep-faked videos. We conduct extensive experiments to empirically demonstrate\nthe superiority and effectiveness of our approach under both classification and\nanomaly detection evaluation settings against the state-of-the-art deep\nforensic methods.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 16:47:02 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Wang", "Gengxing", ""], ["Zhou", "Jiahuan", ""], ["Wu", "Ying", ""]]}, {"id": "2008.04851", "submitter": "Xi Li", "authors": "Fangfang Wang, Yifeng Chen, Fei Wu, and Xi Li", "title": "TextRay: Contour-based Geometric Modeling for Arbitrary-shaped Scene\n  Text Detection", "comments": "Accepted to ACM MM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arbitrary-shaped text detection is a challenging task due to the complex\ngeometric layouts of texts such as large aspect ratios, various scales, random\nrotations and curve shapes. Most state-of-the-art methods solve this problem\nfrom bottom-up perspectives, seeking to model a text instance of complex\ngeometric layouts with simple local units (e.g., local boxes or pixels) and\ngenerate detections with heuristic post-processings. In this work, we propose\nan arbitrary-shaped text detection method, namely TextRay, which conducts\ntop-down contour-based geometric modeling and geometric parameter learning\nwithin a single-shot anchor-free framework. The geometric modeling is carried\nout under polar system with a bidirectional mapping scheme between shape space\nand parameter space, encoding complex geometric layouts into unified\nrepresentations. For effective learning of the representations, we design a\ncentral-weighted training strategy and a content loss which builds propagation\npaths between geometric encodings and visual content. TextRay outputs simple\npolygon detections at one pass with only one NMS post-processing. Experiments\non several benchmark datasets demonstrate the effectiveness of the proposed\napproach. The code is available at https://github.com/LianaWang/TextRay.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 16:52:10 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 07:29:25 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Wang", "Fangfang", ""], ["Chen", "Yifeng", ""], ["Wu", "Fei", ""], ["Li", "Xi", ""]]}, {"id": "2008.04852", "submitter": "Ricardo Martin Brualla", "authors": "Ricardo Martin-Brualla, Rohit Pandey, Sofien Bouaziz, Matthew Brown,\n  Dan B Goldman", "title": "GeLaTO: Generative Latent Textured Objects", "comments": "ECCV 2020 Spotlight. Project website: https://gelato-paper.github.io", "journal-ref": "European Conference on Computer Vision 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate modeling of 3D objects exhibiting transparency, reflections and thin\nstructures is an extremely challenging problem. Inspired by billboards and\ngeometric proxies used in computer graphics, this paper proposes Generative\nLatent Textured Objects (GeLaTO), a compact representation that combines a set\nof coarse shape proxies defining low frequency geometry with learned neural\ntextures, to encode both medium and fine scale geometry as well as\nview-dependent appearance. To generate the proxies' textures, we learn a joint\nlatent space allowing category-level appearance and geometry interpolation. The\nproxies are independently rasterized with their corresponding neural texture\nand composited using a U-Net, which generates an output photorealistic image\nincluding an alpha map. We demonstrate the effectiveness of our approach by\nreconstructing complex objects from a sparse set of views. We show results on a\ndataset of real images of eyeglasses frames, which are particularly challenging\nto reconstruct using classical methods. We also demonstrate that these coarse\nproxies can be handcrafted when the underlying object geometry is easy to\nmodel, like eyeglasses, or generated using a neural network for more complex\ncategories, such as cars.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 16:55:26 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Martin-Brualla", "Ricardo", ""], ["Pandey", "Rohit", ""], ["Bouaziz", "Sofien", ""], ["Brown", "Matthew", ""], ["Goldman", "Dan B", ""]]}, {"id": "2008.04855", "submitter": "Praveen Damacharla", "authors": "Praveen Damacharla, Ahmad Y. Javaid, Jennie J. Gallimore, Vijay K.\n  Devabhaktuni", "title": "Common Metrics to Benchmark Human-Machine Teams (HMT): A Review", "comments": null, "journal-ref": "in IEEE Access, vol. 6, pp. 38637-38655, 2018", "doi": "10.1109/ACCESS.2018.2853560", "report-no": null, "categories": "cs.CY cs.HC cs.LG cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A significant amount of work is invested in human-machine teaming (HMT)\nacross multiple fields. Accurately and effectively measuring system performance\nof an HMT is crucial for moving the design of these systems forward. Metrics\nare the enabling tools to devise a benchmark in any system and serve as an\nevaluation platform for assessing the performance, along with the verification\nand validation, of a system. Currently, there is no agreed-upon set of\nbenchmark metrics for developing HMT systems. Therefore, identification and\nclassification of common metrics are imperative to create a benchmark in the\nHMT field. The key focus of this review is to conduct a detailed survey aimed\nat identification of metrics employed in different segments of HMT and to\ndetermine the common metrics that can be used in the future to benchmark HMTs.\nWe have organized this review as follows: identification of metrics used in\nHMTs until now, and classification based on functionality and measuring\ntechniques. Additionally, we have also attempted to analyze all the identified\nmetrics in detail while classifying them as theoretical, applied, real-time,\nnon-real-time, measurable, and observable metrics. We conclude this review with\na detailed analysis of the identified common metrics along with their usage to\nbenchmark HMTs.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 16:57:52 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Damacharla", "Praveen", ""], ["Javaid", "Ahmad Y.", ""], ["Gallimore", "Jennie J.", ""], ["Devabhaktuni", "Vijay K.", ""]]}, {"id": "2008.04859", "submitter": "Dimitris Tsipras", "authors": "Shibani Santurkar, Dimitris Tsipras, Aleksander Madry", "title": "BREEDS: Benchmarks for Subpopulation Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a methodology for assessing the robustness of models to\nsubpopulation shift---specifically, their ability to generalize to novel data\nsubpopulations that were not observed during training. Our approach leverages\nthe class structure underlying existing datasets to control the data\nsubpopulations that comprise the training and test distributions. This enables\nus to synthesize realistic distribution shifts whose sources can be precisely\ncontrolled and characterized, within existing large-scale datasets. Applying\nthis methodology to the ImageNet dataset, we create a suite of subpopulation\nshift benchmarks of varying granularity. We then validate that the\ncorresponding shifts are tractable by obtaining human baselines for them.\nFinally, we utilize these benchmarks to measure the sensitivity of standard\nmodel architectures as well as the effectiveness of off-the-shelf train-time\nrobustness interventions. Code and data available at\nhttps://github.com/MadryLab/BREEDS-Benchmarks .\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 17:04:47 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Santurkar", "Shibani", ""], ["Tsipras", "Dimitris", ""], ["Madry", "Aleksander", ""]]}, {"id": "2008.04861", "submitter": "Masaki Ikuta", "authors": "Masaki Ikuta and Jun Zhang", "title": "TextureWGAN: Texture Preserving WGAN with MLE Regularizer for Inverse\n  Problems", "comments": "Submitted to SPIE Medical Imaging Conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many algorithms and methods have been proposed for inverse problems\nparticularly with the recent surge of interest in machine learning and deep\nlearning methods. Among all proposed methods, the most popular and effective\nmethod is the convolutional neural network (CNN) with mean square error (MSE).\nThis method has been proven effective in super-resolution, image de-noising,\nand image reconstruction. However, this method is known to over-smooth images\ndue to the nature of MSE. MSE based methods minimize Euclidean distance for all\npixels between a baseline image and a generated image by CNN and ignore the\nspatial information of the pixels such as image texture. In this paper, we\nproposed a new method based on Wasserstein GAN (WGAN) for inverse problems. We\nshowed that the WGAN-based method was effective to preserve image texture. It\nalso used a maximum likelihood estimation (MLE) regularizer to preserve pixel\nfidelity. Maintaining image texture and pixel fidelity is the most important\nrequirement for medical imaging. We used Peak Signal to Noise Ratio (PSNR) and\nStructure Similarity (SSIM) to evaluate the proposed method quantitatively. We\nalso conducted first-order and second-order statistical image texture analysis\nto assess image texture.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 17:06:34 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 01:24:02 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Ikuta", "Masaki", ""], ["Zhang", "Jun", ""]]}, {"id": "2008.04876", "submitter": "Jiaxi Tang", "authors": "Jiaxi Tang, Hongyi Wen, Ke Wang", "title": "Revisiting Adversarially Learned Injection Attacks Against Recommender\n  Systems", "comments": "Accepted at Recsys 20", "journal-ref": null, "doi": "10.1145/3383313.3412243", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems play an important role in modern information and\ne-commerce applications. While increasing research is dedicated to improving\nthe relevance and diversity of the recommendations, the potential risks of\nstate-of-the-art recommendation models are under-explored, that is, these\nmodels could be subject to attacks from malicious third parties, through\ninjecting fake user interactions to achieve their purposes. This paper revisits\nthe adversarially-learned injection attack problem, where the injected fake\nuser `behaviors' are learned locally by the attackers with their own model --\none that is potentially different from the model under attack, but shares\nsimilar properties to allow attack transfer. We found that most existing works\nin literature suffer from two major limitations: (1) they do not solve the\noptimization problem precisely, making the attack less harmful than it could\nbe, (2) they assume perfect knowledge for the attack, causing the lack of\nunderstanding for realistic attack capabilities. We demonstrate that the exact\nsolution for generating fake users as an optimization problem could lead to a\nmuch larger impact. Our experiments on a real-world dataset reveal important\nproperties of the attack, including attack transferability and its limitations.\nThese findings can inspire useful defensive methods against this possible\nexisting attack.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 17:30:02 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 05:03:41 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Tang", "Jiaxi", ""], ["Wen", "Hongyi", ""], ["Wang", "Ke", ""]]}, {"id": "2008.04878", "submitter": "Zhijian Liu", "authors": "Kuan Wang, Zhijian Liu, Yujun Lin, Ji Lin, Song Han", "title": "Hardware-Centric AutoML for Mixed-Precision Quantization", "comments": "Journal preprint of arXiv:1811.08886 (IJCV, 2020). The first three\n  authors contributed equally to this work. Project page:\n  https://hanlab.mit.edu/projects/haq/", "journal-ref": "International Journal of Computer Vision (IJCV), Volume 128, Issue\n  8-9, pp 2035-2048, 2020", "doi": "10.1007/s11263-020-01339-6", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model quantization is a widely used technique to compress and accelerate deep\nneural network (DNN) inference. Emergent DNN hardware accelerators begin to\nsupport mixed precision (1-8 bits) to further improve the computation\nefficiency, which raises a great challenge to find the optimal bitwidth for\neach layer: it requires domain experts to explore the vast design space trading\noff among accuracy, latency, energy, and model size, which is both\ntime-consuming and sub-optimal. Conventional quantization algorithm ignores the\ndifferent hardware architectures and quantizes all the layers in a uniform way.\nIn this paper, we introduce the Hardware-Aware Automated Quantization (HAQ)\nframework which leverages the reinforcement learning to automatically determine\nthe quantization policy, and we take the hardware accelerator's feedback in the\ndesign loop. Rather than relying on proxy signals such as FLOPs and model size,\nwe employ a hardware simulator to generate direct feedback signals (latency and\nenergy) to the RL agent. Compared with conventional methods, our framework is\nfully automated and can specialize the quantization policy for different neural\nnetwork architectures and hardware architectures. Our framework effectively\nreduced the latency by 1.4-1.95x and the energy consumption by 1.9x with\nnegligible loss of accuracy compared with the fixed bitwidth (8 bits)\nquantization. Our framework reveals that the optimal policies on different\nhardware architectures (i.e., edge and cloud architectures) under different\nresource constraints (i.e., latency, energy, and model size) are drastically\ndifferent. We interpreted the implication of different quantization policies,\nwhich offer insights for both neural network architecture design and hardware\narchitecture design.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 17:30:22 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Wang", "Kuan", ""], ["Liu", "Zhijian", ""], ["Lin", "Yujun", ""], ["Lin", "Ji", ""], ["Han", "Song", ""]]}, {"id": "2008.04882", "submitter": "Tryambak Gangopadhyay", "authors": "Tryambak Gangopadhyay, Sin Yong Tan, Zhanhong Jiang, Rui Meng, Soumik\n  Sarkar", "title": "Spatiotemporal Attention for Multivariate Time Series Prediction and\n  Interpretation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series modeling and prediction problems are abundant in\nmany machine learning application domains. Accurate interpretation of such\nprediction outcomes from a machine learning model that explicitly captures\ntemporal correlations can significantly benefit the domain experts. In this\ncontext, temporal attention has been successfully applied to isolate the\nimportant time steps for the input time series. However, in multivariate time\nseries problems, spatial interpretation is also critical to understand the\ncontributions of different variables on the model outputs. We propose a novel\ndeep learning architecture, called spatiotemporal attention mechanism (STAM)\nfor simultaneous learning of the most important time steps and variables. STAM\nis a causal (i.e., only depends on past inputs and does not use future inputs)\nand scalable (i.e., scales well with an increase in the number of variables)\napproach that is comparable to the state-of-the-art models in terms of\ncomputational tractability. We demonstrate our models' performance on two\npopular public datasets and a domain-specific dataset. When compared with the\nbaseline models, the results show that STAM maintains state-of-the-art\nprediction accuracy while offering the benefit of accurate spatiotemporal\ninterpretability. The learned attention weights are validated from a domain\nknowledge perspective for these real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 17:34:55 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 17:32:06 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Gangopadhyay", "Tryambak", ""], ["Tan", "Sin Yong", ""], ["Jiang", "Zhanhong", ""], ["Meng", "Rui", ""], ["Sarkar", "Soumik", ""]]}, {"id": "2008.04887", "submitter": "Vincent Gauthier", "authors": "Hugo Alatrista-Salas and Vincent Gauthier and Miguel Nunez-del-Prado\n  and Monique Becker", "title": "Impact of natural disasters on consumer behavior: case of the 2017 El\n  Nino phenomenon in Peru", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0244409", "report-no": null, "categories": "cs.SI cs.LG physics.data-an physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  El Nino is an extreme weather event featuring unusual warming of surface\nwaters in the eastern equatorial Pacific Ocean. This phenomenon is\ncharacterized by heavy rains and floods that negatively affect the economic\nactivities of the impacted areas. Understanding how this phenomenon influences\nconsumption behavior at different granularity levels is essential for\nrecommending strategies to normalize the situation. With this aim, we performed\na multi-scale analysis of data associated with bank transactions involving\ncredit and debit cards. Our findings can be summarized into two main results:\nCoarse-grained analysis reveals the presence of the El Ni\\~no phenomenon and\nthe recovery time in a given territory, while fine-grained analysis\ndemonstrates a change in individuals' purchasing patterns and in merchant\nrelevance as a consequence of the climatic event. The results also indicate\nthat society successfully withstood the natural disaster owing to the economic\nstructure built over time. In this study, we present a new method that may be\nuseful for better characterizing future extreme events.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 17:44:39 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Alatrista-Salas", "Hugo", ""], ["Gauthier", "Vincent", ""], ["Nunez-del-Prado", "Miguel", ""], ["Becker", "Monique", ""]]}, {"id": "2008.04893", "submitter": "Song Fang", "authors": "Song Fang and Quanyan Zhu", "title": "Channel Leakage, Information-Theoretic Limitations of Obfuscation, and\n  Optimal Privacy Mask Design for Streaming Data", "comments": "The title was changed from \"Channel Leakage and Information Theoretic\n  Privacy-Distortion Tradeoffs for Streaming Data\" to the current one on 29th\n  September 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.LG eess.SP math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we first introduce the notion of channel leakage as the\nminimum mutual information between the channel input and channel output. As its\nname indicates, channel leakage quantifies the minimum information leakage to\nthe malicious receiver. In a broad sense, it can be viewed as a dual concept of\nchannel capacity, which characterizes the maximum information transmission to\nthe targeted receiver. We obtain explicit formulas of channel leakage for the\nwhite Gaussian case, the colored Gaussian case, and the fading case. We then\nutilize this notion to investigate the fundamental limitations of obfuscation\nin terms of privacy-distortion tradeoffs (as well as privacy-power tradeoffs)\nfor streaming data; particularly, we derive analytical tradeoff equations for\nthe stationary case, the non-stationary case, and the finite-time case. Our\nresults also indicate explicitly how to design the privacy masks in an optimal\nway.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 17:55:47 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 16:47:49 GMT"}, {"version": "v3", "created": "Tue, 25 Aug 2020 16:16:33 GMT"}, {"version": "v4", "created": "Thu, 24 Sep 2020 23:32:36 GMT"}, {"version": "v5", "created": "Tue, 29 Sep 2020 21:15:37 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Fang", "Song", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2008.04899", "submitter": "Sarah Young", "authors": "Sarah Young, Dhiraj Gandhi, Shubham Tulsiani, Abhinav Gupta, Pieter\n  Abbeel, Lerrel Pinto", "title": "Visual Imitation Made Easy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual imitation learning provides a framework for learning complex\nmanipulation behaviors by leveraging human demonstrations. However, current\ninterfaces for imitation such as kinesthetic teaching or teleoperation\nprohibitively restrict our ability to efficiently collect large-scale data in\nthe wild. Obtaining such diverse demonstration data is paramount for the\ngeneralization of learned skills to novel scenarios. In this work, we present\nan alternate interface for imitation that simplifies the data collection\nprocess while allowing for easy transfer to robots. We use commercially\navailable reacher-grabber assistive tools both as a data collection device and\nas the robot's end-effector. To extract action information from these visual\ndemonstrations, we use off-the-shelf Structure from Motion (SfM) techniques in\naddition to training a finger detection network. We experimentally evaluate on\ntwo challenging tasks: non-prehensile pushing and prehensile stacking, with\n1000 diverse demonstrations for each task. For both tasks, we use standard\nbehavior cloning to learn executable policies from the previously collected\noffline demonstrations. To improve learning performance, we employ a variety of\ndata augmentations and provide an extensive analysis of its effects. Finally,\nwe demonstrate the utility of our interface by evaluating on real robotic\nscenarios with previously unseen objects and achieve a 87% success rate on\npushing and a 62% success rate on stacking. Robot videos are available at\nhttps://dhiraj100892.github.io/Visual-Imitation-Made-Easy.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 17:58:50 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Young", "Sarah", ""], ["Gandhi", "Dhiraj", ""], ["Tulsiani", "Shubham", ""], ["Gupta", "Abhinav", ""], ["Abbeel", "Pieter", ""], ["Pinto", "Lerrel", ""]]}, {"id": "2008.04938", "submitter": "Joseph Cleveland", "authors": "Joseph Cleveland, Derek Cheng, Michael Zhou, Thorsten Joachims,\n  Douglass Turnbull", "title": "Content-based Music Similarity with Triplet Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the feasibility of using triplet neural networks to embed songs\nbased on content-based music similarity. Our network is trained using triplets\nof songs such that two songs by the same artist are embedded closer to one\nanother than to a third song by a different artist. We compare two models that\nare trained using different ways of picking this third song: at random vs.\nbased on shared genre labels. Our experiments are conducted using songs from\nthe Free Music Archive and use standard audio features. The initial results\nshow that shallow Siamese networks can be used to embed music for a simple\nartist retrieval task.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 18:10:02 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Cleveland", "Joseph", ""], ["Cheng", "Derek", ""], ["Zhou", "Michael", ""], ["Joachims", "Thorsten", ""], ["Turnbull", "Douglass", ""]]}, {"id": "2008.04946", "submitter": "Girik Malik", "authors": "Girik Malik and Ish K. Gulati", "title": "Little Motion, Big Results: Using Motion Magnification to Reveal Subtle\n  Tremors in Infants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting tremors is challenging for both humans and machines. Infants\nexposed to opioids during pregnancy often show signs and symptoms of withdrawal\nafter birth, which are easy to miss with the human eye. The constellation of\nclinical features, termed as Neonatal Abstinence Syndrome (NAS), include\ntremors, seizures, irritability, etc. The current standard of care uses\nFinnegan Neonatal Abstinence Syndrome Scoring System (FNASS), based on\nsubjective evaluations. Monitoring with FNASS requires highly skilled nursing\nstaff, making continuous monitoring difficult. In this paper we propose an\nautomated tremor detection system using amplified motion signals. We\ndemonstrate its applicability on bedside video of infant exhibiting signs of\nNAS. Further, we test different modes of deep convolutional network based\nmotion magnification, and identify that dynamic mode works best in the clinical\nsetting, being invariant to common orientational changes. We propose a strategy\nfor discharge and follow up for NAS patients, using motion magnification to\nsupplement the existing protocols. Overall our study suggests methods for\nbridging the gap in current practices, training and resource utilization.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 15:35:55 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Malik", "Girik", ""], ["Gulati", "Ish K.", ""]]}, {"id": "2008.04965", "submitter": "Mark Sandler", "authors": "Mark Sandler, Andrey Zhmoginov, Liangcheng Luo, Alexander Mordvintsev,\n  Ettore Randazzo, Blaise Ag\\'uera y Arcas", "title": "Image segmentation via Cellular Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new approach for building cellular automata to\nsolve real-world segmentation problems. We design and train a cellular\nautomaton that can successfully segment high-resolution images. We consider a\ncolony that densely inhabits the pixel grid, and all cells are governed by a\nrandomized update that uses the current state, the color, and the state of the\n$3\\times 3$ neighborhood. The space of possible rules is defined by a small\nneural network. The update rule is applied repeatedly in parallel to a large\nrandom subset of cells and after convergence is used to produce segmentation\nmasks that are then back-propagated to learn the optimal update rules using\nstandard gradient descent methods. We demonstrate that such models can be\nlearned efficiently with only limited trajectory length and that they show\nremarkable ability to organize the information to produce a globally consistent\nsegmentation result, using only local information exchange. From a practical\nperspective, our approach allows us to build very efficient models -- our\nsmallest automaton uses less than 10,000 parameters to solve complex\nsegmentation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 19:04:09 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 00:37:47 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Sandler", "Mark", ""], ["Zhmoginov", "Andrey", ""], ["Luo", "Liangcheng", ""], ["Mordvintsev", "Alexander", ""], ["Randazzo", "Ettore", ""], ["Arcas", "Blaise Ag\u00faera y", ""]]}, {"id": "2008.04968", "submitter": "Chongshou Li Dr", "authors": "Xinke Li, Chongshou Li, Zekun Tong, Andrew Lim, Junsong Yuan, Yuwei\n  Wu, Jing Tang, Raymond Huang", "title": "Campus3D: A Photogrammetry Point Cloud Benchmark for Hierarchical\n  Understanding of Outdoor Scene", "comments": "Accepted by the 28th ACM International Conference on Multimedia (ACM\n  MM 2020)", "journal-ref": "Proceedings of the 28th ACM International Conference on Multimedia\n  2020", "doi": "10.1145/3394171.3413661", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning on 3D scene-based point cloud has received extensive attention as\nits promising application in many fields, and well-annotated and multisource\ndatasets can catalyze the development of those data-driven approaches. To\nfacilitate the research of this area, we present a richly-annotated 3D point\ncloud dataset for multiple outdoor scene understanding tasks and also an\neffective learning framework for its hierarchical segmentation task. The\ndataset was generated via the photogrammetric processing on unmanned aerial\nvehicle (UAV) images of the National University of Singapore (NUS) campus, and\nhas been point-wisely annotated with both hierarchical and instance-based\nlabels. Based on it, we formulate a hierarchical learning problem for 3D point\ncloud segmentation and propose a measurement evaluating consistency across\nvarious hierarchies. To solve this problem, a two-stage method including\nmulti-task (MT) learning and hierarchical ensemble (HE) with consistency\nconsideration is proposed. Experimental results demonstrate the superiority of\nthe proposed method and potential advantages of our hierarchical annotations.\nIn addition, we benchmark results of semantic and instance segmentation, which\nis accessible online at https://3d.dataset.site with the dataset and all source\ncodes.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 19:10:32 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Li", "Xinke", ""], ["Li", "Chongshou", ""], ["Tong", "Zekun", ""], ["Lim", "Andrew", ""], ["Yuan", "Junsong", ""], ["Wu", "Yuwei", ""], ["Tang", "Jing", ""], ["Huang", "Raymond", ""]]}, {"id": "2008.04975", "submitter": "Ping Li", "authors": "Farzin Haddadpour, Belhal Karimi, Ping Li, Xiaoyun Li", "title": "FedSKETCH: Communication-Efficient and Private Federated Learning via\n  Sketching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication complexity and privacy are the two key challenges in Federated\nLearning where the goal is to perform a distributed learning through a large\nvolume of devices. In this work, we introduce FedSKETCH and FedSKETCHGATE\nalgorithms to address both challenges in Federated learning jointly, where\nthese algorithms are intended to be used for homogeneous and heterogeneous data\ndistribution settings respectively. The key idea is to compress the\naccumulation of local gradients using count sketch, therefore, the server does\nnot have access to the gradients themselves which provides privacy.\nFurthermore, due to the lower dimension of sketching used, our method exhibits\ncommunication-efficiency property as well. We provide, for the aforementioned\nschemes, sharp convergence guarantees.\n  Finally, we back up our theory with various set of experiments.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 19:22:48 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Haddadpour", "Farzin", ""], ["Karimi", "Belhal", ""], ["Li", "Ping", ""], ["Li", "Xiaoyun", ""]]}, {"id": "2008.04988", "submitter": "Rui Liu", "authors": "Rui Liu and Alex Olshevsky", "title": "Asymptotic Convergence Rate of Alternating Minimization for Rank One\n  Matrix Completion", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study alternating minimization for matrix completion in the simplest\npossible setting: completing a rank-one matrix from a revealed subset of the\nentries. We bound the asymptotic convergence rate by the variational\ncharacterization of eigenvalues of a reversible consensus problem. This leads\nto a polynomial upper bound on the asymptotic rate in terms of number of nodes\nas well as the largest degree of the graph of revealed entries.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 19:56:35 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Liu", "Rui", ""], ["Olshevsky", "Alex", ""]]}, {"id": "2008.04990", "submitter": "Tengyang Xie", "authors": "Tengyang Xie, Nan Jiang", "title": "Batch Value-function Approximation with Only Realizability", "comments": "Published in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We make progress in a long-standing problem of batch reinforcement learning\n(RL): learning $Q^\\star$ from an exploratory and polynomial-sized dataset,\nusing a realizable and otherwise arbitrary function class. In fact, all\nexisting algorithms demand function-approximation assumptions stronger than\nrealizability, and the mounting negative evidence has led to a conjecture that\nsample-efficient learning is impossible in this setting (Chen and Jiang, 2019).\nOur algorithm, BVFT, breaks the hardness conjecture (albeit under a stronger\nnotion of exploratory data) via a tournament procedure that reduces the\nlearning problem to pairwise comparison, and solves the latter with the help of\na state-action partition constructed from the compared functions. We also\ndiscuss how BVFT can be applied to model selection among other extensions and\nopen problems.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 20:09:37 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 05:01:21 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 04:41:20 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Xie", "Tengyang", ""], ["Jiang", "Nan", ""]]}, {"id": "2008.05000", "submitter": "Javier Fernandez-Marques", "authors": "Shyam A. Tailor, Javier Fernandez-Marques, Nicholas D. Lane", "title": "Degree-Quant: Quantization-Aware Training for Graph Neural Networks", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have demonstrated strong performance on a wide\nvariety of tasks due to their ability to model non-uniform structured data.\nDespite their promise, there exists little research exploring methods to make\nthem more efficient at inference time. In this work, we explore the viability\nof training quantized GNNs, enabling the usage of low precision integer\narithmetic during inference. We identify the sources of error that uniquely\narise when attempting to quantize GNNs, and propose an architecturally-agnostic\nmethod, Degree-Quant, to improve performance over existing quantization-aware\ntraining baselines commonly used on other architectures, such as CNNs. We\nvalidate our method on six datasets and show, unlike previous attempts, that\nmodels generalize to unseen graphs. Models trained with Degree-Quant for INT8\nquantization perform as well as FP32 models in most cases; for INT4 models, we\nobtain up to 26% gains over the baselines. Our work enables up to 4.7x speedups\non CPU when using INT8 arithmetic.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 20:53:50 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 15:29:16 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 15:27:59 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Tailor", "Shyam A.", ""], ["Fernandez-Marques", "Javier", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "2008.05004", "submitter": "Shaojie Tang", "authors": "Shaojie Tang", "title": "Beyond Pointwise Submodularity: Non-Monotone Adaptive Submodular\n  Maximization in Linear Time", "comments": "22 pages, accepted to TCS. This version subsumes our preliminary\n  results presented arXiv:2007.04214", "journal-ref": "Theoretical Computer Science, Volume 850, 4 January 2021, Pages\n  249-261", "doi": "10.1016/j.tcs.2020.11.007", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the non-monotone adaptive submodular maximization\nproblem subject to a cardinality constraint. We first revisit the adaptive\nrandom greedy algorithm proposed in \\citep{gotovos2015non}, where they show\nthat this algorithm achieves a $1/e$ approximation ratio if the objective\nfunction is adaptive submodular and pointwise submodular. It is not clear\nwhether the same guarantee holds under adaptive submodularity (without\nresorting to pointwise submodularity) or not. Our first contribution is to show\nthat the adaptive random greedy algorithm achieves a $1/e$ approximation ratio\nunder adaptive submodularity. One limitation of the adaptive random greedy\nalgorithm is that it requires $O(n\\times k)$ value oracle queries, where $n$ is\nthe size of the ground set and $k$ is the cardinality constraint. Our second\ncontribution is to develop the first linear-time algorithm for the non-monotone\nadaptive submodular maximization problem. Our algorithm achieves a\n$1/e-\\epsilon$ approximation ratio (this bound is improved to $1-1/e-\\epsilon$\nfor monotone case), using only $O(n\\epsilon^{-2}\\log \\epsilon^{-1})$ value\noracle queries. Notably, $O(n\\epsilon^{-2}\\log \\epsilon^{-1})$ is independent\nof the cardinality constraint. For the monotone case, we propose a faster\nalgorithm that achieves a $1-1/e-\\epsilon$ approximation ratio in expectation\nwith $O(n \\log \\frac{1}{\\epsilon})$ value oracle queries. We also generalize\nour study by considering a partition matroid constraint, and develop a\nlinear-time algorithm for monotone and fully adaptive submodular functions.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 21:06:52 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 13:36:50 GMT"}, {"version": "v3", "created": "Sat, 7 Nov 2020 16:48:49 GMT"}, {"version": "v4", "created": "Tue, 15 Dec 2020 18:41:15 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Tang", "Shaojie", ""]]}, {"id": "2008.05011", "submitter": "Munir Georges", "authors": "Munir Georges, Jonathan Huang, Tobias Bocklet", "title": "Compact Speaker Embedding: lrx-vector", "comments": "Accepted to INTERSPEECH 2020", "journal-ref": "Proc. Interspeech 2020", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) have recently been widely used in speaker\nrecognition systems, achieving state-of-the-art performance on various\nbenchmarks. The x-vector architecture is especially popular in this research\ncommunity, due to its excellent performance and manageable computational\ncomplexity. In this paper, we present the lrx-vector system, which is the\nlow-rank factorized version of the x-vector embedding network. The primary\nobjective of this topology is to further reduce the memory requirement of the\nspeaker recognition system. We discuss the deployment of knowledge distillation\nfor training the lrx-vector system and compare against low-rank factorization\nwith SVD. On the VOiCES 2019 far-field corpus we were able to reduce the\nweights by 28% compared to the full-rank x-vector system while keeping the\nrecognition rate constant (1.83% EER).\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 21:32:16 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Georges", "Munir", ""], ["Huang", "Jonathan", ""], ["Bocklet", "Tobias", ""]]}, {"id": "2008.05024", "submitter": "Kuo-Wei Lai", "authors": "Kuo-Wei Lai, Manisha Aggarwal, Peter van Zijl, Xu Li, Jeremias Sulam", "title": "Learned Proximal Networks for Quantitative Susceptibility Mapping", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative Susceptibility Mapping (QSM) estimates tissue magnetic\nsusceptibility distributions from Magnetic Resonance (MR) phase measurements by\nsolving an ill-posed dipole inversion problem. Conventional single orientation\nQSM methods usually employ regularization strategies to stabilize such\ninversion, but may suffer from streaking artifacts or over-smoothing. Multiple\norientation QSM such as calculation of susceptibility through multiple\norientation sampling (COSMOS) can give well-conditioned inversion and an\nartifact free solution but has expensive acquisition costs. On the other hand,\nConvolutional Neural Networks (CNN) show great potential for medical image\nreconstruction, albeit often with limited interpretability. Here, we present a\nLearned Proximal Convolutional Neural Network (LP-CNN) for solving the\nill-posed QSM dipole inversion problem in an iterative proximal gradient\ndescent fashion. This approach combines the strengths of data-driven\nrestoration priors and the clear interpretability of iterative solvers that can\ntake into account the physical model of dipole convolution. During training,\nour LP-CNN learns an implicit regularizer via its proximal, enabling the\ndecoupling between the forward operator and the data-driven parameters in the\nreconstruction algorithm. More importantly, this framework is believed to be\nthe first deep learning QSM approach that can naturally handle an arbitrary\nnumber of phase input measurements without the need for any ad-hoc rotation or\nre-training. We demonstrate that the LP-CNN provides state-of-the-art\nreconstruction results compared to both traditional and deep learning methods\nwhile allowing for more flexibility in the reconstruction process.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 22:35:24 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Lai", "Kuo-Wei", ""], ["Aggarwal", "Manisha", ""], ["van Zijl", "Peter", ""], ["Li", "Xu", ""], ["Sulam", "Jeremias", ""]]}, {"id": "2008.05030", "submitter": "Dylan Slack", "authors": "Dylan Slack, Sophie Hilgard, Sameer Singh, Himabindu Lakkaraju", "title": "Reliable Post hoc Explanations: Modeling Uncertainty in Explainability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As black box explanations are increasingly being employed to establish model\ncredibility in high stakes settings, it is important to ensure that these\nexplanations are accurate and reliable. However, prior work demonstrates that\nexplanations generated by state-of-the-art techniques are inconsistent,\nunstable, and provide very little insight into their correctness and\nreliability. In addition, these methods are also computationally inefficient,\nand require significant hyper-parameter tuning. In this paper, we address the\naforementioned challenges by developing a novel Bayesian framework for\ngenerating local explanations along with their associated uncertainty. We\ninstantiate this framework to obtain Bayesian versions of LIME and KernelSHAP\nwhich output credible intervals for the feature importances, capturing the\nassociated uncertainty. The resulting explanations not only enable us to make\nconcrete inferences about their quality (e.g., there is a 95\\% chance that the\nfeature importance lies within the given range), but are also highly consistent\nand stable. We carry out a detailed theoretical analysis that leverages the\naforementioned uncertainty to estimate how many perturbations to sample, and\nhow to sample for faster convergence. This work makes the first attempt at\naddressing several critical issues with popular explanation methods in one\nshot, thereby generating consistent, stable, and reliable explanations with\nguarantees in a computationally efficient manner. Experimental evaluation with\nmultiple real world datasets and user studies demonstrate that the efficacy of\nthe proposed framework.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 22:52:21 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 18:55:01 GMT"}, {"version": "v3", "created": "Sun, 11 Jul 2021 01:50:27 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Slack", "Dylan", ""], ["Hilgard", "Sophie", ""], ["Singh", "Sameer", ""], ["Lakkaraju", "Himabindu", ""]]}, {"id": "2008.05042", "submitter": "Basheer Qolomany", "authors": "Basheer Qolomany, Ihab Mohammed, Ala Al-Fuqaha, Mohsen Guizan, Junaid\n  Qadir", "title": "Trust-Based Cloud Machine Learning Model Selection For Industrial IoT\n  and Smart City Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With Machine Learning (ML) services now used in a number of mission-critical\nhuman-facing domains, ensuring the integrity and trustworthiness of ML models\nbecomes all-important. In this work, we consider the paradigm where cloud\nservice providers collect big data from resource-constrained devices for\nbuilding ML-based prediction models that are then sent back to be run locally\non the intermittently-connected resource-constrained devices. Our proposed\nsolution comprises an intelligent polynomial-time heuristic that maximizes the\nlevel of trust of ML models by selecting and switching between a subset of the\nML models from a superset of models in order to maximize the trustworthiness\nwhile respecting the given reconfiguration budget/rate and reducing the cloud\ncommunication overhead. We evaluate the performance of our proposed heuristic\nusing two case studies. First, we consider Industrial IoT (IIoT) services, and\nas a proxy for this setting, we use the turbofan engine degradation simulation\ndataset to predict the remaining useful life of an engine. Our results in this\nsetting show that the trust level of the selected models is 0.49% to 3.17% less\ncompared to the results obtained using Integer Linear Programming (ILP).\nSecond, we consider Smart Cities services, and as a proxy of this setting, we\nuse an experimental transportation dataset to predict the number of cars. Our\nresults show that the selected model's trust level is 0.7% to 2.53% less\ncompared to the results obtained using ILP. We also show that our proposed\nheuristic achieves an optimal competitive ratio in a polynomial-time\napproximation scheme for the problem.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 23:58:03 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Qolomany", "Basheer", ""], ["Mohammed", "Ihab", ""], ["Al-Fuqaha", "Ala", ""], ["Guizan", "Mohsen", ""], ["Qadir", "Junaid", ""]]}, {"id": "2008.05044", "submitter": "Eric Chen", "authors": "Eric Z. Chen, Xiao Chen, Jingyuan Lyu, Yuan Zheng, Terrence Chen, Jian\n  Xu, Shanhui Sun", "title": "Real-Time Cardiac Cine MRI with Residual Convolutional Recurrent Neural\n  Network", "comments": "Presented at ISMRM 2020 as the digital poster", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time cardiac cine MRI does not require ECG gating in the data\nacquisition and is more useful for patients who can not hold their breaths or\nhave abnormal heart rhythms. However, to achieve fast image acquisition,\nreal-time cine commonly acquires highly undersampled data, which imposes a\nsignificant challenge for MRI image reconstruction. We propose a residual\nconvolutional RNN for real-time cardiac cine reconstruction. To the best of our\nknowledge, this is the first work applying deep learning approach to Cartesian\nreal-time cardiac cine reconstruction. Based on the evaluation from\nradiologists, our deep learning model shows superior performance than\ncompressed sensing.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 00:23:05 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 14:35:56 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Chen", "Eric Z.", ""], ["Chen", "Xiao", ""], ["Lyu", "Jingyuan", ""], ["Zheng", "Yuan", ""], ["Chen", "Terrence", ""], ["Xu", "Jian", ""], ["Sun", "Shanhui", ""]]}, {"id": "2008.05049", "submitter": "Dianbo Sui", "authors": "Dianbo Sui, Yubo Chen, Kang Liu and Jun Zhao", "title": "Distantly Supervised Relation Extraction in Federated Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates distantly supervised relation extraction in federated\nsettings. Previous studies focus on distant supervision under the assumption of\ncentralized training, which requires collecting texts from different platforms\nand storing them on one machine. However, centralized training is challenged by\ntwo issues, namely, data barriers and privacy protection, which make it almost\nimpossible or cost-prohibitive to centralize data from multiple platforms.\nTherefore, it is worthy to investigate distant supervision in the federated\nlearning paradigm, which decouples the model training from the need for direct\naccess to the raw data. Overcoming label noise of distant supervision, however,\nbecomes more difficult in federated settings, since the sentences containing\nthe same entity pair may scatter around different platforms. In this paper, we\npropose a federated denoising framework to suppress label noise in federated\nsettings. The core of this framework is a multiple instance learning based\ndenoising method that is able to select reliable instances via cross-platform\ncollaboration. Various experimental results on New York Times dataset and miRNA\ngene regulation relation dataset demonstrate the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 00:58:39 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Sui", "Dianbo", ""], ["Chen", "Yubo", ""], ["Liu", "Kang", ""], ["Zhao", "Jun", ""]]}, {"id": "2008.05052", "submitter": "Sisi Ma", "authors": "Sisi Ma, Roshan Tourani", "title": "Predictive and Causal Implications of using Shapley Value for Model\n  Interpretation", "comments": "Accepted by KDD CD workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shapley value is a concept from game theory. Recently, it has been used for\nexplaining complex models produced by machine learning techniques. Although the\nmathematical definition of Shapley value is straight-forward, the implication\nof using it as a model interpretation tool is yet to be described. In the\ncurrent paper, we analyzed Shapley value in the Bayesian network framework. We\nestablished the relationship between Shapley value and conditional\nindependence, a key concept in both predictive and causal modeling. Our results\nindicate that, eliminating a variable with high Shapley value from a model do\nnot necessarily impair predictive performance, whereas eliminating a variable\nwith low Shapley value from a model could impair performance. Therefore, using\nShapley value for feature selection do not result in the most parsimonious and\npredictively optimal model in the general case. More importantly, Shapley value\nof a variable do not reflect their causal relationship with the target of\ninterest.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 01:08:08 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Ma", "Sisi", ""], ["Tourani", "Roshan", ""]]}, {"id": "2008.05058", "submitter": "Abhinav Valada", "authors": "Borna Be\\v{s}i\\'c and Abhinav Valada", "title": "Dynamic Object Removal and Spatio-Temporal RGB-D Inpainting via\n  Geometry-Aware Adversarial Learning", "comments": "Dataset, code and models are available at\n  http://rl.uni-freiburg.de/research/rgbd-inpainting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic objects have a significant impact on the robot's perception of the\nenvironment which degrades the performance of essential tasks such as\nlocalization and mapping. In this work, we address this problem by synthesizing\nplausible color, texture and geometry in regions occluded by dynamic objects.\nWe propose the novel geometry-aware DynaFill architecture that follows a\ncoarse-to-fine topology and incorporates our gated recurrent feedback mechanism\nto adaptively fuse information from previous timesteps. We optimize our\narchitecture using adversarial training to synthesize fine realistic textures\nwhich enables it to hallucinate color and depth structure in occluded regions\nonline in a spatially and temporally coherent manner, without relying on future\nframe information. Casting our inpainting problem as an image-to-image\ntranslation task, our model also corrects regions correlated with the presence\nof dynamic objects in the scene, such as shadows or reflections. We introduce a\nlarge-scale hyperrealistic dataset with RGB-D images, semantic segmentation\nlabels, camera poses as well as groundtruth RGB-D information of occluded\nregions. Extensive quantitative and qualitative evaluations show that our\napproach achieves state-of-the-art performance, even in challenging weather\nconditions. Furthermore, we present results for retrieval-based visual\nlocalization with the synthesized images that demonstrate the utility of our\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 01:23:21 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 16:33:29 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 01:40:17 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Be\u0161i\u0107", "Borna", ""], ["Valada", "Abhinav", ""]]}, {"id": "2008.05060", "submitter": "Mona Jalal", "authors": "Won Hwa Kim, Mona Jalal, Seongjae Hwang, Sterling C. Johnson, Vikas\n  Singh", "title": "Online Graph Completion: Multivariate Signal Recovery in Computer Vision", "comments": "9 pages, 7 figures, CVPR 2017 Conference", "journal-ref": null, "doi": "10.1109/CVPR.2017.533", "report-no": null, "categories": "cs.CV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adoption of \"human-in-the-loop\" paradigms in computer vision and machine\nlearning is leading to various applications where the actual data acquisition\n(e.g., human supervision) and the underlying inference algorithms are closely\ninterwined. While classical work in active learning provides effective\nsolutions when the learning module involves classification and regression\ntasks, many practical issues such as partially observed measurements, financial\nconstraints and even additional distributional or structural aspects of the\ndata typically fall outside the scope of this treatment. For instance, with\nsequential acquisition of partial measurements of data that manifest as a\nmatrix (or tensor), novel strategies for completion (or collaborative\nfiltering) of the remaining entries have only been studied recently. Motivated\nby vision problems where we seek to annotate a large dataset of images via a\ncrowdsourced platform or alternatively, complement results from a\nstate-of-the-art object detector using human feedback, we study the\n\"completion\" problem defined on graphs, where requests for additional\nmeasurements must be made sequentially. We design the optimization model in the\nFourier domain of the graph describing how ideas based on adaptive\nsubmodularity provide algorithms that work well in practice. On a large set of\nimages collected from Imgur, we see promising results on images that are\notherwise difficult to categorize. We also show applications to an experimental\ndesign problem in neuroimaging.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 01:34:21 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Kim", "Won Hwa", ""], ["Jalal", "Mona", ""], ["Hwang", "Seongjae", ""], ["Johnson", "Sterling C.", ""], ["Singh", "Vikas", ""]]}, {"id": "2008.05086", "submitter": "Vikas Joshi", "authors": "Vikas Joshi, Rui Zhao, Rupesh R. Mehta, Kshitiz Kumar, Jinyu Li", "title": "Transfer Learning Approaches for Streaming End-to-End Speech Recognition\n  System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning (TL) is widely used in conventional hybrid automatic speech\nrecognition (ASR) system, to transfer the knowledge from source to target\nlanguage. TL can be applied to end-to-end (E2E) ASR system such as recurrent\nneural network transducer (RNN-T) models, by initializing the encoder and/or\nprediction network of the target language with the pre-trained models from\nsource language. In the hybrid ASR system, transfer learning is typically done\nby initializing the target language acoustic model (AM) with source language\nAM. Several transfer learning strategies exist in the case of the RNN-T\nframework, depending upon the choice of the initialization model for encoder\nand prediction networks. This paper presents a comparative study of four\ndifferent TL methods for RNN-T framework. We show 17% relative word error rate\nreduction with different TL methods over randomly initialized RNN-T model. We\nalso study the impact of TL with varying amount of training data ranging from\n50 hours to 1000 hours and show the efficacy of TL for languages with small\namount of training data.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 03:25:05 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 14:27:06 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Joshi", "Vikas", ""], ["Zhao", "Rui", ""], ["Mehta", "Rupesh R.", ""], ["Kumar", "Kshitiz", ""], ["Li", "Jinyu", ""]]}, {"id": "2008.05088", "submitter": "Julie Iskander Dr", "authors": "Julie Iskander and Mohammed Hossny", "title": "An ocular biomechanics environment for reinforcement learning", "comments": "5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has been applied to human movement through\nphysiologically-based biomechanical models to add insights into the neural\ncontrol of these movements; it is also useful in the design of prosthetics and\nrobotics. In this paper, we extend the use of reinforcement learning into\ncontrolling an ocular biomechanical system to perform saccades, which is one of\nthe fastest eye movement systems. We describe an ocular environment and an\nagent trained using Deep Deterministic Policy Gradients method to perform\nsaccades. The agent was able to match the desired eye position with a mean\ndeviation angle of 3:5+/-1:25 degrees. The proposed framework is a first step\ntowards using the capabilities of deep reinforcement learning to enhance our\nunderstanding of ocular biomechanics.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 03:39:37 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Iskander", "Julie", ""], ["Hossny", "Mohammed", ""]]}, {"id": "2008.05089", "submitter": "Dai Quoc Nguyen", "authors": "Dai Quoc Nguyen and Tu Dinh Nguyen and Dinh Phung", "title": "Quaternion Graph Neural Networks", "comments": "The extended abstract has been accepted to NeurIPS 2020 Workshop on\n  Differential Geometry meets Deep Learning (DiffGeo4DL). The code in Pytorch\n  and Tensorflow is available at: https://github.com/daiquocnguyen/QGNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, graph neural networks (GNNs) become a principal research direction\nto learn low-dimensional continuous embeddings of nodes and graphs to predict\nnode and graph labels, respectively. However, Euclidean embeddings have high\ndistortion when using GNNs to model complex graphs such as social networks.\nFurthermore, existing GNNs are not very efficient with the high number of model\nparameters when increasing the number of hidden layers. Therefore, we move\nbeyond the Euclidean space to a hyper-complex vector space to improve graph\nrepresentation quality and reduce the number of model parameters. To this end,\nwe propose quaternion graph neural networks (QGNN) to generalize GCNs within\nthe Quaternion space to learn quaternion embeddings for nodes and graphs. The\nQuaternion space, a hyper-complex vector space, provides highly meaningful\ncomputations through Hamilton product compared to the Euclidean and complex\nvector spaces. As a result, our QGNN can reduce the model size up to four times\nand enhance learning better graph representations. Experimental results show\nthat the proposed QGNN produces state-of-the-art accuracies on a range of\nwell-known benchmark datasets for three downstream tasks, including graph\nclassification, semi-supervised node classification, and text (node)\nclassification. Our code is available at: https://github.com/daiquocnguyen/QGNN\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 03:41:03 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 18:30:29 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 15:20:22 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Nguyen", "Dai Quoc", ""], ["Nguyen", "Tu Dinh", ""], ["Phung", "Dinh", ""]]}, {"id": "2008.05095", "submitter": "Jianye Pang", "authors": "Jianye Pang, Kai Yi, Wanguang Yin, Min Xu", "title": "Experimental Analysis of Legendre Decomposition in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this technical report, we analyze Legendre decomposition for non-negative\ntensor in theory and application. In theory, the properties of dual parameters\nand dually flat manifold in Legendre decomposition are reviewed, and the\nprocess of tensor projection and parameter updating is analyzed. In\napplication, a series of verification experiments and clustering experiments\nwith parameters on submanifold were carried out, hoping to find an effective\nlower dimensional representation of the input tensor. The experimental results\nshow that the parameters on submanifold have no ability to be directly used as\nlow-rank representations. Combined with analysis, we connect Legendre\ndecomposition with neural networks and low-rank representation applications,\nand put forward some promising prospects.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 04:11:17 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 14:08:41 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Pang", "Jianye", ""], ["Yi", "Kai", ""], ["Yin", "Wanguang", ""], ["Xu", "Min", ""]]}, {"id": "2008.05101", "submitter": "Bohan Zhuang", "authors": "Peng Chen, Bohan Zhuang, Chunhua Shen", "title": "FATNN: Fast and Accurate Ternary Neural Networks", "comments": "Accepted to Proc. Int. Conf. Computer Vision, ICCV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ternary Neural Networks (TNNs) have received much attention due to being\npotentially orders of magnitude faster in inference, as well as more power\nefficient, than full-precision counterparts. However, 2 bits are required to\nencode the ternary representation with only 3 quantization levels leveraged. As\na result, conventional TNNs have similar memory consumption and speed compared\nwith the standard 2-bit models, but have worse representational capability.\nMoreover, there is still a significant gap in accuracy between TNNs and\nfull-precision networks, hampering their deployment to real applications. To\ntackle these two challenges, in this work, we first show that, under some mild\nconstraints, computational complexity of the ternary inner product can be\nreduced by a factor of 2. Second, to mitigate the performance gap, we\nelaborately design an implementation-dependent ternary quantization algorithm.\nThe proposed framework is termed Fast and Accurate Ternary Neural Networks\n(FATNN). Experiments on image classification demonstrate that our FATNN\nsurpasses the state-of-the-arts by a significant margin in accuracy. More\nimportantly, speedup evaluation compared with various precisions is analyzed on\nseveral platforms, which serves as a strong benchmark for further research.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 04:26:18 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 09:21:34 GMT"}, {"version": "v3", "created": "Fri, 19 Mar 2021 03:57:13 GMT"}, {"version": "v4", "created": "Thu, 29 Jul 2021 11:50:10 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Chen", "Peng", ""], ["Zhuang", "Bohan", ""], ["Shen", "Chunhua", ""]]}, {"id": "2008.05117", "submitter": "Stefano Cerri", "authors": "Stefano Cerri, Andrew Hoopes, Douglas N. Greve, Mark M\\\"uhlau, Koen\n  Van Leemput", "title": "A Longitudinal Method for Simultaneous Whole-Brain and Lesion\n  Segmentation in Multiple Sclerosis", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-66843-3_12", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel method for the segmentation of longitudinal\nbrain MRI scans of patients suffering from Multiple Sclerosis. The method\nbuilds upon an existing cross-sectional method for simultaneous whole-brain and\nlesion segmentation, introducing subject-specific latent variables to encourage\ntemporal consistency between longitudinal scans. It is very generally\napplicable, as it does not make any prior assumptions on the scanner, the MRI\nprotocol, or the number and timing of longitudinal follow-up scans. Preliminary\nexperiments on three longitudinal datasets indicate that the proposed method\nproduces more reliable segmentations and detects disease effects better than\nthe cross-sectional method it is based upon.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 05:43:59 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 13:03:48 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Cerri", "Stefano", ""], ["Hoopes", "Andrew", ""], ["Greve", "Douglas N.", ""], ["M\u00fchlau", "Mark", ""], ["Van Leemput", "Koen", ""]]}, {"id": "2008.05123", "submitter": "Yan Qin", "authors": "Yan Qin, Chau Yuen, Stefan Adams", "title": "Invariant learning based multi-stage identification for Lithium-ion\n  battery performance degradation", "comments": "Accepted by IECON 2020 (The 46th Annual Conference of the IEEE\n  Industrial Electronics Society)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By informing accurate performance (e.g., capacity), health state management\nplays a significant role in safeguarding battery and its powered system. While\nmost current approaches are primarily based on data-driven methods, lacking\nin-depth analysis of battery performance degradation mechanism may discount\ntheir performances. To fill in the research gap about data-driven battery\nperformance degradation analysis, an invariant learning based method is\nproposed to investigate whether the battery performance degradation follows a\nfixed behavior. First, to unfold the hidden dynamics of cycling battery data,\nmeasurements are reconstructed in phase subspace. Next, a novel multi-stage\ndivision strategy is put forward to judge the existent of multiple degradation\nbehaviors. Then the whole aging procedure is sequentially divided into several\nsegments, among which cycling data with consistent degradation speed are\nassigned in the same stage. Simulations on a well-know benchmark verify the\nefficacy of the proposed multi-stages identification strategy. The proposed\nmethod not only enables insights into degradation mechanism from data\nperspective, but also will be helpful to related topics, such as stage of\nhealth.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 06:09:46 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Qin", "Yan", ""], ["Yuen", "Chau", ""], ["Adams", "Stefan", ""]]}, {"id": "2008.05124", "submitter": "Manuele Rusci Mr.", "authors": "Manuele Rusci, Marco Fariselli, Alessandro Capotondi, Luca Benini", "title": "Leveraging Automated Mixed-Low-Precision Quantization for tiny edge\n  microcontrollers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The severe on-chip memory limitations are currently preventing the deployment\nof the most accurate Deep Neural Network (DNN) models on tiny MicroController\nUnits (MCUs), even if leveraging an effective 8-bit quantization scheme. To\ntackle this issue, in this paper we present an automated mixed-precision\nquantization flow based on the HAQ framework but tailored for the memory and\ncomputational characteristics of MCU devices. Specifically, a Reinforcement\nLearning agent searches for the best uniform quantization levels, among 2, 4, 8\nbits, of individual weight and activation tensors, under the tight constraints\non RAM and FLASH embedded memory sizes. We conduct an experimental analysis on\nMobileNetV1, MobileNetV2 and MNasNet models for Imagenet classification.\nConcerning the quantization policy search, the RL agent selects quantization\npolicies that maximize the memory utilization. Given an MCU-class memory bound\nof 2MB for weight-only quantization, the compressed models produced by the\nmixed-precision engine result as accurate as the state-of-the-art solutions\nquantized with a non-uniform function, which is not tailored for CPUs featuring\ninteger-only arithmetic. This denotes the viability of uniform quantization,\nrequired for MCU deployments, for deep weights compression. When also limiting\nthe activation memory budget to 512kB, the best MobileNetV1 model scores up to\n68.4% on Imagenet thanks to the found quantization policy, resulting to be 4%\nmore accurate than the other 8-bit networks fitting the same memory\nconstraints.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 06:09:58 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Rusci", "Manuele", ""], ["Fariselli", "Marco", ""], ["Capotondi", "Alessandro", ""], ["Benini", "Luca", ""]]}, {"id": "2008.05129", "submitter": "Xin Sun", "authors": "Xin Sun, Chi Zhang, Guosheng Lin and Keck-Voon Ling", "title": "Open Set Recognition with Conditional Probabilistic Generative Models", "comments": "Extended version of CGDL arXiv:2003.08823 in CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have made breakthroughs in a wide range of visual\nunderstanding tasks. A typical challenge that hinders their real-world\napplications is that unknown samples may be fed into the system during the\ntesting phase, but traditional deep neural networks will wrongly recognize\nthese unknown samples as one of the known classes. Open set recognition (OSR)\nis a potential solution to overcome this problem, where the open set classifier\nshould have the flexibility to reject unknown samples and meanwhile maintain\nhigh classification accuracy in known classes. Probabilistic generative models,\nsuch as Variational Autoencoders (VAE) and Adversarial Autoencoders (AAE), are\npopular methods to detect unknowns, but they cannot provide discriminative\nrepresentations for known classification. In this paper, we propose a novel\nframework, called Conditional Probabilistic Generative Models (CPGM), for open\nset recognition. The core insight of our work is to add discriminative\ninformation into the probabilistic generative models, such that the proposed\nmodels can not only detect unknown samples but also classify known classes by\nforcing different latent features to approximate conditional Gaussian\ndistributions. We discuss many model variants and provide comprehensive\nexperiments to study their characteristics. Experiment results on multiple\nbenchmark datasets reveal that the proposed method significantly outperforms\nthe baselines and achieves new state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 06:23:49 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 10:18:43 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Sun", "Xin", ""], ["Zhang", "Chi", ""], ["Lin", "Guosheng", ""], ["Ling", "Keck-Voon", ""]]}, {"id": "2008.05131", "submitter": "Deren Lei", "authors": "Yilei Zeng, Deren Lei, Beichen Li, Gangrong Jiang, Emilio Ferrara,\n  Michael Zyda", "title": "Learning to Reason in Round-based Games: Multi-task Sequence Generation\n  for Purchasing Decision Making in First-person Shooters", "comments": "16th AAAI Conference on Artificial Intelligence and Interactive\n  Digital Entertainment (AIIDE-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential reasoning is a complex human ability, with extensive previous\nresearch focusing on gaming AI in a single continuous game, round-based\ndecision makings extending to a sequence of games remain less explored.\nCounter-Strike: Global Offensive (CS:GO), as a round-based game with abundant\nexpert demonstrations, provides an excellent environment for multi-player\nround-based sequential reasoning. In this work, we propose a Sequence Reasoner\nwith Round Attribute Encoder and Multi-Task Decoder to interpret the strategies\nbehind the round-based purchasing decisions. We adopt few-shot learning to\nsample multiple rounds in a match, and modified model agnostic meta-learning\nalgorithm Reptile for the meta-learning loop. We formulate each round as a\nmulti-task sequence generation problem. Our state representations combine\naction encoder, team encoder, player features, round attribute encoder, and\neconomy encoders to help our agent learn to reason under this specific\nmulti-player round-based scenario. A complete ablation study and comparison\nwith the greedy approach certify the effectiveness of our model. Our research\nwill open doors for interpretable AI for understanding episodic and long-term\npurchasing strategies beyond the gaming community.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 06:29:26 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Zeng", "Yilei", ""], ["Lei", "Deren", ""], ["Li", "Beichen", ""], ["Jiang", "Gangrong", ""], ["Ferrara", "Emilio", ""], ["Zyda", "Michael", ""]]}, {"id": "2008.05132", "submitter": "Jieshan Chen", "authors": "Jieshan Chen, Mulong Xie, Zhenchang Xing, Chunyang Chen, Xiwei Xu,\n  Liming Zhu and Guoqiang Li", "title": "Object Detection for Graphical User Interface: Old Fashioned or Deep\n  Learning or a Combination?", "comments": "13 pages, accepted to ESEC/FSE '20", "journal-ref": null, "doi": "10.1145/3368089.3409691", "report-no": null, "categories": "cs.CV cs.HC cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting Graphical User Interface (GUI) elements in GUI images is a\ndomain-specific object detection task. It supports many software engineering\ntasks, such as GUI animation and testing, GUI search and code generation.\nExisting studies for GUI element detection directly borrow the mature methods\nfrom computer vision (CV) domain, including old fashioned ones that rely on\ntraditional image processing features (e.g., canny edge, contours), and deep\nlearning models that learn to detect from large-scale GUI data. Unfortunately,\nthese CV methods are not originally designed with the awareness of the unique\ncharacteristics of GUIs and GUI elements and the high localization accuracy of\nthe GUI element detection task. We conduct the first large-scale empirical\nstudy of seven representative GUI element detection methods on over 50k GUI\nimages to understand the capabilities, limitations and effective designs of\nthese methods. This study not only sheds the light on the technical challenges\nto be addressed but also informs the design of new GUI element detection\nmethods. We accordingly design a new GUI-specific old-fashioned method for\nnon-text GUI element detection which adopts a novel top-down coarse-to-fine\nstrategy, and incorporate it with the mature deep learning model for GUI text\ndetection.Our evaluation on 25,000 GUI images shows that our method\nsignificantly advances the start-of-the-art performance in GUI element\ndetection.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 06:36:33 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 12:57:33 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Chen", "Jieshan", ""], ["Xie", "Mulong", ""], ["Xing", "Zhenchang", ""], ["Chen", "Chunyang", ""], ["Xu", "Xiwei", ""], ["Zhu", "Liming", ""], ["Li", "Guoqiang", ""]]}, {"id": "2008.05157", "submitter": "Di Qiu", "authors": "Di Qiu, Jin Zeng, Zhanghan Ke, Wenxiu Sun, Chengxi Yang", "title": "Towards Geometry Guided Neural Relighting with Flash Photography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous image based relighting methods require capturing multiple images to\nacquire high frequency lighting effect under different lighting conditions,\nwhich needs nontrivial effort and may be unrealistic in certain practical use\nscenarios. While such approaches rely entirely on cleverly sampling the color\nimages under different lighting conditions, little has been done to utilize\ngeometric information that crucially influences the high-frequency features in\nthe images, such as glossy highlight and cast shadow. We therefore propose a\nframework for image relighting from a single flash photograph with its\ncorresponding depth map using deep learning. By incorporating the depth map,\nour approach is able to extrapolate realistic high-frequency effects under\nnovel lighting via geometry guided image decomposition from the flashlight\nimage, and predict the cast shadow map from the shadow-encoding transformed\ndepth map. Moreover, the single-image based setup greatly simplifies the data\ncapture process. We experimentally validate the advantage of our geometry\nguided approach over state-of-the-art image-based approaches in intrinsic image\ndecomposition and image relighting, and also demonstrate our performance on\nreal mobile phone photo examples.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 08:03:28 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Qiu", "Di", ""], ["Zeng", "Jin", ""], ["Ke", "Zhanghan", ""], ["Sun", "Wenxiu", ""], ["Yang", "Chengxi", ""]]}, {"id": "2008.05163", "submitter": "Rudolf Jagdhuber", "authors": "Rudolf Jagdhuber and J\\\"org Rahnenf\\\"uhrer", "title": "Implications on Feature Detection when using the Benefit-Cost Ratio", "comments": "v2: Added ancillary files and corrected floating of figures. 10\n  pages, 2 figures, submitted to SN Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many practical machine learning applications, there are two objectives:\none is to maximize predictive accuracy and the other is to minimize costs of\nthe resulting model. These costs of individual features may be financial costs,\nbut can also refer to other aspects, like for example evaluation time. Feature\nselection addresses both objectives, as it reduces the number of features and\ncan improve the generalization ability of the model. If costs differ between\nfeatures, the feature selection needs to trade-off the individual benefit and\ncost of each feature. A popular trade-off choice is the ratio of both, the BCR\n(benefit-cost ratio). In this paper we analyze implications of using this\nmeasure with special focus to the ability to distinguish relevant features from\nnoise. We perform a simulation study for different cost and data settings and\nobtain detection rates of relevant features and empirical distributions of the\ntrade-off ratio. Our simulation study exposed a clear impact of the cost\nsetting on the detection rate. In situations with large cost differences and\nsmall effect sizes, the BCR missed relevant features and preferred cheap noise\nfeatures. We conclude that a trade-off between predictive performance and costs\nwithout a controlling hyperparameter can easily overemphasize very cheap noise\nfeatures. While the simple benefit-cost ratio offers an easy solution to\nincorporate costs, it is important to be aware of its risks. Avoiding costs\nclose to 0, rescaling large cost differences, or using a hyperparameter\ntrade-off are ways to counteract the adverse effects exposed in this paper.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 08:25:42 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 16:30:15 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Jagdhuber", "Rudolf", ""], ["Rahnenf\u00fchrer", "J\u00f6rg", ""]]}, {"id": "2008.05168", "submitter": "Tiankui Zhang", "authors": "Tiankui Zhang, Ziduan Wang, Yuanwei Liu, Wenjun Xu and Arumugam\n  Nallanathan", "title": "Caching Placement and Resource Allocation for Cache-Enabling UAV NOMA\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TVT.2020.3015578", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article investigates the cache-enabling unmanned aerial vehicle (UAV)\ncellular networks with massive access capability supported by non-orthogonal\nmultiple access (NOMA). The delivery of a large volume of multimedia contents\nfor ground users is assisted by a mobile UAV base station, which caches some\npopular contents for wireless backhaul link traffic offloading. In\ncache-enabling UAV NOMA networks, the caching placement of content caching\nphase and radio resource allocation of content delivery phase are crucial for\nnetwork performance. To cope with the dynamic UAV locations and content\nrequests in practical scenarios, we formulate the long-term caching placement\nand resource allocation optimization problem for content delivery delay\nminimization as a Markov decision process (MDP). The UAV acts as an agent to\ntake actions for caching placement and resource allocation, which includes the\nuser scheduling of content requests and the power allocation of NOMA users. In\norder to tackle the MDP, we propose a Q-learning based caching placement and\nresource allocation algorithm, where the UAV learns and selects action with\n\\emph{soft ${\\varepsilon}$-greedy} strategy to search for the optimal match\nbetween actions and states. Since the action-state table size of Q-learning\ngrows with the number of states in the dynamic networks, we propose a function\napproximation based algorithm with combination of stochastic gradient descent\nand deep neural networks, which is suitable for large-scale networks. Finally,\nthe numerical results show that the proposed algorithms provide considerable\nperformance compared to benchmark algorithms, and obtain a trade-off between\nnetwork performance and calculation complexity.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 08:33:51 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Zhang", "Tiankui", ""], ["Wang", "Ziduan", ""], ["Liu", "Yuanwei", ""], ["Xu", "Wenjun", ""], ["Nallanathan", "Arumugam", ""]]}, {"id": "2008.05171", "submitter": "Erich Schubert", "authors": "Erich Schubert and Peter J. Rousseeuw", "title": "Fast and Eager k-Medoids Clustering: O(k) Runtime Improvement of the\n  PAM, CLARA, and CLARANS Algorithms", "comments": null, "journal-ref": "Information Systems, 2021", "doi": "10.1016/j.is.2021.101804", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering non-Euclidean data is difficult, and one of the most used\nalgorithms besides hierarchical clustering is the popular algorithm\nPartitioning Around Medoids (PAM), also simply referred to as k-medoids\nclustering. In Euclidean geometry the mean-as used in k-means-is a good\nestimator for the cluster center, but this does not exist for arbitrary\ndissimilarities. PAM uses the medoid instead, the object with the smallest\ndissimilarity to all others in the cluster. This notion of centrality can be\nused with any (dis-)similarity, and thus is of high relevance to many domains\nand applications. A key issue with PAM is its high run time cost. We propose\nmodifications to the PAM algorithm that achieve an O(k)-fold speedup in the\nsecond (\"SWAP\") phase of the algorithm, but will still find the same results as\nthe original PAM algorithm. If we relax the choice of swaps performed (while\nretaining comparable quality), we can further accelerate the algorithm by\neagerly performing additional swaps in each iteration. With the substantially\nfaster SWAP, we can now explore faster initialization strategies, because (i)\nthe classic (\"BUILD\") initialization now becomes the bottleneck, and (ii) our\nswap is fast enough to compensate for worse starting conditions. We also show\nhow the CLARA and CLARANS algorithms benefit from the proposed modifications.\nWhile we do not study the parallelization of our approach in this work, it can\neasily be combined with earlier approaches to use PAM and CLARA on big data\n(some of which use PAM as a subroutine, hence can immediately benefit from\nthese improvements), where the performance with high k becomes increasingly\nimportant. In experiments on real data with k=100,200, we observed a 458x\nrespectively 1191x speedup compared to the original PAM SWAP algorithm, making\nPAM applicable to larger data sets, and in particular to higher k.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 08:37:50 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 08:16:45 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Schubert", "Erich", ""], ["Rousseeuw", "Peter J.", ""]]}, {"id": "2008.05175", "submitter": "Lin Zhang", "authors": "Haiwei Wu, Lin Zhang, Lin Yang, Xuyang Wang, Junjie Wang, Dong Zhang,\n  Ming Li", "title": "Mask Detection and Breath Monitoring from Speech: on Data Augmentation,\n  Feature Representation and Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces our approaches for the Mask and Breathing Sub-Challenge\nin the Interspeech COMPARE Challenge 2020. For the mask detection task, we\ntrain deep convolutional neural networks with filter-bank energies,\ngender-aware features, and speaker-aware features. Support Vector Machines\nfollows as the back-end classifiers for binary prediction on the extracted deep\nembeddings. Several data augmentation schemes are used to increase the quantity\nof training data and improve our models' robustness, including speed\nperturbation, SpecAugment, and random erasing. For the speech breath monitoring\ntask, we investigate different bottleneck features based on the Bi-LSTM\nstructure. Experimental results show that our proposed methods outperform the\nbaselines and achieve 0.746 PCC and 78.8% UAR on the Breathing and Mask\nevaluation set, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 08:42:50 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 08:44:19 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Wu", "Haiwei", ""], ["Zhang", "Lin", ""], ["Yang", "Lin", ""], ["Wang", "Xuyang", ""], ["Wang", "Junjie", ""], ["Zhang", "Dong", ""], ["Li", "Ming", ""]]}, {"id": "2008.05201", "submitter": "Qihao Zhu", "authors": "Qihao Zhu, Zeyu Sun, Xiran Liang, Yingfei Xiong, Lu Zhang", "title": "OCoR: An Overlapping-Aware Code Retriever", "comments": null, "journal-ref": "ASE 2020: 35th IEEE/ACM International Conference on Automated\n  Software Engineering Proceedings", "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code retrieval helps developers reuse the code snippet in the open-source\nprojects. Given a natural language description, code retrieval aims to search\nfor the most relevant code among a set of code. Existing state-of-the-art\napproaches apply neural networks to code retrieval. However, these approaches\nstill fail to capture an important feature: overlaps. The overlaps between\ndifferent names used by different people indicate that two different names may\nbe potentially related (e.g., \"message\" and \"msg\"), and the overlaps between\nidentifiers in code and words in natural language descriptions indicate that\nthe code snippet and the description may potentially be related. To address\nthese problems, we propose a novel neural architecture named OCoR, where we\nintroduce two specifically-designed components to capture overlaps: the first\nembeds identifiers by character to capture the overlaps between identifiers,\nand the second introduces a novel overlap matrix to represent the degrees of\noverlaps between each natural language word and each identifier.\n  The evaluation was conducted on two established datasets. The experimental\nresults show that OCoR significantly outperforms the existing state-of-the-art\napproaches and achieves 13.1% to 22.3% improvements. Moreover, we also\nconducted several in-depth experiments to help understand the performance of\ndifferent components in OCoR.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 09:43:35 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 12:05:03 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Zhu", "Qihao", ""], ["Sun", "Zeyu", ""], ["Liang", "Xiran", ""], ["Xiong", "Yingfei", ""], ["Zhang", "Lu", ""]]}, {"id": "2008.05204", "submitter": "Iason Katsamenis", "authors": "Iason Katsamenis, Eftychios Protopapadakis, Anastasios Doulamis,\n  Nikolaos Doulamis, Athanasios Voulodimos", "title": "Pixel-level Corrosion Detection on Metal Constructions by Fusion of Deep\n  Learning Semantic and Contour Segmentation", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Corrosion detection on metal constructions is a major challenge in civil\nengineering for quick, safe and effective inspection. Existing image analysis\napproaches tend to place bounding boxes around the defected region which is not\nadequate both for structural analysis and pre-fabrication, an innovative\nconstruction concept which reduces maintenance cost, time and improves safety.\nIn this paper, we apply three semantic segmentation-oriented deep learning\nmodels (FCN, U-Net and Mask R-CNN) for corrosion detection, which perform\nbetter in terms of accuracy and time and require a smaller number of annotated\nsamples compared to other deep models, e.g. CNN. However, the final images\nderived are still not sufficiently accurate for structural analysis and\npre-fabrication. Thus, we adopt a novel data projection scheme that fuses the\nresults of color segmentation, yielding accurate but over-segmented contours of\na region, with a processed area of the deep masks, resulting in high-confidence\ncorroded pixels.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 09:54:17 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Katsamenis", "Iason", ""], ["Protopapadakis", "Eftychios", ""], ["Doulamis", "Anastasios", ""], ["Doulamis", "Nikolaos", ""], ["Voulodimos", "Athanasios", ""]]}, {"id": "2008.05214", "submitter": "Heechang Ryu", "authors": "Heechang Ryu, Hayong Shin, Jinkyoo Park", "title": "REMAX: Relational Representation for Multi-Agent Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training a multi-agent reinforcement learning (MARL) model is generally\ndifficult because there are numerous combinations of complex interactions among\nagents that induce certain reward signals. Especially when there is a sparse\nreward signal, the training becomes more difficult. Previous studies have tried\nto resolve this issue by employing an intrinsic reward, which is a signal\nspecifically designed for inducing the interactions among agents, to boost the\nMARL model training. However, this approach requires extensive prior knowledge\nto design an intrinsic reward. To optimize the training of an MARL model, we\npropose a learning-based exploration strategy to generate the initial states of\na game. The proposed method adopts a variational graph autoencoder to represent\na state of a game such that (1) the state can be compactly encoded to the\nlatent representation by considering the relationship among agents, and (2) the\nlatent representation can be used as an effective input to the surrogate model\npredicting the exploration score. The proposed method determines the latent\nrepresentations that maximize the surrogate model and decodes these\nrepresentations to generate the initial states from which the MARL model starts\ntraining. Empirically, we demonstrate that the generated states improve the\ntraining and performance of MARL more than the existing exploration methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 10:23:35 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Ryu", "Heechang", ""], ["Shin", "Hayong", ""], ["Park", "Jinkyoo", ""]]}, {"id": "2008.05221", "submitter": "Manish Gupta", "authors": "Manish Gupta, Puneet Agrawal", "title": "Compression of Deep Learning Models for Text: A Survey", "comments": "Accepted at TKDD for publication. 53 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the fields of natural language processing (NLP) and\ninformation retrieval (IR) have made tremendous progress thanksto deep learning\nmodels like Recurrent Neural Networks (RNNs), Gated Recurrent Units (GRUs) and\nLong Short-Term Memory (LSTMs)networks, and Transformer [120] based models like\nBidirectional Encoder Representations from Transformers (BERT) [24],\nGenerativePre-training Transformer (GPT-2) [94], Multi-task Deep Neural Network\n(MT-DNN) [73], Extra-Long Network (XLNet) [134], Text-to-text transfer\ntransformer (T5) [95], T-NLG [98] and GShard [63]. But these models are\nhumongous in size. On the other hand,real world applications demand small model\nsize, low response times and low computational power wattage. In this survey,\nwediscuss six different types of methods (Pruning, Quantization, Knowledge\nDistillation, Parameter Sharing, Tensor Decomposition, andSub-quadratic\nTransformer based methods) for compression of such models to enable their\ndeployment in real industry NLP projects.Given the critical need of building\napplications with efficient and small models, and the large amount of recently\npublished work inthis area, we believe that this survey organizes the plethora\nof work done by the 'deep learning for NLP' community in the past fewyears and\npresents it as a coherent story.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 10:42:14 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 10:41:02 GMT"}, {"version": "v3", "created": "Sun, 11 Apr 2021 12:25:10 GMT"}, {"version": "v4", "created": "Sun, 13 Jun 2021 17:47:28 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Gupta", "Manish", ""], ["Agrawal", "Puneet", ""]]}, {"id": "2008.05223", "submitter": "Patrick Leydon", "authors": "Patrick Leydon, Martin O'Connell, Derek Greene and Kathleen M Curran", "title": "Bone Segmentation in Contrast Enhanced Whole-Body Computed Tomography", "comments": "15 pages, 10 figures and 3 tables. Submitted to The Journal of\n  Physics in Medicine and Biology for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation of bone regions allows for enhanced diagnostics, disease\ncharacterisation and treatment monitoring in CT imaging. In contrast enhanced\nwhole-body scans accurate automatic segmentation is particularly difficult as\nlow dose whole body protocols reduce image quality and make contrast enhanced\nregions more difficult to separate when relying on differences in pixel\nintensities. This paper outlines a U-net architecture with novel preprocessing\ntechniques, based on the windowing of training data and the modification of\nsigmoid activation threshold selection to successfully segment bone-bone marrow\nregions from low dose contrast enhanced whole-body CT scans. The proposed\nmethod achieved mean Dice coefficients of 0.979, 0.965, and 0.934 on two\ninternal datasets and one external test dataset respectively. We have\ndemonstrated that appropriate preprocessing is important for differentiating\nbetween bone and contrast dye, and that excellent results can be achieved with\nlimited data.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 10:48:38 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 14:32:15 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Leydon", "Patrick", ""], ["O'Connell", "Martin", ""], ["Greene", "Derek", ""], ["Curran", "Kathleen M", ""]]}, {"id": "2008.05228", "submitter": "Jugoslav Stojcheski", "authors": "Jugoslav Stojcheski, Valkyrie Felso, Falk Lieder", "title": "Optimal to-do list gamification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What should I work on first? What can wait until later? Which projects should\nI prioritize and which tasks are not worth my time? These are challenging\nquestions that many people face every day. People's intuitive strategy is to\nprioritize their immediate experience over the long-term consequences. This\nleads to procrastination and the neglect of important long-term projects in\nfavor of seemingly urgent tasks that are less important. Optimal gamification\nstrives to help people overcome these problems by incentivizing each task by a\nnumber of points that communicates how valuable it is in the long-run.\nUnfortunately, computing the optimal number of points with standard dynamic\nprogramming methods quickly becomes intractable as the number of a person's\nprojects and the number of tasks required by each project increase. Here, we\nintroduce and evaluate a scalable method for identifying which tasks are most\nimportant in the long run and incentivizing each task according to its\nlong-term value. Our method makes it possible to create to-do list gamification\napps that can handle the size and complexity of people's to-do lists in the\nreal world.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 10:59:13 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Stojcheski", "Jugoslav", ""], ["Felso", "Valkyrie", ""], ["Lieder", "Falk", ""]]}, {"id": "2008.05232", "submitter": "Gregor Cerar", "authors": "Gregor Cerar, Halil Yetgin, Bla\\v{z} Bertalani\\v{c}, Carolina Fortuna", "title": "Learning to Detect Anomalous Wireless Links in IoT Networks", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2020.3039333", "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After decades of research, the Internet of Things (IoT) is finally permeating\nreal-life and helps improve the efficiency of infrastructures and processes as\nwell as our health. As a massive number of IoT devices are deployed, they\nnaturally incur great operational costs to ensure intended operations. To\neffectively handle such intended operations in massive IoT networks, automatic\ndetection of malfunctioning, namely anomaly detection, becomes a critical but\nchallenging task. In this paper, motivated by a real-world experimental IoT\ndeployment, we introduce four types of wireless network anomalies that are\nidentified at the link layer. We study the performance of threshold- and\nmachine learning (ML)-based classifiers to automatically detect these\nanomalies. We examine the relative performance of three supervised and three\nunsupervised ML techniques on both non-encoded and encoded (autoencoder)\nfeature representations. Our results demonstrate that; i) selected supervised\napproaches are able to detect anomalies with F1 scores of above 0.98, while\nunsupervised ones are also capable of detecting the said anomalies with F1\nscores of, on average, 0.90, and ii) OC-SVM outperforms all the other\nunsupervised ML approaches reaching at F1 scores of 0.99 for SuddenD, 0.95 for\nSuddenR, 0.93 for InstaD and 0.95 for SlowD.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 11:03:57 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 20:38:50 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Cerar", "Gregor", ""], ["Yetgin", "Halil", ""], ["Bertalani\u010d", "Bla\u017e", ""], ["Fortuna", "Carolina", ""]]}, {"id": "2008.05247", "submitter": "Alex Serban", "authors": "Alex Serban, Erik Poll, Joost Visser", "title": "Learning to Learn from Mistakes: Robust Optimization for Adversarial\n  Noise", "comments": "Published at ICANN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sensitivity to adversarial noise hinders deployment of machine learning\nalgorithms in security-critical applications. Although many adversarial\ndefenses have been proposed, robustness to adversarial noise remains an open\nproblem. The most compelling defense, adversarial training, requires a\nsubstantial increase in processing time and it has been shown to overfit on the\ntraining data. In this paper, we aim to overcome these limitations by training\nrobust models in low data regimes and transfer adversarial knowledge between\ndifferent models. We train a meta-optimizer which learns to robustly optimize a\nmodel using adversarial examples and is able to transfer the knowledge learned\nto new models, without the need to generate new adversarial examples.\nExperimental results show the meta-optimizer is consistent across different\narchitectures and data sets, suggesting it is possible to automatically patch\nadversarial vulnerabilities.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 11:44:01 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Serban", "Alex", ""], ["Poll", "Erik", ""], ["Visser", "Joost", ""]]}, {"id": "2008.05248", "submitter": "Thomas Kehrenberg", "authors": "Thomas Kehrenberg, Myles Bartlett, Oliver Thomas, Novi Quadrianto", "title": "Null-sampling for Interpretable and Fair Representations", "comments": "Published as a conference paper at the 16th European Conference on\n  Computer Vision (ECCV), Glasgow, UK, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to learn invariant representations, in the data domain, to achieve\ninterpretability in algorithmic fairness. Invariance implies a selectivity for\nhigh level, relevant correlations w.r.t. class label annotations, and a\nrobustness to irrelevant correlations with protected characteristics such as\nrace or gender. We introduce a non-trivial setup in which the training set\nexhibits a strong bias such that class label annotations are irrelevant and\nspurious correlations cannot be distinguished. To address this problem, we\nintroduce an adversarially trained model with a null-sampling procedure to\nproduce invariant representations in the data domain. To enable\ndisentanglement, a partially-labelled representative set is used. By placing\nthe representations into the data domain, the changes made by the model are\neasily examinable by human auditors. We show the effectiveness of our method on\nboth image and tabular datasets: Coloured MNIST, the CelebA and the Adult\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 11:49:01 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Kehrenberg", "Thomas", ""], ["Bartlett", "Myles", ""], ["Thomas", "Oliver", ""], ["Quadrianto", "Novi", ""]]}, {"id": "2008.05258", "submitter": "Zhanghan Ke", "authors": "Zhanghan Ke, Di Qiu, Kaican Li, Qiong Yan, Rynson W.H. Lau", "title": "Guided Collaborative Training for Pixel-wise Semi-Supervised Learning", "comments": "16th European Conference on Computer Vision (ECCV 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the generalization of semi-supervised learning (SSL) to\ndiverse pixel-wise tasks. Although SSL methods have achieved impressive results\nin image classification, the performances of applying them to pixel-wise tasks\nare unsatisfactory due to their need for dense outputs. In addition, existing\npixel-wise SSL approaches are only suitable for certain tasks as they usually\nrequire to use task-specific properties. In this paper, we present a new SSL\nframework, named Guided Collaborative Training (GCT), for pixel-wise tasks,\nwith two main technical contributions. First, GCT addresses the issues caused\nby the dense outputs through a novel flaw detector. Second, the modules in GCT\nlearn from unlabeled data collaboratively through two newly proposed\nconstraints that are independent of task-specific properties. As a result, GCT\ncan be applied to a wide range of pixel-wise tasks without structural\nadaptation. Our extensive experiments on four challenging vision tasks,\nincluding semantic segmentation, real image denoising, portrait image matting,\nand night image enhancement, show that GCT outperforms state-of-the-art SSL\nmethods by a large margin. Our code available at:\nhttps://github.com/ZHKKKe/PixelSSL.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 12:08:25 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Ke", "Zhanghan", ""], ["Qiu", "Di", ""], ["Li", "Kaican", ""], ["Yan", "Qiong", ""], ["Lau", "Rynson W. H.", ""]]}, {"id": "2008.05289", "submitter": "Dipjyoti Paul", "authors": "Dipjyoti Paul, Yannis Pantazis, Yannis Stylianou", "title": "Speaker Conditional WaveRNN: Towards Universal Neural Vocoder for Unseen\n  Speaker and Recording Conditions", "comments": "Accepted in INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in deep learning led to human-level performance in\nsingle-speaker speech synthesis. However, there are still limitations in terms\nof speech quality when generalizing those systems into multiple-speaker models\nespecially for unseen speakers and unseen recording qualities. For instance,\nconventional neural vocoders are adjusted to the training speaker and have poor\ngeneralization capabilities to unseen speakers. In this work, we propose a\nvariant of WaveRNN, referred to as speaker conditional WaveRNN (SC-WaveRNN). We\ntarget towards the development of an efficient universal vocoder even for\nunseen speakers and recording conditions. In contrast to standard WaveRNN,\nSC-WaveRNN exploits additional information given in the form of speaker\nembeddings. Using publicly-available data for training, SC-WaveRNN achieves\nsignificantly better performance over baseline WaveRNN on both subjective and\nobjective metrics. In MOS, SC-WaveRNN achieves an improvement of about 23% for\nseen speaker and seen recording condition and up to 95% for unseen speaker and\nunseen condition. Finally, we extend our work by implementing a multi-speaker\ntext-to-speech (TTS) synthesis similar to zero-shot speaker adaptation. In\nterms of performance, our system has been preferred over the baseline TTS\nsystem by 60% over 15.5% and by 60.9% over 32.6%, for seen and unseen speakers,\nrespectively.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 13:54:46 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Paul", "Dipjyoti", ""], ["Pantazis", "Yannis", ""], ["Stylianou", "Yannis", ""]]}, {"id": "2008.05332", "submitter": "Pargorn Puttapirat", "authors": "Zeyu Gao, Pargorn Puttapirat, Jiangbo Shi, Chen Li", "title": "Renal Cell Carcinoma Detection and Subtyping with Minimal Point-Based\n  Annotation in Whole-Slide Images", "comments": "10 pages, 5 figure, 3 tables, accepted at MICCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Obtaining a large amount of labeled data in medical imaging is laborious and\ntime-consuming, especially for histopathology. However, it is much easier and\ncheaper to get unlabeled data from whole-slide images (WSIs). Semi-supervised\nlearning (SSL) is an effective way to utilize unlabeled data and alleviate the\nneed for labeled data. For this reason, we proposed a framework that employs an\nSSL method to accurately detect cancerous regions with a novel annotation\nmethod called Minimal Point-Based annotation, and then utilize the predicted\nresults with an innovative hybrid loss to train a classification model for\nsubtyping. The annotator only needs to mark a few points and label them are\ncancer or not in each WSI. Experiments on three significant subtypes of renal\ncell carcinoma (RCC) proved that the performance of the classifier trained with\nthe Min-Point annotated dataset is comparable to a classifier trained with the\nsegmentation annotated dataset for cancer region detection. And the subtyping\nmodel outperforms a model trained with only diagnostic labels by 12% in terms\nof f1-score for testing WSIs.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 14:12:07 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Gao", "Zeyu", ""], ["Puttapirat", "Pargorn", ""], ["Shi", "Jiangbo", ""], ["Li", "Chen", ""]]}, {"id": "2008.05333", "submitter": "Liang Chen", "authors": "Liang Chen", "title": "Variance-reduced Language Pretraining via a Mask Proposal Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning, a.k.a., pretraining, is important in natural\nlanguage processing. Most of the pretraining methods first randomly mask some\npositions in a sentence and then train a model to recover the tokens at the\nmasked positions. In such a way, the model can be trained without human\nlabeling, and the massive data can be used with billion parameters. Therefore,\nthe optimization efficiency becomes critical. In this paper, we tackle the\nproblem from the view of gradient variance reduction. In particular, we first\npropose a principled gradient variance decomposition theorem, which shows that\nthe variance of the stochastic gradient of the language pretraining can be\nnaturally decomposed into two terms: the variance that arises from the sample\nof data in a batch, and the variance that arises from the sampling of the mask.\nThe second term is the key difference between selfsupervised learning and\nsupervised learning, which makes the pretraining slower. In order to reduce the\nvariance of the second part, we leverage the importance sampling strategy,\nwhich aims at sampling the masks according to a proposal distribution instead\nof the uniform distribution. It can be shown that if the proposal distribution\nis proportional to the gradient norm, the variance of the sampling is reduced.\nTo improve efficiency, we introduced a MAsk Proposal Network (MAPNet), which\napproximates the optimal mask proposal distribution and is trained end-to-end\nalong with the model. According to the experimental result, our model converges\nmuch faster and achieves higher performance than the baseline BERT model.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 14:12:32 GMT"}, {"version": "v2", "created": "Sun, 16 Aug 2020 15:40:33 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Chen", "Liang", ""]]}, {"id": "2008.05367", "submitter": "Wei Deng", "authors": "Wei Deng, Qi Feng, Liyao Gao, Faming Liang, Guang Lin", "title": "Non-convex Learning via Replica Exchange Stochastic Gradient MCMC", "comments": "Accepted by ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Replica exchange Monte Carlo (reMC), also known as parallel tempering, is an\nimportant technique for accelerating the convergence of the conventional Markov\nChain Monte Carlo (MCMC) algorithms. However, such a method requires the\nevaluation of the energy function based on the full dataset and is not scalable\nto big data. The na\\\"ive implementation of reMC in mini-batch settings\nintroduces large biases, which cannot be directly extended to the stochastic\ngradient MCMC (SGMCMC), the standard sampling method for simulating from deep\nneural networks (DNNs). In this paper, we propose an adaptive replica exchange\nSGMCMC (reSGMCMC) to automatically correct the bias and study the corresponding\nproperties. The analysis implies an acceleration-accuracy trade-off in the\nnumerical discretization of a Markov jump process in a stochastic environment.\nEmpirically, we test the algorithm through extensive experiments on various\nsetups and obtain the state-of-the-art results on CIFAR10, CIFAR100, and SVHN\nin both supervised learning and semi-supervised learning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 15:02:59 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 02:28:35 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 15:55:25 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Deng", "Wei", ""], ["Feng", "Qi", ""], ["Gao", "Liyao", ""], ["Liang", "Faming", ""], ["Lin", "Guang", ""]]}, {"id": "2008.05373", "submitter": "Abdelrahman Abdallah", "authors": "Abdelrahman Abdallah, Mohamed Hamada and Daniyar Nurseitov", "title": "Attention-based Fully Gated CNN-BGRU for Russian Handwritten Text", "comments": null, "journal-ref": "J. Imaging 2020, 6, 141", "doi": "10.3390/jimaging6120141", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research approaches the task of handwritten text with attention\nencoder-decoder networks that are trained on Kazakh and Russian language. We\ndeveloped a novel deep neural network model based on Fully Gated CNN, supported\nby Multiple bidirectional GRU and Attention mechanisms to manipulate\nsophisticated features that achieve 0.045 Character Error Rate (CER), 0.192\nWord Error Rate (WER) and 0.253 Sequence Error Rate (SER) for the first test\ndataset and 0.064 CER, 0.24 WER and 0.361 SER for the second test dataset.\nAlso, we propose fully gated layers by taking the advantage of multiple the\noutput feature from Tahn and input feature, this proposed work achieves better\nresults and We experimented with our model on the Handwritten Kazakh & Russian\nDatabase (HKR). Our research is the first work on the HKR dataset and\ndemonstrates state-of-the-art results to most of the other existing models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 15:14:47 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 09:54:20 GMT"}, {"version": "v3", "created": "Sat, 15 Aug 2020 18:54:49 GMT"}, {"version": "v4", "created": "Tue, 18 Aug 2020 10:10:31 GMT"}, {"version": "v5", "created": "Thu, 20 Aug 2020 13:59:37 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Abdallah", "Abdelrahman", ""], ["Hamada", "Mohamed", ""], ["Nurseitov", "Daniyar", ""]]}, {"id": "2008.05381", "submitter": "Jeff Druce", "authors": "Shashank Manjunath, Aitzaz Nathaniel, Jeff Druce, Stan German", "title": "Improving the Performance of Fine-Grain Image Classifiers via Generative\n  Data Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in machine learning (ML) and computer vision tools have\nenabled applications in a wide variety of arenas such as financial analytics,\nmedical diagnostics, and even within the Department of Defense. However, their\nwidespread implementation in real-world use cases poses several challenges: (1)\nmany applications are highly specialized, and hence operate in a \\emph{sparse\ndata} domain; (2) ML tools are sensitive to their training sets and typically\nrequire cumbersome, labor-intensive data collection and data labelling\nprocesses; and (3) ML tools can be extremely \"black box,\" offering users little\nto no insight into the decision-making process or how new data might affect\nprediction performance. To address these challenges, we have designed and\ndeveloped Data Augmentation from Proficient Pre-Training of Robust Generative\nAdversarial Networks (DAPPER GAN), an ML analytics support tool that\nautomatically generates novel views of training images in order to improve\ndownstream classifier performance. DAPPER GAN leverages high-fidelity\nembeddings generated by a StyleGAN2 model (trained on the LSUN cars dataset) to\ncreate novel imagery for previously unseen classes. We experimentally evaluate\nthis technique on the Stanford Cars dataset, demonstrating improved vehicle\nmake and model classification accuracy and reduced requirements for real data\nusing our GAN based data augmentation framework. The method's validity was\nsupported through an analysis of classifier performance on both augmented and\nnon-augmented datasets, achieving comparable or better accuracy with up to 30\\%\nless real data across visually similar classes. To support this method, we\ndeveloped a novel augmentation method that can manipulate semantically\nmeaningful dimensions (e.g., orientation) of the target object in the embedding\nspace.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 15:29:11 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Manjunath", "Shashank", ""], ["Nathaniel", "Aitzaz", ""], ["Druce", "Jeff", ""], ["German", "Stan", ""]]}, {"id": "2008.05396", "submitter": "Chenglizhao Chen", "authors": "Chenglizhao Chen, Hongmeng Zhao, Huan Yang, Chong Peng, Teng Yu", "title": "Full Reference Screen Content Image Quality Assessment by Fusing\n  Multi-level Structure Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The screen content images (SCIs) usually comprise various content types with\nsharp edges, in which the artifacts or distortions can be well sensed by the\nvanilla structure similarity measurement in a full reference manner.\nNonetheless, almost all of the current SOTA structure similarity metrics are\n\"locally\" formulated in a single-level manner, while the true human visual\nsystem (HVS) follows the multi-level manner, and such mismatch could eventually\nprevent these metrics from achieving trustworthy quality assessment. To\nameliorate, this paper advocates a novel solution to measure structure\nsimilarity \"globally\" from the perspective of sparse representation. To perform\nmulti-level quality assessment in accordance with the real HVS, the\nabove-mentioned global metric will be integrated with the conventional local\nones by resorting to the newly devised selective deep fusion network. To\nvalidate its efficacy and effectiveness, we have compared our method with 12\nSOTA methods over two widely-used large-scale public SCI datasets, and the\nquantitative results indicate that our method yields significantly higher\nconsistency with subjective quality score than the currently leading works.\nBoth the source code and data are also publicly available to gain widespread\nacceptance and facilitate new advancement and its validation.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 10:20:25 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Chen", "Chenglizhao", ""], ["Zhao", "Hongmeng", ""], ["Yang", "Huan", ""], ["Peng", "Chong", ""], ["Yu", "Teng", ""]]}, {"id": "2008.05397", "submitter": "Chenglizhao Chen", "authors": "Zhenyu Wu, Shuai Li, Chenglizhao Chen, Aimin Hao, Hong Qin", "title": "Rethinking of the Image Salient Object Detection: Object-level Semantic\n  Saliency Re-ranking First, Pixel-wise Saliency Refinement Latter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The real human attention is an interactive activity between our visual system\nand our brain, using both low-level visual stimulus and high-level semantic\ninformation. Previous image salient object detection (SOD) works conduct their\nsaliency predictions in a multi-task manner, i.e., performing pixel-wise\nsaliency regression and segmentation-like saliency refinement at the same time,\nwhich degenerates their feature backbones in revealing semantic information.\nHowever, given an image, we tend to pay more attention to those regions which\nare semantically salient even in the case that these regions are perceptually\nnot the most salient ones at first glance. In this paper, we divide the SOD\nproblem into two sequential tasks: 1) we propose a lightweight, weakly\nsupervised deep network to coarsely locate those semantically salient regions\nfirst; 2) then, as a post-processing procedure, we selectively fuse multiple\noff-the-shelf deep models on these semantically salient regions as the\npixel-wise saliency refinement. In sharp contrast to the state-of-the-art\n(SOTA) methods that focus on learning pixel-wise saliency in \"single image\"\nusing perceptual clues mainly, our method has investigated the \"object-level\nsemantic ranks between multiple images\", of which the methodology is more\nconsistent with the real human attention mechanism. Our method is simple yet\neffective, which is the first attempt to consider the salient object detection\nmainly as an object-level semantic re-ranking problem.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 07:12:43 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Wu", "Zhenyu", ""], ["Li", "Shuai", ""], ["Chen", "Chenglizhao", ""], ["Hao", "Aimin", ""], ["Qin", "Hong", ""]]}, {"id": "2008.05399", "submitter": "Zhiyun Ren", "authors": "Ziwei Fan, Evan Burgun, Zhiyun Ren, Titus Schleyer, Xia Ning", "title": "Improving information retrieval from electronic health records using\n  dynamic and multi-collaborative filtering", "comments": "18 pages, 11 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the rapid growth of information available about individual patients,\nmost physicians suffer from information overload when they review patient\ninformation in health information technology systems. In this manuscript, we\npresent a novel hybrid dynamic and multi-collaborative filtering method to\nimprove information retrieval from electronic health records. This method\nrecommends relevant information from electronic health records for physicians\nduring patient visits. It models information search dynamics using a Markov\nmodel. It also leverages the key idea of collaborative filtering, originating\nfrom Recommender Systems, to prioritize information based on various\nsimilarities among physicians, patients and information items. We tested this\nnew method using real electronic health record data from the Indiana Network\nfor Patient Care. Our experimental results demonstrated that for 46.7% of\ntesting cases, this new method is able to correctly prioritize relevant\ninformation among top-5 recommendations that physicians are truly interested\nin.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 15:46:33 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Fan", "Ziwei", ""], ["Burgun", "Evan", ""], ["Ren", "Zhiyun", ""], ["Schleyer", "Titus", ""], ["Ning", "Xia", ""]]}, {"id": "2008.05409", "submitter": "Oeslle Lucena", "authors": "Oeslle Lucena, Sjoerd B. Vos, Vejay Vakharia, John Duncan, Keyoumars\n  Ashkan, Rachel Sparks, Sebastien Ourselin", "title": "Enhancing Fiber Orientation Distributions using convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate local fiber orientation distribution (FOD) modeling based on\ndiffusion magnetic resonance imaging (dMRI) capable of resolving complex fiber\nconfigurations benefits from specific acquisition protocols that sample a high\nnumber of gradient directions (b-vecs), a high maximum b-value(b-vals), and\nmultiple b-values (multi-shell). However, acquisition time is limited in a\nclinical setting and commercial scanners may not provide such dMRI sequences.\nTherefore, dMRI is often acquired as single-shell (single b-value). In this\nwork, we learn improved FODs for commercially acquired MRI. We evaluate\npatch-based 3D convolutional neural networks (CNNs)on their ability to regress\nmulti-shell FOD representations from single-shell representations, where the\nrepresentation is a spherical harmonics obtained from constrained spherical\ndeconvolution (CSD) to model FODs. We evaluate U-Net and HighResNet 3D CNN\narchitectures on data from the Human Connectome Project and an in-house\ndataset. We evaluate how well each CNN model can resolve local fiber\norientation 1) when training and testing on datasets with the same dMRI\nacquisition protocol; 2) when testing on a dataset with a different dMRI\nacquisition protocol than used to train the CNN models; and 3) when testing on\na dataset with a fewer number of gradient directions than used to train the CNN\nmodels. Our approach may enable robust CSD model estimation on single-shell\ndMRI acquisition protocols with few gradient directions, reducing acquisition\ntimes, facilitating translation of improved FOD estimation to time-limited\nclinical environments.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 16:06:25 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 18:41:44 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Lucena", "Oeslle", ""], ["Vos", "Sjoerd B.", ""], ["Vakharia", "Vejay", ""], ["Duncan", "John", ""], ["Ashkan", "Keyoumars", ""], ["Sparks", "Rachel", ""], ["Ourselin", "Sebastien", ""]]}, {"id": "2008.05427", "submitter": "Kostas Kolomvatsos", "authors": "Kostas Kolomvatsos, Christos Anagnostopoulos", "title": "An Intelligent Edge-Centric Queries Allocation Scheme based on Ensemble\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of Internet of Things (IoT) and Edge Computing (EC) can\nassist in the delivery of novel applications that will facilitate end users\nactivities. Data collected by numerous devices present in the IoT\ninfrastructure can be hosted into a set of EC nodes becoming the subject of\nprocessing tasks for the provision of analytics. Analytics are derived as the\nresult of various queries defined by end users or applications. Such queries\ncan be executed in the available EC nodes to limit the latency in the provision\nof responses. In this paper, we propose a meta-ensemble learning scheme that\nsupports the decision making for the allocation of queries to the appropriate\nEC nodes. Our learning model decides over queries' and nodes' characteristics.\nWe provide the description of a matching process between queries and nodes\nafter concluding the contextual information for each envisioned characteristic\nadopted in our meta-ensemble scheme. We rely on widely known ensemble models,\ncombine them and offer an additional processing layer to increase the\nperformance. The aim is to result a subset of EC nodes that will host each\nincoming query. Apart from the description of the proposed model, we report on\nits evaluation and the corresponding results. Through a large set of\nexperiments and a numerical analysis, we aim at revealing the pros and cons of\nthe proposed scheme.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 16:32:46 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Kolomvatsos", "Kostas", ""], ["Anagnostopoulos", "Christos", ""]]}, {"id": "2008.05437", "submitter": "Meraj Hashemizadeh", "authors": "Meraj Hashemizadeh and Michelle Liu and Jacob Miller and Guillaume\n  Rabusseau", "title": "Adaptive Learning of Tensor Network Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor Networks (TN) offer a powerful framework to efficiently represent very\nhigh-dimensional objects. TN have recently shown their potential for machine\nlearning applications and offer a unifying view of common tensor decomposition\nmodels such as Tucker, tensor train (TT) and tensor ring (TR). However,\nidentifying the best tensor network structure from data for a given task is\nchallenging. In this work, we leverage the TN formalism to develop a generic\nand efficient adaptive algorithm to jointly learn the structure and the\nparameters of a TN from data. Our method is based on a simple greedy approach\nstarting from a rank one tensor and successively identifying the most promising\ntensor network edges for small rank increments. Our algorithm can adaptively\nidentify TN structures with small number of parameters that effectively\noptimize any differentiable objective function. Experiments on tensor\ndecomposition, tensor completion and model compression tasks demonstrate the\neffectiveness of the proposed algorithm. In particular, our method outperforms\nthe state-of-the-art evolutionary topology search [Li and Sun, 2020] for tensor\ndecomposition of images (while being orders of magnitude faster) and finds\nefficient tensor network structures to compress neural networks outperforming\npopular TT based approaches [Novikov et al., 2015].\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 16:41:56 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 18:46:43 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Hashemizadeh", "Meraj", ""], ["Liu", "Michelle", ""], ["Miller", "Jacob", ""], ["Rabusseau", "Guillaume", ""]]}, {"id": "2008.05443", "submitter": "Duong Nguyen", "authors": "Duong Nguyen, Matthieu Simonin, Guillaume Hajduch, Rodolphe Vadaine,\n  C\\'edric Tedeschi and Ronan Fablet", "title": "Detection of Abnormal Vessel Behaviours from AIS data using GeoTrackNet:\n  from the Laboratory to the Ocean", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The constant growth of maritime traffic leads to the need of automatic\nanomaly detection, which has been attracting great research attention.\nInformation provided by AIS (Automatic Identification System) data, together\nwith recent outstanding progresses of deep learning, make vessel monitoring\nusing neural networks (NNs) a very promising approach. This paper analyses a\nnovel neural network we have recently introduced -- GeoTrackNet -- regarding\noperational contexts. Especially, we aim to evaluate (i) the relevance of the\nabnormal behaviours detected by GeoTrackNet with respect to expert\ninterpretations, (ii) the extent to which GeoTrackNet may process AIS data\nstreams in real time. We report experiments showing the high potential to meet\noperational levels of the model.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 17:11:45 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Nguyen", "Duong", ""], ["Simonin", "Matthieu", ""], ["Hajduch", "Guillaume", ""], ["Vadaine", "Rodolphe", ""], ["Tedeschi", "C\u00e9dric", ""], ["Fablet", "Ronan", ""]]}, {"id": "2008.05454", "submitter": "Alessandro Lameiras Koerich", "authors": "Mohammad Esmaeilpour, Raymel Alfonso Sallo, Olivier St-Georges,\n  Patrick Cardinal, Alessandro Lameiras Koerich", "title": "Improving Stability of LS-GANs for Audio and Speech Signals", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the instability issue of generative adversarial\nnetwork (GAN) by proposing a new similarity metric in unitary space of Schur\ndecomposition for 2D representations of audio and speech signals. We show that\nencoding departure from normality computed in this vector space into the\ngenerator optimization formulation helps to craft more comprehensive\nspectrograms. We demonstrate the effectiveness of binding this metric for\nenhancing stability in training with less mode collapse compared to baseline\nGANs. Experimental results on subsets of UrbanSound8k and Mozilla common voice\ndatasets have shown considerable improvements on the quality of the generated\nsamples measured by the Fr\\'echet inception distance. Moreover, reconstructed\nsignals from these samples, have achieved higher signal to noise ratio compared\nto regular LS-GANs.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 17:41:25 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Esmaeilpour", "Mohammad", ""], ["Sallo", "Raymel Alfonso", ""], ["St-Georges", "Olivier", ""], ["Cardinal", "Patrick", ""], ["Koerich", "Alessandro Lameiras", ""]]}, {"id": "2008.05456", "submitter": "Gurtej Kanwar", "authors": "Denis Boyda, Gurtej Kanwar, S\\'ebastien Racani\\`ere, Danilo Jimenez\n  Rezende, Michael S. Albergo, Kyle Cranmer, Daniel C. Hackett, Phiala E.\n  Shanahan", "title": "Sampling using $SU(N)$ gauge equivariant flows", "comments": "24 pages, 19 figures", "journal-ref": "Phys. Rev. D 103, 074504 (2021)", "doi": "10.1103/PhysRevD.103.074504", "report-no": "MIT-CTP/5228", "categories": "hep-lat cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a flow-based sampling algorithm for $SU(N)$ lattice gauge theories\nthat is gauge-invariant by construction. Our key contribution is constructing a\nclass of flows on an $SU(N)$ variable (or on a $U(N)$ variable by a simple\nalternative) that respect matrix conjugation symmetry. We apply this technique\nto sample distributions of single $SU(N)$ variables and to construct flow-based\nsamplers for $SU(2)$ and $SU(3)$ lattice gauge theory in two dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 17:43:39 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 18:39:15 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Boyda", "Denis", ""], ["Kanwar", "Gurtej", ""], ["Racani\u00e8re", "S\u00e9bastien", ""], ["Rezende", "Danilo Jimenez", ""], ["Albergo", "Michael S.", ""], ["Cranmer", "Kyle", ""], ["Hackett", "Daniel C.", ""], ["Shanahan", "Phiala E.", ""]]}, {"id": "2008.05458", "submitter": "Sakshi Mishra", "authors": "Sakshi Mishra, Anya Petersen, Stephen M. Frank, Michelle Slovensky", "title": "Deep Learning Based Load Forecasting: from Research to Deployment --\n  Opportunities and Challenges", "comments": "6 pages, 3 figures, conference paper under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electricity load forecasting for buildings and campuses is becoming\nincreasingly important as the penetration of distributed energy resources\ngrows. Efficient operation and dispatch of DERs requires reasonably accurate\nprediction of future energy consumption in order to conduct near-real-time\noptimized dispatch of on-site generation and storage assets. Load forecasting\nhas traditionally been done by electric utilities for load pockets spanning\nlarge geographic areas and therefore has not been a common practice in the\nbuildings' and campuses' operational arena. Given the growing trends of\nresearch and prototyping in the grid-interactive efficient buildings domain,\ncharacteristics beyond simple algorithm forecast accuracy are important in\ndetermining the algorithm's true utility for the smart buildings. These other\ncharacteristics include the overall design of the deployed architecture and the\noperational efficiency of the forecasting system. In this work, we present a\ndeep-learning-based load forecasting system that predicts the building load at\none-hour interval for 18 hours in the future. We also present the challenges\nassociated with the real-time deployment of such systems as well as the\nresearch opportunities presented by a fully functional forecasting system that\nhas been developed within the National Renewable Energy Laboratory's\nIntelligent Campus program.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 17:47:38 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Mishra", "Sakshi", ""], ["Petersen", "Anya", ""], ["Frank", "Stephen M.", ""], ["Slovensky", "Michelle", ""]]}, {"id": "2008.05459", "submitter": "Jun Qi", "authors": "Jun Qi, Jun Du, Sabato Marco Siniscalchi, Xiaoli Ma, Chin-Hui Lee", "title": "Analyzing Upper Bounds on Mean Absolute Errors for Deep Neural Network\n  Based Vector-to-Vector Regression", "comments": null, "journal-ref": "IEEE Transactions on Signal Processing, Vol 68, pp. 3411-3422,\n  2020", "doi": "10.1109/TSP.2020.2993164", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that, in vector-to-vector regression utilizing deep\nneural networks (DNNs), a generalized loss of mean absolute error (MAE) between\nthe predicted and expected feature vectors is upper bounded by the sum of an\napproximation error, an estimation error, and an optimization error. Leveraging\nupon error decomposition techniques in statistical learning theory and\nnon-convex optimization theory, we derive upper bounds for each of the three\naforementioned errors and impose necessary constraints on DNN models. Moreover,\nwe assess our theoretical results through a set of image de-noising and speech\nenhancement experiments. Our proposed upper bounds of MAE for DNN based\nvector-to-vector regression are corroborated by the experimental results and\nthe upper bounds are valid with and without the \"over-parametrization\"\ntechnique.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 19:39:41 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Qi", "Jun", ""], ["Du", "Jun", ""], ["Siniscalchi", "Sabato Marco", ""], ["Ma", "Xiaoli", ""], ["Lee", "Chin-Hui", ""]]}, {"id": "2008.05503", "submitter": "Zeeshan Ahmad", "authors": "Zeeshan Ahmad and Naimul Khan", "title": "Multi-level Stress Assessment Using Multi-domain Fusion of ECG Signal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stress analysis and assessment of affective states of mind using ECG as a\nphysiological signal is a burning research topic in biomedical signal\nprocessing. However, existing literature provides only binary assessment of\nstress, while multiple levels of assessment may be more beneficial for\nhealthcare applications. Furthermore, in present research, ECG signal for\nstress analysis is examined independently in spatial domain or in transform\ndomains but the advantage of fusing these domains has not been fully utilized.\nTo get the maximum advantage of fusing diferent domains, we introduce a dataset\nwith multiple stress levels and then classify these levels using a novel deep\nlearning approach by converting ECG signal into signal images based on R-R\npeaks without any feature extraction. Moreover, We made signal images\nmultimodal and multidomain by converting them into time-frequency and frequency\ndomain using Gabor wavelet transform (GWT) and Discrete Fourier Transform (DFT)\nrespectively. Convolutional Neural networks (CNNs) are used to extract features\nfrom different modalities and then decision level fusion is performed for\nimproving the classification accuracy. The experimental results on an in-house\ndataset collected with 15 users show that with proposed fusion framework and\nusing ECG signal to image conversion, we reach an average accuracy of 85.45%.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 18:08:35 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Ahmad", "Zeeshan", ""], ["Khan", "Naimul", ""]]}, {"id": "2008.05515", "submitter": "Simin Wang", "authors": "Simin Wang, Liguo Huang, Jidong Ge, Tengfei Zhang, Haitao Feng, Ming\n  Li, He Zhang and Vincent Ng", "title": "Synergy between Machine/Deep Learning and Software Engineering: How Far\n  Are We?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since 2009, the deep learning revolution, which was triggered by the\nintroduction of ImageNet, has stimulated the synergy between Machine Learning\n(ML)/Deep Learning (DL) and Software Engineering (SE). Meanwhile, critical\nreviews have emerged that suggest that ML/DL should be used cautiously. To\nimprove the quality (especially the applicability and generalizability) of\nML/DL-related SE studies, and to stimulate and enhance future collaborations\nbetween SE/AI researchers and industry practitioners, we conducted a 10-year\nSystematic Literature Review (SLR) on 906 ML/DL-related SE papers published\nbetween 2009 and 2018. Our trend analysis demonstrated the mutual impacts that\nML/DL and SE have had on each other. At the same time, however, we also\nobserved a paucity of replicable and reproducible ML/DL-related SE studies and\nidentified five factors that influence their replicability and reproducibility.\nTo improve the applicability and generalizability of research results, we\nanalyzed what ingredients in a study would facilitate an understanding of why a\nML/DL technique was selected for a specific SE problem. In addition, we\nidentified the unique trends of impacts of DL models on SE tasks, as well as\nfive unique challenges that needed to be met in order to better leverage DL to\nimprove the productivity of SE tasks. Finally, we outlined a road-map that we\nbelieve can facilitate the transfer of ML/DL-based SE research results into\nreal-world industry practices.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 18:19:30 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Wang", "Simin", ""], ["Huang", "Liguo", ""], ["Ge", "Jidong", ""], ["Zhang", "Tengfei", ""], ["Feng", "Haitao", ""], ["Li", "Ming", ""], ["Zhang", "He", ""], ["Ng", "Vincent", ""]]}, {"id": "2008.05519", "submitter": "Ruimeng Hu", "authors": "Jiequn Han, Ruimeng Hu, Jihao Long", "title": "Convergence of Deep Fictitious Play for Stochastic Differential Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.LG q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic differential games have been used extensively to model agents'\ncompetitions in Finance, for instance, in P2P lending platforms from the\nFintech industry, the banking system for systemic risk, and insurance markets.\nThe recently proposed machine learning algorithm, deep fictitious play,\nprovides a novel efficient tool for finding Markovian Nash equilibrium of large\n$N$-player asymmetric stochastic differential games [J. Han and R. Hu,\nMathematical and Scientific Machine Learning Conference, pages 221-245, PMLR,\n2020]. By incorporating the idea of fictitious play, the algorithm decouples\nthe game into $N$ sub-optimization problems, and identifies each player's\noptimal strategy with the deep backward stochastic differential equation (BSDE)\nmethod parallelly and repeatedly. In this paper, we prove the convergence of\ndeep fictitious play (DFP) to the true Nash equilibrium. We can also show that\nthe strategy based on DFP forms an $\\eps$-Nash equilibrium. We generalize the\nalgorithm by proposing a new approach to decouple the games, and present\nnumerical results of large population games showing the empirical convergence\nof the algorithm beyond the technical assumptions in the theorems.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 18:27:13 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2021 07:46:08 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Han", "Jiequn", ""], ["Hu", "Ruimeng", ""], ["Long", "Jihao", ""]]}, {"id": "2008.05523", "submitter": "Paula Gradu", "authors": "Paula Gradu and John Hallman and Elad Hazan", "title": "Non-Stochastic Control with Bandit Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of controlling a linear dynamical system with\nadversarial perturbations where the only feedback available to the controller\nis the scalar loss, and the loss function itself is unknown. For this problem,\nwith either a known or unknown system, we give an efficient sublinear regret\nalgorithm. The main algorithmic difficulty is the dependence of the loss on\npast controls. To overcome this issue, we propose an efficient algorithm for\nthe general setting of bandit convex optimization for loss functions with\nmemory, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 18:40:00 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Gradu", "Paula", ""], ["Hallman", "John", ""], ["Hazan", "Elad", ""]]}, {"id": "2008.05533", "submitter": "Phillip Swazinna", "authors": "Phillip Swazinna, Steffen Udluft, Thomas Runkler", "title": "Overcoming Model Bias for Robust Offline Deep Reinforcement Learning", "comments": null, "journal-ref": "Engineering Applications of Artificial Intelligence, Volume 104,\n  2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art reinforcement learning algorithms mostly rely on being\nallowed to directly interact with their environment to collect millions of\nobservations. This makes it hard to transfer their success to industrial\ncontrol problems, where simulations are often very costly or do not exist, and\nexploring in the real environment can potentially lead to catastrophic events.\nRecently developed, model-free, offline RL algorithms, can learn from a single\ndataset (containing limited exploration) by mitigating extrapolation error in\nvalue functions. However, the robustness of the training process is still\ncomparatively low, a problem known from methods using value functions. To\nimprove robustness and stability of the learning process, we use dynamics\nmodels to assess policy performance instead of value functions, resulting in\nMOOSE (MOdel-based Offline policy Search with Ensembles), an algorithm which\nensures low model bias by keeping the policy within the support of the data. We\ncompare MOOSE with state-of-the-art model-free, offline RL algorithms { BRAC,}\nBEAR and BCQ on the Industrial Benchmark and MuJoCo continuous control tasks in\nterms of robust performance, and find that MOOSE outperforms its model-free\ncounterparts in almost all considered cases, often even by far.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 19:08:55 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 12:22:38 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 14:27:51 GMT"}, {"version": "v4", "created": "Thu, 22 Jul 2021 13:43:12 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Swazinna", "Phillip", ""], ["Udluft", "Steffen", ""], ["Runkler", "Thomas", ""]]}, {"id": "2008.05536", "submitter": "Rahul Singh", "authors": "Rahul Singh, Tarun Joshi, Vijayan N. Nair, and Agus Sudjianto", "title": "Model Robustness with Text Classification: Semantic-preserving\n  adversarial attacks", "comments": "12 Pages, 3 Figures, 10 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose algorithms to create adversarial attacks to assess model\nrobustness in text classification problems. They can be used to create white\nbox attacks and black box attacks while at the same time preserving the\nsemantics and syntax of the original text. The attacks cause significant number\nof flips in white-box setting and same rule based can be used in black-box\nsetting. In a black-box setting, the attacks created are able to reverse\ndecisions of transformer based architectures.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 19:17:46 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 01:05:09 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Singh", "Rahul", ""], ["Joshi", "Tarun", ""], ["Nair", "Vijayan N.", ""], ["Sudjianto", "Agus", ""]]}, {"id": "2008.05552", "submitter": "Martin J{\\o}rgensen", "authors": "Martin J{\\o}rgensen and S{\\o}ren Hauberg", "title": "Reparametrization Invariance in non-parametric Causal Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal discovery estimates the underlying physical process that generates the\nobserved data: does X cause Y or does Y cause X? Current methodologies use\nstructural conditions to turn the causal query into a statistical query, when\nonly observational data is available. But what if these statistical queries are\nsensitive to causal invariants? This study investigates one such invariant: the\ncausal relationship between X and Y is invariant to the marginal distributions\nof X and Y. We propose an algorithm that uses a non-parametric estimator that\nis robust to changes in the marginal distributions. This way we may marginalize\nthe marginals, and inspect what relationship is intrinsically there. The\nresulting causal estimator is competitive with current methodologies and has\nhigh emphasis on the uncertainty in the causal query; an aspect just as\nimportant as the query itself.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 20:00:47 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["J\u00f8rgensen", "Martin", ""], ["Hauberg", "S\u00f8ren", ""]]}, {"id": "2008.05556", "submitter": "Gabriel Dulac-Arnold", "authors": "Arthur Argenson, Gabriel Dulac-Arnold", "title": "Model-Based Offline Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline learning is a key part of making reinforcement learning (RL) useable\nin real systems. Offline RL looks at scenarios where there is data from a\nsystem's operation, but no direct access to the system when learning a policy.\nRecent work on training RL policies from offline data has shown results both\nwith model-free policies learned directly from the data, or with planning on\ntop of learnt models of the data. Model-free policies tend to be more\nperformant, but are more opaque, harder to command externally, and less easy to\nintegrate into larger systems. We propose an offline learner that generates a\nmodel that can be used to control the system directly through planning. This\nallows us to have easily controllable policies directly from data, without ever\ninteracting with the system. We show the performance of our algorithm,\nModel-Based Offline Planning (MBOP) on a series of robotics-inspired tasks, and\ndemonstrate its ability leverage planning to respect environmental constraints.\nWe are able to find near-optimal polices for certain simulated systems from as\nlittle as 50 seconds of real-time system interaction, and create zero-shot\ngoal-conditioned policies on a series of environments. An accompanying video\ncan be found here: https://youtu.be/nxGGHdZOFts\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 20:06:52 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 16:41:47 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 17:22:51 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Argenson", "Arthur", ""], ["Dulac-Arnold", "Gabriel", ""]]}, {"id": "2008.05558", "submitter": "Jeffrey Zhang", "authors": "Amir Ali Ahmadi, Jeffrey Zhang", "title": "On the complexity of finding a local minimizer of a quadratic function\n  over a polytope", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that unless P=NP, there cannot be a polynomial-time algorithm that\nfinds a point within Euclidean distance $c^n$ (for any constant $c \\ge 0$) of a\nlocal minimizer of an $n$-variate quadratic function over a polytope. This\nresult (even with $c=0$) answers a question of Pardalos and Vavasis that\nappeared in 1992 on a list of seven open problems in complexity theory for\nnumerical optimization. Our proof technique also implies that the problem of\ndeciding whether a quadratic function has a local minimizer over an (unbounded)\npolyhedron, and that of deciding if a quartic polynomial has a local minimizer\nare NP-hard.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 20:09:34 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 00:25:54 GMT"}, {"version": "v3", "created": "Fri, 4 Jun 2021 23:34:08 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ahmadi", "Amir Ali", ""], ["Zhang", "Jeffrey", ""]]}, {"id": "2008.05566", "submitter": "Naimul Mefraz Khan", "authors": "Anika Tabassum, Naimul Khan", "title": "An Efficient Confidence Measure-Based Evaluation Metric for Breast\n  Cancer Screening Using Bayesian Neural Networks", "comments": "To be presented at the IEEE ICHI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Screening mammograms is the gold standard for detecting breast cancer early.\nWhile a good amount of work has been performed on mammography image\nclassification, especially with deep neural networks, there has not been much\nexploration into the confidence or uncertainty measurement of the\nclassification. In this paper, we propose a confidence measure-based evaluation\nmetric for breast cancer screening. We propose a modular network architecture,\nwhere a traditional neural network is used as a feature extractor with transfer\nlearning, followed by a simple Bayesian neural network. Utilizing a two-stage\napproach helps reducing the computational complexity, making the proposed\nframework attractive for wider deployment. We show that by providing the\nmedical practitioners with a tool to tune two hyperparameters of the Bayesian\nneural network, namely, fraction of sampled number of networks and minimum\nprobability, the framework can be adapted as needed by the domain expert.\nFinally, we argue that instead of just a single number such as accuracy, a\ntuple (accuracy, coverage, sampled number of networks, and minimum probability)\ncan be utilized as an evaluation metric of our framework. We provide\nexperimental results on the CBIS-DDSM dataset, where we show the trends in\naccuracy-coverage tradeoff while tuning the two hyperparameters. We also show\nthat our confidence tuning results in increased accuracy with a reduced set of\nimages with high confidence when compared to the baseline transfer learning. To\nmake the proposed framework readily deployable, we provide (anonymized) source\ncode with reproducible results at https://git.io/JvRqE.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 20:34:14 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Tabassum", "Anika", ""], ["Khan", "Naimul", ""]]}, {"id": "2008.05567", "submitter": "Soren Pirk", "authors": "Till Niese, S\\\"oren Pirk, Matthias Albrecht, Bedrich Benes, Oliver\n  Deussen", "title": "Procedural Urban Forestry", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The placement of vegetation plays a central role in the realism of virtual\nscenes. We introduce procedural placement models (PPMs) for vegetation in urban\nlayouts. PPMs are environmentally sensitive to city geometry and allow\nidentifying plausible plant positions based on structural and functional zones\nin an urban layout. PPMs can either be directly used by defining their\nparameters or can be learned from satellite images and land register data.\nTogether with approaches for generating buildings and trees, this allows us to\npopulate urban landscapes with complex 3D vegetation. The effectiveness of our\nframework is shown through examples of large-scale city scenes and close-ups of\nindividually grown tree models; we also validate it by a perceptual user study.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 20:44:56 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 00:35:44 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Niese", "Till", ""], ["Pirk", "S\u00f6ren", ""], ["Albrecht", "Matthias", ""], ["Benes", "Bedrich", ""], ["Deussen", "Oliver", ""]]}, {"id": "2008.05575", "submitter": "Swayamjit Saha", "authors": "Swayamjit Saha, Niladri Majumder and Devansh Sangani", "title": "Comprehensive forecasting based analysis using stacked stateless and\n  stateful Gated Recurrent Unit models", "comments": "12 pages, 2 figures, 6 tables; typos corrected, references added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Photovoltaic power is a renewable source of energy which is highly used in\nindustries. In economically struggling countries it can be a potential source\nof electric energy as other non-renewable resources are already exhausting. Now\nif installation of a photovoltaic cell in a region is done prior to research,\nit may not provide the desired energy output required for running that region.\nHence forecasting is required which can elicit the output from a particular\nregion considering its geometrical coordinates, solar parameter like GHI and\nweather parameters like temperature and wind speed etc. Our paper explores\nforecasting of solar irradiance on four such regions, out of which three is in\nWest Bengal and one outside to depict with using stacked Gated Recurrent Unit\n(GRU) models. We have checked that stateful stacked gated recurrent unit model\nimproves the prediction accuracy significantly.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 21:13:16 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 15:19:53 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Saha", "Swayamjit", ""], ["Majumder", "Niladri", ""], ["Sangani", "Devansh", ""]]}, {"id": "2008.05587", "submitter": "Corentin Lonjarret", "authors": "Corentin Lonjarret, Roch Auburtin, C\\'eline Robardet and Marc\n  Plantevit", "title": "Sequential recommendation with metric models based on frequent sequences", "comments": "25 pages, 6 figures, submitted to DAMI (under review)", "journal-ref": "Data Min Knowl Disc (2021)", "doi": "10.1007/s10618-021-00744-w", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling user preferences (long-term history) and user dynamics (short-term\nhistory) is of greatest importance to build efficient sequential recommender\nsystems. The challenge lies in the successful combination of the whole user's\nhistory and his recent actions (sequential dynamics) to provide personalized\nrecommendations. Existing methods capture the sequential dynamics of a user\nusing fixed-order Markov chains (usually first order chains) regardless of the\nuser, which limits both the impact of the past of the user on the\nrecommendation and the ability to adapt its length to the user profile. In this\narticle, we propose to use frequent sequences to identify the most relevant\npart of the user history for the recommendation. The most salient items are\nthen used in a unified metric model that embeds items based on user preferences\nand sequential dynamics. Extensive experiments demonstrate that our method\noutperforms state-of-the-art, especially on sparse datasets. We show that\nconsidering sequences of varying lengths improves the recommendations and we\nalso emphasize that these sequences provide explanations on the recommendation.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 22:08:04 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Lonjarret", "Corentin", ""], ["Auburtin", "Roch", ""], ["Robardet", "C\u00e9line", ""], ["Plantevit", "Marc", ""]]}, {"id": "2008.05590", "submitter": "Nishant Yadav", "authors": "Nishant Yadav, Sai Ravela, Auroop R. Ganguly", "title": "Machine Learning for Robust Identification of Complex Nonlinear\n  Dynamical Systems: Applications to Earth Systems Modeling", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems exhibiting nonlinear dynamics, including but not limited to chaos,\nare ubiquitous across Earth Sciences such as Meteorology, Hydrology, Climate\nand Ecology, as well as Biology such as neural and cardiac processes. However,\nSystem Identification remains a challenge. In climate and earth systems models,\nwhile governing equations follow from first principles and understanding of key\nprocesses has steadily improved, the largest uncertainties are often caused by\nparameterizations such as cloud physics, which in turn have witnessed limited\nimprovements over the last several decades. Climate scientists have pointed to\nMachine Learning enhanced parameter estimation as a possible solution, with\nproof-of-concept methodological adaptations being examined on idealized\nsystems. While climate science has been highlighted as a \"Big Data\" challenge\nowing to the volume and complexity of archived model-simulations and\nobservations from remote and in-situ sensors, the parameter estimation process\nis often relatively a \"small data\" problem. A crucial question for data\nscientists in this context is the relevance of state-of-the-art data-driven\napproaches including those based on deep neural networks or kernel-based\nprocesses. Here we consider a chaotic system - two-level Lorenz-96 - used as a\nbenchmark model in the climate science literature, adopt a methodology based on\nGaussian Processes for parameter estimation and compare the gains in predictive\nunderstanding with a suite of Deep Learning and strawman Linear Regression\nmethods. Our results show that adaptations of kernel-based Gaussian Processes\ncan outperform other approaches under small data constraints along with\nuncertainty quantification; and needs to be considered as a viable approach in\nclimate science and earth system modeling.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 22:37:12 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Yadav", "Nishant", ""], ["Ravela", "Sai", ""], ["Ganguly", "Auroop R.", ""]]}, {"id": "2008.05598", "submitter": "Aske Plaat", "authors": "Aske Plaat, Walter Kosters, Mike Preuss", "title": "Deep Model-Based Reinforcement Learning for High-Dimensional Problems, a\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep reinforcement learning has shown remarkable success in the past few\nyears. Highly complex sequential decision making problems have been solved in\ntasks such as game playing and robotics. Unfortunately, the sample complexity\nof most deep reinforcement learning methods is high, precluding their use in\nsome important applications. Model-based reinforcement learning creates an\nexplicit model of the environment dynamics to reduce the need for environment\nsamples. Current deep learning methods use high-capacity networks to solve\nhigh-dimensional problems. Unfortunately, high-capacity models typically\nrequire many samples, negating the potential benefit of lower sample complexity\nin model-based methods. A challenge for deep model-based methods is therefore\nto achieve high predictive power while maintaining low sample complexity. In\nrecent years, many model-based methods have been introduced to address this\nchallenge. In this paper, we survey the contemporary model-based landscape.\nFirst we discuss definitions and relations to other fields. We propose a\ntaxonomy based on three approaches: using explicit planning on given\ntransitions, using explicit planning on learned transitions, and end-to-end\nlearning of both planning and transitions. We use these approaches to organize\na comprehensive overview of important recent developments such as latent\nmodels. We describe methods and benchmarks, and we suggest directions for\nfuture work for each of the approaches. Among promising research directions are\ncurriculum learning, uncertainty modeling, and use of latent models for\ntransfer learning.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 08:49:04 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 22:40:17 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Plaat", "Aske", ""], ["Kosters", "Walter", ""], ["Preuss", "Mike", ""]]}, {"id": "2008.05600", "submitter": "Dongbo Xi", "authors": "Dongbo Xi, Bowen Song, Fuzhen Zhuang, Yongchun Zhu, Shuai Chen, Tianyi\n  Zhang, Yuan Qi, Qing He", "title": "Modeling the Field Value Variations and Field Interactions\n  Simultaneously for Fraud Detection", "comments": "Accepted by AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the explosive growth of e-commerce, online transaction fraud has become\none of the biggest challenges for e-commerce platforms. The historical\nbehaviors of users provide rich information for digging into the users' fraud\nrisk. While considerable efforts have been made in this direction, a\nlong-standing challenge is how to effectively exploit internal user information\nand provide explainable prediction results. In fact, the value variations of\nsame field from different events and the interactions of different fields\ninside one event have proven to be strong indicators for fraudulent behaviors.\nIn this paper, we propose the Dual Importance-aware Factorization Machines\n(DIFM), which exploits the internal field information among users' behavior\nsequence from dual perspectives, i.e., field value variations and field\ninteractions simultaneously for fraud detection. The proposed model is deployed\nin the risk management system of one of the world's largest e-commerce\nplatforms, which utilize it to provide real-time transaction fraud detection.\nExperimental results on real industrial data from different regions in the\nplatform clearly demonstrate that our model achieves significant improvements\ncompared with various state-of-the-art baseline models. Moreover, the DIFM\ncould also give an insight into the explanation of the prediction results from\ndual perspectives.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 18:44:00 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 09:39:43 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Xi", "Dongbo", ""], ["Song", "Bowen", ""], ["Zhuang", "Fuzhen", ""], ["Zhu", "Yongchun", ""], ["Chen", "Shuai", ""], ["Zhang", "Tianyi", ""], ["Qi", "Yuan", ""], ["He", "Qing", ""]]}, {"id": "2008.05607", "submitter": "Frank Emmert-Streib", "authors": "Frank Emmert-Streib, Olli Yli-Harja, Matthias Dehmer", "title": "A clarification of misconceptions, myths and desired status of\n  artificial intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field artificial intelligence (AI) has been founded over 65 years ago.\nStarting with great hopes and ambitious goals the field progressed though\nvarious stages of popularity and received recently a revival in the form of\ndeep neural networks. Some problems of AI are that so far neither\n'intelligence' nor the goals of AI are formally defined causing confusion when\ncomparing AI to other fields. In this paper, we present a perspective on the\ndesired and current status of AI in relation to machine learning and statistics\nand clarify common misconceptions and myths. Our discussion is intended to\nuncurtain the veil of vagueness surrounding AI to see its true countenance.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 17:22:53 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Emmert-Streib", "Frank", ""], ["Yli-Harja", "Olli", ""], ["Dehmer", "Matthias", ""]]}, {"id": "2008.05621", "submitter": "Chao Ma", "authors": "Chao Ma, Lei Wu, Weinan E", "title": "The Slow Deterioration of the Generalization Error of the Random Feature\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The random feature model exhibits a kind of resonance behavior when the\nnumber of parameters is close to the training sample size. This behavior is\ncharacterized by the appearance of large generalization gap, and is due to the\noccurrence of very small eigenvalues for the associated Gram matrix. In this\npaper, we examine the dynamic behavior of the gradient descent algorithm in\nthis regime. We show, both theoretically and experimentally, that there is a\ndynamic self-correction mechanism at work: The larger the eventual\ngeneralization gap, the slower it develops, both because of the small\neigenvalues. This gives us ample time to stop the training process and obtain\nsolutions with good generalization property.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 00:35:49 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Ma", "Chao", ""], ["Wu", "Lei", ""], ["E", "Weinan", ""]]}, {"id": "2008.05640", "submitter": "Liang Pang", "authors": "Changying Hao, Liang Pang, Yanyan Lan, Fei Sun, Jiafeng Guo, Xueqi\n  Cheng", "title": "Ranking Enhanced Dialogue Generation", "comments": "Accepted at CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3411918", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How to effectively utilize the dialogue history is a crucial problem in\nmulti-turn dialogue generation. Previous works usually employ various neural\nnetwork architectures (e.g., recurrent neural networks, attention mechanisms,\nand hierarchical structures) to model the history. However, a recent empirical\nstudy by Sankar et al. has shown that these architectures lack the ability of\nunderstanding and modeling the dynamics of the dialogue history. For example,\nthe widely used architectures are insensitive to perturbations of the dialogue\nhistory, such as words shuffling, utterances missing, and utterances\nreordering. To tackle this problem, we propose a Ranking Enhanced Dialogue\ngeneration framework in this paper. Despite the traditional representation\nencoder and response generation modules, an additional ranking module is\nintroduced to model the ranking relation between the former utterance and\nconsecutive utterances. Specifically, the former utterance and consecutive\nutterances are treated as query and corresponding documents, and both local and\nglobal ranking losses are designed in the learning process. In this way, the\ndynamics in the dialogue history can be explicitly captured. To evaluate our\nproposed models, we conduct extensive experiments on three public datasets,\ni.e., bAbI, PersonaChat, and JDC. Experimental results show that our models\nproduce better responses in terms of both quantitative measures and human\njudgments, as compared with the state-of-the-art dialogue generation models.\nFurthermore, we give some detailed experimental analysis to show where and how\nthe improvements come from.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 01:49:56 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Hao", "Changying", ""], ["Pang", "Liang", ""], ["Lan", "Yanyan", ""], ["Sun", "Fei", ""], ["Guo", "Jiafeng", ""], ["Cheng", "Xueqi", ""]]}, {"id": "2008.05642", "submitter": "Rongqun Lin", "authors": "Rongqun Lin, Linwei Zhu, Shiqi Wang and Sam Kwong", "title": "Towards Modality Transferable Visual Information Representation with\n  Optimal Model Compression", "comments": "Accepted in ACM Multimedia 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compactly representing the visual signals is of fundamental importance in\nvarious image/video-centered applications. Although numerous approaches were\ndeveloped for improving the image and video coding performance by removing the\nredundancies within visual signals, much less work has been dedicated to the\ntransformation of the visual signals to another well-established modality for\nbetter representation capability. In this paper, we propose a new scheme for\nvisual signal representation that leverages the philosophy of transferable\nmodality. In particular, the deep learning model, which characterizes and\nabsorbs the statistics of the input scene with online training, could be\nefficiently represented in the sense of rate-utility optimization to serve as\nthe enhancement layer in the bitstream. As such, the overall performance can be\nfurther guaranteed by optimizing the new modality incorporated. The proposed\nframework is implemented on the state-of-the-art video coding standard (i.e.,\nversatile video coding), and significantly better representation capability has\nbeen observed based on extensive evaluations.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 01:52:40 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Lin", "Rongqun", ""], ["Zhu", "Linwei", ""], ["Wang", "Shiqi", ""], ["Kwong", "Sam", ""]]}, {"id": "2008.05644", "submitter": "Long Sha", "authors": "Tong Yang, Long Sha, Justin Li, Pengyu Hong", "title": "A Deep Learning Approach for COVID-19 Trend Prediction", "comments": "7 pages, 11 figures, accepted by KDD 2020 epiDAMIK workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we developed a deep learning model-based approach to forecast\nthe spreading trend of SARS-CoV-2 in the United States. We implemented the\ndesigned model using the United States to confirm cases and state demographic\ndata and achieved promising trend prediction results. The model incorporates\ndemographic information and epidemic time-series data through a Gated Recurrent\nUnit structure. The identification of dominating demographic factors is\ndelivered in the end.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 16:47:45 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Yang", "Tong", ""], ["Sha", "Long", ""], ["Li", "Justin", ""], ["Hong", "Pengyu", ""]]}, {"id": "2008.05646", "submitter": "Sudipta Paul Ms.", "authors": "Sudipta Paul and Subhankar Mishra", "title": "LAC : LSTM AUTOENCODER with Community for Insider Threat Detection", "comments": "10 pages, 8 figures, 5 tables, Accepted to the 3rd ICIST 2020, Tokyo,\n  Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The employees of any organization, institute, or industry, spend a\nsignificant amount of time on a computer network, where they develop their own\nroutine of activities in the form of network transactions over a time period.\nInsider threat detection involves identifying deviations in the routines or\nanomalies which may cause harm to the organization in the form of data leaks\nand secrets sharing. If not automated, this process involves feature\nengineering for modeling human behavior which is a tedious and time-consuming\ntask. Anomalies in human behavior are forwarded to a human analyst for final\nthreat classification. We developed an unsupervised deep neural network model\nusing LSTM AUTOENCODER which learns to mimic the behavior of individual\nemployees from their day-wise time-stamped sequence of activities. It predicts\nthe threat scenario via significant loss from anomalous routine. Employees in a\ncommunity tend to align their routine with each other rather than the employees\noutside their communities, this motivates us to explore a variation of the\nAUTOENCODER, LSTM AUTOENCODER- trained on the interleaved sequences of\nactivities in the Community (LAC). We evaluate the model on the CERT v6.2\ndataset and perform analysis on the loss for normal and anomalous routine\nacross 4000 employees. The aim of our paper is to detect the anomalous\nemployees as well as to explore how the surrounding employees are affecting\nthat employees' routine over time.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 02:08:39 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Paul", "Sudipta", ""], ["Mishra", "Subhankar", ""]]}, {"id": "2008.05650", "submitter": "Jianzong Wang", "authors": "Zhenpeng Zheng, Jianzong Wang, Ning Cheng, Jian Luo, Jing Xiao", "title": "MLNET: An Adaptive Multiple Receptive-field Attention Neural Network for\n  Voice Activity Detection", "comments": "will be presented in INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice activity detection (VAD) makes a distinction between speech and\nnon-speech and its performance is of crucial importance for speech based\nservices. Recently, deep neural network (DNN)-based VADs have achieved better\nperformance than conventional signal processing methods. The existed DNNbased\nmodels always handcrafted a fixed window to make use of the contextual speech\ninformation to improve the performance of VAD. However, the fixed window of\ncontextual speech information can't handle various unpredicatable noise\nenvironments and highlight the critical speech information to VAD task. In\norder to solve this problem, this paper proposed an adaptive multiple\nreceptive-field attention neural network, called MLNET, to finish VAD task. The\nMLNET leveraged multi-branches to extract multiple contextual speech\ninformation and investigated an effective attention block to weight the most\ncrucial parts of the context for final classification. Experiments in\nreal-world scenarios demonstrated that the proposed MLNET-based model\noutperformed other baselines.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 02:24:28 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Zheng", "Zhenpeng", ""], ["Wang", "Jianzong", ""], ["Cheng", "Ning", ""], ["Luo", "Jian", ""], ["Xiao", "Jing", ""]]}, {"id": "2008.05654", "submitter": "Homagni Saha", "authors": "Homagni Saha, Sin Yong Tan, Ali Saffari, Mohamad Katanbaf, Joshua R.\n  Smith, Soumik Sarkar", "title": "Few shot clustering for indoor occupancy detection with extremely\n  low-quality images from battery free cameras", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable detection of human occupancy in indoor environments is critical for\nvarious energy efficiency, security, and safety applications. We consider this\nchallenge of occupancy detection using extremely low-quality,\nprivacy-preserving images from low power image sensors. We propose a combined\nfew shot learning and clustering algorithm to address this challenge that has\nvery low commissioning and maintenance cost. While the few shot learning\nconcept enables us to commission our system with a few labeled examples, the\nclustering step serves the purpose of online adaptation to changing imaging\nenvironment over time. Apart from validating and comparing our algorithm on\nbenchmark datasets, we also demonstrate performance of our algorithm on\nstreaming images collected from real homes using our novel battery free camera\nhardware.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 02:47:01 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Saha", "Homagni", ""], ["Tan", "Sin Yong", ""], ["Saffari", "Ali", ""], ["Katanbaf", "Mohamad", ""], ["Smith", "Joshua R.", ""], ["Sarkar", "Soumik", ""]]}, {"id": "2008.05660", "submitter": "Nathan Gavenski", "authors": "Nathan Gavenski and Juarez Monteiro and Roger Granada and Felipe\n  Meneguzzi and Rodrigo C. Barros", "title": "Imitating Unknown Policies via Exploration", "comments": "This paper has been accepted in the British Machine Vision Virtual\n  Conference (BMVC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavioral cloning is an imitation learning technique that teaches an agent\nhow to behave through expert demonstrations. Recent approaches use\nself-supervision of fully-observable unlabeled snapshots of the states to\ndecode state-pairs into actions. However, the iterative learning scheme from\nthese techniques are prone to getting stuck into bad local minima. We address\nthese limitations incorporating a two-phase model into the original framework,\nwhich learns from unlabeled observations via exploration, substantially\nimproving traditional behavioral cloning by exploiting (i) a sampling mechanism\nto prevent bad local minima, (ii) a sampling mechanism to improve exploration,\nand (iii) self-attention modules to capture global features. The resulting\ntechnique outperforms the previous state-of-the-art in four different\nenvironments by a large margin.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 03:03:35 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Gavenski", "Nathan", ""], ["Monteiro", "Juarez", ""], ["Granada", "Roger", ""], ["Meneguzzi", "Felipe", ""], ["Barros", "Rodrigo C.", ""]]}, {"id": "2008.05687", "submitter": "Weituo Hao", "authors": "Weituo Hao, Nikhil Mehta, Kevin J Liang, Pengyu Cheng, Mostafa\n  El-Khamy, Lawrence Carin", "title": "WAFFLe: Weight Anonymized Factorization for Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In domains where data are sensitive or private, there is great value in\nmethods that can learn in a distributed manner without the data ever leaving\nthe local devices. In light of this need, federated learning has emerged as a\npopular training paradigm. However, many federated learning approaches trade\ntransmitting data for communicating updated weight parameters for each local\ndevice. Therefore, a successful breach that would have otherwise directly\ncompromised the data instead grants whitebox access to the local model, which\nopens the door to a number of attacks, including exposing the very data\nfederated learning seeks to protect. Additionally, in distributed scenarios,\nindividual client devices commonly exhibit high statistical heterogeneity. Many\ncommon federated approaches learn a single global model; while this may do well\non average, performance degrades when the i.i.d. assumption is violated,\nunderfitting individuals further from the mean, and raising questions of\nfairness. To address these issues, we propose Weight Anonymized Factorization\nfor Federated Learning (WAFFLe), an approach that combines the Indian Buffet\nProcess with a shared dictionary of weight factors for neural networks.\nExperiments on MNIST, FashionMNIST, and CIFAR-10 demonstrate WAFFLe's\nsignificant improvement to local test performance and fairness while\nsimultaneously providing an extra layer of security.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 04:26:31 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Hao", "Weituo", ""], ["Mehta", "Nikhil", ""], ["Liang", "Kevin J", ""], ["Cheng", "Pengyu", ""], ["El-Khamy", "Mostafa", ""], ["Carin", "Lawrence", ""]]}, {"id": "2008.05730", "submitter": "Kjetil Olsen Lye", "authors": "Kjetil O. Lye, Siddhartha Mishra, Deep Ray and Praveen Chandrasekhar", "title": "Iterative Surrogate Model Optimization (ISMO): An active learning\n  algorithm for PDE constrained optimization with deep neural networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2020.113575", "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel active learning algorithm, termed as iterative surrogate\nmodel optimization (ISMO), for robust and efficient numerical approximation of\nPDE constrained optimization problems. This algorithm is based on deep neural\nnetworks and its key feature is the iterative selection of training data\nthrough a feedback loop between deep neural networks and any underlying\nstandard optimization algorithm. Under suitable hypotheses, we show that the\nresulting optimizers converge exponentially fast (and with exponentially\ndecaying variance), with respect to increasing number of training samples.\nNumerical examples for optimal control, parameter identification and shape\noptimization problems for PDEs are provided to validate the proposed theory and\nto illustrate that ISMO significantly outperforms a standard deep neural\nnetwork based surrogate optimization algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 07:31:07 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Lye", "Kjetil O.", ""], ["Mishra", "Siddhartha", ""], ["Ray", "Deep", ""], ["Chandrasekhar", "Praveen", ""]]}, {"id": "2008.05753", "submitter": "Jong Chul Ye", "authors": "Jawook Gu, Jong Chul Ye", "title": "AdaIN-Switchable CycleGAN for Efficient Unsupervised Low-Dose CT\n  Denoising", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Recently, deep learning approaches have been extensively studied for low-dose\nCT denoising thanks to its superior performance despite the fast computational\ntime. In particular, cycleGAN has been demonstrated as a powerful unsupervised\nlearning scheme to improve the low-dose CT image quality without requiring\nmatched high-dose reference data. Unfortunately, one of the main limitations of\nthe cycleGAN approach is that it requires two deep neural network generators at\nthe training phase, although only one of them is used at the inference phase.\nThe secondary auxiliary generator is needed to enforce the cycle-consistency,\nbut the additional memory requirement and increases of the learnable parameters\nare the main huddles for cycleGAN training. To address this issue, here we\npropose a novel cycleGAN architecture using a single switchable generator. In\nparticular, a single generator is implemented using adaptive instance\nnormalization (AdaIN) layers so that the baseline generator converting a\nlow-dose CT image to a routine-dose CT image can be switched to a generator\nconverting high-dose to low-dose by simply changing the AdaIN code. Thanks to\nthe shared baseline network, the additional memory requirement and weight\nincreases are minimized, and the training can be done more stably even with\nsmall training data. Experimental results show that the proposed method\noutperforms the previous cycleGAN approaches while using only about half the\nparameters.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 08:30:23 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Gu", "Jawook", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2008.05756", "submitter": "Enrico Bagli", "authors": "Margherita Grandini, Enrico Bagli, Giorgio Visani", "title": "Metrics for Multi-Class Classification: an Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification tasks in machine learning involving more than two classes are\nknown by the name of \"multi-class classification\". Performance indicators are\nvery useful when the aim is to evaluate and compare different classification\nmodels or machine learning techniques. Many metrics come in handy to test the\nability of a multi-class classifier. Those metrics turn out to be useful at\ndifferent stage of the development process, e.g. comparing the performance of\ntwo different models or analysing the behaviour of the same model by tuning\ndifferent parameters. In this white paper we review a list of the most\npromising multi-class metrics, we highlight their advantages and disadvantages\nand show their possible usages during the development of a classification\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 08:41:44 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Grandini", "Margherita", ""], ["Bagli", "Enrico", ""], ["Visani", "Giorgio", ""]]}, {"id": "2008.05758", "submitter": "Amrit Singh Bedi", "authors": "Zeeshan Akhtar, Amrit Singh Bedi, and Ketan Rajawat", "title": "Conservative Stochastic Optimization with Expectation Constraints", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2021.3082467", "report-no": null, "categories": "math.OC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers stochastic convex optimization problems where the\nobjective and constraint functions involve expectations with respect to the\ndata indices or environmental variables, in addition to deterministic convex\nconstraints on the domain of the variables. Although the setting is generic and\narises in different machine learning applications, online and efficient\napproaches for solving such problems have not been widely studied. Since the\nunderlying data distribution is unknown a priori, a closed-form solution is\ngenerally not available, and classical deterministic optimization paradigms are\nnot applicable. State-of-the-art approaches, such as those using the saddle\npoint framework, can ensure that the optimality gap as well as the constraint\nviolation decay as $\\O\\left(T^{-\\frac{1}{2}}\\right)$ where $T$ is the number of\nstochastic gradients. The domain constraints are assumed simple and handled via\nprojection at every iteration. In this work, we propose a novel conservative\nstochastic optimization algorithm (CSOA) that achieves zero constraint\nviolation and $\\O\\left(T^{-\\frac{1}{2}}\\right)$ optimality gap.\n  Further, the projection operation (for scenarios when calculating projection\nis expensive) in the proposed algorithm can be avoided by considering the\nconditional gradient or Frank-Wolfe (FW) variant of the algorithm. The\nstate-of-the-art stochastic FW variants achieve an optimality gap of\n$\\O\\left(T^{-\\frac{1}{3}}\\right)$ after $T$ iterations, though these algorithms\nhave not been applied to problems with functional expectation constraints. In\nthis work, we propose the FW-CSOA algorithm that is not only projection-free\nbut also achieves zero constraint violation with\n$\\O\\left(T^{-\\frac{1}{4}}\\right)$ decay of the optimality gap. The efficacy of\nthe proposed algorithms is tested on two relevant problems: fair classification\nand structured matrix completion.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 08:56:24 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 05:32:29 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Akhtar", "Zeeshan", ""], ["Bedi", "Amrit Singh", ""], ["Rajawat", "Ketan", ""]]}, {"id": "2008.05759", "submitter": "Tadej \\v{S}kvorc", "authors": "Tadej \\v{S}kvorc, Polona Gantar, Marko Robnik-\\v{S}ikonja", "title": "MICE: Mining Idioms with Contextual Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Idiomatic expressions can be problematic for natural language processing\napplications as their meaning cannot be inferred from their constituting words.\nA lack of successful methodological approaches and sufficiently large datasets\nprevents the development of machine learning approaches for detecting idioms,\nespecially for expressions that do not occur in the training set. We present an\napproach, called MICE, that uses contextual embeddings for that purpose. We\npresent a new dataset of multi-word expressions with literal and idiomatic\nmeanings and use it to train a classifier based on two state-of-the-art\ncontextual word embeddings: ELMo and BERT. We show that deep neural networks\nusing both embeddings perform much better than existing approaches, and are\ncapable of detecting idiomatic word use, even for expressions that were not\npresent in the training set. We demonstrate cross-lingual transfer of developed\nmodels and analyze the size of the required dataset.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 08:56:40 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["\u0160kvorc", "Tadej", ""], ["Gantar", "Polona", ""], ["Robnik-\u0160ikonja", "Marko", ""]]}, {"id": "2008.05760", "submitter": "Albert Gatt", "authors": "Carlos Mena, Albert Gatt, Andrea DeMarco, Claudia Borg, Lonneke van\n  der Plas, Amanda Muscat, Ian Padovani", "title": "MASRI-HEADSET: A Maltese Corpus for Speech Recognition", "comments": "8 pages, 2 figures, 4 tables, 1 appendix. Appears in Proceedings of\n  the 12th edition of the Language Resources and Evaluation Conference\n  (LREC'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Maltese, the national language of Malta, is spoken by approximately 500,000\npeople. Speech processing for Maltese is still in its early stages of\ndevelopment. In this paper, we present the first spoken Maltese corpus designed\npurposely for Automatic Speech Recognition (ASR). The MASRI-HEADSET corpus was\ndeveloped by the MASRI project at the University of Malta. It consists of 8\nhours of speech paired with text, recorded by using short text snippets in a\nlaboratory environment. The speakers were recruited from different geographical\nlocations all over the Maltese islands, and were roughly evenly distributed by\ngender. This paper also presents some initial results achieved in baseline\nexperiments for Maltese ASR using Sphinx and Kaldi. The MASRI-HEADSET Corpus is\npublicly available for research/academic purposes.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 08:57:16 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Mena", "Carlos", ""], ["Gatt", "Albert", ""], ["DeMarco", "Andrea", ""], ["Borg", "Claudia", ""], ["van der Plas", "Lonneke", ""], ["Muscat", "Amanda", ""], ["Padovani", "Ian", ""]]}, {"id": "2008.05767", "submitter": "Jihun Oh", "authors": "Jihun Oh, SangJeong Lee, Meejeong Park, Pooni Walagaurav and Kiseok\n  Kwon", "title": "Weight Equalizing Shift Scaler-Coupled Post-training Quantization", "comments": "9 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-training, layer-wise quantization is preferable because it is free from\nretraining and is hardware-friendly. Nevertheless, accuracy degradation has\noccurred when a neural network model has a big difference of per-out-channel\nweight ranges. In particular, the MobileNet family has a tragedy drop in top-1\naccuracy from 70.60% ~ 71.87% to 0.1% on the ImageNet dataset after 8-bit\nweight quantization. To mitigate this significant accuracy reduction, we\npropose a new weight equalizing shift scaler, i.e. rescaling the weight range\nper channel by a 4-bit binary shift, prior to a layer-wise quantization. To\nrecover the original output range, inverse binary shifting is efficiently fused\nto the existing per-layer scale compounding in the fixed-computing\nconvolutional operator of the custom neural processing unit. The binary shift\nis a key feature of our algorithm, which significantly improved the accuracy\nperformance without impeding the memory footprint. As a result, our proposed\nmethod achieved a top-1 accuracy of 69.78% ~ 70.96% in MobileNets and showed\nrobust performance in varying network models and tasks, which is competitive to\nchannel-wise quantization results.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 09:19:57 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Oh", "Jihun", ""], ["Lee", "SangJeong", ""], ["Park", "Meejeong", ""], ["Walagaurav", "Pooni", ""], ["Kwon", "Kiseok", ""]]}, {"id": "2008.05772", "submitter": "Jong Chul Ye", "authors": "Boah Kim, Dong Hwan Kim, Seong Ho Park, Jieun Kim, June-Goo Lee, Jong\n  Chul Ye", "title": "CycleMorph: Cycle Consistent Unsupervised Deformable Image Registration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image registration is a fundamental task in medical image analysis. Recently,\ndeep learning based image registration methods have been extensively\ninvestigated due to their excellent performance despite the ultra-fast\ncomputational time. However, the existing deep learning methods still have\nlimitation in the preservation of original topology during the deformation with\nregistration vector fields. To address this issues, here we present a\ncycle-consistent deformable image registration. The cycle consistency enhances\nimage registration performance by providing an implicit regularization to\npreserve topology during the deformation. The proposed method is so flexible\nthat can be applied for both 2D and 3D registration problems for various\napplications, and can be easily extended to multi-scale implementation to deal\nwith the memory issues in large volume registration. Experimental results on\nvarious datasets from medical and non-medical applications demonstrate that the\nproposed method provides effective and accurate registration on diverse image\npairs within a few seconds. Qualitative and quantitative evaluations on\ndeformation fields also verify the effectiveness of the cycle consistency of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 09:30:12 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Kim", "Boah", ""], ["Kim", "Dong Hwan", ""], ["Park", "Seong Ho", ""], ["Kim", "Jieun", ""], ["Lee", "June-Goo", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2008.05785", "submitter": "Daniyar Turmukhambetov", "authors": "Anita Rau, Guillermo Garcia-Hernando, Danail Stoyanov, Gabriel J.\n  Brostow, Daniyar Turmukhambetov", "title": "Predicting Visual Overlap of Images Through Interpretable Non-Metric Box\n  Embeddings", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To what extent are two images picturing the same 3D surfaces? Even when this\nis a known scene, the answer typically requires an expensive search across\nscale space, with matching and geometric verification of large sets of local\nfeatures. This expense is further multiplied when a query image is evaluated\nagainst a gallery, e.g. in visual relocalization. While we don't obviate the\nneed for geometric verification, we propose an interpretable image-embedding\nthat cuts the search in scale space to essentially a lookup.\n  Our approach measures the asymmetric relation between two images. The model\nthen learns a scene-specific measure of similarity, from training examples with\nknown 3D visible-surface overlaps. The result is that we can quickly identify,\nfor example, which test image is a close-up version of another, and by what\nscale factor. Subsequently, local features need only be detected at that scale.\nWe validate our scene-specific model by showing how this embedding yields\ncompetitive image-matching results, while being simpler, faster, and also\ninterpretable by humans.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 10:01:07 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Rau", "Anita", ""], ["Garcia-Hernando", "Guillermo", ""], ["Stoyanov", "Danail", ""], ["Brostow", "Gabriel J.", ""], ["Turmukhambetov", "Daniyar", ""]]}, {"id": "2008.05788", "submitter": "Erik Scharw\\\"achter", "authors": "Erik Scharw\\\"achter and Emmanuel M\\\"uller", "title": "Statistical Evaluation of Anomaly Detectors for Sequences", "comments": "5 pages, 6 figures, accepted at the 6th KDD Workshop on Mining and\n  Learning from Time Series (KDD MiLeTS 2020), source code available at\n  https://github.com/diozaka/anomaly-eval", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although precision and recall are standard performance measures for anomaly\ndetection, their statistical properties in sequential detection settings are\npoorly understood. In this work, we formalize a notion of precision and recall\nwith temporal tolerance for point-based anomaly detection in sequential data.\nThese measures are based on time-tolerant confusion matrices that may be used\nto compute time-tolerant variants of many other standard measures. However,\ncare has to be taken to preserve interpretability. We perform a statistical\nsimulation study to demonstrate that precision and recall may overestimate the\nperformance of a detector, when computed with temporal tolerance. To alleviate\nthis problem, we show how to obtain null distributions for the two measures to\nassess the statistical significance of reported results.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 10:07:27 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Scharw\u00e4chter", "Erik", ""], ["M\u00fcller", "Emmanuel", ""]]}, {"id": "2008.05789", "submitter": "Ying Cheng", "authors": "Ying Cheng, Ruize Wang, Zhihao Pan, Rui Feng, Yuejie Zhang", "title": "Look, Listen, and Attend: Co-Attention Network for Self-Supervised\n  Audio-Visual Representation Learning", "comments": "Accepted by the 28th ACM International Conference on Multimedia (ACM\n  MM 2020)", "journal-ref": null, "doi": "10.1145/3394171.3413869", "report-no": null, "categories": "cs.MM cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When watching videos, the occurrence of a visual event is often accompanied\nby an audio event, e.g., the voice of lip motion, the music of playing\ninstruments. There is an underlying correlation between audio and visual\nevents, which can be utilized as free supervised information to train a neural\nnetwork by solving the pretext task of audio-visual synchronization. In this\npaper, we propose a novel self-supervised framework with co-attention mechanism\nto learn generic cross-modal representations from unlabelled videos in the\nwild, and further benefit downstream tasks. Specifically, we explore three\ndifferent co-attention modules to focus on discriminative visual regions\ncorrelated to the sounds and introduce the interactions between them.\nExperiments show that our model achieves state-of-the-art performance on the\npretext task while having fewer parameters compared with existing methods. To\nfurther evaluate the generalizability and transferability of our approach, we\napply the pre-trained model on two downstream tasks, i.e., sound source\nlocalization and action recognition. Extensive experiments demonstrate that our\nmodel provides competitive results with other self-supervised methods, and also\nindicate that our approach can tackle the challenging scenes which contain\nmultiple sound sources.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 10:08:12 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Cheng", "Ying", ""], ["Wang", "Ruize", ""], ["Pan", "Zhihao", ""], ["Feng", "Rui", ""], ["Zhang", "Yuejie", ""]]}, {"id": "2008.05803", "submitter": "Joao Marques-Silva", "authors": "Joao Marques-Silva, Thomas Gerspacher, Martin C. Cooper, Alexey\n  Ignatiev, Nina Narodytska", "title": "Explaining Naive Bayes and Other Linear Classifiers with Polynomial Time\n  and Delay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work proposed the computation of so-called PI-explanations of Naive\nBayes Classifiers (NBCs). PI-explanations are subset-minimal sets of\nfeature-value pairs that are sufficient for the prediction, and have been\ncomputed with state-of-the-art exact algorithms that are worst-case exponential\nin time and space. In contrast, we show that the computation of one\nPI-explanation for an NBC can be achieved in log-linear time, and that the same\nresult also applies to the more general class of linear classifiers.\nFurthermore, we show that the enumeration of PI-explanations can be obtained\nwith polynomial delay. Experimental results demonstrate the performance gains\nof the new algorithms when compared with earlier work. The experimental results\nalso investigate ways to measure the quality of heuristic explanations\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 10:25:30 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 09:48:14 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Marques-Silva", "Joao", ""], ["Gerspacher", "Thomas", ""], ["Cooper", "Martin C.", ""], ["Ignatiev", "Alexey", ""], ["Narodytska", "Nina", ""]]}, {"id": "2008.05804", "submitter": "Dell Zhang", "authors": "Dell Zhang, Alexander Kuhnle, Julian Richardson, Murat Sensoy", "title": "Process Discovery for Structured Program Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core task in process mining is process discovery which aims to learn an\naccurate process model from event log data. In this paper, we propose to use\n(block-) structured programs directly as target process models so as to\nestablish connections to the field of program synthesis and facilitate the\ntranslation from abstract process models to executable processes, e.g., for\nrobotic process automation. Furthermore, we develop a novel bottom-up\nagglomerative approach to the discovery of such structured program process\nmodels. In comparison with the popular top-down recursive inductive miner, our\nproposed agglomerative miner enjoys the similar theoretical guarantee to\nproduce sound process models (without deadlocks and other anomalies) while\nexhibiting some advantages like avoiding silent activities and accommodating\nduplicate activities. The proposed algorithm works by iteratively applying a\nfew graph rewriting rules to the directly-follows-graph of activities. For\nreal-world (sparse) directly-follows-graphs, the algorithm has quadratic\ncomputational complexity with respect to the number of distinct activities. To\nour knowledge, this is the first process discovery algorithm that is made for\nthe purpose of program synthesis. Experiments on the BPI-Challenge 2020 dataset\nand the Karel programming dataset have demonstrated that our proposed algorithm\ncan outperform the inductive miner not only according to the traditional\nprocess discovery metrics but also in terms of the effectiveness in finding out\nthe true underlying structured program from a small number of its execution\ntraces.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 10:33:10 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Zhang", "Dell", ""], ["Kuhnle", "Alexander", ""], ["Richardson", "Julian", ""], ["Sensoy", "Murat", ""]]}, {"id": "2008.05808", "submitter": "Yuyan Wang", "authors": "Yuyan Wang, Zhe Zhao, Bo Dai, Christopher Fifty, Dong Lin, Lichan\n  Hong, Ed H. Chi", "title": "Small Towers Make Big Differences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning aims at solving multiple machine learning tasks at the\nsame time. A good solution to a multi-task learning problem should be\ngeneralizable in addition to being Pareto optimal. In this paper, we provide\nsome insights on understanding the trade-off between Pareto efficiency and\ngeneralization as a result of parameterization in multi-task deep learning\nmodels. As a multi-objective optimization problem, enough parameterization is\nneeded for handling task conflicts in a constrained solution space; however,\nfrom a multi-task generalization perspective, over-parameterization undermines\nthe benefit of learning a shared representation which helps harder tasks or\ntasks with limited training examples. A delicate balance between multi-task\ngeneralization and multi-objective optimization is therefore needed for finding\na better trade-off between efficiency and generalization. To this end, we\npropose a method of under-parameterized self-auxiliaries for multi-task models\nto achieve the best of both worlds. It is task-agnostic and works with other\nmulti-task learning algorithms. Empirical results show that small towers of\nunder-parameterized self-auxiliaries can make big differences in improving\nPareto efficiency in various multi-task applications.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 10:45:31 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Wang", "Yuyan", ""], ["Zhao", "Zhe", ""], ["Dai", "Bo", ""], ["Fifty", "Christopher", ""], ["Lin", "Dong", ""], ["Hong", "Lichan", ""], ["Chi", "Ed H.", ""]]}, {"id": "2008.05809", "submitter": "Dipjyoti Paul", "authors": "Dipjyoti Paul, Muhammed PV Shifas, Yannis Pantazis, Yannis Stylianou", "title": "Enhancing Speech Intelligibility in Text-To-Speech Synthesis using\n  Speaking Style Conversion", "comments": "Accepted in INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased adoption of digital assistants makes text-to-speech (TTS)\nsynthesis systems an indispensable feature of modern mobile devices. It is\nhence desirable to build a system capable of generating highly intelligible\nspeech in the presence of noise. Past studies have investigated style\nconversion in TTS synthesis, yet degraded synthesized quality often leads to\nworse intelligibility. To overcome such limitations, we proposed a novel\ntransfer learning approach using Tacotron and WaveRNN based TTS synthesis. The\nproposed speech system exploits two modification strategies: (a) Lombard\nspeaking style data and (b) Spectral Shaping and Dynamic Range Compression\n(SSDRC) which has been shown to provide high intelligibility gains by\nredistributing the signal energy on the time-frequency domain. We refer to this\nextension as Lombard-SSDRC TTS system. Intelligibility enhancement as\nquantified by the Intelligibility in Bits (SIIB-Gauss) measure shows that the\nproposed Lombard-SSDRC TTS system shows significant relative improvement\nbetween 110% and 130% in speech-shaped noise (SSN), and 47% to 140% in\ncompeting-speaker noise (CSN) against the state-of-the-art TTS approach.\nAdditional subjective evaluation shows that Lombard-SSDRC TTS successfully\nincreases the speech intelligibility with relative improvement of 455% for SSN\nand 104% for CSN in median keyword correction rate compared to the baseline TTS\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 10:51:56 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Paul", "Dipjyoti", ""], ["Shifas", "Muhammed PV", ""], ["Pantazis", "Yannis", ""], ["Stylianou", "Yannis", ""]]}, {"id": "2008.05823", "submitter": "An Xu", "authors": "An Xu, Zhouyuan Huo, Heng Huang", "title": "Training Faster with Compressed Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the distributed machine learning methods show the potential for the\nspeed-up of training large deep neural networks, the communication cost has\nbeen the notorious bottleneck to constrain the performance. To address this\nchallenge, the gradient compression based communication-efficient distributed\nlearning methods were designed to reduce the communication cost, and more\nrecently the local error feedback was incorporated to compensate for the\nperformance loss. However, in this paper, we will show the \"gradient mismatch\"\nproblem of the local error feedback in centralized distributed training and\nthis issue can lead to degraded performance compared with full-precision\ntraining. To solve this critical problem, we propose two novel techniques: 1)\nstep ahead; 2) error averaging. Both our theoretical and empirical results show\nthat our new methods can alleviate the \"gradient mismatch\" problem. Experiments\nshow that we can even train \\textbf{faster with compressed gradient} than\nfull-precision training \\textbf{regarding training epochs}.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 11:21:07 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Xu", "An", ""], ["Huo", "Zhouyuan", ""], ["Huang", "Heng", ""]]}, {"id": "2008.05825", "submitter": "Thorsten Gl\\\"usenkamp", "authors": "Thorsten Gl\\\"usenkamp", "title": "Unifying supervised learning and VAEs -- automating statistical\n  inference in high-energy physics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.HE astro-ph.IM hep-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A KL-divergence objective of the joint distribution of data and labels allows\nto unify supervised learning, variational autoencoders (VAEs) and\nsemi-supervised learning under one umbrella of variational inference. This\nviewpoint has several advantages. For VAEs, it clarifies the interpretation of\nencoder and decoder parts. For supervised learning, it re-iterates that the\ntraining procedure approximates the true posterior over labels and can always\nbe viewed as approximate likelihood-free inference. This is typically not\ndiscussed, even though the derivation is well-known in the literature. In the\ncontext of semi-supervised learning it motivates an extended supervised scheme\nwhich allows to calculate a goodness-of-fit p-value using posterior predictive\nsimulations. Flow-based networks with a standard normal base distribution are\ncrucial. We discuss how they allow to rigorously define coverage for arbitrary\njoint posteriors on $\\mathbb{R}^n \\times \\mathcal{S}^m$, which encompasses\nposteriors over directions. Finally, systematic uncertainties are naturally\nincluded in the variational viewpoint. With the three ingredients of (1)\nsystematics, (2) coverage and (3) goodness-of-fit, flow-based neural networks\nhave the potential to replace a large part of the statistical toolbox of the\ncontemporary high-energy physicist.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 11:28:57 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 18:27:11 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Gl\u00fcsenkamp", "Thorsten", ""]]}, {"id": "2008.05826", "submitter": "Tao Hu", "authors": "Pengwan Yang, Vincent Tao Hu, Pascal Mettes, Cees G. M. Snoek", "title": "Localizing the Common Action Among a Few Videos", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper strives to localize the temporal extent of an action in a long\nuntrimmed video. Where existing work leverages many examples with their start,\ntheir ending, and/or the class of the action during training time, we propose\nfew-shot common action localization. The start and end of an action in a long\nuntrimmed video is determined based on just a hand-full of trimmed video\nexamples containing the same action, without knowing their common class label.\nTo address this task, we introduce a new 3D convolutional network architecture\nable to align representations from the support videos with the relevant query\nvideo segments. The network contains: (\\textit{i}) a mutual enhancement module\nto simultaneously complement the representation of the few trimmed support\nvideos and the untrimmed query video; (\\textit{ii}) a progressive alignment\nmodule that iteratively fuses the support videos into the query branch; and\n(\\textit{iii}) a pairwise matching module to weigh the importance of different\nsupport videos. Evaluation of few-shot common action localization in untrimmed\nvideos containing a single or multiple action instances demonstrates the\neffectiveness and general applicability of our proposal.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 11:31:23 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 12:30:01 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Yang", "Pengwan", ""], ["Hu", "Vincent Tao", ""], ["Mettes", "Pascal", ""], ["Snoek", "Cees G. M.", ""]]}, {"id": "2008.05828", "submitter": "Madhura Pande", "authors": "Madhura Pande, Aakriti Budhraja, Preksha Nema, Pratyush Kumar, Mitesh\n  M. Khapra", "title": "On the Importance of Local Information in Transformer Based Models", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The self-attention module is a key component of Transformer-based models,\nwherein each token pays attention to every other token. Recent studies have\nshown that these heads exhibit syntactic, semantic, or local behaviour. Some\nstudies have also identified promise in restricting this attention to be local,\ni.e., a token attending to other tokens only in a small neighbourhood around\nit. However, no conclusive evidence exists that such local attention alone is\nsufficient to achieve high accuracy on multiple NLP tasks. In this work, we\nsystematically analyse the role of locality information in learnt models and\ncontrast it with the role of syntactic information. More specifically, we first\ndo a sensitivity analysis and show that, at every layer, the representation of\na token is much more sensitive to tokens in a small neighborhood around it than\nto tokens which are syntactically related to it. We then define an attention\nbias metric to determine whether a head pays more attention to local tokens or\nto syntactically related tokens. We show that a larger fraction of heads have a\nlocality bias as compared to a syntactic bias. Having established the\nimportance of local attention heads, we train and evaluate models where varying\nfractions of the attention heads are constrained to be local. Such models would\nbe more efficient as they would have fewer computations in the attention layer.\nWe evaluate these models on 4 GLUE datasets (QQP, SST-2, MRPC, QNLI) and 2 MT\ndatasets (En-De, En-Ru) and clearly demonstrate that such constrained models\nhave comparable performance to the unconstrained models. Through this\nsystematic evaluation we establish that attention in Transformer-based models\ncan be constrained to be local without affecting performance.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 11:32:47 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Pande", "Madhura", ""], ["Budhraja", "Aakriti", ""], ["Nema", "Preksha", ""], ["Kumar", "Pratyush", ""], ["Khapra", "Mitesh M.", ""]]}, {"id": "2008.05838", "submitter": "Gabriel Michau Dr.", "authors": "Gabriel Michau, Chi-Ching Hsu and Olga Fink", "title": "Interpretable Detection of Partial Discharge in Power Lines with Deep\n  Learning", "comments": "13 pages, 4 figures, 2 tables", "journal-ref": "Sensors 2021", "doi": "10.3390/s21062154", "report-no": "Sensors 2021, no. 6: 2154", "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Partial discharge (PD) is a common indication of faults in power systems,\nsuch as generators, and cables. These PD can eventually result in costly\nrepairs and substantial power outages. PD detection traditionally relies on\nhand-crafted features and domain expertise to identify very specific pulses in\nthe electrical current, and the performance declines in the presence of noise\nor of superposed pulses. In this paper, we propose a novel end-to-end framework\nbased on convolutional neural networks. The framework has two contributions.\nFirst, it does not require any feature extraction and enables robust PD\ndetection. Second, we devise the pulse activation map. It provides\ninterpretability of the results for the domain experts with the identification\nof the pulses that led to the detection of the PDs. The performance is\nevaluated on a public dataset for the detection of damaged power lines. An\nablation study demonstrates the benefits of each part of the proposed\nframework.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 11:52:02 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 15:03:30 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 07:23:30 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Michau", "Gabriel", ""], ["Hsu", "Chi-Ching", ""], ["Fink", "Olga", ""]]}, {"id": "2008.05849", "submitter": "Lei Shi", "authors": "Ahmed Alamri, Mohammad Alshehri, Alexandra I. Cristea, Filipe D.\n  Pereira, Elaine Oliveira, Lei Shi, Craig Stewart", "title": "Predicting MOOCs Dropout Using Only Two Easily Obtainable Features from\n  the First Week's Activities", "comments": "Intelligent Tutoring Systems. ITS 2019. Lecture Notes in Computer\n  Science, vol 11528. Springer, Cham", "journal-ref": null, "doi": "10.1007/978-3-030-22244-4_20", "report-no": null, "categories": "cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  While Massive Open Online Course (MOOCs) platforms provide knowledge in a new\nand unique way, the very high number of dropouts is a significant drawback.\nSeveral features are considered to contribute towards learner attrition or lack\nof interest, which may lead to disengagement or total dropout. The jury is\nstill out on which factors are the most appropriate predictors. However, the\nliterature agrees that early prediction is vital to allow for a timely\nintervention. Whilst feature-rich predictors may have the best chance for high\naccuracy, they may be unwieldy. This study aims to predict learner dropout\nearly-on, from the first week, by comparing several machine-learning\napproaches, including Random Forest, Adaptive Boost, XGBoost and GradientBoost\nClassifiers. The results show promising accuracies (82%-94%) using as little as\n2 features. We show that the accuracies obtained outperform state of the art\napproaches, even when the latter deploy several features.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 10:44:49 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Alamri", "Ahmed", ""], ["Alshehri", "Mohammad", ""], ["Cristea", "Alexandra I.", ""], ["Pereira", "Filipe D.", ""], ["Oliveira", "Elaine", ""], ["Shi", "Lei", ""], ["Stewart", "Craig", ""]]}, {"id": "2008.05850", "submitter": "Lei Shi", "authors": "Lei Shi, Alexandra I. Cristea, Armando M. Toda, Wilk Oliveira", "title": "Revealing the Hidden Patterns: A Comparative Study on Profiling\n  Subpopulations of MOOC Students", "comments": "Information Systems Development: Information Systems Beyond 2020\n  (ISD2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Massive Open Online Courses (MOOCs) exhibit a remarkable heterogeneity of\nstudents. The advent of complex \"big data\" from MOOC platforms is a challenging\nyet rewarding opportunity to deeply understand how students are engaged in\nMOOCs. Past research, looking mainly into overall behavior, may have missed\npatterns related to student diversity. Using a large dataset from a MOOC\noffered by FutureLearn, we delve into a new way of investigating hidden\npatterns through both machine learning and statistical modelling. In this\npaper, we report on clustering analysis of student activities and comparative\nanalysis on both behavioral patterns and demographical patterns between student\nsubpopulations in the MOOC. Our approach allows for a deeper understanding of\nhow MOOC students behave and achieve. Our findings may be used to design\nadaptive strategies towards an enhanced MOOC experience\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 10:38:50 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Shi", "Lei", ""], ["Cristea", "Alexandra I.", ""], ["Toda", "Armando M.", ""], ["Oliveira", "Wilk", ""]]}, {"id": "2008.05859", "submitter": "Luciano Sbaiz", "authors": "Thomas Fischbacher and Luciano Sbaiz", "title": "Single-Photon Image Classification", "comments": "See ancillary files for training code and pre-trained models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing-based machine learning mainly focuses on quantum computing\nhardware that is experimentally challenging to realize due to requiring quantum\ngates that operate at very low temperature. Instead, we demonstrate the\nexistence of a lower performance and much lower effort island on the\naccuracy-vs-qubits graph that may well be experimentally accessible with room\ntemperature optics. This high temperature \"quantum computing toy model\" is\nnevertheless interesting to study as it allows rather accessible explanations\nof key concepts in quantum computing, in particular interference, entanglement,\nand the measurement process.\n  We specifically study the problem of classifying an example from the MNIST\nand Fashion-MNIST datasets, subject to the constraint that we have to make a\nprediction after the detection of the very first photon that passed a\ncoherently illuminated filter showing the example. Whereas a classical set-up\nin which a photon is detected after falling on one of the $28\\times 28$ image\npixels is limited to a (maximum likelihood estimation) accuracy of $21.27\\%$\nfor MNIST, respectively $18.27\\%$ for Fashion-MNIST, we show that the\ntheoretically achievable accuracy when exploiting inference by optically\ntransforming the quantum state of the photon is at least $41.27\\%$ for MNIST,\nrespectively $36.14\\%$ for Fashion-MNIST.\n  We show in detail how to train the corresponding transformation with\nTensorFlow and also explain how this example can serve as a teaching tool for\nthe measurement process in quantum mechanics.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 12:37:21 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 14:23:07 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Fischbacher", "Thomas", ""], ["Sbaiz", "Luciano", ""]]}, {"id": "2008.05867", "submitter": "Luca Corinzia", "authors": "Luca Corinzia, Fabian Laumer, Alessandro Candreva, Maurizio Taramasso,\n  Francesco Maisano, Joachim M. Buhmann", "title": "Neural collaborative filtering for unsupervised mitral valve\n  segmentation in echocardiography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The segmentation of the mitral valve annulus and leaflets specifies a crucial\nfirst step to establish a machine learning pipeline that can support physicians\nin performing multiple tasks, e.g.\\ diagnosis of mitral valve diseases,\nsurgical planning, and intraoperative procedures. Current methods for mitral\nvalve segmentation on 2D echocardiography videos require extensive interaction\nwith annotators and perform poorly on low-quality and noisy videos. We propose\nan automated and unsupervised method for the mitral valve segmentation based on\na low dimensional embedding of the echocardiography videos using neural network\ncollaborative filtering. The method is evaluated in a collection of\nechocardiography videos of patients with a variety of mitral valve diseases,\nand additionally on an independent test cohort. It outperforms state-of-the-art\n\\emph{unsupervised} and \\emph{supervised} methods on low-quality videos or in\nthe case of sparse annotation.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 12:53:26 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Corinzia", "Luca", ""], ["Laumer", "Fabian", ""], ["Candreva", "Alessandro", ""], ["Taramasso", "Maurizio", ""], ["Maisano", "Francesco", ""], ["Buhmann", "Joachim M.", ""]]}, {"id": "2008.05880", "submitter": "Lifang He", "authors": "Hao Peng, Jianxin Li, Zheng Wang, Renyu Yang, Mingzhe Liu, Mingming\n  Zhang, Philip S. Yu and Lifang He", "title": "Lifelong Property Price Prediction: A Case Study for the Toronto Real\n  Estate Market", "comments": "14 pages, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Luce, the first life-long predictive model for automated property\nvaluation. Luce addresses two critical issues of property valuation: the lack\nof recent sold prices and the sparsity of house data. It is designed to operate\non a limited volume of recent house transaction data. As a departure from prior\nwork, Luce organizes the house data in a heterogeneous information network\n(HIN) where graph nodes are house entities and attributes that are important\nfor house price valuation. We employ a Graph Convolutional Network (GCN) to\nextract the spatial information from the HIN for house-related data like\ngeographical locations, and then use a Long Short Term Memory (LSTM) network to\nmodel the temporal dependencies for house transaction data over time. Unlike\nprior work, Luce can make effective use of the limited house transactions data\nin the past few months to update valuation information for all house entities\nwithin the HIN. By providing a complete and up-to-date house valuation dataset,\nLuce thus massively simplifies the downstream valuation task for the targeting\nproperties. We demonstrate the benefit of Luce by applying it to large,\nreal-life datasets obtained from the Toronto real estate market. Extensive\nexperimental results show that Luce not only significantly outperforms prior\nproperty valuation methods but also often reaches and sometimes exceeds the\nvaluation accuracy given by independent experts when using the actual\nrealization price as the ground truth.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 07:32:16 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Peng", "Hao", ""], ["Li", "Jianxin", ""], ["Wang", "Zheng", ""], ["Yang", "Renyu", ""], ["Liu", "Mingzhe", ""], ["Zhang", "Mingming", ""], ["Yu", "Philip S.", ""], ["He", "Lifang", ""]]}, {"id": "2008.05892", "submitter": "Quan Meng", "authors": "Quan Meng, Jiakai Zhang, Qiang Hu, Xuming He, Jingyi Yu", "title": "LGNN: A Context-aware Line Segment Detector", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": "10.1145/3394171.3413784", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel real-time line segment detection scheme called Line Graph\nNeural Network (LGNN). Existing approaches require a computationally expensive\nverification or postprocessing step. Our LGNN employs a deep convolutional\nneural network (DCNN) for proposing line segment directly, with a graph neural\nnetwork (GNN) module for reasoning their connectivities. Specifically, LGNN\nexploits a new quadruplet representation for each line segment where the GNN\nmodule takes the predicted candidates as vertexes and constructs a sparse graph\nto enforce structural context. Compared with the state-of-the-art, LGNN\nachieves near real-time performance without compromising accuracy. LGNN further\nenables time-sensitive 3D applications. When a 3D point cloud is accessible, we\npresent a multi-modal line segment classification technique for extracting a 3D\nwireframe of the environment robustly and efficiently.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 13:23:18 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 03:43:06 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Meng", "Quan", ""], ["Zhang", "Jiakai", ""], ["Hu", "Qiang", ""], ["He", "Xuming", ""], ["Yu", "Jingyi", ""]]}, {"id": "2008.05900", "submitter": "Ninghan Chen", "authors": "Ninghan Chen, Zhiqiang Zhong, Jun Pang", "title": "An Exploratory Study of COVID-19 Information on Twitter in the Greater\n  Region", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The outbreak of the COVID-19 leads to a burst of information in major online\nsocial networks (OSNs). Facing this constantly changing situation, OSNs have\nbecome an essential platform for people expressing opinions and seeking\nup-to-the-minute information. Thus, discussions on OSNs may become a reflection\nof reality. This paper aims to figure out the distinctive characteristics of\nthe Greater Region (GR) through conducting a data-driven exploratory study of\nTwitter COVID-19 information in the GR and related countries using machine\nlearning and representation learning methods. We find that tweets volume and\nCOVID-19 cases in GR and related countries are correlated, but this correlation\nonly exists in a particular period of the pandemic. Moreover, we plot the\nchanging of topics in each country and region from 2020-01-22 to 2020-06-05,\nfiguring out the main differences between GR and related countries.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 16:37:58 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 12:49:02 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Chen", "Ninghan", ""], ["Zhong", "Zhiqiang", ""], ["Pang", "Jun", ""]]}, {"id": "2008.05903", "submitter": "Stefan Klus", "authors": "Kateryna Melnyk, Stefan Klus, Gr\\'egoire Montavon, Tim Conrad", "title": "GraphKKE: Graph Kernel Koopman Embedding for Human Microbiome Analysis", "comments": null, "journal-ref": null, "doi": "10.1007/s41109-020-00339-2", "report-no": null, "categories": "q-bio.QM cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More and more diseases have been found to be strongly correlated with\ndisturbances in the microbiome constitution, e.g., obesity, diabetes, or some\ncancer types. Thanks to modern high-throughput omics technologies, it becomes\npossible to directly analyze human microbiome and its influence on the health\nstatus. Microbial communities are monitored over long periods of time and the\nassociations between their members are explored. These relationships can be\ndescribed by a time-evolving graph. In order to understand responses of the\nmicrobial community members to a distinct range of perturbations such as\nantibiotics exposure or diseases and general dynamical properties, the\ntime-evolving graph of the human microbial communities has to be analyzed. This\nbecomes especially challenging due to dozens of complex interactions among\nmicrobes and metastable dynamics. The key to solving this problem is the\nrepresentation of the time-evolving graphs as fixed-length feature vectors\npreserving the original dynamics. We propose a method for learning the\nembedding of the time-evolving graph that is based on the spectral analysis of\ntransfer operators and graph kernels. We demonstrate that our method can\ncapture temporary changes in the time-evolving graph on both created synthetic\ndata and real-world data. Our experiments demonstrate the efficacy of the\nmethod. Furthermore, we show that our method can be applied to human microbiome\ndata to study dynamic processes.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 10:57:02 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 09:35:33 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2020 12:06:13 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Melnyk", "Kateryna", ""], ["Klus", "Stefan", ""], ["Montavon", "Gr\u00e9goire", ""], ["Conrad", "Tim", ""]]}, {"id": "2008.05906", "submitter": "Md Fahimuzzman Sohan", "authors": "Md Fahimuzzman Sohan", "title": "So You Need Datasets for Your COVID-19 Detection Research Using Machine\n  Learning?", "comments": "6 pages, 1 figure, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millions of people are infected by the coronavirus disease 2019 (COVID19)\naround the world. Machine Learning (ML) techniques are being used for COVID19\ndetection research from the beginning of the epidemic. This article represents\nthe detailed information on frequently used datasets in COVID19 detection using\nMachine Learning (ML). We investigated 96 papers on COVID19 detection between\nJanuary 2020 and June 2020. We extracted the information about used datasets\nfrom the articles and represented them here simultaneously. This investigation\nwill help future researchers to find the COVID19 datasets without difficulty.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 18:25:09 GMT"}, {"version": "v2", "created": "Sun, 16 Aug 2020 09:21:10 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sohan", "Md Fahimuzzman", ""]]}, {"id": "2008.05912", "submitter": "Laurence Aitchison", "authors": "Laurence Aitchison", "title": "A statistical theory of cold posteriors in deep neural networks", "comments": "Published at ICLR 2021 (https://openreview.net/forum?id=Rd138pWXMvG)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To get Bayesian neural networks to perform comparably to standard neural\nnetworks it is usually necessary to artificially reduce uncertainty using a\n\"tempered\" or \"cold\" posterior. This is extremely concerning: if the prior is\naccurate, Bayes inference/decision theory is optimal, and any artificial\nchanges to the posterior should harm performance. While this suggests that the\nprior may be at fault, here we argue that in fact, BNNs for image\nclassification use the wrong likelihood. In particular, standard image\nbenchmark datasets such as CIFAR-10 are carefully curated. We develop a\ngenerative model describing curation which gives a principled Bayesian account\nof cold posteriors, because the likelihood under this new generative model\nclosely matches the tempered likelihoods used in past work.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 13:46:58 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 14:33:30 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Aitchison", "Laurence", ""]]}, {"id": "2008.05913", "submitter": "Laurence Aitchison", "authors": "Laurence Aitchison", "title": "A statistical theory of semi-supervised learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We currently lack a solid statistical understanding of semi-supervised\nlearning methods, instead treating them as a collection of highly effective\ntricks. This precludes the principled combination e.g. of Bayesian methods and\nsemi-supervised learning, as semi-supervised learning objectives are not\ncurrently formulated as likelihoods for an underlying generative model of the\ndata. Here, we note that standard image benchmark datasets such as CIFAR-10 are\ncarefully curated, and we provide a generative model describing the curation\nprocess. Under this generative model, several state-of-the-art semi-supervised\nlearning techniques, including entropy minimization, pseudo-labelling and the\nFixMatch family emerge naturally as variational lower-bounds on the\nlog-likelihood.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 13:50:27 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Aitchison", "Laurence", ""]]}, {"id": "2008.05930", "submitter": "Sergio Casas", "authors": "Abbas Sadat, Sergio Casas, Mengye Ren, Xinyu Wu, Pranaab Dhawan,\n  Raquel Urtasun", "title": "Perceive, Predict, and Plan: Safe Motion Planning Through Interpretable\n  Semantic Representations", "comments": "European Conference on Computer Vision (ECCV) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel end-to-end learnable network that performs\njoint perception, prediction and motion planning for self-driving vehicles and\nproduces interpretable intermediate representations. Unlike existing neural\nmotion planners, our motion planning costs are consistent with our perception\nand prediction estimates. This is achieved by a novel differentiable semantic\noccupancy representation that is explicitly used as cost by the motion planning\nprocess. Our network is learned end-to-end from human demonstrations. The\nexperiments in a large-scale manual-driving dataset and closed-loop simulation\nshow that the proposed model significantly outperforms state-of-the-art\nplanners in imitating the human behaviors while producing much safer\ntrajectories.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 14:40:46 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Sadat", "Abbas", ""], ["Casas", "Sergio", ""], ["Ren", "Mengye", ""], ["Wu", "Xinyu", ""], ["Dhawan", "Pranaab", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2008.05932", "submitter": "Vincenzo Bonnici Ph.D.", "authors": "Vincenzo Bonnici", "title": "Kullback-Leibler divergence between quantum distributions, and its\n  upper-bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents an upper-bound to value that the Kullback-Leibler (KL)\ndivergence can reach for a class of probability distributions called quantum\ndistributions (QD). The aim is to find a distribution $U$ which maximizes the\nKL divergence from a given distribution $P$ under the assumption that $P$ and\n$U$ have been generated by distributing a given discrete quantity, a quantum.\nQuantum distributions naturally represent a wide range of probability\ndistributions that are used in practical applications. Moreover, such a class\nof distributions can be obtained as an approximation of any probability\ndistribution. The retrieving of an upper-bound for the entropic divergence is\nhere shown to be possible under the condition that the compared distributions\nare quantum distributions over the same quantum value, thus they become\ncomparable. Thus, entropic divergence acquires a more powerful meaning when it\nis applied to comparable distributions. This aspect should be taken into\naccount in future developments of divergences. The theoretical findings are\nused for proposing a notion of normalized KL divergence that is empirically\nshown to behave differently from already known measures.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 14:42:13 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 08:55:37 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 12:39:33 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Bonnici", "Vincenzo", ""]]}, {"id": "2008.05938", "submitter": "Andrea Ceccarelli", "authors": "Francesco Secci, Andrea Ceccarelli", "title": "RGB cameras failures and their effects in autonomous driving\n  applications", "comments": "submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RGB cameras are one of the most relevant sensors for autonomous driving\napplications. It is undeniable that failures of vehicle cameras may compromise\nthe autonomous driving task, possibly leading to unsafe behaviors when images\nthat are subsequently processed by the driving system are altered. To support\nthe definition of safe and robust vehicle architectures and intelligent\nsystems, in this paper we define the failure modes of a vehicle camera,\ntogether with an analysis of effects and known mitigations. Further, we build a\nsoftware library for the generation of the corresponding failed images and we\nfeed them to six object detectors for mono and stereo cameras and to the\nself-driving agent of an autonomous driving simulator. The resulting\nmisbehaviors with respect to operating with clean images allow a better\nunderstanding of failures effects and the related safety risks in image-based\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 14:47:50 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 15:06:58 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Secci", "Francesco", ""], ["Ceccarelli", "Andrea", ""]]}, {"id": "2008.05948", "submitter": "Radu Tudor Ionescu", "authors": "Nicolae-C\\u{a}t\\u{a}lin Ristea, Andrei Anghel, Radu Tudor Ionescu", "title": "Estimating Magnitude and Phase of Automotive Radar Signals under\n  Multiple Interference Sources with Fully Convolutional Networks", "comments": "arXiv admin note: text overlap with arXiv:2007.11102", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radar sensors are gradually becoming a wide-spread equipment for road\nvehicles, playing a crucial role in autonomous driving and road safety. The\nbroad adoption of radar sensors increases the chance of interference among\nsensors from different vehicles, generating corrupted range profiles and\nrange-Doppler maps. In order to extract distance and velocity of multiple\ntargets from range-Doppler maps, the interference affecting each range profile\nneeds to be mitigated. In this paper, we propose a fully convolutional neural\nnetwork for automotive radar interference mitigation. In order to train our\nnetwork in a real-world scenario, we introduce a new data set of realistic\nautomotive radar signals with multiple targets and multiple interferers. To our\nknowledge, this is the first work to mitigate interference from multiple\nsources. Furthermore, we introduce a new training regime that eliminates noisy\nweights, showing superior results compared to the widely-used dropout. While\nsome previous works successfully estimated the magnitude of automotive radar\nsignals, we are the first to propose a deep learning model that can accurately\nestimate the phase. For instance, our novel approach reduces the phase\nestimation error with respect to the commonly-adopted zeroing technique by\nhalf, from 12.55 degrees to 6.58 degrees. Considering the lack of databases for\nautomotive radar interference mitigation, we release as open source our\nlarge-scale data set that closely replicates the real-world automotive scenario\nfor multiple interference cases, allowing others to objectively compare their\nfuture work in this domain. Our data set is available for download at:\nhttp://github.com/ristea/arim-v2.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 18:50:38 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Ristea", "Nicolae-C\u0103t\u0103lin", ""], ["Anghel", "Andrei", ""], ["Ionescu", "Radu Tudor", ""]]}, {"id": "2008.05952", "submitter": "Stephen Tu", "authors": "Nicholas M. Boffi and Stephen Tu and Nikolai Matni and Jean-Jacques E.\n  Slotine and Vikas Sindhwani", "title": "Learning Stability Certificates from Data", "comments": "Fixes an error in the statement and proof of Theorem 5.1, Theorem\n  5.2, and Proposition D.1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many existing tools in nonlinear control theory for establishing stability or\nsafety of a dynamical system can be distilled to the construction of a\ncertificate function that guarantees a desired property. However, algorithms\nfor synthesizing certificate functions typically require a closed-form\nanalytical expression of the underlying dynamics, which rules out their use on\nmany modern robotic platforms. To circumvent this issue, we develop algorithms\nfor learning certificate functions only from trajectory data. We establish\nbounds on the generalization error - the probability that a certificate will\nnot certify a new, unseen trajectory - when learning from trajectories, and we\nconvert such generalization error bounds into global stability guarantees. We\ndemonstrate empirically that certificates for complex dynamics can be\nefficiently learned, and that the learned certificates can be used for\ndownstream tasks such as adaptive control.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 14:58:42 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 17:47:06 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Boffi", "Nicholas M.", ""], ["Tu", "Stephen", ""], ["Matni", "Nikolai", ""], ["Slotine", "Jean-Jacques E.", ""], ["Sindhwani", "Vikas", ""]]}, {"id": "2008.05955", "submitter": "Mona Jalal", "authors": "Mona Jalal, Josef Spjut, Ben Boudaoud, Margrit Betke", "title": "SIDOD: A Synthetic Image Dataset for 3D Object Pose Recognition with\n  Distractors", "comments": "3 pages, 4 figures, 1 table, Accepted at CVPR 2019 Workshop", "journal-ref": null, "doi": "10.1109/CVPRW.2019.00063", "report-no": null, "categories": "cs.CV cs.GR cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new, publicly-available image dataset generated by the NVIDIA\nDeep Learning Data Synthesizer intended for use in object detection, pose\nestimation, and tracking applications. This dataset contains 144k stereo image\npairs that synthetically combine 18 camera viewpoints of three photorealistic\nvirtual environments with up to 10 objects (chosen randomly from the 21 object\nmodels of the YCB dataset [1]) and flying distractors. Object and camera pose,\nscene lighting, and quantity of objects and distractors were randomized. Each\nprovided view includes RGB, depth, segmentation, and surface normal images, all\npixel level. We describe our approach for domain randomization and provide\ninsight into the decisions that produced the dataset.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 00:14:19 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Jalal", "Mona", ""], ["Spjut", "Josef", ""], ["Boudaoud", "Ben", ""], ["Betke", "Margrit", ""]]}, {"id": "2008.05959", "submitter": "Philippe Esling", "authors": "Philippe Esling, Ninon Devis", "title": "Creativity in the era of artificial intelligence", "comments": "Keynote paper - JIM Conference 2020 - 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Creativity is a deeply debated topic, as this concept is arguably\nquintessential to our humanity. Across different epochs, it has been infused\nwith an extensive variety of meanings relevant to that era. Along these, the\nevolution of technology have provided a plurality of novel tools for creative\npurposes. Recently, the advent of Artificial Intelligence (AI), through deep\nlearning approaches, have seen proficient successes across various\napplications. The use of such technologies for creativity appear in a natural\ncontinuity to the artistic trend of this century. However, the aura of a\ntechnological artefact labeled as intelligent has unleashed passionate and\nsomewhat unhinged debates on its implication for creative endeavors. In this\npaper, we aim to provide a new perspective on the question of creativity at the\nera of AI, by blurring the frontier between social and computational sciences.\nTo do so, we rely on reflections from social science studies of creativity to\nview how current AI would be considered through this lens. As creativity is a\nhighly context-prone concept, we underline the limits and deficiencies of\ncurrent AI, requiring to move towards artificial creativity. We argue that the\nobjective of trying to purely mimic human creative traits towards a\nself-contained ex-nihilo generative machine would be highly counterproductive,\nputting us at risk of not harnessing the almost unlimited possibilities offered\nby the sheer computational power of artificial agents.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 15:07:34 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Esling", "Philippe", ""], ["Devis", "Ninon", ""]]}, {"id": "2008.05966", "submitter": "Manaar Alam", "authors": "Manaar Alam and Sayandeep Saha and Debdeep Mukhopadhyay and Sandip\n  Kundu", "title": "Deep-Lock: Secure Authorization for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trained Deep Neural Network (DNN) models are considered valuable Intellectual\nProperties (IP) in several business models. Prevention of IP theft and\nunauthorized usage of such DNN models has been raised as of significant concern\nby industry. In this paper, we address the problem of preventing unauthorized\nusage of DNN models by proposing a generic and lightweight key-based\nmodel-locking scheme, which ensures that a locked model functions correctly\nonly upon applying the correct secret key. The proposed scheme, known as\nDeep-Lock, utilizes S-Boxes with good security properties to encrypt each\nparameter of a trained DNN model with secret keys generated from a master key\nvia a key scheduling algorithm. The resulting dense network of encrypted\nweights is found robust against model fine-tuning attacks. Finally, Deep-Lock\ndoes not require any intervention in the structure and training of the DNN\nmodels, making it applicable for all existing software and hardware\nimplementations of DNN.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 15:22:49 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Alam", "Manaar", ""], ["Saha", "Sayandeep", ""], ["Mukhopadhyay", "Debdeep", ""], ["Kundu", "Sandip", ""]]}, {"id": "2008.05969", "submitter": "Tong Yang", "authors": "Tong Yang, Long Sha, Pengyu Hong", "title": "Variance Regularization for Accelerating Stochastic Optimization", "comments": "22 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While nowadays most gradient-based optimization methods focus on exploring\nthe high-dimensional geometric features, the random error accumulated in a\nstochastic version of any algorithm implementation has not been stressed yet.\nIn this work, we propose a universal principle which reduces the random error\naccumulation by exploiting statistic information hidden in mini-batch\ngradients. This is achieved by regularizing the learning-rate according to\nmini-batch variances. Due to the complementarity of our perspective, this\nregularization could provide a further improvement for stochastic\nimplementation of generic 1st order approaches. With empirical results, we\ndemonstrated the variance regularization could speed up the convergence as well\nas stabilize the stochastic optimization.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 15:34:01 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Yang", "Tong", ""], ["Sha", "Long", ""], ["Hong", "Pengyu", ""]]}, {"id": "2008.05972", "submitter": "Pramod Vadiraja", "authors": "Pramod Vadiraja and Muhammad Ali Chattha", "title": "A Survey on Knowledge integration techniques with Artificial Neural\n  Networks for seq-2-seq/time series models", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, with the advent of massive computational power and the\navailability of huge amounts of data, Deep neural networks have enabled the\nexploration of uncharted areas in several domains. But at times, they\nunder-perform due to insufficient data, poor data quality, data that might not\nbe covering the domain broadly, etc. Knowledge-based systems leverage expert\nknowledge for making decisions and suitably take actions. Such systems retain\ninterpretability in the decision-making process. This paper focuses on\nexploring techniques to integrate expert knowledge to the Deep Neural Networks\nfor sequence-to-sequence and time series models to improve their performance\nand interpretability.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 15:40:38 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Vadiraja", "Pramod", ""], ["Chattha", "Muhammad Ali", ""]]}, {"id": "2008.05984", "submitter": "Elena Arcari", "authors": "Elena Arcari, Andrea Carron, Melanie N. Zeilinger", "title": "Meta Learning MPC using Finite-Dimensional Gaussian Process\n  Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data availability has dramatically increased in recent years, driving\nmodel-based control methods to exploit learning techniques for improving the\nsystem description, and thus control performance. Two key factors that hinder\nthe practical applicability of learning methods in control are their high\ncomputational complexity and limited generalization capabilities to unseen\nconditions. Meta-learning is a powerful tool that enables efficient learning\nacross a finite set of related tasks, easing adaptation to new unseen tasks.\nThis paper makes use of a meta-learning approach for adaptive model predictive\ncontrol, by learning a system model that leverages data from previous related\ntasks, while enabling fast fine-tuning to the current task during closed-loop\noperation. The dynamics is modeled via Gaussian process regression and,\nbuilding on the Karhunen-Lo{\\`e}ve expansion, can be approximately reformulated\nas a finite linear combination of kernel eigenfunctions. Using data collected\nover a set of tasks, the eigenfunction hyperparameters are optimized in a\nmeta-training phase by maximizing a variational bound for the log-marginal\nlikelihood. During meta-testing, the eigenfunctions are fixed, so that only the\nlinear parameters are adapted to the new unseen task in an online adaptive\nfashion via Bayesian linear regression, providing a simple and efficient\ninference scheme. Simulation results are provided for autonomous racing with\nminiature race cars adapting to unseen road conditions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 15:59:38 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Arcari", "Elena", ""], ["Carron", "Andrea", ""], ["Zeilinger", "Melanie N.", ""]]}, {"id": "2008.05987", "submitter": "Alqamah Sayeed", "authors": "Alqamah Sayeed, Yunsoo Choi, Ebrahim Eslami, Jia Jung, Yannic Lops,\n  Ahmed Khan Salman", "title": "A Novel CMAQ-CNN Hybrid Model to Forecast Hourly Surface-Ozone\n  Concentrations Fourteen Days in Advance", "comments": "15 pages, 4 main figures and supplemantary figures and tables", "journal-ref": null, "doi": "10.1038/s41598-021-90446-6", "report-no": null, "categories": "physics.ao-ph cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Issues regarding air quality and related health concerns have prompted this\nstudy, which develops an accurate and computationally fast, efficient hybrid\nmodeling system that combines numerical modeling and machine learning for\nforecasting concentrations of surface ozone. Currently available numerical\nmodeling systems for air quality predictions (e.g., CMAQ, NCEP EMP) can\nforecast 24 to 48 hours in advance. In this study, we develop a modeling system\nbased on a convolutional neural network (CNN) model that is not only fast but\ncovers a temporal period of two weeks with a resolution as small as a single\nhour for 255 stations. The CNN model uses forecasted meteorology from the\nWeather Research and Forecasting model (processed by the Meteorology-Chemistry\nInterface Processor), forecasted air quality from the Community Multi-scale Air\nQuality Model (CMAQ), and previous 24-hour concentrations of various measurable\nair quality parameters as inputs and predicts the following 14-day hourly\nsurface ozone concentrations. The model achieves an average accuracy of 0.91 in\nterms of the index of agreement for the first day and 0.78 for the fourteenth\nday while the average index of agreement for one day ahead prediction from the\nCMAQ is 0.77. Through this study, we intend to amalgamate the best features of\nnumerical modeling (i.e., fine spatial resolution) and a deep neural network\n(i.e., computation speed and accuracy) to achieve more accurate spatio-temporal\npredictions of hourly ozone concentrations. Although the primary purpose of\nthis study is the prediction of hourly ozone concentrations, the system can be\nextended to various other pollutants.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 16:02:05 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Sayeed", "Alqamah", ""], ["Choi", "Yunsoo", ""], ["Eslami", "Ebrahim", ""], ["Jung", "Jia", ""], ["Lops", "Yannic", ""], ["Salman", "Ahmed Khan", ""]]}, {"id": "2008.05994", "submitter": "David Glowacki", "authors": "Lars A. Bratholm, Will Gerrard, Brandon Anderson, Shaojie Bai,\n  Sunghwan Choi, Lam Dang, Pavel Hanchar, Addison Howard, Guillaume Huard,\n  Sanghoon Kim, Zico Kolter, Risi Kondor, Mordechai Kornbluth, Youhan Lee,\n  Youngsoo Lee, Jonathan P. Mailoa, Thanh Tu Nguyen, Milos Popovic, Goran\n  Rakocevic, Walter Reade, Wonho Song, Luka Stojanovic, Erik H. Thiede, Nebojsa\n  Tijanic, Andres Torrubia, Devin Willmott, Craig P. Butts, David R. Glowacki,\n  and Kaggle participants", "title": "A community-powered search of machine learning strategy space to find\n  NMR property prediction models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rise of machine learning (ML) has created an explosion in the potential\nstrategies for using data to make scientific predictions. For physical\nscientists wishing to apply ML strategies to a particular domain, it can be\ndifficult to assess in advance what strategy to adopt within a vast space of\npossibilities. Here we outline the results of an online community-powered\neffort to swarm search the space of ML strategies and develop algorithms for\npredicting atomic-pairwise nuclear magnetic resonance (NMR) properties in\nmolecules. Using an open-source dataset, we worked with Kaggle to design and\nhost a 3-month competition which received 47,800 ML model predictions from\n2,700 teams in 84 countries. Within 3 weeks, the Kaggle community produced\nmodels with comparable accuracy to our best previously published \"in-house\"\nefforts. A meta-ensemble model constructed as a linear combination of the top\npredictions has a prediction accuracy which exceeds that of any individual\nmodel, 7-19x better than our previous state-of-the-art. The results highlight\nthe potential of transformer architectures for predicting quantum mechanical\n(QM) molecular properties.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 16:23:40 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Bratholm", "Lars A.", ""], ["Gerrard", "Will", ""], ["Anderson", "Brandon", ""], ["Bai", "Shaojie", ""], ["Choi", "Sunghwan", ""], ["Dang", "Lam", ""], ["Hanchar", "Pavel", ""], ["Howard", "Addison", ""], ["Huard", "Guillaume", ""], ["Kim", "Sanghoon", ""], ["Kolter", "Zico", ""], ["Kondor", "Risi", ""], ["Kornbluth", "Mordechai", ""], ["Lee", "Youhan", ""], ["Lee", "Youngsoo", ""], ["Mailoa", "Jonathan P.", ""], ["Nguyen", "Thanh Tu", ""], ["Popovic", "Milos", ""], ["Rakocevic", "Goran", ""], ["Reade", "Walter", ""], ["Song", "Wonho", ""], ["Stojanovic", "Luka", ""], ["Thiede", "Erik H.", ""], ["Tijanic", "Nebojsa", ""], ["Torrubia", "Andres", ""], ["Willmott", "Devin", ""], ["Butts", "Craig P.", ""], ["Glowacki", "David R.", ""], ["participants", "Kaggle", ""]]}, {"id": "2008.06006", "submitter": "Quan Wang", "authors": "Shaojin Ding, Ye Jia, Ke Hu, Quan Wang", "title": "Textual Echo Cancellation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Textual Echo Cancellation (TEC) - a framework for\ncancelling the text-to-speech (TTS) playback echo from overlapping speech\nrecordings. Such a system can largely improve speech recognition performance\nand user experience for intelligent devices such as smart speakers, as the user\ncan talk to the device while the device is still playing the TTS signal\nresponding to the previous query. We implement this system by using a novel\nsequence-to-sequence model with multi-source attention that takes both the\nmicrophone mixture signal and source text of the TTS playback as inputs, and\npredicts the enhanced audio. Experiments show that the textual information of\nthe TTS playback is critical to enhancement performance. Besides, the text\nsequence is much smaller in size compared with the raw acoustic signal of the\nTTS playback, and can be immediately transmitted to the device or ASR server\neven before the playback is synthesized. Therefore, our proposed approach\neffectively reduces Internet communication and latency compared with\nalternative approaches such as acoustic echo cancellation (AEC).\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 16:47:30 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 16:18:42 GMT"}, {"version": "v3", "created": "Fri, 2 Jul 2021 17:23:53 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Ding", "Shaojin", ""], ["Jia", "Ye", ""], ["Hu", "Ke", ""], ["Wang", "Quan", ""]]}, {"id": "2008.06020", "submitter": "Kelvin Wong", "authors": "Kelvin Wong, Qiang Zhang, Ming Liang, Bin Yang, Renjie Liao, Abbas\n  Sadat, Raquel Urtasun", "title": "Testing the Safety of Self-driving Vehicles by Simulating Perception and\n  Prediction", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for testing the safety of self-driving vehicles in\nsimulation. We propose an alternative to sensor simulation, as sensor\nsimulation is expensive and has large domain gaps. Instead, we directly\nsimulate the outputs of the self-driving vehicle's perception and prediction\nsystem, enabling realistic motion planning testing. Specifically, we use paired\ndata in the form of ground truth labels and real perception and prediction\noutputs to train a model that predicts what the online system will produce.\nImportantly, the inputs to our system consists of high definition maps,\nbounding boxes, and trajectories, which can be easily sketched by a test\nengineer in a matter of minutes. This makes our approach a much more scalable\nsolution. Quantitative results on two large-scale datasets demonstrate that we\ncan realistically test motion planning using our simulations.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 17:20:02 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Wong", "Kelvin", ""], ["Zhang", "Qiang", ""], ["Liang", "Ming", ""], ["Yang", "Bin", ""], ["Liao", "Renjie", ""], ["Sadat", "Abbas", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2008.06021", "submitter": "Matteo Testa", "authors": "Arslan Ali, Matteo Testa, Tiziano Bianchi, Enrico Magli", "title": "BioMetricNet: deep unconstrained face verification through learning of\n  metrics regularized onto Gaussian distributions", "comments": "Accepted at ECCV20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present BioMetricNet: a novel framework for deep unconstrained face\nverification which learns a regularized metric to compare facial features.\nDifferently from popular methods such as FaceNet, the proposed approach does\nnot impose any specific metric on facial features; instead, it shapes the\ndecision space by learning a latent representation in which matching and\nnon-matching pairs are mapped onto clearly separated and well-behaved target\ndistributions. In particular, the network jointly learns the best feature\nrepresentation, and the best metric that follows the target distributions, to\nbe used to discriminate face images. In this paper we present this general\nframework, first of its kind for facial verification, and tailor it to Gaussian\ndistributions. This choice enables the use of a simple linear decision boundary\nthat can be tuned to achieve the desired trade-off between false alarm and\ngenuine acceptance rate, and leads to a loss function that can be written in\nclosed form. Extensive analysis and experimentation on publicly available\ndatasets such as Labeled Faces in the wild (LFW), Youtube faces (YTF),\nCelebrities in Frontal-Profile in the Wild (CFP), and challenging datasets like\ncross-age LFW (CALFW), cross-pose LFW (CPLFW), In-the-wild Age Dataset (AgeDB)\nshow a significant performance improvement and confirms the effectiveness and\nsuperiority of BioMetricNet over existing state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 17:22:46 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Ali", "Arslan", ""], ["Testa", "Matteo", ""], ["Bianchi", "Tiziano", ""], ["Magli", "Enrico", ""]]}, {"id": "2008.06029", "submitter": "Burhaneddin Yaman", "authors": "Burhaneddin Yaman, Seyed Amir Hossein Hosseini, Steen Moeller, Jutta\n  Ellermann, K\\^amil U\\u{g}urbil, Mehmet Ak\\c{c}akaya", "title": "Multi-Mask Self-Supervised Learning for Physics-Guided Neural Networks\n  in Highly Accelerated MRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG eess.SP physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: To develop an improved self-supervised learning strategy that\nefficiently uses the acquired data for training a physics-guided reconstruction\nnetwork without a database of fully-sampled data.\n  Methods: Currently self-supervised learning for physics-guided reconstruction\nnetworks splits acquired undersampled data into two disjoint sets, where one is\nused for data consistency (DC) in the unrolled network and the other to define\nthe training loss. The proposed multi-mask self-supervised learning via data\nundersampling (SSDU) splits acquired measurements into multiple pairs of\ndisjoint sets for each training sample, while using one of these sets for DC\nunits and the other for defining loss, thereby more efficiently using the\nundersampled data. Multi-mask SSDU is applied on fully-sampled 3D knee and\nprospectively undersampled 3D brain MRI datasets, which are retrospectively\nsubsampled to acceleration rate (R)=8, and compared to CG-SENSE and single-mask\nSSDU DL-MRI, as well as supervised DL-MRI when fully-sampled data is available.\n  Results: Results on knee MRI show that the proposed multi-mask SSDU\noutperforms SSDU and performs closely with supervised DL-MRI, while\nsignificantly outperforming CG-SENSE. A clinical reader study further ranks the\nmulti-mask SSDU higher than supervised DL-MRI in terms of SNR and aliasing\nartifacts. Results on brain MRI show that multi-mask SSDU achieves better\nreconstruction quality compared to SSDU and CG-SENSE. Reader study demonstrates\nthat multi-mask SSDU at R=8 significantly improves reconstruction compared to\nsingle-mask SSDU at R=8, as well as CG-SENSE at R=2.\n  Conclusion: The proposed multi-mask SSDU approach enables improved training\nof physics-guided neural networks without fully-sampled data, by enabling\nefficient use of the undersampled data with multiple masks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 17:36:59 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Yaman", "Burhaneddin", ""], ["Hosseini", "Seyed Amir Hossein", ""], ["Moeller", "Steen", ""], ["Ellermann", "Jutta", ""], ["U\u011furbil", "K\u00e2mil", ""], ["Ak\u00e7akaya", "Mehmet", ""]]}, {"id": "2008.06035", "submitter": "Srikrishna Karanam", "authors": "Meng Zheng and Srikrishna Karanam and Terrence Chen and Richard J.\n  Radke and Ziyan Wu", "title": "Towards Visually Explaining Similarity Models", "comments": "13 pages, 10 figures, 4 tables. arXiv admin note: substantial text\n  overlap with arXiv:1911.07381", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of visually explaining similarity models, i.e.,\nexplaining why a model predicts two images to be similar in addition to\nproducing a scalar score. While much recent work in visual model\ninterpretability has focused on gradient-based attention, these methods rely on\na classification module to generate visual explanations. Consequently, they\ncannot readily explain other kinds of models that do not use or need\nclassification-like loss functions (e.g., similarity models trained with a\nmetric learning loss). In this work, we bridge this crucial gap, presenting a\nmethod to generate gradient-based visual attention for image similarity\npredictors. By relying solely on the learned feature embedding, we show that\nour approach can be applied to any kind of CNN-based similarity architecture,\nan important step towards generic visual explainability. We show that our\nresulting attention maps serve more than just interpretability; they can be\ninfused into the model learning process itself with new trainable constraints.\nWe show that the resulting similarity models perform, and can be visually\nexplained, better than the corresponding baseline models trained without these\nconstraints. We demonstrate our approach using extensive experiments on three\ndifferent kinds of tasks: generic image retrieval, person re-identification,\nand low-shot semantic segmentation.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 17:47:41 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 17:00:38 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Zheng", "Meng", ""], ["Karanam", "Srikrishna", ""], ["Chen", "Terrence", ""], ["Radke", "Richard J.", ""], ["Wu", "Ziyan", ""]]}, {"id": "2008.06036", "submitter": "Jonathan Efroni", "authors": "Yonathan Efroni, Nadav Merlis, Shie Mannor", "title": "Reinforcement Learning with Trajectory Feedback", "comments": "AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard feedback model of reinforcement learning requires revealing the\nreward of every visited state-action pair. However, in practice, it is often\nthe case that such frequent feedback is not available. In this work, we take a\nfirst step towards relaxing this assumption and require a weaker form of\nfeedback, which we refer to as \\emph{trajectory feedback}. Instead of observing\nthe reward obtained after every action, we assume we only receive a score that\nrepresents the quality of the whole trajectory observed by the agent, namely,\nthe sum of all rewards obtained over this trajectory. We extend reinforcement\nlearning algorithms to this setting, based on least-squares estimation of the\nunknown reward, for both the known and unknown transition model cases, and\nstudy the performance of these algorithms by analyzing their regret. For cases\nwhere the transition model is unknown, we offer a hybrid optimistic-Thompson\nSampling approach that results in a tractable algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 17:49:18 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 20:04:50 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Efroni", "Yonathan", ""], ["Merlis", "Nadav", ""], ["Mannor", "Shie", ""]]}, {"id": "2008.06043", "submitter": "Eric A Mitchell", "authors": "Eric Mitchell, Rafael Rafailov, Xue Bin Peng, Sergey Levine, Chelsea\n  Finn", "title": "Offline Meta-Reinforcement Learning with Advantage Weighting", "comments": "ICML 2021; for code & project info, see\n  http://sites.google.com/view/macaw-metarl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the offline meta-reinforcement learning (offline\nmeta-RL) problem setting and proposes an algorithm that performs well in this\nsetting. Offline meta-RL is analogous to the widely successful supervised\nlearning strategy of pre-training a model on a large batch of fixed,\npre-collected data (possibly from various tasks) and fine-tuning the model to a\nnew task with relatively little data. That is, in offline meta-RL, we\nmeta-train on fixed, pre-collected data from several tasks in order to adapt to\na new task with a very small amount (less than 5 trajectories) of data from the\nnew task. By nature of being offline, algorithms for offline meta-RL can\nutilize the largest possible pool of training data available and eliminate\npotentially unsafe or costly data collection during meta-training. This setting\ninherits the challenges of offline RL, but it differs significantly because\noffline RL does not generally consider a) transfer to new tasks or b) limited\ndata from the test task, both of which we face in offline meta-RL. Targeting\nthe offline meta-RL setting, we propose Meta-Actor Critic with Advantage\nWeighting (MACAW), an optimization-based meta-learning algorithm that uses\nsimple, supervised regression objectives for both the inner and outer loop of\nmeta-training. On offline variants of common meta-RL benchmarks, we empirically\nfind that this approach enables fully offline meta-reinforcement learning and\nachieves notable gains over prior methods.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 17:57:14 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 17:35:24 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 17:33:01 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Mitchell", "Eric", ""], ["Rafailov", "Rafael", ""], ["Peng", "Xue Bin", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "2008.06048", "submitter": "Jeff Ens Mr", "authors": "Jeff Ens, Philippe Pasquier", "title": "MMM : Exploring Conditional Multi-Track Music Generation with the\n  Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose the Multi-Track Music Machine (MMM), a generative system based on\nthe Transformer architecture that is capable of generating multi-track music.\nIn contrast to previous work, which represents musical material as a single\ntime-ordered sequence, where the musical events corresponding to different\ntracks are interleaved, we create a time-ordered sequence of musical events for\neach track and concatenate several tracks into a single sequence. This takes\nadvantage of the Transformer's attention-mechanism, which can adeptly handle\nlong-term dependencies. We explore how various representations can offer the\nuser a high degree of control at generation time, providing an interactive demo\nthat accommodates track-level and bar-level inpainting, and offers control over\ntrack instrumentation and note density.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 02:36:34 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 19:13:39 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Ens", "Jeff", ""], ["Pasquier", "Philippe", ""]]}, {"id": "2008.06069", "submitter": "Ali Shahin Shamsabadi", "authors": "Ali Shahin Shamsabadi, Changjae Oh, Andrea Cavallaro", "title": "Semantically Adversarial Learnable Filters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an adversarial framework to craft perturbations that mislead\nclassifiers by accounting for the image content and the semantics of the\nlabels. The proposed framework combines a structure loss and a semantic\nadversarial loss in a multi-task objective function to train a fully\nconvolutional neural network. The structure loss helps generate perturbations\nwhose type and magnitude are defined by a target image processing filter. The\nsemantic adversarial loss considers groups of (semantic) labels to craft\nperturbations that prevent the filtered image being classified with a label in\nthe same group. We validate our framework by selecting as target filters detail\nenhancement, log transformation and gamma correction filters, and evaluate the\nadversarially filtered images against three classifiers, ResNet50, ResNet18 and\nAlexNet, pre-trained on ImageNet. We show that the proposed framework generates\nfiltered images with a high success rate, robustness, and transferability to\nunseen classifiers.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 18:12:40 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 18:12:06 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Shamsabadi", "Ali Shahin", ""], ["Oh", "Changjae", ""], ["Cavallaro", "Andrea", ""]]}, {"id": "2008.06072", "submitter": "Arash Mohammadi", "authors": "Parnian Afshar, Farnoosh Naderkhani, Anastasia Oikonomou, Moezedin\n  Javad Rafiee, Arash Mohammadi, and Konstantinos N. Plataniotis", "title": "MIXCAPS: A Capsule Network-based Mixture of Experts for Lung Nodule\n  Malignancy Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lung diseases including infections such as Pneumonia, Tuberculosis, and novel\nCoronavirus (COVID-19), together with Lung Cancer are significantly widespread\nand are, typically, considered life threatening. In particular, lung cancer is\namong the most common and deadliest cancers with a low 5-year survival rate.\nTimely diagnosis of lung cancer is, therefore, of paramount importance as it\ncan save countless lives. In this regard, deep learning radiomics solutions\nhave the promise of extracting the most useful features on their own in an\nend-to-end fashion without having access to the annotated boundaries. Among\ndifferent deep learning models, Capsule Networks are proposed to overcome\nshortcomings of the Convolutional Neural Networks (CNN) such as their inability\nto recognize detailed spatial relations. Capsule networks have so far shown\nsatisfying performance in medical imaging problems. Capitalizing on their\nsuccess, in this study, we propose a novel capsule network-based mixture of\nexperts, referred to as the MIXCAPS. The proposed MIXCAPS architecture takes\nadvantage of not only the capsule network's capabilities to handle small\ndatasets, but also automatically splitting dataset through a convolutional\ngating network. MIXCAPS enables capsule network experts to specialize on\ndifferent subsets of the data. Our results show that MIXCAPS outperforms a\nsingle capsule network and a mixture of CNNs, with an accuracy of 92.88%,\nsensitivity of 93.2%, specificity of 92.3% and area under the curve of 0.963.\nOur experiments also show that there is a relation between the gate outputs and\na couple of hand-crafted features, illustrating explainable nature of the\nproposed MIXCAPS. To further evaluate generalization capabilities of the\nproposed MIXCAPS architecture, additional experiments on a brain tumor dataset\nare performed showing potentials of MIXCAPS for detection of tumors related to\nother organs.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 18:16:07 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Afshar", "Parnian", ""], ["Naderkhani", "Farnoosh", ""], ["Oikonomou", "Anastasia", ""], ["Rafiee", "Moezedin Javad", ""], ["Mohammadi", "Arash", ""], ["Plataniotis", "Konstantinos N.", ""]]}, {"id": "2008.06073", "submitter": "Andrey Kurenkov", "authors": "Andrey Kurenkov, Joseph Taglic, Rohun Kulkarni, Marcus\n  Dominguez-Kuhne, Animesh Garg, Roberto Mart\\'in-Mart\\'in, Silvio Savarese", "title": "Visuomotor Mechanical Search: Learning to Retrieve Target Objects in\n  Clutter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When searching for objects in cluttered environments, it is often necessary\nto perform complex interactions in order to move occluding objects out of the\nway and fully reveal the object of interest and make it graspable. Due to the\ncomplexity of the physics involved and the lack of accurate models of the\nclutter, planning and controlling precise predefined interactions with accurate\noutcome is extremely hard, when not impossible. In problems where accurate\n(forward) models are lacking, Deep Reinforcement Learning (RL) has shown to be\na viable solution to map observations (e.g. images) to good interactions in the\nform of close-loop visuomotor policies. However, Deep RL is sample inefficient\nand fails when applied directly to the problem of unoccluding objects based on\nimages. In this work we present a novel Deep RL procedure that combines i)\nteacher-aided exploration, ii) a critic with privileged information, and iii)\nmid-level representations, resulting in sample efficient and effective learning\nfor the problem of uncovering a target object occluded by a heap of unknown\nobjects. Our experiments show that our approach trains faster and converges to\nmore efficient uncovering solutions than baselines and ablations, and that our\nuncovering policies lead to an average improvement in the graspability of the\ntarget object, facilitating downstream retrieval applications.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 18:23:00 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Kurenkov", "Andrey", ""], ["Taglic", "Joseph", ""], ["Kulkarni", "Rohun", ""], ["Dominguez-Kuhne", "Marcus", ""], ["Garg", "Animesh", ""], ["Mart\u00edn-Mart\u00edn", "Roberto", ""], ["Savarese", "Silvio", ""]]}, {"id": "2008.06081", "submitter": "Jiameng Fan", "authors": "Jiameng Fan, Wenchao Li", "title": "Adversarial Training and Provable Robustness: A Tale of Two Objectives", "comments": "Accepted at AAAI 2021", "journal-ref": "Vol. 35 No. 8: AAAI-2021 Technical Tracks 8", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a principled framework that combines adversarial training and\nprovable robustness verification for training certifiably robust neural\nnetworks. We formulate the training problem as a joint optimization problem\nwith both empirical and provable robustness objectives and develop a novel\ngradient-descent technique that can eliminate bias in stochastic\nmulti-gradients. We perform both theoretical analysis on the convergence of the\nproposed technique and experimental comparison with state-of-the-arts. Results\non MNIST and CIFAR-10 show that our method can consistently match or outperform\nprior approaches for provable l infinity robustness. Notably, we achieve 6.60%\nverified test error on MNIST at epsilon = 0.3, and 66.57% on CIFAR-10 with\nepsilon = 8/255.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 18:49:15 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 15:56:34 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 18:07:53 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Fan", "Jiameng", ""], ["Li", "Wenchao", ""]]}, {"id": "2008.06082", "submitter": "Usman Khan", "authors": "Muhammad I. Qureshi and Ran Xin and Soummya Kar and Usman A. Khan", "title": "Push-SAGA: A decentralized stochastic algorithm with variance reduction\n  over directed graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Push-SAGA, a decentralized stochastic first-order\nmethod for finite-sum minimization over a directed network of nodes. Push-SAGA\ncombines node-level variance reduction to remove the uncertainty caused by\nstochastic gradients, network-level gradient tracking to address the\ndistributed nature of the data, and push-sum consensus to tackle the challenge\nof directed communication links. We show that Push-SAGA achieves linear\nconvergence to the exact solution for smooth and strongly convex problems and\nis thus the first linearly-convergent stochastic algorithm over arbitrary\nstrongly connected directed graphs. We also characterize the regimes in which\nPush-SAGA achieves a linear speed-up compared to its centralized counterpart\nand achieves a network-independent convergence rate. We illustrate the behavior\nand convergence properties of Push-SAGA with the help of numerical experiments\non strongly convex and non-convex problems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 18:52:17 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 20:46:52 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Qureshi", "Muhammad I.", ""], ["Xin", "Ran", ""], ["Kar", "Soummya", ""], ["Khan", "Usman A.", ""]]}, {"id": "2008.06101", "submitter": "Xiangyu Guo", "authors": "Xiangyu Guo, Janardhan Kulkarni, Shi Li, Jiayi Xian", "title": "Consistent $k$-Median: Simpler, Better and Robust", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce and study the online consistent $k$-clustering\nwith outliers problem, generalizing the non-outlier version of the problem\nstudied in [Lattanzi-Vassilvitskii, ICML17].\n  We show that a simple local-search based online algorithm can give a\nbicriteria constant approximation for the problem with $O(k^2 \\log^2 (nD))$\nswaps of medians (recourse) in total, where $D$ is the diameter of the metric.\nWhen restricted to the problem without outliers, our algorithm is simpler,\ndeterministic and gives better approximation ratio and recourse, compared to\nthat of [Lattanzi-Vassilvitskii, ICML17].\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 20:24:28 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Guo", "Xiangyu", ""], ["Kulkarni", "Janardhan", ""], ["Li", "Shi", ""], ["Xian", "Jiayi", ""]]}, {"id": "2008.06110", "submitter": "Brian Hartman", "authors": "Marie-Pier Cote, Brian Hartman, Olivier Mercier, Joshua Meyers, Jared\n  Cummings, Elijah Harmon", "title": "Synthesizing Property & Casualty Ratemaking Datasets using Generative\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to confidentiality issues, it can be difficult to access or share\ninteresting datasets for methodological development in actuarial science, or\nother fields where personal data are important. We show how to design three\ndifferent types of generative adversarial networks (GANs) that can build a\nsynthetic insurance dataset from a confidential original dataset. The goal is\nto obtain synthetic data that no longer contains sensitive information but\nstill has the same structure as the original dataset and retains the\nmultivariate relationships. In order to adequately model the specific\ncharacteristics of insurance data, we use GAN architectures adapted for\nmulti-categorical data: a Wassertein GAN with gradient penalty (MC-WGAN-GP), a\nconditional tabular GAN (CTGAN) and a Mixed Numerical and Categorical\nDifferentially Private GAN (MNCDP-GAN). For transparency, the approaches are\nillustrated using a public dataset, the French motor third party liability\ndata. We compare the three different GANs on various aspects: ability to\nreproduce the original data structure and predictive models, privacy, and ease\nof use. We find that the MC-WGAN-GP synthesizes the best data, the CTGAN is the\neasiest to use, and the MNCDP-GAN guarantees differential privacy.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 21:02:44 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Cote", "Marie-Pier", ""], ["Hartman", "Brian", ""], ["Mercier", "Olivier", ""], ["Meyers", "Joshua", ""], ["Cummings", "Jared", ""], ["Harmon", "Elijah", ""]]}, {"id": "2008.06120", "submitter": "Gabriel Bender", "authors": "Gabriel Bender, Hanxiao Liu, Bo Chen, Grace Chu, Shuyang Cheng,\n  Pieter-Jan Kindermans, Quoc Le", "title": "Can weight sharing outperform random architecture search? An\n  investigation with TuNAS", "comments": "Published at CVPR 2020", "journal-ref": "Proceedings of the IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition (CVPR), 2020, pp. 14323-14332", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient Neural Architecture Search methods based on weight sharing have\nshown good promise in democratizing Neural Architecture Search for computer\nvision models. There is, however, an ongoing debate whether these efficient\nmethods are significantly better than random search. Here we perform a thorough\ncomparison between efficient and random search methods on a family of\nprogressively larger and more challenging search spaces for image\nclassification and detection on ImageNet and COCO. While the efficacies of both\nmethods are problem-dependent, our experiments demonstrate that there are\nlarge, realistic tasks where efficient search methods can provide substantial\ngains over random search. In addition, we propose and evaluate techniques which\nimprove the quality of searched architectures and reduce the need for manual\nhyper-parameter tuning.\n  Source code and experiment data are available at\nhttps://github.com/google-research/google-research/tree/master/tunas\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 21:32:40 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Bender", "Gabriel", ""], ["Liu", "Hanxiao", ""], ["Chen", "Bo", ""], ["Chu", "Grace", ""], ["Cheng", "Shuyang", ""], ["Kindermans", "Pieter-Jan", ""], ["Le", "Quoc", ""]]}, {"id": "2008.06121", "submitter": "Guanlong Zhao", "authors": "Arindrima Datta, Guanlong Zhao, Bhuvana Ramabhadran, Eugene Weinstein", "title": "LSTM Acoustic Models Learn to Align and Pronounce with Graphemes", "comments": "5 pages, 4 figures. This work was done between summer 2018 and spring\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automated speech recognition coverage of the world's languages continues to\nexpand. However, standard phoneme based systems require handcrafted lexicons\nthat are difficult and expensive to obtain. To address this problem, we propose\na training methodology for a grapheme-based speech recognizer that can be\ntrained in a purely data-driven fashion. Built with LSTM networks and trained\nwith the cross-entropy loss, the grapheme-output acoustic models we study are\nalso extremely practical for real-world applications as they can be decoded\nwith conventional ASR stack components such as language models and FST\ndecoders, and produce good quality audio-to-grapheme alignments that are useful\nin many speech applications. We show that the grapheme models are competitive\nin WER with their phoneme-output counterparts when trained on large datasets,\nwith the advantage that grapheme models do not require explicit linguistic\nknowledge as an input. We further compare the alignments generated by the\nphoneme and grapheme models to demonstrate the quality of the pronunciations\nlearnt by them using four Indian languages that vary linguistically in spoken\nand written forms.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 21:38:36 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Datta", "Arindrima", ""], ["Zhao", "Guanlong", ""], ["Ramabhadran", "Bhuvana", ""], ["Weinstein", "Eugene", ""]]}, {"id": "2008.06135", "submitter": "Hongmei He Ph.D", "authors": "Hongmei He, Mengyuan Chen, Gang Xu, Zhilong Zhu, Zhenhuan Zhu", "title": "Learnability and Robustness of Shallow Neural Networks Learned With a\n  Performance-Driven BP and a Variant PSO For Edge Decision-Making", "comments": "36 pages, 21 figues for corresponding eps files. Neural Comput &\n  Applic (2021)", "journal-ref": null, "doi": "10.1007/s00521-021-06019-1", "report-no": null, "categories": "cs.NE cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many cases, the computing resources are limited without the benefit from\nGPU, especially in the edge devices of IoT enabled systems. It may not be easy\nto implement complex AI models in edge devices. The Universal Approximation\nTheorem states that a shallow neural network (SNN) can represent any nonlinear\nfunction. However, how fat is an SNN enough to solve a nonlinear\ndecision-making problem in edge devices? In this paper, we focus on the\nlearnability and robustness of SNNs, obtained by a greedy tight force heuristic\nalgorithm (performance driven BP) and a loose force meta-heuristic algorithm (a\nvariant of PSO). Two groups of experiments are conducted to examine the\nlearnability and the robustness of SNNs with Sigmoid activation,\nlearned/optimised by KPI-PDBPs and KPI-VPSOs, where, KPIs (key performance\nindicators: error (ERR), accuracy (ACC) and $F_1$ score) are the objectives,\ndriving the searching process. An incremental approach is applied to examine\nthe impact of hidden neuron numbers on the performance of SNNs,\nlearned/optimised by KPI-PDBPs and KPI-VPSOs. From the engineering prospective,\nall sensors are well justified for a specific task. Hence, all sensor readings\nshould be strongly correlated to the target. Therefore, the structure of an SNN\nshould depend on the dimensions of a problem space. The experimental results\nshow that the number of hidden neurons up to the dimension number of a problem\nspace is enough; the learnability of SNNs, produced by KPI-PDBP, is better than\nthat of SNNs, optimized by KPI-VPSO, regarding the performance and learning\ntime on the training data sets; the robustness of SNNs learned by KPI-PDBPs and\nKPI-VPSOs depends on the data sets; and comparing with other classic machine\nlearning models, ACC-PDBPs win for almost all tested data sets.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 23:33:00 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["He", "Hongmei", ""], ["Chen", "Mengyuan", ""], ["Xu", "Gang", ""], ["Zhu", "Zhilong", ""], ["Zhu", "Zhenhuan", ""]]}, {"id": "2008.06141", "submitter": "Trevor Avant", "authors": "Trevor Avant, Kristi A. Morgansen", "title": "Analytical bounds on the local Lipschitz constants of affine-ReLU\n  functions", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we determine analytical bounds on the local Lipschitz\nconstants of of affine functions composed with rectified linear units (ReLUs).\nAffine-ReLU functions represent a widely used layer in deep neural networks,\ndue to the fact that convolution, fully-connected, and normalization functions\nare all affine, and are often followed by a ReLU activation function. Using an\nanalytical approach, we mathematically determine upper bounds on the local\nLipschitz constant of an affine-ReLU function, show how these bounds can be\ncombined to determine a bound on an entire network, and discuss how the bounds\ncan be efficiently computed, even for larger layers and networks. We show\nseveral examples by applying our results to AlexNet, as well as several smaller\nnetworks based on the MNIST and CIFAR-10 datasets. The results show that our\nmethod produces tighter bounds than the standard conservative bound (i.e. the\nproduct of the spectral norms of the layers' linear matrices), especially for\nsmall perturbations.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 00:23:21 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Avant", "Trevor", ""], ["Morgansen", "Kristi A.", ""]]}, {"id": "2008.06148", "submitter": "Jeffrey Zhang", "authors": "Amir Ali Ahmadi, Jeffrey Zhang", "title": "Complexity aspects of local minima and related notions", "comments": "41 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the notions of (i) critical points, (ii) second-order points,\n(iii) local minima, and (iv) strict local minima for multivariate polynomials.\nFor each type of point, and as a function of the degree of the polynomial, we\nstudy the complexity of deciding (1) if a given point is of that type, and (2)\nif a polynomial has a point of that type. Our results characterize the\ncomplexity of these two questions for all degrees left open by prior\nliterature. Our main contributions reveal that many of these questions turn out\nto be tractable for cubic polynomials. In particular, we present an\nefficiently-checkable necessary and sufficient condition for local minimality\nof a point for a cubic polynomial. We also show that a local minimum of a cubic\npolynomial can be efficiently found by solving semidefinite programs of size\nlinear in the number of variables. By contrast, we show that it is strongly\nNP-hard to decide if a cubic polynomial has a critical point. We also prove\nthat the set of second-order points of any cubic polynomial is a spectrahedron,\nand conversely that any spectrahedron is the projection of the set of\nsecond-order points of a cubic polynomial. In our final section, we briefly\npresent a potential application of finding local minima of cubic polynomials to\nthe design of a third-order Newton method.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 00:50:13 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 22:05:57 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Ahmadi", "Amir Ali", ""], ["Zhang", "Jeffrey", ""]]}, {"id": "2008.06151", "submitter": "Emanuel Azcona", "authors": "Emanuel A. Azcona, Pierre Besson, Yunan Wu, Arjun Punjabi, Adam\n  Martersteck, Amil Dravid, Todd B. Parrish, S. Kathleen Bandt, Aggelos K.\n  Katsaggelos", "title": "Interpretation of Brain Morphology in Association to Alzheimer's Disease\n  Dementia Classification Using Graph Convolutional Networks on Triangulated\n  Meshes", "comments": "Accepted for the Shape in Medical Imaging (ShapeMI) workshop at\n  MICCAI International Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG math.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a mesh-based technique to aid in the classification of Alzheimer's\ndisease dementia (ADD) using mesh representations of the cortex and subcortical\nstructures. Deep learning methods for classification tasks that utilize\nstructural neuroimaging often require extensive learning parameters to\noptimize. Frequently, these approaches for automated medical diagnosis also\nlack visual interpretability for areas in the brain involved in making a\ndiagnosis. This work: (a) analyzes brain shape using surface information of the\ncortex and subcortical structures, (b) proposes a residual learning framework\nfor state-of-the-art graph convolutional networks which offer a significant\nreduction in learnable parameters, and (c) offers visual interpretability of\nthe network via class-specific gradient information that localizes important\nregions of interest in our inputs. With our proposed method leveraging the use\nof cortical and subcortical surface information, we outperform other machine\nlearning methods with a 96.35% testing accuracy for the ADD vs. healthy control\nproblem. We confirm the validity of our model by observing its performance in a\n25-trial Monte Carlo cross-validation. The generated visualization maps in our\nstudy show correspondences with current knowledge regarding the structural\nlocalization of pathological changes in the brain associated to dementia of the\nAlzheimer's type.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 01:10:39 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 23:59:56 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2020 06:58:20 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Azcona", "Emanuel A.", ""], ["Besson", "Pierre", ""], ["Wu", "Yunan", ""], ["Punjabi", "Arjun", ""], ["Martersteck", "Adam", ""], ["Dravid", "Amil", ""], ["Parrish", "Todd B.", ""], ["Bandt", "S. Kathleen", ""], ["Katsaggelos", "Aggelos K.", ""]]}, {"id": "2008.06164", "submitter": "Rihuan Ke", "authors": "Rihuan Ke and Carola-Bibiane Sch\\\"onlieb", "title": "Unsupervised Image Restoration Using Partially Linear Denoisers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network based methods are the state of the art in various image\nrestoration problems. Standard supervised learning frameworks require a set of\nnoisy measurement and clean image pairs for which a distance between the output\nof the restoration model and the ground truth, clean images is minimized. The\nground truth images, however, are often unavailable or very expensive to\nacquire in real-world applications. We circumvent this problem by proposing a\nclass of structured denoisers that can be decomposed as the sum of a nonlinear\nimage-dependent mapping, a linear noise-dependent term and a small residual\nterm. We show that these denoisers can be trained with only noisy images under\nthe condition that the noise has zero mean and known variance. The exact\ndistribution of the noise, however, is not assumed to be known. We show the\nsuperiority of our approach for image denoising, and demonstrate its extension\nto solving other restoration problems such as blind deblurring where the ground\ntruth is not available. Our method outperforms some recent unsupervised and\nself-supervised deep denoising models that do not require clean images for\ntheir training. For blind deblurring problems, the method, using only one noisy\nand blurry observation per image, reaches a quality not far away from its fully\nsupervised counterparts on a benchmark dataset.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 02:13:19 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 13:56:06 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Ke", "Rihuan", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""]]}, {"id": "2008.06170", "submitter": "Yuncheng Wu", "authors": "Yuncheng Wu, Shaofeng Cai, Xiaokui Xiao, Gang Chen, Beng Chin Ooi", "title": "Privacy Preserving Vertical Federated Learning for Tree-based Models", "comments": "Proc. VLDB Endow. 13(11): 2090-2103 (2020)", "journal-ref": null, "doi": "10.14778/3407790.3407811", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is an emerging paradigm that enables multiple\norganizations to jointly train a model without revealing their private data to\neach other. This paper studies {\\it vertical} federated learning, which tackles\nthe scenarios where (i) collaborating organizations own data of the same set of\nusers but with disjoint features, and (ii) only one organization holds the\nlabels. We propose Pivot, a novel solution for privacy preserving vertical\ndecision tree training and prediction, ensuring that no intermediate\ninformation is disclosed other than those the clients have agreed to release\n(i.e., the final tree model and the prediction output). Pivot does not rely on\nany trusted third party and provides protection against a semi-honest adversary\nthat may compromise $m-1$ out of $m$ clients. We further identify two privacy\nleakages when the trained decision tree model is released in plaintext and\npropose an enhanced protocol to mitigate them. The proposed solution can also\nbe extended to tree ensemble models, e.g., random forest (RF) and gradient\nboosting decision tree (GBDT) by treating single decision trees as building\nblocks. Theoretical and experimental analysis suggest that Pivot is efficient\nfor the privacy achieved.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 02:32:36 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Wu", "Yuncheng", ""], ["Cai", "Shaofeng", ""], ["Xiao", "Xiaokui", ""], ["Chen", "Gang", ""], ["Ooi", "Beng Chin", ""]]}, {"id": "2008.06180", "submitter": "Sohei Itahara", "authors": "Sohei Itahara, Takayuki Nishio, Yusuke Koda, Masahiro Morikura and\n  Koji Yamamoto", "title": "Distillation-Based Semi-Supervised Federated Learning for\n  Communication-Efficient Collaborative Training with Non-IID Private Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study develops a federated learning (FL) framework overcoming largely\nincremental communication costs due to model sizes in typical frameworks\nwithout compromising model performance. To this end, based on the idea of\nleveraging an unlabeled open dataset, we propose a distillation-based\nsemi-supervised FL (DS-FL) algorithm that exchanges the outputs of local models\namong mobile devices, instead of model parameter exchange employed by the\ntypical frameworks. In DS-FL, the communication cost depends only on the output\ndimensions of the models and does not scale up according to the model size. The\nexchanged model outputs are used to label each sample of the open dataset,\nwhich creates an additionally labeled dataset. Based on the new dataset, local\nmodels are further trained, and model performance is enhanced owing to the data\naugmentation effect. We further highlight that in DS-FL, the heterogeneity of\nthe devices' dataset leads to ambiguous of each data sample and lowing of the\ntraining convergence. To prevent this, we propose entropy reduction averaging,\nwhere the aggregated model outputs are intentionally sharpened. Moreover,\nextensive experiments show that DS-FL reduces communication costs up to 99%\nrelative to those of the FL benchmark while achieving similar or higher\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 03:47:27 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 08:35:43 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Itahara", "Sohei", ""], ["Nishio", "Takayuki", ""], ["Koda", "Yusuke", ""], ["Morikura", "Masahiro", ""], ["Yamamoto", "Koji", ""]]}, {"id": "2008.06187", "submitter": "Juan Liu", "authors": "Juan Liu and Kevin M Koch", "title": "Weakly-supervised Learning for Single-step Quantitative Susceptibility\n  Mapping", "comments": "Accepted by MICCAI Workshop MLMIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Quantitative susceptibility mapping (QSM) utilizes MRI phase information to\nestimate tissue magnetic susceptibility. The generation of QSM requires solving\nill-posed background field removal (BFR) and field-to-source inversion\nproblems. Because current QSM techniques struggle to generate reliable QSM in\nclinical contexts, QSM clinical translation is greatly hindered. Recently, deep\nlearning (DL) approaches for QSM reconstruction have shown impressive\nperformance. Due to inherent non-existent ground-truth, these DL techniques use\neither calculation of susceptibility through multiple orientation sampling\n(COSMOS) maps or synthetic data for training, which are constrained by the\navailability and accuracy of COSMOS maps or domain shift when training data and\ntesting data have different domains. To address these limitations, we propose a\nweakly-supervised single-step QSM reconstruction method, denoted as wTFI, to\ndirectly reconstruct QSM from the total field without BFR. wTFI uses the BFR\nmethod RESHARP local fields as supervision to perform a multi-task learning of\nlocal tissue fields and QSM, and is capable of recovering magnetic\nsusceptibility estimates near the edges of the brain where are eroded in\nRESHARP and realize whole brain QSM estimation. Quantitative and qualitative\nevaluation shows that wTFI can generate high-quality local field and\nsusceptibility maps in a variety of neuroimaging contexts.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 04:28:08 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Liu", "Juan", ""], ["Koch", "Kevin M", ""]]}, {"id": "2008.06189", "submitter": "Syed Ali Hassan", "authors": "Syed Ali Hassan, Tariq Rahim, Soo Young Shin", "title": "An Improved Deep Convolutional Neural Network-Based Autonomous Road\n  Inspection Scheme Using Unmanned Aerial Vehicles", "comments": "10 pages, 11 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancements in artificial intelligence (AI) gives a great opportunity to\ndevelop an autonomous devices. The contribution of this work is an improved\nconvolutional neural network (CNN) model and its implementation for the\ndetection of road cracks, potholes, and yellow lane in the road. The purpose of\nyellow lane detection and tracking is to realize autonomous navigation of\nunmanned aerial vehicle (UAV) by following yellow lane while detecting and\nreporting the road cracks and potholes to the server through WIFI or 5G medium.\nThe fabrication of own data set is a hectic and time-consuming task. The data\nset is created, labeled and trained using default and an improved model. The\nperformance of both these models is benchmarked with respect to accuracy, mean\naverage precision (mAP) and detection time. In the testing phase, it was\nobserved that the performance of the improved model is better in respect of\naccuracy and mAP. The improved model is implemented in UAV using the robot\noperating system for the autonomous detection of potholes and cracks in roads\nvia UAV front camera vision in real-time.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 04:35:10 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Hassan", "Syed Ali", ""], ["Rahim", "Tariq", ""], ["Shin", "Soo Young", ""]]}, {"id": "2008.06197", "submitter": "Bin Gu", "authors": "Bin Gu, Zhiyuan Dang, Xiang Li, Heng Huang", "title": "Federated Doubly Stochastic Kernel Learning for Vertically Partitioned\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a lot of real-world data mining and machine learning applications, data\nare provided by multiple providers and each maintains private records of\ndifferent feature sets about common entities. It is challenging to train these\nvertically partitioned data effectively and efficiently while keeping data\nprivacy for traditional data mining and machine learning algorithms. In this\npaper, we focus on nonlinear learning with kernels, and propose a federated\ndoubly stochastic kernel learning (FDSKL) algorithm for vertically partitioned\ndata. Specifically, we use random features to approximate the kernel mapping\nfunction and use doubly stochastic gradients to update the solutions, which are\nall computed federatedly without the disclosure of data. Importantly, we prove\nthat FDSKL has a sublinear convergence rate, and can guarantee the data\nsecurity under the semi-honest assumption. Extensive experimental results on a\nvariety of benchmark datasets show that FDSKL is significantly faster than\nstate-of-the-art federated learning methods when dealing with kernels, while\nretaining the similar generalization performance.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 05:46:56 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Gu", "Bin", ""], ["Dang", "Zhiyuan", ""], ["Li", "Xiang", ""], ["Huang", "Heng", ""]]}, {"id": "2008.06199", "submitter": "Xinghua Qu", "authors": "Xinghua Qu, Yew-Soon Ong, Abhishek Gupta, Zhu Sun", "title": "Adversary Agnostic Robust Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) policies have been shown to be deceived by\nperturbations (e.g., random noise or intensional adversarial attacks) on state\nobservations that appear at test time but are unknown during training. To\nincrease the robustness of DRL policies, previous approaches assume that the\nknowledge of adversaries can be added into the training process to achieve the\ncorresponding generalization ability on these perturbed observations. However,\nsuch an assumption not only makes the robustness improvement more expensive but\nmay also leave a model less effective to other kinds of attacks in the wild. In\ncontrast, we propose an adversary agnostic robust DRL paradigm that does not\nrequire learning from adversaries. To this end, we first theoretically derive\nthat robustness could indeed be achieved independently of the adversaries based\non a policy distillation setting. Motivated by this finding, we propose a new\npolicy distillation loss with two terms: 1) a prescription gap maximization\nloss aiming at simultaneously maximizing the likelihood of the action selected\nby the teacher policy and the entropy over the remaining actions; 2) a\ncorresponding Jacobian regularization loss that minimizes the magnitude of the\ngradient with respect to the input state. The theoretical analysis shows that\nour distillation loss guarantees to increase the prescription gap and the\nadversarial robustness. Furthermore, experiments on five Atari games firmly\nverify the superiority of our approach in terms of boosting adversarial\nrobustness compared to other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 06:04:15 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 06:38:19 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Qu", "Xinghua", ""], ["Ong", "Yew-Soon", ""], ["Gupta", "Abhishek", ""], ["Sun", "Zhu", ""]]}, {"id": "2008.06217", "submitter": "Lixu Wang", "authors": "Lixu Wang, Shichao Xu, Xiao Wang, Qi Zhu", "title": "Addressing Class Imbalance in Federated Learning", "comments": "17 pages, Accept by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a promising approach for training decentralized\ndata located on local client devices while improving efficiency and privacy.\nHowever, the distribution and quantity of the training data on the clients'\nside may lead to significant challenges such as class imbalance and non-IID\n(non-independent and identically distributed) data, which could greatly impact\nthe performance of the common model. While much effort has been devoted to\nhelping FL models converge when encountering non-IID data, the imbalance issue\nhas not been sufficiently addressed. In particular, as FL training is executed\nby exchanging gradients in an encrypted form, the training data is not\ncompletely observable to either clients or servers, and previous methods for\nclass imbalance do not perform well for FL. Therefore, it is crucial to design\nnew methods for detecting class imbalance in FL and mitigating its impact. In\nthis work, we propose a monitoring scheme that can infer the composition of\ntraining data for each FL round, and design a new loss function --\n\\textbf{Ratio Loss} to mitigate the impact of the imbalance. Our experiments\ndemonstrate the importance of acknowledging class imbalance and taking measures\nas early as possible in FL training, and the effectiveness of our method in\nmitigating the impact. Our method is shown to significantly outperform previous\nmethods, while maintaining client privacy.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 07:28:08 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 01:56:21 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Wang", "Lixu", ""], ["Xu", "Shichao", ""], ["Wang", "Xiao", ""], ["Zhu", "Qi", ""]]}, {"id": "2008.06218", "submitter": "Wonyoung Shin", "authors": "Wonyoung Shin, Jung-Woo Ha, Shengzhe Li, Yongwoo Cho, Hoyean Song,\n  Sunyoung Kwon", "title": "Which Strategies Matter for Noisy Label Classification? Insight into\n  Loss and Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Label noise is a critical factor that degrades the generalization performance\nof deep neural networks, thus leading to severe issues in real-world problems.\nExisting studies have employed strategies based on either loss or uncertainty\nto address noisy labels, and ironically some strategies contradict each other:\nemphasizing or discarding uncertain samples or concentrating on high or low\nloss samples. To elucidate how opposing strategies can enhance model\nperformance and offer insights into training with noisy labels, we present\nanalytical results on how loss and uncertainty values of samples change\nthroughout the training process. From the in-depth analysis, we design a new\nrobust training method that emphasizes clean and informative samples, while\nminimizing the influence of noise using both loss and uncertainty. We\ndemonstrate the effectiveness of our method with extensive experiments on\nsynthetic and real-world datasets for various deep learning models. The results\nshow that our method significantly outperforms other state-of-the-art methods\nand can be used generally regardless of neural network architectures.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 07:34:32 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Shin", "Wonyoung", ""], ["Ha", "Jung-Woo", ""], ["Li", "Shengzhe", ""], ["Cho", "Yongwoo", ""], ["Song", "Hoyean", ""], ["Kwon", "Sunyoung", ""]]}, {"id": "2008.06220", "submitter": "Abhimanyu Dubey", "authors": "Abhimanyu Dubey and Alex Pentland", "title": "Kernel Methods for Cooperative Multi-Agent Contextual Bandits", "comments": "19 pages including supplement, camera-ready at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative multi-agent decision making involves a group of agents\ncooperatively solving learning problems while communicating over a network with\ndelays. In this paper, we consider the kernelised contextual bandit problem,\nwhere the reward obtained by an agent is an arbitrary linear function of the\ncontexts' images in the related reproducing kernel Hilbert space (RKHS), and a\ngroup of agents must cooperate to collectively solve their unique decision\nproblems. For this problem, we propose \\textsc{Coop-KernelUCB}, an algorithm\nthat provides near-optimal bounds on the per-agent regret, and is both\ncomputationally and communicatively efficient. For special cases of the\ncooperative problem, we also provide variants of \\textsc{Coop-KernelUCB} that\nprovides optimal per-agent regret. In addition, our algorithm generalizes\nseveral existing results in the multi-agent bandit setting. Finally, on a\nseries of both synthetic and real-world multi-agent network benchmarks, we\ndemonstrate that our algorithm significantly outperforms existing benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 07:37:44 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Dubey", "Abhimanyu", ""], ["Pentland", "Alex", ""]]}, {"id": "2008.06225", "submitter": "Jie Fang", "authors": "Jie Fang, Jianwu Lin, Shutao Xia, Yong Jiang, Zhikang Xia, Xiang Liu", "title": "Neural Network-based Automatic Factor Construction", "comments": "Accepted by the Journal, Quantitative Finance. 21 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instead of conducting manual factor construction based on traditional and\nbehavioural finance analysis, academic researchers and quantitative investment\nmanagers have leveraged Genetic Programming (GP) as an automatic feature\nconstruction tool in recent years, which builds reverse polish mathematical\nexpressions from trading data into new factors. However, with the development\nof deep learning, more powerful feature extraction tools are available. This\npaper proposes Neural Network-based Automatic Factor Construction (NNAFC), a\ntailored neural network framework that can automatically construct diversified\nfinancial factors based on financial domain knowledge and a variety of neural\nnetwork structures. The experiment results show that NNAFC can construct more\ninformative and diversified factors than GP, to effectively enrich the current\nfactor pool. For the current market, both fully connected and recurrent neural\nnetwork structures are better at extracting information from financial time\nseries than convolution neural network structures. Moreover, new factors\nconstructed by NNAFC can always improve the return, Sharpe ratio, and the max\ndraw-down of a multi-factor quantitative investment strategy due to their\nintroducing more information and diversification to the existing factor pool.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 07:44:49 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 16:20:53 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 16:20:18 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Fang", "Jie", ""], ["Lin", "Jianwu", ""], ["Xia", "Shutao", ""], ["Jiang", "Yong", ""], ["Xia", "Zhikang", ""], ["Liu", "Xiang", ""]]}, {"id": "2008.06233", "submitter": "Bin Gu", "authors": "Bin Gu, An Xu, Zhouyuan Huo, Cheng Deng, Heng Huang", "title": "Privacy-Preserving Asynchronous Federated Learning Algorithms for\n  Multi-Party Vertically Collaborative Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The privacy-preserving federated learning for vertically partitioned data has\nshown promising results as the solution of the emerging multi-party joint\nmodeling application, in which the data holders (such as government branches,\nprivate finance and e-business companies) collaborate throughout the learning\nprocess rather than relying on a trusted third party to hold data. However,\nexisting federated learning algorithms for vertically partitioned data are\nlimited to synchronous computation. To improve the efficiency when the\nunbalanced computation/communication resources are common among the parties in\nthe federated learning system, it is essential to develop asynchronous training\nalgorithms for vertically partitioned data while keeping the data privacy. In\nthis paper, we propose an asynchronous federated SGD (AFSGD-VP) algorithm and\nits SVRG and SAGA variants on the vertically partitioned data. Moreover, we\nprovide the convergence analyses of AFSGD-VP and its SVRG and SAGA variants\nunder the condition of strong convexity. We also discuss their model privacy,\ndata privacy, computational complexities and communication costs. To the best\nof our knowledge, AFSGD-VP and its SVRG and SAGA variants are the first\nasynchronous federated learning algorithms for vertically partitioned data.\nExtensive experimental results on a variety of vertically partitioned datasets\nnot only verify the theoretical results of AFSGD-VP and its SVRG and SAGA\nvariants, but also show that our algorithms have much higher efficiency than\nthe corresponding synchronous algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 08:08:15 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Gu", "Bin", ""], ["Xu", "An", ""], ["Huo", "Zhouyuan", ""], ["Deng", "Cheng", ""], ["Huang", "Heng", ""]]}, {"id": "2008.06239", "submitter": "Andrea Madotto Mr", "authors": "Andrea Madotto, Zihan Liu, Zhaojiang Lin, Pascale Fung", "title": "Language Models as Few-Shot Learner for Task-Oriented Dialogue Systems", "comments": "Blog (https://andreamad8.github.io/few-shot-gpt/), Medium\n  (https://medium.com/@madottoandrea/language-model-as-few-shot-learner-for-task-oriented-dialogue-systems-db4765796744)\n  and Code (https://github.com/andreamad8/TASK-ORIENTED-LM-FEWSHOT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-oriented dialogue systems use four connected modules, namely, Natural\nLanguage Understanding (NLU), a Dialogue State Tracking (DST), Dialogue Policy\n(DP) and Natural Language Generation (NLG). A research challenge is to learn\neach module with the least amount of samples (i.e., few-shots) given the high\ncost related to the data collection. The most common and effective technique to\nsolve this problem is transfer learning, where large language models, either\npre-trained on text or task-specific data, are fine-tuned on the few samples.\nThese methods require fine-tuning steps and a set of parameters for each task.\nDifferently, language models, such as GPT-2 (Radford et al., 2019) and GPT-3\n(Brown et al., 2020), allow few-shot learning by priming the model with few\nexamples. In this paper, we evaluate the priming few-shot ability of language\nmodels in the NLU, DST, DP and NLG tasks. Importantly, we highlight the current\nlimitations of this approach, and we discuss the possible implication for\nfuture work.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 08:23:21 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 10:56:47 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Madotto", "Andrea", ""], ["Liu", "Zihan", ""], ["Lin", "Zhaojiang", ""], ["Fung", "Pascale", ""]]}, {"id": "2008.06242", "submitter": "Mingsheng Long", "authors": "Yuchen Zhang, Mingsheng Long, Jianmin Wang, Michael I. Jordan", "title": "On Localized Discrepancy for Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the discrepancy-based generalization theories for unsupervised\ndomain adaptation. Previous theories introduced distribution discrepancies\ndefined as the supremum over complete hypothesis space. The hypothesis space\nmay contain hypotheses that lead to unnecessary overestimation of the risk\nbound. This paper studies the localized discrepancies defined on the hypothesis\nspace after localization. First, we show that these discrepancies have\ndesirable properties. They could be significantly smaller than the pervious\ndiscrepancies. Their values will be different if we exchange the two domains,\nthus can reveal asymmetric transfer difficulties. Next, we derive improved\ngeneralization bounds with these discrepancies. We show that the discrepancies\ncould influence the rate of the sample complexity. Finally, we further extend\nthe localized discrepancies for achieving super transfer and derive\ngeneralization bounds that could be even more sample-efficient on source\ndomain.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 08:30:02 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Zhang", "Yuchen", ""], ["Long", "Mingsheng", ""], ["Wang", "Jianmin", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2008.06244", "submitter": "Abhimanyu Dubey", "authors": "Abhimanyu Dubey and Alex Pentland", "title": "Cooperative Multi-Agent Bandits with Heavy Tails", "comments": "26 pages including appendix, camera-ready for ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the heavy-tailed stochastic bandit problem in the cooperative\nmulti-agent setting, where a group of agents interact with a common bandit\nproblem, while communicating on a network with delays. Existing algorithms for\nthe stochastic bandit in this setting utilize confidence intervals arising from\nan averaging-based communication protocol known as~\\textit{running consensus},\nthat does not lend itself to robust estimation for heavy-tailed settings. We\npropose \\textsc{MP-UCB}, a decentralized multi-agent algorithm for the\ncooperative stochastic bandit that incorporates robust estimation with a\nmessage-passing protocol. We prove optimal regret bounds for \\textsc{MP-UCB}\nfor several problem settings, and also demonstrate its superiority to existing\nmethods. Furthermore, we establish the first lower bounds for the cooperative\nbandit problem, in addition to providing efficient algorithms for robust bandit\nestimation of location.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 08:34:32 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Dubey", "Abhimanyu", ""], ["Pentland", "Alex", ""]]}, {"id": "2008.06246", "submitter": "Chaojie Ji", "authors": "Chaojie Ji, Yijia Zheng, Ruxin Wang, Yunpeng Cai and Hongyan Wu", "title": "Graph Polish: A Novel Graph Generation Paradigm for Molecular\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular optimization, which transforms a given input molecule X into\nanother Y with desirable properties, is essential in molecular drug discovery.\nThe traditional translating approaches, generating the molecular graphs from\nscratch by adding some substructures piece by piece, prone to error because of\nthe large set of candidate substructures in a large number of steps to the\nfinal target. In this study, we present a novel molecular optimization\nparadigm, Graph Polish, which changes molecular optimization from the\ntraditional \"two-language translating\" task into a \"single-language polishing\"\ntask. The key to this optimization paradigm is to find an optimization center\nsubject to the conditions that the preserved areas around it ought to be\nmaximized and thereafter the removed and added regions should be minimized. We\nthen propose an effective and efficient learning framework T&S polish to\ncapture the long-term dependencies in the optimization steps. The T component\nautomatically identifies and annotates the optimization centers and the\npreservation, removal and addition of some parts of the molecule, and the S\ncomponent learns these behaviors and applies these actions to a new molecule.\nFurthermore, the proposed paradigm can offer an intuitive interpretation for\neach molecular optimization result. Experiments with multiple optimization\ntasks are conducted on four benchmark datasets. The proposed T&S polish\napproach achieves significant advantage over the five state-of-the-art baseline\nmethods on all the tasks. In addition, extensive studies are conducted to\nvalidate the effectiveness, explainability and time saving of the novel\noptimization paradigm.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 08:36:13 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Ji", "Chaojie", ""], ["Zheng", "Yijia", ""], ["Wang", "Ruxin", ""], ["Cai", "Yunpeng", ""], ["Wu", "Hongyan", ""]]}, {"id": "2008.06273", "submitter": "Katharina Prinz", "authors": "Katharina Prinz, Arthur Flexer and Gerhard Widmer", "title": "The Impact of Label Noise on a Music Tagger", "comments": "In Proceedings of the 13th International Workshop on Machine Learning\n  and Music, European Conference on Machine Learning and Principles and\n  Practice of Knowledge Discovery in Databases", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore how much can be learned from noisy labels in audio music tagging.\nOur experiments show that carefully annotated labels result in highest figures\nof merit, but even high amounts of noisy labels contain enough information for\nsuccessful learning. Artificial corruption of curated data allows us to\nquantize this contribution of noisy labels.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 10:00:30 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Prinz", "Katharina", ""], ["Flexer", "Arthur", ""], ["Widmer", "Gerhard", ""]]}, {"id": "2008.06274", "submitter": "Shantanu Chandra", "authors": "Shantanu Chandra, Pushkar Mishra, Helen Yannakoudakis, Madhav\n  Nimishakavi, Marzieh Saeidi, Ekaterina Shutova", "title": "Graph-based Modeling of Online Communities for Fake News Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, there has been a substantial effort towards\nautomated detection of fake news on social media platforms. Existing research\nhas modeled the structure, style, content, and patterns in dissemination of\nonline posts, as well as the demographic traits of users who interact with\nthem. However, no attention has been directed towards modeling the properties\nof online communities that interact with the posts. In this work, we propose a\nnovel social context-aware fake news detection framework, SAFER, based on graph\nneural networks (GNNs). The proposed framework aggregates information with\nrespect to: 1) the nature of the content disseminated, 2) content-sharing\nbehavior of users, and 3) the social network of those users. We furthermore\nperform a systematic comparison of several GNN models for this task and\nintroduce novel methods based on relational and hyperbolic GNNs, which have not\nbeen previously used for user or community modeling within NLP. We empirically\ndemonstrate that our framework yields significant improvements over existing\ntext-based techniques and achieves state-of-the-art results on fake news\ndatasets from two different domains.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 10:01:34 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 14:02:47 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 16:04:41 GMT"}, {"version": "v4", "created": "Mon, 23 Nov 2020 15:07:48 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Chandra", "Shantanu", ""], ["Mishra", "Pushkar", ""], ["Yannakoudakis", "Helen", ""], ["Nimishakavi", "Madhav", ""], ["Saeidi", "Marzieh", ""], ["Shutova", "Ekaterina", ""]]}, {"id": "2008.06285", "submitter": "Zichen Zhu", "authors": "Shenyu Zhang, Zichen Zhu, Qingquan Bao", "title": "Rb-PaStaNet: A Few-Shot Human-Object Interaction Detection Based on\n  Rules and Part States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Existing Human-Object Interaction (HOI) Detection approaches have achieved\ngreat progress on nonrare classes while rare HOI classes are still not\nwell-detected. In this paper, we intend to apply human prior knowledge into the\nexisting work. So we add human-labeled rules to PaStaNet and propose\nRb-PaStaNet aimed at improving rare HOI classes detection. Our results show a\ncertain improvement of the rare classes, while the non-rare classes and the\noverall improvement is more considerable.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 10:32:15 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Zhang", "Shenyu", ""], ["Zhu", "Zichen", ""], ["Bao", "Qingquan", ""]]}, {"id": "2008.06293", "submitter": "Dmitri Goldenberg", "authors": "Dmitri Goldenberg, Javier Albert, Lucas Bernardi and Pablo Estevez", "title": "Free Lunch! Retrospective Uplift Modeling for Dynamic Promotions\n  Recommendation within ROI Constraints", "comments": "Accepted to Fourteenth ACM Conference on Recommender Systems, Brazil,\n  September, 2020", "journal-ref": "2020. In Fourteenth ACM Conference on Recommender Systems (RecSys\n  '20). Association for Computing Machinery, New York, NY, USA, 486-491", "doi": "10.1145/3383313.3412215", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Promotions and discounts have become key components of modern e-commerce\nplatforms. For online travel platforms (OTPs), popular promotions include room\nupgrades, free meals and transportation services. By offering these promotions,\ncustomers can get more value for their money, while both the OTP and its travel\npartners may grow their loyal customer base. However, the promotions usually\nincur a cost that, if uncontrolled, can become unsustainable. Consequently, for\na promotion to be viable, its associated costs must be balanced by incremental\nrevenue within set financial constraints. Personalized treatment assignment can\nbe used to satisfy such constraints.\n  This paper introduces a novel uplift modeling technique, relying on the\nKnapsack Problem formulation, that dynamically optimizes the incremental\ntreatment outcome subject to the required Return on Investment (ROI)\nconstraints. The technique leverages Retrospective Estimation, a modeling\napproach that relies solely on data from positive outcome examples. The method\nalso addresses training data bias, long term effects, and seasonality\nchallenges via online-dynamic calibration. This approach was tested via offline\nexperiments and online randomized controlled trials at Booking .com - a leading\nOTP with millions of customers worldwide, resulting in a significant increase\nin the target outcome while staying within the required financial constraints\nand outperforming other approaches.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 11:13:58 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 06:31:44 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Goldenberg", "Dmitri", ""], ["Albert", "Javier", ""], ["Bernardi", "Lucas", ""], ["Estevez", "Pablo", ""]]}, {"id": "2008.06294", "submitter": "Maria H\\\"ugle", "authors": "Maria H\\\"ugle, Gabriel Kalweit, Thomas Huegle and Joschka Boedecker", "title": "A Dynamic Deep Neural Network For Multimodal Clinical Data Analysis", "comments": "Accepted at the AAAI 2020 International Workshop on Health\n  Intelligence", "journal-ref": null, "doi": "10.1007/978-3-030-53352-6", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical data from electronic medical records, registries or trials provide a\nlarge source of information to apply machine learning methods in order to\nfoster precision medicine, e.g. by finding new disease phenotypes or performing\nindividual disease prediction. However, to take full advantage of deep learning\nmethods on clinical data, architectures are necessary that 1) are robust with\nrespect to missing and wrong values, and 2) can deal with highly variable-sized\nlists and long-term dependencies of individual diagnosis, procedures,\nmeasurements and medication prescriptions. In this work, we elaborate\nlimitations of fully-connected neural networks and classical machine learning\nmethods in this context and propose AdaptiveNet, a novel recurrent neural\nnetwork architecture, which can deal with multiple lists of different events,\nalleviating the aforementioned limitations. We employ the architecture to the\nproblem of disease progression prediction in rheumatoid arthritis using the\nSwiss Clinical Quality Management registry, which contains over 10.000 patients\nand more than 65.000 patient visits. Our proposed approach leads to more\ncompact representations and outperforms the classical baselines.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 11:19:32 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["H\u00fcgle", "Maria", ""], ["Kalweit", "Gabriel", ""], ["Huegle", "Thomas", ""], ["Boedecker", "Joschka", ""]]}, {"id": "2008.06296", "submitter": "Zeng Li", "authors": "Zeng Li, Chuanlong Xie, Qinwen Wang", "title": "Provable More Data Hurt in High Dimensional Least Squares Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the finite-sample prediction risk of the\nhigh-dimensional least squares estimator. We derive the central limit theorem\nfor the prediction risk when both the sample size and the number of features\ntend to infinity. Furthermore, the finite-sample distribution and the\nconfidence interval of the prediction risk are provided. Our theoretical\nresults demonstrate the sample-wise nonmonotonicity of the prediction risk and\nconfirm \"more data hurt\" phenomenon.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 11:33:30 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Li", "Zeng", ""], ["Xie", "Chuanlong", ""], ["Wang", "Qinwen", ""]]}, {"id": "2008.06298", "submitter": "Rudolf Jagdhuber", "authors": "Rudolf Jagdhuber, Michel Lang and J\\\"org Rahnenf\\\"uhrer", "title": "Feature Selection Methods for Cost-Constrained Classification in Random\n  Forests", "comments": "Corrected minor typo in Figure 1, Added ancillary files", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cost-sensitive feature selection describes a feature selection problem, where\nfeatures raise individual costs for inclusion in a model. These costs allow to\nincorporate disfavored aspects of features, e.g. failure rates of as measuring\ndevice, or patient harm, in the model selection process. Random Forests define\na particularly challenging problem for feature selection, as features are\ngenerally entangled in an ensemble of multiple trees, which makes a post hoc\nremoval of features infeasible. Feature selection methods therefore often\neither focus on simple pre-filtering methods, or require many Random Forest\nevaluations along their optimization path, which drastically increases the\ncomputational complexity. To solve both issues, we propose Shallow Tree\nSelection, a novel fast and multivariate feature selection method that selects\nfeatures from small tree structures. Additionally, we also adapt three standard\nfeature selection algorithms for cost-sensitive learning by introducing a\nhyperparameter-controlled benefit-cost ratio criterion (BCR) for each method.\nIn an extensive simulation study, we assess this criterion, and compare the\nproposed methods to multiple performance-based baseline alternatives on four\nartificial data settings and seven real-world data settings. We show that all\nmethods using a hyperparameterized BCR criterion outperform the baseline\nalternatives. In a direct comparison between the proposed methods, each method\nindicates strengths in certain settings, but no one-fits-all solution exists.\nOn a global average, we could identify preferable choices among our BCR based\nmethods. Nevertheless, we conclude that a practical analysis should never rely\non a single method only, but always compare different approaches to obtain the\nbest results.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 11:39:52 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 04:25:16 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Jagdhuber", "Rudolf", ""], ["Lang", "Michel", ""], ["Rahnenf\u00fchrer", "J\u00f6rg", ""]]}, {"id": "2008.06302", "submitter": "Arash Bozorgchenani", "authors": "Arash Bozorgchenani, Setareh Maghsudi, Daniele Tarchi, Ekram Hossain", "title": "Computation Offloading in Heterogeneous Vehicular Edge Networks: On-line\n  and Off-policy Bandit Solutions", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid advancement in vehicular communications and intelligent\ntransportation systems technologies, task offloading in vehicular networking\nscenarios is emerging as a promising, yet challenging, paradigm in mobile edge\ncomputing. In this paper, we study the computation offloading problem from\nmobile vehicles/users, more specifically, the network- and base station\nselection problem, in a heterogeneous Vehicular Edge Computing (VEC) scenario,\nwhere networks have different traffic loads. In a fast-varying vehicular\nenvironment, the latency in computation offloading that arises as a result of\nnetwork congestion (e.g. at the edge computing servers co-located with the base\nstations) is a key performance metric. However, due to the non-stationary\nproperty of such environments, predicting network congestion is an involved\ntask. To address this challenge, we propose an on-line algorithm and an\noff-policy learning algorithm based on bandit theory. To dynamically select the\nleast congested network in a piece-wise stationary environment, from the\noffloading history, these algorithms learn the latency that the offloaded tasks\nexperience. In addition, to minimize the task loss due to the mobility of the\nvehicles, we develop a method for base station selection and a relaying\nmechanism in the chosen network based on the sojourn time of the vehicles.\nThrough extensive numerical analysis, we demonstrate that the proposed\nlearning-based solutions adapt to the traffic changes of the network by\nselecting the least congested network. Moreover, the proposed approaches\nimprove the latency of offloaded tasks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 11:48:13 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Bozorgchenani", "Arash", ""], ["Maghsudi", "Setareh", ""], ["Tarchi", "Daniele", ""], ["Hossain", "Ekram", ""]]}, {"id": "2008.06311", "submitter": "Feng Xia", "authors": "Ke Hou, Jiaying Liu, Yin Peng, Bo Xu, Ivan Lee, Feng Xia", "title": "DINE: A Framework for Deep Incomplete Network Embedding", "comments": "12 pages, 3 figures", "journal-ref": "The 32nd Australasian Joint Conference on Artificial Intelligence\n  (AI), 2-5 Dec 2019, Adelaide Australia", "doi": "10.1007/978-3-030-39469-1_7", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network representation learning (NRL) plays a vital role in a variety of\ntasks such as node classification and link prediction. It aims to learn\nlow-dimensional vector representations for nodes based on network structures or\nnode attributes. While embedding techniques on complete networks have been\nintensively studied, in real-world applications, it is still a challenging task\nto collect complete networks. To bridge the gap, in this paper, we propose a\nDeep Incomplete Network Embedding method, namely DINE. Specifically, we first\ncomplete the missing part including both nodes and edges in a partially\nobservable network by using the expectation-maximization framework. To improve\nthe embedding performance, we consider both network structures and node\nattributes to learn node representations. Empirically, we evaluate DINE over\nthree networks on multi-label classification and link prediction tasks. The\nresults demonstrate the superiority of our proposed approach compared against\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 04:59:35 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Hou", "Ke", ""], ["Liu", "Jiaying", ""], ["Peng", "Yin", ""], ["Xu", "Bo", ""], ["Lee", "Ivan", ""], ["Xia", "Feng", ""]]}, {"id": "2008.06319", "submitter": "Christian Hubbs", "authors": "Christian D. Hubbs and Hector D. Perez and Owais Sarwar and Nikolaos\n  V. Sahinidis and Ignacio E. Grossmann and John M. Wassick", "title": "OR-Gym: A Reinforcement Learning Library for Operations Research\n  Problems", "comments": "29 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has been widely applied to game-playing and\nsurpassed the best human-level performance in many domains, yet there are few\nuse-cases in industrial or commercial settings. We introduce OR-Gym, an\nopen-source library for developing reinforcement learning algorithms to address\noperations research problems. In this paper, we apply reinforcement learning to\nthe knapsack, multi-dimensional bin packing, multi-echelon supply chain, and\nmulti-period asset allocation model problems, as well as benchmark the RL\nsolutions against MILP and heuristic models. These problems are used in\nlogistics, finance, engineering, and are common in many business operation\nsettings. We develop environments based on prototypical models in the\nliterature and implement various optimization and heuristic models in order to\nbenchmark the RL results. By re-framing a series of classic optimization\nproblems as RL tasks, we seek to provide a new tool for the operations research\ncommunity, while also opening those in the RL community to many of the problems\nand challenges in the OR field.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 12:21:22 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 11:58:49 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Hubbs", "Christian D.", ""], ["Perez", "Hector D.", ""], ["Sarwar", "Owais", ""], ["Sahinidis", "Nikolaos V.", ""], ["Grossmann", "Ignacio E.", ""], ["Wassick", "John M.", ""]]}, {"id": "2008.06326", "submitter": "Shashank Gupta", "authors": "Shashank Gupta, Antonio Robles-Kelly and Mohamed Reda Bouadjenek", "title": "Feature Extraction Functions for Neural Logic Rule Learning", "comments": "to be published in S+SSPR 2020 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining symbolic human knowledge with neural networks provides a rule-based\nante-hoc explanation of the output. In this paper, we propose feature\nextracting functions for integrating human knowledge abstracted as logic rules\ninto the predictive behavior of a neural network. These functions are embodied\nas programming functions, which represent the applicable domain knowledge as a\nset of logical instructions and provide a modified distribution of independent\nfeatures on input data. Unlike other existing neural logic approaches, the\nprogrammatic nature of these functions implies that they do not require any\nkind of special mathematical encoding, which makes our method very general and\nflexible in nature. We illustrate the performance of our approach for sentiment\nclassification and compare our results to those obtained using two baselines.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 12:35:07 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 13:01:02 GMT"}, {"version": "v3", "created": "Wed, 7 Apr 2021 13:05:17 GMT"}, {"version": "v4", "created": "Sun, 11 Apr 2021 06:15:17 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Gupta", "Shashank", ""], ["Robles-Kelly", "Antonio", ""], ["Bouadjenek", "Mohamed Reda", ""]]}, {"id": "2008.06330", "submitter": "Siqi Liu", "authors": "Eduardo Mortani Barbosa Jr., Warren B. Gefter, Rochelle Yang, Florin\n  C. Ghesu, Siqi Liu, Boris Mailhe, Awais Mansoor, Sasa Grbic, Sebastian Piat,\n  Guillaume Chabin, Vishwanath R S., Abishek Balachandran, Sebastian Vogt,\n  Valentin Ziebandt, Steffen Kappler, Dorin Comaniciu", "title": "Automated detection and quantification of COVID-19 airspace disease on\n  chest radiographs: A novel approach achieving radiologist-level performance\n  using a CNN trained on digital reconstructed radiographs (DRRs) from CT-based\n  ground-truth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: To leverage volumetric quantification of airspace disease (AD)\nderived from a superior modality (CT) serving as ground truth, projected onto\ndigitally reconstructed radiographs (DRRs) to: 1) train a convolutional neural\nnetwork to quantify airspace disease on paired CXRs; and 2) compare the\nDRR-trained CNN to expert human readers in the CXR evaluation of patients with\nconfirmed COVID-19.\n  Materials and Methods: We retrospectively selected a cohort of 86 COVID-19\npatients (with positive RT-PCR), from March-May 2020 at a tertiary hospital in\nthe northeastern USA, who underwent chest CT and CXR within 48 hrs. The ground\ntruth volumetric percentage of COVID-19 related AD (POv) was established by\nmanual AD segmentation on CT. The resulting 3D masks were projected into 2D\nanterior-posterior digitally reconstructed radiographs (DRR) to compute\narea-based AD percentage (POa). A convolutional neural network (CNN) was\ntrained with DRR images generated from a larger-scale CT dataset of COVID-19\nand non-COVID-19 patients, automatically segmenting lungs, AD and quantifying\nPOa on CXR. CNN POa results were compared to POa quantified on CXR by two\nexpert readers and to the POv ground-truth, by computing correlations and mean\nabsolute errors.\n  Results: Bootstrap mean absolute error (MAE) and correlations between POa and\nPOv were 11.98% [11.05%-12.47%] and 0.77 [0.70-0.82] for average of expert\nreaders, and 9.56%-9.78% [8.83%-10.22%] and 0.78-0.81 [0.73-0.85] for the CNN,\nrespectively.\n  Conclusion: Our CNN trained with DRR using CT-derived airspace quantification\nachieved expert radiologist level of accuracy in the quantification of airspace\ndisease on CXR, in patients with positive RT-PCR for COVID-19.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 14:33:03 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Barbosa", "Eduardo Mortani", "Jr."], ["Gefter", "Warren B.", ""], ["Yang", "Rochelle", ""], ["Ghesu", "Florin C.", ""], ["Liu", "Siqi", ""], ["Mailhe", "Boris", ""], ["Mansoor", "Awais", ""], ["Grbic", "Sasa", ""], ["Piat", "Sebastian", ""], ["Chabin", "Guillaume", ""], ["S.", "Vishwanath R", ""], ["Balachandran", "Abishek", ""], ["Vogt", "Sebastian", ""], ["Ziebandt", "Valentin", ""], ["Kappler", "Steffen", ""], ["Comaniciu", "Dorin", ""]]}, {"id": "2008.06332", "submitter": "Beate Sick", "authors": "Lisa Herzog, Elvis Murina, Oliver D\\\"urr, Susanne Wegener, Beate Sick", "title": "Integrating uncertainty in deep neural networks for MRI based stroke\n  analysis", "comments": "21 pages, 13 figures", "journal-ref": "Medical Image Analysis (2020): 101790", "doi": "10.1016/j.media.2020.101790", "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At present, the majority of the proposed Deep Learning (DL) methods provide\npoint predictions without quantifying the models uncertainty. However, a\nquantification of the reliability of automated image analysis is essential, in\nparticular in medicine when physicians rely on the results for making critical\ntreatment decisions. In this work, we provide an entire framework to diagnose\nischemic stroke patients incorporating Bayesian uncertainty into the analysis\nprocedure. We present a Bayesian Convolutional Neural Network (CNN) yielding a\nprobability for a stroke lesion on 2D Magnetic Resonance (MR) images with\ncorresponding uncertainty information about the reliability of the prediction.\nFor patient-level diagnoses, different aggregation methods are proposed and\nevaluated, which combine the single image-level predictions. Those methods take\nadvantage of the uncertainty in image predictions and report model uncertainty\nat the patient-level. In a cohort of 511 patients, our Bayesian CNN achieved an\naccuracy of 95.33% at the image-level representing a significant improvement of\n2% over a non-Bayesian counterpart. The best patient aggregation method yielded\n95.89% of accuracy. Integrating uncertainty information about image predictions\nin aggregation models resulted in higher uncertainty measures to false patient\nclassifications, which enabled to filter critical patient diagnoses that are\nsupposed to be closer examined by a medical doctor. We therefore recommend\nusing Bayesian approaches not only for improved image-level prediction and\nuncertainty estimation but also for the detection of uncertain aggregations at\nthe patient-level.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 09:50:17 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Herzog", "Lisa", ""], ["Murina", "Elvis", ""], ["D\u00fcrr", "Oliver", ""], ["Wegener", "Susanne", ""], ["Sick", "Beate", ""]]}, {"id": "2008.06340", "submitter": "Patrizio Frosini", "authors": "Stefano Botteghi, Martina Brasini, Patrizio Frosini, Nicola Quercioli", "title": "On the finite representation of group equivariant operators via\n  permutant measures", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.LG math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of $G$-equivariant operators is of great interest to explain and\nunderstand the architecture of neural networks. In this paper we show that each\nlinear $G$-equivariant operator can be produced by a suitable permutant\nmeasure, provided that the group $G$ transitively acts on a finite signal\ndomain $X$. This result makes available a new method to build linear\n$G$-equivariant operators in the finite setting.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 14:25:04 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Botteghi", "Stefano", ""], ["Brasini", "Martina", ""], ["Frosini", "Patrizio", ""], ["Quercioli", "Nicola", ""]]}, {"id": "2008.06344", "submitter": "Maria D. Ruiz-Medina", "authors": "A. Torres-Signes, M.P. Fr\\'ias and M.D. Ruiz-Medina", "title": "COVID-19 mortality analysis from soft-data multivariate curve regression\n  and machine learning", "comments": "This paper is currently submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multiple objective space-time forecasting approach is presented involving\ncyclical curve log-regression, and multivariate time series spatial residual\ncorrelation analysis. Specifically, the mean quadratic loss function is\nminimized in the framework of trigonometric regression. While, in our\nsubsequent spatial residual correlation analysis, maximization of the\nlikelihood allows us to compute the posterior mode in a Bayesian multivariate\ntime series soft-data framework. The presented approach is applied to the\nanalysis of COVID-19 mortality in the first wave affecting the Spanish\nCommunities, since March, 8, 2020 until May, 13, 2020. An empirical comparative\nstudy with Machine Learning (ML) regression, based on random k-fold\ncross-validation, and bootstrapping confidence interval and probability density\nestimation, is carried out. This empirical analysis also investigates the\nperformance of ML regression models in a hard- and soft- data frameworks. The\nresults could be extrapolated to other counts, countries, and posterior\nCOVID-19 waves.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 15:59:10 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 12:09:21 GMT"}, {"version": "v3", "created": "Sat, 27 Mar 2021 08:11:31 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Torres-Signes", "A.", ""], ["Fr\u00edas", "M. P.", ""], ["Ruiz-Medina", "M. D.", ""]]}, {"id": "2008.06348", "submitter": "Andrew Flynn Mr", "authors": "Andrew Flynn, Vassilios A. Tsachouridis, and Andreas Amann", "title": "Multifunctionality in a Reservoir Computer", "comments": null, "journal-ref": null, "doi": "10.1063/5.0019974", "report-no": null, "categories": "cs.NE cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multifunctionality is a well observed phenomenological feature of biological\nneural networks and considered to be of fundamental importance to the survival\nof certain species over time. These multifunctional neural networks are capable\nof performing more than one task without changing any network connections. In\nthis paper we investigate how this neurological idiosyncrasy can be achieved in\nan artificial setting with a modern machine learning paradigm known as\n`Reservoir Computing'. A training technique is designed to enable a Reservoir\nComputer to perform tasks of a multifunctional nature. We explore the critical\neffects that changes in certain parameters can have on the Reservoir Computers'\nability to express multifunctionality. We also expose the existence of several\n`untrained attractors'; attractors which dwell within the prediction state\nspace of the Reservoir Computer that were not part of the training. We conduct\na bifurcation analysis of these untrained attractors and discuss the\nimplications of our results.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 21:05:53 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 12:31:33 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Flynn", "Andrew", ""], ["Tsachouridis", "Vassilios A.", ""], ["Amann", "Andreas", ""]]}, {"id": "2008.06353", "submitter": "Milda Pocevi\\v{c}i\\=ut\\.e", "authors": "Milda Pocevi\\v{c}i\\=ut\\.e and Gabriel Eilertsen and Claes Lundstr\\\"om", "title": "Survey of XAI in digital pathology", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-50402-1_4", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) has shown great promise for diagnostic imaging\nassessments. However, the application of AI to support medical diagnostics in\nclinical routine comes with many challenges. The algorithms should have high\nprediction accuracy but also be transparent, understandable and reliable. Thus,\nexplainable artificial intelligence (XAI) is highly relevant for this domain.\nWe present a survey on XAI within digital pathology, a medical imaging\nsub-discipline with particular characteristics and needs. The review includes\nseveral contributions. Firstly, we give a thorough overview of current XAI\ntechniques of potential relevance for deep learning methods in pathology\nimaging, and categorise them from three different aspects. In doing so, we\nincorporate uncertainty estimation methods as an integral part of the XAI\nlandscape. We also connect the technical methods to the specific prerequisites\nin digital pathology and present findings to guide future research efforts. The\nsurvey is intended for both technical researchers and medical professionals,\none of the objectives being to establish a common ground for cross-disciplinary\ndiscussions.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 13:11:54 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Pocevi\u010di\u016bt\u0117", "Milda", ""], ["Eilertsen", "Gabriel", ""], ["Lundstr\u00f6m", "Claes", ""]]}, {"id": "2008.06359", "submitter": "Debangshu Banerjee", "authors": "Debangshu Banerjee", "title": "HEX and Neurodynamic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hex is a complex game with a high branching factor. For the first time Hex is\nbeing attempted to be solved without the use of game tree structures and\nassociated methods of pruning. We also are abstaining from any heuristic\ninformation about Virtual Connections or Semi Virtual Connections which were\npreviously used in all previous known computer versions of the game. The\nH-search algorithm which was the basis of finding such connections and had been\nused with success in previous Hex playing agents has been forgone. Instead what\nwe use is reinforcement learning through self play and approximations through\nneural networks to by pass the problem of high branching factor and maintaining\nlarge tables for state-action evaluations. Our code is based primarily on\nNeuroHex. The inspiration is drawn from the recent success of AlphaGo Zero.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 07:36:50 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Banerjee", "Debangshu", ""]]}, {"id": "2008.06365", "submitter": "Shruti Jadon", "authors": "Shruti Jadon", "title": "An Overview of Deep Learning Architectures in Few-Shot Learning Domain", "comments": "11 pages, 11 figures", "journal-ref": null, "doi": "10.13140/RG.2.2.31573.24803/1", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since 2012, Deep learning has revolutionized Artificial Intelligence and has\nachieved state-of-the-art outcomes in different domains, ranging from Image\nClassification to Speech Generation. Though it has many potentials, our current\narchitectures come with the pre-requisite of large amounts of data. Few-Shot\nLearning (also known as one-shot learning) is a sub-field of machine learning\nthat aims to create such models that can learn the desired objective with less\ndata, similar to how humans learn. In this paper, we have reviewed some of the\nwell-known deep learning-based approaches towards few-shot learning. We have\ndiscussed the recent achievements, challenges, and possibilities of improvement\nof few-shot learning based deep learning architectures. Our aim for this paper\nis threefold: (i) Give a brief introduction to deep learning architectures for\nfew-shot learning with pointers to core references. (ii) Indicate how deep\nlearning has been applied to the low-data regime, from data preparation to\nmodel training. and, (iii) Provide a starting point for people interested in\nexperimenting and perhaps contributing to the field of few-shot learning by\npointing out some useful resources and open-source code. Our code is available\nat Github: https://github.com/shruti-jadon/Hands-on-One-Shot-Learning.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 06:58:45 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 03:06:33 GMT"}, {"version": "v3", "created": "Wed, 19 Aug 2020 18:23:15 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Jadon", "Shruti", ""]]}, {"id": "2008.06376", "submitter": "Jason Armitage", "authors": "Jason Armitage, Endri Kacupaj, Golsa Tahmasebzadeh, Swati, Maria\n  Maleshkova, Ralph Ewerth, Jens Lehmann", "title": "MLM: A Benchmark Dataset for Multitask Learning with Multiple Languages\n  and Modalities", "comments": null, "journal-ref": "Proceedings of the 29th ACM International Conference on\n  Information & Knowledge Management, pp. 2967-2974. 2020", "doi": "10.1145/3340531.3412783", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce the MLM (Multiple Languages and Modalities)\ndataset - a new resource to train and evaluate multitask systems on samples in\nmultiple modalities and three languages. The generation process and inclusion\nof semantic data provide a resource that further tests the ability for\nmultitask systems to learn relationships between entities. The dataset is\ndesigned for researchers and developers who build applications that perform\nmultiple tasks on data encountered on the web and in digital archives. A second\nversion of MLM provides a geo-representative subset of the data with weighted\nsamples for countries of the European Union. We demonstrate the value of the\nresource in developing novel applications in the digital humanities with a\nmotivating use case and specify a benchmark set of tasks to retrieve modalities\nand locate entities in the dataset. Evaluation of baseline multitask and single\ntask systems on the full and geo-representative versions of MLM demonstrate the\nchallenges of generalising on diverse data. In addition to the digital\nhumanities, we expect the resource to contribute to research in multimodal\nrepresentation learning, location estimation, and scene understanding.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 14:00:05 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 10:00:43 GMT"}, {"version": "v3", "created": "Fri, 4 Sep 2020 16:10:28 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Armitage", "Jason", ""], ["Kacupaj", "Endri", ""], ["Tahmasebzadeh", "Golsa", ""], ["Swati", "", ""], ["Maleshkova", "Maria", ""], ["Ewerth", "Ralph", ""], ["Lehmann", "Jens", ""]]}, {"id": "2008.06388", "submitter": "Michael Roberts", "authors": "Michael Roberts, Derek Driggs, Matthew Thorpe, Julian Gilbey, Michael\n  Yeung, Stephan Ursprung, Angelica I. Aviles-Rivero, Christian Etmann, Cathal\n  McCague, Lucian Beer, Jonathan R. Weir-McCall, Zhongzhao Teng, Effrossyni\n  Gkrania-Klotsas, James H.F. Rudd, Evis Sala, Carola-Bibiane Sch\\\"onlieb (on\n  behalf of the AIX-COVNET collaboration)", "title": "Common pitfalls and recommendations for using machine learning to detect\n  and prognosticate for COVID-19 using chest radiographs and CT scans", "comments": "35 pages, 3 figures, 2 tables, updated to the period 1 January 2020 -\n  3 October 2020", "journal-ref": "Nature Machine Intelligence 3, 199-217 (2021)", "doi": "10.1038/s42256-021-00307-0", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods offer great promise for fast and accurate detection\nand prognostication of COVID-19 from standard-of-care chest radiographs (CXR)\nand computed tomography (CT) images. Many articles have been published in 2020\ndescribing new machine learning-based models for both of these tasks, but it is\nunclear which are of potential clinical utility. In this systematic review, we\nsearch EMBASE via OVID, MEDLINE via PubMed, bioRxiv, medRxiv and arXiv for\npublished papers and preprints uploaded from January 1, 2020 to October 3, 2020\nwhich describe new machine learning models for the diagnosis or prognosis of\nCOVID-19 from CXR or CT images. Our search identified 2,212 studies, of which\n415 were included after initial screening and, after quality screening, 61\nstudies were included in this systematic review. Our review finds that none of\nthe models identified are of potential clinical use due to methodological flaws\nand/or underlying biases. This is a major weakness, given the urgency with\nwhich validated COVID-19 models are needed. To address this, we give many\nrecommendations which, if followed, will solve these issues and lead to higher\nquality model development and well documented manuscripts.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 14:25:21 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 08:10:35 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 13:56:25 GMT"}, {"version": "v4", "created": "Tue, 5 Jan 2021 19:41:55 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Roberts", "Michael", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Driggs", "Derek", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Thorpe", "Matthew", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Gilbey", "Julian", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Yeung", "Michael", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Ursprung", "Stephan", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Aviles-Rivero", "Angelica I.", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Etmann", "Christian", "", "on\n  behalf of the AIX-COVNET collaboration"], ["McCague", "Cathal", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Beer", "Lucian", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Weir-McCall", "Jonathan R.", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Teng", "Zhongzhao", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Gkrania-Klotsas", "Effrossyni", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Rudd", "James H. F.", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Sala", "Evis", "", "on\n  behalf of the AIX-COVNET collaboration"], ["Sch\u00f6nlieb", "Carola-Bibiane", "", "on\n  behalf of the AIX-COVNET collaboration"]]}, {"id": "2008.06389", "submitter": "Cristina Pinneri", "authors": "Cristina Pinneri, Shambhuraj Sawant, Sebastian Blaes, Jan Achterhold,\n  Joerg Stueckler, Michal Rolinek and Georg Martius", "title": "Sample-efficient Cross-Entropy Method for Real-time Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trajectory optimizers for model-based reinforcement learning, such as the\nCross-Entropy Method (CEM), can yield compelling results even in\nhigh-dimensional control tasks and sparse-reward environments. However, their\nsampling inefficiency prevents them from being used for real-time planning and\ncontrol. We propose an improved version of the CEM algorithm for fast planning,\nwith novel additions including temporally-correlated actions and memory,\nrequiring 2.7-22x less samples and yielding a performance increase of 1.2-10x\nin high-dimensional control problems.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 14:25:59 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Pinneri", "Cristina", ""], ["Sawant", "Shambhuraj", ""], ["Blaes", "Sebastian", ""], ["Achterhold", "Jan", ""], ["Stueckler", "Joerg", ""], ["Rolinek", "Michal", ""], ["Martius", "Georg", ""]]}, {"id": "2008.06395", "submitter": "Francesco Mannella", "authors": "Francesco Mannella", "title": "Supervised Topological Maps", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controlling the internal representation space of a neural network is a\ndesirable feature because it allows to generate new data in a supervised\nmanner. In this paper we will show how this can be achieved while building a\nlow-dimensional mapping of the input stream, by deriving a generalized\nalgorithm starting from Self Organizing Maps (SOMs). SOMs are a kind of neural\nnetwork which can be trained with unsupervised learning to produce a\nlow-dimensional discretized mapping of the input space. They can be used for\nthe generation of new data through backward propagation of interpolations made\nfrom the mapping grid. Unfortunately the final topology of the mapping space of\na SOM is not known before learning, so interpolating new data in a supervised\nway is not an easy task. Here we will show a variation from the SOM algorithm\nconsisting in constraining the update of prototypes so that it is also a\nfunction of the distance of its prototypes from extrinsically given targets in\nthe mapping space. We will demonstrate how such variants, that we will call\nSupervised Topological Maps (STMs), allow for a supervised mapping where the\nposition of internal representations in the mapping space is determined by the\nexperimenter. Controlling the internal representation space in STMs reveals to\nbe an easier task than what is currently done using other algorithms such as\nvariational or adversarial autoencoders.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 14:30:16 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 21:50:10 GMT"}, {"version": "v3", "created": "Wed, 2 Sep 2020 09:30:22 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Mannella", "Francesco", ""]]}, {"id": "2008.06402", "submitter": "Stefanos Laskaridis", "authors": "Stefanos Laskaridis, Stylianos I. Venieris, Mario Almeida, Ilias\n  Leontiadis, Nicholas D. Lane", "title": "SPINN: Synergistic Progressive Inference of Neural Networks over Device\n  and Cloud", "comments": "Accepted at the 26th Annual International Conference on Mobile\n  Computing and Networking (MobiCom), 2020", "journal-ref": null, "doi": "10.1145/3372224.3419194", "report-no": null, "categories": "cs.LG cs.CV cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the soaring use of convolutional neural networks (CNNs) in mobile\napplications, uniformly sustaining high-performance inference on mobile has\nbeen elusive due to the excessive computational demands of modern CNNs and the\nincreasing diversity of deployed devices. A popular alternative comprises\noffloading CNN processing to powerful cloud-based servers. Nevertheless, by\nrelying on the cloud to produce outputs, emerging mission-critical and\nhigh-mobility applications, such as drone obstacle avoidance or interactive\napplications, can suffer from the dynamic connectivity conditions and the\nuncertain availability of the cloud. In this paper, we propose SPINN, a\ndistributed inference system that employs synergistic device-cloud computation\ntogether with a progressive inference method to deliver fast and robust CNN\ninference across diverse settings. The proposed system introduces a novel\nscheduler that co-optimises the early-exit policy and the CNN splitting at run\ntime, in order to adapt to dynamic conditions and meet user-defined\nservice-level requirements. Quantitative evaluation illustrates that SPINN\noutperforms its state-of-the-art collaborative inference counterparts by up to\n2x in achieved throughput under varying network conditions, reduces the server\ncost by up to 6.8x and improves accuracy by 20.7% under latency constraints,\nwhile providing robust operation under uncertain connectivity conditions and\nsignificant energy savings compared to cloud-centric execution.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 15:00:19 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 10:24:41 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Laskaridis", "Stefanos", ""], ["Venieris", "Stylianos I.", ""], ["Almeida", "Mario", ""], ["Leontiadis", "Ilias", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "2008.06415", "submitter": "Rishikesh Magar", "authors": "Mohammadreza Karamad, Rishikesh Magar, Yuting Shi, Samira Siahrostami,\n  Ian D. Gates and Amir Barati Farimani", "title": "Orbital Graph Convolutional Neural Network for Material Property\n  Prediction", "comments": "3 figures in main text. 7 figures in SI. Accepted for publication by\n  Physical Review Materials. The template used for the latex has been taken\n  from: https://github.com/brenhinkeller/preprint-template.tex", "journal-ref": "Phys. Rev. Materials 4, 093801 (2020)", "doi": "10.1103/PhysRevMaterials.4.093801", "report-no": null, "categories": "physics.comp-ph cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Material representations that are compatible with machine learning models\nplay a key role in developing models that exhibit high accuracy for property\nprediction. Atomic orbital interactions are one of the important factors that\ngovern the properties of crystalline materials, from which the local chemical\nenvironments of atoms is inferred. Therefore, to develop robust machine\nlearningmodels for material properties prediction, it is imperative to include\nfeatures representing such chemical attributes. Here, we propose the Orbital\nGraph Convolutional Neural Network (OGCNN), a crystal graph convolutional\nneural network framework that includes atomic orbital interaction features that\nlearns material properties in a robust way. In addition, we embedded an\nencoder-decoder network into the OGCNN enabling it to learn important features\namong basic atomic (elemental features), orbital-orbital interactions, and\ntopological features. We examined the performance of this model on a broad\nrange of crystalline material data to predict different properties. We\nbenchmarked the performance of the OGCNN model with that of: 1) the crystal\ngraph convolutional neural network (CGCNN), 2) other state-of-the-art\ndescriptors for material representations including Many-body Tensor\nRepresentation (MBTR) and the Smooth Overlap of Atomic Positions (SOAP), and 3)\nother conventional regression machine learning algorithms where different\ncrystal featurization methods have been used. We find that OGCNN significantly\noutperforms them. The OGCNN model with high predictive accuracy can be used to\ndiscover new materials among the immense phase and compound spaces of materials\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 15:22:22 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Karamad", "Mohammadreza", ""], ["Magar", "Rishikesh", ""], ["Shi", "Yuting", ""], ["Siahrostami", "Samira", ""], ["Gates", "Ian D.", ""], ["Farimani", "Amir Barati", ""]]}, {"id": "2008.06431", "submitter": "David E. Shaw", "authors": "John J. Cherian, Andrew G. Taube, Robert T. McGibbon, Panagiotis\n  Angelikopoulos, Guy Blanc, Michael Snarski, Daniel D. Richman, John L.\n  Klepeis, David E. Shaw", "title": "Efficient hyperparameter optimization by way of PAC-Bayes bound\n  minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying optimal values for a high-dimensional set of hyperparameters is a\nproblem that has received growing attention given its importance to large-scale\nmachine learning applications such as neural architecture search. Recently\ndeveloped optimization methods can be used to select thousands or even millions\nof hyperparameters. Such methods often yield overfit models, however, leading\nto poor performance on unseen data. We argue that this overfitting results from\nusing the standard hyperparameter optimization objective function. Here we\npresent an alternative objective that is equivalent to a Probably Approximately\nCorrect-Bayes (PAC-Bayes) bound on the expected out-of-sample error. We then\ndevise an efficient gradient-based algorithm to minimize this objective; the\nproposed method has asymptotic space and time complexity equal to or better\nthan other gradient-based hyperparameter optimization methods. We show that\nthis new method significantly reduces out-of-sample error when applied to\nhyperparameter optimization problems known to be prone to overfitting.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 15:54:51 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Cherian", "John J.", ""], ["Taube", "Andrew G.", ""], ["McGibbon", "Robert T.", ""], ["Angelikopoulos", "Panagiotis", ""], ["Blanc", "Guy", ""], ["Snarski", "Michael", ""], ["Richman", "Daniel D.", ""], ["Klepeis", "John L.", ""], ["Shaw", "David E.", ""]]}, {"id": "2008.06434", "submitter": "Paul Baggenstoss", "authors": "Paul M Baggenstoss", "title": "The Projected Belief Network Classfier : both Generative and\n  Discriminative", "comments": null, "journal-ref": "EUSIPCO 2020, Amsterdam (Jan 2021)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The projected belief network (PBN) is a layered generative network with\ntractable likelihood function, and is based on a feed-forward neural network\n(FF-NN). It can therefore share an embodiment with a discriminative classifier\nand can inherit the best qualities of both types of network. In this paper, a\nconvolutional PBN is constructed that is both fully discriminative and fully\ngenerative and is tested on spectrograms of spoken commands. It is shown that\nthe network displays excellent qualities from either the discriminative or\ngenerative viewpoint. Random data synthesis and visible data reconstruction\nfrom low-dimensional hidden variables are shown, while classifier performance\napproaches that of a regularized discriminative network. Combination with a\nconventional discriminative CNN is also demonstrated.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 16:00:54 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Baggenstoss", "Paul M", ""]]}, {"id": "2008.06439", "submitter": "Manoj Acharya", "authors": "Manoj Acharya, Tyler L. Hayes, Christopher Kanan", "title": "RODEO: Replay for Online Object Detection", "comments": "Accepted for poster presentation at BMVC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can incrementally learn to do new visual detection tasks, which is a\nhuge challenge for today's computer vision systems. Incrementally trained deep\nlearning models lack backwards transfer to previously seen classes and suffer\nfrom a phenomenon known as $\"catastrophic forgetting.\"$ In this paper, we\npioneer online streaming learning for object detection, where an agent must\nlearn examples one at a time with severe memory and computational constraints.\nIn object detection, a system must output all bounding boxes for an image with\nthe correct label. Unlike earlier work, the system described in this paper can\nlearn this task in an online manner with new classes being introduced over\ntime. We achieve this capability by using a novel memory replay mechanism that\nefficiently replays entire scenes. We achieve state-of-the-art results on both\nthe PASCAL VOC 2007 and MS COCO datasets.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 16:03:52 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Acharya", "Manoj", ""], ["Hayes", "Tyler L.", ""], ["Kanan", "Christopher", ""]]}, {"id": "2008.06452", "submitter": "Fei Cheng", "authors": "Fei Cheng and Yusuke Miyao", "title": "Predicting Event Time by Classifying Sub-Level Temporal Relations\n  Induced from a Unified Representation of Time Anchors", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Extracting event time from news articles is a challenging but attractive\ntask. In contrast to the most existing pair-wised temporal link annotation,\nReimers et al.(2016) proposed to annotate the time anchor (a.k.a. the exact\ntime) of each event. Their work represents time anchors with discrete\nrepresentations of Single-Day/Multi-Day and Certain/Uncertain. This increases\nthe complexity of modeling the temporal relations between two time anchors,\nwhich cannot be categorized into the relations of Allen's interval algebra\n(Allen, 1990).\n  In this paper, we propose an effective method to decompose such complex\ntemporal relations into sub-level relations by introducing a unified quadruple\nrepresentation for both Single-Day/Multi-Day and Certain/Uncertain time\nanchors. The temporal relation classifiers are trained in a multi-label\nclassification manner. The system structure of our approach is much simpler\nthan the existing decision tree model (Reimers et al., 2018), which is composed\nby a dozen of node classifiers. Another contribution of this work is to\nconstruct a larger event time corpus (256 news documents) with a reasonable\nInter-Annotator Agreement (IAA), for the purpose of overcoming the data\nshortage of the existing event time corpus (36 news documents). The empirical\nresults show our approach outperforms the state-of-the-art decision tree model\nand the increase of data size obtained a significant improvement of\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 16:30:07 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Cheng", "Fei", ""], ["Miyao", "Yusuke", ""]]}, {"id": "2008.06456", "submitter": "Salem Lahlou", "authors": "Lucas Willems, Salem Lahlou, Yoshua Bengio", "title": "Mastering Rate based Curriculum Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent automatic curriculum learning algorithms, and in particular\nTeacher-Student algorithms, rely on the notion of learning progress, making the\nassumption that the good next tasks are the ones on which the learner is making\nthe fastest progress or digress. In this work, we first propose a simpler and\nimproved version of these algorithms. We then argue that the notion of learning\nprogress itself has several shortcomings that lead to a low sample efficiency\nfor the learner. We finally propose a new algorithm, based on the notion of\nmastering rate, that significantly outperforms learning progress-based\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 16:34:01 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Willems", "Lucas", ""], ["Lahlou", "Salem", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2008.06460", "submitter": "Marzieh Mozafari", "authors": "Marzieh Mozafari, Reza Farahbakhsh, Noel Crespi", "title": "Hate Speech Detection and Racial Bias Mitigation in Social Media based\n  on BERT model", "comments": "This paper has been accepted in the PLOS ONE journal in August 2020", "journal-ref": null, "doi": "10.1371/journal.pone.0237861", "report-no": null, "categories": "cs.SI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disparate biases associated with datasets and trained classifiers in hateful\nand abusive content identification tasks have raised many concerns recently.\nAlthough the problem of biased datasets on abusive language detection has been\naddressed more frequently, biases arising from trained classifiers have not yet\nbeen a matter of concern. Here, we first introduce a transfer learning approach\nfor hate speech detection based on an existing pre-trained language model\ncalled BERT and evaluate the proposed model on two publicly available datasets\nannotated for racism, sexism, hate or offensive content on Twitter. Next, we\nintroduce a bias alleviation mechanism in hate speech detection task to\nmitigate the effect of bias in training set during the fine-tuning of our\npre-trained BERT-based model. Toward that end, we use an existing\nregularization method to reweight input samples, thereby decreasing the effects\nof high correlated training set' s n-grams with class labels, and then\nfine-tune our pre-trained BERT-based model with the new re-weighted samples. To\nevaluate our bias alleviation mechanism, we employ a cross-domain approach in\nwhich we use the trained classifiers on the aforementioned datasets to predict\nthe labels of two new datasets from Twitter, AAE-aligned and White-aligned\ngroups, which indicate tweets written in African-American English (AAE) and\nStandard American English (SAE) respectively. The results show the existence of\nsystematic racial bias in trained classifiers as they tend to assign tweets\nwritten in AAE from AAE-aligned group to negative classes such as racism,\nsexism, hate, and offensive more often than tweets written in SAE from\nWhite-aligned. However, the racial bias in our classifiers reduces\nsignificantly after our bias alleviation mechanism is incorporated. This work\ncould institute the first step towards debiasing hate speech and abusive\nlanguage detection systems.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 16:47:25 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 10:06:40 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Mozafari", "Marzieh", ""], ["Farahbakhsh", "Reza", ""], ["Crespi", "Noel", ""]]}, {"id": "2008.06471", "submitter": "Gal Metzer", "authors": "Gal Metzer, Rana Hanocka, Raja Giryes, Daniel Cohen-Or", "title": "Self-Sampling for Neural Point Cloud Consolidation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel technique for neural point cloud consolidation which\nlearns from only the input point cloud. Unlike other point upsampling methods\nwhich analyze shapes via local patches, in this work, we learn from global\nsubsets. We repeatedly self-sample the input point cloud with global subsets\nthat are used to train a deep neural network. Specifically, we define source\nand target subsets according to the desired consolidation criteria (e.g.,\ngenerating sharp points or points in sparse regions). The network learns a\nmapping from source to target subsets, and implicitly learns to consolidate the\npoint cloud. During inference, the network is fed with random subsets of points\nfrom the input, which it displaces to synthesize a consolidated point set. We\nleverage the inductive bias of neural networks to eliminate noise and outliers,\na notoriously difficult problem in point cloud consolidation. The shared\nweights of the network are optimized over the entire shape, learning non-local\nstatistics and exploiting the recurrence of local-scale geometries.\nSpecifically, the network encodes the distribution of the underlying shape\nsurface within a fixed set of local kernels, which results in the best\nexplanation of the underlying shape surface. We demonstrate the ability to\nconsolidate point sets from a variety of shapes, while eliminating outliers and\nnoise.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 17:16:02 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 17:09:31 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Metzer", "Gal", ""], ["Hanocka", "Rana", ""], ["Giryes", "Raja", ""], ["Cohen-Or", "Daniel", ""]]}, {"id": "2008.06489", "submitter": "Alqamah Sayeed", "authors": "Alqamah Sayeed, Yunsoo Choi, Jia Jung, Yannic Lops, Ebrahim Eslami,\n  Ahmed Khan Salman", "title": "A Deep Convolutional Neural Network Model for improving WRF Forecasts", "comments": "CNN, weather forecast, WRF, Artificial Intelligence, Machine\n  Learning, wind speed forecast, rainfall forecast", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancements in numerical weather prediction models have accelerated,\nfostering a more comprehensive understanding of physical phenomena pertaining\nto the dynamics of weather and related computing resources. Despite these\nadvancements, these models contain inherent biases due to parameterization and\nlinearization of the differential equations that reduce forecasting accuracy.\nIn this work, we investigate the use of a computationally efficient deep\nlearning method, the Convolutional Neural Network (CNN), as a post-processing\ntechnique that improves mesoscale Weather and Research Forecasting (WRF) one\nday forecast (with a one-hour temporal resolution) outputs. Using the CNN\narchitecture, we bias-correct several meteorological parameters calculated by\nthe WRF model for all of 2018. We train the CNN model with a four-year history\n(2014-2017) to investigate the patterns in WRF biases and then reduce these\nbiases in forecasts for surface wind speed and direction, precipitation,\nrelative humidity, surface pressure, dewpoint temperature, and surface\ntemperature. The WRF data, with a spatial resolution of 27 km, covers South\nKorea. We obtain ground observations from the Korean Meteorological\nAdministration station network for 93 weather station locations. The results\nindicate a noticeable improvement in WRF forecasts in all station locations.\nThe average of annual index of agreement for surface wind, precipitation,\nsurface pressure, temperature, dewpoint temperature and relative humidity of\nall stations are 0.85 (WRF:0.67), 0.62 (WRF:0.56), 0.91 (WRF:0.69), 0.99\n(WRF:0.98), 0.98 (WRF:0.98), and 0.92 (WRF:0.87), respectively. While this\nstudy focuses on South Korea, the proposed approach can be applied for any\nmeasured weather parameters at any location.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 17:48:06 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Sayeed", "Alqamah", ""], ["Choi", "Yunsoo", ""], ["Jung", "Jia", ""], ["Lops", "Yannic", ""], ["Eslami", "Ebrahim", ""], ["Salman", "Ahmed Khan", ""]]}, {"id": "2008.06495", "submitter": "Yuandong Tian", "authors": "Yuandong Tian, Qucheng Gong, Tina Jiang", "title": "Joint Policy Search for Multi-agent Collaboration with Imperfect\n  Information", "comments": "Minor fix of the algorithm block", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To learn good joint policies for multi-agent collaboration with imperfect\ninformation remains a fundamental challenge. While for two-player zero-sum\ngames, coordinate-ascent approaches (optimizing one agent's policy at a time,\ne.g., self-play) work with guarantees, in multi-agent cooperative setting they\noften converge to sub-optimal Nash equilibrium. On the other hand, directly\nmodeling joint policy changes in imperfect information game is nontrivial due\nto complicated interplay of policies (e.g., upstream updates affect downstream\nstate reachability). In this paper, we show global changes of game values can\nbe decomposed to policy changes localized at each information set, with a novel\nterm named policy-change density. Based on this, we propose Joint Policy\nSearch(JPS) that iteratively improves joint policies of collaborative agents in\nimperfect information games, without re-evaluating the entire game. On\nmulti-agent collaborative tabular games, JPS is proven to never worsen\nperformance and can improve solutions provided by unilateral approaches (e.g,\nCFR), outperforming algorithms designed for collaborative policy learning (e.g.\nBAD). Furthermore, for real-world games, JPS has an online form that naturally\nlinks with gradient updates. We test it to Contract Bridge, a 4-player\nimperfect-information game where a team of $2$ collaborates to compete against\nthe other. In its bidding phase, players bid in turn to find a good contract\nthrough a limited information channel. Based on a strong baseline agent that\nbids competitive bridge purely through domain-agnostic self-play, JPS improves\ncollaboration of team players and outperforms WBridge5, a championship-winning\nsoftware, by $+0.63$ IMPs (International Matching Points) per board over 1k\ngames, substantially better than previous SoTA ($+0.41$ IMPs/b) under\nDouble-Dummy evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 17:58:47 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 02:35:56 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 17:14:14 GMT"}, {"version": "v4", "created": "Thu, 22 Oct 2020 20:09:48 GMT"}, {"version": "v5", "created": "Sun, 6 Dec 2020 01:10:09 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Tian", "Yuandong", ""], ["Gong", "Qucheng", ""], ["Jiang", "Tina", ""]]}, {"id": "2008.06520", "submitter": "Ruojin Cai", "authors": "Ruojin Cai, Guandao Yang, Hadar Averbuch-Elor, Zekun Hao, Serge\n  Belongie, Noah Snavely, and Bharath Hariharan", "title": "Learning Gradient Fields for Shape Generation", "comments": "Published in ECCV 2020 (Spotlight); Project page:\n  https://www.cs.cornell.edu/~ruojin/ShapeGF/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel technique to generate shapes from point\ncloud data. A point cloud can be viewed as samples from a distribution of 3D\npoints whose density is concentrated near the surface of the shape. Point cloud\ngeneration thus amounts to moving randomly sampled points to high-density\nareas. We generate point clouds by performing stochastic gradient ascent on an\nunnormalized probability density, thereby moving sampled points toward the\nhigh-likelihood regions. Our model directly predicts the gradient of the log\ndensity field and can be trained with a simple objective adapted from\nscore-based generative models. We show that our method can reach\nstate-of-the-art performance for point cloud auto-encoding and generation,\nwhile also allowing for extraction of a high-quality implicit surface. Code is\navailable at https://github.com/RuojinCai/ShapeGF.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 18:06:15 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 04:34:18 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Cai", "Ruojin", ""], ["Yang", "Guandao", ""], ["Averbuch-Elor", "Hadar", ""], ["Hao", "Zekun", ""], ["Belongie", "Serge", ""], ["Snavely", "Noah", ""], ["Hariharan", "Bharath", ""]]}, {"id": "2008.06542", "submitter": "Quanming Yao", "authors": "Yaqing Wang and Quanming Yao and James T. Kwok", "title": "A Scalable, Adaptive and Sound Nonconvex Regularizer for Low-rank Matrix\n  Completion", "comments": "WebConf 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix learning is at the core of many machine learning problems. A number of\nreal-world applications such as collaborative filtering and text mining\n  can be formulated as a low-rank matrix completion problem, which recovers\nincomplete matrix using low-rank assumptions. To ensure that the matrix\nsolution has a low rank, a recent trend is to use nonconvex regularizers that\nadaptively penalize singular values. They offer good recovery performance and\nhave nice theoretical properties, but are computationally expensive due to\nrepeated access to individual singular values. In this paper, based on the key\ninsight that adaptive shrinkage on singular values improve empirical\nperformance, we propose a new nonconvex low-rank regularizer called \"nuclear\nnorm minus Frobenius norm\" regularizer, which is scalable, adaptive and sound.\nWe first show it provably holds the adaptive shrinkage property. Further, we\ndiscover its factored form which bypasses the computation of singular values\nand allows fast optimization by general optimization algorithms. Stable\nrecovery and convergence are guaranteed. Extensive low-rank matrix completion\nexperiments on a number of synthetic and real-world data sets show that the\nproposed method obtains state-of-the-art recovery performance while being the\nfastest in comparison to existing low-rank matrix learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 18:47:58 GMT"}, {"version": "v2", "created": "Sat, 22 Aug 2020 18:17:04 GMT"}, {"version": "v3", "created": "Sat, 3 Oct 2020 17:21:17 GMT"}, {"version": "v4", "created": "Mon, 22 Feb 2021 07:54:12 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Wang", "Yaqing", ""], ["Yao", "Quanming", ""], ["Kwok", "James T.", ""]]}, {"id": "2008.06543", "submitter": "Fuxun Yu", "authors": "Fuxun Yu, Chenchen Liu, Di Wang, Yanzhi Wang, Xiang Chen", "title": "AntiDote: Attention-based Dynamic Optimization for Neural Network\n  Runtime Efficiency", "comments": "Accepted in DATE'2020 (Best Paper Nomination)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) achieved great cognitive performance at\nthe expense of considerable computation load. To relieve the computation load,\nmany optimization works are developed to reduce the model redundancy by\nidentifying and removing insignificant model components, such as weight\nsparsity and filter pruning. However, these works only evaluate model\ncomponents' static significance with internal parameter information, ignoring\ntheir dynamic interaction with external inputs. With per-input feature\nactivation, the model component significance can dynamically change, and thus\nthe static methods can only achieve sub-optimal results. Therefore, we propose\na dynamic CNN optimization framework in this work. Based on the neural network\nattention mechanism, we propose a comprehensive dynamic optimization framework\nincluding (1) testing-phase channel and column feature map pruning, as well as\n(2) training-phase optimization by targeted dropout. Such a dynamic\noptimization framework has several benefits: (1) First, it can accurately\nidentify and aggressively remove per-input feature redundancy with considering\nthe model-input interaction; (2) Meanwhile, it can maximally remove the feature\nmap redundancy in various dimensions thanks to the multi-dimension flexibility;\n(3) The training-testing co-optimization favors the dynamic pruning and helps\nmaintain the model accuracy even with very high feature pruning ratio.\nExtensive experiments show that our method could bring 37.4% to 54.5% FLOPs\nreduction with negligible accuracy drop on various of test networks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 18:48:13 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Yu", "Fuxun", ""], ["Liu", "Chenchen", ""], ["Wang", "Di", ""], ["Wang", "Yanzhi", ""], ["Chen", "Xiang", ""]]}, {"id": "2008.06551", "submitter": "Aditay Tripathi", "authors": "Aditay Tripathi, Rajath R Dani, Anand Mishra, Anirban Chakraborty", "title": "Sketch-Guided Object Localization in Natural Images", "comments": "ECCV 2020 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the novel problem of localizing all the instances of an object\n(seen or unseen during training) in a natural image via sketch query. We refer\nto this problem as sketch-guided object localization. This problem is\ndistinctively different from the traditional sketch-based image retrieval task\nwhere the gallery set often contains images with only one object. The\nsketch-guided object localization proves to be more challenging when we\nconsider the following: (i) the sketches used as queries are abstract\nrepresentations with little information on the shape and salient attributes of\nthe object, (ii) the sketches have significant variability as they are\nhand-drawn by a diverse set of untrained human subjects, and (iii) there exists\na domain gap between sketch queries and target natural images as these are\nsampled from very different data distributions. To address the problem of\nsketch-guided object localization, we propose a novel cross-modal attention\nscheme that guides the region proposal network (RPN) to generate object\nproposals relevant to the sketch query. These object proposals are later scored\nagainst the query to obtain final localization. Our method is effective with as\nlittle as a single sketch query. Moreover, it also generalizes well to object\ncategories not seen during training and is effective in localizing multiple\nobject instances present in the image. Furthermore, we extend our framework to\na multi-query setting using novel feature fusion and attention fusion\nstrategies introduced in this paper. The localization performance is evaluated\non publicly available object detection benchmarks, viz. MS-COCO and PASCAL-VOC,\nwith sketch queries obtained from `Quick, Draw!'. The proposed method\nsignificantly outperforms related baselines on both single-query and\nmulti-query localization tasks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 19:35:56 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Tripathi", "Aditay", ""], ["Dani", "Rajath R", ""], ["Mishra", "Anand", ""], ["Chakraborty", "Anirban", ""]]}, {"id": "2008.06555", "submitter": "Lalit Jain", "authors": "Lalit Jain, Kevin Jamieson", "title": "A New Perspective on Pool-Based Active Classification and\n  False-Discovery Control", "comments": null, "journal-ref": "Published at Neurips 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many scientific settings there is a need for adaptive experimental design\nto guide the process of identifying regions of the search space that contain as\nmany true positives as possible subject to a low rate of false discoveries\n(i.e. false alarms). Such regions of the search space could differ drastically\nfrom a predicted set that minimizes 0/1 error and accurate identification could\nrequire very different sampling strategies. Like active learning for binary\nclassification, this experimental design cannot be optimally chosen a priori,\nbut rather the data must be taken sequentially and adaptively. However, unlike\nclassification with 0/1 error, collecting data adaptively to find a set with\nhigh true positive rate and low false discovery rate (FDR) is not as well\nunderstood. In this paper we provide the first provably sample efficient\nadaptive algorithm for this problem. Along the way we highlight connections\nbetween classification, combinatorial bandits, and FDR control making\ncontributions to each.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 19:49:19 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Jain", "Lalit", ""], ["Jamieson", "Kevin", ""]]}, {"id": "2008.06570", "submitter": "Monica Ribero", "authors": "Peter Kairouz, M\\'onica Ribero, Keith Rush, Abhradeep Thakurta", "title": "Fast Dimension Independent Private AdaGrad on Publicly Estimated\n  Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of empirical risk minimziation (ERM) with differential\nprivacy. We show that noisy AdaGrad, given appropriate knowledge and conditions\non the subspace from which gradients can be drawn, achieves a regret comparable\nto traditional AdaGrad plus a well-controlled term due to noise. We show a\nconvergence rate of $O(\\text{Tr}(G_T)/T)$, where $G_T$ captures the geometry of\nthe gradient subspace. Since $\\text{Tr}(G_T)=O(\\sqrt{T})$ we can obtain faster\nrates for convex and Lipschitz functions, compared to the $O(1/\\sqrt{T})$ rate\nachieved by known versions of noisy (stochastic) gradient descent with\ncomparable noise variance. In particular, we show that if the gradients lie in\na known constant rank subspace, and assuming algorithmic access to an envelope\nwhich bounds decaying sensitivity, one can achieve faster convergence to an\nexcess empirical risk of $\\tilde O(1/\\epsilon n)$, where $\\epsilon$ is the\nprivacy budget and $n$ the number of samples. Letting $p$ be the problem\ndimension, this result implies that, by running noisy Adagrad, we can bypass\nthe DP-SGD bound $\\tilde O(\\sqrt{p}/\\epsilon n)$ in $T=(\\epsilon\nn)^{2/(1+2\\alpha)}$ iterations, where $\\alpha \\geq 0$ is a parameter\ncontrolling gradient norm decay, instead of the rate achieved by SGD of\n$T=\\epsilon^2n^2$. Our results operate with general convex functions in both\nconstrained and unconstrained minimization.\n  Along the way, we do a perturbation analysis of noisy AdaGrad of independent\ninterest. Our utility guarantee for the private ERM problem follows as a\ncorollary to the regret guarantee of noisy AdaGrad.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 20:46:38 GMT"}, {"version": "v2", "created": "Sat, 30 Jan 2021 23:34:27 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Kairouz", "Peter", ""], ["Ribero", "M\u00f3nica", ""], ["Rush", "Keith", ""], ["Thakurta", "Abhradeep", ""]]}, {"id": "2008.06595", "submitter": "Teng Liu", "authors": "Teng Liu, Xingyu Mu, Bing Huang, Xiaolin Tang, Fuqing Zhao, Xiao Wang,\n  Dongpu Cao", "title": "Decision-making at Unsignalized Intersection for Autonomous Vehicles:\n  Left-turn Maneuver with Deep Reinforcement Learning", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-making module enables autonomous vehicles to reach appropriate\nmaneuvers in the complex urban environments, especially the intersection\nsituations. This work proposes a deep reinforcement learning (DRL) based\nleft-turn decision-making framework at unsignalized intersection for autonomous\nvehicles. The objective of the studied automated vehicle is to make an\nefficient and safe left-turn maneuver at a four-way unsignalized intersection.\nThe exploited DRL methods include deep Q-learning (DQL) and double DQL.\nSimulation results indicate that the presented decision-making strategy could\nefficaciously reduce the collision rate and improve transport efficiency. This\nwork also reveals that the constructed left-turn control structure has a great\npotential to be applied in real-time.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 22:44:26 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Liu", "Teng", ""], ["Mu", "Xingyu", ""], ["Huang", "Bing", ""], ["Tang", "Xiaolin", ""], ["Zhao", "Fuqing", ""], ["Wang", "Xiao", ""], ["Cao", "Dongpu", ""]]}, {"id": "2008.06622", "submitter": "Jesse Zhang", "authors": "Jesse Zhang, Brian Cheung, Chelsea Finn, Sergey Levine, Dinesh\n  Jayaraman", "title": "Cautious Adaptation For Reinforcement Learning in Safety-Critical\n  Settings", "comments": "15 pages, 8 figures, ICML 2020. Website with code:\n  https://sites.google.com/berkeley.edu/carl", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, PMLR 119:11055-11065, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) in real-world safety-critical target settings\nlike urban driving is hazardous, imperiling the RL agent, other agents, and the\nenvironment. To overcome this difficulty, we propose a \"safety-critical\nadaptation\" task setting: an agent first trains in non-safety-critical \"source\"\nenvironments such as in a simulator, before it adapts to the target environment\nwhere failures carry heavy costs. We propose a solution approach, CARL, that\nbuilds on the intuition that prior experience in diverse environments equips an\nagent to estimate risk, which in turn enables relative safety through\nrisk-averse, cautious adaptation. CARL first employs model-based RL to train a\nprobabilistic model to capture uncertainty about transition dynamics and\ncatastrophic states across varied source environments. Then, when exploring a\nnew safety-critical environment with unknown dynamics, the CARL agent plans to\navoid actions that could lead to catastrophic states. In experiments on car\ndriving, cartpole balancing, half-cheetah locomotion, and robotic object\nmanipulation, CARL successfully acquires cautious exploration behaviors,\nyielding higher rewards with fewer failures than strong RL adaptation\nbaselines. Website at https://sites.google.com/berkeley.edu/carl.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 01:40:59 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Zhang", "Jesse", ""], ["Cheung", "Brian", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""], ["Jayaraman", "Dinesh", ""]]}, {"id": "2008.06626", "submitter": "Akifumi Wachi", "authors": "Akifumi Wachi and Yanan Sui", "title": "Safe Reinforcement Learning in Constrained Markov Decision Processes", "comments": "10 pages, 6 figures, Accepted to ICML2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safe reinforcement learning has been a promising approach for optimizing the\npolicy of an agent that operates in safety-critical applications. In this\npaper, we propose an algorithm, SNO-MDP, that explores and optimizes Markov\ndecision processes under unknown safety constraints. Specifically, we take a\nstepwise approach for optimizing safety and cumulative reward. In our method,\nthe agent first learns safety constraints by expanding the safe region, and\nthen optimizes the cumulative reward in the certified safe region. We provide\ntheoretical guarantees on both the satisfaction of the safety constraint and\nthe near-optimality of the cumulative reward under proper regularity\nassumptions. In our experiments, we demonstrate the effectiveness of SNO-MDP\nthrough two experiments: one uses a synthetic data in a new, openly-available\nenvironment named GP-SAFETY-GYM, and the other simulates Mars surface\nexploration by using real observation data.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 02:20:23 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wachi", "Akifumi", ""], ["Sui", "Yanan", ""]]}, {"id": "2008.06630", "submitter": "Igor Vasiljevic", "authors": "Igor Vasiljevic, Vitor Guizilini, Rares Ambrus, Sudeep Pillai, Wolfram\n  Burgard, Greg Shakhnarovich, Adrien Gaidon", "title": "Neural Ray Surfaces for Self-Supervised Learning of Depth and Ego-motion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning has emerged as a powerful tool for depth and\nego-motion estimation, leading to state-of-the-art results on benchmark\ndatasets. However, one significant limitation shared by current methods is the\nassumption of a known parametric camera model -- usually the standard pinhole\ngeometry -- leading to failure when applied to imaging systems that deviate\nsignificantly from this assumption (e.g., catadioptric cameras or underwater\nimaging). In this work, we show that self-supervision can be used to learn\naccurate depth and ego-motion estimation without prior knowledge of the camera\nmodel. Inspired by the geometric model of Grossberg and Nayar, we introduce\nNeural Ray Surfaces (NRS), convolutional networks that represent pixel-wise\nprojection rays, approximating a wide range of cameras. NRS are fully\ndifferentiable and can be learned end-to-end from unlabeled raw videos. We\ndemonstrate the use of NRS for self-supervised learning of visual odometry and\ndepth estimation from raw videos obtained using a wide variety of camera\nsystems, including pinhole, fisheye, and catadioptric.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 02:29:13 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Vasiljevic", "Igor", ""], ["Guizilini", "Vitor", ""], ["Ambrus", "Rares", ""], ["Pillai", "Sudeep", ""], ["Burgard", "Wolfram", ""], ["Shakhnarovich", "Greg", ""], ["Gaidon", "Adrien", ""]]}, {"id": "2008.06631", "submitter": "Yue Xing", "authors": "Yue Xing, Qifan Song, Guang Cheng", "title": "On the Generalization Properties of Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern machine learning and deep learning models are shown to be vulnerable\nwhen testing data are slightly perturbed. Existing theoretical studies of\nadversarial training algorithms mostly focus on either adversarial training\nlosses or local convergence properties. In contrast, this paper studies the\ngeneralization performance of a generic adversarial training algorithm.\nSpecifically, we consider linear regression models and two-layer neural\nnetworks (with lazy training) using squared loss under low-dimensional and\nhigh-dimensional regimes. In the former regime, after overcoming the\nnon-smoothness of adversarial training, the adversarial risk of the trained\nmodels can converge to the minimal adversarial risk. In the latter regime, we\ndiscover that data interpolation prevents the adversarially robust estimator\nfrom being consistent. Therefore, inspired by successes of the least absolute\nshrinkage and selection operator (LASSO), we incorporate the L1 penalty in the\nhigh dimensional adversarial learning and show that it leads to consistent\nadversarially robust estimation. A series of numerical studies are conducted to\ndemonstrate how the smoothness and L1 penalization help improve the adversarial\nrobustness of DNN models.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 02:32:09 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 14:19:31 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Xing", "Yue", ""], ["Song", "Qifan", ""], ["Cheng", "Guang", ""]]}, {"id": "2008.06632", "submitter": "Zahra Anvari", "authors": "Zahra Anvari, Vassilis Athitsos", "title": "Dehaze-GLCGAN: Unpaired Single Image De-hazing via Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single image de-hazing is a challenging problem, and it is far from solved.\nMost current solutions require paired image datasets that include both hazy\nimages and their corresponding haze-free ground-truth images. However, in\nreality, lighting conditions and other factors can produce a range of haze-free\nimages that can serve as ground truth for a hazy image, and a single ground\ntruth image cannot capture that range. This limits the scalability and\npracticality of paired image datasets in real-world applications. In this\npaper, we focus on unpaired single image de-hazing and we do not rely on the\nground truth image or physical scattering model. We reduce the image de-hazing\nproblem to an image-to-image translation problem and propose a dehazing\nGlobal-Local Cycle-consistent Generative Adversarial Network (Dehaze-GLCGAN).\nGenerator network of Dehaze-GLCGAN combines an encoder-decoder architecture\nwith residual blocks to better recover the haze free scene. We also employ a\nglobal-local discriminator structure to deal with spatially varying haze.\nThrough ablation study, we demonstrate the effectiveness of different factors\nin the performance of the proposed network. Our extensive experiments over\nthree benchmark datasets show that our network outperforms previous work in\nterms of PSNR and SSIM while being trained on smaller amount of data compared\nto other methods.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 02:43:00 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Anvari", "Zahra", ""], ["Athitsos", "Vassilis", ""]]}, {"id": "2008.06635", "submitter": "Chengcheng Wan", "authors": "Chengcheng Wan, Henry Hoffmann, Shan Lu, Michael Maire", "title": "Orthogonalized SGD and Nested Architectures for Anytime Neural Networks", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel variant of SGD customized for training network\narchitectures that support anytime behavior: such networks produce a series of\nincreasingly accurate outputs over time. Efficient architectural designs for\nthese networks focus on re-using internal state; subnetworks must produce\nrepresentations relevant for both immediate prediction as well as refinement by\nsubsequent network stages. We consider traditional branched networks as well as\na new class of recursively nested networks. Our new optimizer, Orthogonalized\nSGD, dynamically re-balances task-specific gradients when training a multitask\nnetwork. In the context of anytime architectures, this optimizer projects\ngradients from later outputs onto a parameter subspace that does not interfere\nwith those from earlier outputs. Experiments demonstrate that training with\nOrthogonalized SGD significantly improves generalization accuracy of anytime\nnetworks.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 03:06:34 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wan", "Chengcheng", ""], ["Hoffmann", "Henry", ""], ["Lu", "Shan", ""], ["Maire", "Michael", ""]]}, {"id": "2008.06640", "submitter": "Hongzhi Wang", "authors": "Hongzhi Wang, Yan Wei and Hao Yan", "title": "Automatic Storage Structure Selection for hybrid Workload", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the use of database systems, the design of the storage engine and data\nmodel directly affects the performance of the database when performing queries.\nTherefore, the users of the database need to select the storage engine and\ndesign data model according to the workload encountered. However, in a hybrid\nworkload, the query set of the database is dynamically changing, and the design\nof its optimal storage structure is also changing. Motivated by this, we\npropose an automatic storage structure selection system based on learning cost,\nwhich is used to dynamically select the optimal storage structure of the\ndatabase under hybrid workloads. In the system, we introduce a machine learning\nmethod to build a cost model for the storage engine, and a column-oriented data\nlayout generation algorithm. Experimental results show that the proposed system\ncan choose the optimal combination of storage engine and data model according\nto the current workload, which greatly improves the performance of the default\nstorage structure. And the system is designed to be compatible with different\nstorage engines for easy use in practical applications.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 03:42:33 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wang", "Hongzhi", ""], ["Wei", "Yan", ""], ["Yan", "Hao", ""]]}, {"id": "2008.06653", "submitter": "Alireza Makhzani", "authors": "Sicong Huang, Alireza Makhzani, Yanshuai Cao, Roger Grosse", "title": "Evaluating Lossy Compression Rates of Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of deep generative modeling has succeeded in producing\nastonishingly realistic-seeming images and audio, but quantitative evaluation\nremains a challenge. Log-likelihood is an appealing metric due to its grounding\nin statistics and information theory, but it can be challenging to estimate for\nimplicit generative models, and scalar-valued metrics give an incomplete\npicture of a model's quality. In this work, we propose to use rate distortion\n(RD) curves to evaluate and compare deep generative models. While estimating RD\ncurves is seemingly even more computationally demanding than log-likelihood\nestimation, we show that we can approximate the entire RD curve using nearly\nthe same computations as were previously used to achieve a single\nlog-likelihood estimate. We evaluate lossy compression rates of VAEs, GANs, and\nadversarial autoencoders (AAEs) on the MNIST and CIFAR10 datasets. Measuring\nthe entire RD curve gives a more complete picture than scalar-valued metrics,\nand we arrive at a number of insights not obtainable from log-likelihoods\nalone.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 05:08:28 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Huang", "Sicong", ""], ["Makhzani", "Alireza", ""], ["Cao", "Yanshuai", ""], ["Grosse", "Roger", ""]]}, {"id": "2008.06662", "submitter": "Xinyun Chen", "authors": "Xinyun Chen, Chen Liang, Adams Wei Yu, Dawn Song, Denny Zhou", "title": "Compositional Generalization via Neural-Symbolic Stack Machines", "comments": "Published in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite achieving tremendous success, existing deep learning models have\nexposed limitations in compositional generalization, the capability to learn\ncompositional rules and apply them to unseen cases in a systematic manner. To\ntackle this issue, we propose the Neural-Symbolic Stack Machine (NeSS). It\ncontains a neural network to generate traces, which are then executed by a\nsymbolic stack machine enhanced with sequence manipulation operations. NeSS\ncombines the expressive power of neural sequence models with the recursion\nsupported by the symbolic stack machine. Without training supervision on\nexecution traces, NeSS achieves 100% generalization performance in four\ndomains: the SCAN benchmark of language-driven navigation tasks, the task of\nfew-shot learning of compositional instructions, the compositional machine\ntranslation benchmark, and context-free grammar parsing tasks.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 06:23:20 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 07:16:10 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Chen", "Xinyun", ""], ["Liang", "Chen", ""], ["Yu", "Adams Wei", ""], ["Song", "Dawn", ""], ["Zhou", "Denny", ""]]}, {"id": "2008.06668", "submitter": "Yihao Feng", "authors": "Yihao Feng, Tongzheng Ren, Ziyang Tang, Qiang Liu", "title": "Accountable Off-Policy Evaluation With Kernel Bellman Statistics", "comments": "22 pages, 4 figures, ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider off-policy evaluation (OPE), which evaluates the performance of a\nnew policy from observed data collected from previous experiments, without\nrequiring the execution of the new policy. This finds important applications in\nareas with high execution cost or safety concerns, such as medical diagnosis,\nrecommendation systems and robotics. In practice, due to the limited\ninformation from off-policy data, it is highly desirable to construct rigorous\nconfidence intervals, not just point estimation, for the policy performance. In\nthis work, we propose a new variational framework which reduces the problem of\ncalculating tight confidence bounds in OPE into an optimization problem on a\nfeasible set that catches the true state-action value function with high\nprobability. The feasible set is constructed by leveraging statistical\nproperties of a recently proposed kernel Bellman loss (Feng et al., 2019). We\ndesign an efficient computational approach for calculating our bounds, and\nextend it to perform post-hoc diagnosis and correction for existing estimators.\nEmpirical results show that our method yields tight confidence intervals in\ndifferent settings.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 07:24:38 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Feng", "Yihao", ""], ["Ren", "Tongzheng", ""], ["Tang", "Ziyang", ""], ["Liu", "Qiang", ""]]}, {"id": "2008.06672", "submitter": "Nanyu Li", "authors": "Nanyu Li, Yujuan Si, Duo Deng, Chunyu Yuan", "title": "ECG beats classification via online sparse dictionary and time pyramid\n  matching", "comments": "7 pages,5 figure", "journal-ref": "17th IEEE International Conference on Communication\n  Technology(ICCT 2017)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the Bag-Of-Word (BOW) algorithm provides efficient features and\npromotes the accuracy of the ECG classification system. However, BOW algorithm\nhas two shortcomings: (1). it has large quantization errors and poor\nreconstruction performance; (2). it loses heart beat's time information, and\nmay provide confusing features for different kinds of heart beats. Furthermore,\nECG classification system can be used for long time monitoring and analysis of\ncardiovascular patients, while a huge amount of data will be produced, so we\nurgently need an efficient compression algorithm. In view of the above\nproblems, we use the wavelet feature to construct the sparse dictionary, which\nlower the quantization error to a minimum. In order to reduce the complexity of\nour algorithm and adapt to large-scale heart beats operation, we combine the\nOnline Dictionary Learning with Feature-sign algorithm to update the dictionary\nand coefficients. Coefficients matrix is used to represent ECG beats, which\ngreatly reduces the memory consumption, and solve the problem of quantitative\nerror simultaneously. Finally, we construct the pyramid to match coefficients\nof each ECG beat. Thus, we obtain the features that contain the beat time\ninformation by time stochastic pooling. It is efficient to solve the problem of\nlosing time information. The experimental results show that: on the one hand,\nthe proposed algorithm has advantages of high reconstruction performance for\nBOW, this storage method is high fidelity and low memory consumption; on the\nother hand, our algorithm yields highest accuracy in ECG beats classification;\nso this method is more suitable for large-scale heart beats data storage and\nclassification.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 08:10:21 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Li", "Nanyu", ""], ["Si", "Yujuan", ""], ["Deng", "Duo", ""], ["Yuan", "Chunyu", ""]]}, {"id": "2008.06677", "submitter": "Alessio Benavoli", "authors": "Alessio Benavoli, Dario Azzimonti, Dario Piga", "title": "Preferential Bayesian optimisation with Skew Gaussian Processes", "comments": "arXiv admin note: text overlap with arXiv:2012.06846", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preferential Bayesian optimisation (PBO) deals with optimisation problems\nwhere the objective function can only be accessed via preference judgments,\nsuch as \"this is better than that\" between two candidate solutions (like in A/B\ntests or recommender systems). The state-of-the-art approach to PBO uses a\nGaussian process to model the preference function and a Bernoulli likelihood to\nmodel the observed pairwise comparisons. Laplace's method is then employed to\ncompute posterior inferences and, in particular, to build an appropriate\nacquisition function. In this paper, we prove that the true posterior\ndistribution of the preference function is a Skew Gaussian Process (SkewGP),\nwith highly skewed pairwise marginals and, thus, show that Laplace's method\nusually provides a very poor approximation. We then derive an efficient method\nto compute the exact SkewGP posterior and use it as surrogate model for PBO\nemploying standard acquisition functions (Upper Credible Bound, etc.). We\nillustrate the benefits of our exact PBO-SkewGP in a variety of experiments, by\nshowing that it consistently outperforms PBO based on Laplace's approximation\nboth in terms of convergence speed and computational time. We also show that\nour framework can be extended to deal with mixed preferential-categorical BO,\nwhere binary judgments (valid or non-valid) together with preference judgments\nare available.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 08:23:17 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 12:17:27 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 17:46:11 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Benavoli", "Alessio", ""], ["Azzimonti", "Dario", ""], ["Piga", "Dario", ""]]}, {"id": "2008.06686", "submitter": "Eugene Valassakis", "authors": "Eugene Valassakis, Zihan Ding and Edward Johns", "title": "Crossing The Gap: A Deep Dive into Zero-Shot Sim-to-Real Transfer for\n  Dynamics", "comments": "To be published at IROS 2020. 8 pages, 6 figures. For supplementary\n  material and code, please visit :\n  https://www.robot-learning.uk/crossing-the-gap", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot sim-to-real transfer of tasks with complex dynamics is a highly\nchallenging and unsolved problem. A number of solutions have been proposed in\nrecent years, but we have found that many works do not present a thorough\nevaluation in the real world, or underplay the significant engineering effort\nand task-specific fine tuning that is required to achieve the published\nresults. In this paper, we dive deeper into the sim-to-real transfer challenge,\ninvestigate why this is such a difficult problem, and present objective\nevaluations of a number of transfer methods across a range of real-world tasks.\nSurprisingly, we found that a method which simply injects random forces into\nthe simulation performs just as well as more complex methods, such as those\nwhich randomise the simulator's dynamics parameters, or adapt a policy online\nusing recurrent network architectures.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 09:14:42 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Valassakis", "Eugene", ""], ["Ding", "Zihan", ""], ["Johns", "Edward", ""]]}, {"id": "2008.06687", "submitter": "Csongor V\\'arady", "authors": "Csongor V\\'arady (1 and 2), Riccardo Volpi (1) and Luigi Malag\\`o (1)\n  and Nihat Ay (2) ((1) Romanian Institute for Science and Technology\n  University, Cluj-Napoca, Romania, (2) Max Planck Institute for Mathematics in\n  the Sciences, Leipzig, Germany)", "title": "Natural Wake-Sleep Algorithm", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The benefits of using the natural gradient are well known in a wide range of\noptimization problems. However, for the training of common neural networks the\nresulting increase in computational complexity sets a limitation to its\npractical application. Helmholtz Machines are a particular type of generative\nmodel composed of two Sigmoid Belief Networks (SBNs), acting as an encoder and\na decoder, commonly trained using the Wake-Sleep (WS) algorithm and its\nreweighted version RWS. For SBNs, it has been shown how the locality of the\nconnections in the graphical structure induces sparsity in the Fisher\ninformation matrix. The resulting block diagonal structure can be efficiently\nexploited to reduce the computational complexity of the Fisher matrix inversion\nand thus compute the natural gradient exactly, without the need of\napproximations. We present a geometric adaptation of well-known methods from\nthe literature, introducing the Natural Wake-Sleep (NWS) and the Natural\nReweighted Wake-Sleep (NRWS) algorithms. We present an experimental analysis of\nthe novel geometrical algorithms based on the convergence speed and the value\nof the log-likelihood, both with respect to the number of iterations and the\ntime complexity and demonstrating improvements on these aspects over their\nrespective non-geometric baselines.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 09:25:32 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["V\u00e1rady", "Csongor", "", "1 and 2"], ["Volpi", "Riccardo", ""], ["Malag\u00f2", "Luigi", ""], ["Ay", "Nihat", ""]]}, {"id": "2008.06696", "submitter": "Varshit Dubey", "authors": "Varshit S. Dubey, Ruhshad Kasad and Karan Agrawal", "title": "Autonomous Braking and Throttle System: A Deep Reinforcement Learning\n  Approach for Naturalistic Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous Braking and Throttle control is key in developing safe driving\nsystems for the future. There exists a need for autonomous vehicles to\nnegotiate a multi-agent environment while ensuring safety and comfort. A Deep\nReinforcement Learning based autonomous throttle and braking system is\npresented. For each time step, the proposed system makes a decision to apply\nthe brake or throttle. The throttle and brake are modelled as continuous action\nspace values. We demonstrate 2 scenarios where there is a need for a\nsophisticated braking and throttle system, i.e when there is a static obstacle\nin front of our agent like a car, stop sign. The second scenario consists of 2\nvehicles approaching an intersection. The policies for brake and throttle\ncontrol are learned through computer simulation using Deep deterministic policy\ngradients. The experiment shows that the system not only avoids a collision,\nbut also it ensures that there is smooth change in the values of throttle/brake\nas it gets out of the emergency situation and abides by the speed regulations,\ni.e the system resembles human driving.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 10:37:07 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Dubey", "Varshit S.", ""], ["Kasad", "Ruhshad", ""], ["Agrawal", "Karan", ""]]}, {"id": "2008.06700", "submitter": "Karthik C. S.", "authors": "Vincent Cohen-Addad, Karthik C. S., and Guillaume Lagarde", "title": "On Efficient Low Distortion Ultrametric Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG cs.LG math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classic problem in unsupervised learning and data analysis is to find\nsimpler and easy-to-visualize representations of the data that preserve its\nessential properties. A widely-used method to preserve the underlying\nhierarchical structure of the data while reducing its complexity is to find an\nembedding of the data into a tree or an ultrametric. The most popular\nalgorithms for this task are the classic linkage algorithms (single, average,\nor complete). However, these methods on a data set of $n$ points in\n$\\Omega(\\log n)$ dimensions exhibit a quite prohibitive running time of\n$\\Theta(n^2)$.\n  In this paper, we provide a new algorithm which takes as input a set of\npoints $P$ in $\\mathbb{R}^d$, and for every $c\\ge 1$, runs in time\n$n^{1+\\frac{\\rho}{c^2}}$ (for some universal constant $\\rho>1$) to output an\nultrametric $\\Delta$ such that for any two points $u,v$ in $P$, we have\n$\\Delta(u,v)$ is within a multiplicative factor of $5c$ to the distance between\n$u$ and $v$ in the \"best\" ultrametric representation of $P$. Here, the best\nultrametric is the ultrametric $\\tilde\\Delta$ that minimizes the maximum\ndistance distortion with respect to the $\\ell_2$ distance, namely that\nminimizes $\\underset{u,v \\in P}{\\max}\\ \\frac{\\tilde\\Delta(u,v)}{\\|u-v\\|_2}$.\n  We complement the above result by showing that under popular complexity\ntheoretic assumptions, for every constant $\\varepsilon>0$, no algorithm with\nrunning time $n^{2-\\varepsilon}$ can distinguish between inputs in\n$\\ell_\\infty$-metric that admit isometric embedding and those that incur a\ndistortion of $\\frac{3}{2}$.\n  Finally, we present empirical evaluation on classic machine learning datasets\nand show that the output of our algorithm is comparable to the output of the\nlinkage algorithms while achieving a much faster running time.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 11:06:45 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Cohen-Addad", "Vincent", ""], ["S.", "Karthik C.", ""], ["Lagarde", "Guillaume", ""]]}, {"id": "2008.06716", "submitter": "Evgeny Frolov", "authors": "Leyla Mirvakhabova, Evgeny Frolov, Valentin Khrulkov, Ivan Oseledets,\n  Alexander Tuzhilin", "title": "Performance of Hyperbolic Geometry Models on Top-N Recommendation Tasks", "comments": "Accepted at ACM RecSys 2020; 7 pages", "journal-ref": null, "doi": "10.1145/3383313.3412219", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple autoencoder based on hyperbolic geometry for solving\nstandard collaborative filtering problem. In contrast to many modern deep\nlearning techniques, we build our solution using only a single hidden layer.\nRemarkably, even with such a minimalistic approach, we not only outperform the\nEuclidean counterpart but also achieve a competitive performance with respect\nto the current state-of-the-art. We additionally explore the effects of space\ncurvature on the quality of hyperbolic models and propose an efficient\ndata-driven method for estimating its optimal value.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 13:21:10 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Mirvakhabova", "Leyla", ""], ["Frolov", "Evgeny", ""], ["Khrulkov", "Valentin", ""], ["Oseledets", "Ivan", ""], ["Tuzhilin", "Alexander", ""]]}, {"id": "2008.06717", "submitter": "Kiran Mahesh Nd", "authors": "Kiran Mahesh ND", "title": "Site Reliability Engineering: Application of Item Response Theory to\n  Application Deployment Practices and Controls", "comments": "10 pages. Topic on software application reliability and Item Response\n  Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliability of an application or solution in production environment is one of\nthe fundamental features where every SRE team is critically focused upon. At\nthe same time achieving extreme reliability comes with the cost which include\nbut not limited to slow pace of new feature deployments, operations cost and\nopportunity cost. One such earlier effort in giving an objective metric to\nstrike the fine balance between acceptable reliability and product velocity is\nerror budget and its associated policy. There are also contemporary deployment\nguidelines and controls per organization to ascertain the reliability of an\napplication deployment version into customer facing or production environments.\nThis work proposes new objective metrics called Application Deployment Score\nestimated using dichotomous Item Response Theory model. This score is used to\nassess the improvement trend of each application version deployed into customer\nfacing environment, identify the improvement scope for each application\ndeployment in each area of deployment guidelines and controls, adjust the error\nbudget i.e. soft error budget of a interdependent application in application\nmesh by giving soft collective responsibility and finally defines a new metric\ncalled deployment index which helps to assess the effectiveness of these\ncontemporary deployment guidelines and controls in upholding the agreed SLOs of\nthe application in customer facing environments. This study opens a new field\nof research in developing new underlying latent indexes (i.e. new objective\nmetrics) in SRE and DevOps space.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 13:33:48 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["ND", "Kiran Mahesh", ""]]}, {"id": "2008.06721", "submitter": "Tariq Rahim", "authors": "Tariq Rahim, Syed Ali Hassan, Soo Young Shin", "title": "A Deep Convolutional Neural Network for the Detection of Polyps in\n  Colonoscopy Images", "comments": "21Pages,7 Figues,Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computerized detection of colonic polyps remains an unsolved issue because of\nthe wide variation in the appearance, texture, color, size, and presence of the\nmultiple polyp-like imitators during colonoscopy. In this paper, we propose a\ndeep convolutional neural network based model for the computerized detection of\npolyps within colonoscopy images. The proposed model comprises 16 convolutional\nlayers with 2 fully connected layers, and a Softmax layer, where we implement a\nunique approach using different convolutional kernels within the same hidden\nlayer for deeper feature extraction. We applied two different activation\nfunctions, MISH and rectified linear unit activation functions for deeper\npropagation of information and self regularized smooth non-monotonicity.\nFurthermore, we used a generalized intersection of union, thus overcoming\nissues such as scale invariance, rotation, and shape. Data augmentation\ntechniques such as photometric and geometric distortions are adapted to\novercome the obstacles faced in polyp detection. Detailed benchmarked results\nare provided, showing better performance in terms of precision, sensitivity,\nF1- score, F2- score, and dice-coefficient, thus proving the efficacy of the\nproposed model.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 13:55:44 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Rahim", "Tariq", ""], ["Hassan", "Syed Ali", ""], ["Shin", "Soo Young", ""]]}, {"id": "2008.06729", "submitter": "Hector Javier Hortua", "authors": "Hector J. Hortua, Luigi Malago, Riccardo Volpi", "title": "Reliable Uncertainties for Bayesian Neural Networks using\n  Alpha-divergences", "comments": "Accepted at the ICML 2020: Workshop on Uncertainty and Robustness in\n  Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Neural Networks (BNNs) often result uncalibrated after training,\nusually tending towards overconfidence. Devising effective calibration methods\nwith low impact in terms of computational complexity is thus of central\ninterest. In this paper we present calibration methods for BNNs based on the\nalpha divergences from Information Geometry. We compare the use of alpha\ndivergence in training and in calibration, and we show how the use in\ncalibration provides better calibrated uncertainty estimates for specific\nchoices of alpha and is more efficient especially for complex network\narchitectures. We empirically demonstrate the advantages of alpha calibration\nin regression problems involving parameter estimation and inferred correlations\nbetween output uncertainties.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 15:03:46 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Hortua", "Hector J.", ""], ["Malago", "Luigi", ""], ["Volpi", "Riccardo", ""]]}, {"id": "2008.06736", "submitter": "Jingfeng Wu", "authors": "Jingfeng Wu, Vladimir Braverman, Lin F. Yang", "title": "Obtaining Adjustable Regularization for Free via Iterate Averaging", "comments": "ICML 2020 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization for optimization is a crucial technique to avoid overfitting\nin machine learning. In order to obtain the best performance, we usually train\na model by tuning the regularization parameters. It becomes costly, however,\nwhen a single round of training takes significant amount of time. Very\nrecently, Neu and Rosasco show that if we run stochastic gradient descent (SGD)\non linear regression problems, then by averaging the SGD iterates properly, we\nobtain a regularized solution. It left open whether the same phenomenon can be\nachieved for other optimization problems and algorithms. In this paper, we\nestablish an averaging scheme that provably converts the iterates of SGD on an\narbitrary strongly convex and smooth objective function to its regularized\ncounterpart with an adjustable regularization parameter. Our approaches can be\nused for accelerated and preconditioned optimization methods as well. We\nfurther show that the same methods work empirically on more general\noptimization objectives including neural networks. In sum, we obtain adjustable\nregularization for free for a large class of optimization problems and resolve\nan open question raised by Neu and Rosasco.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 15:28:05 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wu", "Jingfeng", ""], ["Braverman", "Vladimir", ""], ["Yang", "Lin F.", ""]]}, {"id": "2008.06738", "submitter": "Brahma Pavse", "authors": "Brahma Pavse, Ishan Durugkar, Josiah Hanna, Peter Stone", "title": "Reducing Sampling Error in Batch Temporal Difference Learning", "comments": "Accepted to International Conference on Machine Learning (ICML) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal difference (TD) learning is one of the main foundations of modern\nreinforcement learning. This paper studies the use of TD(0), a canonical TD\nalgorithm, to estimate the value function of a given policy from a batch of\ndata. In this batch setting, we show that TD(0) may converge to an inaccurate\nvalue function because the update following an action is weighted according to\nthe number of times that action occurred in the batch -- not the true\nprobability of the action under the given policy. To address this limitation,\nwe introduce \\textit{policy sampling error corrected}-TD(0) (PSEC-TD(0)).\nPSEC-TD(0) first estimates the empirical distribution of actions in each state\nin the batch and then uses importance sampling to correct for the mismatch\nbetween the empirical weighting and the correct weighting for updates following\neach action. We refine the concept of a certainty-equivalence estimate and\nargue that PSEC-TD(0) is a more data efficient estimator than TD(0) for a fixed\nbatch of data. Finally, we conduct an empirical evaluation of PSEC-TD(0) on\nthree batch value function learning tasks, with a hyperparameter sensitivity\nanalysis, and show that PSEC-TD(0) produces value function estimates with lower\nmean squared error than TD(0).\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 15:30:06 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Pavse", "Brahma", ""], ["Durugkar", "Ishan", ""], ["Hanna", "Josiah", ""], ["Stone", "Peter", ""]]}, {"id": "2008.06755", "submitter": "David Leslie", "authors": "David Leslie", "title": "Tackling COVID-19 through Responsible AI Innovation: Five Steps in the\n  Right Direction", "comments": "Harvard Data Science Review (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Innovations in data science and AI/ML have a central role to play in\nsupporting global efforts to combat COVID-19. The versatility of AI/ML\ntechnologies enables scientists and technologists to address an impressively\nbroad range of biomedical, epidemiological, and socioeconomic challenges. This\nwide-reaching scientific capacity, however, also raises a diverse array of\nethical challenges. The need for researchers to act quickly and globally in\ntackling SARS-CoV-2 demands unprecedented practices of open research and\nresponsible data sharing at a time when innovation ecosystems are hobbled by\nproprietary protectionism, inequality, and a lack of public trust. Moreover,\nsocietally impactful interventions like digital contact tracing are raising\nfears of surveillance creep and are challenging widely held commitments to\nprivacy, autonomy, and civil liberties. Prepandemic concerns that data-driven\ninnovations may function to reinforce entrenched dynamics of societal inequity\nhave likewise intensified given the disparate impact of the virus on vulnerable\nsocial groups and the life-and-death consequences of biased and discriminatory\npublic health outcomes. To address these concerns, I offer five steps that need\nto be taken to encourage responsible research and innovation. These provide a\npractice-based path to responsible AI/ML design and discovery centered on open,\naccountable, equitable, and democratically governed processes and products.\nWhen taken from the start, these steps will not only enhance the capacity of\ninnovators to tackle COVID-19 responsibly, they will, more broadly, help to\nbetter equip the data science and AI/ML community to cope with future pandemics\nand to support a more humane, rational, and just society.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 17:26:48 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Leslie", "David", ""]]}, {"id": "2008.06767", "submitter": "Fuxun Yu", "authors": "Fuxun Yu, Weishan Zhang, Zhuwei Qin, Zirui Xu, Di Wang, Chenchen Liu,\n  Zhi Tian, Xiang Chen", "title": "Heterogeneous Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning learns from scattered data by fusing collaborative models\nfrom local nodes. However, due to chaotic information distribution, the model\nfusion may suffer from structural misalignment with regard to unmatched\nparameters. In this work, we propose a novel federated learning framework to\nresolve this issue by establishing a firm structure-information alignment\nacross collaborative models. Specifically, we design a feature-oriented\nregulation method ({$\\Psi$-Net}) to ensure explicit feature information\nallocation in different neural network structures. Applying this regulating\nmethod to collaborative models, matchable structures with similar feature\ninformation can be initialized at the very early training stage. During the\nfederated learning process under either IID or non-IID scenarios, dedicated\ncollaboration schemes further guarantee ordered information distribution with\ndefinite structure matching, so as the comprehensive model alignment.\nEventually, this framework effectively enhances the federated learning\napplicability to extensive heterogeneous settings, while providing excellent\nconvergence speed, accuracy, and computation/communication efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 19:06:59 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Yu", "Fuxun", ""], ["Zhang", "Weishan", ""], ["Qin", "Zhuwei", ""], ["Xu", "Zirui", ""], ["Wang", "Di", ""], ["Liu", "Chenchen", ""], ["Tian", "Zhi", ""], ["Chen", "Xiang", ""]]}, {"id": "2008.06775", "submitter": "Karan Goel", "authors": "Karan Goel, Albert Gu, Yixuan Li and Christopher R\\'e", "title": "Model Patching: Closing the Subgroup Performance Gap with Data\n  Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers in machine learning are often brittle when deployed. Particularly\nconcerning are models with inconsistent performance on specific subgroups of a\nclass, e.g., exhibiting disparities in skin cancer classification in the\npresence or absence of a spurious bandage. To mitigate these performance\ndifferences, we introduce model patching, a two-stage framework for improving\nrobustness that encourages the model to be invariant to subgroup differences,\nand focus on class information shared by subgroups. Model patching first models\nsubgroup features within a class and learns semantic transformations between\nthem, and then trains a classifier with data augmentations that deliberately\nmanipulate subgroup features. We instantiate model patching with CAMEL, which\n(1) uses a CycleGAN to learn the intra-class, inter-subgroup augmentations, and\n(2) balances subgroup performance using a theoretically-motivated subgroup\nconsistency regularizer, accompanied by a new robust objective. We demonstrate\nCAMEL's effectiveness on 3 benchmark datasets, with reductions in robust error\nof up to 33% relative to the best baseline. Lastly, CAMEL successfully patches\na model that fails due to spurious features on a real-world skin cancer\ndataset.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 20:01:23 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Goel", "Karan", ""], ["Gu", "Albert", ""], ["Li", "Yixuan", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2008.06780", "submitter": "Francesco La Rosa", "authors": "Francesco La Rosa, Erin S Beck, Ahmed Abdulkadir, Jean-Philippe\n  Thiran, Daniel S Reich, Pascal Sati, Meritxell Bach Cuadra", "title": "Automated Detection of Cortical Lesions in Multiple Sclerosis Patients\n  with 7T MRI", "comments": "Accepted to MICCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automated detection of cortical lesions (CLs) in patients with multiple\nsclerosis (MS) is a challenging task that, despite its clinical relevance, has\nreceived very little attention. Accurate detection of the small and scarce\nlesions requires specialized sequences and high or ultra-high field MRI. For\nsupervised training based on multimodal structural MRI at 7T, two experts\ngenerated ground truth segmentation masks of 60 patients with 2014 CLs. We\nimplemented a simplified 3D U-Net with three resolution levels (3D U-Net-). By\nincreasing the complexity of the task (adding brain tissue segmentation), while\nrandomly dropping input channels during training, we improved the performance\ncompared to the baseline. Considering a minimum lesion size of 0.75 {\\mu}L, we\nachieved a lesion-wise cortical lesion detection rate of 67% and a false\npositive rate of 42%. However, 393 (24%) of the lesions reported as false\npositives were post-hoc confirmed as potential or definite lesions by an\nexpert. This indicates the potential of the proposed method to support experts\nin the tedious process of CL manual segmentation.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 20:35:12 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["La Rosa", "Francesco", ""], ["Beck", "Erin S", ""], ["Abdulkadir", "Ahmed", ""], ["Thiran", "Jean-Philippe", ""], ["Reich", "Daniel S", ""], ["Sati", "Pascal", ""], ["Cuadra", "Meritxell Bach", ""]]}, {"id": "2008.06785", "submitter": "Alex Berian", "authors": "Alex Berian, Kory Staab, Noel Teku, Gregory Ditzler, Tamal Bose, Ravi\n  Tandon", "title": "Adversarial Filters for Secure Modulation Classification", "comments": "This is a placeholder to show that we are the first to do something\n  like this. We intend to submit this work to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Modulation Classification (MC) refers to the problem of classifying the\nmodulation class of a wireless signal. In the wireless communications pipeline,\nMC is the first operation performed on the received signal and is critical for\nreliable decoding. This paper considers the problem of secure modulation\nclassification, where a transmitter (Alice) wants to maximize MC accuracy at a\nlegitimate receiver (Bob) while minimizing MC accuracy at an eavesdropper\n(Eve).\n  The contribution of this work is to design novel adversarial learning\ntechniques for secure MC. In particular, we present adversarial filtering based\nalgorithms for secure MC, in which Alice uses a carefully designed adversarial\nfilter to mask the transmitted signal, that can maximize MC accuracy at Bob\nwhile minimizing MC accuracy at Eve. We present two filtering based algorithms,\nnamely gradient ascent filter (GAF), and a fast gradient filter method (FGFM),\nwith varying levels of complexity.\n  Our proposed adversarial filtering based approaches significantly outperform\nadditive adversarial perturbations (used in the traditional ML community and\nother prior works on secure MC) and also have several other desirable\nproperties. In particular, GAF and FGFM algorithms are a) computational\nefficient (allow fast decoding at Bob), b) power-efficient (do not require\nexcessive transmit power at Alice); and c) SNR efficient (i.e., perform well\neven at low SNR values at Bob).\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 20:51:54 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Berian", "Alex", ""], ["Staab", "Kory", ""], ["Teku", "Noel", ""], ["Ditzler", "Gregory", ""], ["Bose", "Tamal", ""], ["Tandon", "Ravi", ""]]}, {"id": "2008.06786", "submitter": "Ben Adlam", "authors": "Ben Adlam and Jeffrey Pennington", "title": "The Neural Tangent Kernel in High Dimensions: Triple Descent and a\n  Multi-Scale Theory of Generalization", "comments": "Published as a conference paper in the Proceedings of the 37th\n  International Conference on Machine Learning; 31 pages; 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep learning models employ considerably more parameters than required\nto fit the training data. Whereas conventional statistical wisdom suggests such\nmodels should drastically overfit, in practice these models generalize\nremarkably well. An emerging paradigm for describing this unexpected behavior\nis in terms of a \\emph{double descent} curve, in which increasing a model's\ncapacity causes its test error to first decrease, then increase to a maximum\nnear the interpolation threshold, and then decrease again in the\noverparameterized regime. Recent efforts to explain this phenomenon\ntheoretically have focused on simple settings, such as linear regression or\nkernel regression with unstructured random features, which we argue are too\ncoarse to reveal important nuances of actual neural networks. We provide a\nprecise high-dimensional asymptotic analysis of generalization under kernel\nregression with the Neural Tangent Kernel, which characterizes the behavior of\nwide neural networks optimized with gradient descent. Our results reveal that\nthe test error has non-monotonic behavior deep in the overparameterized regime\nand can even exhibit additional peaks and descents when the number of\nparameters scales quadratically with the dataset size.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 20:55:40 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Adlam", "Ben", ""], ["Pennington", "Jeffrey", ""]]}, {"id": "2008.06798", "submitter": "Geoffrey Yu", "authors": "Geoffrey X. Yu, Tovi Grossman, Gennady Pekhimenko", "title": "Skyline: Interactive In-Editor Computational Performance Profiling for\n  Deep Neural Network Training", "comments": "14 pages, 5 figures. Appears in the proceedings of UIST'20", "journal-ref": null, "doi": "10.1145/3379337.3415890", "report-no": null, "categories": "cs.HC cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a state-of-the-art deep neural network (DNN) is a\ncomputationally-expensive and time-consuming process, which incentivizes deep\nlearning developers to debug their DNNs for computational performance. However,\neffectively performing this debugging requires intimate knowledge about the\nunderlying software and hardware systems---something that the typical deep\nlearning developer may not have. To help bridge this gap, we present Skyline: a\nnew interactive tool for DNN training that supports in-editor computational\nperformance profiling, visualization, and debugging. Skyline's key contribution\nis that it leverages special computational properties of DNN training to\nprovide (i) interactive performance predictions and visualizations, and (ii)\ndirectly manipulatable visualizations that, when dragged, mutate the batch size\nin the code. As an in-editor tool, Skyline allows users to leverage these\ndiagnostic features to debug the performance of their DNNs during development.\nAn exploratory qualitative user study of Skyline produced promising results;\nall the participants found Skyline to be useful and easy to use.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 22:17:00 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 14:57:58 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Yu", "Geoffrey X.", ""], ["Grossman", "Tovi", ""], ["Pekhimenko", "Gennady", ""]]}, {"id": "2008.06799", "submitter": "Divyanshu Marwah", "authors": "Divyanshu Marwah, Sneha Srivastava, Anusha Gupta, Shruti Verma", "title": "Chrome Dino Run using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning is one of the most advanced set of algorithms known to\nmankind which can compete in games and perform at par or even better than\nhumans. In this paper we study most popular model free reinforcement learning\nalgorithms along with convolutional neural network to train the agent for\nplaying the game of Chrome Dino Run. We have used two of the popular temporal\ndifference approaches namely Deep Q-Learning, and Expected SARSA and also\nimplemented Double DQN model to train the agent and finally compare the scores\nwith respect to the episodes and convergence of algorithms with respect to\ntimesteps.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 22:18:20 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Marwah", "Divyanshu", ""], ["Srivastava", "Sneha", ""], ["Gupta", "Anusha", ""], ["Verma", "Shruti", ""]]}, {"id": "2008.06808", "submitter": "Jayden Ooi", "authors": "Henry Tsai, Jayden Ooi, Chun-Sung Ferng, Hyung Won Chung, Jason Riesa", "title": "Finding Fast Transformers: One-Shot Neural Architecture Search by\n  Component Composition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Transformer-based models have achieved stateof-the-art results in many tasks\nin natural language processing. However, such models are usually slow at\ninference time, making deployment difficult. In this paper, we develop an\nefficient algorithm to search for fast models while maintaining model quality.\nWe describe a novel approach to decompose the Transformer architecture into\nsmaller components, and propose a sampling-based one-shot architecture search\nmethod to find an optimal model for inference. The model search process is more\nefficient than alternatives, adding only a small overhead to training time. By\napplying our methods to BERT-base architectures, we achieve 10% to 30% speedup\nfor pre-trained BERT and 70% speedup on top of a previous state-of-the-art\ndistilled BERT model on Cloud TPU-v2 with a generally acceptable drop in\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 23:12:25 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Tsai", "Henry", ""], ["Ooi", "Jayden", ""], ["Ferng", "Chun-Sung", ""], ["Chung", "Hyung Won", ""], ["Riesa", "Jason", ""]]}, {"id": "2008.06822", "submitter": "Sizhe Chen", "authors": "Sizhe Chen, Fan He, Xiaolin Huang, Kun Zhang", "title": "Relevance Attack on Detectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on high-transferable adversarial attacks on detectors,\nwhich are hard to attack in a black-box manner, because of their\nmultiple-output characteristics and the diversity across architectures. To\npursue a high attack transferability, one plausible way is to find a common\nproperty across detectors, which facilitates the discovery of common\nweaknesses. We are the first to suggest that the relevance map from\ninterpreters for detectors is such a property. Based on it, we design a\nRelevance Attack on Detectors (RAD), which achieves a state-of-the-art\ntransferability, exceeding existing results by above 20%. On MS COCO, the\ndetection mAPs for all 8 black-box architectures are more than halved and the\nsegmentation mAPs are also significantly influenced. Given the great\ntransferability of RAD, we generate the first adversarial dataset for object\ndetection and instance segmentation, i.e., Adversarial Objects in COntext\n(AOCO), which helps to quickly evaluate and improve the robustness of\ndetectors.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 02:44:25 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 06:27:56 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Chen", "Sizhe", ""], ["He", "Fan", ""], ["Huang", "Xiaolin", ""], ["Zhang", "Kun", ""]]}, {"id": "2008.06828", "submitter": "Nguyen Quoc Khanh Le Dr.", "authors": "Hieu X. Le, Phuong D. Nguyen, Thang H. Nguyen, Khanh N.Q. Le, Thanh T.\n  Nguyen", "title": "A novel approach to remove foreign objects from chest X-ray images", "comments": "9 pages, 7 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initially proposed a deep learning approach for foreign objects inpainting\nin smartphone-camera captured chest radiographs utilizing the cheXphoto\ndataset. Foreign objects which can significantly affect the quality of a\ncomputer-aided diagnostic prediction are captured under various settings. In\nthis paper, we used multi-method to tackle both removal and inpainting chest\nradiographs. Firstly, an object detection model is trained to separate the\nforeign objects from the given image. Subsequently, the binary mask of each\nobject is extracted utilizing a segmentation model. Each pair of the binary\nmask and the extracted object are then used for inpainting purposes. Finally,\nthe in-painted regions are now merged back to the original image, resulting in\na clean and non-foreign-object-existing output. To conclude, we achieved\nstate-of-the-art accuracy. The experimental results showed a new approach to\nthe possible applications of this method for chest X-ray images detection.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 03:06:28 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Le", "Hieu X.", ""], ["Nguyen", "Phuong D.", ""], ["Nguyen", "Thang H.", ""], ["Le", "Khanh N. Q.", ""], ["Nguyen", "Thanh T.", ""]]}, {"id": "2008.06831", "submitter": "Tin Vu", "authors": "Tin Vu, Ahmed Eldawy", "title": "DeepSampling: Selectivity Estimation with Predicted Error and Response\n  Time", "comments": "9 pages, published in DeepSpatial 2020", "journal-ref": "ACM SIGKDD Workshop on Deep Learning for Spatiotemporal Data,\n  Applications, and Systems, 2020", "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of spatial data urges the research community to find\nefficient processing techniques for interactive queries on large volumes of\ndata. Approximate Query Processing (AQP) is the most prominent technique that\ncan provide real-time answer for ad-hoc queries based on a random sample.\nUnfortunately, existing AQP methods provide an answer without providing any\naccuracy metrics due to the complex relationship between the sample size, the\nquery parameters, the data distribution, and the result accuracy. This paper\nproposes DeepSampling, a deep-learning-based model that predicts the accuracy\nof a sample-based AQP algorithm, specially selectivity estimation, given the\nsample size, the input distribution, and query parameters. The model can also\nbe reversed to measure the sample size that would produce a desired accuracy.\nDeepSampling is the first system that provides a reliable tool for existing\nspatial databases to control the accuracy of AQP.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 03:23:01 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Vu", "Tin", ""], ["Eldawy", "Ahmed", ""]]}, {"id": "2008.06853", "submitter": "Ce Ju", "authors": "Ce Ju", "title": "Geometric Foundations of Data Reduction", "comments": "79 pages, Suvery", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to write a complete survey of the (spectral)\nmanifold learning methods and nonlinear dimensionality reduction (NLDR) in data\nreduction. The first two NLDR methods in history were respectively published in\nScience in 2000 in which they solve the similar reduction problem of\nhigh-dimensional data endowed with the intrinsic nonlinear structure. The\nintrinsic nonlinear structure is always interpreted as a concept in manifolds\nfrom geometry and topology in theoretical mathematics by computer scientists\nand theoretical physicists. In 2001, the concept of Manifold Learning first\nappears as an NLDR method called Laplacian Eigenmaps purposed by Belkin and\nNiyogi. In the typical manifold learning setup, the data set, also called the\nobservation set, is distributed on or near a low dimensional manifold $M$\nembedded in $\\mathbb{R}^D$, which yields that each observation has a\n$D$-dimensional representation. The goal of (spectral) manifold learning is to\nreduce these observations as a compact lower-dimensional representation based\non the geometric information. The reduction procedure is called the (spectral)\nmanifold learning method. In this paper, we derive each (spectral) manifold\nlearning method with the matrix and operator representation, and we then\ndiscuss the convergence behavior of each method in a geometric uniform\nlanguage. Hence, we name the survey Geometric Foundations of Data Reduction.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 07:59:22 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Ju", "Ce", ""]]}, {"id": "2008.06856", "submitter": "Guy Amit", "authors": "Guy Amit, Moshe Levy, Ishai Rosenberg, Asaf Shabtai, Yuval Elovici", "title": "FOOD: Fast Out-Of-Distribution Detector", "comments": "Guy Amit and Moshe Levy contributed equally to this paper Updated\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) perform well at classifying inputs associated\nwith the classes they have been trained on, which are known as in distribution\ninputs. However, out-of-distribution (OOD) inputs pose a great challenge to\nDNNs and consequently represent a major risk when DNNs are implemented in\nsafety-critical systems. Extensive research has been performed in the domain of\nOOD detection. However, current state-of-the-art methods for OOD detection\nsuffer from at least one of the following limitations: (1) increased inference\ntime - this limits existing methods' applicability to many real-world\napplications, and (2) the need for OOD training data - such data can be\ndifficult to acquire and may not be representative enough, thus limiting the\nability of the OOD detector to generalize. In this paper, we propose FOOD --\nFast Out-Of-Distribution detector -- an extended DNN classifier capable of\nefficiently detecting OOD samples with minimal inference time overhead. Our\narchitecture features a DNN with a final Gaussian layer combined with the log\nlikelihood ratio statistical test and an additional output neuron for OOD\ndetection. Instead of using real OOD data, we use a novel method to craft\nartificial OOD samples from in-distribution data, which are used to train our\nOOD detector neuron. We evaluate FOOD's detection performance on the SVHN,\nCIFAR-10, and CIFAR-100 datasets. Our results demonstrate that in addition to\nachieving state-of-the-art performance, FOOD is fast and applicable to\nreal-world applications.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 08:22:43 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 11:48:23 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 15:41:10 GMT"}, {"version": "v4", "created": "Tue, 23 Feb 2021 16:19:52 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Amit", "Guy", ""], ["Levy", "Moshe", ""], ["Rosenberg", "Ishai", ""], ["Shabtai", "Asaf", ""], ["Elovici", "Yuval", ""]]}, {"id": "2008.06860", "submitter": "Sachin Saxena", "authors": "Sachin Saxena", "title": "TextDecepter: Hard Label Black Box Attack on Text Classifiers", "comments": "10 pages, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has been proven to be susceptible to carefully crafted\nsamples, known as adversarial examples. The generation of these adversarial\nexamples helps to make the models more robust and gives us an insight into the\nunderlying decision-making of these models. Over the years, researchers have\nsuccessfully attacked image classifiers in both, white and black-box settings.\nHowever, these methods are not directly applicable to texts as text data is\ndiscrete. In recent years, research on crafting adversarial examples against\ntextual applications has been on the rise. In this paper, we present a novel\napproach for hard-label black-box attacks against Natural Language Processing\n(NLP) classifiers, where no model information is disclosed, and an attacker can\nonly query the model to get a final decision of the classifier, without\nconfidence scores of the classes involved. Such an attack scenario applies to\nreal-world black-box models being used for security-sensitive applications such\nas sentiment analysis and toxic content detection.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 08:57:01 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 00:06:56 GMT"}, {"version": "v3", "created": "Fri, 27 Nov 2020 02:27:55 GMT"}, {"version": "v4", "created": "Sat, 19 Dec 2020 23:01:13 GMT"}, {"version": "v5", "created": "Tue, 22 Dec 2020 03:21:17 GMT"}, {"version": "v6", "created": "Mon, 28 Dec 2020 00:23:08 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Saxena", "Sachin", ""]]}, {"id": "2008.06866", "submitter": "Angel Ayala", "authors": "Angel Ayala, Bruno Fernandes, Francisco Cruz, David Mac\\^edo, Adriano\n  L. I. Oliveira, and Cleber Zanchettin", "title": "KutralNet: A Portable Deep Learning Model for Fire Recognition", "comments": "Accepted in the IEEE International Joint Conference on Neural\n  Networks (IJCNN), 2020", "journal-ref": "2020 International Joint Conference on Neural Networks (IJCNN)", "doi": "10.1109/IJCNN48605.2020.9207202", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the automatic fire alarm systems detect the fire presence through\nsensors like thermal, smoke, or flame. One of the new approaches to the problem\nis the use of images to perform the detection. The image approach is promising\nsince it does not need specific sensors and can be easily embedded in different\ndevices. However, besides the high performance, the computational cost of the\nused deep learning methods is a challenge to their deployment in portable\ndevices. In this work, we propose a new deep learning architecture that\nrequires fewer floating-point operations (flops) for fire recognition.\nAdditionally, we propose a portable approach for fire recognition and the use\nof modern techniques such as inverted residual block, convolutions like\ndepth-wise, and octave, to reduce the model's computational cost. The\nexperiments show that our model keeps high accuracy while substantially\nreducing the number of parameters and flops. One of our models presents 71\\%\nfewer parameters than FireNet, while still presenting competitive accuracy and\nAUROC performance. The proposed methods are evaluated on FireNet and FiSmo\ndatasets. The obtained results are promising for the implementation of the\nmodel in a mobile device, considering the reduced number of flops and\nparameters acquired.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 09:35:25 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Ayala", "Angel", ""], ["Fernandes", "Bruno", ""], ["Cruz", "Francisco", ""], ["Mac\u00eado", "David", ""], ["Oliveira", "Adriano L. I.", ""], ["Zanchettin", "Cleber", ""]]}, {"id": "2008.06869", "submitter": "Ralph Foorthuis", "authors": "Ralph Foorthuis", "title": "SECODA: Segmentation- and Combination-Based Detection of Anomalies", "comments": "12 pages (including DSAA conference poster), 9 figures, 3 tables.\n  Presented at DSAA 2017, the IEEE International Conference on Data Science and\n  Advanced Analytics", "journal-ref": null, "doi": "10.1109/DSAA.2017.35", "report-no": null, "categories": "cs.DB cs.AI cs.LG stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study introduces SECODA, a novel general-purpose unsupervised\nnon-parametric anomaly detection algorithm for datasets containing continuous\nand categorical attributes. The method is guaranteed to identify cases with\nunique or sparse combinations of attribute values. Continuous attributes are\ndiscretized repeatedly in order to correctly determine the frequency of such\nvalue combinations. The concept of constellations, exponentially increasing\nweights and discretization cut points, as well as a pruning heuristic are used\nto detect anomalies with an optimal number of iterations. Moreover, the\nalgorithm has a low memory imprint and its runtime performance scales linearly\nwith the size of the dataset. An evaluation with simulated and real-life\ndatasets shows that this algorithm is able to identify many different types of\nanomalies, including complex multidimensional instances. An evaluation in terms\nof a data quality use case with a real dataset demonstrates that SECODA can\nbring relevant and practical value to real-world settings.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 10:03:14 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Foorthuis", "Ralph", ""]]}, {"id": "2008.06877", "submitter": "Meysam Asgari-Chenaghlu", "authors": "Meysam Asgari-Chenaghlu, Mohammad-Reza Feizi-Derakhshi, Leili\n  farzinvash, Mohammad-Ali Balafar, Cina Motamed", "title": "TopicBERT: A Transformer transfer learning based memory-graph approach\n  for multimodal streaming social media topic detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real time nature of social networks with bursty short messages and their\nrespective large data scale spread among vast variety of topics are research\ninterest of many researchers. These properties of social networks which are\nknown as 5'Vs of big data has led to many unique and enlightenment algorithms\nand techniques applied to large social networking datasets and data streams.\nMany of these researches are based on detection and tracking of hot topics and\ntrending social media events that help revealing many unanswered questions.\nThese algorithms and in some cases software products mostly rely on the nature\nof the language itself. Although, other techniques such as unsupervised data\nmining methods are language independent but many requirements for a\ncomprehensive solution are not met. Many research issues such as noisy\nsentences that adverse grammar and new online user invented words are\nchallenging maintenance of a good social network topic detection and tracking\nmethodology; The semantic relationship between words and in most cases,\nsynonyms are also ignored by many of these researches. In this research, we use\nTransformers combined with an incremental community detection algorithm.\nTransformer in one hand, provides the semantic relation between words in\ndifferent contexts. On the other hand, the proposed graph mining technique\nenhances the resulting topics with aid of simple structural rules. Named entity\nrecognition from multimodal data, image and text, labels the named entities\nwith entity type and the extracted topics are tuned using them. All operations\nof proposed system has been applied with big social data perspective under\nNoSQL technologies. In order to present a working and systematic solution, we\ncombined MongoDB with Neo4j as two major database systems of our work. The\nproposed system shows higher precision and recall compared to other methods in\nthree different datasets.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 10:39:50 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Asgari-Chenaghlu", "Meysam", ""], ["Feizi-Derakhshi", "Mohammad-Reza", ""], ["farzinvash", "Leili", ""], ["Balafar", "Mohammad-Ali", ""], ["Motamed", "Cina", ""]]}, {"id": "2008.06885", "submitter": "Tsuyoshi Kato", "authors": "Takahiko Henmi, Esmeraldo Ronnie Rey Zara, Yoshihiro Hirohashi,\n  Tsuyoshi Kato", "title": "Adaptive Signal Variances: CNN Initialization Through Modern\n  Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNN) have achieved the unwavering\nconfidence in its performance on image processing tasks. The CNN architecture\nconstitutes a variety of different types of layers including the convolution\nlayer and the max-pooling layer. CNN practitioners widely understand the fact\nthat the stability of learning depends on how to initialize the model\nparameters in each layer. Nowadays, no one doubts that the de facto standard\nscheme for initialization is the so-called Kaiming initialization that has been\ndeveloped by He et al. The Kaiming scheme was derived from a much simpler model\nthan the currently used CNN structure having evolved since the emergence of the\nKaiming scheme. The Kaiming model consists only of the convolution and fully\nconnected layers, ignoring the max-pooling layer and the global average pooling\nlayer. In this study, we derived the initialization scheme again not from the\nsimplified Kaiming model, but precisely from the modern CNN architectures, and\nempirically investigated how the new initialization method performs compared to\nthe de facto standard ones that are widely used today.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 11:26:29 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 06:11:44 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Henmi", "Takahiko", ""], ["Zara", "Esmeraldo Ronnie Rey", ""], ["Hirohashi", "Yoshihiro", ""], ["Kato", "Tsuyoshi", ""]]}, {"id": "2008.06924", "submitter": "Li Zhou", "authors": "Li Zhou and Kevin Small", "title": "Inverse Reinforcement Learning with Natural Language Goals", "comments": "To appear in Proceedings of the 35th AAAI Conference on Artificial\n  Intelligence (AAAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans generally use natural language to communicate task requirements to\neach other. Ideally, natural language should also be usable for communicating\ngoals to autonomous machines (e.g., robots) to minimize friction in task\nspecification. However, understanding and mapping natural language goals to\nsequences of states and actions is challenging. Specifically, existing work\nalong these lines has encountered difficulty in generalizing learned policies\nto new natural language goals and environments. In this paper, we propose a\nnovel adversarial inverse reinforcement learning algorithm to learn a\nlanguage-conditioned policy and reward function. To improve generalization of\nthe learned policy and reward function, we use a variational goal generator to\nrelabel trajectories and sample diverse goals during training. Our algorithm\noutperforms multiple baselines by a large margin on a vision-based natural\nlanguage instruction following dataset (Room-2-Room), demonstrating a promising\nadvance in enabling the use of natural language instructions in specifying\nagent goals.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 14:43:49 GMT"}, {"version": "v2", "created": "Sat, 22 Aug 2020 02:44:41 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 04:40:17 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Zhou", "Li", ""], ["Small", "Kevin", ""]]}, {"id": "2008.06933", "submitter": "Anna Bogomolova", "authors": "Anna Bogomolova, Kseniia Kingsep and Boris Voskresenskii", "title": "The reinforcement learning-based multi-agent cooperative approach for\n  the adaptive speed regulation on a metallurgical pickling line", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a holistic data-driven approach to the problem of productivity\nincrease on the example of a metallurgical pickling line. The proposed approach\ncombines mathematical modeling as a base algorithm and a cooperative\nMulti-Agent Reinforcement Learning (MARL) system implemented such as to enhance\nthe performance by multiple criteria while also meeting safety and reliability\nrequirements and taking into account the unexpected volatility of certain\ntechnological processes. We demonstrate how Deep Q-Learning can be applied to a\nreal-life task in a heavy industry, resulting in significant improvement of\npreviously existing automation systems.The problem of input data scarcity is\nsolved by a two-step combination of LSTM and CGAN, which helps to embrace both\nthe tabular representation of the data and its sequential properties. Offline\nRL training, a necessity in this setting, has become possible through the\nsophisticated probabilistic kinematic environment.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 15:10:39 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Bogomolova", "Anna", ""], ["Kingsep", "Kseniia", ""], ["Voskresenskii", "Boris", ""]]}, {"id": "2008.06937", "submitter": "Brian Gardner BG", "authors": "Brian Gardner, Andr\\'e Gr\\\"uning", "title": "Supervised Learning with First-to-Spike Decoding in Multilayer Spiking\n  Neural Networks", "comments": "41 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental studies support the notion of spike-based neuronal information\nprocessing in the brain, with neural circuits exhibiting a wide range of\ntemporally-based coding strategies to rapidly and efficiently represent sensory\nstimuli. Accordingly, it would be desirable to apply spike-based computation to\ntackling real-world challenges, and in particular transferring such theory to\nneuromorphic systems for low-power embedded applications. Motivated by this, we\npropose a new supervised learning method that can train multilayer spiking\nneural networks to solve classification problems based on a rapid,\nfirst-to-spike decoding strategy. The proposed learning rule supports multiple\nspikes fired by stochastic hidden neurons, and yet is stable by relying on\nfirst-spike responses generated by a deterministic output layer. In addition to\nthis, we also explore several distinct, spike-based encoding strategies in\norder to form compact representations of presented input data. We demonstrate\nthe classification performance of the learning rule as applied to several\nbenchmark datasets, including MNIST. The learning rule is capable of\ngeneralising from the data, and is successful even when used with constrained\nnetwork architectures containing few input and hidden layer neurons.\nFurthermore, we highlight a novel encoding strategy, termed `scanline\nencoding', that can transform image data into compact spatiotemporal patterns\nfor subsequent network processing. Designing constrained, but optimised,\nnetwork structures and performing input dimensionality reduction has strong\nimplications for neuromorphic applications.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 15:34:48 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Gardner", "Brian", ""], ["Gr\u00fcning", "Andr\u00e9", ""]]}, {"id": "2008.06940", "submitter": "Khushnood Abbas", "authors": "Khushnood Abbas, Alireza Abbasi, Dong Shi, Niu Ling, Mingsheng Shang,\n  Chen Liong, and Bolun Chen", "title": "TempNodeEmb:Temporal Node Embedding considering temporal edge influence\n  matrix", "comments": "IEEE double column 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the evolutionary patterns of real-world evolving complex\nsystems such as human interactions, transport networks, biological\ninteractions, and computer networks has important implications in our daily\nlives. Predicting future links among the nodes in such networks reveals an\nimportant aspect of the evolution of temporal networks. To analyse networks,\nthey are mapped to adjacency matrices, however, a single adjacency matrix\ncannot represent complex relationships (e.g. temporal pattern), and therefore,\nsome approaches consider a simplified representation of temporal networks but\nin high-dimensional and generally sparse matrices. As a result, adjacency\nmatrices cannot be directly used by machine learning models for making network\nor node level predictions. To overcome this problem, automated frameworks are\nproposed for learning low-dimensional vectors for nodes or edges, as\nstate-of-the-art techniques in predicting temporal patterns in networks such as\nlink prediction. However, these models fail to consider temporal dimensions of\nthe networks. This gap motivated us to propose in this research a new node\nembedding technique which exploits the evolving nature of the networks\nconsidering a simple three-layer graph neural network at each time step, and\nextracting node orientation by Given's angle method. To prove our proposed\nalgorithm's efficiency, we evaluated the efficiency of our proposed algorithm\nagainst six state-of-the-art benchmark network embedding models, on four real\ntemporal networks data, and the results show our model outperforms other\nmethods in predicting future links in temporal networks.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 15:39:07 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Abbas", "Khushnood", ""], ["Abbasi", "Alireza", ""], ["Shi", "Dong", ""], ["Ling", "Niu", ""], ["Shang", "Mingsheng", ""], ["Liong", "Chen", ""], ["Chen", "Bolun", ""]]}, {"id": "2008.06952", "submitter": "Aaron Zweig", "authors": "Aaron Zweig, Joan Bruna", "title": "A Functional Perspective on Learning Symmetric Functions with Neural\n  Networks", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symmetric functions, which take as input an unordered, fixed-size set, are\nknown to be universally representable by neural networks that enforce\npermutation invariance. These architectures only give guarantees for fixed\ninput sizes, yet in many practical applications, including point clouds and\nparticle physics, a relevant notion of generalization should include varying\nthe input size. In this work we treat symmetric functions (of any size) as\nfunctions over probability measures, and study the learning and representation\nof neural networks defined on measures. By focusing on shallow architectures,\nwe establish approximation and generalization bounds under different choices of\nregularization (such as RKHS and variation norms), that capture a hierarchy of\nfunctional spaces with increasing degree of non-linear learning. The resulting\nmodels can be learned efficiently and enjoy generalization guarantees that\nextend across input sizes, as we verify empirically.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 16:34:33 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 15:50:04 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 22:50:58 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Zweig", "Aaron", ""], ["Bruna", "Joan", ""]]}, {"id": "2008.06971", "submitter": "Sajid Gul Khawaja", "authors": "Asad Mansoor Khan, Ayesha Sadiq, Sajid Gul Khawaja, Muhammad Usman\n  Akram, Ali Saeed", "title": "Physical Action Categorization using Signal Analysis and Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Daily life of thousands of individuals around the globe suffers due to\nphysical or mental disability related to limb movement. The quality of life for\nsuch individuals can be made better by use of assistive applications and\nsystems. In such scenario, mapping of physical actions from movement to a\ncomputer aided application can lead the way for solution. Surface\nElectromyography (sEMG) presents a non-invasive mechanism through which we can\ntranslate the physical movement to signals for classification and use in\napplications. In this paper, we propose a machine learning based framework for\nclassification of 4 physical actions. The framework looks into the various\nfeatures from different modalities which contribution from time domain,\nfrequency domain, higher order statistics and inter channel statistics. Next,\nwe conducted a comparative analysis of k-NN, SVM and ELM classifier using the\nfeature set. Effect of different combinations of feature set has also been\nrecorded. Finally, the classifier accuracy with SVM and 1-NN based classifier\nfor a subset of features gives an accuracy of 95.21 and 95.83 respectively.\nAdditionally, we have also proposed that dimensionality reduction by use of PCA\nleads to only a minor drop of less than 5.55% in accuracy while using only\n9.22% of the original feature set. These finding are useful for algorithm\ndesigner to choose the best approach keeping in mind the resources available\nfor execution of algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 18:43:00 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Khan", "Asad Mansoor", ""], ["Sadiq", "Ayesha", ""], ["Khawaja", "Sajid Gul", ""], ["Akram", "Muhammad Usman", ""], ["Saeed", "Ali", ""]]}, {"id": "2008.06973", "submitter": "Mansoor Rezghi", "authors": "S. Amirreza Badran, Mansoor Rezghi", "title": "An adaptive synchronization approach for weights of deep reinforcement\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Q-Networks (DQN) is one of the most well-known methods of deep\nreinforcement learning, which uses deep learning to approximate the\naction-value function. Solving numerous Deep reinforcement learning challenges\nsuch as moving targets problem and the correlation between samples are the main\nadvantages of this model. Although there have been various extensions of DQN in\nrecent years, they all use a similar method to DQN to overcome the problem of\nmoving targets. Despite the advantages mentioned, synchronizing the network\nweight in a fixed step size, independent of the agent's behavior, may in some\ncases cause the loss of some properly learned networks. These lost networks may\nlead to states with more rewards, hence better samples stored in the replay\nmemory for future training. In this paper, we address this problem from the DQN\nfamily and provide an adaptive approach for the synchronization of the neural\nweights used in DQN. In this method, the synchronization of weights is done\nbased on the recent behavior of the agent, which is measured by a criterion at\nthe end of the intervals. To test this method, we adjusted the DQN and rainbow\nmethods with the proposed adaptive synchronization method. We compared these\nadjusted methods with their standard form on well-known games, which results\nconfirm the quality of our synchronization methods.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 18:49:35 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Badran", "S. Amirreza", ""], ["Rezghi", "Mansoor", ""]]}, {"id": "2008.06974", "submitter": "Mona Jalal", "authors": "Alyssa Smith, David Assefa Tofu, Mona Jalal, Edward Edberg Halim,\n  Yimeng Sun, Vidya Akavoor, Margrit Betke, Prakash Ishwar, Lei Guo, Derry\n  Wijaya", "title": "OpenFraming: We brought the ML; you bring the data. Interact with your\n  data and discover its frames", "comments": "8 pages, 8 figures, EMNLP 2020 demonstration papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When journalists cover a news story, they can cover the story from multiple\nangles or perspectives. A news article written about COVID-19 for example,\nmight focus on personal preventative actions such as mask-wearing, while\nanother might focus on COVID-19's impact on the economy. These perspectives are\ncalled \"frames,\" which when used may influence public perception and opinion of\nthe issue. We introduce a Web-based system for analyzing and classifying frames\nin text documents. Our goal is to make effective tools for automatic frame\ndiscovery and labeling based on topic modeling and deep learning widely\naccessible to researchers from a diverse array of disciplines. To this end, we\nprovide both state-of-the-art pre-trained frame classification models on\nvarious issues as well as a user-friendly pipeline for training novel\nclassification models on user-provided corpora. Researchers can submit their\ndocuments and obtain frames of the documents. The degree of user involvement is\nflexible: they can run models that have been pre-trained on select issues;\nsubmit labeled documents and train a new model for frame classification; or\nsubmit unlabeled documents and obtain potential frames of the documents. The\ncode making up our system is also open-sourced and well-documented, making the\nsystem transparent and expandable. The system is available on-line at\nhttp://www.openframing.org and via our GitHub page\nhttps://github.com/davidatbu/openFraming .\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 18:59:30 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Smith", "Alyssa", ""], ["Tofu", "David Assefa", ""], ["Jalal", "Mona", ""], ["Halim", "Edward Edberg", ""], ["Sun", "Yimeng", ""], ["Akavoor", "Vidya", ""], ["Betke", "Margrit", ""], ["Ishwar", "Prakash", ""], ["Guo", "Lei", ""], ["Wijaya", "Derry", ""]]}, {"id": "2008.06975", "submitter": "Changchun Yang", "authors": "Changchun Yang, Hengrong Lan, and Fei Gao", "title": "Deep Learning Enables Robust and Precise Light Focusing on Treatment\n  Needs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If light passes through the body tissues, focusing only on areas where\ntreatment needs, such as tumors, will revolutionize many biomedical imaging and\ntherapy technologies. So how to focus light through deep inhomogeneous tissues\novercoming scattering is Holy Grail in biomedical areas. In this paper, we use\ndeep learning to learn and accelerate the process of phase pre-compensation\nusing wavefront shaping. We present an approach (LoftGAN, light only focuses on\ntreatment needs) for learning the relationship between phase domain X and\nspeckle domain Y . Our goal is not just to learn an inverse mapping F:Y->X such\nthat we can know the corresponding X needed for imaging Y like most work, but\nalso to make focusing that is susceptible to disturbances more robust and\nprecise by ensuring that the phase obtained can be forward mapped back to\nspeckle. So we introduce different constraints to enforce F(Y)=X and H(F(Y))=Y\nwith the transmission mapping H:X->Y. Both simulation and physical experiments\nare performed to investigate the effects of light focusing to demonstrate the\neffectiveness of our method and comparative experiments prove the crucial\nimprovement of robustness and precision. Codes are available at\nhttps://github.com/ChangchunYang/LoftGAN.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 19:01:20 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Yang", "Changchun", ""], ["Lan", "Hengrong", ""], ["Gao", "Fei", ""]]}, {"id": "2008.06979", "submitter": "Jos\\'e Ribeiro MSc.", "authors": "Jos\\'e Ribeiro, Lair Meneses, Denis Costa, Wando Miranda, Ronnie Alves", "title": "Prediction of Homicides in Urban Centers: A Machine Learning Approach", "comments": "17 pages, 4 tables and 3 figures, Accepted in IntelliSys 2021", "journal-ref": "IntelliSys 2021", "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Relevant research has been highlighted in the computing community to develop\nmachine learning models capable of predicting the occurrence of crimes,\nanalyzing contexts of crimes, extracting profiles of individuals linked to\ncrime, and analyzing crimes over time. However, models capable of predicting\nspecific crimes, such as homicide, are not commonly found in the current\nliterature. This research presents a machine learning model to predict homicide\ncrimes, using a dataset that uses generic data (without study location\ndependencies) based on incident report records for 34 different types of\ncrimes, along with time and space data from crime reports. Experimentally, data\nfrom the city of Bel\\'em - Par\\'a, Brazil was used. These data were transformed\nto make the problem generic, enabling the replication of this model to other\nlocations. In the research, analyses were performed with simple and robust\nalgorithms on the created dataset. With this, statistical tests were performed\nwith 11 different classification methods and the results are related to the\nprediction's occurrence and non-occurrence of homicide crimes in the month\nsubsequent to the occurrence of other registered crimes, with 76% assertiveness\nfor both classes of the problem, using Random Forest. Results are considered as\na baseline for the proposed problem.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 19:13:53 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 20:01:54 GMT"}, {"version": "v3", "created": "Thu, 4 Mar 2021 15:59:59 GMT"}, {"version": "v4", "created": "Sun, 21 Mar 2021 18:35:10 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Ribeiro", "Jos\u00e9", ""], ["Meneses", "Lair", ""], ["Costa", "Denis", ""], ["Miranda", "Wando", ""], ["Alves", "Ronnie", ""]]}, {"id": "2008.06986", "submitter": "Subrata Goswami", "authors": "Subrata Goswami", "title": "False Detection (Positives and Negatives) in Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection is a very important function of visual perception systems.\nSince the early days of classical object detection based on HOG to modern deep\nlearning based detectors, object detection has improved in accuracy. Two stage\ndetectors usually have higher accuracy than single stage ones. Both types of\ndetectors use some form of quantization of the search space of rectangular\nregions of image. There are far more of the quantized elements than true\nobjects. The way these bounding boxes are filtered out possibly results in the\nfalse positive and false negatives. This empirical experimental study explores\nways of reducing false positives and negatives with labelled data.. In the\nprocess also discovered insufficient labelling in Openimage 2019 Object\nDetection dataset.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 20:09:05 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Goswami", "Subrata", ""]]}, {"id": "2008.06996", "submitter": "Dmitry Krotov", "authors": "Dmitry Krotov, John Hopfield", "title": "Large Associative Memory Problem in Neurobiology and Machine Learning", "comments": "Accepted for publication at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense Associative Memories or modern Hopfield networks permit storage and\nreliable retrieval of an exponentially large (in the dimension of feature\nspace) number of memories. At the same time, their naive implementation is\nnon-biological, since it seemingly requires the existence of many-body synaptic\njunctions between the neurons. We show that these models are effective\ndescriptions of a more microscopic (written in terms of biological degrees of\nfreedom) theory that has additional (hidden) neurons and only requires two-body\ninteractions between them. For this reason our proposed microscopic theory is a\nvalid model of large associative memory with a degree of biological\nplausibility. The dynamics of our network and its reduced dimensional\nequivalent both minimize energy (Lyapunov) functions. When certain dynamical\nvariables (hidden neurons) are integrated out from our microscopic theory, one\ncan recover many of the models that were previously discussed in the\nliterature, e.g. the model presented in \"Hopfield Networks is All You Need\"\npaper. We also provide an alternative derivation of the energy function and the\nupdate rule proposed in the aforementioned paper and clarify the relationships\nbetween various models of this class.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 21:03:52 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 20:06:50 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 22:20:05 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Krotov", "Dmitry", ""], ["Hopfield", "John", ""]]}, {"id": "2008.07000", "submitter": "Szymon P{\\l}otka", "authors": "Tomasz W{\\l}odarczyk, Szymon P{\\l}otka, Przemys{\\l}aw Rokita, Nicole\n  Sochacki-W\\'ojcicka, Jakub W\\'ojcicki, Micha{\\l} Lipa, Tomasz Trzci\\'nski", "title": "Spontaneous preterm birth prediction using convolutional neural networks", "comments": "Accepted at MICCAI Workshop on Perinatal, Preterm and Paediatric\n  Image analysis (PIPPI) 2020, Lima, Peru", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An estimated 15 million babies are born too early every year. Approximately 1\nmillion children die each year due to complications of preterm birth (PTB).\nMany survivors face a lifetime of disability, including learning disabilities\nand visual and hearing problems. Although manual analysis of ultrasound images\n(US) is still prevalent, it is prone to errors due to its subjective component\nand complex variations in the shape and position of organs across patients. In\nthis work, we introduce a conceptually simple convolutional neural network\n(CNN) trained for segmenting prenatal ultrasound images and classifying task\nfor the purpose of preterm birth detection. Our method efficiently segments\ndifferent types of cervixes in transvaginal ultrasound images while\nsimultaneously predicting a preterm birth based on extracted image features\nwithout human oversight. We employed three popular network models: U-Net, Fully\nConvolutional Network, and Deeplabv3 for the cervix segmentation task. Based on\nthe conducted results and model efficiency, we decided to extend U-Net by\nadding a parallel branch for classification task. The proposed model is trained\nand evaluated on a dataset consisting of 354 2D transvaginal ultrasound images\nand achieved a segmentation accuracy with a mean Jaccard coefficient index of\n0.923 $\\pm$ 0.081 and a classification sensitivity of 0.677 $\\pm$ 0.042 with a\n3.49\\% false positive rate. Our method obtained better results in the\nprediction of preterm birth based on transvaginal ultrasound images compared to\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 21:21:33 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 19:35:33 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["W\u0142odarczyk", "Tomasz", ""], ["P\u0142otka", "Szymon", ""], ["Rokita", "Przemys\u0142aw", ""], ["Sochacki-W\u00f3jcicka", "Nicole", ""], ["W\u00f3jcicki", "Jakub", ""], ["Lipa", "Micha\u0142", ""], ["Trzci\u0144ski", "Tomasz", ""]]}, {"id": "2008.07001", "submitter": "Marah Halawa", "authors": "Marah Halawa, Manuel W\\\"ollhaf, Eduardo Vellasques, Urko S\\'anchez\n  Sanz, and Olaf Hellwich", "title": "Learning Disentangled Expression Representations from Facial Images", "comments": "Accepted at ECCV2020 workshops", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face images are subject to many different factors of variation, especially in\nunconstrained in-the-wild scenarios. For most tasks involving such images, e.g.\nexpression recognition from video streams, having enough labeled data is\nprohibitively expensive. One common strategy to tackle such a problem is to\nlearn disentangled representations for the different factors of variation of\nthe observed data using adversarial learning. In this paper, we use a\nformulation of the adversarial loss to learn disentangled representations for\nface images. The used model facilitates learning on single-task datasets and\nimproves the state-of-the-art in expression recognition with an accuracy\nof60.53%on the AffectNetdataset, without using any additional data.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 21:23:32 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 06:58:13 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Halawa", "Marah", ""], ["W\u00f6llhaf", "Manuel", ""], ["Vellasques", "Eduardo", ""], ["Sanz", "Urko S\u00e1nchez", ""], ["Hellwich", "Olaf", ""]]}, {"id": "2008.07007", "submitter": "Kacper Sokol", "authors": "Kacper Sokol and Peter Flach", "title": "Towards Faithful and Meaningful Interpretable Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable representations are the backbone of many black-box explainers.\nThey translate the low-level data representation necessary for good predictive\nperformance into high-level human-intelligible concepts used to convey the\nexplanation. Notably, the explanation type and its cognitive complexity are\ndirectly controlled by the interpretable representation, allowing to target a\nparticular audience and use case. However, many explainers that rely on\ninterpretable representations overlook their merit and fall back on default\nsolutions, which may introduce implicit assumptions, thereby degrading the\nexplanatory power of such techniques. To address this problem, we study\nproperties of interpretable representations that encode presence and absence of\nhuman-comprehensible concepts. We show how they are operationalised for\ntabular, image and text data, discussing their strengths and weaknesses.\nFinally, we analyse their explanatory properties in the context of tabular\ndata, where a linear model is used to quantify the importance of interpretable\nconcepts.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 21:44:03 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sokol", "Kacper", ""], ["Flach", "Peter", ""]]}, {"id": "2008.07009", "submitter": "Lucas N. Ferreira", "authors": "Lucas N. Ferreira, Levi H. S. Lelis and Jim Whitehead", "title": "Computer-Generated Music for Tabletop Role-Playing Games", "comments": "To be published in the 16th AAAI Conference ON Artificial\n  Intelligence and Interactive Digital Entertainment", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present Bardo Composer, a system to generate background\nmusic for tabletop role-playing games. Bardo Composer uses a speech recognition\nsystem to translate player speech into text, which is classified according to a\nmodel of emotion. Bardo Composer then uses Stochastic Bi-Objective Beam Search,\na variant of Stochastic Beam Search that we introduce in this paper, with a\nneural model to generate musical pieces conveying the desired emotion. We\nperformed a user study with 116 participants to evaluate whether people are\nable to correctly identify the emotion conveyed in the pieces generated by the\nsystem. In our study we used pieces generated for Call of the Wild, a Dungeons\nand Dragons campaign available on YouTube. Our results show that human subjects\ncould correctly identify the emotion of the generated music pieces as\naccurately as they were able to identify the emotion of pieces written by\nhumans.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 21:53:49 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Ferreira", "Lucas N.", ""], ["Lelis", "Levi H. S.", ""], ["Whitehead", "Jim", ""]]}, {"id": "2008.07015", "submitter": "Elahe Arani", "authors": "Elahe Arani, Fahad Sarfraz and Bahram Zonooz", "title": "Adversarial Concurrent Training: Optimizing Robustness and Accuracy\n  Trade-off of Deep Neural Networks", "comments": "Accepted at 31st British Machine Vision Conference (BMVC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training has been proven to be an effective technique for\nimproving the adversarial robustness of models. However, there seems to be an\ninherent trade-off between optimizing the model for accuracy and robustness. To\nthis end, we propose Adversarial Concurrent Training (ACT), which employs\nadversarial training in a collaborative learning framework whereby we train a\nrobust model in conjunction with a natural model in a minimax game. ACT\nencourages the two models to align their feature space by using the\ntask-specific decision boundaries and explore the input space more broadly.\nFurthermore, the natural model acts as a regularizer, enforcing priors on\nfeatures that the robust model should learn. Our analyses on the behavior of\nthe models show that ACT leads to a robust model with lower model complexity,\nhigher information compression in the learned representations, and high\nposterior entropy solutions indicative of convergence to a flatter minima. We\ndemonstrate the effectiveness of the proposed approach across different\ndatasets and network architectures. On ImageNet, ACT achieves 68.20% standard\naccuracy and 44.29% robustness accuracy under a 100-iteration untargeted\nattack, improving upon the standard adversarial training method's 65.70%\nstandard accuracy and 42.36% robustness.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 22:14:48 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 18:31:40 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Arani", "Elahe", ""], ["Sarfraz", "Fahad", ""], ["Zonooz", "Bahram", ""]]}, {"id": "2008.07029", "submitter": "Syrine Belakaria", "authors": "Syrine Belakaria, Aryan Deshwal, Janardhan Rao Doppa", "title": "Uncertainty aware Search Framework for Multi-Objective Bayesian\n  Optimization with Constraints", "comments": "9 pages, 2 figures, 1 table", "journal-ref": "7th ICML Workshop on Automated Machine Learning (2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of constrained multi-objective (MO) blackbox\noptimization using expensive function evaluations, where the goal is to\napproximate the true Pareto set of solutions satisfying a set of constraints\nwhile minimizing the number of function evaluations. We propose a novel\nframework named Uncertainty-aware Search framework for Multi-Objective\nOptimization with Constraints (USeMOC) to efficiently select the sequence of\ninputs for evaluation to solve this problem. The selection method of USeMOC\nconsists of solving a cheap constrained MO optimization problem via surrogate\nmodels of the true functions to identify the most promising candidates and\npicking the best candidate based on a measure of uncertainty. We applied this\nframework to optimize the design of a multi-output switched-capacitor voltage\nregulator via expensive simulations. Our experimental results show that USeMOC\nis able to achieve more than 90 % reduction in the number of simulations needed\nto uncover optimized circuits.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 23:34:09 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 04:53:56 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Belakaria", "Syrine", ""], ["Deshwal", "Aryan", ""], ["Doppa", "Janardhan Rao", ""]]}, {"id": "2008.07030", "submitter": "Chun Kit Wong", "authors": "Chun Kit Wong, Stephanie Marchesseau, Maria Kalimeri, Tiang Siew Yap,\n  Serena S. H. Teo, Lingaraj Krishna, Alfredo Franco-Obreg\\'on, Stacey K. H.\n  Tay, Chin Meng Khoo, Philip T. H. Lee, Melvin K. S. Leow, John J. Totman,\n  Mary C. Stephenson", "title": "Training CNN Classifiers for Semantic Segmentation using Partially\n  Annotated Images: with Application on Human Thigh and Calf MRI", "comments": "Submitted to IEEE Transactions on Medical Imaging (Special Issue on\n  Annotation-Efficient Deep Learning for Medical Imaging)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Medical image datasets with pixel-level labels tend to have a\nlimited number of organ or tissue label classes annotated, even when the images\nhave wide anatomical coverage. With supervised learning, multiple classifiers\nare usually needed given these partially annotated datasets. In this work, we\npropose a set of strategies to train one single classifier in segmenting all\nlabel classes that are heterogeneously annotated across multiple datasets\nwithout moving into semi-supervised learning. Methods: Masks were first created\nfrom each label image through a process we termed presence masking. Three\npresence masking modes were evaluated, differing mainly in weightage assigned\nto the annotated and unannotated classes. These masks were then applied to the\nloss function during training to remove the influence of unannotated classes.\nResults: Evaluation against publicly available CT datasets shows that presence\nmasking is a viable method for training class-generic classifiers. Our\nclass-generic classifier can perform as well as multiple class-specific\nclassifiers combined, while the training duration is similar to that required\nfor one class-specific classifier. Furthermore, the class-generic classifier\ncan outperform the class-specific classifiers when trained on smaller datasets.\nFinally, consistent results are observed from evaluations against human thigh\nand calf MRI datasets collected in-house. Conclusion: The evaluation outcomes\nshow that presence masking is capable of significantly improving both training\nand inference efficiency across imaging modalities and anatomical regions.\nImproved performance may even be observed on small datasets. Significance:\nPresence masking strategies can reduce the computational resources and costs\ninvolved in manual medical image annotations. All codes are publicly available\nat https://github.com/wong-ck/DeepSegment.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 23:38:02 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wong", "Chun Kit", ""], ["Marchesseau", "Stephanie", ""], ["Kalimeri", "Maria", ""], ["Yap", "Tiang Siew", ""], ["Teo", "Serena S. H.", ""], ["Krishna", "Lingaraj", ""], ["Franco-Obreg\u00f3n", "Alfredo", ""], ["Tay", "Stacey K. H.", ""], ["Khoo", "Chin Meng", ""], ["Lee", "Philip T. H.", ""], ["Leow", "Melvin K. S.", ""], ["Totman", "John J.", ""], ["Stephenson", "Mary C.", ""]]}, {"id": "2008.07032", "submitter": "Zhe Chen", "authors": "Zhe Chen, Yuyan Wang, Dong Lin, Derek Zhiyuan Cheng, Lichan Hong, Ed\n  H. Chi, Claire Cui", "title": "Beyond Point Estimate: Inferring Ensemble Prediction Variation from\n  Neuron Activation Strength in Recommender Systems", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Despite deep neural network (DNN)'s impressive prediction performance in\nvarious domains, it is well known now that a set of DNN models trained with the\nsame model specification and the same data can produce very different\nprediction results. Ensemble method is one state-of-the-art benchmark for\nprediction uncertainty estimation. However, ensembles are expensive to train\nand serve for web-scale traffic.\n  In this paper, we seek to advance the understanding of prediction variation\nestimated by the ensemble method. Through empirical experiments on two widely\nused benchmark datasets MovieLens and Criteo in recommender systems, we observe\nthat prediction variations come from various randomness sources, including\ntraining data shuffling, and parameter random initialization. By introducing\nmore randomness into model training, we notice that ensemble's mean predictions\ntend to be more accurate while the prediction variations tend to be higher.\nMoreover, we propose to infer prediction variation from neuron activation\nstrength and demonstrate the strong prediction power from activation strength\nfeatures. Our experiment results show that the average R squared on MovieLens\nis as high as 0.56 and on Criteo is 0.81. Our method performs especially well\nwhen detecting the lowest and highest variation buckets, with 0.92 AUC and 0.89\nAUC respectively. Our approach provides a simple way for prediction variation\nestimation, which opens up new opportunities for future work in many\ninteresting areas (e.g.,model-based reinforcement learning) without relying on\nserving expensive ensemble models.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 00:08:27 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Chen", "Zhe", ""], ["Wang", "Yuyan", ""], ["Lin", "Dong", ""], ["Cheng", "Derek Zhiyuan", ""], ["Hong", "Lichan", ""], ["Chi", "Ed H.", ""], ["Cui", "Claire", ""]]}, {"id": "2008.07055", "submitter": "Mark Herbster", "authors": "Mark Herbster, Stephen Pasteris, Lisa Tse", "title": "Online Multitask Learning with Long-Term Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel online multitask setting. In this setting each task is\npartitioned into a sequence of segments that is unknown to the learner.\nAssociated with each segment is a hypothesis from some hypothesis class. We\ngive algorithms that are designed to exploit the scenario where there are many\nsuch segments but significantly fewer associated hypotheses. We prove regret\nbounds that hold for any segmentation of the tasks and any association of\nhypotheses to the segments. In the single-task setting this is equivalent to\nswitching with long-term memory in the sense of [Bousquet and Warmuth; 2003].\nWe provide an algorithm that predicts on each trial in time linear in the\nnumber of hypotheses when the hypothesis class is finite. We also consider\ninfinite hypothesis classes from reproducing kernel Hilbert spaces for which we\ngive an algorithm whose per trial time complexity is cubic in the number of\ncumulative trials. In the single-task special case this is the first example of\nan efficient regret-bounded switching algorithm with long-term memory for a\nnon-parametric hypothesis class.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 01:43:59 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Herbster", "Mark", ""], ["Pasteris", "Stephen", ""], ["Tse", "Lisa", ""]]}, {"id": "2008.07063", "submitter": "Philippe Goulet Coulombe", "authors": "Philippe Goulet Coulombe", "title": "To Bag is to Prune", "comments": "added references; corrected typos; added NN discussions and results,\n  new experiments and discussion on double descent", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is notoriously difficult to build a bad Random Forest (RF). Concurrently,\nRF blatantly overfits in-sample without any apparent consequence out-of-sample.\nStandard arguments, like the classic bias-variance trade-off or double descent,\ncannot rationalize this paradox. I propose a new explanation: bootstrap\naggregation and model perturbation as implemented by RF automatically prune a\nlatent \"true\" tree. More generally, randomized ensembles of greedily optimized\nlearners implicitly perform optimal early stopping out-of-sample. So there is\nno need to tune the stopping point. By construction, novel variants of Boosting\nand MARS are also eligible for automatic tuning. I empirically demonstrate the\nproperty, with simulated and real data, by reporting that these new completely\noverfitting ensembles perform similarly to their tuned counterparts -- or\nbetter.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 02:45:32 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 04:10:02 GMT"}, {"version": "v3", "created": "Fri, 5 Mar 2021 16:54:07 GMT"}, {"version": "v4", "created": "Tue, 8 Jun 2021 21:54:35 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Coulombe", "Philippe Goulet", ""]]}, {"id": "2008.07071", "submitter": "Dewen Zeng", "authors": "Dewen Zeng, Weiwen Jiang, Tianchen Wang, Xiaowei Xu, Haiyun Yuan,\n  Meiping Huang, Jian Zhuang, Jingtong Hu, Yiyu Shi", "title": "Towards Cardiac Intervention Assistance: Hardware-aware Neural\n  Architecture Exploration for Real-Time 3D Cardiac Cine MRI Segmentation", "comments": "8 pages, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time cardiac magnetic resonance imaging (MRI) plays an increasingly\nimportant role in guiding various cardiac interventions. In order to provide\nbetter visual assistance, the cine MRI frames need to be segmented on-the-fly\nto avoid noticeable visual lag. In addition, considering reliability and\npatient data privacy, the computation is preferably done on local hardware.\nState-of-the-art MRI segmentation methods mostly focus on accuracy only, and\ncan hardly be adopted for real-time application or on local hardware. In this\nwork, we present the first hardware-aware multi-scale neural architecture\nsearch (NAS) framework for real-time 3D cardiac cine MRI segmentation. The\nproposed framework incorporates a latency regularization term into the loss\nfunction to handle real-time constraints, with the consideration of underlying\nhardware. In addition, the formulation is fully differentiable with respect to\nthe architecture parameters, so that stochastic gradient descent (SGD) can be\nused for optimization to reduce the computation cost while maintaining\noptimization quality. Experimental results on ACDC MICCAI 2017 dataset\ndemonstrate that our hardware-aware multi-scale NAS framework can reduce the\nlatency by up to 3.5 times and satisfy the real-time constraints, while still\nachieving competitive segmentation accuracy, compared with the state-of-the-art\nNAS segmentation framework.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 03:22:57 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 01:11:50 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Zeng", "Dewen", ""], ["Jiang", "Weiwen", ""], ["Wang", "Tianchen", ""], ["Xu", "Xiaowei", ""], ["Yuan", "Haiyun", ""], ["Huang", "Meiping", ""], ["Zhuang", "Jian", ""], ["Hu", "Jingtong", ""], ["Shi", "Yiyu", ""]]}, {"id": "2008.07072", "submitter": "Fatemeh Ganji", "authors": "Shahin Tajik and Fatemeh Ganji", "title": "Artificial Neural Networks and Fault Injection Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This chapter is on the security assessment of artificial intelligence (AI)\nand neural network (NN) accelerators in the face of fault injection attacks.\nMore specifically, it discusses the assets on these platforms and compares them\nwith ones known and well-studied in the field of cryptographic systems. This is\na crucial step that must be taken in order to define the threat models\nprecisely. With respect to that, fault attacks mounted on NNs and AI\naccelerators are explored.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 03:29:57 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 16:27:03 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Tajik", "Shahin", ""], ["Ganji", "Fatemeh", ""]]}, {"id": "2008.07079", "submitter": "Quentin Gendre", "authors": "Quentin Gendre, Tomoyuki Kaneko", "title": "Playing Catan with Cross-dimensional Neural Network", "comments": "12 pages, 5 tables and 10 figures; submitted to the ICONIP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catan is a strategic board game having interesting properties, including\nmulti-player, imperfect information, stochastic, complex state space structure\n(hexagonal board where each vertex, edge and face has its own features, cards\nfor each player, etc), and a large action space (including negotiation).\nTherefore, it is challenging to build AI agents by Reinforcement Learning (RL\nfor short), without domain knowledge nor heuristics. In this paper, we\nintroduce cross-dimensional neural networks to handle a mixture of information\nsources and a wide variety of outputs, and empirically demonstrate that the\nnetwork dramatically improves RL in Catan. We also show that, for the first\ntime, a RL agent can outperform jsettler, the best heuristic agent available.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 04:09:29 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Gendre", "Quentin", ""], ["Kaneko", "Tomoyuki", ""]]}, {"id": "2008.07081", "submitter": "Xiaoyi Chen", "authors": "Xiaoyi Chen, Pratik Chaudhari", "title": "MIDAS: Multi-agent Interaction-aware Decision-making with Adaptive\n  Strategies for Urban Autonomous Navigation", "comments": "Code available at https://github.com/sherrychen1120/MIDAS. To be\n  presented at IEEE International Conference on Robotics and Automation (ICRA),\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Autonomous navigation in crowded, complex urban environments requires\ninteracting with other agents on the road. A common solution to this problem is\nto use a prediction model to guess the likely future actions of other agents.\nWhile this is reasonable, it leads to overly conservative plans because it does\nnot explicitly model the mutual influence of the actions of interacting agents.\nThis paper builds a reinforcement learning-based method named MIDAS where an\nego-agent learns to affect the control actions of other cars in urban driving\nscenarios. MIDAS uses an attention-mechanism to handle an arbitrary number of\nother agents and includes a \"driver-type\" parameter to learn a single policy\nthat works across different planning objectives. We build a simulation\nenvironment that enables diverse interaction experiments with a large number of\nagents and methods for quantitatively studying the safety, efficiency, and\ninteraction among vehicles. MIDAS is validated using extensive experiments and\nwe show that it (i) can work across different road geometries, (ii) results in\nan adaptive ego policy that can be tuned easily to satisfy performance criteria\nsuch as aggressive or cautious driving, (iii) is robust to changes in the\ndriving policies of external agents, and (iv) is more efficient and safer than\nexisting approaches to interaction-aware decision-making.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 04:34:25 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 05:05:22 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Chen", "Xiaoyi", ""], ["Chaudhari", "Pratik", ""]]}, {"id": "2008.07083", "submitter": "Haneul Ko", "authors": "Seung Wook Kim, Keunsoo Ko, Haneul Ko, Victor C. M. Leung", "title": "Edge Network-Assisted Real-Time Object Detection Framework for\n  Autonomous Driving", "comments": "This paper will be published in IEEE Network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles (AVs) can achieve the desired results within a short\nduration by offloading tasks even requiring high computational power (e.g.,\nobject detection (OD)) to edge clouds. However, although edge clouds are\nexploited, real-time OD cannot always be guaranteed due to dynamic channel\nquality. To mitigate this problem, we propose an edge network-assisted\nreal-time OD framework~(EODF). In an EODF, AVs extract the region of\ninterests~(RoIs) of the captured image when the channel quality is not\nsufficiently good for supporting real-time OD. Then, AVs compress the image\ndata on the basis of the RoIs and transmit the compressed one to the edge\ncloud. In so doing, real-time OD can be achieved owing to the reduced\ntransmission latency. To verify the feasibility of our framework, we evaluate\nthe probability that the results of OD are not received within the inter-frame\nduration (i.e., outage probability) and their accuracy. From the evaluation, we\ndemonstrate that the proposed EODF provides the results to AVs in real-time and\nachieves satisfactory accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 04:35:20 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Kim", "Seung Wook", ""], ["Ko", "Keunsoo", ""], ["Ko", "Haneul", ""], ["Leung", "Victor C. M.", ""]]}, {"id": "2008.07085", "submitter": "Soham Deshmukh", "authors": "Soham Deshmukh, Bhiksha Raj, Rita Singh", "title": "Multi-Task Learning for Interpretable Weakly Labelled Sound Event\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weakly Labelled learning has garnered lot of attention in recent years due to\nits potential to scale Sound Event Detection (SED) and is formulated as\nMultiple Instance Learning (MIL) problem. This paper proposes a Multi-Task\nLearning (MTL) framework for learning from Weakly Labelled Audio data which\nencompasses the traditional MIL setup. To show the utility of proposed\nframework, we use the input TimeFrequency representation (T-F) reconstruction\nas the auxiliary task. We show that the chosen auxiliary task de-noises\ninternal T-F representation and improves SED performance under noisy\nrecordings. Our second contribution is introducing two step Attention Pooling\nmechanism. By having 2-steps in attention mechanism, the network retains better\nT-F level information without compromising SED performance. The visualisation\nof first step and second step attention weights helps in localising the\naudio-event in T-F domain. For evaluating the proposed framework, we remix the\nDCASE 2019 task 1 acoustic scene data with DCASE 2018 Task 2 sounds event data\nunder 0, 10 and 20 db SNR resulting in a multi-class Weakly labelled SED\nproblem. The proposed total framework outperforms existing benchmark models\nover all SNRs, specifically 22.3 %, 12.8 %, 5.9 % improvement over benchmark\nmodel on 0, 10 and 20 dB SNR respectively. We carry out ablation study to\ndetermine the contribution of each auxiliary task and 2-step Attention Pooling\nto the SED performance improvement. The code is publicly released\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 04:46:25 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 18:22:09 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Deshmukh", "Soham", ""], ["Raj", "Bhiksha", ""], ["Singh", "Rita", ""]]}, {"id": "2008.07087", "submitter": "Hongyu Ren", "authors": "Hongyu Ren, Yuke Zhu, Jure Leskovec, Anima Anandkumar, Animesh Garg", "title": "OCEAN: Online Task Inference for Compositional Tasks with Context\n  Adaptation", "comments": "UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world tasks often exhibit a compositional structure that contains a\nsequence of simpler sub-tasks. For instance, opening a door requires reaching,\ngrasping, rotating, and pulling the door knob. Such compositional tasks require\nan agent to reason about the sub-task at hand while orchestrating global\nbehavior accordingly. This can be cast as an online task inference problem,\nwhere the current task identity, represented by a context variable, is\nestimated from the agent's past experiences with probabilistic inference.\nPrevious approaches have employed simple latent distributions, e.g., Gaussian,\nto model a single context for the entire task. However, this formulation lacks\nthe expressiveness to capture the composition and transition of the sub-tasks.\nWe propose a variational inference framework OCEAN to perform online task\ninference for compositional tasks. OCEAN models global and local context\nvariables in a joint latent space, where the global variables represent a\nmixture of sub-tasks required for the task, while the local variables capture\nthe transitions between the sub-tasks. Our framework supports flexible latent\ndistributions based on prior knowledge of the task structure and can be trained\nin an unsupervised manner. Experimental results show that OCEAN provides more\neffective task inference with sequential context adaptation and thus leads to a\nperformance boost on complex, multi-stage tasks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 04:50:34 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Ren", "Hongyu", ""], ["Zhu", "Yuke", ""], ["Leskovec", "Jure", ""], ["Anandkumar", "Anima", ""], ["Garg", "Animesh", ""]]}, {"id": "2008.07092", "submitter": "Mahima Chaudhary", "authors": "Mahima Chaudhary, Sumona Mukhopadhyay, Marin Litoiu, Lauren E Sergio,\n  Meaghan S Adams", "title": "Understanding Brain Dynamics for Color Perception using Wearable EEG\n  headband", "comments": "10 pages,10 figures, Conference- EVOKE CASCON 2020", "journal-ref": "Proceedings of 30th Annual International Conference on Computer\n  Science and Software Engineering 2020", "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The perception of color is an important cognitive feature of the human brain.\nThe variety of colors that impinge upon the human eye can trigger changes in\nbrain activity which can be captured using electroencephalography (EEG). In\nthis work, we have designed a multiclass classification model to detect the\nprimary colors from the features of raw EEG signals. In contrast to previous\nresearch, our method employs spectral power features, statistical features as\nwell as correlation features from the signal band power obtained from\ncontinuous Morlet wavelet transform instead of raw EEG, for the classification\ntask. We have applied dimensionality reduction techniques such as Forward\nFeature Selection and Stacked Autoencoders to reduce the dimension of data\neventually increasing the model's efficiency. Our proposed methodology using\nForward Selection and Random Forest Classifier gave the best overall accuracy\nof 80.6\\% for intra-subject classification. Our approach shows promise in\ndeveloping techniques for cognitive tasks using color cues such as controlling\nInternet of Thing (IoT) devices by looking at primary colors for individuals\nwith restricted motor abilities.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 05:25:16 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Chaudhary", "Mahima", ""], ["Mukhopadhyay", "Sumona", ""], ["Litoiu", "Marin", ""], ["Sergio", "Lauren E", ""], ["Adams", "Meaghan S", ""]]}, {"id": "2008.07097", "submitter": "Jiaying Liu", "authors": "Jiaying Liu, Feng Xia, Lei Wang, Bo Xu, Xiangjie Kong, Hanghang Tong,\n  and Irwin King", "title": "Shifu2: A Network Representation Learning Based Model for\n  Advisor-advisee Relationship Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advisor-advisee relationship represents direct knowledge heritage, and\nsuch relationship may not be readily available from academic libraries and\nsearch engines. This work aims to discover advisor-advisee relationships hidden\nbehind scientific collaboration networks. For this purpose, we propose a novel\nmodel based on Network Representation Learning (NRL), namely Shifu2, which\ntakes the collaboration network as input and the identified advisor-advisee\nrelationship as output. In contrast to existing NRL models, Shifu2 considers\nnot only the network structure but also the semantic information of nodes and\nedges. Shifu2 encodes nodes and edges into low-dimensional vectors\nrespectively, both of which are then utilized to identify advisor-advisee\nrelationships. Experimental results illustrate improved stability and\neffectiveness of the proposed model over state-of-the-art methods. In addition,\nwe generate a large-scale academic genealogy dataset by taking advantage of\nShifu2.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 05:40:06 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Liu", "Jiaying", ""], ["Xia", "Feng", ""], ["Wang", "Lei", ""], ["Xu", "Bo", ""], ["Kong", "Xiangjie", ""], ["Tong", "Hanghang", ""], ["King", "Irwin", ""]]}, {"id": "2008.07111", "submitter": "Ronald Chang", "authors": "Kevin M. Chen and Ronald Y. Chang", "title": "Semi-Supervised Learning with GANs for Device-Free Fingerprinting Indoor\n  Localization", "comments": "Accepted at IEEE GLOBECOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Device-free wireless indoor localization is a key enabling technology for the\nInternet of Things (IoT). Fingerprint-based indoor localization techniques are\na commonly used solution. This paper proposes a semi-supervised, generative\nadversarial network (GAN)-based device-free fingerprinting indoor localization\nsystem. The proposed system uses a small amount of labeled data and a large\namount of unlabeled data (i.e., semi-supervised), thus considerably reducing\nthe expensive data labeling effort. Experimental results show that, as compared\nto the state-of-the-art supervised scheme, the proposed semi-supervised system\nachieves comparable performance with equal, sufficient amount of labeled data,\nand significantly superior performance with equal, highly limited amount of\nlabeled data. Besides, the proposed semi-supervised system retains its\nperformance over a broad range of the amount of labeled data. The interactions\nbetween the generator, discriminator, and classifier models of the proposed\nGAN-based system are visually examined and discussed. A mathematical\ndescription of the proposed system is also presented.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 06:32:13 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Chen", "Kevin M.", ""], ["Chang", "Ronald Y.", ""]]}, {"id": "2008.07118", "submitter": "Ziyu Wang", "authors": "Ziyu Wang, Yiyi Zhang, Yixiao Zhang, Junyan Jiang, Ruihan Yang, Junbo\n  Zhao (Jake), Gus Xia", "title": "PIANOTREE VAE: Structured Representation Learning for Polyphonic Music", "comments": null, "journal-ref": "In Proceedings of 21st International Conference on Music\n  Information Retrieval (ISMIR), Montreal, Canada (virtual conference), 2020", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant approach for music representation learning involves the deep\nunsupervised model family variational autoencoder (VAE). However, most, if not\nall, viable attempts on this problem have largely been limited to monophonic\nmusic. Normally composed of richer modality and more complex musical\nstructures, the polyphonic counterpart has yet to be addressed in the context\nof music representation learning. In this work, we propose the PianoTree VAE, a\nnovel tree-structure extension upon VAE aiming to fit the polyphonic music\nlearning. The experiments prove the validity of the PianoTree VAE via\n(i)-semantically meaningful latent code for polyphonic segments; (ii)-more\nsatisfiable reconstruction aside of decent geometry learned in the latent\nspace; (iii)-this model's benefits to the variety of the downstream music\ngeneration.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 06:48:59 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wang", "Ziyu", "", "Jake"], ["Zhang", "Yiyi", "", "Jake"], ["Zhang", "Yixiao", "", "Jake"], ["Jiang", "Junyan", "", "Jake"], ["Yang", "Ruihan", "", "Jake"], ["Zhao", "Junbo", "", "Jake"], ["Xia", "Gus", ""]]}, {"id": "2008.07122", "submitter": "Ziyu Wang", "authors": "Ziyu Wang, Dingsu Wang, Yixiao Zhang, Gus Xia", "title": "Learning Interpretable Representation for Controllable Polyphonic Music\n  Generation", "comments": null, "journal-ref": "In Proceedings of 21st International Conference on Music\n  Information Retrieval (ISMIR), Montreal, Canada, 2020", "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep generative models have become the leading methods for algorithmic\ncomposition, it remains a challenging problem to control the generation process\nbecause the latent variables of most deep-learning models lack good\ninterpretability. Inspired by the content-style disentanglement idea, we design\na novel architecture, under the VAE framework, that effectively learns two\ninterpretable latent factors of polyphonic music: chord and texture. The\ncurrent model focuses on learning 8-beat long piano composition segments. We\nshow that such chord-texture disentanglement provides a controllable generation\npathway leading to a wide spectrum of applications, including compositional\nstyle transfer, texture variation, and accompaniment arrangement. Both\nobjective and subjective evaluations show that our method achieves a successful\ndisentanglement and high quality controlled music generation.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 07:11:16 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wang", "Ziyu", ""], ["Wang", "Dingsu", ""], ["Zhang", "Yixiao", ""], ["Xia", "Gus", ""]]}, {"id": "2008.07125", "submitter": "Luca Demetrio", "authors": "Luca Demetrio and Scott E. Coull and Battista Biggio and Giovanni\n  Lagorio and Alessandro Armando and Fabio Roli", "title": "Adversarial EXEmples: A Survey and Experimental Evaluation of Practical\n  Attacks on Machine Learning for Windows Malware Detection", "comments": null, "journal-ref": "ACM Transactions on Privacy and Security, 2021", "doi": "10.1145/3473039", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that adversarial Windows malware samples - referred to\nas adversarial EXEmples in this paper - can bypass machine learning-based\ndetection relying on static code analysis by perturbing relatively few input\nbytes. To preserve malicious functionality, previous attacks either add bytes\nto existing non-functional areas of the file, potentially limiting their\neffectiveness, or require running computationally-demanding validation steps to\ndiscard malware variants that do not correctly execute in sandbox environments.\nIn this work, we overcome these limitations by developing a unifying framework\nthat does not only encompass and generalize previous attacks against\nmachine-learning models, but also includes three novel attacks based on\npractical, functionality-preserving manipulations to the Windows Portable\nExecutable (PE) file format. These attacks, named Full DOS, Extend and Shift,\ninject the adversarial payload by respectively manipulating the DOS header,\nextending it, and shifting the content of the first section. Our experimental\nresults show that these attacks outperform existing ones in both white-box and\nblack-box scenarios, achieving a better trade-off in terms of evasion rate and\nsize of the injected payload, while also enabling evasion of models that have\nbeen shown to be robust to previous attacks. To facilitate reproducibility of\nour findings, we open source our framework and all the corresponding attack\nimplementations as part of the secml-malware Python library. We conclude this\nwork by discussing the limitations of current machine learning-based malware\ndetectors, along with potential mitigation strategies based on embedding domain\nknowledge coming from subject-matter experts directly into the learning\nprocess.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 07:16:57 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 08:15:59 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Demetrio", "Luca", ""], ["Coull", "Scott E.", ""], ["Biggio", "Battista", ""], ["Lagorio", "Giovanni", ""], ["Armando", "Alessandro", ""], ["Roli", "Fabio", ""]]}, {"id": "2008.07141", "submitter": "Zhixiang Ren", "authors": "Zhixiang Ren, Yongheng Liu, Tianhui Shi, Lei Xie, Yue Zhou, Jidong\n  Zhai, Youhui Zhang, Yunquan Zhang, Wenguang Chen", "title": "AIPerf: Automated machine learning as an AI-HPC benchmark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The plethora of complex artificial intelligence (AI) algorithms and available\nhigh performance computing (HPC) power stimulates the expeditious development\nof AI components with heterogeneous designs. Consequently, the need for\ncross-stack performance benchmarking of AI-HPC systems emerges rapidly. The de\nfacto HPC benchmark LINPACK can not reflect AI computing power and I/O\nperformance without representative workload. The current popular AI benchmarks\nlike MLPerf have fixed problem size therefore limited scalability. To address\nthese issues, we propose an end-to-end benchmark suite utilizing automated\nmachine learning (AutoML), which not only represents real AI scenarios, but\nalso is auto-adaptively scalable to various scales of machines. We implement\nthe algorithms in a highly parallel and flexible way to ensure the efficiency\nand optimization potential on diverse systems with customizable configurations.\nWe utilize operations per second (OPS), which is measured in an analytical and\nsystematic approach, as the major metric to quantify the AI performance. We\nperform evaluations on various systems to ensure the benchmark's stability and\nscalability, from 4 nodes with 32 NVIDIA Tesla T4 (56.1 Tera-OPS measured), up\nto 512 nodes with 4096 Huawei Ascend 910 (194.53 Peta-OPS measured), and the\nresults show near-linear weak scalability. With flexible workload and single\nmetric, our benchmark can scale and rank AI-HPC easily.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 08:06:43 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 08:53:50 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2020 07:29:24 GMT"}, {"version": "v4", "created": "Thu, 8 Oct 2020 13:22:19 GMT"}, {"version": "v5", "created": "Mon, 12 Oct 2020 13:50:56 GMT"}, {"version": "v6", "created": "Tue, 27 Oct 2020 10:02:34 GMT"}, {"version": "v7", "created": "Mon, 15 Mar 2021 02:25:55 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Ren", "Zhixiang", ""], ["Liu", "Yongheng", ""], ["Shi", "Tianhui", ""], ["Xie", "Lei", ""], ["Zhou", "Yue", ""], ["Zhai", "Jidong", ""], ["Zhang", "Youhui", ""], ["Zhang", "Yunquan", ""], ["Chen", "Wenguang", ""]]}, {"id": "2008.07142", "submitter": "Ziyu Wang", "authors": "Ziyu Wang, Ke Chen, Junyan Jiang, Yiyi Zhang, Maoran Xu, Shuqi Dai,\n  Xianbin Gu, Gus Xia", "title": "POP909: A Pop-song Dataset for Music Arrangement Generation", "comments": null, "journal-ref": "In Proceedings of 21st International Conference on Music\n  Information Retrieval (ISMIR), Montreal, Canada (virtual conference), 2020", "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music arrangement generation is a subtask of automatic music generation,\nwhich involves reconstructing and re-conceptualizing a piece with new\ncompositional techniques. Such a generation process inevitably requires\nreference from the original melody, chord progression, or other structural\ninformation. Despite some promising models for arrangement, they lack more\nrefined data to achieve better evaluations and more practical results. In this\npaper, we propose POP909, a dataset which contains multiple versions of the\npiano arrangements of 909 popular songs created by professional musicians. The\nmain body of the dataset contains the vocal melody, the lead instrument melody,\nand the piano accompaniment for each song in MIDI format, which are aligned to\nthe original audio files. Furthermore, we provide the annotations of tempo,\nbeat, key, and chords, where the tempo curves are hand-labeled and others are\ndone by MIR algorithms. Finally, we conduct several baseline experiments with\nthis dataset using standard deep music generation algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 08:08:14 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wang", "Ziyu", ""], ["Chen", "Ke", ""], ["Jiang", "Junyan", ""], ["Zhang", "Yiyi", ""], ["Xu", "Maoran", ""], ["Dai", "Shuqi", ""], ["Gu", "Xianbin", ""], ["Xia", "Gus", ""]]}, {"id": "2008.07146", "submitter": "Yuta Saito", "authors": "Yuta Saito, Shunsuke Aihara, Megumi Matsutani, Yusuke Narita", "title": "Open Bandit Dataset and Pipeline: Towards Realistic and Reproducible\n  Off-Policy Evaluation", "comments": "Please follow the updates of the whole project at\n  https://groups.google.com/g/open-bandit-project", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy evaluation (OPE) aims to estimate the performance of hypothetical\npolicies using data generated by a different policy. Because of its huge\npotential impact, there has been growing research interest in OPE. There is,\nhowever, no real-world public dataset that enables the evaluation of OPE,\nmaking its experimental studies unrealistic and irreproducible. With the goal\nof enabling realistic and reproducible OPE research, we publicize the Open\nBandit Dataset collected on a large-scale fashion e-commerce platform,\nZOZOTOWN. Our dataset is unique in that it contains a set of multiple logged\nbandit feedback datasets collected by running different policies on the same\nplatform. This enables realistic and reproducible experimental comparisons of\ndifferent OPE estimators for the first time. We also develop Python software\ncalled the Open Bandit Pipeline to streamline and standardize the\nimplementations of bandit algorithms and OPE. Our open data and pipeline will\ncontribute to the fair and transparent OPE research and help the community\nidentify fruitful research directions. Finally, we provide extensive benchmark\nexperiments of existing OPE estimators using our data and pipeline. Our\nexperiments open up essential challenges and new avenues for future OPE\nresearch. Our pipeline and example data are available at\nhttps://github.com/st-tech/zr-obp.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 08:23:50 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 14:39:36 GMT"}, {"version": "v3", "created": "Sat, 6 Feb 2021 18:11:53 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Saito", "Yuta", ""], ["Aihara", "Shunsuke", ""], ["Matsutani", "Megumi", ""], ["Narita", "Yusuke", ""]]}, {"id": "2008.07180", "submitter": "Antonious Girgis Mamdouh", "authors": "Antonious M. Girgis, Deepesh Data, Suhas Diggavi, Peter Kairouz, and\n  Ananda Theertha Suresh", "title": "Shuffled Model of Federated Learning: Privacy, Communication and\n  Accuracy Trade-offs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a distributed empirical risk minimization (ERM) optimization\nproblem with communication efficiency and privacy requirements, motivated by\nthe federated learning (FL) framework. Unique challenges to the traditional ERM\nproblem in the context of FL include (i) need to provide privacy guarantees on\nclients' data, (ii) compress the communication between clients and the server,\nsince clients might have low-bandwidth links, (iii) work with a dynamic client\npopulation at each round of communication between the server and the clients,\nas a small fraction of clients are sampled at each round. To address these\nchallenges we develop (optimal) communication-efficient schemes for private\nmean estimation for several $\\ell_p$ spaces, enabling efficient gradient\naggregation for each iteration of the optimization solution of the ERM. We also\nprovide lower and upper bounds for mean estimation with privacy and\ncommunication constraints for arbitrary $\\ell_p$ spaces. To get the overall\ncommunication, privacy, and optimization performance operation point, we\ncombine this with privacy amplification opportunities inherent to this setup.\nOur solution takes advantage of the inherent privacy amplification provided by\nclient sampling and data sampling at each client (through Stochastic Gradient\nDescent) as well as the recently developed privacy framework using\nanonymization, which effectively presents to the server responses that are\nrandomly shuffled with respect to the clients. Putting these together, we\ndemonstrate that one can get the same privacy, optimization-performance\noperating point developed in recent methods that use full-precision\ncommunication, but at a much lower communication cost, i.e., effectively\ngetting communication efficiency for \"free\".\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 09:41:04 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 16:54:50 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Girgis", "Antonious M.", ""], ["Data", "Deepesh", ""], ["Diggavi", "Suhas", ""], ["Kairouz", "Peter", ""], ["Suresh", "Ananda Theertha", ""]]}, {"id": "2008.07191", "submitter": "Mostafa Sadeghi", "authors": "Viet-Nhat Nguyen, Mostafa Sadeghi, Elisa Ricci, Xavier Alameda-Pineda", "title": "Deep Variational Generative Models for Audio-visual Speech Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we are interested in audio-visual speech separation given a\nsingle-channel audio recording as well as visual information (lips movements)\nassociated with each speaker. We propose an unsupervised technique based on\naudio-visual generative modeling of clean speech. More specifically, during\ntraining, a latent variable generative model is learned from clean speech\nspectrograms using a variational auto-encoder (VAE). To better utilize the\nvisual information, the posteriors of the latent variables are inferred from\nmixed speech (instead of clean speech) as well as the visual data. The visual\nmodality also serves as a prior for latent variables, through a visual network.\nAt test time, the learned generative model (both for speaker-independent and\nspeaker-dependent scenarios) is combined with an unsupervised non-negative\nmatrix factorization (NMF) variance model for background noise. All the latent\nvariables and noise parameters are then estimated by a Monte Carlo\nexpectation-maximization algorithm. Our experiments show that the proposed\nunsupervised VAE-based method yields better separation performance than\nNMF-based approaches as well as a supervised deep learning-based technique.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 10:12:33 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Nguyen", "Viet-Nhat", ""], ["Sadeghi", "Mostafa", ""], ["Ricci", "Elisa", ""], ["Alameda-Pineda", "Xavier", ""]]}, {"id": "2008.07192", "submitter": "Antonio Ferrara", "authors": "Vito Walter Anelli, Yashar Deldjoo, Tommaso Di Noia, Antonio Ferrara,\n  Fedelucio Narducci", "title": "How to Put Users in Control of their Data in Federated Top-N\n  Recommendation with Learning to Rank", "comments": "Accepted at the 36th ACM/SIGAPP Symposium on Applied Computing (SAC\n  '21)", "journal-ref": null, "doi": "10.1145/3412841.3442010", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recommendation services are extensively adopted in several user-centered\napplications as a tool to alleviate the information overload problem and help\nusers in orienteering in a vast space of possible choices. In such scenarios,\ndata ownership is a crucial concern since users may not be willing to share\ntheir sensitive preferences (e.g., visited locations) with a central server.\nUnfortunately, data harvesting and collection is at the basis of modern,\nstate-of-the-art approaches to recommendation. To address this issue, we\npresent FPL, an architecture in which users collaborate in training a central\nfactorization model while controlling the amount of sensitive data leaving\ntheir devices. The proposed approach implements pair-wise learning-to-rank\noptimization by following the Federated Learning principles, originally\nconceived to mitigate the privacy risks of traditional machine learning. The\npublic implementation is available at https://split.to/sisinflab-fpl.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 10:13:15 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 15:45:41 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 20:24:20 GMT"}, {"version": "v4", "created": "Tue, 22 Dec 2020 10:14:40 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Anelli", "Vito Walter", ""], ["Deldjoo", "Yashar", ""], ["Di Noia", "Tommaso", ""], ["Ferrara", "Antonio", ""], ["Narducci", "Fedelucio", ""]]}, {"id": "2008.07207", "submitter": "David Melhart", "authors": "David Melhart, Daniele Gravina, Georgios N. Yannakakis", "title": "Moment-to-moment Engagement Prediction through the Eyes of the Observer:\n  PUBG Streaming on Twitch", "comments": "Version accepted for the Conference on the Foundations of Digital\n  Games 2020 - Malta", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is it possible to predict moment-to-moment gameplay engagement based solely\non game telemetry? Can we reveal engaging moments of gameplay by observing the\nway the viewers of the game behave? To address these questions in this paper,\nwe reframe the way gameplay engagement is defined and we view it, instead,\nthrough the eyes of a game's live audience. We build prediction models for\nviewers' engagement based on data collected from the popular battle royale game\nPlayerUnknown's Battlegrounds as obtained from the Twitch streaming service. In\nparticular, we collect viewers' chat logs and in-game telemetry data from\nseveral hundred matches of five popular streamers (containing over 100,000 game\nevents) and machine learn the mapping between gameplay and viewer chat\nfrequency during play, using small neural network architectures. Our key\nfindings showcase that engagement models trained solely on 40 gameplay features\ncan reach accuracies of up to 80% on average and 84% at best. Our models are\nscalable and generalisable as they perform equally well within- and\nacross-streamers, as well as across streamer play styles.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 10:40:34 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Melhart", "David", ""], ["Gravina", "Daniele", ""], ["Yannakakis", "Georgios N.", ""]]}, {"id": "2008.07225", "submitter": "Pooyan Safari", "authors": "Pooyan Safari, Behnam Shariati, Johannes Karl Fischer", "title": "Privacy-Preserving Distributed Learning Framework for 6G Telecom\n  Ecosystems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a privacy-preserving distributed learning framework for telecom\necosystems in the 6G-era that enables the vision of shared ownership and\ngovernance of ML models, while protecting the privacy of the data owners. We\ndemonstrate its benefits by applying it to the use-case of Quality of\nTransmission (QoT) estimation in multi-domain multi-vendor optical networks,\nwhere no data of individual domains is shared with the network management\nsystem (NMS).\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 11:16:44 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Safari", "Pooyan", ""], ["Shariati", "Behnam", ""], ["Fischer", "Johannes Karl", ""]]}, {"id": "2008.07230", "submitter": "Ji Guan", "authors": "Ji Guan, Wang Fang, and Mingsheng Ying", "title": "Robustness Verification of Quantum Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Several important models of machine learning algorithms have been\nsuccessfully generalized to the quantum world, with potential speedup to\ntraining classical classifiers and applications to data analytics in quantum\nphysics that can be implemented on the near future quantum computers. However,\nquantum noise is a major obstacle to the practical implementation of quantum\nmachine learning. In this work, we define a formal framework for the robustness\nverification and analysis of quantum machine learning algorithms against\nnoises. A robust bound is derived and an algorithm is developed to check\nwhether or not a quantum machine learning algorithm is robust with respect to\nquantum training data. In particular, this algorithm can find adversarial\nexamples during checking. Our approach is implemented on Google's TensorFlow\nQuantum and can verify the robustness of quantum machine learning algorithms\nwith respect to a small disturbance of noises, derived from the surrounding\nenvironment. The effectiveness of our robust bound and algorithm is confirmed\nby the experimental results, including quantum bits classification as the\n\"Hello World\" example, quantum phase recognition and cluster excitation\ndetection from real world intractable physical problems, and the classification\nof MNIST from the classical world.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 11:56:23 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 15:59:52 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Guan", "Ji", ""], ["Fang", "Wang", ""], ["Ying", "Mingsheng", ""]]}, {"id": "2008.07231", "submitter": "Piotr Masztalski", "authors": "Piotr Masztalski, Mateusz Matuszewski, Karol Piaskowski, Micha{\\l}\n  Romaniuk", "title": "StoRIR: Stochastic Room Impulse Response Generation for Audio Data\n  Augmentation", "comments": "Accepted for INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce StoRIR - a stochastic room impulse response\ngeneration method dedicated to audio data augmentation in machine learning\napplications. This technique, in contrary to geometrical methods like\nimage-source or ray tracing, does not require prior definition of room\ngeometry, absorption coefficients or microphone and source placement and is\ndependent solely on the acoustic parameters of the room. The method is\nintuitive, easy to implement and allows to generate RIRs of very complicated\nenclosures. We show that StoRIR, when used for audio data augmentation in a\nspeech enhancement task, allows deep learning models to achieve better results\non a wide range of metrics than when using the conventional image-source\nmethod, effectively improving many of them by more than 5 %. We publish a\nPython implementation of StoRIR online\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 11:56:47 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Masztalski", "Piotr", ""], ["Matuszewski", "Mateusz", ""], ["Piaskowski", "Karol", ""], ["Romaniuk", "Micha\u0142", ""]]}, {"id": "2008.07234", "submitter": "Ines Rieger", "authors": "Jaspar Pahl, Ines Rieger, Dominik Seuss", "title": "Multi-label Learning with Missing Values using Combined Facial Action\n  Unit Datasets", "comments": "Presented at the first Workshop on the Art of Learning with Missing\n  Values (Artemiss) hosted by the 37th International Conference on Machine\n  Learning (ICML) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial action units allow an objective, standardized description of facial\nmicro movements which can be used to describe emotions in human faces.\nAnnotating data for action units is an expensive and time-consuming task, which\nleads to a scarce data situation. By combining multiple datasets from different\nstudies, the amount of training data for a machine learning algorithm can be\nincreased in order to create robust models for automated, multi-label action\nunit detection. However, every study annotates different action units, leading\nto a tremendous amount of missing labels in a combined database. In this work,\nwe examine this challenge and present our approach to create a combined\ndatabase and an algorithm capable of learning under the presence of missing\nlabels without inferring their values. Our approach shows competitive\nperformance compared to recent competitions in action unit detection.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 11:58:06 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Pahl", "Jaspar", ""], ["Rieger", "Ines", ""], ["Seuss", "Dominik", ""]]}, {"id": "2008.07235", "submitter": "Yantong Wang", "authors": "Yantong Wang, Vasilis Friderikos", "title": "A Survey of Deep Learning for Data Caching in Edge Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of edge caching provision in emerging 5G and beyond mobile\nnetworks is a promising method to deal both with the traffic congestion problem\nin the core network as well as reducing latency to access popular content. In\nthat respect end user demand for popular content can be satisfied by\nproactively caching it at the network edge, i.e, at close proximity to the\nusers. In addition to model based caching schemes learning-based edge caching\noptimizations has recently attracted significant attention and the aim\nhereafter is to capture these recent advances for both model based and data\ndriven techniques in the area of proactive caching. This paper summarizes the\nutilization of deep learning for data caching in edge network. We first outline\nthe typical research topics in content caching and formulate a taxonomy based\non network hierarchical structure. Then, a number of key types of deep learning\nalgorithms are presented, ranging from supervised learning to unsupervised\nlearning as well as reinforcement learning. Furthermore, a comparison of\nstate-of-the-art literature is provided from the aspects of caching topics and\ndeep learning methods. Finally, we discuss research challenges and future\ndirections of applying deep learning for caching\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 12:02:32 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Wang", "Yantong", ""], ["Friderikos", "Vasilis", ""]]}, {"id": "2008.07240", "submitter": "Wei Pan", "authors": "Qingrui Zhang and Wei Pan and Vasso Reppa", "title": "Model-Reference Reinforcement Learning for Collision-Free Tracking\n  Control of Autonomous Surface Vehicles", "comments": "Extension of arXiv:2003.13839", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.RO cs.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a novel model-reference reinforcement learning algorithm\nfor the intelligent tracking control of uncertain autonomous surface vehicles\nwith collision avoidance. The proposed control algorithm combines a\nconventional control method with reinforcement learning to enhance control\naccuracy and intelligence. In the proposed control design, a nominal system is\nconsidered for the design of a baseline tracking controller using a\nconventional control approach. The nominal system also defines the desired\nbehaviour of uncertain autonomous surface vehicles in an obstacle-free\nenvironment. Thanks to reinforcement learning, the overall tracking controller\nis capable of compensating for model uncertainties and achieving collision\navoidance at the same time in environments with obstacles. In comparison to\ntraditional deep reinforcement learning methods, our proposed learning-based\ncontrol can provide stability guarantees and better sample efficiency. We\ndemonstrate the performance of the new algorithm using an example of autonomous\nsurface vehicles.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 12:15:15 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Zhang", "Qingrui", ""], ["Pan", "Wei", ""], ["Reppa", "Vasso", ""]]}, {"id": "2008.07244", "submitter": "Piotr Masztalski", "authors": "Micha{\\l} Romaniuk, Piotr Masztalski, Karol Piaskowski, Mateusz\n  Matuszewski", "title": "Efficient Low-Latency Speech Enhancement with Mobile Audio Streaming\n  Networks", "comments": "Accepted for INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Mobile Audio Streaming Networks (MASnet) for efficient low-latency\nspeech enhancement, which is particularly suitable for mobile devices and other\napplications where computational capacity is a limitation. MASnet processes\nlinear-scale spectrograms, transforming successive noisy frames into\ncomplex-valued ratio masks which are then applied to the respective noisy\nframes. MASnet can operate in a low-latency incremental inference mode which\nmatches the complexity of layer-by-layer batch mode. Compared to a similar\nfully-convolutional architecture, MASnet incorporates depthwise and pointwise\nconvolutions for a large reduction in fused multiply-accumulate operations per\nsecond (FMA/s), at the cost of some reduction in SNR.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 12:18:34 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Romaniuk", "Micha\u0142", ""], ["Masztalski", "Piotr", ""], ["Piaskowski", "Karol", ""], ["Matuszewski", "Mateusz", ""]]}, {"id": "2008.07247", "submitter": "Krzysztof Rykaczewski", "authors": "Zuzanna Kwiatkowska, Beniamin Kalinowski, Micha{\\l} Ko\\'smider,\n  Krzysztof Rykaczewski", "title": "Deep Learning Based Open Set Acoustic Scene Classification", "comments": "This paper was submitted to conference INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we compare the performance of three selected techniques in open\nset acoustic scenes classification (ASC). We test thresholding of the softmax\noutput of a deep network classifier, which is the most popular technique\nnowadays employed in ASC. Further we compare the results with the Openmax\nclassifier which is derived from the computer vision field. As the third model,\nwe use the Adapted Class-Conditioned Autoencoder (Adapted C2AE) which is our\nvariation of another computer vision related technique called C2AE. Adapted\nC2AE encompasses a more fair comparison of the given experiments and simplifies\nthe original inference procedure, making it more applicable in the real-life\nscenarios. We also analyse two training scenarios: without additional knowledge\nof unknown classes and another where a limited subset of examples from the\nunknown classes is available. We find that the C2AE based method outperforms\nthe thresholding and Openmax, obtaining $85.5\\%$ Area Under the Receiver\nOperating Characteristic curve (AUROC) and $66\\%$ of open set accuracy on data\nused in Detection and Classification of Acoustic Scenes and Events Challenge\n2019 Task 1C.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 12:23:27 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Kwiatkowska", "Zuzanna", ""], ["Kalinowski", "Beniamin", ""], ["Ko\u015bmider", "Micha\u0142", ""], ["Rykaczewski", "Krzysztof", ""]]}, {"id": "2008.07249", "submitter": "Reza Malekian Ph.D.", "authors": "Jessica Quach, Reza Malekian", "title": "Exploring the weather impact on bike sharing usage through a clustering\n  analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bike sharing systems (BSS) have been a popular traveling service for years\nand are used worldwide. It is attractive for cities and users who wants to\npromote healthier lifestyles; to reduce air pollution and greenhouse gas\nemission as well as improve traffic. One major challenge to docked bike sharing\nsystem is redistributing bikes and balancing dock stations. Some studies\npropose models that can help forecasting bike usage; strategies for rebalancing\nbike distribution; establish patterns or how to identify patterns. Other\nstudies propose to extend the approach by including weather data. This study\naims to extend upon these proposals and opportunities to explore how and in\nwhat magnitude weather impacts bike usage. Bike usage data and weather data are\ngathered for the city of Washington D.C. and are analyzed using k-means\nclustering algorithm. K-means managed to identify three clusters that\ncorrespond to bike usage depending on weather conditions. The results show that\nthe weather impact on bike usage was noticeable between clusters. It showed\nthat temperature followed by precipitation weighted the most, out of five\nweather variables.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 12:24:37 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Quach", "Jessica", ""], ["Malekian", "Reza", ""]]}, {"id": "2008.07257", "submitter": "Yuan Liang", "authors": "Yuan Liang, Yange Guo, Yanxia Gong, Chunjie Luo, Jianfeng Zhan, Yunyou\n  Huang", "title": "FLBench: A Benchmark Suite for Federated Learning", "comments": "12 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a new machine learning paradigm. The goal is to build a\nmachine learning model from the data sets distributed on multiple devices\nso-called an isolated data island, while keeping their data secure and private.\nMost existing federated learning benchmarks work manually splits commonly used\npublic datasets into partitions to simulate real world isolated data island\nscenarios. Still, this simulation fails to capture real world isolated data\nisland intrinsic characteristics. This paper presents a federated learning (FL)\nbenchmark suite named FLBench. FLBench contains three domains: medical,\nfinancial, and AIoT. By configuring various domains, FLBench is qualified to\nevaluate federated learning systems and algorithms essential aspects, like\ncommunication, scenario transformation, privacy-preserving, data distribution\nheterogeneity, and cooperation strategy. Hence, it becomes a promising platform\nfor developing novel federated learning algorithms. Currently, FLBench is open\nsourced and in fast evolution. We package it as an automated deployment tool.\nThe benchmark suite is available from\nhttps://www.benchcouncil.org/flbench.html.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 12:41:46 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 11:08:56 GMT"}, {"version": "v3", "created": "Fri, 12 Mar 2021 02:22:31 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Liang", "Yuan", ""], ["Guo", "Yange", ""], ["Gong", "Yanxia", ""], ["Luo", "Chunjie", ""], ["Zhan", "Jianfeng", ""], ["Huang", "Yunyou", ""]]}, {"id": "2008.07263", "submitter": "Jing Zhang", "authors": "Jing Zhang, Deng Liang, Aiping Liu, Min Gao, Xiang Chen, Xu Zhang, Xun\n  Chen", "title": "MLBF-Net: A Multi-Lead-Branch Fusion Network for Multi-Class Arrhythmia\n  Classification Using 12-Lead ECG", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic arrhythmia detection using 12-lead electrocardiogram (ECG) signal\nplays a critical role in early prevention and diagnosis of cardiovascular\ndiseases. In the previous studies on automatic arrhythmia detection, most\nmethods concatenated 12 leads of ECG into a matrix, and then input the matrix\nto a variety of feature extractors or deep neural networks for extracting\nuseful information. Under such frameworks, these methods had the ability to\nextract comprehensive features (known as integrity) of 12-lead ECG since the\ninformation of each lead interacts with each other during training. However,\nthe diverse lead-specific features (known as diversity) among 12 leads were\nneglected, causing inadequate information learning for 12-lead ECG. To maximize\nthe information learning of multi-lead ECG, the information fusion of\ncomprehensive features with integrity and lead-specific features with diversity\nshould be taken into account. In this paper, we propose a novel\nMulti-Lead-Branch Fusion Network (MLBF-Net) architecture for arrhythmia\nclassification by integrating multi-loss optimization to jointly learning\ndiversity and integrity of multi-lead ECG. MLBF-Net is composed of three\ncomponents: 1) multiple lead-specific branches for learning the diversity of\nmulti-lead ECG; 2) cross-lead features fusion by concatenating the output\nfeature maps of all branches for learning the integrity of multi-lead ECG; 3)\nmulti-loss co-optimization for all the individual branches and the concatenated\nnetwork. We demonstrate our MLBF-Net on China Physiological Signal Challenge\n2018 which is an open 12-lead ECG dataset. The experimental results show that\nMLBF-Net obtains an average $F_1$ score of 0.855, reaching the highest\narrhythmia classification performance. The proposed method provides a promising\nsolution for multi-lead ECG analysis from an information fusion perspective.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 12:51:39 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Zhang", "Jing", ""], ["Liang", "Deng", ""], ["Liu", "Aiping", ""], ["Gao", "Min", ""], ["Chen", "Xiang", ""], ["Zhang", "Xu", ""], ["Chen", "Xun", ""]]}, {"id": "2008.07267", "submitter": "Christopher Schr\\\"oder", "authors": "Christopher Schr\\\"oder and Andreas Niekler", "title": "A Survey of Active Learning for Text Classification using Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Natural language processing (NLP) and neural networks (NNs) have both\nundergone significant changes in recent years. For active learning (AL)\npurposes, NNs are, however, less commonly used -- despite their current\npopularity. By using the superior text classification performance of NNs for\nAL, we can either increase a model's performance using the same amount of data\nor reduce the data and therefore the required annotation efforts while keeping\nthe same performance. We review AL for text classification using deep neural\nnetworks (DNNs) and elaborate on two main causes which used to hinder the\nadoption: (a) the inability of NNs to provide reliable uncertainty estimates,\non which the most commonly used query strategies rely, and (b) the challenge of\ntraining DNNs on small data. To investigate the former, we construct a taxonomy\nof query strategies, which distinguishes between data-based, model-based, and\nprediction-based instance selection, and investigate the prevalence of these\nclasses in recent research. Moreover, we review recent NN-based advances in NLP\nlike word embeddings or language models in the context of (D)NNs, survey the\ncurrent state-of-the-art at the intersection of AL, text classification, and\nDNNs and relate recent advances in NLP to AL. Finally, we analyze recent work\nin AL for text classification, connect the respective query strategies to the\ntaxonomy, and outline commonalities and shortcomings. As a result, we highlight\ngaps in current research and present open research questions.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 12:53:20 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Schr\u00f6der", "Christopher", ""], ["Niekler", "Andreas", ""]]}, {"id": "2008.07275", "submitter": "Damian Borth", "authors": "L\\'ea Steinacker, Miriam Meckel, Genia Kostka, Damian Borth", "title": "Facial Recognition: A cross-national Survey on Public Acceptance,\n  Privacy, and Discrimination", "comments": "ICML 2020 - Law and Machine Learning Workshop, Vienna, Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With rapid advances in machine learning (ML), more of this technology is\nbeing deployed into the real world interacting with us and our environment. One\nof the most widely applied application of ML is facial recognition as it is\nrunning on millions of devices. While being useful for some people, others\nperceive it as a threat when used by public authorities. This discrepancy and\nthe lack of policy increases the uncertainty in the ML community about the\nfuture direction of facial recognition research and development. In this paper\nwe present results from a cross-national survey about public acceptance,\nprivacy, and discrimination of the use of facial recognition technology (FRT)\nin the public. This study provides insights about the opinion towards FRT from\nChina, Germany, the United Kingdom (UK), and the United States (US), which can\nserve as input for policy makers and legal regulators.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 14:17:21 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Steinacker", "L\u00e9a", ""], ["Meckel", "Miriam", ""], ["Kostka", "Genia", ""], ["Borth", "Damian", ""]]}, {"id": "2008.07277", "submitter": "Renlong Jie", "authors": "Renlong Jie, Junbin Gao, Andrey Vasnev and Minh-Ngoc Tran", "title": "Adaptive Hierarchical Hyper-gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we investigate learning rate adaption at different levels\nbased on the hyper-gradient descent framework and propose a method that\nadaptively learns the optimizer parameters by combining multiple levels of\nlearning rates with hierarchical structures. Meanwhile, we show the\nrelationship between regularizing over-parameterized learning rates and\nbuilding combinations of adaptive learning rates at different levels. The\nexperiments on several network architectures, including feed-forward networks,\nLeNet-5 and ResNet-18/34, show that the proposed multi-level adaptive approach\ncan outperform baseline adaptive methods in a variety of circumstances.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 13:01:36 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 13:19:18 GMT"}, {"version": "v3", "created": "Tue, 11 May 2021 06:48:55 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Jie", "Renlong", ""], ["Gao", "Junbin", ""], ["Vasnev", "Andrey", ""], ["Tran", "Minh-Ngoc", ""]]}, {"id": "2008.07278", "submitter": "Vishwali Mhasawade", "authors": "Vishwali Mhasawade, Yuan Zhao, Rumi Chunara", "title": "Machine Learning in Population and Public Health", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in population and public health focuses on the mechanisms between\ndifferent cultural, social, and environmental factors and their effect on the\nhealth, of not just individuals, but communities as a whole. We present here a\nvery brief introduction into research in these fields, as well as connections\nto existing machine learning work to help activate the machine learning\ncommunity on such topics and highlight specific opportunities where machine\nlearning, public and population health may synergize to better achieve health\nequity.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 14:10:00 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Mhasawade", "Vishwali", ""], ["Zhao", "Yuan", ""], ["Chunara", "Rumi", ""]]}, {"id": "2008.07280", "submitter": "Manan Dey", "authors": "Shanya Sharma and Manan Dey", "title": "Assessing Viewer's Mental Health by Detecting Depression in YouTube\n  Videos", "comments": "AI for Social Good workshop at NeurIPS (2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Depression is one of the most prevalent mental health issues around the\nworld, proving to be one of the leading causes of suicide and placing large\neconomic burdens on families and society. In this paper, we develop and test\nthe efficacy of machine learning techniques applied to the content of YouTube\nvideos captured through their transcripts and determine if the videos are\ndepressive or have a depressing trigger. Our model can detect depressive videos\nwith an accuracy of 83%. We also introduce a real-life evaluation technique to\nvalidate our classification based on the comments posted on a video by\ncalculating the CES-D scores of the comments. This work conforms greatly with\nthe UN Sustainable Goal of ensuring Good Health and Well Being with major\nconformity with section UN SDG 3.4.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 16:17:35 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sharma", "Shanya", ""], ["Dey", "Manan", ""]]}, {"id": "2008.07281", "submitter": "Jun Qi", "authors": "Jun Qi, Jun Du, Sabato Marco Siniscalchi, Xiaoli Ma, Chin-Hui Lee", "title": "On Mean Absolute Error for Deep Neural Network Based Vector-to-Vector\n  Regression", "comments": null, "journal-ref": "IEEE Signal Processing Letters, 2020", "doi": "10.1109/LSP.2020.3016837", "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we exploit the properties of mean absolute error (MAE) as a\nloss function for the deep neural network (DNN) based vector-to-vector\nregression. The goal of this work is two-fold: (i) presenting performance\nbounds of MAE, and (ii) demonstrating new properties of MAE that make it more\nappropriate than mean squared error (MSE) as a loss function for DNN based\nvector-to-vector regression. First, we show that a generalized upper-bound for\nDNN-based vector- to-vector regression can be ensured by leveraging the known\nLipschitz continuity property of MAE. Next, we derive a new generalized upper\nbound in the presence of additive noise. Finally, in contrast to conventional\nMSE commonly adopted to approximate Gaussian errors for regression, we show\nthat MAE can be interpreted as an error modeled by Laplacian distribution.\nSpeech enhancement experiments are conducted to corroborate our proposed\ntheorems and validate the performance advantages of MAE over MSE for DNN based\nregression.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 22:41:26 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Qi", "Jun", ""], ["Du", "Jun", ""], ["Siniscalchi", "Sabato Marco", ""], ["Ma", "Xiaoli", ""], ["Lee", "Chin-Hui", ""]]}, {"id": "2008.07283", "submitter": "Sergio Garrido", "authors": "Sergio Garrido, Stanislav S. Borysov, Jeppe Rich, Francisco C. Pereira", "title": "Estimating Causal Effects with the Neural Autoregressive Density\n  Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of causal effects is fundamental in situations were the underlying\nsystem will be subject to active interventions. Part of building a causal\ninference engine is defining how variables relate to each other, that is,\ndefining the functional relationship between variables given conditional\ndependencies. In this paper, we deviate from the common assumption of linear\nrelationships in causal models by making use of neural autoregressive density\nestimators and use them to estimate causal effects within the Pearl's\ndo-calculus framework. Using synthetic data, we show that the approach can\nretrieve causal effects from non-linear systems without explicitly modeling the\ninteractions between the variables.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 13:12:38 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 13:03:20 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Garrido", "Sergio", ""], ["Borysov", "Stanislav S.", ""], ["Rich", "Jeppe", ""], ["Pereira", "Francisco C.", ""]]}, {"id": "2008.07284", "submitter": "Eiji Uchibe", "authors": "Eiji Uchibe and Kenji Doya", "title": "Imitation learning based on entropy-regularized forward and inverse\n  reinforcement learning", "comments": "33 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes Entropy-Regularized Imitation Learning (ERIL), which is a\ncombination of forward and inverse reinforcement learning under the framework\nof the entropy-regularized Markov decision process. ERIL minimizes the reverse\nKullback-Leibler (KL) divergence between two probability distributions induced\nby a learner and an expert. Inverse reinforcement learning (RL) in ERIL\nevaluates the log-ratio between two distributions using the density ratio\ntrick, which is widely used in generative adversarial networks. More\nspecifically, the log-ratio is estimated by building two binary discriminators.\nThe first discriminator is a state-only function, and it tries to distinguish\nthe state generated by the forward RL step from the expert's state. The second\ndiscriminator is a function of current state, action, and transitioned state,\nand it distinguishes the generated experiences from the ones provided by the\nexpert. Since the second discriminator has the same hyperparameters of the\nforward RL step, it can be used to control the discriminator's ability. The\nforward RL minimizes the reverse KL estimated by the inverse RL. We show that\nminimizing the reverse KL divergence is equivalent to finding an optimal policy\nunder entropy regularization. Consequently, a new policy is derived from an\nalgorithm that resembles Dynamic Policy Programming and Soft Actor-Critic. Our\nexperimental results on MuJoCo-simulated environments show that ERIL is more\nsample-efficient than such previous methods. We further apply the method to\nhuman behaviors in performing a pole-balancing task and show that the estimated\nreward functions show how every subject achieves the goal.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 13:12:44 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Uchibe", "Eiji", ""], ["Doya", "Kenji", ""]]}, {"id": "2008.07298", "submitter": "Buse Gul Atli Tekgul", "authors": "Buse Gul Atli, Yuxi Xia, Samuel Marchal, N. Asokan", "title": "WAFFLE: Watermarking in Federated Learning", "comments": "Will appear in the proceedings of SRDS 2021; 14 pages, 11 figures, 10\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning is a distributed learning technique where machine learning\nmodels are trained on client devices in which the local training data resides.\nThe training is coordinated via a central server which is, typically,\ncontrolled by the intended owner of the resulting model. By avoiding the need\nto transport the training data to the central server, federated learning\nimproves privacy and efficiency. But it raises the risk of model theft by\nclients because the resulting model is available on every client device. Even\nif the application software used for local training may attempt to prevent\ndirect access to the model, a malicious client may bypass any such restrictions\nby reverse engineering the application software. Watermarking is a well-known\ndeterrence method against model theft by providing the means for model owners\nto demonstrate ownership of their models. Several recent deep neural network\n(DNN) watermarking techniques use backdooring: training the models with\nadditional mislabeled data. Backdooring requires full access to the training\ndata and control of the training process. This is feasible when a single party\ntrains the model in a centralized manner, but not in a federated learning\nsetting where the training process and training data are distributed among\nseveral client devices. In this paper, we present WAFFLE, the first approach to\nwatermark DNN models trained using federated learning. It introduces a\nretraining step at the server after each aggregation of local models into the\nglobal model. We show that WAFFLE efficiently embeds a resilient watermark into\nmodels incurring only negligible degradation in test accuracy (-0.17%), and\ndoes not require access to training data. We also introduce a novel technique\nto generate the backdoor used as a watermark. It outperforms prior techniques,\nimposing no communication, and low computational (+3.2%) overhead.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 13:27:45 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 13:33:02 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 10:04:49 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Atli", "Buse Gul", ""], ["Xia", "Yuxi", ""], ["Marchal", "Samuel", ""], ["Asokan", "N.", ""]]}, {"id": "2008.07303", "submitter": "Philipp Geiger", "authors": "Philipp Geiger, Christoph-Nikolas Straehle", "title": "Learning game-theoretic models of multiagent trajectories using implicit\n  layers", "comments": "Accepted at AAAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For prediction of interacting agents' trajectories, we propose an end-to-end\ntrainable architecture that hybridizes neural nets with game-theoretic\nreasoning, has interpretable intermediate representations, and transfers to\ndownstream decision making. It uses a net that reveals preferences from the\nagents' past joint trajectory, and a differentiable implicit layer that maps\nthese preferences to local Nash equilibria, forming the modes of the predicted\nfuture trajectory. Additionally, it learns an equilibrium refinement concept.\nFor tractability, we introduce a new class of continuous potential games and an\nequilibrium-separating partition of the action space. We provide theoretical\nresults for explicit gradients and soundness. In experiments, we evaluate our\napproach on two real-world data sets, where we predict highway driver merging\ntrajectories, and on a simple decision-making transfer task.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 13:34:12 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 15:09:02 GMT"}, {"version": "v3", "created": "Thu, 17 Sep 2020 14:43:04 GMT"}, {"version": "v4", "created": "Wed, 9 Dec 2020 21:07:22 GMT"}, {"version": "v5", "created": "Tue, 2 Feb 2021 14:16:44 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Geiger", "Philipp", ""], ["Straehle", "Christoph-Nikolas", ""]]}, {"id": "2008.07309", "submitter": "Xavier Ferrer Aran", "authors": "Xavier Ferrer, Tom van Nuenen, Jose M. Such, Mark Cot\\'e and Natalia\n  Criado", "title": "Bias and Discrimination in AI: a cross-disciplinary perspective", "comments": null, "journal-ref": null, "doi": "10.1109/MTS.2021.3056293", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread and pervasive use of Artificial Intelligence (AI) for\nautomated decision-making systems, AI bias is becoming more apparent and\nproblematic. One of its negative consequences is discrimination: the unfair, or\nunequal treatment of individuals based on certain characteristics. However, the\nrelationship between bias and discrimination is not always clear. In this\npaper, we survey relevant literature about bias and discrimination in AI from\nan interdisciplinary perspective that embeds technical, legal, social and\nethical dimensions. We show that finding solutions to bias and discrimination\nin AI requires robust cross-disciplinary collaborations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 10:02:04 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Ferrer", "Xavier", ""], ["van Nuenen", "Tom", ""], ["Such", "Jose M.", ""], ["Cot\u00e9", "Mark", ""], ["Criado", "Natalia", ""]]}, {"id": "2008.07318", "submitter": "Suining He", "authors": "Xi Yang and Suining He", "title": "Towards Dynamic Urban Bike Usage Prediction for Station Network\n  Reconfiguration", "comments": "9 pages, UrbComp 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bike sharing has become one of the major choices of transportation for\nresidents in metropolitan cities worldwide. A station-based bike sharing system\nis usually operated in the way that a user picks up a bike from one station,\nand drops it off at another. Bike stations are, however, not static, as the\nbike stations are often reconfigured to accommodate changing demands or city\nurbanization over time. One of the key operations is to evaluate candidate\nlocations and install new stations to expand the bike sharing station network.\nConventional practices have been studied to predict existing station usage,\nwhile evaluating new stations is highly challenging due to the lack of the\nhistorical bike usage.\n  To fill this gap, in this work we propose a novel and efficient bike\nstation-level prediction algorithm called AtCoR, which can predict the bike\nusage at both existing and new stations (candidate locations during\nreconfiguration). In order to address the lack of historical data issues,\nvirtual historical usage of new stations is generated according to their\ncorrelations with the surrounding existing stations, for AtCoR model\ninitialization. We have designed novel station-centered heatmaps which\ncharacterize for each target station centered at the heatmap the trend that\nriders travel between it and the station's neighboring regions, enabling the\nmodel to capture the learnable features of the bike station network. The\ncaptured features are further applied to the prediction of bike usage for new\nstations. Our extensive experiment study on more than 23 million trips from\nthree major bike sharing systems in US, including New York City, Chicago and\nLos Angeles, shows that AtCoR outperforms baselines and state-of-art models in\nprediction of both existing and future stations.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 23:41:29 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Yang", "Xi", ""], ["He", "Suining", ""]]}, {"id": "2008.07320", "submitter": "Charlie Kirkwood", "authors": "Charlie Kirkwood, Theo Economou, Nicolas Pugeault", "title": "Bayesian deep learning for mapping via auxiliary information: a new era\n  for geostatistics?", "comments": "10 pages, 5 figures, version submitted to journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For geospatial modelling and mapping tasks, variants of kriging - the spatial\ninterpolation technique developed by South African mining engineer Danie Krige\n- have long been regarded as the established geostatistical methods. However,\nkriging and its variants (such as regression kriging, in which auxiliary\nvariables or derivatives of these are included as covariates) are relatively\nrestrictive models and lack capabilities that have been afforded to us in the\nlast decade by deep neural networks. Principal among these is feature learning\n- the ability to learn filters to recognise task-specific patterns in gridded\ndata such as images. Here we demonstrate the power of feature learning in a\ngeostatistical context, by showing how deep neural networks can automatically\nlearn the complex relationships between point-sampled target variables and\ngridded auxiliary variables (such as those provided by remote sensing), and in\ndoing so produce detailed maps of chosen target variables. At the same time, in\norder to cater for the needs of decision makers who require well-calibrated\nprobabilities, we obtain uncertainty estimates via a Bayesian approximation\nknown as Monte Carlo dropout. In our example, we produce a national-scale\nprobabilistic geochemical map from point-sampled assay data, with auxiliary\ninformation provided by a terrain elevation grid. Unlike traditional\ngeostatistical approaches, auxiliary variable grids are fed into our deep\nneural network raw. There is no need to provide terrain derivatives (e.g. slope\nangles, roughness, etc) because the deep neural network is capable of learning\nthese and arbitrarily more complex derivatives as necessary to maximise\npredictive performance. We hope our results will raise awareness of the\nsuitability of Bayesian deep learning - and its feature learning capabilities -\nfor large-scale geostatistical applications where uncertainty matters.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 13:56:43 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 12:11:59 GMT"}, {"version": "v3", "created": "Tue, 8 Sep 2020 20:22:04 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Kirkwood", "Charlie", ""], ["Economou", "Theo", ""], ["Pugeault", "Nicolas", ""]]}, {"id": "2008.07324", "submitter": "Karl Fezer", "authors": "Karl Fezer and Andrew Sloss", "title": "Intelligence Primer", "comments": "34 pages, 12 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This primer explores the exciting subject of intelligence. Intelligence is a\nfundamental component of all living things, as well as Artificial\nIntelligence(AI). Artificial Intelligence has the potential to affect all of\nour lives and a new era for modern humans. This paper is an attempt to explore\nthe ideas associated with intelligence, and by doing so understand the\nimplications, constraints, and potentially the capabilities of future\nArtificial Intelligence. As an exploration, we journey into different parts of\nintelligence that appear essential. We hope that people find this useful in\ndetermining where Artificial Intelligence may be headed. Also, during the\nexploration, we hope to create new thought-provoking questions. Intelligence is\nnot a single weighable quantity but a subject that spans Biology, Physics,\nPhilosophy, Cognitive Science, Neuroscience, Psychology, and Computer Science.\nHistorian Yuval Noah Harari pointed out that engineers and scientists in the\nfuture will have to broaden their understandings to include disciplines such as\nPsychology, Philosophy, and Ethics. Fiction writers have long portrayed\nengineers and scientists as deficient in these areas. Today, modern society,\nthe emergence of Artificial Intelligence, and legal requirements all act as\nforcing functions to push these broader subjects into the foreground. We start\nwith an introduction to intelligence and move quickly onto more profound\nthoughts and ideas. We call this a Life, the Universe and Everything primer,\nafter the famous science fiction book by Douglas Adams. Forty-two may very well\nbe the right answer, but what are the questions?\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 15:47:04 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 17:04:46 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Fezer", "Karl", ""], ["Sloss", "Andrew", ""]]}, {"id": "2008.07330", "submitter": "Puja Sahu", "authors": "Puja Sahu and Nandyala Hemachandra", "title": "Optimal Posteriors for Chi-squared Divergence based PAC-Bayesian Bounds\n  and Comparison with KL-divergence based Optimal Posteriors and\n  Cross-Validation Procedure", "comments": "arXiv admin note: text overlap with arXiv:1912.06803", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We investigate optimal posteriors for recently introduced \\cite{begin2016pac}\nchi-squared divergence based PAC-Bayesian bounds in terms of nature of their\ndistribution, scalability of computations, and test set performance. For a\nfinite classifier set, we deduce bounds for three distance functions:\nKL-divergence, linear and squared distances. Optimal posterior weights are\nproportional to deviations of empirical risks, usually with subset support. For\nuniform prior, it is sufficient to search among posteriors on classifier\nsubsets ordered by these risks. We show the bound minimization for linear\ndistance as a convex program and obtain a closed-form expression for its\noptimal posterior. Whereas that for squared distance is a quasi-convex program\nunder a specific condition, and the one for KL-divergence is non-convex\noptimization (a difference of convex functions). To compute such optimal\nposteriors, we derive fast converging fixed point (FP) equations. We apply\nthese approaches to a finite set of SVM regularization parameter values to\nyield stochastic SVMs with tight bounds. We perform a comprehensive performance\ncomparison between our optimal posteriors and known KL-divergence based\nposteriors on a variety of UCI datasets with varying ranges and variances in\nrisk values, etc. Chi-squared divergence based posteriors have weaker bounds\nand worse test errors, hinting at an underlying regularization by KL-divergence\nbased posteriors. Our study highlights the impact of divergence function on the\nperformance of PAC-Bayesian classifiers. We compare our stochastic classifiers\nwith cross-validation based deterministic classifier. The latter has better\ntest errors, but ours is more sample robust, has quantifiable generalization\nguarantees, and is computationally much faster.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 03:15:23 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sahu", "Puja", ""], ["Hemachandra", "Nandyala", ""]]}, {"id": "2008.07331", "submitter": "Shuby Deshpande", "authors": "Shuby Deshpande, Benjamin Eysenbach, Jeff Schneider", "title": "Interactive Visualization for Debugging RL", "comments": "Builds on preliminary work presented at ICML 2020 (WHI)\n  arXiv:2007.05577. An interactive demo of the system can be at\n  https://tinyurl.com/y5gv5t4m", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visualization tools for supervised learning allow users to interpret,\nintrospect, and gain an intuition for the successes and failures of their\nmodels. While reinforcement learning practitioners ask many of the same\nquestions, existing tools are not applicable to the RL setting as these tools\naddress challenges typically found in the supervised learning regime. In this\nwork, we design and implement an interactive visualization tool for debugging\nand interpreting RL algorithms. Our system addresses many features missing from\nprevious tools such as (1) tools for supervised learning often are not\ninteractive; (2) while debugging RL policies researchers use state\nrepresentations that are different from those seen by the agent; (3) a\nframework designed to make the debugging RL policies more conducive. We provide\nan example workflow of how this system could be used, along with ideas for\nfuture extensions.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 15:28:18 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 22:27:29 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Deshpande", "Shuby", ""], ["Eysenbach", "Benjamin", ""], ["Schneider", "Jeff", ""]]}, {"id": "2008.07338", "submitter": "Shawn Mcguire Mr.", "authors": "Shawn McGuire, Charles Delahunt", "title": "Predicting United States policy outcomes with Random Forests", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Two decades of U.S. government legislative outcomes, as well as the policy\npreferences of rich people, the general population, and diverse interest\ngroups, were captured in a detailed dataset curated and analyzed by Gilens,\nPage et al. (2014). They found that the preferences of the rich correlated\nstrongly with policy outcomes, while the preferences of the general population\ndid not, except via a linkage with rich people's preferences. Their analysis\napplied the tools of classical statistical inference, in particular logistic\nregression. In this paper we analyze the Gilens dataset using the complementary\ntools of Random Forest classifiers (RFs), from Machine Learning. We present two\nprimary findings, concerning respectively prediction and inference: (i) Holdout\ntest sets can be predicted with approximately 70% balanced accuracy by models\nthat consult only the preferences of rich people and a small number of powerful\ninterest groups, as well as policy area labels. These results include\nretrodiction, where models trained on pre-1997 cases predicted \"future\"\n(post-1997) cases. The 20% gain in accuracy over baseline (chance), in this\ndetailed but noisy dataset, indicates the high importance of a few wealthy\nplayers in U.S. policy outcomes, and aligns with a body of research indicating\nthat the U.S. government has significant plutocratic tendencies. (ii) The\nfeature selection methods of RF models identify especially salient subsets of\ninterest groups (economic players). These can be used to further investigate\nthe dynamics of governmental policy making, and also offer an example of the\npotential value of RF feature selection methods for inference on datasets such\nas this.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 18:06:57 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["McGuire", "Shawn", ""], ["Delahunt", "Charles", ""]]}, {"id": "2008.07343", "submitter": "Thanh Thi Nguyen", "authors": "Thanh Thi Nguyen, Quoc Viet Hung Nguyen, Dung Tien Nguyen, Edbert B.\n  Hsu, Samuel Yang, Peter Eklund", "title": "Artificial Intelligence in the Battle against Coronavirus (COVID-19): A\n  Survey and Future Research Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Artificial intelligence (AI) has been applied widely in our daily lives in a\nvariety of ways with numerous successful stories. AI has also contributed to\ndealing with the coronavirus disease (COVID-19) pandemic, which has been\nhappening around the globe. This paper presents a survey of AI methods being\nused in various applications in the fight against the COVID-19 outbreak and\noutlines the crucial roles of AI research in this unprecedented battle. We\ntouch on a number of areas where AI plays as an essential component, from\nmedical image processing, data analytics, text mining and natural language\nprocessing, the Internet of Things, to computational biology and medicine. A\nsummary of COVID-19 related data sources that are available for research\npurposes is also presented. Research directions on exploring the potentials of\nAI and enhancing its capabilities and power in the battle are thoroughly\ndiscussed. We highlight 13 groups of problems related to the COVID-19 pandemic\nand point out promising AI methods and tools that can be used to solve those\nproblems. It is envisaged that this study will provide AI researchers and the\nwider community an overview of the current status of AI applications and\nmotivate researchers in harnessing AI potentials in the fight against COVID-19.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 11:11:55 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 03:20:18 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Nguyen", "Thanh Thi", ""], ["Nguyen", "Quoc Viet Hung", ""], ["Nguyen", "Dung Tien", ""], ["Hsu", "Edbert B.", ""], ["Yang", "Samuel", ""], ["Eklund", "Peter", ""]]}, {"id": "2008.07349", "submitter": "Matthew Dirks", "authors": "Matthew Dirks, David Poole", "title": "Binarised Regression with Instance-Varying Costs: Evaluation using\n  Impact Curves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many evaluation methods exist, each for a particular prediction task, and\nthere are a number of prediction tasks commonly performed including\nclassification and regression. In binarised regression, binary decisions are\ngenerated from a learned regression model (or real-valued dependent variable),\nwhich is useful when the division between instances that should be predicted\npositive or negative depends on the utility. For example, in mining, the\nboundary between a valuable rock and a waste rock depends on the market price\nof various metals, which varies with time. This paper proposes impact curves to\nevaluate binarised regression with instance-varying costs, where some instances\nare much worse to be classified as positive (or negative) than other instances;\ne.g., it is much worse to throw away a high-grade gold rock than a medium-grade\ncopper-ore rock, even if the mine wishes to keep both because both are\nprofitable. We show how to construct an impact curve for a variety of domains,\nincluding examples from healthcare, mining, and entertainment. Impact curves\noptimize binary decisions across all utilities of the chosen utility function,\nidentify the conditions where one model may be favoured over another, and\nquantitatively assess improvement between competing models.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 04:16:17 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Dirks", "Matthew", ""], ["Poole", "David", ""]]}, {"id": "2008.07353", "submitter": "Wenlong Mou", "authors": "Wenlong Mou, Zheng Wen, Xi Chen", "title": "On the Sample Complexity of Reinforcement Learning with Policy Space\n  Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the optimal sample complexity in large-scale Reinforcement Learning\n(RL) problems with policy space generalization, i.e. the agent has a prior\nknowledge that the optimal policy lies in a known policy space. Existing\nresults show that without a generalization model, the sample complexity of an\nRL algorithm will inevitably depend on the cardinalities of state space and\naction space, which are intractably large in many practical problems.\n  To avoid such undesirable dependence on the state and action space sizes,\nthis paper proposes a new notion of eluder dimension for the policy space,\nwhich characterizes the intrinsic complexity of policy learning in an arbitrary\nMarkov Decision Process (MDP). Using a simulator oracle, we prove a\nnear-optimal sample complexity upper bound that only depends linearly on the\neluder dimension. We further prove a similar regret bound in deterministic\nsystems without the simulator.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 14:26:18 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Mou", "Wenlong", ""], ["Wen", "Zheng", ""], ["Chen", "Xi", ""]]}, {"id": "2008.07357", "submitter": "Mikhail Belyaev", "authors": "Boris Shirokikh and Ivan Zakazov and Alexey Chernyavskiy and Irina\n  Fedulova and Mikhail Belyaev", "title": "First U-Net Layers Contain More Domain Specific Information Than The\n  Last Ones", "comments": "Accepted to DART workshop at MICCAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MRI scans appearance significantly depends on scanning protocols and,\nconsequently, the data-collection institution. These variations between\nclinical sites result in dramatic drops of CNN segmentation quality on unseen\ndomains. Many of the recently proposed MRI domain adaptation methods operate\nwith the last CNN layers to suppress domain shift. At the same time, the core\nmanifestation of MRI variability is a considerable diversity of image\nintensities. We hypothesize that these differences can be eliminated by\nmodifying the first layers rather than the last ones. To validate this simple\nidea, we conducted a set of experiments with brain MRI scans from six domains.\nOur results demonstrate that 1) domain-shift may deteriorate the quality even\nfor a simple brain extraction segmentation task (surface Dice Score drops from\n0.85-0.89 even to 0.09); 2) fine-tuning of the first layers significantly\noutperforms fine-tuning of the last layers in almost all supervised domain\nadaptation setups. Moreover, fine-tuning of the first layers is a better\nstrategy than fine-tuning of the whole network, if the amount of annotated data\nfrom the new domain is strictly limited.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 14:31:10 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Shirokikh", "Boris", ""], ["Zakazov", "Ivan", ""], ["Chernyavskiy", "Alexey", ""], ["Fedulova", "Irina", ""], ["Belyaev", "Mikhail", ""]]}, {"id": "2008.07361", "submitter": "Luis John", "authors": "Luis H. John, Jan A. Kors, Jenna M. Reps, Patrick B. Ryan, Peter R.\n  Rijnbeek", "title": "How little data do we need for patient-level prediction?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Provide guidance on sample size considerations for developing\npredictive models by empirically establishing the adequate sample size, which\nbalances the competing objectives of improving model performance and reducing\nmodel complexity as well as computational requirements.\n  Materials and Methods: We empirically assess the effect of sample size on\nprediction performance and model complexity by generating learning curves for\n81 prediction problems in three large observational health databases, requiring\ntraining of 17,248 prediction models. The adequate sample size was defined as\nthe sample size for which the performance of a model equalled the maximum model\nperformance minus a small threshold value.\n  Results: The adequate sample size achieves a median reduction of the number\nof observations between 9.5% and 78.5% for threshold values between 0.001 and\n0.02. The median reduction of the number of predictors in the models at the\nadequate sample size varied between 8.6% and 68.3%, respectively.\n  Discussion: Based on our results a conservative, yet significant, reduction\nin sample size and model complexity can be estimated for future prediction\nwork. Though, if a researcher is willing to generate a learning curve a much\nlarger reduction of the model complexity may be possible as suggested by a\nlarge outcome-dependent variability.\n  Conclusion: Our results suggest that in most cases only a fraction of the\navailable data was sufficient to produce a model close to the performance of\none developed on the full data set, but with a substantially reduced model\ncomplexity.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 11:00:13 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["John", "Luis H.", ""], ["Kors", "Jan A.", ""], ["Reps", "Jenna M.", ""], ["Ryan", "Patrick B.", ""], ["Rijnbeek", "Peter R.", ""]]}, {"id": "2008.07363", "submitter": "Ana Paula Appel", "authors": "Ana Paula Appel, Gabriel Louzada Malfatti, Renato Luiz de Freitas\n  Cunha, Bruno Lima, Rogerio de Paula", "title": "Predicting Account Receivables with Machine Learning", "comments": "9 pages, 6 figures, Workshop Machine Learning in Finance. arXiv admin\n  note: substantial text overlap with arXiv:1912.10828", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to predict when invoices will be paid is valuable in multiple\nindustries and supports decision-making processes in most financial workflows.\nHowever, due to the complexity of data related to invoices and the fact that\nthe decision-making process is not registered in the accounts receivable\nsystem, performing this prediction becomes a challenge. In this paper, we\npresent a prototype able to support collectors in predicting the payment of\ninvoices. This prototype is part of a solution developed in partnership with a\nmultinational bank and it has reached up to 81% of prediction accuracy, which\nimproved the prioritization of customers and supported the daily work of\ncollectors. Our simulations show that the adoption of our model to prioritize\nthe work o collectors saves up to ~1.75 million dollars per month. The\nmethodology and results presented in this paper will allow researchers and\npractitioners in dealing with the problem of invoice payment prediction,\nproviding insights and examples of how to tackle issues present in real data.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 11:53:24 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Appel", "Ana Paula", ""], ["Malfatti", "Gabriel Louzada", ""], ["Cunha", "Renato Luiz de Freitas", ""], ["Lima", "Bruno", ""], ["de Paula", "Rogerio", ""]]}, {"id": "2008.07364", "submitter": "Teng Ye", "authors": "Teng Ye, Wei Ai, Lingyu Zhang, Ning Luo, Lulu Zhang, Jieping Ye,\n  Qiaozhu Mei", "title": "Predicting Individual Treatment Effects of Large-scale Team Competitions\n  in a Ride-sharing Economy", "comments": "Accepted to KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millions of drivers worldwide have enjoyed financial benefits and work\nschedule flexibility through a ride-sharing economy, but meanwhile they have\nsuffered from the lack of a sense of identity and career achievement. Equipped\nwith social identity and contest theories, financially incentivized team\ncompetitions have been an effective instrument to increase drivers'\nproductivity, job satisfaction, and retention, and to improve revenue over cost\nfor ride-sharing platforms. While these competitions are overall effective, the\ndecisive factors behind the treatment effects and how they affect the outcomes\nof individual drivers have been largely mysterious. In this study, we analyze\ndata collected from more than 500 large-scale team competitions organized by a\nleading ride-sharing platform, building machine learning models to predict\nindividual treatment effects. Through a careful investigation of features and\npredictors, we are able to reduce out-sample prediction error by more than 24%.\nThrough interpreting the best-performing models, we discover many novel and\nactionable insights regarding how to optimize the design and the execution of\nteam competitions on ride-sharing platforms. A simulated analysis demonstrates\nthat by simply changing a few contest design options, the average treatment\neffect of a real competition is expected to increase by as much as 26%. Our\nprocedure and findings shed light on how to analyze and optimize large-scale\nonline field experiments in general.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 22:01:50 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Ye", "Teng", ""], ["Ai", "Wei", ""], ["Zhang", "Lingyu", ""], ["Luo", "Ning", ""], ["Zhang", "Lulu", ""], ["Ye", "Jieping", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "2008.07365", "submitter": "Remi Leluc", "authors": "Hamid Jalalzai and R\\'emi Leluc", "title": "Feature Clustering for Support Identification in Extreme Regions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the complex structure of multivariate extremes is a major\nchallenge in various fields from portfolio monitoring and environmental risk\nmanagement to insurance. In the framework of multivariate Extreme Value Theory,\na common characterization of extremes' dependence structure is the angular\nmeasure. It is a suitable measure to work in extreme regions as it provides\nmeaningful insights concerning the subregions where extremes tend to\nconcentrate their mass. The present paper develops a novel optimization-based\napproach to assess the dependence structure of extremes. This support\nidentification scheme rewrites as estimating clusters of features which best\ncapture the support of extremes. The dimension reduction technique we provide\nis applied to statistical learning tasks such as feature clustering and anomaly\ndetection. Numerical experiments provide strong empirical evidence of the\nrelevance of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 15:51:53 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 15:54:38 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Jalalzai", "Hamid", ""], ["Leluc", "R\u00e9mi", ""]]}, {"id": "2008.07366", "submitter": "Qian Ye", "authors": "Qian Ye, Xiaohong Chen, Onur Kalan, and Kaan Ozbay", "title": "Using LDA and LSTM Models to Study Public Opinions and Critical Groups\n  Towards Congestion Pricing in New York City through 2007 to 2019", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study explores how people view and respond to the proposals of NYC\ncongestion pricing evolve in time. To understand these responses, Twitter data\nis collected and analyzed. Critical groups in the recurrent process are\ndetected by statistically analyzing the active users and the most mentioned\naccounts, and the trends of people's attitudes and concerns over the years are\nidentified with text mining and hybrid Nature Language Processing techniques,\nincluding LDA topic modeling and LSTM sentiment classification. The result\nshows that multiple interest groups were involved and played crucial roles\nduring the proposal, especially Mayor and Governor, MTA, and outer-borough\nrepresentatives. The public shifted the concern of focus from the plan details\nto a wider city's sustainability and fairness. Furthermore, the plan's approval\nrelies on several elements, the joint agreement reached in the political\nprocess, strong motivation in the real-world, the scheme based on balancing\nmultiple interests, and groups' awareness of tolling's benefits and necessity.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 02:59:29 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Ye", "Qian", ""], ["Chen", "Xiaohong", ""], ["Kalan", "Onur", ""], ["Ozbay", "Kaan", ""]]}, {"id": "2008.07386", "submitter": "Fabio Massimo Zennaro", "authors": "Fabio Massimo Zennaro, Audun J{\\o}sang", "title": "Using Subjective Logic to Estimate Uncertainty in Multi-Armed Bandit\n  Problems", "comments": "Published at ECML/PKDD 2020 Workshop on Uncertainty in Machine\n  Learning, 12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-armed bandit problem is a classical decision-making problem where\nan agent has to learn an optimal action balancing exploration and exploitation.\nProperly managing this trade-off requires a correct assessment of uncertainty;\nin multi-armed bandits, as in other machine learning applications, it is\nimportant to distinguish between stochasticity that is inherent to the system\n(aleatoric uncertainty) and stochasticity that derives from the limited\nknowledge of the agent (epistemic uncertainty). In this paper we consider the\nformalism of subjective logic, a concise and expressive framework to express\nDirichlet-multinomial models as subjective opinions, and we apply it to the\nproblem of multi-armed bandits. We propose new algorithms grounded in\nsubjective logic to tackle the multi-armed bandit problem, we compare them\nagainst classical algorithms from the literature, and we analyze the insights\nthey provide in evaluating the dynamics of uncertainty. Our preliminary results\nsuggest that subjective logic quantities enable useful assessment of\nuncertainty that may be exploited by more refined agents.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 14:53:17 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Zennaro", "Fabio Massimo", ""], ["J\u00f8sang", "Audun", ""]]}, {"id": "2008.07387", "submitter": "Wandong Zhang", "authors": "Wandong Zhang (1 and 2), Yimin Yang (2 and 3), Jonathan Wu (1) ((1)\n  University of Windsor, (2) Lakehead University, (3) Vector Institute for\n  Artificial Intelligence)", "title": "Deep Networks with Fast Retraining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work [1] has utilized Moore-Penrose (MP) inverse in deep convolutional\nneural network (DCNN) learning, which achieves better generalization\nperformance over the DCNN with a stochastic gradient descent (SGD) pipeline.\nHowever, Yang's work has not gained much popularity in practice due to its high\nsensitivity of hyper-parameters and stringent demands of computational\nresources. To enhance its applicability, this paper proposes a novel MP\ninverse-based fast retraining strategy. In each training epoch, a random\nlearning strategy that controls the number of convolutional layers trained in\nthe backward pass is first utilized. Then, an MP inverse-based batch-by-batch\nlearning strategy, which enables the network to be implemented without access\nto industrial-scale computational resources, is developed to refine the dense\nlayer parameters. Experimental results empirically demonstrate that fast\nretraining is a unified strategy that can be used for all DCNNs. Compared to\nother learning strategies, the proposed learning pipeline has robustness\nagainst the hyper-parameters, and the requirement of computational resources is\nsignificantly reduced. [1] Y. Yang, J. Wu, X. Feng, and A. Thangarajah,\n\"Recomputation of dense layers for the perfor-238mance improvement of dcnn,\"\nIEEE Trans. Pattern Anal. Mach. Intell., 2019.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 15:17:38 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 23:37:54 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Zhang", "Wandong", "", "1 and 2"], ["Yang", "Yimin", "", "2 and 3"], ["Wu", "Jonathan", ""]]}, {"id": "2008.07393", "submitter": "Vinay Prabhu", "authors": "Bowen Jing, Vinay Prabhu, Angela Gu, John Whaley", "title": "Rotation-Invariant Gait Identification with Quaternion Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A desireable property of accelerometric gait-based identification systems is\nrobustness to new device orientations presented by users during testing but\nunseen during the training phase. However, traditional Convolutional neural\nnetworks (CNNs) used in these systems compensate poorly for such\ntransformations. In this paper, we target this problem by introducing\nQuaternion CNN, a network architecture which is intrinsically layer-wise\nequivariant and globally invariant under 3D rotations of an array of input\nvectors. We show empirically that this network indeed significantly outperforms\na traditional CNN in a multi-user rotation-invariant gait classification\nsetting .Lastly, we demonstrate how the kernels learned by this QCNN can also\nbe visualized as basis-independent but origin- and chirality-dependent\ntrajectory fragments in the euclidean space, thus yielding a novel mode of\nfeature visualization and extraction.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 23:22:12 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Jing", "Bowen", ""], ["Prabhu", "Vinay", ""], ["Gu", "Angela", ""], ["Whaley", "John", ""]]}, {"id": "2008.07405", "submitter": "Mubarak Albarka Umar", "authors": "Mubarak Albarka Umar, Chen Zhanfang, Yan Liu", "title": "Network Intrusion Detection Using Wrapper-based Decision Tree for\n  Feature Selection", "comments": "8 pages, 3 figures, Presented at ICICSE 2020 Conference Proceedings,\n  which will be published in the International Conference Proceedings Series by\n  ACM, and will be archived in the ACM Digital Library", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the key challenges of machine learning (ML) based intrusion detection\nsystem (IDS) is the expensive computational complexity which is largely due to\nredundant, incomplete, and irrelevant features contain in the IDS datasets. To\novercome such challenge and ensure building an efficient and more accurate IDS\nmodels, many researchers utilize preprocessing techniques such as normalization\nand feature selection in a hybrid modeling approach. In this work, we propose a\nhybrid IDS modeling approach with an algorithm for feature selection (FS) and\nanother for building an IDS. The FS algorithm is a wrapper-based with a\ndecision tree as the feature evaluator. The propose FS method is used in\ncombination with some selected ML algorithms to build IDS models using the\nUNSW-NB15 dataset. Some IDS models are built as a baseline in a single modeling\napproach using the full features of the dataset. We evaluate the effectiveness\nof our propose method by comparing it with the baseline models and also with\nstate-of-the-art works. Our method achieves the best DR of 97.95% and shown to\nbe quite effective in comparison to state-of-the-art works. We, therefore,\nrecommend its usage especially in IDS modeling with the UNSW-NB15 dataset.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 04:00:58 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Umar", "Mubarak Albarka", ""], ["Zhanfang", "Chen", ""], ["Liu", "Yan", ""]]}, {"id": "2008.07424", "submitter": "Jean Ogier Du Terrail", "authors": "Mathieu Andreux, Jean Ogier du Terrail, Constance Beguier, Eric W.\n  Tramel", "title": "Siloed Federated Learning for Multi-Centric Histopathology Datasets", "comments": "Accepted to MICCAI 2020 DCL workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While federated learning is a promising approach for training deep learning\nmodels over distributed sensitive datasets, it presents new challenges for\nmachine learning, especially when applied in the medical domain where\nmulti-centric data heterogeneity is common. Building on previous domain\nadaptation works, this paper proposes a novel federated learning approach for\ndeep learning architectures via the introduction of local-statistic batch\nnormalization (BN) layers, resulting in collaboratively-trained, yet\ncenter-specific models. This strategy improves robustness to data heterogeneity\nwhile also reducing the potential for information leaks by not sharing the\ncenter-specific layer activation statistics. We benchmark the proposed method\non the classification of tumorous histopathology image patches extracted from\nthe Camelyon16 and Camelyon17 datasets. We show that our approach compares\nfavorably to previous state-of-the-art methods, especially for transfer\nlearning across datasets.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 15:49:30 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Andreux", "Mathieu", ""], ["Terrail", "Jean Ogier du", ""], ["Beguier", "Constance", ""], ["Tramel", "Eric W.", ""]]}, {"id": "2008.07426", "submitter": "Matias Valdenegro-Toro", "authors": "Maryam Matin and Matias Valdenegro-Toro", "title": "Hey Human, If your Facial Emotions are Uncertain, You Should Use\n  Bayesian Neural Networks!", "comments": "10 pages, 7 figures, Women in Computer Vision @ ECCV 2020 camera\n  ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial emotion recognition is the task to classify human emotions in face\nimages. It is a difficult task due to high aleatoric uncertainty and visual\nambiguity. A large part of the literature aims to show progress by increasing\naccuracy on this task, but this ignores the inherent uncertainty and ambiguity\nin the task. In this paper we show that Bayesian Neural Networks, as\napproximated using MC-Dropout, MC-DropConnect, or an Ensemble, are able to\nmodel the aleatoric uncertainty in facial emotion recognition, and produce\noutput probabilities that are closer to what a human expects. We also show that\ncalibration metrics show strange behaviors for this task, due to the multiple\nclasses that can be considered correct, which motivates future work. We believe\nour work will motivate other researchers to move away from Classical and into\nBayesian Neural Networks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 15:50:40 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Matin", "Maryam", ""], ["Valdenegro-Toro", "Matias", ""]]}, {"id": "2008.07428", "submitter": "Usman Khan", "authors": "Ran Xin and Usman A. Khan and Soummya Kar", "title": "Fast decentralized non-convex finite-sum optimization with recursive\n  variance reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers decentralized minimization of $N:=nm$ smooth non-convex\ncost functions equally divided over a directed network of $n$ nodes.\nSpecifically, we describe a stochastic first-order gradient method, called\nGT-SARAH, that employs a SARAH-type variance reduction technique and gradient\ntracking (GT) to address the stochastic and decentralized nature of the\nproblem. We show that GT-SARAH, with appropriate algorithmic parameters, finds\nan $\\epsilon$-accurate first-order stationary point with\n$O\\big(\\max\\big\\{N^{\\frac{1}{2}},n(1-\\lambda)^{-2},n^{\\frac{2}{3}}m^{\\frac{1}{3}}(1-\\lambda)^{-1}\\big\\}L\\epsilon^{-2}\\big)$\ngradient complexity, where ${(1-\\lambda)\\in(0,1]}$ is the spectral gap of the\nnetwork weight matrix and $L$ is the smoothness parameter of the cost\nfunctions. This gradient complexity outperforms that of the existing\ndecentralized stochastic gradient methods. In particular, in a big-data regime\nsuch that ${n = O(N^{\\frac{1}{2}}(1-\\lambda)^{3})}$, this gradient complexity\nfurthers reduces to ${O(N^{\\frac{1}{2}}L\\epsilon^{-2})}$, independent of the\nnetwork topology, and matches that of the centralized near-optimal\nvariance-reduced methods. Moreover, in this regime GT-SARAH achieves a\nnon-asymptotic linear speedup, in that, the total number of gradient\ncomputations at each node is reduced by a factor of $1/n$ compared to the\ncentralized near-optimal algorithms that perform all gradient computations at a\nsingle node. To the best of our knowledge, GT-SARAH is the first algorithm that\nachieves this property. In addition, we show that appropriate choices of local\nminibatch size balance the trade-offs between the gradient and communication\ncomplexity of GT-SARAH. Over infinite time horizon, we establish that all nodes\nin GT-SARAH asymptotically achieve consensus and converge to a first-order\nstationary point in the almost sure and mean-squared sense.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 15:51:32 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 19:07:13 GMT"}, {"version": "v3", "created": "Sat, 29 Aug 2020 01:54:21 GMT"}, {"version": "v4", "created": "Tue, 15 Sep 2020 16:19:01 GMT"}, {"version": "v5", "created": "Tue, 15 Jun 2021 03:10:16 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Xin", "Ran", ""], ["Khan", "Usman A.", ""], ["Kar", "Soummya", ""]]}, {"id": "2008.07433", "submitter": "Sriram Vasudevan", "authors": "Sriram Vasudevan, Krishnaram Kenthapadi", "title": "LiFT: A Scalable Framework for Measuring Fairness in ML Applications", "comments": "Accepted for publication in CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3412705", "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many internet applications are powered by machine learned models, which are\nusually trained on labeled datasets obtained through either implicit / explicit\nuser feedback signals or human judgments. Since societal biases may be present\nin the generation of such datasets, it is possible for the trained models to be\nbiased, thereby resulting in potential discrimination and harms for\ndisadvantaged groups. Motivated by the need for understanding and addressing\nalgorithmic bias in web-scale ML systems and the limitations of existing\nfairness toolkits, we present the LinkedIn Fairness Toolkit (LiFT), a framework\nfor scalable computation of fairness metrics as part of large ML systems. We\nhighlight the key requirements in deployed settings, and present the design of\nour fairness measurement system. We discuss the challenges encountered in\nincorporating fairness tools in practice and the lessons learned during\ndeployment at LinkedIn. Finally, we provide open problems based on practical\nexperience.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 03:55:31 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Vasudevan", "Sriram", ""], ["Kenthapadi", "Krishnaram", ""]]}, {"id": "2008.07434", "submitter": "Michael Allen", "authors": "Michael Allen, and Thomas Monks", "title": "Integrating Deep Reinforcement Learning Networks with Health System\n  Simulations", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background and motivation: Combining Deep Reinforcement Learning (Deep RL)\nand Health Systems Simulations has significant potential, for both research\ninto improving Deep RL performance and safety, and in operational practice.\nWhile individual toolkits exist for Deep RL and Health Systems Simulations, no\nframework to integrate the two has been established.\n  Aim: Provide a framework for integrating Deep RL Networks with Health System\nSimulations, and to ensure this framework is compatible with Deep RL agents\nthat have been developed and tested using OpenAI Gym.\n  Methods: We developed our framework based on the OpenAI Gym framework, and\ndemonstrate its use on a simple hospital bed capacity model. We built the Deep\nRL agents using PyTorch, and the Hospital Simulatation using SimPy.\n  Results: We demonstrate example models using a Double Deep Q Network or a\nDuelling Double Deep Q Network as the Deep RL agent.\n  Conclusion: SimPy may be used to create Health System Simulations that are\ncompatible with agents developed and tested on OpenAI Gym environments.\n  GitHub repository of code:\nhttps://github.com/MichaelAllen1966/learninghospital\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 07:44:59 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Allen", "Michael", ""], ["Monks", "Thomas", ""]]}, {"id": "2008.07443", "submitter": "Udit Maniyar", "authors": "Udit Maniyar, Joseph K J, Aniket Anand Deshmukh, Urun Dogan, Vineeth N\n  Balasubramanian", "title": "Zero Shot Domain Generalization", "comments": "Accepted to BMVC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Standard supervised learning setting assumes that training data and test data\ncome from the same distribution (domain). Domain generalization (DG) methods\ntry to learn a model that when trained on data from multiple domains, would\ngeneralize to a new unseen domain. We extend DG to an even more challenging\nsetting, where the label space of the unseen domain could also change. We\nintroduce this problem as Zero-Shot Domain Generalization (to the best of our\nknowledge, the first such effort), where the model generalizes across new\ndomains and also across new classes in those domains. We propose a simple\nstrategy which effectively exploits semantic information of classes, to adapt\nexisting DG methods to meet the demands of Zero-Shot Domain Generalization. We\nevaluate the proposed methods on CIFAR-10, CIFAR-100, F-MNIST and PACS\ndatasets, establishing a strong baseline to foster interest in this new\nresearch direction.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 16:04:03 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Maniyar", "Udit", ""], ["J", "Joseph K", ""], ["Deshmukh", "Aniket Anand", ""], ["Dogan", "Urun", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "2008.07449", "submitter": "Toki Inan", "authors": "Muhammad Nazrul Islam, Toki Tahmid Inan, Suzzana Rafi, Syeda Sabrina\n  Akter, Iqbal H. Sarker, A. K. M. Najmul Islam", "title": "A Survey on the Use of AI and ML for Fighting the COVID-19 Pandemic", "comments": "10 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) and machine learning (ML) have made a paradigm\nshift in health care which, eventually can be used for decision support and\nforecasting by exploring the medical data. Recent studies showed that AI and ML\ncan be used to fight against the COVID-19 pandemic. Therefore, the objective of\nthis review study is to summarize the recent AI and ML based studies that have\nfocused to fight against COVID-19 pandemic. From an initial set of 634\narticles, a total of 35 articles were finally selected through an extensive\ninclusion-exclusion process. In our review, we have explored the\nobjectives/aims of the existing studies (i.e., the role of AI/ML in fighting\nCOVID-19 pandemic); context of the study (i.e., study focused to a specific\ncountry-context or with a global perspective); type and volume of dataset;\nmethodology, algorithms or techniques adopted in the prediction or diagnosis\nprocesses; and mapping the algorithms/techniques with the data type\nhighlighting their prediction/classification accuracy. We particularly focused\non the uses of AI/ML in analyzing the pandemic data in order to depict the most\nrecent progress of AI for fighting against COVID-19 and pointed out the\npotential scope of further research.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 16:49:04 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Islam", "Muhammad Nazrul", ""], ["Inan", "Toki Tahmid", ""], ["Rafi", "Suzzana", ""], ["Akter", "Syeda Sabrina", ""], ["Sarker", "Iqbal H.", ""], ["Islam", "A. K. M. Najmul", ""]]}, {"id": "2008.07451", "submitter": "Meghan Booker", "authors": "Meghan Booker and Anirudha Majumdar", "title": "Learning to Actively Reduce Memory Requirements for Robot Control Tasks", "comments": "13 pages, 5 figures, added Section 4.3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots equipped with rich sensing modalities (e.g., RGB-D cameras) performing\nlong-horizon tasks motivate the need for policies that are highly\nmemory-efficient. State-of-the-art approaches for controlling robots often use\nmemory representations that are excessively rich for the task or rely on\nhand-crafted tricks for memory efficiency. Instead, this work provides a\ngeneral approach for jointly synthesizing memory representations and policies;\nthe resulting policies actively seek to reduce memory requirements.\nSpecifically, we present a reinforcement learning framework that leverages an\nimplementation of the group LASSO regularization to synthesize policies that\nemploy low-dimensional and task-centric memory representations. We demonstrate\nthe efficacy of our approach with simulated examples including navigation in\ndiscrete and continuous spaces as well as vision-based indoor navigation set in\na photo-realistic simulator. The results on these examples indicate that our\nmethod is capable of finding policies that rely only on low-dimensional memory\nrepresentations, improving generalization, and actively reducing memory\nrequirements.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 16:20:13 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 03:27:44 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Booker", "Meghan", ""], ["Majumdar", "Anirudha", ""]]}, {"id": "2008.07459", "submitter": "Guodong Zhang", "authors": "Guodong Zhang, Yuanhao Wang", "title": "On the Suboptimality of Negative Momentum for Minimax Optimization", "comments": "AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smooth game optimization has recently attracted great interest in machine\nlearning as it generalizes the single-objective optimization paradigm. However,\ngame dynamics is more complex due to the interaction between different players\nand is therefore fundamentally different from minimization, posing new\nchallenges for algorithm design. Notably, it has been shown that negative\nmomentum is preferred due to its ability to reduce oscillation in game\ndynamics. Nevertheless, the convergence rate of negative momentum was only\nestablished in simple bilinear games. In this paper, we extend the analysis to\nsmooth and strongly-convex strongly-concave minimax games by taking the\nvariational inequality formulation. By connecting momentum method with\nChebyshev polynomials, we show that negative momentum accelerates convergence\nof game dynamics locally, though with a suboptimal rate. To the best of our\nknowledge, this is the \\emph{first work} that provides an explicit convergence\nrate for negative momentum in this setting.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 16:34:53 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 15:32:29 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 17:15:47 GMT"}, {"version": "v4", "created": "Tue, 26 Jan 2021 17:26:55 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Zhang", "Guodong", ""], ["Wang", "Yuanhao", ""]]}, {"id": "2008.07467", "submitter": "Shaunak Mishra", "authors": "Shaunak Mishra, Manisha Verma, Yichao Zhou, Kapil Thadani, Wei Wang", "title": "Learning to Create Better Ads: Generation and Ranking Approaches for Ad\n  Creative Refinement", "comments": "9 pages, accepted for publication in CIKM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the online advertising industry, the process of designing an ad creative\n(i.e., ad text and image) requires manual labor. Typically, each advertiser\nlaunches multiple creatives via online A/B tests to infer effective creatives\nfor the target audience, that are then refined further in an iterative fashion.\nDue to the manual nature of this process, it is time-consuming to learn,\nrefine, and deploy the modified creatives. Since major ad platforms typically\nrun A/B tests for multiple advertisers in parallel, we explore the possibility\nof collaboratively learning ad creative refinement via A/B tests of multiple\nadvertisers. In particular, given an input ad creative, we study approaches to\nrefine the given ad text and image by: (i) generating new ad text, (ii)\nrecommending keyphrases for new ad text, and (iii) recommending image tags\n(objects in image) to select new ad image. Based on A/B tests conducted by\nmultiple advertisers, we form pairwise examples of inferior and superior ad\ncreatives, and use such pairs to train models for the above tasks. For\ngenerating new ad text, we demonstrate the efficacy of an encoder-decoder\narchitecture with copy mechanism, which allows some words from the (inferior)\ninput text to be copied to the output while incorporating new words associated\nwith higher click-through-rate. For the keyphrase and image tag recommendation\ntask, we demonstrate the efficacy of a deep relevance matching model, as well\nas the relative robustness of ranking approaches compared to ad text generation\nin cold-start scenarios with unseen advertisers. We also share broadly\napplicable insights from our experiments using data from the Yahoo Gemini ad\nplatform.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 16:46:28 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 00:16:11 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Mishra", "Shaunak", ""], ["Verma", "Manisha", ""], ["Zhou", "Yichao", ""], ["Thadani", "Kapil", ""], ["Wang", "Wei", ""]]}, {"id": "2008.07473", "submitter": "Xiaojie Mao", "authors": "Nathan Kallus and Xiaojie Mao", "title": "Stochastic Optimization Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study contextual stochastic optimization problems, where we leverage rich\nauxiliary observations (e.g., product characteristics) to improve decision\nmaking with uncertain variables (e.g., demand). We show how to train forest\ndecision policies for this problem by growing trees that choose splits to\ndirectly optimize the downstream decision quality, rather than splitting to\nimprove prediction accuracy as in the standard random forest algorithm. We\nrealize this seemingly computationally intractable problem by developing\napproximate splitting criteria that utilize optimization perturbation analysis\nto eschew burdensome re-optimization for every candidate split, so that our\nmethod scales to large-scale problems. We prove that our splitting criteria\nconsistently approximate the true risk and that our method achieves asymptotic\noptimality. We extensively validate our method empirically, demonstrating the\nvalue of optimization-aware construction of forests and the success of our\nefficient approximations. We show that our approximate splitting criteria can\nreduce running time hundredfold, while achieving performance close to forest\nalgorithms that exactly re-optimize for every candidate split.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 16:56:06 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 00:17:52 GMT"}, {"version": "v3", "created": "Tue, 8 Sep 2020 14:13:33 GMT"}, {"version": "v4", "created": "Mon, 28 Sep 2020 10:12:16 GMT"}, {"version": "v5", "created": "Fri, 16 Oct 2020 00:46:52 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Kallus", "Nathan", ""], ["Mao", "Xiaojie", ""]]}, {"id": "2008.07496", "submitter": "Mert Sabuncu", "authors": "Mert R. Sabuncu", "title": "Intelligence plays dice: Stochasticity is essential for machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many fields view stochasticity as a way to gain computational efficiency,\nwhile often having to trade off accuracy. In this perspective article, we argue\nthat stochasticity plays a fundamentally different role in machine learning\n(ML) and is likely a critical ingredient of intelligent systems. As we review\nthe ML literature, we notice that stochasticity features in many ML methods,\naffording them robustness, generalizability, and calibration. We also note that\nrandomness seems to be prominent in biological intelligence, from the spiking\npatterns of individual neurons to the complex behavior of animals. We conclude\nwith a discussion of how we believe stochasticity might shape the future of ML.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 17:40:38 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sabuncu", "Mert R.", ""]]}, {"id": "2008.07513", "submitter": "Shiliang Zuo `", "authors": "Shiliang Zuo", "title": "A Realistic Example in 2 Dimension that Gradient Descent Takes\n  Exponential Time to Escape Saddle Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent is a popular algorithm in optimization, and its performance\nin convex settings is mostly well understood. In non-convex settings, it has\nbeen shown that gradient descent is able to escape saddle points asymptotically\nand converge to local minimizers [Lee et. al. 2016]. Recent studies also show a\nperturbed version of gradient descent is enough to escape saddle points\nefficiently [Jin et. al. 2015, Ge et. al. 2017]. In this paper we show a\nnegative result: gradient descent may take exponential time to escape saddle\npoints, with non-pathological two dimensional functions. While our focus is\ntheoretical, we also conduct experiments verifying our theoretical result.\nThrough our analysis we demonstrate that stochasticity is essential to escape\nsaddle points efficiently.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 17:57:30 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Zuo", "Shiliang", ""]]}, {"id": "2008.07514", "submitter": "Yunzhong Hou", "authors": "Yunzhong Hou, Liang Zheng", "title": "Source Free Domain Adaptation with Image Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effort in releasing large-scale datasets may be compromised by privacy and\nintellectual property considerations. A feasible alternative is to release\npre-trained models instead. While these models are strong on their original\ntask (source domain), their performance might degrade significantly when\ndeployed directly in a new environment (target domain), which might not contain\nlabels for training under realistic settings. Domain adaptation (DA) is a known\nsolution to the domain gap problem, but usually requires labeled source data.\nIn this paper, we study the problem of source free domain adaptation (SFDA),\nwhose distinctive feature is that the source domain only provides a pre-trained\nmodel, but no source data. Being source free adds significant challenges to DA,\nespecially when considering that the target dataset is unlabeled. To solve the\nSFDA problem, we propose an image translation approach that transfers the style\nof target images to that of unseen source images. To this end, we align the\nbatch-wise feature statistics of generated images to that stored in batch\nnormalization layers of the pre-trained model. Compared with directly\nclassifying target images, higher accuracy is obtained with these style\ntransferred images using the pre-trained model. On several image classification\ndatasets, we show that the above-mentioned improvements are consistent and\nstatistically significant.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 17:57:33 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 07:11:57 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Hou", "Yunzhong", ""], ["Zheng", "Liang", ""]]}, {"id": "2008.07524", "submitter": "Owen Lockwood", "authors": "Owen Lockwood and Mei Si", "title": "Reinforcement Learning with Quantum Variational Circuits", "comments": "Accepted to AIIDE 2020 Updated to better reflect AAAI formatting", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of quantum computational techniques has advanced greatly in\nrecent years, parallel to the advancements in techniques for deep reinforcement\nlearning. This work explores the potential for quantum computing to facilitate\nreinforcement learning problems. Quantum computing approaches offer important\npotential improvements in time and space complexity over traditional algorithms\nbecause of its ability to exploit the quantum phenomena of superposition and\nentanglement. Specifically, we investigate the use of quantum variational\ncircuits, a form of quantum machine learning. We present our techniques for\nencoding classical data for a quantum variational circuit, we further explore\npure and hybrid quantum algorithms for DQN and Double DQN. Our results indicate\nboth hybrid and pure quantum variational circuit have the ability to solve\nreinforcement learning tasks with a smaller parameter space. These comparison\nare conducted with two OpenAI Gym environments: CartPole and Blackjack, The\nsuccess of this work is indicative of a strong future relationship between\nquantum machine learning and deep reinforcement learning.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 00:13:01 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 23:53:32 GMT"}, {"version": "v3", "created": "Fri, 28 Aug 2020 06:54:21 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Lockwood", "Owen", ""], ["Si", "Mei", ""]]}, {"id": "2008.07527", "submitter": "Carlos Hernandez-Olivan", "authors": "Carlos Hernandez-Olivan, Jose R. Beltran, David Diaz-Guerra", "title": "Music Boundary Detection using Convolutional Neural Networks: A\n  comparative analysis of combined input features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of the structure of musical pieces is a task that remains a\nchallenge for Artificial Intelligence, especially in the field of Deep\nLearning. It requires prior identification of structural boundaries of the\nmusic pieces. This structural boundary analysis has recently been studied with\nunsupervised methods and \\textit{end-to-end} techniques such as Convolutional\nNeural Networks (CNN) using Mel-Scaled Log-magnitude Spectograms features\n(MLS), Self-Similarity Matrices (SSM) or Self-Similarity Lag Matrices (SSLM) as\ninputs and trained with human annotations. Several studies have been published\ndivided into unsupervised and \\textit{end-to-end} methods in which\npre-processing is done in different ways, using different distance metrics and\naudio characteristics, so a generalized pre-processing method to compute model\ninputs is missing. The objective of this work is to establish a general method\nof pre-processing these inputs by comparing the inputs calculated from\ndifferent pooling strategies, distance metrics and audio characteristics, also\ntaking into account the computing time to obtain them. We also establish the\nmost effective combination of inputs to be delivered to the CNN in order to\nestablish the most efficient way to extract the limits of the structure of the\nmusic pieces. With an adequate combination of input matrices and pooling\nstrategies we obtain a measurement accuracy $F_1$ of 0.411 that outperforms the\ncurrent one obtained under the same conditions.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 14:20:51 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Hernandez-Olivan", "Carlos", ""], ["Beltran", "Jose R.", ""], ["Diaz-Guerra", "David", ""]]}, {"id": "2008.07545", "submitter": "Neha Wadia", "authors": "Neha S. Wadia, Daniel Duckworth, Samuel S. Schoenholz, Ethan Dyer and\n  Jascha Sohl-Dickstein", "title": "Whitening and second order optimization both make information in the\n  dataset unusable during training, and can reduce or prevent generalization", "comments": "13+10 pages, 10 figures; minor textual changes and some\n  reorganization, one new figure and a new proof of main theorem added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is predicated on the concept of generalization: a model\nachieving low error on a sufficiently large training set should also perform\nwell on novel samples from the same distribution. We show that both data\nwhitening and second order optimization can harm or entirely prevent\ngeneralization. In general, model training harnesses information contained in\nthe sample-sample second moment matrix of a dataset. For a general class of\nmodels, namely models with a fully connected first layer, we prove that the\ninformation contained in this matrix is the only information which can be used\nto generalize. Models trained using whitened data, or with certain second order\noptimization schemes, have less access to this information, resulting in\nreduced or nonexistent generalization ability. We experimentally verify these\npredictions for several architectures, and further demonstrate that\ngeneralization continues to be harmed even when theoretical requirements are\nrelaxed. However, we also show experimentally that regularized second order\noptimization can provide a practical tradeoff, where training is accelerated\nbut less information is lost, and generalization can in some circumstances even\nimprove.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 18:00:05 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 17:42:29 GMT"}, {"version": "v3", "created": "Sat, 6 Feb 2021 06:29:08 GMT"}, {"version": "v4", "created": "Mon, 19 Jul 2021 07:00:41 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Wadia", "Neha S.", ""], ["Duckworth", "Daniel", ""], ["Schoenholz", "Samuel S.", ""], ["Dyer", "Ethan", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "2008.07559", "submitter": "Kaustubh Dhole", "authors": "Kaustubh D. Dhole", "title": "Resolving Intent Ambiguities by Retrieving Discriminative Clarifying\n  Questions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task oriented Dialogue Systems generally employ intent detection systems in\norder to map user queries to a set of pre-defined intents. However, user\nqueries appearing in natural language can be easily ambiguous and hence such a\ndirect mapping might not be straightforward harming intent detection and\neventually the overall performance of a dialogue system. Moreover, acquiring\ndomain-specific clarification questions is costly. In order to disambiguate\nqueries which are ambiguous between two intents, we propose a novel method of\ngenerating discriminative questions using a simple rule based system which can\ntake advantage of any question generation system without requiring annotated\ndata of clarification questions. Our approach aims at discrimination between\ntwo intents but can be easily extended to clarification over multiple intents.\nSeeking clarification from the user to classify user intents not only helps\nunderstand the user intent effectively, but also reduces the roboticity of the\nconversation and makes the interaction considerably natural.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 18:11:13 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Dhole", "Kaustubh D.", ""]]}, {"id": "2008.07577", "submitter": "Bahare Askari", "authors": "Bahare Askari, Jaroslaw Szlichta, Amirali Salehi-Abari", "title": "Joint Variational Autoencoders for Recommendation with Implicit Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoders (VAEs) have recently shown promising performance in\ncollaborative filtering with implicit feedback. These existing recommendation\nmodels learn user representations to reconstruct or predict user preferences.\nWe introduce joint variational autoencoders (JoVA), an ensemble of two VAEs, in\nwhich VAEs jointly learn both user and item representations and collectively\nreconstruct and predict user preferences. This design allows JoVA to capture\nuser-user and item-item correlations simultaneously. By extending the objective\nfunction of JoVA with a hinge-based pairwise loss function (JoVA-Hinge), we\nfurther specialize it for top-k recommendation with implicit feedback. Our\nextensive experiments on several real-world datasets show that JoVA-Hinge\noutperforms a broad set of state-of-the-art collaborative filtering methods,\nunder a variety of commonly-used metrics. Our empirical results also confirm\nthe outperformance of JoVA-Hinge over existing methods for cold-start users\nwith a limited number of training data.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 19:06:31 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Askari", "Bahare", ""], ["Szlichta", "Jaroslaw", ""], ["Salehi-Abari", "Amirali", ""]]}, {"id": "2008.07587", "submitter": "Abhinav Sagar", "authors": "Abhinav Sagar", "title": "Stochastic Bayesian Neural Networks", "comments": "There is an error in modelling stochastic process. Hence the results\n  are not correct", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks perform variational inference over the weights\nhowever calculation of the posterior distribution remains a challenge. Our work\nbuilds on variational inference techniques for bayesian neural networks using\nthe original Evidence Lower Bound. In this paper, we present a stochastic\nbayesian neural network in which we maximize Evidence Lower Bound using a new\nobjective function which we name as Stochastic Evidence Lower Bound. We\nevaluate our network on 5 publicly available UCI datasets using test RMSE and\nlog likelihood as the evaluation metrics. We demonstrate that our work not only\nbeats the previous state of the art algorithms but is also scalable to larger\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 19:48:34 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 12:17:52 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 18:12:29 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Sagar", "Abhinav", ""]]}, {"id": "2008.07588", "submitter": "Abhinav Sagar", "authors": "Abhinav Sagar", "title": "Uncertainty Quantification using Variational Inference for Biomedical\n  Image Segmentation", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning motivated by convolutional neural networks has been highly\nsuccessful in a range of medical imaging problems like image classification,\nimage segmentation, image synthesis etc. However for validation and\ninterpretability, not only do we need the predictions made by the model but\nalso how confident it is while making those predictions. This is important in\nsafety critical applications for the people to accept it. In this work, we used\nan encoder decoder architecture based on variational inference techniques for\nsegmenting brain tumour images. We compare different backbones architectures\nlike U-Net, V-Net and FCN as sampling data from the conditional distribution\nfor the encoder. We evaluate our work on the publicly available BRATS dataset\nusing Dice Similarity Coefficient (DSC) and Intersection Over Union (IOU) as\nthe evaluation metrics. Our model outperforms previous state of the art results\nwhile making use of uncertainty quantification in a principled bayesian manner.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 20:08:04 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Sagar", "Abhinav", ""]]}, {"id": "2008.07592", "submitter": "Divyansh Singh", "authors": "Divyansh Singh", "title": "Polyth-Net: Classification of Polythene Bags for Garbage Segregation\n  Using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polythene has always been a threat to the environment since its invention. It\nis non-biodegradable and very difficult to recycle. Even after many awareness\ncampaigns and practices, Separation of polythene bags from waste has been a\nchallenge for human civilization. The primary method of segregation deployed is\nmanual handpicking, which causes a dangerous health hazards to the workers and\nis also highly inefficient due to human errors. In this paper I have designed\nand researched on image-based classification of polythene bags using a\ndeep-learning model and its efficiency. This paper focuses on the architecture\nand statistical analysis of its performance on the data set as well as problems\nexperienced in the classification. It also suggests a modified loss function to\nspecifically detect polythene irrespective of its individual features. It aims\nto help the current environment protection endeavours and save countless lives\nlost to the hazards caused by current methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 19:00:56 GMT"}, {"version": "v2", "created": "Sat, 26 Sep 2020 03:08:11 GMT"}, {"version": "v3", "created": "Sun, 20 Dec 2020 05:06:35 GMT"}, {"version": "v4", "created": "Sat, 23 Jan 2021 11:23:16 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Singh", "Divyansh", ""]]}, {"id": "2008.07599", "submitter": "Steve Li", "authors": "Steven Cheng-Xian Li, Benjamin M. Marlin", "title": "Learning from Irregularly-Sampled Time Series: A Missing Data\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Irregularly-sampled time series occur in many domains including healthcare.\nThey can be challenging to model because they do not naturally yield a\nfixed-dimensional representation as required by many standard machine learning\nmodels. In this paper, we consider irregular sampling from the perspective of\nmissing data. We model observed irregularly-sampled time series data as a\nsequence of index-value pairs sampled from a continuous but unobserved\nfunction. We introduce an encoder-decoder framework for learning from such\ngeneric indexed sequences. We propose learning methods for this framework based\non variational autoencoders and generative adversarial networks. For continuous\nirregularly-sampled time series, we introduce continuous convolutional layers\nthat can efficiently interface with existing neural network architectures.\nExperiments show that our models are able to achieve competitive or better\nclassification results on irregularly-sampled multivariate time series compared\nto recent RNN models while offering significantly faster training times.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 20:01:55 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Li", "Steven Cheng-Xian", ""], ["Marlin", "Benjamin M.", ""]]}, {"id": "2008.07606", "submitter": "Shubhada Agrawal", "authors": "Shubhada Agrawal, Wouter M. Koolen, Sandeep Juneja", "title": "Optimal Best-Arm Identification Methods for Tail-Risk Measures", "comments": "55 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional value-at-risk (CVaR) and value-at-risk (VaR) are popular\ntail-risk measures in finance and insurance industries as well as in highly\nreliable, safety-critical uncertain environments where often the underlying\nprobability distributions are heavy-tailed. We use the multi-armed bandit\nbest-arm identification framework and consider the problem of identifying the\narm from amongst finitely many that has the smallest CVaR, VaR, or weighted sum\nof CVaR and mean. The latter captures the risk-return trade-off common in\nfinance. Our main contribution is an optimal $\\delta$-correct algorithm that\nacts on general arms, including heavy-tailed distributions, and matches the\nlower bound on the expected number of samples needed, asymptotically (as\n$\\delta$ approaches $0$). The algorithm requires solving a non-convex\noptimization problem in the space of probability measures, that requires\ndelicate analysis. En-route, we develop new non-asymptotic empirical\nlikelihood-based concentration inequalities for tail-risk measures which are\ntighter than those for popular truncation-based empirical estimators.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 20:23:24 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 12:23:16 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 00:58:34 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Agrawal", "Shubhada", ""], ["Koolen", "Wouter M.", ""], ["Juneja", "Sandeep", ""]]}, {"id": "2008.07609", "submitter": "Shreekanth Prabhu", "authors": "Shreekanth M. Prabhu and Natarajan Subramaniam", "title": "Surveillance of COVID-19 Pandemic using Hidden Markov Model", "comments": "29 pages, 9 figures, submitted to Elsevier Information Sciences\n  Journal on 13 August 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.soc-ph q-bio.PE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 pandemic has brought the whole world to a stand-still over the last\nfew months. In particular the pace at which pandemic has spread has taken\neverybody off-guard. The Governments across the world have responded by\nimposing lock-downs, stopping/restricting travel and mandating social\ndistancing. On the positive side there is wide availability of information on\nactive cases, recoveries and deaths collected daily across regions. However,\nwhat has been particularly challenging is to track the spread of the disease by\nasymptomatic carriers termed as super-spreaders. In this paper we look at\napplying Hidden Markov Model to get a better assessment of extent of spread.\nThe outcome of such analysis can be useful to Governments to design the\nrequired interventions/responses in a calibrated manner. The data we have\nchosen to analyze pertains to Indian scenario.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 05:45:34 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Prabhu", "Shreekanth M.", ""], ["Subramaniam", "Natarajan", ""]]}, {"id": "2008.07614", "submitter": "Qiang Liu", "authors": "Qiang Liu, Tao Han, Ning Zhang, Ye Wang", "title": "DeepSlicing: Deep Reinforcement Learning Assisted Resource Allocation\n  for Network Slicing", "comments": "Accepted by Globecom 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network slicing enables multiple virtual networks run on the same physical\ninfrastructure to support various use cases in 5G and beyond. These use cases,\nhowever, have very diverse network resource demands, e.g., communication and\ncomputation, and various performance metrics such as latency and throughput. To\neffectively allocate network resources to slices, we propose DeepSlicing that\nintegrates the alternating direction method of multipliers (ADMM) and deep\nreinforcement learning (DRL). DeepSlicing decomposes the network slicing\nproblem into a master problem and several slave problems. The master problem is\nsolved based on convex optimization and the slave problem is handled by DRL\nmethod which learns the optimal resource allocation policy. The performance of\nthe proposed algorithm is validated through network simulations.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 20:52:19 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 22:06:24 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Liu", "Qiang", ""], ["Han", "Tao", ""], ["Zhang", "Ning", ""], ["Wang", "Ye", ""]]}, {"id": "2008.07617", "submitter": "Pranav Kairon", "authors": "Pranav Kairon and Siddhartha Bhattacharyya", "title": "Comparative study of variational quantum circuit and quantum\n  backpropagation multilayer perceptron for COVID-19 outbreak predictions", "comments": "Comparative analysis of two quantum neural network models to solve a\n  multi-dimensional regression problem", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are numerous models of quantum neural networks that have been applied\nto variegated problems such as image classification, pattern recognition\netc.Quantum inspired algorithms have been relevant for quite awhile. More\nrecently, in the NISQ era, hybrid quantum classical models have shown promising\nresults. Multi-feature regression is common problem in classical machine\nlearning. Hence we present a comparative analysis of continuous variable\nquantum neural networks (Variational circuits) and quantum backpropagating\nmulti layer perceptron (QBMLP). We have chosen the contemporary problem of\npredicting rise in COVID-19 cases in India and USA. We provide a statistical\ncomparison between two models , both of which perform better than the classical\nartificial neural networks.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 17:57:14 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 11:21:59 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Kairon", "Pranav", ""], ["Bhattacharyya", "Siddhartha", ""]]}, {"id": "2008.07618", "submitter": "Yen-Ju Lu", "authors": "Yen-Ju Lu, Chien-Feng Liao, Xugang Lu, Jeih-weih Hung and Yu Tsao", "title": "Incorporating Broad Phonetic Information for Speech Enhancement", "comments": "to be published in Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In noisy conditions, knowing speech contents facilitates listeners to more\neffectively suppress background noise components and to retrieve pure speech\nsignals. Previous studies have also confirmed the benefits of incorporating\nphonetic information in a speech enhancement (SE) system to achieve better\ndenoising performance. To obtain the phonetic information, we usually prepare a\nphoneme-based acoustic model, which is trained using speech waveforms and\nphoneme labels. Despite performing well in normal noisy conditions, when\noperating in very noisy conditions, however, the recognized phonemes may be\nerroneous and thus misguide the SE process. To overcome the limitation, this\nstudy proposes to incorporate the broad phonetic class (BPC) information into\nthe SE process. We have investigated three criteria to build the BPC, including\ntwo knowledge-based criteria: place and manner of articulatory and one\ndata-driven criterion. Moreover, the recognition accuracies of BPCs are much\nhigher than that of phonemes, thus providing more accurate phonetic information\nto guide the SE process under very noisy conditions. Experimental results\ndemonstrate that the proposed SE with the BPC information framework can achieve\nnotable performance improvements over the baseline system and an SE system\nusing monophonic information in terms of both speech quality intelligibility on\nthe TIMIT dataset.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 09:38:08 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Lu", "Yen-Ju", ""], ["Liao", "Chien-Feng", ""], ["Lu", "Xugang", ""], ["Hung", "Jeih-weih", ""], ["Tsao", "Yu", ""]]}, {"id": "2008.07621", "submitter": "Gautam Krishna", "authors": "Gautam Krishna, Co Tran, Mason Carnahan, Morgan M Hagood, Ahmed H\n  Tewfik", "title": "Speech Recognition using EEG signals recorded using dry electrodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we demonstrate speech recognition using electroencephalography\n(EEG) signals obtained using dry electrodes on a limited English vocabulary\nconsisting of three vowels and one word using a deep learning model. We\ndemonstrate a test accuracy of 79.07 percent on a subset vocabulary consisting\nof two English vowels. Our results demonstrate the feasibility of using EEG\nsignals recorded using dry electrodes for performing the task of speech\nrecognition.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 09:56:45 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Krishna", "Gautam", ""], ["Tran", "Co", ""], ["Carnahan", "Mason", ""], ["Hagood", "Morgan M", ""], ["Tewfik", "Ahmed H", ""]]}, {"id": "2008.07633", "submitter": "Zhuo Feng", "authors": "Ying Zhang, Zhiqiang Zhao, Zhuo Feng", "title": "SF-GRASS: Solver-Free Graph Spectral Sparsification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.NA cs.SI math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent spectral graph sparsification techniques have shown promising\nperformance in accelerating many numerical and graph algorithms, such as\niterative methods for solving large sparse matrices, spectral partitioning of\nundirected graphs, vectorless verification of power/thermal grids,\nrepresentation learning of large graphs, etc. However, prior spectral graph\nsparsification methods rely on fast Laplacian matrix solvers that are usually\nchallenging to implement in practice. This work, for the first time, introduces\na solver-free approach (SF-GRASS) for spectral graph sparsification by\nleveraging emerging spectral graph coarsening and graph signal processing (GSP)\ntechniques. We introduce a local spectral embedding scheme for efficiently\nidentifying spectrally-critical edges that are key to preserving graph spectral\nproperties, such as the first few Laplacian eigenvalues and eigenvectors. Since\nthe key kernel functions in SF-GRASS can be efficiently implemented using\nsparse-matrix-vector-multiplications (SpMVs), the proposed spectral approach is\nsimple to implement and inherently parallel friendly. Our extensive\nexperimental results show that the proposed method can produce a hierarchy of\nhigh-quality spectral sparsifiers in nearly-linear time for a variety of\nreal-world, large-scale graphs and circuit networks when compared with the\nprior state-of-the-art spectral method.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 21:37:19 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Zhang", "Ying", ""], ["Zhao", "Zhiqiang", ""], ["Feng", "Zhuo", ""]]}, {"id": "2008.07641", "submitter": "Pau Riba", "authors": "Pau Riba, Andreas Fischer, Josep Llad\\'os and Alicia Forn\\'es", "title": "Learning Graph Edit Distance by Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The emergence of geometric deep learning as a novel framework to deal with\ngraph-based representations has faded away traditional approaches in favor of\ncompletely new methodologies. In this paper, we propose a new framework able to\ncombine the advances on deep metric learning with traditional approximations of\nthe graph edit distance. Hence, we propose an efficient graph distance based on\nthe novel field of geometric deep learning. Our method employs a message\npassing neural network to capture the graph structure, and thus, leveraging\nthis information for its use on a distance computation. The performance of the\nproposed graph distance is validated on two different scenarios. On the one\nhand, in a graph retrieval of handwritten words~\\ie~keyword spotting, showing\nits superior performance when compared with (approximate) graph edit distance\nbenchmarks. On the other hand, demonstrating competitive results for graph\nsimilarity learning when compared with the current state-of-the-art on a recent\nbenchmark dataset.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 21:49:59 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Riba", "Pau", ""], ["Fischer", "Andreas", ""], ["Llad\u00f3s", "Josep", ""], ["Forn\u00e9s", "Alicia", ""]]}, {"id": "2008.07645", "submitter": "Darius Petermann", "authors": "Darius Petermann, Pritish Chandna, Helena Cuesta, Jordi Bonada, Emilia\n  Gomez", "title": "Deep Learning Based Source Separation Applied To Choir Ensembles", "comments": "To appear at the 21st International Society for Music Information\n  Retrieval Conference, Montr\\'eal, Canada, 2020, audio examples available at:\n  \"https://darius522.github.io/satb-source-separation-results/\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Choral singing is a widely practiced form of ensemble singing wherein a group\nof people sing simultaneously in polyphonic harmony. The most commonly\npracticed setting for choir ensembles consists of four parts; Soprano, Alto,\nTenor and Bass (SATB), each with its own range of fundamental frequencies\n(F$0$s). The task of source separation for this choral setting entails\nseparating the SATB mixture into the constituent parts. Source separation for\nmusical mixtures is well studied and many deep learning based methodologies\nhave been proposed for the same. However, most of the research has been focused\non a typical case which consists in separating vocal, percussion and bass\nsources from a mixture, each of which has a distinct spectral structure. In\ncontrast, the simultaneous and harmonic nature of ensemble singing leads to\nhigh structural similarity and overlap between the spectral components of the\nsources in a choral mixture, making source separation for choirs a harder task\nthan the typical case. This, along with the lack of an appropriate consolidated\ndataset has led to a dearth of research in the field so far. In this paper we\nfirst assess how well some of the recently developed methodologies for musical\nsource separation perform for the case of SATB choirs. We then propose a novel\ndomain-specific adaptation for conditioning the recently proposed U-Net\narchitecture for musical source separation using the fundamental frequency\ncontour of each of the singing groups and demonstrate that our proposed\napproach surpasses results from domain-agnostic architectures.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 22:07:44 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Petermann", "Darius", ""], ["Chandna", "Pritish", ""], ["Cuesta", "Helena", ""], ["Bonada", "Jordi", ""], ["Gomez", "Emilia", ""]]}, {"id": "2008.07648", "submitter": "Zhunxuan Wang", "authors": "Zhunxuan Wang, Linyun He, Chunchuan Lyu and Shay B. Cohen", "title": "Nonparametric Learning of Two-Layer ReLU Residual Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an algorithm that learns two-layer residual units with rectified\nlinear unit (ReLU) activation: suppose the input $\\mathbf{x}$ is from a\ndistribution with support space $\\mathbb{R}^d$ and the ground-truth generative\nmodel is such a residual unit, given by \\[\\mathbf{y}=\n\\boldsymbol{B}^\\ast\\left[\\left(\\boldsymbol{A}^\\ast\\mathbf{x}\\right)^+ +\n\\mathbf{x}\\right]\\text{,}\\] where ground-truth network parameters\n$\\boldsymbol{A}^\\ast \\in \\mathbb{R}^{d\\times d}$ is a nonnegative full-rank\nmatrix and $\\boldsymbol{B}^\\ast \\in \\mathbb{R}^{m\\times d}$ is full-rank with\n$m \\geq d$ and for $\\mathbf{c} \\in \\mathbb{R}^d$, $[\\mathbf{c}^{+}]_i =\n\\max\\{0, c_i\\}$. We design layer-wise objectives as functionals whose analytic\nminimizers express the exact ground-truth network in terms of its parameters\nand nonlinearities. Following this objective landscape, learning residual units\nfrom finite samples can be formulated using convex optimization of a\nnonparametric function: for each layer, we first formulate the corresponding\nempirical risk minimization (ERM) as a positive semi-definite quadratic program\n(QP), then we show the solution space of the QP can be equivalently determined\nby a set of linear inequalities, which can then be efficiently solved by linear\nprogramming (LP). We further prove the statistical strong consistency of our\nalgorithm, and demonstrate the robustness and sample efficiency of our\nalgorithm by experiments.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 22:11:26 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 17:03:23 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Wang", "Zhunxuan", ""], ["He", "Linyun", ""], ["Lyu", "Chunchuan", ""], ["Cohen", "Shay B.", ""]]}, {"id": "2008.07653", "submitter": "David Huberman", "authors": "David B. Huberman, Brian J. Reich, and Howard D. Bondell", "title": "Nonparametric Conditional Density Estimation In A Deep Learning\n  Framework For Short-Term Forecasting", "comments": "44 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-term forecasting is an important tool in understanding environmental\nprocesses. In this paper, we incorporate machine learning algorithms into a\nconditional distribution estimator for the purposes of forecasting tropical\ncyclone intensity. Many machine learning techniques give a single-point\nprediction of the conditional distribution of the target variable, which does\nnot give a full accounting of the prediction variability. Conditional\ndistribution estimation can provide extra insight on predicted response\nbehavior, which could influence decision-making and policy. We propose a\ntechnique that simultaneously estimates the entire conditional distribution and\nflexibly allows for machine learning techniques to be incorporated. A smooth\nmodel is fit over both the target variable and covariates, and a logistic\ntransformation is applied on the model output layer to produce an expression of\nthe conditional density function. We provide two examples of machine learning\nmodels that can be used, polynomial regression and deep learning models. To\nachieve computational efficiency we propose a case-control sampling\napproximation to the conditional distribution. A simulation study for four\ndifferent data distributions highlights the effectiveness of our method\ncompared to other machine learning-based conditional distribution estimation\ntechniques. We then demonstrate the utility of our approach for forecasting\npurposes using tropical cyclone data from the Atlantic Seaboard. This paper\ngives a proof of concept for the promise of our method, further computational\ndevelopments can fully unlock its insights in more complex forecasting and\nother applications.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 22:31:19 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Huberman", "David B.", ""], ["Reich", "Brian J.", ""], ["Bondell", "Howard D.", ""]]}, {"id": "2008.07660", "submitter": "Javad Rahimipour Anaraki", "authors": "Javad Rahimipour Anaraki, Jae Moon, Tom Chau", "title": "Revisiting the Application of Feature Selection Methods to Speech\n  Imagery BCI Datasets", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-computer interface (BCI) aims to establish and improve human and\ncomputer interactions. There has been an increasing interest in designing new\nhardware devices to facilitate the collection of brain signals through various\ntechnologies, such as wet and dry electroencephalogram (EEG) and functional\nnear-infrared spectroscopy (fNIRS) devices. The promising results of machine\nlearning methods have attracted researchers to apply these methods to their\ndata. However, some methods can be overlooked simply due to their inferior\nperformance against a particular dataset. This paper shows how relatively\nsimple yet powerful feature selection/ranking methods can be applied to speech\nimagery datasets and generate significant results. To do so, we introduce two\napproaches, horizontal and vertical settings, to use any feature selection and\nranking methods to speech imagery BCI datasets. Our primary goal is to improve\nthe resulting classification accuracies from support vector machines,\n$k$-nearest neighbour, decision tree, linear discriminant analysis and long\nshort-term memory recurrent neural network classifiers. Our experimental\nresults show that using a small subset of channels, we can retain and, in most\ncases, improve the resulting classification accuracies regardless of the\nclassifier.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 22:48:52 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Anaraki", "Javad Rahimipour", ""], ["Moon", "Jae", ""], ["Chau", "Tom", ""]]}, {"id": "2008.07664", "submitter": "Javad Rahimipour Anaraki", "authors": "Javad Rahimipour Anaraki, Saeed Samet", "title": "Privacy-preserving feature selection: A survey and proposing a new set\n  of protocols", "comments": "29 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is the process of sieving features, in which informative\nfeatures are separated from the redundant and irrelevant ones. This process\nplays an important role in machine learning, data mining and bioinformatics.\nHowever, traditional feature selection methods are only capable of processing\ncentralized datasets and are not able to satisfy today's distributed data\nprocessing needs. These needs require a new category of data processing\nalgorithms called privacy-preserving feature selection, which protects users'\ndata by not revealing any part of the data neither in the intermediate\nprocessing nor in the final results. This is vital for the datasets which\ncontain individuals' data, such as medical datasets. Therefore, it is rational\nto either modify the existing algorithms or propose new ones to not only\nintroduce the capability of being applied to distributed datasets, but also act\nresponsibly in handling users' data by protecting their privacy. In this paper,\nwe will review three privacy-preserving feature selection methods and provide\nsuggestions to improve their performance when any gap is identified. We will\nalso propose a privacy-preserving feature selection method based on the rough\nset feature selection. The proposed method is capable of processing both\nhorizontally and vertically partitioned datasets in two- and multi-parties\nscenarios.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 23:14:45 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Anaraki", "Javad Rahimipour", ""], ["Samet", "Saeed", ""]]}, {"id": "2008.07665", "submitter": "Azade Farshad", "authors": "Yousef Yeganeh, Azade Farshad, Nassir Navab, Shadi Albarqouni", "title": "Inverse Distance Aggregation for Federated Learning with Non-IID Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) has been a promising approach in the field of medical\nimaging in recent years. A critical problem in FL, specifically in medical\nscenarios is to have a more accurate shared model which is robust to noisy and\nout-of distribution clients. In this work, we tackle the problem of statistical\nheterogeneity in data for FL which is highly plausible in medical data where\nfor example the data comes from different sites with different scanner\nsettings. We propose IDA (Inverse Distance Aggregation), a novel adaptive\nweighting approach for clients based on meta-information which handles\nunbalanced and non-iid data. We extensively analyze and evaluate our method\nagainst the well-known FL approach, Federated Averaging as a baseline.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 23:20:01 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Yeganeh", "Yousef", ""], ["Farshad", "Azade", ""], ["Navab", "Nassir", ""], ["Albarqouni", "Shadi", ""]]}, {"id": "2008.07669", "submitter": "Albert Gu", "authors": "Albert Gu, Tri Dao, Stefano Ermon, Atri Rudra, Christopher Re", "title": "HiPPO: Recurrent Memory with Optimal Polynomial Projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem in learning from sequential data is representing cumulative\nhistory in an incremental fashion as more data is processed. We introduce a\ngeneral framework (HiPPO) for the online compression of continuous signals and\ndiscrete time series by projection onto polynomial bases. Given a measure that\nspecifies the importance of each time step in the past, HiPPO produces an\noptimal solution to a natural online function approximation problem. As special\ncases, our framework yields a short derivation of the recent Legendre Memory\nUnit (LMU) from first principles, and generalizes the ubiquitous gating\nmechanism of recurrent neural networks such as GRUs. This formal framework\nyields a new memory update mechanism (HiPPO-LegS) that scales through time to\nremember all history, avoiding priors on the timescale. HiPPO-LegS enjoys the\ntheoretical benefits of timescale robustness, fast updates, and bounded\ngradients. By incorporating the memory dynamics into recurrent neural networks,\nHiPPO RNNs can empirically capture complex temporal dependencies. On the\nbenchmark permuted MNIST dataset, HiPPO-LegS sets a new state-of-the-art\naccuracy of 98.3%. Finally, on a novel trajectory classification task testing\nrobustness to out-of-distribution timescales and missing data, HiPPO-LegS\noutperforms RNN and neural ODE baselines by 25-40% accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 23:39:33 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 02:48:03 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Gu", "Albert", ""], ["Dao", "Tri", ""], ["Ermon", "Stefano", ""], ["Rudra", "Atri", ""], ["Re", "Christopher", ""]]}, {"id": "2008.07672", "submitter": "Jia Chen", "authors": "Jia Chen and Evangelos E. Papalexakis", "title": "Ensemble Node Embeddings using Tensor Decomposition: A Case-Study on\n  DeepWalk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Node embeddings have been attracting increasing attention during the past\nyears. In this context, we propose a new ensemble node embedding approach,\ncalled TenSemble2Vec, by first generating multiple embeddings using the\nexisting techniques and taking them as multiview data input of the state-of-art\ntensor decomposition model namely PARAFAC2 to learn the shared\nlower-dimensional representations of the nodes. Contrary to other embedding\nmethods, our TenSemble2Vec takes advantage of the complementary information\nfrom different methods or the same method with different hyper-parameters,\nwhich bypasses the challenge of choosing models. Extensive tests using\nreal-world data validates the efficiency of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 23:56:06 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Chen", "Jia", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "2008.07683", "submitter": "Karthik Gopalakrishnan", "authors": "Karthik Gopalakrishnan, Behnam Hedayatnia, Longshaokan Wang, Yang Liu,\n  Dilek Hakkani-Tur", "title": "Are Neural Open-Domain Dialog Systems Robust to Speech Recognition\n  Errors in the Dialog History? An Empirical Study", "comments": "Accepted at INTERSPEECH 2020. For dataset, see\n  https://github.com/alexa/Topical-Chat/tree/master/TopicalChatASR/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large end-to-end neural open-domain chatbots are becoming increasingly\npopular. However, research on building such chatbots has typically assumed that\nthe user input is written in nature and it is not clear whether these chatbots\nwould seamlessly integrate with automatic speech recognition (ASR) models to\nserve the speech modality. We aim to bring attention to this important question\nby empirically studying the effects of various types of synthetic and actual\nASR hypotheses in the dialog history on TransferTransfo, a state-of-the-art\nGenerative Pre-trained Transformer (GPT) based neural open-domain dialog system\nfrom the NeurIPS ConvAI2 challenge. We observe that TransferTransfo trained on\nwritten data is very sensitive to such hypotheses introduced to the dialog\nhistory during inference time. As a baseline mitigation strategy, we introduce\nsynthetic ASR hypotheses to the dialog history during training and observe\nmarginal improvements, demonstrating the need for further research into\ntechniques to make end-to-end open-domain chatbots fully speech-robust. To the\nbest of our knowledge, this is the first study to evaluate the effects of\nsynthetic and actual ASR hypotheses on a state-of-the-art neural open-domain\ndialog system and we hope it promotes speech-robustness as an evaluation\ncriterion in open-domain dialog.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 00:36:57 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Gopalakrishnan", "Karthik", ""], ["Hedayatnia", "Behnam", ""], ["Wang", "Longshaokan", ""], ["Liu", "Yang", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "2008.07685", "submitter": "Arindam Jati", "authors": "Arindam Jati, Chin-Cheng Hsu, Monisankha Pal, Raghuveer Peri, Wael\n  AbdAlmageed, Shrikanth Narayanan", "title": "Adversarial Attack and Defense Strategies for Deep Speaker Recognition\n  Systems", "comments": null, "journal-ref": null, "doi": "10.1016/j.csl.2021.101199", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust speaker recognition, including in the presence of malicious attacks,\nis becoming increasingly important and essential, especially due to the\nproliferation of several smart speakers and personal agents that interact with\nan individual's voice commands to perform diverse, and even sensitive tasks.\nAdversarial attack is a recently revived domain which is shown to be effective\nin breaking deep neural network-based classifiers, specifically, by forcing\nthem to change their posterior distribution by only perturbing the input\nsamples by a very small amount. Although, significant progress in this realm\nhas been made in the computer vision domain, advances within speaker\nrecognition is still limited. The present expository paper considers several\nstate-of-the-art adversarial attacks to a deep speaker recognition system,\nemploying strong defense methods as countermeasures, and reporting on several\nablation studies to obtain a comprehensive understanding of the problem. The\nexperiments show that the speaker recognition systems are vulnerable to\nadversarial attacks, and the strongest attacks can reduce the accuracy of the\nsystem from 94% to even 0%. The study also compares the performances of the\nemployed defense methods in detail, and finds adversarial training based on\nProjected Gradient Descent (PGD) to be the best defense method in our setting.\nWe hope that the experiments presented in this paper provide baselines that can\nbe useful for the research community interested in further studying adversarial\nrobustness of speaker recognition systems.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 00:58:19 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Jati", "Arindam", ""], ["Hsu", "Chin-Cheng", ""], ["Pal", "Monisankha", ""], ["Peri", "Raghuveer", ""], ["AbdAlmageed", "Wael", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "2008.07688", "submitter": "Vaibhav Kumar", "authors": "Vaibhav Kumar and Vikas Raunak and Jamie Callan", "title": "Ranking Clarification Questions via Natural Language Inference", "comments": "Accepted at CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3412137", "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Given a natural language query, teaching machines to ask clarifying questions\nis of immense utility in practical natural language processing systems. Such\ninteractions could help in filling information gaps for better machine\ncomprehension of the query. For the task of ranking clarification questions, we\nhypothesize that determining whether a clarification question pertains to a\nmissing entry in a given post (on QA forums such as StackExchange) could be\nconsidered as a special case of Natural Language Inference (NLI), where both\nthe post and the most relevant clarification question point to a shared latent\npiece of information or context. We validate this hypothesis by incorporating\nrepresentations from a Siamese BERT model fine-tuned on NLI and Multi-NLI\ndatasets into our models and demonstrate that our best performing model obtains\na relative performance improvement of 40 percent and 60 percent respectively\n(on the key metric of Precision@1), over the state-of-the-art baseline(s) on\nthe two evaluation sets of the StackExchange dataset, thereby, significantly\nsurpassing the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 01:32:29 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Kumar", "Vaibhav", ""], ["Raunak", "Vikas", ""], ["Callan", "Jamie", ""]]}, {"id": "2008.07695", "submitter": "Jianzong Wang", "authors": "Wenqi Wei, Jianzong Wang, Jiteng Ma, Ning Cheng, Jing Xiao", "title": "A Real-time Robot-based Auxiliary System for Risk Evaluation of COVID-19\n  Infection", "comments": "will be presented in INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a real-time robot-based auxiliary system for risk\nevaluation of COVID-19 infection. It combines real-time speech recognition,\ntemperature measurement, keyword detection, cough detection and other functions\nin order to convert live audio into actionable structured data to achieve the\nCOVID-19 infection risk assessment function. In order to better evaluate the\nCOVID-19 infection, we propose an end-to-end method for cough detection and\nclassification for our proposed system. It is based on real conversation data\nfrom human-robot, which processes speech signals to detect cough and classifies\nit if detected. The structure of our model are maintained concise to be\nimplemented for real-time applications. And we further embed this entire\nauxiliary diagnostic system in the robot and it is placed in the communities,\nhospitals and supermarkets to support COVID-19 testing. The system can be\nfurther leveraged within a business rules engine, thus serving as a foundation\nfor real-time supervision and assistance applications. Our model utilizes a\npretrained, robust training environment that allows for efficient creation and\ncustomization of customer-specific health states.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 01:58:52 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Wei", "Wenqi", ""], ["Wang", "Jianzong", ""], ["Ma", "Jiteng", ""], ["Cheng", "Ning", ""], ["Xiao", "Jing", ""]]}, {"id": "2008.07703", "submitter": "Yi Ren", "authors": "Yi Ren, Jinzheng He, Xu Tan, Tao Qin, Zhou Zhao, Tie-Yan Liu", "title": "PopMAG: Pop Music Accompaniment Generation", "comments": "Accepted by ACM-MM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.IR cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In pop music, accompaniments are usually played by multiple instruments\n(tracks) such as drum, bass, string and guitar, and can make a song more\nexpressive and contagious by arranging together with its melody. Previous works\nusually generate multiple tracks separately and the music notes from different\ntracks not explicitly depend on each other, which hurts the harmony modeling.\nTo improve harmony, in this paper, we propose a novel MUlti-track MIDI\nrepresentation (MuMIDI), which enables simultaneous multi-track generation in a\nsingle sequence and explicitly models the dependency of the notes from\ndifferent tracks. While this greatly improves harmony, unfortunately, it\nenlarges the sequence length and brings the new challenge of long-term music\nmodeling. We further introduce two new techniques to address this challenge: 1)\nWe model multiple note attributes (e.g., pitch, duration, velocity) of a\nmusical note in one step instead of multiple steps, which can shorten the\nlength of a MuMIDI sequence. 2) We introduce extra long-context as memory to\ncapture long-term dependency in music. We call our system for pop music\naccompaniment generation as PopMAG. We evaluate PopMAG on multiple datasets\n(LMD, FreeMidi and CPMD, a private dataset of Chinese pop songs) with both\nsubjective and objective metrics. The results demonstrate the effectiveness of\nPopMAG for multi-track harmony modeling and long-term context modeling.\nSpecifically, PopMAG wins 42\\%/38\\%/40\\% votes when comparing with ground truth\nmusical pieces on LMD, FreeMidi and CPMD datasets respectively and largely\noutperforms other state-of-the-art music accompaniment generation models and\nmulti-track MIDI representations in terms of subjective and objective metrics.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 02:28:36 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Ren", "Yi", ""], ["He", "Jinzheng", ""], ["Tan", "Xu", ""], ["Qin", "Tao", ""], ["Zhao", "Zhou", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2008.07707", "submitter": "Zhiwen Xiao", "authors": "Zhiwen Xiao, Xin Xu, Huanlai Xing and Juan Chen", "title": "RTFN: Robust Temporal Feature Network", "comments": "10pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series analysis plays a vital role in various applications, for\ninstance, healthcare, weather prediction, disaster forecast, etc. However, to\nobtain sufficient shapelets by a feature network is still challenging. To this\nend, we propose a novel robust temporal feature network (RTFN) that contains\ntemporal feature networks and attentional LSTM networks. The temporal feature\nnetworks are built to extract basic features from input data while the\nattentional LSTM networks are devised to capture complicated shapelets and\nrelationships to enrich features. In experiments, we embed RTFN into supervised\nstructure as a feature extraction network and into unsupervised clustering as\nan encoder, respectively. The results show that the RTFN-based supervised\nstructure is a winner of 40 out of 85 datasets and the RTFN-based unsupervised\nclustering performs the best on 4 out of 11 datasets in the UCR2018 archive.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 02:43:30 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 02:03:05 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Xiao", "Zhiwen", ""], ["Xu", "Xin", ""], ["Xing", "Huanlai", ""], ["Chen", "Juan", ""]]}, {"id": "2008.07709", "submitter": "Shusuke Kobayashi", "authors": "Shusuke Kobayashi, Susumu Shirayama", "title": "Selecting Data Adaptive Learner from Multiple Deep Learners using\n  Bayesian Networks", "comments": "14 pages, 12 tables and 4 figures, Submitted to Neural Computing and\n  Applications", "journal-ref": null, "doi": "10.1007/s00521-020-05234-6", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method to predict time-series using multiple deep learners and a Bayesian\nnetwork is proposed. In this study, the input explanatory variables are\nBayesian network nodes that are associated with learners. Training data are\ndivided using K-means clustering, and multiple deep learners are trained\ndepending on the cluster. A Bayesian network is used to determine which deep\nlearner is in charge of predicting a time-series. We determine a threshold\nvalue and select learners with a posterior probability equal to or greater than\nthe threshold value, which could facilitate more robust prediction. The\nproposed method is applied to financial time-series data, and the predicted\nresults for the Nikkei 225 index are demonstrated.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 02:48:43 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Kobayashi", "Shusuke", ""], ["Shirayama", "Susumu", ""]]}, {"id": "2008.07711", "submitter": "Shanjiaoyang Huang", "authors": "Shanjiaoyang Huang, Weiqi Peng, Zhiwei Jia, Zhuowen Tu", "title": "One-pixel Signature: Characterizing CNN Models for Backdoor Detection", "comments": "Accepted at ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the convolution neural networks (CNNs) backdoor detection problem\nby proposing a new representation called one-pixel signature. Our task is to\ndetect/classify if a CNN model has been maliciously inserted with an unknown\nTrojan trigger or not. Here, each CNN model is associated with a signature that\nis created by generating, pixel-by-pixel, an adversarial value that is the\nresult of the largest change to the class prediction. The one-pixel signature\nis agnostic to the design choice of CNN architectures, and how they were\ntrained. It can be computed efficiently for a black-box CNN model without\naccessing the network parameters. Our proposed one-pixel signature demonstrates\na substantial improvement (by around 30% in the absolute detection accuracy)\nover the existing competing methods for backdoored CNN\ndetection/classification. One-pixel signature is a general representation that\ncan be used to characterize CNN models beyond backdoor detection.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 02:54:47 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Huang", "Shanjiaoyang", ""], ["Peng", "Weiqi", ""], ["Jia", "Zhiwei", ""], ["Tu", "Zhuowen", ""]]}, {"id": "2008.07719", "submitter": "Kai Ma", "authors": "Kai Ma, Biao Jie, Daoqiang Zhang", "title": "Ordinal Pattern Kernel for Brain Connectivity Network Classification", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain connectivity networks, which characterize the functional or structural\ninteraction of brain regions, has been widely used for brain disease\nclassification. Kernel-based method, such as graph kernel (i.e., kernel defined\non graphs), has been proposed for measuring the similarity of brain networks,\nand yields the promising classification performance. However, most of graph\nkernels are built on unweighted graph (i.e., network) with edge present or not,\nand neglecting the valuable weight information of edges in brain connectivity\nnetwork, with edge weights conveying the strengths of temporal correlation or\nfiber connection between brain regions. Accordingly, in this paper, we present\nan ordinal pattern kernel for brain connectivity network classification.\nDifferent with existing graph kernels that measures the topological similarity\nof unweighted graphs, the proposed ordinal pattern kernels calculate the\nsimilarity of weighted networks by comparing ordinal patterns from weighted\nnetworks.\n  To evaluate the effectiveness of the proposed ordinal kernel, we further\ndevelop a depth-first-based ordinal pattern kernel, and perform extensive\nexperiments in a real dataset of brain disease from ADNI database. The results\ndemonstrate that our proposed ordinal pattern kernel can achieve better\nclassification performance compared with state-of-the-art graph kernels.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 03:16:40 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 04:07:32 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Ma", "Kai", ""], ["Jie", "Biao", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "2008.07720", "submitter": "Hung Pham Thuc", "authors": "Pham Thuc Hung, Kenji Yamanishi", "title": "Word2vec Skip-gram Dimensionality Selection via Sequential Normalized\n  Maximum Likelihood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a novel information criteria-based approach to\nselect the dimensionality of the word2vec Skip-gram (SG). From the perspective\nof the probability theory, SG is considered as an implicit probability\ndistribution estimation under the assumption that there exists a true\ncontextual distribution among words. Therefore, we apply information criteria\nwith the aim of selecting the best dimensionality so that the corresponding\nmodel can be as close as possible to the true distribution. We examine the\nfollowing information criteria for the dimensionality selection problem: the\nAkaike Information Criterion, Bayesian Information Criterion, and Sequential\nNormalized Maximum Likelihood (SNML) criterion. SNML is the total codelength\nrequired for the sequential encoding of a data sequence on the basis of the\nminimum description length. The proposed approach is applied to both the\noriginal SG model and the SG Negative Sampling model to clarify the idea of\nusing information criteria. Additionally, as the original SNML suffers from\ncomputational disadvantages, we introduce novel heuristics for its efficient\ncomputation. Moreover, we empirically demonstrate that SNML outperforms both\nBIC and AIC. In comparison with other evaluation methods for word embedding,\nthe dimensionality selected by SNML is significantly closer to the optimal\ndimensionality obtained by word analogy or word similarity tasks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 03:24:21 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 04:55:56 GMT"}, {"version": "v3", "created": "Tue, 25 Aug 2020 01:08:24 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Hung", "Pham Thuc", ""], ["Yamanishi", "Kenji", ""]]}, {"id": "2008.07724", "submitter": "Pulkit Khandelwal", "authors": "Pulkit Khandelwal and Paul Yushkevich", "title": "Domain Generalizer: A Few-shot Meta Learning Framework for Domain\n  Generalization in Medical Imaging", "comments": "Medical Image Computing and Computer Assisted Interventions (MICCAI)\n  2020 to be presented at DART 2020. Supplementary material and link to code\n  included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning models perform best when tested on target (test) data domains\nwhose distribution is similar to the set of source (train) domains. However,\nmodel generalization can be hindered when there is significant difference in\nthe underlying statistics between the target and source domains. In this work,\nwe adapt a domain generalization method based on a model-agnostic meta-learning\nframework to biomedical imaging. The method learns a domain-agnostic feature\nrepresentation to improve generalization of models to the unseen test\ndistribution. The method can be used for any imaging task, as it does not\ndepend on the underlying model architecture. We validate the approach through a\ncomputed tomography (CT) vertebrae segmentation task across healthy and\npathological cases on three datasets. Next, we employ few-shot learning, i.e.\ntraining the generalized model using very few examples from the unseen domain,\nto quickly adapt the model to new unseen data distribution. Our results suggest\nthat the method could help generalize models across different medical centers,\nimage acquisition protocols, anatomies, different regions in a given scan,\nhealthy and diseased populations across varied imaging modalities.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 03:35:56 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Khandelwal", "Pulkit", ""], ["Yushkevich", "Paul", ""]]}, {"id": "2008.07730", "submitter": "Ziheng Duan", "authors": "Yifu Zhou, Ziheng Duan, Haoyan Xu, Jie Feng, Anni Ren, Yueyang Wang,\n  Xiaoqian Wang", "title": "Parallel Extraction of Long-term Trends and Short-term Fluctuation\n  Framework for Multivariate Time Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series forecasting is widely used in various fields.\nReasonable prediction results can assist people in planning and\ndecision-making, generate benefits and avoid risks. Normally, there are two\ncharacteristics of time series, that is, long-term trend and short-term\nfluctuation. For example, stock prices will have a long-term upward trend with\nthe market, but there may be a small decline in the short term. These two\ncharacteristics are often relatively independent of each other. However, the\nexisting prediction methods often do not distinguish between them, which\nreduces the accuracy of the prediction model. In this paper, a MTS forecasting\nframework that can capture the long-term trends and short-term fluctuations of\ntime series in parallel is proposed. This method uses the original time series\nand its first difference to characterize long-term trends and short-term\nfluctuations. Three prediction sub-networks are constructed to predict\nlong-term trends, short-term fluctuations and the final value to be predicted.\nIn the overall optimization goal, the idea of multi-task learning is used for\nreference, which is to make the prediction results of long-term trends and\nshort-term fluctuations as close to the real values as possible while requiring\nto approximate the values to be predicted. In this way, the proposed method\nuses more supervision information and can more accurately capture the changing\ntrend of the time series, thereby improving the forecasting performance.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 03:55:29 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 15:30:45 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 16:02:57 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Zhou", "Yifu", ""], ["Duan", "Ziheng", ""], ["Xu", "Haoyan", ""], ["Feng", "Jie", ""], ["Ren", "Anni", ""], ["Wang", "Yueyang", ""], ["Wang", "Xiaoqian", ""]]}, {"id": "2008.07737", "submitter": "Andrea Zanette", "authors": "Andrea Zanette, Alessandro Lazaric, Mykel J. Kochenderfer, Emma\n  Brunskill", "title": "Provably Efficient Reward-Agnostic Navigation with Linear Value\n  Iteration", "comments": "Minor update; appears in NeurIPS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been growing progress on theoretical analyses for provably\nefficient learning in MDPs with linear function approximation, but much of the\nexisting work has made strong assumptions to enable exploration by conventional\nexploration frameworks. Typically these assumptions are stronger than what is\nneeded to find good solutions in the batch setting. In this work, we show how\nunder a more standard notion of low inherent Bellman error, typically employed\nin least-square value iteration-style algorithms, we can provide strong PAC\nguarantees on learning a near optimal value function provided that the linear\nspace is sufficiently \"explorable\". We present a computationally tractable\nalgorithm for the reward-free setting and show how it can be used to learn a\nnear optimal policy for any (linear) reward function, which is revealed only\nonce learning has completed. If this reward function is also estimated from the\nsamples gathered during pure exploration, our results also provide same-order\nPAC guarantees on the performance of the resulting policy for this setting.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 04:34:21 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 02:30:08 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Zanette", "Andrea", ""], ["Lazaric", "Alessandro", ""], ["Kochenderfer", "Mykel J.", ""], ["Brunskill", "Emma", ""]]}, {"id": "2008.07738", "submitter": "Helen Jiang", "authors": "Helen Jiang, Erwen Senge", "title": "Usable Security for ML Systems in Mental Health: A Framework", "comments": "Accepted to Designing AI in Support of Good Mental Health (GOOD)\n  Workshop at KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the applications and demands of Machine learning (ML) systems in mental\nhealth are growing, there is little discussion nor consensus regarding a\nuniquely challenging aspect: building security methods and requirements into\nthese ML systems, and keep the ML system usable for end-users. This question of\nusable security is very important, because the lack of consideration in either\nsecurity or usability would hinder large-scale user adoption and active usage\nof ML systems in mental health applications.\n  In this short paper, we introduce a framework of four pillars, and a set of\ndesired properties which can be used to systematically guide and evaluate\nsecurity-related designs, implementations, and deployments of ML systems for\nmental health. We aim to weave together threads from different domains,\nincorporate existing views, and propose new principles and requirements, in an\neffort to lay out a clear framework where criteria and expectations are\nestablished, and are used to make security mechanisms usable for end-users of\nthose ML systems in mental health. Together with this framework, we present\nseveral concrete scenarios where different usable security cases and profiles\nin ML-systems in mental health applications are examined and evaluated.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 04:44:47 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Jiang", "Helen", ""], ["Senge", "Erwen", ""]]}, {"id": "2008.07739", "submitter": "Lifeng Gu", "authors": "Lifeng Gu", "title": "Positive semidefinite support vector regression metric learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing metric learning methods focus on learning a similarity or\ndistance measure relying on similar and dissimilar relations between sample\npairs. However, pairs of samples cannot be simply identified as similar or\ndissimilar in many real-world applications, e.g., multi-label learning, label\ndistribution learning. To this end, relation alignment metric learning (RAML)\nframework is proposed to handle the metric learning problem in those scenarios.\nBut RAML framework uses SVR solvers for optimization. It can't learn positive\nsemidefinite distance metric which is necessary in metric learning. In this\npaper, we propose two methds to overcame the weakness. Further, We carry out\nseveral experiments on the single-label classification, multi-label\nclassification, label distribution learning to demonstrate the new methods\nachieves favorable performance against RAML framework.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 04:45:59 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Gu", "Lifeng", ""]]}, {"id": "2008.07740", "submitter": "Minhui Huang", "authors": "Minhui Huang, Shiqian Ma, Lifeng Lai", "title": "Robust Low-rank Matrix Completion via an Alternating Manifold Proximal\n  Gradient Continuation Method", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2021.3073544", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust low-rank matrix completion (RMC), or robust principal component\nanalysis with partially observed data, has been studied extensively for\ncomputer vision, signal processing and machine learning applications. This\nproblem aims to decompose a partially observed matrix into the superposition of\na low-rank matrix and a sparse matrix, where the sparse matrix captures the\ngrossly corrupted entries of the matrix. A widely used approach to tackle RMC\nis to consider a convex formulation, which minimizes the nuclear norm of the\nlow-rank matrix (to promote low-rankness) and the l1 norm of the sparse matrix\n(to promote sparsity). In this paper, motivated by some recent works on\nlow-rank matrix completion and Riemannian optimization, we formulate this\nproblem as a nonsmooth Riemannian optimization problem over Grassmann manifold.\nThis new formulation is scalable because the low-rank matrix is factorized to\nthe multiplication of two much smaller matrices. We then propose an alternating\nmanifold proximal gradient continuation (AManPGC) method to solve the proposed\nnew formulation. The convergence rate of the proposed algorithm is rigorously\nanalyzed. Numerical results on both synthetic data and real data on background\nextraction from surveillance videos are reported to demonstrate the advantages\nof the proposed new formulation and algorithm over several popular existing\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 04:46:22 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Huang", "Minhui", ""], ["Ma", "Shiqian", ""], ["Lai", "Lifeng", ""]]}, {"id": "2008.07758", "submitter": "Fei Zheng", "authors": "Fei Zheng", "title": "Efficient Private Machine Learning by Differentiable Random\n  Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing demands for privacy protection, many privacy-preserving\nmachine learning systems were proposed in recent years. However, most of them\ncannot be put into production due to their slow training and inference speed\ncaused by the heavy cost of homomorphic encryption and secure multiparty\ncomputation(MPC) methods. To circumvent this, I proposed a privacy definition\nwhich is suitable for large amount of data in machine learning tasks. Based on\nthat, I showed that random transformations like linear transformation and\nrandom permutation can well protect privacy. Merging random transformations and\narithmetic sharing together, I designed a framework for private machine\nlearning with high efficiency and low computation cost.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 06:17:31 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Zheng", "Fei", ""]]}, {"id": "2008.07759", "submitter": "Senci Ying", "authors": "Senci Ying", "title": "Shared MF: A privacy-preserving recommendation system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization is one of the most commonly used technologies in\nrecommendation system. With the promotion of recommendation system in\ne-commerce shopping, online video and other aspects, distributed recommendation\nsystem has been widely promoted, and the privacy problem of multi-source data\nbecomes more and more important. Based on Federated learning technology, this\npaper proposes a shared matrix factorization scheme called SharedMF. Firstly, a\ndistributed recommendation system is built, and then secret sharing technology\nis used to protect the privacy of local data. Experimental results show that\ncompared with the existing homomorphic encryption methods, our method can have\nfaster execution speed without privacy disclosure, and can better adapt to\nrecommendation scenarios with large amount of data.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 06:19:38 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Ying", "Senci", ""]]}, {"id": "2008.07773", "submitter": "Muhammad Umer Siddique", "authors": "Umer Siddique, Paul Weng, Matthieu Zimmer", "title": "Learning Fair Policies in Multiobjective (Deep) Reinforcement Learning\n  with Average and Discounted Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the operations of autonomous systems generally affect simultaneously\nseveral users, it is crucial that their designs account for fairness\nconsiderations. In contrast to standard (deep) reinforcement learning (RL), we\ninvestigate the problem of learning a policy that treats its users equitably.\nIn this paper, we formulate this novel RL problem, in which an objective\nfunction, which encodes a notion of fairness that we formally define, is\noptimized. For this problem, we provide a theoretical discussion where we\nexamine the case of discounted rewards and that of average rewards. During this\nanalysis, we notably derive a new result in the standard RL setting, which is\nof independent interest: it states a novel bound on the approximation error\nwith respect to the optimal average reward of that of a policy optimal for the\ndiscounted reward. Since learning with discounted rewards is generally easier,\nthis discussion further justifies finding a fair policy for the average reward\nby learning a fair policy for the discounted reward. Thus, we describe how\nseveral classic deep RL algorithms can be adapted to our fair optimization\nproblem, and we validate our approach with extensive experiments in three\ndifferent domains.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 07:17:53 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Siddique", "Umer", ""], ["Weng", "Paul", ""], ["Zimmer", "Matthieu", ""]]}, {"id": "2008.07779", "submitter": "Devendra Swami", "authors": "Devendra Swami, Alay Dilipbhai Shah, Subhrajeet K B Ray", "title": "Predicting Future Sales of Retail Products using Machine Learning", "comments": "6 pages, 4 images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques for making future predictions based upon the present and past\ndata, has always been an area with direct application to various real life\nproblems. We are discussing a similar problem in this paper. The problem\nstatement is provided by Kaggle, which also serves as an ongoing competition on\nthe Kaggle platform. In this project, we worked with a challenging time-series\ndataset consisting of daily sales data, kindly provided by one of the largest\nRussian software firms - 1C Company. The objective is to predict the total\nsales for every product and store in the next month given the past data.\n  In order to perform forecasting for next month, we have deployed eXtreme\nGradient Boosting (XGBoost) and Long Short Term Memory (LSTM) based network\narchitecture to perform learning task. Root mean squared error (RMSE) between\nthe actual and predicted target values is used to evaluate the performance, and\nmake comparisons between the deployed algorithms. It has been found that\nXGBoost fared better than LSTM over this dataset which can be attributed to its\nrelatively higher sparsity.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 07:36:14 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Swami", "Devendra", ""], ["Shah", "Alay Dilipbhai", ""], ["Ray", "Subhrajeet K B", ""]]}, {"id": "2008.07788", "submitter": "Maitreya Patel", "authors": "Maitreya Patel, Mirali Purohit, Jui Shah, and Hemant A. Patil", "title": "CinC-GAN for Effective F0 prediction for Whisper-to-Normal Speech\n  Conversion", "comments": "Accepted in 28th European Signal Processing Conference (EUSIPCO),\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recently, Generative Adversarial Networks (GAN)-based methods have shown\nremarkable performance for the Voice Conversion and WHiSPer-to-normal SPeeCH\n(WHSP2SPCH) conversion. One of the key challenges in WHSP2SPCH conversion is\nthe prediction of fundamental frequency (F0). Recently, authors have proposed\nstate-of-the-art method Cycle-Consistent Generative Adversarial Networks\n(CycleGAN) for WHSP2SPCH conversion. The CycleGAN-based method uses two\ndifferent models, one for Mel Cepstral Coefficients (MCC) mapping, and another\nfor F0 prediction, where F0 is highly dependent on the pre-trained model of MCC\nmapping. This leads to additional non-linear noise in predicted F0. To suppress\nthis noise, we propose Cycle-in-Cycle GAN (i.e., CinC-GAN). It is specially\ndesigned to increase the effectiveness in F0 prediction without losing the\naccuracy of MCC mapping. We evaluated the proposed method on a non-parallel\nsetting and analyzed on speaker-specific, and gender-specific tasks. The\nobjective and subjective tests show that CinC-GAN significantly outperforms the\nCycleGAN. In addition, we analyze the CycleGAN and CinC-GAN for unseen speakers\nand the results show the clear superiority of CinC-GAN.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 07:56:16 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Patel", "Maitreya", ""], ["Purohit", "Mirali", ""], ["Shah", "Jui", ""], ["Patil", "Hemant A.", ""]]}, {"id": "2008.07792", "submitter": "Chengshu Li", "authors": "Fei Xia, Chengshu Li, Roberto Mart\\'in-Mart\\'in, Or Litany, Alexander\n  Toshev, Silvio Savarese", "title": "ReLMoGen: Leveraging Motion Generation in Reinforcement Learning for\n  Mobile Manipulation", "comments": "First two authors contributed equally. Access project website at\n  http://svl.stanford.edu/projects/relmogen", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Reinforcement Learning (RL) approaches use joint control signals\n(positions, velocities, torques) as action space for continuous control tasks.\nWe propose to lift the action space to a higher level in the form of subgoals\nfor a motion generator (a combination of motion planner and trajectory\nexecutor). We argue that, by lifting the action space and by leveraging\nsampling-based motion planners, we can efficiently use RL to solve complex,\nlong-horizon tasks that could not be solved with existing RL methods in the\noriginal action space. We propose ReLMoGen -- a framework that combines a\nlearned policy to predict subgoals and a motion generator to plan and execute\nthe motion needed to reach these subgoals. To validate our method, we apply\nReLMoGen to two types of tasks: 1) Interactive Navigation tasks, navigation\nproblems where interactions with the environment are required to reach the\ndestination, and 2) Mobile Manipulation tasks, manipulation tasks that require\nmoving the robot base. These problems are challenging because they are usually\nlong-horizon, hard to explore during training, and comprise alternating phases\nof navigation and interaction. Our method is benchmarked on a diverse set of\nseven robotics tasks in photo-realistic simulation environments. In all\nsettings, ReLMoGen outperforms state-of-the-art Reinforcement Learning and\nHierarchical Reinforcement Learning baselines. ReLMoGen also shows outstanding\ntransferability between different motion generators at test time, indicating a\ngreat potential to transfer to real robots.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 08:05:15 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 04:44:22 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Xia", "Fei", ""], ["Li", "Chengshu", ""], ["Mart\u00edn-Mart\u00edn", "Roberto", ""], ["Litany", "Or", ""], ["Toshev", "Alexander", ""], ["Savarese", "Silvio", ""]]}, {"id": "2008.07796", "submitter": "Xintao Ren", "authors": "Hao Guo, Xintao Ren, Rongrong Wang, Zhun Cai, Kai Shuang and Yue Sun", "title": "A Hierarchical User Intention-Habit Extract Network for Credit Loan\n  Overdue Risk Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More personal consumer loan products are emerging in mobile banking APP. For\nease of use, application process is always simple, which means that few\napplication information is requested for user to fill when applying for a loan,\nwhich is not conducive to construct users' credit profile. Thus, the simple\napplication process brings huge challenges to the overdue risk detection, as\nhigher overdue rate will result in greater economic losses to the bank. In this\npaper, we propose a model named HUIHEN (Hierarchical User Intention-Habit\nExtract Network) that leverages the users' behavior information in mobile\nbanking APP. Due to the diversity of users' behaviors, we divide behavior\nsequences into sessions according to the time interval, and use the field-aware\nmethod to extract the intra-field information of behaviors. Then, we propose a\nhierarchical network composed of time-aware GRU and user-item-aware GRU to\ncapture users' short-term intentions and users' long-term habits, which can be\nregarded as a supplement to user profile. The proposed model can improve the\naccuracy without increasing the complexity of the original online application\nprocess. Experimental results demonstrate the superiority of HUIHEN and show\nthat HUIHEN outperforms other state-of-art models on all datasets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 08:13:49 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Guo", "Hao", ""], ["Ren", "Xintao", ""], ["Wang", "Rongrong", ""], ["Cai", "Zhun", ""], ["Shuang", "Kai", ""], ["Sun", "Yue", ""]]}, {"id": "2008.07815", "submitter": "Gabriel Michau Dr.", "authors": "Gabriel Michau and Olga Fink", "title": "Unsupervised Transfer Learning for Anomaly Detection: Application to\n  Complementary Operating Condition Transfer", "comments": "14 pages, 7 figures, 3 tables", "journal-ref": null, "doi": "10.1016/j.knosys.2021.106816", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly Detectors are trained on healthy operating condition data and raise\nan alarm when the measured samples deviate from the training data distribution.\nThis means that the samples used to train the model should be sufficient in\nquantity and representative of the healthy operating conditions. But for\nindustrial systems subject to changing operating conditions, acquiring such\ncomprehensive sets of samples requires a long collection period and delay the\npoint at which the anomaly detector can be trained and put in operation.\n  A solution to this problem is to perform unsupervised transfer learning\n(UTL), to transfer complementary data between different units. In the\nliterature however, UTL aims at finding common structure between the datasets,\nto perform clustering or dimensionality reduction. Yet, the task of\ntransferring and combining complementary training data has not been studied.\n  Our proposed framework is designed to transfer complementary operating\nconditions between different units in a completely unsupervised way to train\nmore robust anomaly detectors. It differs, thereby, from other unsupervised\ntransfer learning works as it focuses on a one-class classification problem.\nThe proposed methodology enables to detect anomalies in operating conditions\nonly experienced by other units. The proposed end-to-end framework uses\nadversarial deep learning to ensure alignment of the different units'\ndistributions. The framework introduces a new loss, inspired by a\ndimensionality reduction tool, to enforce the conservation of the inherent\nvariability of each dataset, and uses state-of-the art once-class approach to\ndetect anomalies. We demonstrate the benefit of the proposed framework using\nthree open source datasets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 09:23:39 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 10:32:27 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Michau", "Gabriel", ""], ["Fink", "Olga", ""]]}, {"id": "2008.07816", "submitter": "Anbang Yao", "authors": "Anbang Yao, Dawei Sun", "title": "Knowledge Transfer via Dense Cross-Layer Mutual-Distillation", "comments": "Accepted by ECCV 2020. The code is available at\n  https://github.com/sundw2014/DCM, which is based on the implementation of our\n  DKS work https://github.com/sundw2014/DKS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Distillation (KD) based methods adopt the one-way Knowledge\nTransfer (KT) scheme in which training a lower-capacity student network is\nguided by a pre-trained high-capacity teacher network. Recently, Deep Mutual\nLearning (DML) presented a two-way KT strategy, showing that the student\nnetwork can be also helpful to improve the teacher network. In this paper, we\npropose Dense Cross-layer Mutual-distillation (DCM), an improved two-way KT\nmethod in which the teacher and student networks are trained collaboratively\nfrom scratch. To augment knowledge representation learning, well-designed\nauxiliary classifiers are added to certain hidden layers of both teacher and\nstudent networks. To boost KT performance, we introduce dense bidirectional KD\noperations between the layers appended with classifiers. After training, all\nauxiliary classifiers are discarded, and thus there are no extra parameters\nintroduced to final models. We test our method on a variety of KT tasks,\nshowing its superiorities over related methods. Code is available at\nhttps://github.com/sundw2014/DCM\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 09:25:08 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Yao", "Anbang", ""], ["Sun", "Dawei", ""]]}, {"id": "2008.07820", "submitter": "Tien Mai", "authors": "Tien Mai and Patrick Jaillet", "title": "A Relation Analysis of Markov Decision Process Frameworks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the relation between different Markov Decision Process (MDP)\nframeworks in the machine learning and econometrics literatures, including the\nstandard MDP, the entropy and general regularized MDP, and stochastic MDP,\nwhere the latter is based on the assumption that the reward function is\nstochastic and follows a given distribution. We show that the\nentropy-regularized MDP is equivalent to a stochastic MDP model, and is\nstrictly subsumed by the general regularized MDP. Moreover, we propose a\ndistributional stochastic MDP framework by assuming that the distribution of\nthe reward function is ambiguous. We further show that the distributional\nstochastic MDP is equivalent to the regularized MDP, in the sense that they\nalways yield the same optimal policies. We also provide a connection between\nstochastic/regularized MDP and constrained MDP. Our work gives a unified view\non several important MDP frameworks, which would lead new ways to interpret the\n(entropy/general) regularized MDP frameworks through the lens of stochastic\nrewards and vice-versa. Given the recent popularity of regularized MDP in\n(deep) reinforcement learning, our work brings new understandings of how such\nalgorithmic schemes work and suggest ideas to develop new ones.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 09:27:26 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Mai", "Tien", ""], ["Jaillet", "Patrick", ""]]}, {"id": "2008.07832", "submitter": "Tzu-Jui Julius Wang", "authors": "Tzu-Jui Julius Wang, Selen Pehlivan, Jorma Laaksonen", "title": "Tackling the Unannotated: Scene Graph Generation with Bias-Reduced\n  Models", "comments": "accepted to BMVC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting a scene graph that captures visual entities and their interactions\nin an image has been considered a crucial step towards full scene\ncomprehension. Recent scene graph generation (SGG) models have shown their\ncapability of capturing the most frequent relations among visual entities.\nHowever, the state-of-the-art results are still far from satisfactory, e.g.\nmodels can obtain 31% in overall recall R@100, whereas the likewise important\nmean class-wise recall mR@100 is only around 8% on Visual Genome (VG). The\ndiscrepancy between R and mR results urges to shift the focus from pursuing a\nhigh R to a high mR with a still competitive R. We suspect that the observed\ndiscrepancy stems from both the annotation bias and sparse annotations in VG,\nin which many visual entity pairs are either not annotated at all or only with\na single relation when multiple ones could be valid. To address this particular\nissue, we propose a novel SGG training scheme that capitalizes on self-learned\nknowledge. It involves two relation classifiers, one offering a less biased\nsetting for the other to base on. The proposed scheme can be applied to most of\nthe existing SGG models and is straightforward to implement. We observe\nsignificant relative improvements in mR (between +6.6% and +20.4%) and\ncompetitive or better R (between -2.4% and 0.3%) across all standard SGG tasks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 10:04:51 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Wang", "Tzu-Jui Julius", ""], ["Pehlivan", "Selen", ""], ["Laaksonen", "Jorma", ""]]}, {"id": "2008.07838", "submitter": "Lina Wang", "authors": "Lina Wang, Rui Tang, Yawei Yue, Xingshu Chen, Wei Wang, Yi Zhu, and\n  Xuemei Zeng", "title": "Improving adversarial robustness of deep neural networks by using\n  semantic information", "comments": "13 pages, 9 figures", "journal-ref": "[J]. Knowledge-Based Systems, 2021: 107141", "doi": "10.1016/j.knosys.2021.107141", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vulnerability of deep neural networks (DNNs) to adversarial attack, which\nis an attack that can mislead state-of-the-art classifiers into making an\nincorrect classification with high confidence by deliberately perturbing the\noriginal inputs, raises concerns about the robustness of DNNs to such attacks.\nAdversarial training, which is the main heuristic method for improving\nadversarial robustness and the first line of defense against adversarial\nattacks, requires many sample-by-sample calculations to increase training size\nand is usually insufficiently strong for an entire network. This paper provides\na new perspective on the issue of adversarial robustness, one that shifts the\nfocus from the network as a whole to the critical part of the region close to\nthe decision boundary corresponding to a given class. From this perspective, we\npropose a method to generate a single but image-agnostic adversarial\nperturbation that carries the semantic information implying the directions to\nthe fragile parts on the decision boundary and causes inputs to be\nmisclassified as a specified target. We call the adversarial training based on\nsuch perturbations \"region adversarial training\" (RAT), which resembles\nclassical adversarial training but is distinguished in that it reinforces the\nsemantic information missing in the relevant regions. Experimental results on\nthe MNIST and CIFAR-10 datasets show that this approach greatly improves\nadversarial robustness even using a very small dataset from the training data;\nmoreover, it can defend against FGSM adversarial attacks that have a completely\ndifferent pattern from the model seen during retraining.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 10:23:57 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 02:24:45 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Wang", "Lina", ""], ["Tang", "Rui", ""], ["Yue", "Yawei", ""], ["Chen", "Xingshu", ""], ["Wang", "Wei", ""], ["Zhu", "Yi", ""], ["Zeng", "Xuemei", ""]]}, {"id": "2008.07853", "submitter": "Ovi Paul", "authors": "Ovi Paul", "title": "Image Pre-processing on NumtaDB for Bengali Handwritten Digit\n  Recognition", "comments": "5 pages, 8 figures and 4 tables", "journal-ref": "2018 International Conference on Bangla Speech and Language\n  Processing (ICBSLP), Sylhet, 2018, pp. 1-6", "doi": "10.1109/ICBSLP.2018.8554910", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NumtaDB is by far the largest data-set collection for handwritten digits in\nBengali. This is a diverse dataset containing more than 85000 images. But this\ndiversity also makes this dataset very difficult to work with. The goal of this\npaper is to find the benchmark for pre-processed images which gives good\naccuracy on any machine learning models. The reason being, there are no\navailable pre-processed data for Bengali digit recognition to work with like\nthe English digits for MNIST.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 11:02:25 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Paul", "Ovi", ""]]}, {"id": "2008.07863", "submitter": "Jorge Pe\\~na Queralta", "authors": "Wenshuai Zhao, Jorge Pe\\~na Queralta, Li Qingqing, Tomi Westerlund", "title": "Ubiquitous Distributed Deep Reinforcement Learning at the Edge:\n  Analyzing Byzantine Agents in Discrete Action Spaces", "comments": "Accepted to the 11th International Conference on Emerging Ubiquitous\n  Systems and Pervasive Networks (EUSPN 2020) , Elsevier (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The integration of edge computing in next-generation mobile networks is\nbringing low-latency and high-bandwidth ubiquitous connectivity to a myriad of\ncyber-physical systems. This will further boost the increasing intelligence\nthat is being embedded at the edge in various types of autonomous systems,\nwhere collaborative machine learning has the potential to play a significant\nrole. This paper discusses some of the challenges in multi-agent distributed\ndeep reinforcement learning that can occur in the presence of byzantine or\nmalfunctioning agents. As the simulation-to-reality gap gets bridged, the\nprobability of malfunctions or errors must be taken into account. We show how\nwrong discrete actions can significantly affect the collaborative learning\neffort. In particular, we analyze the effect of having a fraction of agents\nthat might perform the wrong action with a given probability. We study the\nability of the system to converge towards a common working policy through the\ncollaborative learning process based on the number of experiences from each of\nthe agents to be aggregated for each policy update, together with the fraction\nof wrong actions from agents experiencing malfunctions. Our experiments are\ncarried out in a simulation environment using the Atari testbed for the\ndiscrete action spaces, and advantage actor-critic (A2C) for the distributed\nmulti-agent training.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 11:25:39 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Zhao", "Wenshuai", ""], ["Queralta", "Jorge Pe\u00f1a", ""], ["Qingqing", "Li", ""], ["Westerlund", "Tomi", ""]]}, {"id": "2008.07864", "submitter": "Dan Olteanu", "authors": "Dan Olteanu", "title": "The Relational Data Borg is Learning", "comments": "14 pages, 11 figures, VLDB 2020 keynote", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper overviews an approach that addresses machine learning over\nrelational data as a database problem. This is justified by two observations.\nFirst, the input to the learning task is commonly the result of a feature\nextraction query over the relational data. Second, the learning task requires\nthe computation of group-by aggregates.\n  This approach has been already investigated for a number of supervised and\nunsupervised learning tasks, including: ridge linear regression, factorisation\nmachines, support vector machines, decision trees, principal component\nanalysis, and k-means; and also for linear algebra over data matrices.\n  The main message of this work is that the runtime performance of machine\nlearning can be dramatically boosted by a toolbox of techniques that exploit\nthe knowledge of the underlying data. This includes theoretical development on\nthe algebraic, combinatorial, and statistical structure of relational data\nprocessing and systems development on code specialisation, low-level\ncomputation sharing, and parallelisation. These techniques aim at lowering both\nthe complexity and the constant factors of the learning time.\n  This work is the outcome of extensive collaboration of the author with\ncolleagues from RelationalAI, in particular Mahmoud Abo Khamis, Molham Aref,\nHung Ngo, and XuanLong Nguyen, and from the FDB research project, in particular\nAhmet Kara, Milos Nikolic, Maximilian Schleich, Amir Shaikhha, Jakub Zavodny,\nand Haozhe Zhang. The author would also like to thank the members of the FDB\nproject for the figures and examples used in this paper.\n  The author is grateful for support from industry: Amazon Web Services,\nGoogle, Infor, LogicBlox, Microsoft Azure, RelationalAI; and from the funding\nagencies EPSRC and ERC. This project has received funding from the European\nUnion's Horizon 2020 research and innovation programme under grant agreement No\n682588.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 11:25:45 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Olteanu", "Dan", ""]]}, {"id": "2008.07865", "submitter": "Maximilian Toller", "authors": "Maximilian Toller, Bernhard C. Geiger, Roman Kern", "title": "A Formally Robust Time Series Distance Metric", "comments": "MileTS Workshop at KDD'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance-based classification is among the most competitive classification\nmethods for time series data. The most critical component of distance-based\nclassification is the selected distance function. Past research has proposed\nvarious different distance metrics or measures dedicated to particular aspects\nof real-world time series data, yet there is an important aspect that has not\nbeen considered so far: Robustness against arbitrary data contamination. In\nthis work, we propose a novel distance metric that is robust against\narbitrarily \"bad\" contamination and has a worst-case computational complexity\nof $\\mathcal{O}(n\\log n)$. We formally argue why our proposed metric is robust,\nand demonstrate in an empirical evaluation that the metric yields competitive\nclassification accuracy when applied in k-Nearest Neighbor time series\nclassification.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 11:28:50 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Toller", "Maximilian", ""], ["Geiger", "Bernhard C.", ""], ["Kern", "Roman", ""]]}, {"id": "2008.07870", "submitter": "Sandro Hauri", "authors": "Sandro Hauri, Nemanja Djuric, Vladan Radosavljevic, Slobodan Vucetic", "title": "Multi-Modal Trajectory Prediction of NBA Players", "comments": "Accepted Paper at WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  National Basketball Association (NBA) players are highly motivated and\nskilled experts that solve complex decision making problems at every time point\nduring a game. As a step towards understanding how players make their\ndecisions, we focus on their movement trajectories during games. We propose a\nmethod that captures the multi-modal behavior of players, where they might\nconsider multiple trajectories and select the most advantageous one. The method\nis built on an LSTM-based architecture predicting multiple trajectories and\ntheir probabilities, trained by a multi-modal loss function that updates the\nbest trajectories. Experiments on large, fine-grained NBA tracking data show\nthat the proposed method outperforms the state-of-the-art. In addition, the\nresults indicate that the approach generates more realistic trajectories and\nthat it can learn individual playing styles of specific players.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 11:35:44 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Hauri", "Sandro", ""], ["Djuric", "Nemanja", ""], ["Radosavljevic", "Vladan", ""], ["Vucetic", "Slobodan", ""]]}, {"id": "2008.07873", "submitter": "Kun Zhou", "authors": "Kun Zhou, Hui Wang, Wayne Xin Zhao, Yutao Zhu, Sirui Wang, Fuzheng\n  Zhang, Zhongyuan Wang and Ji-Rong Wen", "title": "S^3-Rec: Self-Supervised Learning for Sequential Recommendation with\n  Mutual Information Maximization", "comments": "Accepted as CIKM2020 long paper", "journal-ref": null, "doi": "10.1145/3340531.3411954", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, significant progress has been made in sequential recommendation\nwith deep learning. Existing neural sequential recommendation models usually\nrely on the item prediction loss to learn model parameters or data\nrepresentations. However, the model trained with this loss is prone to suffer\nfrom data sparsity problem. Since it overemphasizes the final performance, the\nassociation or fusion between context data and sequence data has not been well\ncaptured and utilized for sequential recommendation. To tackle this problem, we\npropose the model S^3-Rec, which stands for Self-Supervised learning for\nSequential Recommendation, based on the self-attentive neural architecture. The\nmain idea of our approach is to utilize the intrinsic data correlation to\nderive self-supervision signals and enhance the data representations via\npre-training methods for improving sequential recommendation. For our task, we\ndevise four auxiliary self-supervised objectives to learn the correlations\namong attribute, item, subsequence, and sequence by utilizing the mutual\ninformation maximization (MIM) principle. MIM provides a unified way to\ncharacterize the correlation between different types of data, which is\nparticularly suitable in our scenario. Extensive experiments conducted on six\nreal-world datasets demonstrate the superiority of our proposed method over\nexisting state-of-the-art methods, especially when only limited training data\nis available. Besides, we extend our self-supervised learning method to other\nrecommendation models, which also improve their performance.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 11:44:10 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Zhou", "Kun", ""], ["Wang", "Hui", ""], ["Zhao", "Wayne Xin", ""], ["Zhu", "Yutao", ""], ["Wang", "Sirui", ""], ["Zhang", "Fuzheng", ""], ["Wang", "Zhongyuan", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "2008.07875", "submitter": "Jorge Pe\\~na Queralta", "authors": "Wenshuai Zhao, Jorge Pe\\~na Queralta, Li Qingqing, Tomi Westerlund", "title": "Towards Closing the Sim-to-Real Gap in Collaborative Multi-Robot Deep\n  Reinforcement Learning", "comments": "Accepted to the 5th International Conference on Robotics and\n  Automation Engineering, IEEE, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current research directions in deep reinforcement learning include bridging\nthe simulation-reality gap, improving sample efficiency of experiences in\ndistributed multi-agent reinforcement learning, together with the development\nof robust methods against adversarial agents in distributed learning, among\nmany others. In this work, we are particularly interested in analyzing how\nmulti-agent reinforcement learning can bridge the gap to reality in distributed\nmulti-robot systems where the operation of the different robots is not\nnecessarily homogeneous. These variations can happen due to sensing mismatches,\ninherent errors in terms of calibration of the mechanical joints, or simple\ndifferences in accuracy. While our results are simulation-based, we introduce\nthe effect of sensing, calibration, and accuracy mismatches in distributed\nreinforcement learning with proximal policy optimization (PPO). We discuss on\nhow both the different types of perturbances and how the number of agents\nexperiencing those perturbances affect the collaborative learning effort. The\nsimulations are carried out using a Kuka arm model in the Bullet physics\nengine. This is, to the best of our knowledge, the first work exploring the\nlimitations of PPO in multi-robot systems when considering that different\nrobots might be exposed to different environments where their sensors or\nactuators have induced errors. With the conclusions of this work, we set the\ninitial point for future work on designing and developing methods to achieve\nrobust reinforcement learning on the presence of real-world perturbances that\nmight differ within a multi-robot system.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 11:57:33 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Zhao", "Wenshuai", ""], ["Queralta", "Jorge Pe\u00f1a", ""], ["Qingqing", "Li", ""], ["Westerlund", "Tomi", ""]]}, {"id": "2008.07882", "submitter": "Muhammad Omer", "authors": "Muhammad Omer, Moayad El-Amin, Ammar Nasr and Rami Ahmed", "title": "Modeling, Visualization, and Analysis of African Innovation Performance", "comments": "4 pages, 3 figures, Appeared as a poster presentation at the\n  Practical Machine Learning for Developing Countries workshop in the 2020\n  International Conference on Learning Representation (ICLR), formerly Addis\n  Ababa, held virtually, slides and corresponding video for virtual sessions\n  can be found at: https://pml4dc.github.io/iclr2020/program/pml4dc_47.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we discuss the concepts and emergence of Innovation\nPerformance, and how to quantify it, primarily working with data from the\nGlobal Innovation Index, with emphasis on the African Innovation Performance.\nWe briefly overview existing literature on using machine learning for modeling\ninnovation performance, and use simple machine learning techniques, to analyze\nand predict the \"Mobile App Creation Indicator\" from the Global Innovation\nIndex, by using insights from the stack-overflow developers survey. Also, we\nbuild and compare models to predict the Innovation Output Sub-index, also from\nthe Global Innovation Index.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 12:16:10 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Omer", "Muhammad", ""], ["El-Amin", "Moayad", ""], ["Nasr", "Ammar", ""], ["Ahmed", "Rami", ""]]}, {"id": "2008.07902", "submitter": "Guoli Wu", "authors": "Guoli Wu and Hefeng Dong and Junqiang Song and Jingya Zhang", "title": "Bayesian geoacoustic inversion using mixture density network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian geoacoustic inversion problems are conventionally solved by Markov\nchain Monte Carlo methods or its variants, which are computationally expensive.\nThis paper extends the classic Bayesian geoacoustic inversion framework by\nderiving important geoacoustic statistics of Bayesian geoacoustic inversion\nfrom the multidimensional posterior probability density (PPD) using the mixture\ndensity network (MDN) theory. These statistics make it convenient to train the\nnetwork directly on the whole parameter space and get the multidimensional PPD\nof model parameters. The present approach provides a much more efficient way to\nsolve geoacoustic inversion problems in Bayesian inference framework. The\nnetwork is trained on a simulated dataset of surface-wave dispersion curves\nwith shear-wave velocities as labels and tested on both synthetic and real data\ncases. The results show that the network gives reliable predictions and has\ngood generalization performance on unseen data. Once trained, the network can\nrapidly (within seconds) give a fully probabilistic solution which is\ncomparable to Monte Carlo methods. It provides an promising approach for\nreal-time inversion.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 13:02:40 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 08:00:52 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 02:52:35 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Wu", "Guoli", ""], ["Dong", "Hefeng", ""], ["Song", "Junqiang", ""], ["Zhang", "Jingya", ""]]}, {"id": "2008.07912", "submitter": "Andrew Cropper", "authors": "Andrew Cropper and Sebastijan Duman\\v{c}i\\'c", "title": "Inductive logic programming at 30: a new introduction", "comments": "work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inductive logic programming (ILP) is a form of machine learning. The goal of\nILP is to induce a hypothesis (a set of logical rules) that generalises given\ntraining examples. In contrast to most forms of machine learning, ILP can learn\nhuman-readable hypotheses from small amounts of data. As ILP approaches 30, we\nprovide a new introduction to the field. We introduce the necessary logical\nnotation and the main ILP learning settings. We describe the main building\nblocks of an ILP system. We compare several ILP systems on several dimensions.\nWe describe in detail four systems (Aleph, TILDE, ASPAL, and Metagol). We\ndocument some of the main application areas of ILP. Finally, we summarise the\ncurrent limitations and outline promising directions for future research.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 13:09:25 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 12:52:09 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 16:35:41 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Cropper", "Andrew", ""], ["Duman\u010di\u0107", "Sebastijan", ""]]}, {"id": "2008.07922", "submitter": "Matthew Painter", "authors": "Matthew Painter, Jonathon Hare and Adam Prugel-Bennett", "title": "Linear Disentangled Representations and Unsupervised Action Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disentangled representation learning has seen a surge in interest over recent\ntimes, generally focusing on new models which optimise one of many disparate\ndisentanglement metrics. Symmetry Based Disentangled Representation learning\nintroduced a robust mathematical framework that defined precisely what is meant\nby a \"linear disentangled representation\". This framework determined that such\nrepresentations would depend on a particular decomposition of the symmetry\ngroup acting on the data, showing that actions would manifest through\nirreducible group representations acting on independent representational\nsubspaces. Caselles-Dupre et al [2019] subsequently proposed the first model to\ninduce and demonstrate a linear disentangled representation in a VAE model. In\nthis work we empirically show that linear disentangled representations are not\ngenerally present in standard VAE models and that they instead require altering\nthe loss landscape to induce them. We proceed to show that such representations\nare a desirable property with regard to classical disentanglement metrics.\nFinally we propose a method to induce irreducible representations which forgoes\nthe need for labelled action sequences, as was required by prior work. We\nexplore a number of properties of this method, including the ability to learn\nfrom action sequences without knowledge of intermediate states and robustness\nunder visual noise. We also demonstrate that it can successfully learn 4\nindependent symmetries directly from pixels.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 13:23:57 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 14:41:48 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Painter", "Matthew", ""], ["Hare", "Jonathon", ""], ["Prugel-Bennett", "Adam", ""]]}, {"id": "2008.07939", "submitter": "Van-Hoang Nguyen", "authors": "Van-Hoang Nguyen and Kazunari Sugiyama and Preslav Nakov and Min-Yen\n  Kan", "title": "FANG: Leveraging Social Context for Fake News Detection Using Graph\n  Representation", "comments": "To appear in CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3412046", "report-no": null, "categories": "cs.SI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Factual News Graph (FANG), a novel graphical social context\nrepresentation and learning framework for fake news detection. Unlike previous\ncontextual models that have targeted performance, our focus is on\nrepresentation learning. Compared to transductive models, FANG is scalable in\ntraining as it does not have to maintain all nodes, and it is efficient at\ninference time, without the need to re-process the entire graph. Our\nexperimental results show that FANG is better at capturing the social context\ninto a high fidelity representation, compared to recent graphical and\nnon-graphical models. In particular, FANG yields significant improvements for\nthe task of fake news detection, and it is robust in the case of limited\ntraining data. We further demonstrate that the representations learned by FANG\ngeneralize to related tasks, such as predicting the factuality of reporting of\na news medium.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 14:05:16 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 11:45:23 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Nguyen", "Van-Hoang", ""], ["Sugiyama", "Kazunari", ""], ["Nakov", "Preslav", ""], ["Kan", "Min-Yen", ""]]}, {"id": "2008.07948", "submitter": "Ryo Yonetani", "authors": "Jiaxin Ma and Ryo Yonetani and Zahid Iqbal", "title": "Adaptive Distillation for Decentralized Learning from Heterogeneous\n  Clients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of decentralized learning to achieve a\nhigh-performance global model by asking a group of clients to share local\nmodels pre-trained with their own data resources. We are particularly\ninterested in a specific case where both the client model architectures and\ndata distributions are diverse, which makes it nontrivial to adopt conventional\napproaches such as Federated Learning and network co-distillation. To this end,\nwe propose a new decentralized learning method called Decentralized Learning\nvia Adaptive Distillation (DLAD). Given a collection of client models and a\nlarge number of unlabeled distillation samples, the proposed DLAD 1) aggregates\nthe outputs of the client models while adaptively emphasizing those with higher\nconfidence in given distillation samples and 2) trains the global model to\nimitate the aggregated outputs. Our extensive experimental evaluation on\nmultiple public datasets (MNIST, CIFAR-10, and CINIC-10) demonstrates the\neffectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 14:25:22 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Ma", "Jiaxin", ""], ["Yonetani", "Ryo", ""], ["Iqbal", "Zahid", ""]]}, {"id": "2008.07956", "submitter": "Farhan Khawar", "authors": "Farhan Khawar, Leonard Kin Man Poon, Nevin Lianwen Zhang", "title": "Learning the Structure of Auto-Encoding Recommenders", "comments": "Proceedings of The Web Conference 2020", "journal-ref": null, "doi": "10.1145/3366423.3380135", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoder recommenders have recently shown state-of-the-art performance in\nthe recommendation task due to their ability to model non-linear item\nrelationships effectively. However, existing autoencoder recommenders use\nfully-connected neural network layers and do not employ structure learning.\nThis can lead to inefficient training, especially when the data is sparse as\ncommonly found in collaborative filtering. The aforementioned results in lower\ngeneralization ability and reduced performance. In this paper, we introduce\nstructure learning for autoencoder recommenders by taking advantage of the\ninherent item groups present in the collaborative filtering domain. Due to the\nnature of items in general, we know that certain items are more related to each\nother than to other items. Based on this, we propose a method that first learns\ngroups of related items and then uses this information to determine the\nconnectivity structure of an auto-encoding neural network. This results in a\nnetwork that is sparsely connected. This sparse structure can be viewed as a\nprior that guides the network training. Empirically we demonstrate that the\nproposed structure learning enables the autoencoder to converge to a local\noptimum with a much smaller spectral norm and generalization error bound than\nthe fully-connected network. The resultant sparse network considerably\noutperforms the state-of-the-art methods like \\textsc{Mult-vae/Mult-dae} on\nmultiple benchmarked datasets even when the same number of parameters and flops\nare used. It also has a better cold-start performance.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 14:37:40 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Khawar", "Farhan", ""], ["Poon", "Leonard Kin Man", ""], ["Zhang", "Nevin Lianwen", ""]]}, {"id": "2008.07962", "submitter": "Xin Mao", "authors": "Xin Mao, Wenting Wang, Huimin Xu, Yuanbin Wu, Man Lan", "title": "Relational Reflection Entity Alignment", "comments": "10 pages, Accepted by CIKM2020", "journal-ref": null, "doi": "10.1145/3340531.3412001", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity alignment aims to identify equivalent entity pairs from different\nKnowledge Graphs (KGs), which is essential in integrating multi-source KGs.\nRecently, with the introduction of GNNs into entity alignment, the\narchitectures of recent models have become more and more complicated. We even\nfind two counter-intuitive phenomena within these methods: (1) The standard\nlinear transformation in GNNs is not working well. (2) Many advanced KG\nembedding models designed for link prediction task perform poorly in entity\nalignment. In this paper, we abstract existing entity alignment methods into a\nunified framework, Shape-Builder & Alignment, which not only successfully\nexplains the above phenomena but also derives two key criteria for an ideal\ntransformation operation. Furthermore, we propose a novel GNNs-based method,\nRelational Reflection Entity Alignment (RREA). RREA leverages Relational\nReflection Transformation to obtain relation specific embeddings for each\nentity in a more efficient way. The experimental results on real-world datasets\nshow that our model significantly outperforms the state-of-the-art methods,\nexceeding by 5.8%-10.9% on Hits@1.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 14:49:31 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Mao", "Xin", ""], ["Wang", "Wenting", ""], ["Xu", "Huimin", ""], ["Wu", "Yuanbin", ""], ["Lan", "Man", ""]]}, {"id": "2008.07965", "submitter": "Agostinho A. F. J\\'unior", "authors": "Janderson Ferreira (1), Agostinho A. F. J\\'unior (1), Let\\'icia Castro\n  (1), Yves M. Galv\\~ao (1), Pablo Barros (2), Bruno J. T. Fernandes (1) ((1)\n  Universidade de Pernambuco - Escola Polit\\'ecnica de Pernambuco, (2)\n  Cognitive Architecture for Collaborative Technologies Unit - Istituto\n  Italiano di Tecnologia)", "title": "Analysis of Social Robotic Navigation approaches: CNN Encoder and\n  Incremental Learning as an alternative to Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dealing with social tasks in robotic scenarios is difficult, as having humans\nin the learning loop is incompatible with most of the state-of-the-art machine\nlearning algorithms. This is the case when exploring Incremental learning\nmodels, in particular the ones involving reinforcement learning. In this work,\nwe discuss this problem and possible solutions by analysing a previous study on\nadaptive convolutional encoders for a social navigation task.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 14:54:24 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 15:11:56 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Ferreira", "Janderson", ""], ["J\u00fanior", "Agostinho A. F.", ""], ["Castro", "Let\u00edcia", ""], ["Galv\u00e3o", "Yves M.", ""], ["Barros", "Pablo", ""], ["Fernandes", "Bruno J. T.", ""]]}, {"id": "2008.07970", "submitter": "Divya Gaur", "authors": "Divya Gaur, Joachim Folz, and Andreas Dengel", "title": "Training Deep Neural Networks Without Batch Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training neural networks is an optimization problem, and finding a decent set\nof parameters through gradient descent can be a difficult task. A host of\ntechniques has been developed to aid this process before and during the\ntraining phase. One of the most important and widely used class of method is\nnormalization. It is generally favorable for neurons to receive inputs that are\ndistributed with zero mean and unit variance, so we use statistics about\ndataset to normalize them before the first layer. However, this property cannot\nbe guaranteed for the intermediate activations inside the network. A widely\nused method to enforce this property inside the network is batch normalization.\nIt was developed to combat covariate shift inside networks. Empirically it is\nknown to work, but there is a lack of theoretical understanding about its\neffectiveness and potential drawbacks it might have when used in practice. This\nwork studies batch normalization in detail, while comparing it with other\nmethods such as weight normalization, gradient clipping and dropout. The main\npurpose of this work is to determine if it is possible to train networks\neffectively when batch normalization is removed through adaption of the\ntraining process.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 15:04:40 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Gaur", "Divya", ""], ["Folz", "Joachim", ""], ["Dengel", "Andreas", ""]]}, {"id": "2008.07971", "submitter": "Yunlong Song", "authors": "Florian Fuchs, Yunlong Song, Elia Kaufmann, Davide Scaramuzza, Peter\n  Duerr", "title": "Super-Human Performance in Gran Turismo Sport Using Deep Reinforcement\n  Learning", "comments": "Accepted for Publication at the IEEE Robotics and Automation Letters\n  (RA-L) 2021, and International Conference on Robots and Automation (ICRA)\n  2021", "journal-ref": "IEEE Robotics and Automation Letters (RAL) 2021", "doi": "10.1109/LRA.2021.3064284", "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous car racing is a major challenge in robotics. It raises fundamental\nproblems for classical approaches such as planning minimum-time trajectories\nunder uncertain dynamics and controlling the car at the limits of its handling.\nBesides, the requirement of minimizing the lap time, which is a sparse\nobjective, and the difficulty of collecting training data from human experts\nhave also hindered researchers from directly applying learning-based approaches\nto solve the problem. In the present work, we propose a learning-based system\nfor autonomous car racing by leveraging a high-fidelity physical car\nsimulation, a course-progress proxy reward, and deep reinforcement learning. We\ndeploy our system in Gran Turismo Sport, a world-leading car simulator known\nfor its realistic physics simulation of different race cars and tracks, which\nis even used to recruit human race car drivers. Our trained policy achieves\nautonomous racing performance that goes beyond what had been achieved so far by\nthe built-in AI, and, at the same time, outperforms the fastest driver in a\ndataset of over 50,000 human players.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 15:06:44 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 16:03:52 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Fuchs", "Florian", ""], ["Song", "Yunlong", ""], ["Kaufmann", "Elia", ""], ["Scaramuzza", "Davide", ""], ["Duerr", "Peter", ""]]}, {"id": "2008.07978", "submitter": "Chen Chen", "authors": "Chen Chen, Jaewoo Lee", "title": "Stochastic Adaptive Line Search for Differentially Private Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of private gradient-based optimization algorithms is highly\ndependent on the choice of step size (or learning rate) which often requires\nnon-trivial amount of tuning. In this paper, we introduce a stochastic variant\nof classic backtracking line search algorithm that satisfies R\\'enyi\ndifferential privacy. Specifically, the proposed algorithm adaptively chooses\nthe step size satsisfying the the Armijo condition (with high probability)\nusing noisy gradients and function estimates. Furthermore, to improve the\nprobability with which the chosen step size satisfies the condition, it adjusts\nper-iteration privacy budget during runtime according to the reliability of\nnoisy gradient. A naive implementation of the backtracking search algorithm may\nend up using unacceptably large privacy budget as the ability of adaptive step\nsize selection comes at the cost of extra function evaluations. The proposed\nalgorithm avoids this problem by using the sparse vector technique combined\nwith the recent privacy amplification lemma. We also introduce a privacy budget\nadaptation strategy in which the algorithm adaptively increases the budget when\nit detects that directions pointed by consecutive gradients are drastically\ndifferent. Extensive experiments on both convex and non-convex problems show\nthat the adaptively chosen step sizes allow the proposed algorithm to\nefficiently use the privacy budget and show competitive performance against\nexisting private optimizers.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 15:18:47 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 05:49:54 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Chen", "Chen", ""], ["Lee", "Jaewoo", ""]]}, {"id": "2008.07989", "submitter": "Jascha Kolberg", "authors": "Jascha Kolberg and Marcel Grimmer and Marta Gomez-Barrero and\n  Christoph Busch", "title": "Anomaly Detection with Convolutional Autoencoders for Fingerprint\n  Presentation Attack Detection", "comments": null, "journal-ref": null, "doi": "10.1109/TBIOM.2021.3050036", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the popularity of fingerprint-based biometric authentication\nsystems significantly increased. However, together with many advantages,\nbiometric systems are still vulnerable to presentation attacks (PAs). In\nparticular, this applies for unsupervised applications, where new attacks\nunknown to the system operator may occur. Therefore, presentation attack\ndetection (PAD) methods are used to determine whether samples stem from a bona\nfide subject or from a presentation attack instrument (PAI). In this context,\nmost works are dedicated to solve PAD as a two-class classification problem,\nwhich includes training a model on both bona fide and PA samples. In spite of\nthe good detection rates reported, these methods still face difficulties\ndetecting PAIs from unknown materials. To address this issue, we propose a new\nPAD technique based on autoencoders (AEs) trained only on bona fide samples\n(i.e. one-class), which are captured in the short wave infrared domain. On the\nexperimental evaluation over a database of 19,711 bona fide and 4,339 PA images\nincluding 45 different PAI species, a detection equal error rate (D-EER) of\n2.00% was achieved. Additionally, our best performing AE model is compared to\nfurther one-class classifiers (support vector machine, Gaussian mixture model).\nThe results show the effectiveness of the AE model as it significantly\noutperforms the previously proposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 15:33:41 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 14:08:47 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Kolberg", "Jascha", ""], ["Grimmer", "Marcel", ""], ["Gomez-Barrero", "Marta", ""], ["Busch", "Christoph", ""]]}, {"id": "2008.07996", "submitter": "Aritra Konar", "authors": "Aritra Konar, and Nicholas D. Sidiropoulos", "title": "Mining Large Quasi-cliques with Quality Guarantees from Vertex\n  Neighborhoods", "comments": "Accepted for publication at KDD 2020 (Research Track), 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining dense subgraphs is an important primitive across a spectrum of\ngraph-mining tasks. In this work, we formally establish that two recurring\ncharacteristics of real-world graphs, namely heavy-tailed degree distributions\nand large clustering coefficients, imply the existence of substantially large\nvertex neighborhoods with high edge-density. This observation suggests a very\nsimple approach for extracting large quasi-cliques: simply scan the vertex\nneighborhoods, compute the clustering coefficient of each vertex, and output\nthe best such subgraph. The implementation of such a method requires counting\nthe triangles in a graph, which is a well-studied problem in graph mining. When\nempirically tested across a number of real-world graphs, this approach reveals\na surprise: vertex neighborhoods include maximal cliques of non-trivial sizes,\nand the density of the best neighborhood often compares favorably to subgraphs\nproduced by dedicated algorithms for maximizing subgraph density. For graphs\nwith small clustering coefficients, we demonstrate that small vertex\nneighborhoods can be refined using a local-search method to ``grow'' larger\ncliques and near-cliques. Our results indicate that contrary to worst-case\ntheoretical results, mining cliques and quasi-cliques of non-trivial sizes from\nreal-world graphs is often not a difficult problem, and provides motivation for\nfurther work geared towards a better explanation of these empirical successes.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 15:50:25 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Konar", "Aritra", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "2008.08004", "submitter": "Jesus Lago", "authors": "Jesus Lago, Grzegorz Marcjasz, Bart De Schutter, Rafa{\\l} Weron", "title": "Forecasting day-ahead electricity prices: A review of state-of-the-art\n  algorithms, best practices and an open-access benchmark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the field of electricity price forecasting has benefited from plenty of\ncontributions in the last two decades, it arguably lacks a rigorous approach to\nevaluating new predictive algorithms. The latter are often compared using\nunique, not publicly available datasets and across too short and limited to one\nmarket test samples. The proposed new methods are rarely benchmarked against\nwell established and well performing simpler models, the accuracy metrics are\nsometimes inadequate and testing the significance of differences in predictive\nperformance is seldom conducted. Consequently, it is not clear which methods\nperform well nor what are the best practices when forecasting electricity\nprices. In this paper, we tackle these issues by performing a literature survey\nof state-of-the-art models, comparing state-of-the-art statistical and deep\nlearning methods across multiple years and markets, and by putting forward a\nset of best practices. In addition, we make available the considered datasets,\nforecasts of the state-of-the-art models, and a specifically designed python\ntoolbox, so that new algorithms can be rigorously evaluated in future studies.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 16:19:20 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 15:01:59 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Lago", "Jesus", ""], ["Marcjasz", "Grzegorz", ""], ["De Schutter", "Bart", ""], ["Weron", "Rafa\u0142", ""]]}, {"id": "2008.08005", "submitter": "Siddharth Nayak", "authors": "Siddharth Nayak and Balaraman Ravindran", "title": "Reinforcement Learning for Improving Object Detection", "comments": "14 pages, 6 figures, 4 tables. Accepted in the RLQ-TOD workshop at\n  ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The performance of a trained object detection neural network depends a lot on\nthe image quality. Generally, images are pre-processed before feeding them into\nthe neural network and domain knowledge about the image dataset is used to\nchoose the pre-processing techniques. In this paper, we introduce an algorithm\ncalled ObjectRL to choose the amount of a particular pre-processing to be\napplied to improve the object detection performances of pre-trained networks.\nThe main motivation for ObjectRL is that an image which looks good to a human\neye may not necessarily be the optimal one for a pre-trained object detector to\ndetect objects.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 16:20:04 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Nayak", "Siddharth", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "2008.08006", "submitter": "Jesus Lago", "authors": "Grzegorz Marcjasz, Jesus Lago, Rafa{\\l} Weron", "title": "Neural networks in day-ahead electricity price forecasting: Single vs.\n  multiple outputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in the fields of artificial intelligence and machine\nlearning methods resulted in a significant increase of their popularity in the\nliterature, including electricity price forecasting. Said methods cover a very\nbroad spectrum, from decision trees, through random forests to various\nartificial neural network models and hybrid approaches. In electricity price\nforecasting, neural networks are the most popular machine learning method as\nthey provide a non-linear counterpart for well-tested linear regression models.\nTheir application, however, is not straightforward, with multiple\nimplementation factors to consider. One of such factors is the network's\nstructure. This paper provides a comprehensive comparison of two most common\nstructures when using the deep neural networks -- one that focuses on each hour\nof the day separately, and one that reflects the daily auction structure and\nmodels vectors of the prices. The results show a significant accuracy advantage\nof using the latter, confirmed on data from five distinct power exchanges.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 16:20:31 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Marcjasz", "Grzegorz", ""], ["Lago", "Jesus", ""], ["Weron", "Rafa\u0142", ""]]}, {"id": "2008.08007", "submitter": "Badih Ghazi", "authors": "Badih Ghazi, Ravi Kumar, Pasin Manurangsi", "title": "Differentially Private Clustering: Tight Approximation Ratios", "comments": "60 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the task of differentially private clustering. For several basic\nclustering problems, including Euclidean DensestBall, 1-Cluster, k-means, and\nk-median, we give efficient differentially private algorithms that achieve\nessentially the same approximation ratios as those that can be obtained by any\nnon-private algorithm, while incurring only small additive errors. This\nimproves upon existing efficient algorithms that only achieve some large\nconstant approximation factors.\n  Our results also imply an improved algorithm for the Sample and Aggregate\nprivacy framework. Furthermore, we show that one of the tools used in our\n1-Cluster algorithm can be employed to get a faster quantum algorithm for\nClosestPair in a moderate number of dimensions.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 16:22:06 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Ghazi", "Badih", ""], ["Kumar", "Ravi", ""], ["Manurangsi", "Pasin", ""]]}, {"id": "2008.08024", "submitter": "Neel Dey", "authors": "Guillaume Gisbert, Neel Dey, Hiroshi Ishikawa, Joel Schuman, James\n  Fishbaugh, Guido Gerig", "title": "Self-supervised Denoising via Diffeomorphic Template Estimation:\n  Application to Optical Coherence Tomography", "comments": "To be published in MICCAI Ophthalmic Medical Image Analysis 2020. 11\n  pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical Coherence Tomography (OCT) is pervasive in both the research and\nclinical practice of Ophthalmology. However, OCT images are strongly corrupted\nby noise, limiting their interpretation. Current OCT denoisers leverage\nassumptions on noise distributions or generate targets for training deep\nsupervised denoisers via averaging of repeat acquisitions. However, recent\nself-supervised advances allow the training of deep denoising networks using\nonly repeat acquisitions without clean targets as ground truth, reducing the\nburden of supervised learning. Despite the clear advantages of self-supervised\nmethods, their use is precluded as OCT shows strong structural deformations\neven between sequential scans of the same subject due to involuntary eye\nmotion. Further, direct nonlinear alignment of repeats induces correlation of\nthe noise between images. In this paper, we propose a joint diffeomorphic\ntemplate estimation and denoising framework which enables the use of\nself-supervised denoising for motion deformed repeat acquisitions, without\nempirically registering their noise realizations. Strong qualitative and\nquantitative improvements are achieved in denoising OCT images, with generic\nutility in any imaging modality amenable to multiple exposures.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 16:52:10 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Gisbert", "Guillaume", ""], ["Dey", "Neel", ""], ["Ishikawa", "Hiroshi", ""], ["Schuman", "Joel", ""], ["Fishbaugh", "James", ""], ["Gerig", "Guido", ""]]}, {"id": "2008.08031", "submitter": "Samrat Mukhopadhyay", "authors": "Samrat Mukhopadhyay, and Mrityunjoy Chakraborty", "title": "A Two Stage Generalized Block Orthogonal Matching Pursuit (TSGBOMP)\n  Algorithm", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NA math.IT math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recovery of an unknown sparse signal from a few of its projections is the key\nobjective of compressed sensing. Often one comes across signals that are not\nordinarily sparse but are sparse blockwise. Existing block sparse recovery\nalgorithms like BOMP make the assumption of uniform block size and known block\nboundaries, which are, however, not very practical in many applications. This\npaper addresses this problem and proposes a two step procedure, where the first\nstage is a coarse block location identification stage while the second stage\ncarries out finer localization of a non-zero cluster within the window selected\nin the first stage. A detailed convergence analysis of the proposed algorithm\nis carried out by first defining the so-called pseudoblock-interleaved block\nRIP of the given generalized block sparse signal and then imposing upper bounds\non the corresponding RIC. We also extend the analysis for complex vector as\nwell as matrix entries where it turns out that the extension is non-trivial and\nrequires special care. Furthermore, assuming real Gaussian sensing matrix\nentries, we find a lower bound on the probability that the derived recovery\nbounds are satisfied. The lower bound suggests that there are sets of\nparameters such that the derived bound is satisfied with high probability.\nSimulation results confirm significantly improved performance of the proposed\nalgorithm as compared to BOMP.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:00:55 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Mukhopadhyay", "Samrat", ""], ["Chakraborty", "Mrityunjoy", ""]]}, {"id": "2008.08035", "submitter": "Hesham Rakha", "authors": "Seifeldeen Eteifa, Hesham A. Rakha, Hoda Eldardiry", "title": "Predicting Coordinated Actuated Traffic Signal Change Times using LSTM\n  Neural Networks", "comments": "Paper submitted to Transportation Research Board Annual Meeting", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle acceleration and deceleration maneuvers at traffic signals results in\nsignificant fuel and energy consumption levels. Green light optimal speed\nadvisory systems require reliable estimates of signal switching times to\nimprove vehicle fuel efficiency. Obtaining these estimates is difficult for\nactuated signals where the length of each green indication changes to\naccommodate varying traffic conditions. This study details a four-step Long\nShort-Term Memory deep learning-based methodology that can be used to provide\nreasonable switching time estimates from green to red and vice versa while\nbeing robust to missing data. The four steps are data gathering, data\npreparation, machine learning model tuning, and model testing and evaluation.\nThe input to the models included controller logic, signal timing parameters,\ntime of day, traffic state from detectors, vehicle actuation data, and\npedestrian actuation data. The methodology is applied and evaluated on data\nfrom an intersection in Northern Virginia. A comparative analysis is conducted\nbetween different loss functions including the mean squared error, mean\nabsolute error, and mean relative error used in LSTM and a new loss function is\nproposed. The results show that while the proposed loss function outperforms\nconventional loss functions in terms of overall absolute error values, the\nchoice of the loss function is dependent on the prediction horizon. In\nparticular, the proposed loss function is outperformed by the mean relative\nerror for very short prediction horizons and mean squared error for very long\nprediction horizons.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 15:11:21 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Eteifa", "Seifeldeen", ""], ["Rakha", "Hesham A.", ""], ["Eldardiry", "Hoda", ""]]}, {"id": "2008.08037", "submitter": "Christopher Jung", "authors": "Christopher Jung, Changhwa Lee, Mallesh M. Pai, Aaron Roth, Rakesh\n  Vohra", "title": "Moment Multicalibration for Uncertainty Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to achieve the notion of \"multicalibration\" from H\\'ebert-Johnson\net al. [2018] not just for means, but also for variances and other higher\nmoments. Informally, it means that we can find regression functions which,\ngiven a data point, can make point predictions not just for the expectation of\nits label, but for higher moments of its label distribution as well-and those\npredictions match the true distribution quantities when averaged not just over\nthe population as a whole, but also when averaged over an enormous number of\nfinely defined subgroups. It yields a principled way to estimate the\nuncertainty of predictions on many different subgroups-and to diagnose\npotential sources of unfairness in the predictive power of features across\nsubgroups. As an application, we show that our moment estimates can be used to\nderive marginal prediction intervals that are simultaneously valid as averaged\nover all of the (sufficiently large) subgroups for which moment\nmulticalibration has been obtained.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:08:31 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Jung", "Christopher", ""], ["Lee", "Changhwa", ""], ["Pai", "Mallesh M.", ""], ["Roth", "Aaron", ""], ["Vohra", "Rakesh", ""]]}, {"id": "2008.08038", "submitter": "Jack McKenzie", "authors": "Jack R. McKenzie, Peter A. Appleby, Thomas House, Neil Walton", "title": "Fast Approximate Bayesian Contextual Cold Start Learning (FAB-COST)", "comments": null, "journal-ref": null, "doi": "10.5281/zenodo.4418676", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cold-start is a notoriously difficult problem which can occur in\nrecommendation systems, and arises when there is insufficient information to\ndraw inferences for users or items. To address this challenge, a contextual\nbandit algorithm -- the Fast Approximate Bayesian Contextual Cold Start\nLearning algorithm (FAB-COST) -- is proposed, which is designed to provide\nimproved accuracy compared to the traditionally used Laplace approximation in\nthe logistic contextual bandit, while controlling both algorithmic complexity\nand computational cost. To this end, FAB-COST uses a combination of two moment\nprojection variational methods: Expectation Propagation (EP), which performs\nwell at the cold start, but becomes slow as the amount of data increases; and\nAssumed Density Filtering (ADF), which has slower growth of computational cost\nwith data size but requires more data to obtain an acceptable level of\naccuracy. By switching from EP to ADF when the dataset becomes large, it is\nable to exploit their complementary strengths. The empirical justification for\nFAB-COST is presented, and systematically compared to other approaches on\nsimulated data. In a benchmark against the Laplace approximation on real data\nconsisting of over $670,000$ impressions from autotrader.co.uk, FAB-COST\ndemonstrates at one point increase of over $16\\%$ in user clicks. On the basis\nof these results, it is argued that FAB-COST is likely to be an attractive\napproach to cold-start recommendation systems in a variety of contexts.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:08:39 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["McKenzie", "Jack R.", ""], ["Appleby", "Peter A.", ""], ["House", "Thomas", ""], ["Walton", "Neil", ""]]}, {"id": "2008.08041", "submitter": "Wilfredo Tovar", "authors": "Wilfredo Tovar", "title": "Deep Learning Based on Generative Adversarial and Convolutional Neural\n  Networks for Financial Time Series Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the big data era, deep learning and intelligent data mining technique\nsolutions have been applied by researchers in various areas. Forecast and\nanalysis of stock market data have represented an essential role in today's\neconomy, and a significant challenge to the specialist since the market's\ntendencies are immensely complex, chaotic and are developed within a highly\ndynamic environment. There are numerous researches from multiple areas\nintending to take on that challenge, and Machine Learning approaches have been\nthe focus of many of them. There are multiple models of Machine Learning\nalgorithms been able to obtain competent outcomes doing that class of\nforesight. This paper proposes the implementation of a generative adversarial\nnetwork (GAN), which is composed by a bi-directional Long short-term memory\n(LSTM) and convolutional neural network(CNN) referred as Bi-LSTM-CNN to\ngenerate synthetic data that agree with existing real financial data so the\nfeatures of stocks with positive or negative trends can be retained to predict\nfuture trends of a stock. The novelty of this proposed solution that distinct\nfrom previous solutions is that this paper introduced the concept of a hybrid\nsystem (Bi-LSTM-CNN) rather than a sole LSTM model. It was collected data from\nmultiple stock markets such as TSX, SHCOMP, KOSPI 200 and the S&P 500,\nproposing an adaptative-hybrid system for trends prediction on stock market\nprices, and carried a comprehensive evaluation on several commonly utilized\nmachine learning prototypes, and it is concluded that the proposed solution\napproach outperforms preceding models. Additionally, during the research stage\nfrom preceding works, gaps were found between investors and researchers who\ndedicated to the technical domain.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 08:42:46 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 18:29:41 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Tovar", "Wilfredo", ""]]}, {"id": "2008.08044", "submitter": "Deborshee Sen", "authors": "Deborshee Sen and Theodore Papamarkou and David Dunson", "title": "Bayesian neural networks and dimensionality reduction", "comments": "29 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In conducting non-linear dimensionality reduction and feature learning, it is\ncommon to suppose that the data lie near a lower-dimensional manifold. A class\nof model-based approaches for such problems includes latent variables in an\nunknown non-linear regression function; this includes Gaussian process latent\nvariable models and variational auto-encoders (VAEs) as special cases. VAEs are\nartificial neural networks (ANNs) that employ approximations to make\ncomputation tractable; however, current implementations lack adequate\nuncertainty quantification in estimating the parameters, predictive densities,\nand lower-dimensional subspace, and can be unstable and lack interpretability\nin practice. We attempt to solve these problems by deploying Markov chain Monte\nCarlo sampling algorithms (MCMC) for Bayesian inference in ANN models with\nlatent variables. We address issues of identifiability by imposing constraints\non the ANN parameters as well as by using anchor points. This is demonstrated\non simulated and real data examples. We find that current MCMC sampling schemes\nface fundamental challenges in neural networks involving latent variables,\nmotivating new research directions.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:11:07 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 15:47:32 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Sen", "Deborshee", ""], ["Papamarkou", "Theodore", ""], ["Dunson", "David", ""]]}, {"id": "2008.08045", "submitter": "Arash Azhand", "authors": "Dr. Arash Azhand, Dr. Sophie Rabe, Dr. Swantje M\\\"uller, Igor Sattler,\n  Dr. Anika Steinert", "title": "Algorithm Based on One Monocular Video Delivers Highly Valid and\n  Reliable Gait Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite its paramount importance for manifold use cases (e.g., in the health\ncare industry, sports, rehabilitation and fitness assessment), sufficiently\nvalid and reliable gait parameter measurement is still limited to high-tech\ngait laboratories mostly. Here, we demonstrate the excellent validity and\ntest-retest repeatability of a novel gait assessment system which is built upon\nmodern convolutional neural networks to extract three-dimensional skeleton\njoints from monocular frontal-view videos of walking humans. The validity study\nis based on a comparison to the GAITRite pressure-sensitive walkway system. All\nmeasured gait parameters (gait speed, cadence, step length and step time)\nshowed excellent concurrent validity for multiple walk trials at normal and\nfast gait speeds. The test-retest-repeatability is on the same level as the\nGAITRite system. In conclusion, we are convinced that our results can pave the\nway for cost, space and operationally effective gait analysis in broad\nmainstream applications. Most sensor-based systems are costly, must be operated\nby extensively trained personnel (e.g., motion capture systems) or - even if\nnot quite as costly - still possess considerable complexity (e.g., wearable\nsensors). In contrast, a video sufficient for the assessment method presented\nhere can be obtained by anyone, without much training, via a smartphone camera.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 12:02:22 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 14:04:52 GMT"}, {"version": "v3", "created": "Tue, 25 Aug 2020 16:08:21 GMT"}, {"version": "v4", "created": "Tue, 8 Sep 2020 14:48:22 GMT"}, {"version": "v5", "created": "Wed, 23 Jun 2021 08:34:15 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Azhand", "Dr. Arash", ""], ["Rabe", "Dr. Sophie", ""], ["M\u00fcller", "Dr. Swantje", ""], ["Sattler", "Igor", ""], ["Steinert", "Dr. Anika", ""]]}, {"id": "2008.08046", "submitter": "Fuqiang Gu Dr", "authors": "Fuqiang Gu, Weicong Sng, Tasbolat Taunyazov and Harold Soh", "title": "TactileSGNet: A Spiking Graph Neural Network for Event-based Tactile\n  Object Recognition", "comments": "IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tactile perception is crucial for a variety of robot tasks including grasping\nand in-hand manipulation. New advances in flexible, event-driven, electronic\nskins may soon endow robots with touch perception capabilities similar to\nhumans. These electronic skins respond asynchronously to changes (e.g., in\npressure, temperature), and can be laid out irregularly on the robot's body or\nend-effector. However, these unique features may render current deep learning\napproaches such as convolutional feature extractors unsuitable for tactile\nlearning. In this paper, we propose a novel spiking graph neural network for\nevent-based tactile object recognition. To make use of local connectivity of\ntaxels, we present several methods for organizing the tactile data in a graph\nstructure. Based on the constructed graphs, we develop a spiking graph\nconvolutional network. The event-driven nature of spiking neural network makes\nit arguably more suitable for processing the event-based data. Experimental\nresults on two tactile datasets show that the proposed method outperforms other\nstate-of-the-art spiking methods, achieving high accuracies of approximately\n90\\% when classifying a variety of different household objects.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 03:35:15 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Gu", "Fuqiang", ""], ["Sng", "Weicong", ""], ["Taunyazov", "Tasbolat", ""], ["Soh", "Harold", ""]]}, {"id": "2008.08048", "submitter": "Youssef Aboutaleb", "authors": "Youssef M. Aboutaleb, Moshe Ben-Akiva, Patrick Jaillet", "title": "Learning Structure in Nested Logit Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new data-driven methodology for nested logit\nstructure discovery. Nested logit models allow the modeling of positive\ncorrelations between the error terms of the utility specifications of the\ndifferent alternatives in a discrete choice scenario through the specification\nof a nesting structure. Current nested logit model estimation practices require\nan a priori specification of a nesting structure by the modeler. In this we\nwork we optimize over all possible specifications of the nested logit model\nthat are consistent with rational utility maximization. We formulate the\nproblem of learning an optimal nesting structure from the data as a mixed\ninteger nonlinear programming (MINLP) optimization problem and solve it using a\nvariant of the linear outer approximation algorithm. We exploit the tree\nstructure of the problem and utilize the latest advances in integer\noptimization to bring practical tractability to the optimization problem we\nintroduce. We demonstrate the ability of our algorithm to correctly recover the\ntrue nesting structure from synthetic data in a Monte Carlo experiment. In an\nempirical illustration using a stated preference survey on modes of\ntransportation in the U.S. state of Massachusetts, we use our algorithm to\nobtain an optimal nesting tree representing the correlations between the\nunobserved effects of the different travel mode choices. We provide our\nimplementation as a customizable and open-source code base written in the Julia\nprogramming language.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:15:43 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Aboutaleb", "Youssef M.", ""], ["Ben-Akiva", "Moshe", ""], ["Jaillet", "Patrick", ""]]}, {"id": "2008.08049", "submitter": "Wassime Siguerdidjane", "authors": "Wassime Siguerdidjane, Farbod Khameneifar, Fr\\'ed\\'erick P. Gosselin", "title": "Efficient planning of peen-forming patterns via artificial neural\n  networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.mfglet.2020.08.001", "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust automation of the shot peen forming process demands a closed-loop\nfeedback in which a suitable treatment pattern needs to be found in real-time\nfor each treatment iteration. In this work, we present a method for finding the\npeen-forming patterns, based on a neural network (NN), which learns the\nnonlinear function that relates a given target shape (input) to its optimal\npeening pattern (output), from data generated by finite element simulations.\nThe trained NN yields patterns with an average binary accuracy of 98.8\\% with\nrespect to the ground truth in microseconds.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:17:46 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Siguerdidjane", "Wassime", ""], ["Khameneifar", "Farbod", ""], ["Gosselin", "Fr\u00e9d\u00e9rick P.", ""]]}, {"id": "2008.08057", "submitter": "Siddharth Samsi", "authors": "Siddharth Samsi, Andrew Prout, Michael Jones, Andrew Kirby, Bill\n  Arcand, Bill Bergeron, David Bestor, Chansup Byun, Vijay Gadepally, Michael\n  Houle, Matthew Hubbell, Anna Klein, Peter Michaleas, Lauren Milechin, Julie\n  Mullen, Antonio Rosa, Charles Yee, Albert Reuther, Jeremy Kepner", "title": "Benchmarking network fabrics for data distributed training of deep\n  neural networks", "comments": "Accepted for publication at IEEE HPEC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence/Machine Learning applications require the training of\ncomplex models on large amounts of labelled data. The large computational\nrequirements for training deep models have necessitated the development of new\nmethods for faster training. One such approach is the data parallel approach,\nwhere the training data is distributed across multiple compute nodes. This\napproach is simple to implement and supported by most of the commonly used\nmachine learning frameworks. The data parallel approach leverages MPI for\ncommunicating gradients across all nodes. In this paper, we examine the effects\nof using different physical hardware interconnects and network-related software\nprimitives for enabling data distributed deep learning. We compare the effect\nof using GPUDirect and NCCL on Ethernet and OmniPath fabrics. Our results show\nthat using Ethernet-based networking in shared HPC systems does not have a\nsignificant effect on the training times for commonly used deep neural network\narchitectures or traditional HPC applications such as Computational Fluid\nDynamics.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:38:30 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Samsi", "Siddharth", ""], ["Prout", "Andrew", ""], ["Jones", "Michael", ""], ["Kirby", "Andrew", ""], ["Arcand", "Bill", ""], ["Bergeron", "Bill", ""], ["Bestor", "David", ""], ["Byun", "Chansup", ""], ["Gadepally", "Vijay", ""], ["Houle", "Michael", ""], ["Hubbell", "Matthew", ""], ["Klein", "Anna", ""], ["Michaleas", "Peter", ""], ["Milechin", "Lauren", ""], ["Mullen", "Julie", ""], ["Rosa", "Antonio", ""], ["Yee", "Charles", ""], ["Reuther", "Albert", ""], ["Kepner", "Jeremy", ""]]}, {"id": "2008.08059", "submitter": "Eran Malach", "authors": "Eran Malach, Shai Shalev-Shwartz", "title": "When Hardness of Approximation Meets Hardness of Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A supervised learning algorithm has access to a distribution of labeled\nexamples, and needs to return a function (hypothesis) that correctly labels the\nexamples. The hypothesis of the learner is taken from some fixed class of\nfunctions (e.g., linear classifiers, neural networks etc.). A failure of the\nlearning algorithm can occur due to two possible reasons: wrong choice of\nhypothesis class (hardness of approximation), or failure to find the best\nfunction within the hypothesis class (hardness of learning). Although both\napproximation and learnability are important for the success of the algorithm,\nthey are typically studied separately. In this work, we show a single hardness\nproperty that implies both hardness of approximation using linear classes and\nshallow networks, and hardness of learning using correlation queries and\ngradient-descent. This allows us to obtain new results on hardness of\napproximation and learnability of parity functions, DNF formulas and $AC^0$\ncircuits.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:41:28 GMT"}, {"version": "v2", "created": "Sun, 23 Aug 2020 13:46:10 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Malach", "Eran", ""], ["Shalev-Shwartz", "Shai", ""]]}, {"id": "2008.08060", "submitter": "Zhenge Jia", "authors": "Zhenge Jia, Zhepeng Wang, Feng Hong, Lichuan Ping, Yiyu Shi, Jingtong\n  Hu", "title": "Personalized Deep Learning for Ventricular Arrhythmias Detection on\n  Medical IoT Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Life-threatening ventricular arrhythmias (VA) are the leading cause of sudden\ncardiac death (SCD), which is the most significant cause of natural death in\nthe US. The implantable cardioverter defibrillator (ICD) is a small device\nimplanted to patients under high risk of SCD as a preventive treatment. The ICD\ncontinuously monitors the intracardiac rhythm and delivers shock when detecting\nthe life-threatening VA. Traditional methods detect VA by setting criteria on\nthe detected rhythm. However, those methods suffer from a high inappropriate\nshock rate and require a regular follow-up to optimize criteria parameters for\neach ICD recipient. To ameliorate the challenges, we propose the personalized\ncomputing framework for deep learning based VA detection on medical IoT\nsystems. The system consists of intracardiac and surface rhythm monitors, and\nthe cloud platform for data uploading, diagnosis, and CNN model\npersonalization. We equip the system with real-time inference on both\nintracardiac and surface rhythm monitors. To improve the detection accuracy, we\nenable the monitors to detect VA collaboratively by proposing the cooperative\ninference. We also introduce the CNN personalization for each patient based on\nthe computing framework to tackle the unlabeled and limited rhythm data\nproblem. When compared with the traditional detection algorithm, the proposed\nmethod achieves comparable accuracy on VA rhythm detection and 6.6% reduction\nin inappropriate shock rate, while the average inference latency is kept at\n71ms.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:41:58 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Jia", "Zhenge", ""], ["Wang", "Zhepeng", ""], ["Hong", "Feng", ""], ["Ping", "Lichuan", ""], ["Shi", "Yiyu", ""], ["Hu", "Jingtong", ""]]}, {"id": "2008.08062", "submitter": "Siddharth Samsi", "authors": "Siddharth Samsi, Michael Jones, Mark M. Veillette", "title": "Compute, Time and Energy Characterization of Encoder-Decoder Networks\n  with Automatic Mixed Precision Training", "comments": "Accepted for publication at IEEE HPEC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have shown great success in many diverse fields. The\ntraining of these networks can take significant amounts of time, compute and\nenergy. As datasets get larger and models become more complex, the exploration\nof model architectures becomes prohibitive. In this paper we examine the\ncompute, energy and time costs of training a UNet based deep neural network for\nthe problem of predicting short term weather forecasts (called precipitation\nNowcasting). By leveraging a combination of data distributed and\nmixed-precision training, we explore the design space for this problem. We also\nshow that larger models with better performance come at a potentially\nincremental cost if appropriate optimizations are used. We show that it is\npossible to achieve a significant improvement in training time by leveraging\nmixed-precision training without sacrificing model performance. Additionally,\nwe find that a 1549% increase in the number of trainable parameters for a\nnetwork comes at a relatively smaller 63.22% increase in energy usage for a\nUNet with 4 encoding layers.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:44:24 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Samsi", "Siddharth", ""], ["Jones", "Michael", ""], ["Veillette", "Mark M.", ""]]}, {"id": "2008.08071", "submitter": "Lunjia Hu", "authors": "Lunjia Hu, Omer Reingold", "title": "Robust Mean Estimation on Highly Incomplete Data with Arbitrary Outliers", "comments": "29 pages, 2 figures. Published in AISTATS 2021. More details in the\n  proof of Claim 14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of robustly estimating the mean of a $d$-dimensional\ndistribution given $N$ examples, where most coordinates of every example may be\nmissing and $\\varepsilon N$ examples may be arbitrarily corrupted. Assuming\neach coordinate appears in a constant factor more than $\\varepsilon N$\nexamples, we show algorithms that estimate the mean of the distribution with\ninformation-theoretically optimal dimension-independent error guarantees in\nnearly-linear time $\\widetilde O(Nd)$. Our results extend recent work on\ncomputationally-efficient robust estimation to a more widely applicable\nincomplete-data setting.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:53:34 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 07:50:25 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 01:13:12 GMT"}, {"version": "v4", "created": "Sat, 6 Mar 2021 19:39:54 GMT"}, {"version": "v5", "created": "Mon, 3 May 2021 04:25:56 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Hu", "Lunjia", ""], ["Reingold", "Omer", ""]]}, {"id": "2008.08072", "submitter": "Michael S. Ryoo", "authors": "Michael S. Ryoo, AJ Piergiovanni, Juhana Kangaspunta, Anelia Angelova", "title": "AssembleNet++: Assembling Modality Representations via Attention\n  Connections", "comments": "ECCV 2020 camera-ready version", "journal-ref": "ECCV 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We create a family of powerful video models which are able to: (i) learn\ninteractions between semantic object information and raw appearance and motion\nfeatures, and (ii) deploy attention in order to better learn the importance of\nfeatures at each convolutional block of the network. A new network component\nnamed peer-attention is introduced, which dynamically learns the attention\nweights using another block or input modality. Even without pre-training, our\nmodels outperform the previous work on standard public activity recognition\ndatasets with continuous videos, establishing new state-of-the-art. We also\nconfirm that our findings of having neural connections from the object modality\nand the use of peer-attention is generally applicable for different existing\narchitectures, improving their performances. We name our model explicitly as\nAssembleNet++. The code will be available at:\nhttps://sites.google.com/corp/view/assemblenet/\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:54:08 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Ryoo", "Michael S.", ""], ["Piergiovanni", "AJ", ""], ["Kangaspunta", "Juhana", ""], ["Angelova", "Anelia", ""]]}, {"id": "2008.08078", "submitter": "Venkatasubramanian Viswanathan", "authors": "Dilip Krishnamurthy and Nikifar Lazouski and Michal L. Gala and\n  Karthish Manthiram and Venkatasubramanian Viswanathan", "title": "Closed-Loop Design of Proton Donors for Lithium-Mediated Ammonia\n  Synthesis with Interpretable Models and Molecular Machine Learning", "comments": "27 pages, 6 figures, 30 pages of Supporting Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we experimentally determined the efficacy of several classes of\nproton donors for lithium-mediated electrochemical nitrogen reduction in a\ntetrahydrofuran-based electrolyte, an attractive alternative method for\nproducing ammonia. We then built an interpretable data-driven classification\nmodel which identified solvatochromic Kamlet-Taft parameters as important for\ndistinguishing between active and inactive proton donors. After curating a\ndataset for the Kamlet-Taft parameters, we trained a deep learning model to\npredict the Kamlet-Taft parameters. The combination of classification model and\ndeep learning model provides a predictive mapping from a given proton donor to\nthe ability to produce ammonia. We demonstrate that this combination of\nclassification model with deep learning is superior to a purely mechanistic or\ndata-driven approach in accuracy and experimental data efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:58:52 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 17:47:41 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Krishnamurthy", "Dilip", ""], ["Lazouski", "Nikifar", ""], ["Gala", "Michal L.", ""], ["Manthiram", "Karthish", ""], ["Viswanathan", "Venkatasubramanian", ""]]}, {"id": "2008.08080", "submitter": "Raphael Sonabend", "authors": "Raphael Sonabend, Franz J. Kir\\'aly, Andreas Bender, Bernd Bischl,\n  Michel Lang", "title": "mlr3proba: An R Package for Machine Learning in Survival Analysis", "comments": "Submitted to Bioinformatics", "journal-ref": null, "doi": "10.1093/bioinformatics/btab039", "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning has become increasingly popular over the last few\ndecades, so too has the number of machine learning interfaces for implementing\nthese models. Whilst many R libraries exist for machine learning, very few\noffer extended support for survival analysis. This is problematic considering\nits importance in fields like medicine, bioinformatics, economics, engineering,\nand more. mlr3proba provides a comprehensive machine learning interface for\nsurvival analysis and connects with mlr3's general model tuning and\nbenchmarking facilities to provide a systematic infrastructure for survival\nmodeling and evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 11:21:24 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 11:41:25 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Sonabend", "Raphael", ""], ["Kir\u00e1ly", "Franz J.", ""], ["Bender", "Andreas", ""], ["Bischl", "Bernd", ""], ["Lang", "Michel", ""]]}, {"id": "2008.08113", "submitter": "Rishika Agarwal", "authors": "Rishika Agarwal, Xiaochuan Niu, Pranay Dighe, Srikanth Vishnubhotla,\n  Sameer Badaskar, Devang Naik", "title": "Complementary Language Model and Parallel Bi-LRNN for False Trigger\n  Mitigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  False triggers in voice assistants are unintended invocations of the\nassistant, which not only degrade the user experience but may also compromise\nprivacy. False trigger mitigation (FTM) is a process to detect the false\ntrigger events and respond appropriately to the user. In this paper, we propose\na novel solution to the FTM problem by introducing a parallel ASR decoding\nprocess with a special language model trained from \"out-of-domain\" data\nsources. Such language model is complementary to the existing language model\noptimized for the assistant task. A bidirectional lattice RNN (Bi-LRNN)\nclassifier trained from the lattices generated by the complementary language\nmodel shows a $38.34\\%$ relative reduction of the false trigger (FT) rate at\nthe fixed rate of $0.4\\%$ false suppression (FS) of correct invocations,\ncompared to the current Bi-LRNN model. In addition, we propose to train a\nparallel Bi-LRNN model based on the decoding lattices from both language\nmodels, and examine various ways of implementation. The resulting model leads\nto further reduction in the false trigger rate by $10.8\\%$.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 18:21:33 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Agarwal", "Rishika", ""], ["Niu", "Xiaochuan", ""], ["Dighe", "Pranay", ""], ["Vishnubhotla", "Srikanth", ""], ["Badaskar", "Sameer", ""], ["Naik", "Devang", ""]]}, {"id": "2008.08118", "submitter": "Mohammad-Parsa Hosseini", "authors": "Mohammad-Parsa Hosseini, Cecilia Hemingway, Jerard Madamba, Alexander\n  McKee, Natalie Ploof, Jennifer Schuman, and Elliot Voss", "title": "Review of Machine Learning Algorithms for Brain Stroke Diagnosis and\n  Prognosis by EEG Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, strokes are the leading cause of adult disability in the United\nStates. Traditional treatment and rehabilitation options such as physical\ntherapy and tissue plasminogen activator are limited in their effectiveness and\nability to restore mobility and function to the patient. As a result, there\nexists an opportunity to greatly improve the treatment for strokes. Machine\nlearning, specifically techniques that utilize Brain-Computer Interfaces (BCIs)\nto help the patient either restore neurologic pathways or effectively\ncommunicate with an electronic prosthetic, show promising results when applied\nto both stroke diagnosis and rehabilitation. In this review, sources that\ndesign and implement BCIs for treatment of stroke patients are evaluated and\ncategorized based on their successful applications for stroke diagnosis or\nstroke rehabilitation. The various machine learning techniques and algorithms\nthat are addressed and combined with BCI technology show that the use of BCIs\nfor stroke treatment is a promising and rapidly expanding field.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 19:50:29 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Hosseini", "Mohammad-Parsa", ""], ["Hemingway", "Cecilia", ""], ["Madamba", "Jerard", ""], ["McKee", "Alexander", ""], ["Ploof", "Natalie", ""], ["Schuman", "Jennifer", ""], ["Voss", "Elliot", ""]]}, {"id": "2008.08134", "submitter": "Martin Aum\\\"uller", "authors": "Martin Aum\\\"uller and Anders Bourgeat and Jana Schmurr", "title": "Differentially Private Sketches for Jaccard Similarity Estimation", "comments": "Accepted at SISAP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes two locally-differential private algorithms for\nreleasing user vectors such that the Jaccard similarity between these vectors\ncan be efficiently estimated. The basic building block is the well known\nMinHash method. To achieve a privacy-utility trade-off, MinHash is extended in\ntwo ways using variants of Generalized Randomized Response and the Laplace\nMechanism. A theoretical analysis provides bounds on the absolute error and\nexperiments show the utility-privacy trade-off on synthetic and real-world\ndata. The paper ends with a critical discussion of related work.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 19:42:46 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Aum\u00fcller", "Martin", ""], ["Bourgeat", "Anders", ""], ["Schmurr", "Jana", ""]]}, {"id": "2008.08136", "submitter": "Ramy Battrawy", "authors": "Rishav, Ramy Battrawy, Ren\\'e Schuster, Oliver Wasenm\\\"uller and\n  Didier Stricker", "title": "DeepLiDARFlow: A Deep Learning Architecture For Scene Flow Estimation\n  Using Monocular Camera and Sparse LiDAR", "comments": "This paper is accepted to IROS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene flow is the dense 3D reconstruction of motion and geometry of a scene.\nMost state-of-the-art methods use a pair of stereo images as input for full\nscene reconstruction. These methods depend a lot on the quality of the RGB\nimages and perform poorly in regions with reflective objects, shadows,\nill-conditioned light environment and so on. LiDAR measurements are much less\nsensitive to the aforementioned conditions but LiDAR features are in general\nunsuitable for matching tasks due to their sparse nature. Hence, using both\nLiDAR and RGB can potentially overcome the individual disadvantages of each\nsensor by mutual improvement and yield robust features which can improve the\nmatching process. In this paper, we present DeepLiDARFlow, a novel deep\nlearning architecture which fuses high level RGB and LiDAR features at multiple\nscales in a monocular setup to predict dense scene flow. Its performance is\nmuch better in the critical regions where image-only and LiDAR-only methods are\ninaccurate. We verify our DeepLiDARFlow using the established data sets KITTI\nand FlyingThings3D and we show strong robustness compared to several\nstate-of-the-art methods which used other input modalities. The code of our\npaper is available at https://github.com/dfki-av/DeepLiDARFlow.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 19:51:08 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Rishav", "", ""], ["Battrawy", "Ramy", ""], ["Schuster", "Ren\u00e9", ""], ["Wasenm\u00fcller", "Oliver", ""], ["Stricker", "Didier", ""]]}, {"id": "2008.08148", "submitter": "Saket Dingliwal", "authors": "Hai Pham, Amrith Setlur, Saket Dingliwal, Tzu-Hsiang Lin, Barnabas\n  Poczos, Kang Huang, Zhuo Li, Jae Lim, Collin McCormack, Tam Vu", "title": "Robust Handwriting Recognition with Limited and Noisy Data", "comments": "icfhr2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the advent of deep learning in computer vision, the general\nhandwriting recognition problem is far from solved. Most existing approaches\nfocus on handwriting datasets that have clearly written text and carefully\nsegmented labels. In this paper, we instead focus on learning handwritten\ncharacters from maintenance logs, a constrained setting where data is very\nlimited and noisy. We break the problem into two consecutive stages of word\nsegmentation and word recognition respectively and utilize data augmentation\ntechniques to train both stages. Extensive comparisons with popular baselines\nfor scene-text detection and word recognition show that our system achieves a\nlower error rate and is more suited to handle noisy and difficult documents\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 20:33:23 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Pham", "Hai", ""], ["Setlur", "Amrith", ""], ["Dingliwal", "Saket", ""], ["Lin", "Tzu-Hsiang", ""], ["Poczos", "Barnabas", ""], ["Huang", "Kang", ""], ["Li", "Zhuo", ""], ["Lim", "Jae", ""], ["McCormack", "Collin", ""], ["Vu", "Tam", ""]]}, {"id": "2008.08157", "submitter": "Oliver Limoyo", "authors": "Oliver Limoyo and Bryan Chan and Filip Mari\\'c and Brandon Wagstaff\n  and Rupam Mahmood and Jonathan Kelly", "title": "Heteroscedastic Uncertainty for Robust Generative Latent Dynamics", "comments": "In IEEE Robotics and Automation Letters (RA-L) and presented at the\n  IEEE International Conference on Intelligent Robots and Systems (IROS'20),\n  Las Vegas, USA, October 25-29, 2020", "journal-ref": null, "doi": "10.1109/LRA.2020.3015449", "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning or identifying dynamics from a sequence of high-dimensional\nobservations is a difficult challenge in many domains, including reinforcement\nlearning and control. The problem has recently been studied from a generative\nperspective through latent dynamics: high-dimensional observations are embedded\ninto a lower-dimensional space in which the dynamics can be learned. Despite\nsome successes, latent dynamics models have not yet been applied to real-world\nrobotic systems where learned representations must be robust to a variety of\nperceptual confounds and noise sources not seen during training. In this paper,\nwe present a method to jointly learn a latent state representation and the\nassociated dynamics that is amenable for long-term planning and closed-loop\ncontrol under perceptually difficult conditions. As our main contribution, we\ndescribe how our representation is able to capture a notion of heteroscedastic\nor input-specific uncertainty at test time by detecting novel or\nout-of-distribution (OOD) inputs. We present results from prediction and\ncontrol experiments on two image-based tasks: a simulated pendulum balancing\ntask and a real-world robotic manipulator reaching task. We demonstrate that\nour model produces significantly more accurate predictions and exhibits\nimproved control performance, compared to a model that assumes homoscedastic\nuncertainty only, in the presence of varying degrees of input degradation.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 21:04:33 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Limoyo", "Oliver", ""], ["Chan", "Bryan", ""], ["Mari\u0107", "Filip", ""], ["Wagstaff", "Brandon", ""], ["Mahmood", "Rupam", ""], ["Kelly", "Jonathan", ""]]}, {"id": "2008.08161", "submitter": "Junhua Yan", "authors": "Junhua Yan, Hasan Faik Alan and Jasleen Kaur", "title": "Fingerprinting Search Keywords over HTTPS at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The possibility of fingerprinting the search keywords issued by a user on\npopular web search engines is a significant threat to user privacy. This threat\nhas received surprisingly little attention in the network traffic analysis\nliterature. In this work, we consider the problem of keyword fingerprinting of\nHTTPS traffic -- we study the impact of several factors, including client\nplatform diversity, choice of search engine, feature sets as well as\nclassification frameworks. We conduct both closed-world and open-world\nevaluations using nearly 4 million search queries collected over a period of\nthree months. Our analysis reveals several insights into the threat of keyword\nfingerprinting in modern HTTPS traffic.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 21:24:52 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Yan", "Junhua", ""], ["Alan", "Hasan Faik", ""], ["Kaur", "Jasleen", ""]]}, {"id": "2008.08162", "submitter": "Georgios D. Barmparis", "authors": "G. D. Barmparis and G. P. Tsironis", "title": "Physics-informed machine learning for the COVID-19 pandemic: Adherence\n  to social distancing and short-term predictions for eight countries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.LG physics.bio-ph physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spread of COVID-19 during the initial phase of the first half of 2020 was\ncurtailed to a larger or lesser extent through measures of social distancing\nimposed by most countries. In this work, we link directly, through machine\nlearning techniques, infection data at a country level to a single number that\nsignifies social distancing effectiveness. We assume that the standard SIR\nmodel gives a reasonable description of the dynamics of spreading, and thus the\nsocial distancing aspect can be modeled through time-dependent infection rates\nthat are imposed externally. We use an exponential ansatz to analyze the SIR\nmodel, find an exact solution for the time-independent infection rate, and\nderive a simple first-order differential equation for the time-dependent\ninfection rate as a function of the infected population. Using infected number\ndata from the \"first wave\" of the infection from eight countries, and through\nphysics-informed machine learning, we extract the degree of linear dependence\nin social distancing that led to the specific infections. We find that in the\ntwo extremes are Greece, with the highest decay slope on one side, and the US\non the other with a practically flat \"decay\". The hierarchy of slopes is\ncompatible with the effectiveness of the pandemic containment in each country.\nFinally, we train our network with data after the end of the analyzed period,\nand we make week-long predictions for the current phase of the infection that\nappear to be very close to the actual infection values.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 21:26:30 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Barmparis", "G. D.", ""], ["Tsironis", "G. P.", ""]]}, {"id": "2008.08170", "submitter": "Feihu Huang", "authors": "Feihu Huang, Shangqian Gao, Jian Pei, Heng Huang", "title": "Accelerated Zeroth-Order and First-Order Momentum Methods from Mini to\n  Minimax Optimization", "comments": "66 pages. In this version, we change the Lyapunov functions for our\n  Acc-ZOMDA and Acc-MDA methods in the convergence analysis. Then our Acc-ZOMDA\n  method obtains a lower query complexity and our Acc-MDA method achieves a\n  lower gradient complexity", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper, we propose a class of accelerated zeroth-order and first-order\nmomentum methods for both nonconvex mini-optimization and minimax-optimization.\nSpecifically, we propose a new accelerated zeroth-order momentum (Acc-ZOM)\nmethod to solve stochastic mini-optimization problems. We prove that the\nAcc-ZOM method achieves a lower query complexity of\n$\\tilde{O}(d^{3/4}\\epsilon^{-3})$ for finding an $\\epsilon$-stationary point,\nwhich improves the best known result by a factor of $O(d^{1/4})$ where $d$\ndenotes the parameter dimension. In particular, the Acc-ZOM does not require\nlarge batches required in the existing zeroth-order stochastic algorithms. At\nthe same time, we propose an accelerated zeroth-order momentum descent ascent\n(Acc-ZOMDA) method for black-box minimax-optimization. We prove that the\nAcc-ZOMDA method reaches a lower query complexity of\n$\\tilde{O}((d_1+d_2)^{9/10}\\kappa_y^{3}\\epsilon^{-3})$ for finding an\n$\\epsilon$-stationary point, which improves the best known result by a factor\nof $O((d_1+d_2)^{1/10})$ where $d_1$ and $d_2$ denote dimensions of\noptimization parameters and $\\kappa_y$ is condition number. Moreover, we\npropose an accelerated first-order momentum descent ascent (Acc-MDA) method for\nsolving white-box minimax problems, and prove that it achieves a lower gradient\ncomplexity of $\\tilde{O}(\\kappa_y^{(3-\\nu/2)}\\epsilon^{-3})$ with $\\nu>0$ for\nfinding an $\\epsilon$-stationary point, which improves the best known result by\na factor of $O(\\kappa_y^{\\nu/2})$. Extensive experimental results on the\nblack-box adversarial attack to deep neural networks (DNNs) and poisoning\nattack demonstrate the efficiency of our algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 22:19:29 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 21:48:49 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 02:33:46 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Huang", "Feihu", ""], ["Gao", "Shangqian", ""], ["Pei", "Jian", ""], ["Huang", "Heng", ""]]}, {"id": "2008.08177", "submitter": "Aryan Deshwal", "authors": "Aryan Deshwal, Syrine Belakaria, Janardhan Rao Doppa", "title": "Scalable Combinatorial Bayesian Optimization with Tractable Statistical\n  models", "comments": "15 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of optimizing expensive blackbox functions over\ncombinatorial spaces (e.g., sets, sequences, trees, and graphs). BOCS (Baptista\nand Poloczek, 2018) is a state-of-the-art Bayesian optimization method for\ntractable statistical models, which performs semi-definite programming based\nacquisition function optimization (AFO) to select the next structure for\nevaluation. Unfortunately, BOCS scales poorly for large number of binary and/or\ncategorical variables. Based on recent advances in submodular relaxation (Ito\nand Fujimaki, 2016) for solving Binary Quadratic Programs, we study an approach\nreferred as Parametrized Submodular Relaxation (PSR) towards the goal of\nimproving the scalability and accuracy of solving AFO problems for BOCS model.\nPSR approach relies on two key ideas. First, reformulation of AFO problem as\nsubmodular relaxation with some unknown parameters, which can be solved\nefficiently using minimum graph cut algorithms. Second, construction of an\noptimization problem to estimate the unknown parameters with close\napproximation to the true objective. Experiments on diverse benchmark problems\nshow significant improvements with PSR for BOCS model. The source code is\navailable at https://github.com/aryandeshwal/Submodular_Relaxation_BOCS .\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 22:56:46 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Deshwal", "Aryan", ""], ["Belakaria", "Syrine", ""], ["Doppa", "Janardhan Rao", ""]]}, {"id": "2008.08186", "submitter": "Xiaoyan Han", "authors": "Vardan Papyan, X.Y. Han, David L. Donoho", "title": "Prevalence of Neural Collapse during the terminal phase of deep learning\n  training", "comments": null, "journal-ref": null, "doi": "10.1073/pnas.2015509117", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern practice for training classification deepnets involves a Terminal\nPhase of Training (TPT), which begins at the epoch where training error first\nvanishes; During TPT, the training error stays effectively zero while training\nloss is pushed towards zero. Direct measurements of TPT, for three prototypical\ndeepnet architectures and across seven canonical classification datasets,\nexpose a pervasive inductive bias we call Neural Collapse, involving four\ndeeply interconnected phenomena: (NC1) Cross-example within-class variability\nof last-layer training activations collapses to zero, as the individual\nactivations themselves collapse to their class-means; (NC2) The class-means\ncollapse to the vertices of a Simplex Equiangular Tight Frame (ETF); (NC3) Up\nto rescaling, the last-layer classifiers collapse to the class-means, or in\nother words to the Simplex ETF, i.e. to a self-dual configuration; (NC4) For a\ngiven activation, the classifier's decision collapses to simply choosing\nwhichever class has the closest train class-mean, i.e. the Nearest Class Center\n(NCC) decision rule. The symmetric and very simple geometry induced by the TPT\nconfers important benefits, including better generalization performance, better\nrobustness, and better interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 23:12:54 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 16:15:50 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Papyan", "Vardan", ""], ["Han", "X. Y.", ""], ["Donoho", "David L.", ""]]}, {"id": "2008.08191", "submitter": "James Brofos", "authors": "James A. Brofos and Roy R. Lederman", "title": "Non-Canonical Hamiltonian Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hamiltonian Monte Carlo is typically based on the assumption of an underlying\ncanonical symplectic structure. Numerical integrators designed for the\ncanonical structure are incompatible with motion generated by non-canonical\ndynamics. These non-canonical dynamics, motivated by examples in physics and\nsymplectic geometry, correspond to techniques such as preconditioning which are\nroutinely used to improve algorithmic performance. Indeed, recently, a special\ncase of non-canonical structure, magnetic Hamiltonian Monte Carlo, was\ndemonstrated to provide advantageous sampling properties. We present a\nframework for Hamiltonian Monte Carlo using non-canonical symplectic\nstructures. Our experimental results demonstrate sampling advantages associated\nto Hamiltonian Monte Carlo with non-canonical structure. To summarize our\ncontributions: (i) we develop non-canonical HMC from foundations in symplectic\ngeomtry; (ii) we construct an HMC procedure using implicit integration that\nsatisfies the detailed balance; (iii) we propose to accelerate the sampling\nusing an {\\em approximate} explicit methodology; (iv) we study two novel,\nrandomly-generated non-canonical structures: magnetic momentum and the coupled\nmagnet structure, with implicit and explicit integration.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 23:25:20 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Brofos", "James A.", ""], ["Lederman", "Roy R.", ""]]}, {"id": "2008.08198", "submitter": "Zhengchun Liu", "authors": "Zhengchun Liu, Hemant Sharma, Jun-Sang Park, Peter Kenesei, Antonino\n  Miceli, Jonathan Almer, Rajkumar Kettimuthu, Ian Foster", "title": "BraggNN: Fast X-ray Bragg Peak Analysis Using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  X-ray diffraction based microscopy techniques such as High Energy Diffraction\nMicroscopy rely on knowledge of the position of diffraction peaks with high\nprecision. These positions are typically computed by fitting the observed\nintensities in area detector data to a theoretical peak shape such as\npseudo-Voigt. As experiments become more complex and detector technologies\nevolve, the computational cost of such peak detection and shape fitting becomes\nthe biggest hurdle to the rapid analysis required for real-time feedback during\nin-situ experiments. To this end, we propose BraggNN, a deep learning-based\nmethod that can determine peak positions much more rapidly than conventional\npseudo-Voigt peak fitting. When applied to a test dataset, BraggNN gives errors\nof less than 0.29 and 0.57 pixels, relative to the conventional method, for 75%\nand 95% of the peaks, respectively. When applied to a real experimental\ndataset, a 3D reconstruction that used peak positions computed by BraggNN\nyields 15% better results on average as compared to a reconstruction obtained\nusing peak positions determined using conventional 2D pseudo-Voigt fitting.\nRecent advances in deep learning method implementations and special-purpose\nmodel inference accelerators allow BraggNN to deliver enormous performance\nimprovements relative to the conventional method, running, for example, more\nthan 200 times faster than a conventional method on a consumer-class GPU card\nwith out-of-the-box software.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 23:57:07 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 20:10:12 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Liu", "Zhengchun", ""], ["Sharma", "Hemant", ""], ["Park", "Jun-Sang", ""], ["Kenesei", "Peter", ""], ["Miceli", "Antonino", ""], ["Almer", "Jonathan", ""], ["Kettimuthu", "Rajkumar", ""], ["Foster", "Ian", ""]]}, {"id": "2008.08221", "submitter": "Zhaoyi Xu", "authors": "Zhaoyi Xu, Joseph Homer Saleh", "title": "Machine Learning for Reliability Engineering and Safety Applications:\n  Review of Current Status and Future Opportunities", "comments": "50 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) pervades an increasing number of academic disciplines\nand industries. Its impact is profound, and several fields have been\nfundamentally altered by it, autonomy and computer vision for example;\nreliability engineering and safety will undoubtedly follow suit. There is\nalready a large but fragmented literature on ML for reliability and safety\napplications, and it can be overwhelming to navigate and integrate into a\ncoherent whole. In this work, we facilitate this task by providing a synthesis\nof, and a roadmap to this ever-expanding analytical landscape and highlighting\nits major landmarks and pathways. We first provide an overview of the different\nML categories and sub-categories or tasks, and we note several of the\ncorresponding models and algorithms. We then look back and review the use of ML\nin reliability and safety applications. We examine several publications in each\ncategory/sub-category, and we include a short discussion on the use of Deep\nLearning to highlight its growing popularity and distinctive advantages.\nFinally, we look ahead and outline several promising future opportunities for\nleveraging ML in service of advancing reliability and safety considerations.\nOverall, we argue that ML is capable of providing novel insights and\nopportunities to solve important challenges in reliability and safety\napplications. It is also capable of teasing out more accurate insights from\naccident datasets than with traditional analysis tools, and this in turn can\nlead to better informed decision-making and more effective accident prevention.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 02:08:56 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Xu", "Zhaoyi", ""], ["Saleh", "Joseph Homer", ""]]}, {"id": "2008.08226", "submitter": "Robert Strauss", "authors": "Robert Strauss", "title": "Augmenting Neural Differential Equations to Model Unknown Dynamical\n  Systems with Incomplete State Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Ordinary Differential Equations replace the right-hand side of a\nconventional ODE with a neural net, which by virtue of the universal\napproximation theorem, can be trained to the representation of any function.\nWhen we do not know the function itself, but have state trajectories (time\nevolution) of the ODE system we can still train the neural net to learn the\nrepresentation of the underlying but unknown ODE. However if the state of the\nsystem is incompletely known then the right-hand side of the ODE cannot be\ncalculated. The derivatives to propagate the system are unavailable. We show\nthat a specially augmented Neural ODE can learn the system when given\nincomplete state information. As a worked example we apply neural ODEs to the\nLotka-Voltera problem of 3 species, rabbits, wolves, and bears. We show that\neven when the data for the bear time series is removed the remaining time\nseries of the rabbits and wolves is sufficient to learn the dynamical system\ndespite the missing the incomplete state information. This is surprising since\na conventional ODE system cannot output the correct derivatives without the\nfull state as the input. We implement augmented neural ODEs and differential\nequation solvers in the julia programming language.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 02:21:13 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 00:11:16 GMT"}, {"version": "v3", "created": "Sat, 22 Aug 2020 02:59:26 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Strauss", "Robert", ""]]}, {"id": "2008.08246", "submitter": "Jialun Pei", "authors": "Jialun Pei, He Tang, Tianyang Cheng, Chuanbo Chen", "title": "Salient Instance Segmentation with Region and Box-level Annotations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Salient instance segmentation is a new challenging task that received\nwidespread attention in the saliency detection area. The new generation of\nsaliency detection provides a strong theoretical and technical basis for video\nsurveillance. Due to the limited scale of the existing dataset and the high\nmask annotations cost, plenty of supervision source is urgently needed to train\na well-performing salient instance model. In this paper, we aim to train a\nnovel salient instance segmentation framework by an inexact supervision without\nresorting to laborious labeling. To this end, we present a cyclic global\ncontext salient instance segmentation network (CGCNet), which is supervised by\nthe combination of salient regions and bounding boxes from the ready-made\nsalient object detection datasets. To locate salient instance more accurately,\na global feature refining layer is proposed that dilates the features of the\nregion of interest (ROI) to the global context in a scene. Meanwhile, a\nlabeling updating scheme is embedded in the proposed framework to update the\ncoarse-grained labels for next iteration. Experiment results demonstrate that\nthe proposed end-to-end framework trained by inexact supervised annotations can\nbe competitive to the existing fully supervised salient instance segmentation\nmethods. Without bells and whistles, our proposed method achieves a mask AP of\n58.3% in the test set of Dataset1K that outperforms the mainstream\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 03:43:45 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 06:41:52 GMT"}, {"version": "v3", "created": "Wed, 28 Apr 2021 07:38:49 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Pei", "Jialun", ""], ["Tang", "He", ""], ["Cheng", "Tianyang", ""], ["Chen", "Chuanbo", ""]]}, {"id": "2008.08248", "submitter": "Qiaoying Huang", "authors": "Qiaoying Huang, Dong Yang, Yikun Xian, Pengxiang Wu, Jingru Yi, Hui\n  Qu, Dimitris Metaxas", "title": "Enhanced MRI Reconstruction Network using Neural Architecture Search", "comments": "10 pages. Code will be released soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accurate reconstruction of under-sampled magnetic resonance imaging (MRI)\ndata using modern deep learning technology, requires significant effort to\ndesign the necessary complex neural network architectures. The cascaded network\narchitecture for MRI reconstruction has been widely used, while it suffers from\nthe \"vanishing gradient\" problem when the network becomes deep. In addition,\nhomogeneous architecture degrades the representation capacity of the network.\nIn this work, we present an enhanced MRI reconstruction network using a\nresidual in residual basic block. For each cell in the basic block, we use the\ndifferentiable neural architecture search (NAS) technique to automatically\nchoose the optimal operation among eight variants of the dense block. This new\nheterogeneous network is evaluated on two publicly available datasets and\noutperforms all current state-of-the-art methods, which demonstrates the\neffectiveness of our proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 03:44:31 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Huang", "Qiaoying", ""], ["Yang", "Dong", ""], ["Xian", "Yikun", ""], ["Wu", "Pengxiang", ""], ["Yi", "Jingru", ""], ["Qu", "Hui", ""], ["Metaxas", "Dimitris", ""]]}, {"id": "2008.08272", "submitter": "Tung D. Le", "authors": "Tian Jin, Gheorghe-Teodor Bercea, Tung D. Le, Tong Chen, Gong Su,\n  Haruki Imai, Yasushi Negishi, Anh Leu, Kevin O'Brien, Kiyokuni Kawachiya, and\n  Alexandre E. Eichenberger", "title": "Compiling ONNX Neural Network Models Using MLIR", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network models are becoming increasingly popular and have been\nused in various tasks such as computer vision, speech recognition, and natural\nlanguage processing. Machine learning models are commonly trained in a\nresource-rich environment and then deployed in a distinct environment such as\nhigh availability machines or edge devices. To assist the portability of\nmodels, the open-source community has proposed the Open Neural Network Exchange\n(ONNX) standard. In this paper, we present a high-level, preliminary report on\nour onnx-mlir compiler, which generates code for the inference of deep neural\nnetwork models described in the ONNX format. Onnx-mlir is an open-source\ncompiler implemented using the Multi-Level Intermediate Representation (MLIR)\ninfrastructure recently integrated in the LLVM project. Onnx-mlir relies on the\nMLIR concept of dialects to implement its functionality. We propose here two\nnew dialects: (1) an ONNX specific dialect that encodes the ONNX standard\nsemantics, and (2) a loop-based dialect to provide for a common lowering point\nfor all ONNX dialect operations. Each intermediate representation facilitates\nits own characteristic set of graph-level and loop-based optimizations\nrespectively. We illustrate our approach by following several models through\nthe proposed representations and we include some early optimization work and\nperformance results.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 05:28:08 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 01:15:28 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Jin", "Tian", ""], ["Bercea", "Gheorghe-Teodor", ""], ["Le", "Tung D.", ""], ["Chen", "Tong", ""], ["Su", "Gong", ""], ["Imai", "Haruki", ""], ["Negishi", "Yasushi", ""], ["Leu", "Anh", ""], ["O'Brien", "Kevin", ""], ["Kawachiya", "Kiyokuni", ""], ["Eichenberger", "Alexandre E.", ""]]}, {"id": "2008.08273", "submitter": "Sung Min Cho", "authors": "Sung Min Cho, Eunhyeok Park, Sungjoo Yoo", "title": "MEANTIME: Mixture of Attention Mechanisms with Multi-temporal Embeddings\n  for Sequential Recommendation", "comments": "Accepted at RecSys 2020", "journal-ref": null, "doi": "10.1145/3383313.3412216", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, self-attention based models have achieved state-of-the-art\nperformance in sequential recommendation task. Following the custom from\nlanguage processing, most of these models rely on a simple positional embedding\nto exploit the sequential nature of the user's history. However, there are some\nlimitations regarding the current approaches. First, sequential recommendation\nis different from language processing in that timestamp information is\navailable. Previous models have not made good use of it to extract additional\ncontextual information. Second, using a simple embedding scheme can lead to\ninformation bottleneck since the same embedding has to represent all possible\ncontextual biases. Third, since previous models use the same positional\nembedding in each attention head, they can wastefully learn overlapping\npatterns. To address these limitations, we propose MEANTIME (MixturE of\nAtteNTIon mechanisms with Multi-temporal Embeddings) which employs multiple\ntypes of temporal embeddings designed to capture various patterns from the\nuser's behavior sequence, and an attention structure that fully leverages such\ndiversity. Experiments on real-world data show that our proposed method\noutperforms current state-of-the-art sequential recommendation methods, and we\nprovide an extensive ablation study to analyze how the model gains from the\ndiverse positional information.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 05:32:14 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 07:18:14 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Cho", "Sung Min", ""], ["Park", "Eunhyeok", ""], ["Yoo", "Sungjoo", ""]]}, {"id": "2008.08284", "submitter": "Qian Xu", "authors": "Xu Qian, Victor Li, Crews Darren", "title": "Channel-wise Hessian Aware trace-Weighted Quantization of Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Second-order information has proven to be very effective in determining the\nredundancy of neural network weights and activations. Recent paper proposes to\nuse Hessian traces of weights and activations for mixed-precision quantization\nand achieves state-of-the-art results. However, prior works only focus on\nselecting bits for each layer while the redundancy of different channels within\na layer also differ a lot. This is mainly because the complexity of determining\nbits for each channel is too high for original methods. Here, we introduce\nChannel-wise Hessian Aware trace-Weighted Quantization (CW-HAWQ). CW-HAWQ uses\nHessian trace to determine the relative sensitivity order of different channels\nof activations and weights. What's more, CW-HAWQ proposes to use deep\nReinforcement learning (DRL) Deep Deterministic Policy Gradient (DDPG)-based\nagent to find the optimal ratios of different quantization bits and assign bits\nto channels according to the Hessian trace order. The number of states in\nCW-HAWQ is much smaller compared with traditional AutoML based mix-precision\nmethods since we only need to search ratios for the quantization bits. Compare\nCW-HAWQ with state-of-the-art shows that we can achieve better results for\nmultiple networks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 06:34:56 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Qian", "Xu", ""], ["Li", "Victor", ""], ["Darren", "Crews", ""]]}, {"id": "2008.08289", "submitter": "Afshin Abdi", "authors": "Afshin Abdi, Saeed Rashidi, Faramarz Fekri, Tushar Krishna", "title": "Restructuring, Pruning, and Adjustment of Deep Models for Parallel\n  Distributed Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using multiple nodes and parallel computing algorithms has become a principal\ntool to improve training and execution times of deep neural networks as well as\neffective collective intelligence in sensor networks. In this paper, we\nconsider the parallel implementation of an already-trained deep model on\nmultiple processing nodes (a.k.a. workers) where the deep model is divided into\nseveral parallel sub-models, each of which is executed by a worker. Since\nlatency due to synchronization and data transfer among workers negatively\nimpacts the performance of the parallel implementation, it is desirable to have\nminimum interdependency among parallel sub-models. To achieve this goal, we\npropose to rearrange the neurons in the neural network and partition them\n(without changing the general topology of the neural network), such that the\ninterdependency among sub-models is minimized under the computations and\ncommunications constraints of the workers. We propose RePurpose, a layer-wise\nmodel restructuring and pruning technique that guarantees the performance of\nthe overall parallelized model. To efficiently apply RePurpose, we propose an\napproach based on $\\ell_0$ optimization and the Munkres assignment algorithm.\nWe show that, compared to the existing methods, RePurpose significantly\nimproves the efficiency of the distributed inference via parallel\nimplementation, both in terms of communication and computational complexity.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 06:44:41 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Abdi", "Afshin", ""], ["Rashidi", "Saeed", ""], ["Fekri", "Faramarz", ""], ["Krishna", "Tushar", ""]]}, {"id": "2008.08290", "submitter": "Jiuniu Wang", "authors": "Wenjia Xu, Yongqin Xian, Jiuniu Wang, Bernt Schiele, Zeynep Akata", "title": "Attribute Prototype Network for Zero-Shot Learning", "comments": "NeurIPS 2020. The code is publicly available at\n  https://wenjiaxu.github.io/APN-ZSL/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From the beginning of zero-shot learning research, visual attributes have\nbeen shown to play an important role. In order to better transfer\nattribute-based knowledge from known to unknown classes, we argue that an image\nrepresentation with integrated attribute localization ability would be\nbeneficial for zero-shot learning. To this end, we propose a novel zero-shot\nrepresentation learning framework that jointly learns discriminative global and\nlocal features using only class-level attributes. While a visual-semantic\nembedding layer learns global features, local features are learned through an\nattribute prototype network that simultaneously regresses and decorrelates\nattributes from intermediate features. We show that our locality augmented\nimage representations achieve a new state-of-the-art on three zero-shot\nlearning benchmarks. As an additional benefit, our model points to the visual\nevidence of the attributes in an image, e.g. for the CUB dataset, confirming\nthe improved attribute localization ability of our image representation.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 06:46:35 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 09:46:00 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2021 02:26:42 GMT"}, {"version": "v4", "created": "Thu, 6 May 2021 09:13:08 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Xu", "Wenjia", ""], ["Xian", "Yongqin", ""], ["Wang", "Jiuniu", ""], ["Schiele", "Bernt", ""], ["Akata", "Zeynep", ""]]}, {"id": "2008.08316", "submitter": "Margarita Osadchy", "authors": "Ben Mussay, Daniel Feldman, Samson Zhou, Vladimir Braverman, Margarita\n  Osadchy", "title": "Data-Independent Structured Pruning of Neural Networks via Coresets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model compression is crucial for deployment of neural networks on devices\nwith limited computational and memory resources. Many different methods show\ncomparable accuracy of the compressed model and similar compression rates.\nHowever, the majority of the compression methods are based on heuristics and\noffer no worst-case guarantees on the trade-off between the compression rate\nand the approximation error for an arbitrarily new sample. We propose the first\nefficient structured pruning algorithm with a provable trade-off between its\ncompression rate and the approximation error for any future test sample. Our\nmethod is based on the coreset framework and it approximates the output of a\nlayer of neurons/filters by a coreset of neurons/filters in the previous layer\nand discards the rest. We apply this framework in a layer-by-layer fashion from\nthe bottom to the top. Unlike previous works, our coreset is data independent,\nmeaning that it provably guarantees the accuracy of the function for any input\n$x\\in \\mathbb{R}^d$, including an adversarial one.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 08:03:09 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Mussay", "Ben", ""], ["Feldman", "Daniel", ""], ["Zhou", "Samson", ""], ["Braverman", "Vladimir", ""], ["Osadchy", "Margarita", ""]]}, {"id": "2008.08330", "submitter": "Junjie Tan", "authors": "Junjie Tan, Ying-Chang Liang, Nguyen Cong Luong, Dusit Niyato", "title": "Toward Smart Security Enhancement of Federated Learning Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As traditional centralized learning networks (CLNs) are facing increasing\nchallenges in terms of privacy preservation, communication overheads, and\nscalability, federated learning networks (FLNs) have been proposed as a\npromising alternative paradigm to support the training of machine learning (ML)\nmodels. In contrast to the centralized data storage and processing in CLNs,\nFLNs exploit a number of edge devices (EDs) to store data and perform training\ndistributively. In this way, the EDs in FLNs can keep training data locally,\nwhich preserves privacy and reduces communication overheads. However, since the\nmodel training within FLNs relies on the contribution of all EDs, the training\nprocess can be disrupted if some of the EDs upload incorrect or falsified\ntraining results, i.e., poisoning attacks. In this paper, we review the\nvulnerabilities of FLNs, and particularly give an overview of poisoning attacks\nand mainstream countermeasures. Nevertheless, the existing countermeasures can\nonly provide passive protection and fail to consider the training fees paid for\nthe contributions of the EDs, resulting in a unnecessarily high training cost.\nHence, we present a smart security enhancement framework for FLNs. In\nparticular, a verify-before-aggregate (VBA) procedure is developed to identify\nand remove the non-benign training results from the EDs. Afterward, deep\nreinforcement learning (DRL) is applied to learn the behaving patterns of the\nEDs and to actively select the EDs that can provide benign training results and\ncharge low training fees. Simulation results reveal that the proposed framework\ncan protect FLNs effectively and efficiently.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 08:46:39 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Tan", "Junjie", ""], ["Liang", "Ying-Chang", ""], ["Luong", "Nguyen Cong", ""], ["Niyato", "Dusit", ""]]}, {"id": "2008.08342", "submitter": "Xiangming Meng", "authors": "Xiangming Meng and Tomoyuki Obuchi and Yoshiyuki Kabashima", "title": "Structure Learning in Inverse Ising Problems Using $\\ell_2$-Regularized\n  Linear Estimator", "comments": "35 pages, 8 figures", "journal-ref": null, "doi": "10.1088/1742-5468/abfa10", "report-no": null, "categories": "cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inference performance of the pseudolikelihood method is discussed in the\nframework of the inverse Ising problem when the $\\ell_2$-regularized (ridge)\nlinear regression is adopted. This setup is introduced for theoretically\ninvestigating the situation where the data generation model is different from\nthe inference one, namely the model mismatch situation. In the teacher-student\nscenario under the assumption that the teacher couplings are sparse, the\nanalysis is conducted using the replica and cavity methods, with a special\nfocus on whether the presence/absence of teacher couplings is correctly\ninferred or not. The result indicates that despite the model mismatch, one can\nperfectly identify the network structure using naive linear regression without\nregularization when the number of spins $N$ is smaller than the dataset size\n$M$, in the thermodynamic limit $N\\to \\infty$. Further, to access the\nunderdetermined region $M < N$, we examine the effect of the $\\ell_2$\nregularization, and find that biases appear in all the coupling estimates,\npreventing the perfect identification of the network structure. We, however,\nfind that the biases are shown to decay exponentially fast as the distance from\nthe center spin chosen in the pseudolikelihood method grows. Based on this\nfinding, we propose a two-stage estimator: In the first stage, the ridge\nregression is used and the estimates are pruned by a relatively small\nthreshold; in the second stage the naive linear regression is conducted only on\nthe remaining couplings, and the resultant estimates are again pruned by\nanother relatively large threshold. This estimator with the appropriate\nregularization coefficient and thresholds is shown to achieve the perfect\nidentification of the network structure even in $0<M/N<1$. Results of extensive\nnumerical experiments support these findings.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 09:11:33 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 02:29:14 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Meng", "Xiangming", ""], ["Obuchi", "Tomoyuki", ""], ["Kabashima", "Yoshiyuki", ""]]}, {"id": "2008.08345", "submitter": "Dominik Engel", "authors": "Dominik Engel, Timo Ropinski", "title": "Deep Volumetric Ambient Occlusion", "comments": "IEEE VIS SciVis 2020", "journal-ref": null, "doi": "10.1109/TVCG.2020.3030344", "report-no": null, "categories": "cs.CV cs.GR cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel deep learning based technique for volumetric ambient\nocclusion in the context of direct volume rendering. Our proposed Deep\nVolumetric Ambient Occlusion (DVAO) approach can predict per-voxel ambient\nocclusion in volumetric data sets, while considering global information\nprovided through the transfer function. The proposed neural network only needs\nto be executed upon change of this global information, and thus supports\nreal-time volume interaction. Accordingly, we demonstrate DVAOs ability to\npredict volumetric ambient occlusion, such that it can be applied interactively\nwithin direct volume rendering. To achieve the best possible results, we\npropose and analyze a variety of transfer function representations and\ninjection strategies for deep neural networks. Based on the obtained results we\nalso give recommendations applicable in similar volume learning scenarios.\nLastly, we show that DVAO generalizes to a variety of modalities, despite being\ntrained on computed tomography data only.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 09:19:08 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 06:13:14 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Engel", "Dominik", ""], ["Ropinski", "Timo", ""]]}, {"id": "2008.08352", "submitter": "Demetris Marnerides", "authors": "Lvyin Duan, Demetris Marnerides, Alan Chalmers, Zhichun Lei and Kurt\n  Debattista", "title": "Deep Controllable Backlight Dimming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dual-panel displays require local dimming algorithms in order to reproduce\ncontent with high fidelity and high dynamic range. In this work, a novel deep\nlearning based local dimming method is proposed for rendering HDR images on\ndual-panel HDR displays. The method uses a Convolutional Neural Network to\npredict backlight values, using as input the HDR image that is to be displayed.\nThe model is designed and trained via a controllable power parameter that\nallows a user to trade off between power and quality. The proposed method is\nevaluated against six other methods on a test set of 105 HDR images, using a\nvariety of quantitative quality metrics. Results demonstrate improved display\nquality and better power consumption when using the proposed method compared to\nthe best alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 09:42:42 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Duan", "Lvyin", ""], ["Marnerides", "Demetris", ""], ["Chalmers", "Alan", ""], ["Lei", "Zhichun", ""], ["Debattista", "Kurt", ""]]}, {"id": "2008.08353", "submitter": "Furui Cheng", "authors": "Furui Cheng, Yao Ming, Huamin Qu", "title": "DECE: Decision Explorer with Counterfactual Explanations for Machine\n  Learning Models", "comments": "10 pages, 7 figures. The paper will be published on IEEE Transactions\n  on Visualization and Computer Graphics (TVCG)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With machine learning models being increasingly applied to various\ndecision-making scenarios, people have spent growing efforts to make machine\nlearning models more transparent and explainable. Among various explanation\ntechniques, counterfactual explanations have the advantages of being\nhuman-friendly and actionable -- a counterfactual explanation tells the user\nhow to gain the desired prediction with minimal changes to the input. Besides,\ncounterfactual explanations can also serve as efficient probes to the models'\ndecisions. In this work, we exploit the potential of counterfactual\nexplanations to understand and explore the behavior of machine learning models.\nWe design DECE, an interactive visualization system that helps understand and\nexplore a model's decisions on individual instances and data subsets,\nsupporting users ranging from decision-subjects to model developers. DECE\nsupports exploratory analysis of model decisions by combining the strengths of\ncounterfactual explanations at instance- and subgroup-levels. We also introduce\na set of interactions that enable users to customize the generation of\ncounterfactual explanations to find more actionable ones that can suit their\nneeds. Through three use cases and an expert interview, we demonstrate the\neffectiveness of DECE in supporting decision exploration tasks and instance\nexplanations.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 09:44:47 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Cheng", "Furui", ""], ["Ming", "Yao", ""], ["Qu", "Huamin", ""]]}, {"id": "2008.08384", "submitter": "Alfred Laugros", "authors": "Alfred Laugros, Alice Caplier, Matthieu Ospici", "title": "Addressing Neural Network Robustness with Mixup and Targeted Labeling\n  Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their performance, Artificial Neural Networks are not reliable enough\nfor most of industrial applications. They are sensitive to noises, rotations,\nblurs and adversarial examples. There is a need to build defenses that protect\nagainst a wide range of perturbations, covering the most traditional common\ncorruptions and adversarial examples. We propose a new data augmentation\nstrategy called M-TLAT and designed to address robustness in a broad sense. Our\napproach combines the Mixup augmentation and a new adversarial training\nalgorithm called Targeted Labeling Adversarial Training (TLAT). The idea of\nTLAT is to interpolate the target labels of adversarial examples with the\nground-truth labels. We show that M-TLAT can increase the robustness of image\nclassifiers towards nineteen common corruptions and five adversarial attacks,\nwithout reducing the accuracy on clean samples.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 11:34:11 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Laugros", "Alfred", ""], ["Caplier", "Alice", ""], ["Ospici", "Matthieu", ""]]}, {"id": "2008.08386", "submitter": "Steffen Goebbels", "authors": "Steffen Goebbels", "title": "ReLU activated Multi-Layer Neural Networks trained with Mixed Integer\n  Linear Programs", "comments": "published paper. Technical Report 2021-01, Niederrhein University of\n  Applied Sciences, Faculty of Electrical Engineering and Computer Science,\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, it is demonstrated through a case study that multilayer\nfeedforward neural networks activated by ReLU functions can in principle be\ntrained iteratively with Mixed Integer Linear Programs (MILPs) as follows.\nWeights are determined with batch learning. Multiple iterations are used per\nbatch of training data. In each iteration, the algorithm starts at the output\nlayer and propagates information back to the first hidden layer to adjust the\nweights using MILPs or Linear Programs. For each layer, the goal is to minimize\nthe difference between its output and the corresponding target output. The\ntarget output of the last (output) layer is equal to the ground truth. The\ntarget output of a previous layer is defined as the adjusted input of the\nfollowing layer. For a given layer, weights are computed by solving a MILP.\nThen, except for the first hidden layer, the input values are also modified\nwith a MILP to better match the layer outputs to their corresponding target\noutputs. The method was tested and compared with Tensorflow/Keras (Adam\noptimizer) using two simple networks on the MNIST dataset containing\nhandwritten digits. Accuracies of the same magnitude as with Tensorflow/Keras\nwere achieved.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 11:42:34 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 18:19:29 GMT"}, {"version": "v3", "created": "Fri, 9 Apr 2021 07:19:27 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Goebbels", "Steffen", ""]]}, {"id": "2008.08397", "submitter": "Nicolas Rivera", "authors": "Tamara Fernandez, Nicolas Rivera, Wenkai Xu and Arthur Gretton", "title": "Kernelized Stein Discrepancy Tests of Goodness-of-fit for Time-to-Event\n  Data", "comments": "Proceedings of the International Conference on Machine Learning, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Survival Analysis and Reliability Theory are concerned with the analysis of\ntime-to-event data, in which observations correspond to waiting times until an\nevent of interest such as death from a particular disease or failure of a\ncomponent in a mechanical system. This type of data is unique due to the\npresence of censoring, a type of missing data that occurs when we do not\nobserve the actual time of the event of interest but, instead, we have access\nto an approximation for it given by random interval in which the observation is\nknown to belong. Most traditional methods are not designed to deal with\ncensoring, and thus we need to adapt them to censored time-to-event data. In\nthis paper, we focus on non-parametric goodness-of-fit testing procedures based\non combining the Stein's method and kernelized discrepancies. While for\nuncensored data, there is a natural way of implementing a kernelized Stein\ndiscrepancy test, for censored data there are several options, each of them\nwith different advantages and disadvantages. In this paper, we propose a\ncollection of kernelized Stein discrepancy tests for time-to-event data, and we\nstudy each of them theoretically and empirically; our experimental results show\nthat our proposed methods perform better than existing tests, including\nprevious tests based on a kernelized maximum mean discrepancy.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 12:27:43 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 18:13:45 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Fernandez", "Tamara", ""], ["Rivera", "Nicolas", ""], ["Xu", "Wenkai", ""], ["Gretton", "Arthur", ""]]}, {"id": "2008.08400", "submitter": "Alexander Immer", "authors": "Alexander Immer, Maciej Korzepa, Matthias Bauer", "title": "Improving predictions of Bayesian neural nets via local linearization", "comments": "AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalized Gauss-Newton (GGN) approximation is often used to make\npractical Bayesian deep learning approaches scalable by replacing a second\norder derivative with a product of first order derivatives. In this paper we\nargue that the GGN approximation should be understood as a local linearization\nof the underlying Bayesian neural network (BNN), which turns the BNN into a\ngeneralized linear model (GLM). Because we use this linearized model for\nposterior inference, we should also predict using this modified model instead\nof the original one. We refer to this modified predictive as \"GLM predictive\"\nand show that it effectively resolves common underfitting problems of the\nLaplace approximation. It extends previous results in this vein to general\nlikelihoods and has an equivalent Gaussian process formulation, which enables\nalternative inference schemes for BNNs in function space. We demonstrate the\neffectiveness of our approach on several standard classification datasets as\nwell as on out-of-distribution detection. We provide an implementation at\nhttps://github.com/AlexImmer/BNN-predictions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 12:35:55 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 14:45:01 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 17:59:47 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Immer", "Alexander", ""], ["Korzepa", "Maciej", ""], ["Bauer", "Matthias", ""]]}, {"id": "2008.08405", "submitter": "Krishna Subramani", "authors": "Krishna Subramani, Preeti Rao", "title": "HpRNet : Incorporating Residual Noise Modeling for Violin in a\n  Variational Parametric Synthesizer", "comments": "https://github.com/SubramaniKrishna/HpRNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Models for Audio Synthesis have been gaining momentum in the last\nfew years. More recently, parametric representations of the audio signal have\nbeen incorporated to facilitate better musical control of the synthesized\noutput. In this work, we investigate a parametric model for violin tones, in\nparticular the generative modeling of the residual bow noise to make for more\nnatural tone quality. To aid in our analysis, we introduce a dataset of\nCarnatic Violin Recordings where bow noise is an integral part of the playing\nstyle of higher pitched notes in specific gestural contexts. We obtain insights\nabout each of the harmonic and residual components of the signal, as well as\ntheir interdependence, via observations on the latent space derived in the\ncourse of variational encoding of the spectral envelopes of the sustained\nsounds.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 12:48:32 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Subramani", "Krishna", ""], ["Rao", "Preeti", ""]]}, {"id": "2008.08416", "submitter": "JooYeol Yun", "authors": "JooYeol Yun, JungWoo Oh, and IlDong Yun", "title": "Gradually Applying Weakly Supervised and Active Learning for Mass\n  Detection in Breast Ultrasound Images", "comments": null, "journal-ref": "Appl. Sci. 2020, 10(13), 4519", "doi": "10.3390/app10134519", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for effectively utilizing weakly annotated image data in\nan object detection tasks of breast ultrasound images. Given the problem\nsetting where a small, strongly annotated dataset and a large, weakly annotated\ndataset with no bounding box information are available, training an object\ndetection model becomes a non-trivial problem. We suggest a controlled weight\nfor handling the effect of weakly annotated images in a two stage object\ndetection model. We~also present a subsequent active learning scheme for safely\nassigning weakly annotated images a strong annotation using the trained model.\nExperimental results showed a 24\\% point increase in correct localization\n(CorLoc) measure, which is the ratio of correctly localized and classified\nimages, by assigning the properly controlled weight. Performing active learning\nafter a model is trained showed an additional increase in CorLoc. We tested the\nproposed method on the Stanford Dog datasets to assure that it can be applied\nto general cases, where strong annotations are insufficient to obtain\nresembling results. The presented method showed that higher performance is\nachievable with lesser annotation effort.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 13:09:00 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Yun", "JooYeol", ""], ["Oh", "JungWoo", ""], ["Yun", "IlDong", ""]]}, {"id": "2008.08424", "submitter": "Harkirat Behl", "authors": "Harkirat Singh Behl, At{\\i}l{\\i}m G\\\"une\\c{s} Baydin, Ran Gal, Philip\n  H.S. Torr, Vibhav Vineet", "title": "AutoSimulate: (Quickly) Learning Synthetic Data Generation", "comments": "ECCV 2020", "journal-ref": "European Conference on Computer Vision (ECCV) 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation is increasingly being used for generating large labelled datasets\nin many machine learning problems. Recent methods have focused on adjusting\nsimulator parameters with the goal of maximising accuracy on a validation task,\nusually relying on REINFORCE-like gradient estimators. However these approaches\nare very expensive as they treat the entire data generation, model training,\nand validation pipeline as a black-box and require multiple costly objective\nevaluations at each iteration. We propose an efficient alternative for optimal\nsynthetic data generation, based on a novel differentiable approximation of the\nobjective. This allows us to optimize the simulator, which may be\nnon-differentiable, requiring only one objective evaluation at each iteration\nwith a little overhead. We demonstrate on a state-of-the-art photorealistic\nrenderer that the proposed method finds the optimal data distribution faster\n(up to $50\\times$), with significantly reduced training data generation (up to\n$30\\times$) and better accuracy ($+8.7\\%$) on real-world test datasets than\nprevious methods.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 11:36:11 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Behl", "Harkirat Singh", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Gal", "Ran", ""], ["Torr", "Philip H. S.", ""], ["Vineet", "Vibhav", ""]]}, {"id": "2008.08427", "submitter": "Sho Sonoda Dr", "authors": "Sho Sonoda, Ming Li, Feilong Cao, Changqin Huang, Yu Guang Wang", "title": "On the Approximation Lower Bound for Neural Nets with Random Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A random net is a shallow neural network where the hidden layer is frozen\nwith random assignment and the output layer is trained by convex optimization.\nUsing random weights for a hidden layer is an effective method to avoid the\ninevitable non-convexity in standard gradient descent learning. It has recently\nbeen adopted in the study of deep learning theory. Here, we investigate the\nexpressive power of random nets. We show that, despite the well-known fact that\na shallow neural network is a universal approximator, a random net cannot\nachieve zero approximation error even for smooth functions. In particular, we\nprove that for a class of smooth functions, if the proposal distribution is\ncompactly supported, then a lower bound is positive. Based on the ridgelet\nanalysis and harmonic analysis for neural networks, the proof uses the\nPlancherel theorem and an estimate for the truncated tail of the parameter\ndistribution. We corroborate our theoretical results with various simulation\nstudies, and generally two main take-home messages are offered: (i) Not any\ndistribution for selecting random weights is feasible to build a universal\napproximator; (ii) A suitable assignment of random weights exists but to some\ndegree is associated with the complexity of the target function.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 13:26:12 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Sonoda", "Sho", ""], ["Li", "Ming", ""], ["Cao", "Feilong", ""], ["Huang", "Changqin", ""], ["Wang", "Yu Guang", ""]]}, {"id": "2008.08432", "submitter": "Gael Kamdem De Teyou Dr", "authors": "Gael Kamdem De Teyou, Yuliya Tarabalka, Isabelle Manighetti, Rafael\n  Almar, Sebastien Tripod", "title": "Deep Neural Networks for automatic extraction of features in time series\n  satellite images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many earth observation programs such as Landsat, Sentinel, SPOT, and Pleiades\nproduce huge volume of medium to high resolution multi-spectral images every\nday that can be organized in time series. In this work, we exploit both\ntemporal and spatial information provided by these images to generate land\ncover maps. For this purpose, we combine a fully convolutional neural network\nwith a convolutional long short-term memory. Implementation details of the\nproposed spatio-temporal neural network architecture are provided. Experimental\nresults show that the temporal information provided by time series images\nallows increasing the accuracy of land cover classification, thus producing\nup-to-date maps that can help in identifying changes on earth.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 09:26:52 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["De Teyou", "Gael Kamdem", ""], ["Tarabalka", "Yuliya", ""], ["Manighetti", "Isabelle", ""], ["Almar", "Rafael", ""], ["Tripod", "Sebastien", ""]]}, {"id": "2008.08433", "submitter": "Qingjie Meng", "authors": "Qingjie Meng and Daniel Rueckert and Bernhard Kainz", "title": "Unsupervised Cross-domain Image Classification by Distance Metric Guided\n  Feature Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning deep neural networks that are generalizable across different domains\nremains a challenge due to the problem of domain shift. Unsupervised domain\nadaptation is a promising avenue which transfers knowledge from a source domain\nto a target domain without using any labels in the target domain. Contemporary\ntechniques focus on extracting domain-invariant features using domain\nadversarial training. However, these techniques neglect to learn discriminative\nclass boundaries in the latent representation space on a target domain and\nyield limited adaptation performance. To address this problem, we propose\ndistance metric guided feature alignment (MetFA) to extract discriminative as\nwell as domain-invariant features on both source and target domains. The\nproposed MetFA method explicitly and directly learns the latent representation\nwithout using domain adversarial training. Our model integrates class\ndistribution alignment to transfer semantic knowledge from a source domain to a\ntarget domain. We evaluate the proposed method on fetal ultrasound datasets for\ncross-device image classification. Experimental results demonstrate that the\nproposed method outperforms the state-of-the-art and enables model\ngeneralization.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 13:36:57 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Meng", "Qingjie", ""], ["Rueckert", "Daniel", ""], ["Kainz", "Bernhard", ""]]}, {"id": "2008.08445", "submitter": "Hao Wang", "authors": "Hao Wang, Jingrong Chen, Xinchen Wan, Han Tian, Jiacheng Xia, Gaoxiong\n  Zeng, Weiyan Wang, Kai Chen, Wei Bai, Junchen Jiang", "title": "Domain-specific Communication Optimization for Distributed DNN Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication overhead poses an important obstacle to distributed DNN\ntraining and draws increasing attention in recent years. Despite continuous\nefforts, prior solutions such as gradient compression/reduction,\ncompute/communication overlapping and layer-wise flow scheduling, etc., are\nstill coarse-grained and insufficient for an efficient distributed training\nespecially when the network is under pressure. We present DLCP, a novel\nsolution exploiting the domain-specific properties of deep learning to optimize\ncommunication overhead of DNN training in a fine-grained manner. At its heart,\nDLCP comprises of several key innovations beyond prior work: e.g., it exploits\n{\\em bounded loss tolerance} of SGD-based training to improve tail\ncommunication latency which cannot be avoided purely through gradient\ncompression. It then performs fine-grained packet-level prioritization and\ndropping, as opposed to flow-level scheduling, based on layers and magnitudes\nof gradients to further speedup model convergence without affecting accuracy.\nIn addition, it leverages inter-packet order-independency to perform per-packet\nload balancing without causing classical re-ordering issues. DLCP works with\nboth Parameter Server and collective communication routines. We have\nimplemented DLCP with commodity switches, integrated it with various training\nframeworks including TensorFlow, MXNet and PyTorch, and deployed it in our\nsmall-scale testbed with 10 Nvidia V100 GPUs. Our testbed experiments and\nlarge-scale simulations show that DLCP delivers up to $84.3\\%$ additional\ntraining acceleration over the best existing solutions.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 09:53:21 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Wang", "Hao", ""], ["Chen", "Jingrong", ""], ["Wan", "Xinchen", ""], ["Tian", "Han", ""], ["Xia", "Jiacheng", ""], ["Zeng", "Gaoxiong", ""], ["Wang", "Weiyan", ""], ["Chen", "Kai", ""], ["Bai", "Wei", ""], ["Jiang", "Junchen", ""]]}, {"id": "2008.08461", "submitter": "Benjamin Miller", "authors": "Benjamin Kurt Miller, Mario Geiger, Tess E. Smidt, Frank No\\'e", "title": "Relevance of Rotationally Equivariant Convolutions for Predicting\n  Molecular Properties", "comments": "Machine Learning for Molecules Workshop at NeurIPS 2020, NeurIPS\n  workshop on Interpretable Inductive Biases and Physically Structured Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equivariant neural networks (ENNs) are graph neural networks embedded in\n$\\mathbb{R}^3$ and are well suited for predicting molecular properties. The ENN\nlibrary e3nn has customizable convolutions, which can be designed to depend\nonly on distances between points, or also on angular features, making them\nrotationally invariant, or equivariant, respectively. This paper studies the\npractical value of including angular dependencies for molecular property\nprediction directly via an ablation study with \\texttt{e3nn} and the QM9 data\nset. We find that, for fixed network depth and parameter count, adding angular\nfeatures decreased test error by an average of 23%. Meanwhile, increasing\nnetwork depth decreased test error by only 4% on average, implying that\nrotationally equivariant layers are comparatively parameter efficient. We\npresent an explanation of the accuracy improvement on the dipole moment, the\ntarget which benefited most from the introduction of angular features.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 14:07:36 GMT"}, {"version": "v2", "created": "Sat, 22 Aug 2020 10:26:07 GMT"}, {"version": "v3", "created": "Sat, 14 Nov 2020 18:57:27 GMT"}, {"version": "v4", "created": "Tue, 24 Nov 2020 09:27:37 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Miller", "Benjamin Kurt", ""], ["Geiger", "Mario", ""], ["Smidt", "Tess E.", ""], ["No\u00e9", "Frank", ""]]}, {"id": "2008.08476", "submitter": "Alberto Marchisio", "authors": "Alberto Marchisio, Andrea Massa, Vojtech Mrazek, Beatrice Bussolino,\n  Maurizio Martina, Muhammad Shafique", "title": "NASCaps: A Framework for Neural Architecture Search to Optimize the\n  Accuracy and Hardware Efficiency of Convolutional Capsule Networks", "comments": "To appear at the IEEE/ACM International Conference on Computer-Aided\n  Design (ICCAD '20), November 2-5, 2020, Virtual Event, USA", "journal-ref": null, "doi": "10.1145/3400302.3415731", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have made significant improvements to reach the\ndesired accuracy to be employed in a wide variety of Machine Learning (ML)\napplications. Recently the Google Brain's team demonstrated the ability of\nCapsule Networks (CapsNets) to encode and learn spatial correlations between\ndifferent input features, thereby obtaining superior learning capabilities\ncompared to traditional (i.e., non-capsule based) DNNs. However, designing\nCapsNets using conventional methods is a tedious job and incurs significant\ntraining effort. Recent studies have shown that powerful methods to\nautomatically select the best/optimal DNN model configuration for a given set\nof applications and a training dataset are based on the Neural Architecture\nSearch (NAS) algorithms. Moreover, due to their extreme computational and\nmemory requirements, DNNs are employed using the specialized hardware\naccelerators in IoT-Edge/CPS devices. In this paper, we propose NASCaps, an\nautomated framework for the hardware-aware NAS of different types of DNNs,\ncovering both traditional convolutional DNNs and CapsNets. We study the\nefficacy of deploying a multi-objective Genetic Algorithm (e.g., based on the\nNSGA-II algorithm). The proposed framework can jointly optimize the network\naccuracy and the corresponding hardware efficiency, expressed in terms of\nenergy, memory, and latency of a given hardware accelerator executing the DNN\ninference. Besides supporting the traditional DNN layers, our framework is the\nfirst to model and supports the specialized capsule layers and dynamic routing\nin the NAS-flow. We evaluate our framework on different datasets, generating\ndifferent network configurations, and demonstrate the tradeoffs between the\ndifferent output metrics. We will open-source the complete framework and\nconfigurations of the Pareto-optimal architectures at\nhttps://github.com/ehw-fit/nascaps.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 14:29:36 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Marchisio", "Alberto", ""], ["Massa", "Andrea", ""], ["Mrazek", "Vojtech", ""], ["Bussolino", "Beatrice", ""], ["Martina", "Maurizio", ""], ["Shafique", "Muhammad", ""]]}, {"id": "2008.08496", "submitter": "Saul Calderon Ramirez", "authors": "Saul Calderon-Ramirez, Shengxiang-Yang, Armaghan Moemeni, David\n  Elizondo, Simon Colreavy-Donnelly, Luis Fernando Chavarria-Estrada, Miguel A.\n  Molina-Cabello", "title": "Correcting Data Imbalance for Semi-Supervised Covid-19 Detection Using\n  X-ray Chest Images", "comments": "Under journal review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Corona Virus (COVID-19) is an internationalpandemic that has quickly\npropagated throughout the world. The application of deep learning for image\nclassification of chest X-ray images of Covid-19 patients, could become a novel\npre-diagnostic detection methodology. However, deep learning architectures\nrequire large labelled datasets. This is often a limitation when the subject of\nresearch is relatively new as in the case of the virus outbreak, where dealing\nwith small labelled datasets is a challenge. Moreover, in the context of a new\nhighly infectious disease, the datasets are also highly imbalanced,with few\nobservations from positive cases of the new disease. In this work we evaluate\nthe performance of the semi-supervised deep learning architecture known as\nMixMatch using a very limited number of labelled observations and highly\nimbalanced labelled dataset. We propose a simple approach for correcting data\nimbalance, re-weight each observationin the loss function, giving a higher\nweight to the observationscorresponding to the under-represented class. For\nunlabelled observations, we propose the usage of the pseudo and augmentedlabels\ncalculated by MixMatch to choose the appropriate weight. The MixMatch method\ncombined with the proposed pseudo-label based balance correction improved\nclassification accuracy by up to 10%, with respect to the non balanced MixMatch\nalgorithm, with statistical significance. We tested our proposed approach with\nseveral available datasets using 10, 15 and 20 labelledobservations.\nAdditionally, a new dataset is included among thetested datasets, composed of\nchest X-ray images of Costa Rican adult patients\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 15:16:57 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 20:53:08 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Calderon-Ramirez", "Saul", ""], ["Shengxiang-Yang", "", ""], ["Moemeni", "Armaghan", ""], ["Elizondo", "David", ""], ["Colreavy-Donnelly", "Simon", ""], ["Chavarria-Estrada", "Luis Fernando", ""], ["Molina-Cabello", "Miguel A.", ""]]}, {"id": "2008.08501", "submitter": "Lorenzo Federici Mr.", "authors": "Alessandro Zavoli and Lorenzo Federici", "title": "Reinforcement Learning for Low-Thrust Trajectory Design of\n  Interplanetary Missions", "comments": "2020 AAS/AIAA Astrodynamics Specialist Virtual Lake Tahoe Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the use of Reinforcement Learning for the robust\ndesign of low-thrust interplanetary trajectories in presence of severe\ndisturbances, modeled alternatively as Gaussian additive process noise,\nobservation noise, control actuation errors on thrust magnitude and direction,\nand possibly multiple missed thrust events. The optimal control problem is\nrecast as a time-discrete Markov Decision Process to comply with the standard\nformulation of reinforcement learning. An open-source implementation of the\nstate-of-the-art algorithm Proximal Policy Optimization is adopted to carry out\nthe training process of a deep neural network, used to map the spacecraft\n(observed) states to the optimal control policy. The resulting Guidance and\nControl Network provides both a robust nominal trajectory and the associated\nclosed-loop guidance law. Numerical results are presented for a typical\nEarth-Mars mission. First, in order to validate the proposed approach, the\nsolution found in a (deterministic) unperturbed scenario is compared with the\noptimal one provided by an indirect technique. Then, the robustness and\noptimality of the obtained closed-loop guidance laws is assessed by means of\nMonte Carlo campaigns performed in the considered uncertain scenarios. These\npreliminary results open up new horizons for the use of reinforcement learning\nin the robust design of interplanetary missions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 15:22:15 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Zavoli", "Alessandro", ""], ["Federici", "Lorenzo", ""]]}, {"id": "2008.08516", "submitter": "Hugo Jair  Escalante", "authors": "Hugo Jair Escalante", "title": "Automated Machine Learning -- a brief review at the end of the early\n  years", "comments": "Preprint submitted to Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated machine learning (AutoML) is the sub-field of machine learning that\naims at automating, to some extend, all stages of the design of a machine\nlearning system. In the context of supervised learning, AutoML is concerned\nwith feature extraction, pre processing, model design and post processing.\nMajor contributions and achievements in AutoML have been taking place during\nthe recent decade. We are therefore in perfect timing to look back and realize\nwhat we have learned. This chapter aims to summarize the main findings in the\nearly years of AutoML. More specifically, in this chapter an introduction to\nAutoML for supervised learning is provided and an historical review of progress\nin this field is presented. Likewise, the main paradigms of AutoML are\ndescribed and research opportunities are outlined.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 15:48:49 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 16:23:41 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2020 14:45:40 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Escalante", "Hugo Jair", ""]]}, {"id": "2008.08522", "submitter": "Marta Golabek", "authors": "Marta Go{\\l}\\k{a}bek, Robin Senge, and Rainer Neumann", "title": "Demand Forecasting using Long Short-Term Memory Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate to what extent long short-term memory neural\nnetworks (LSTMs) are suitable for demand forecasting in the e-grocery retail\nsector. For this purpose, univariate as well as multivariate LSTM-based models\nwere developed and tested for 100 fast-moving consumer goods in the context of\na master's thesis. On average, the developed models showed better results for\nfood products than the comparative models from both statistical and machine\nlearning families. Solely in the area of beverages random forest and linear\nregression achieved slightly better results. This outcome suggests that LSTMs\ncan be used for demand forecasting at product level. The performance of the\nmodels presented here goes beyond the current state of research, as can be seen\nfrom the evaluations based on a data set that unfortunately has not been\npublicly available to date.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 16:01:23 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Go\u0142\u0105bek", "Marta", ""], ["Senge", "Robin", ""], ["Neumann", "Rainer", ""]]}, {"id": "2008.08523", "submitter": "Hang Du", "authors": "Anna Zhu, Hang Du, Shengwu Xiong", "title": "Scene Text Detection with Selected Anchor", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object proposal technique with dense anchoring scheme for scene text\ndetection were applied frequently to achieve high recall. It results in the\nsignificant improvement in accuracy but waste of computational searching,\nregression and classification. In this paper, we propose an anchor\nselection-based region proposal network (AS-RPN) using effective selected\nanchors instead of dense anchors to extract text proposals. The center, scales,\naspect ratios and orientations of anchors are learnable instead of fixing,\nwhich leads to high recall and greatly reduced numbers of anchors. By replacing\nthe anchor-based RPN in Faster RCNN, the AS-RPN-based Faster RCNN can achieve\ncomparable performance with previous state-of-the-art text detecting approaches\non standard benchmarks, including COCO-Text, ICDAR2013, ICDAR2015 and\nMSRA-TD500 when using single-scale and single model (ResNet50) testing only.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 16:03:13 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Zhu", "Anna", ""], ["Du", "Hang", ""], ["Xiong", "Shengwu", ""]]}, {"id": "2008.08525", "submitter": "Giorgio Pietro Biondetti", "authors": "Giorgio Pietro Biondetti, Romane Gauriau, Christopher P. Bridge,\n  Charles Lu, Katherine P. Andriole", "title": "\"Name that manufacturer\". Relating image acquisition bias with task\n  complexity when training deep learning models: experiments on head CT", "comments": "15 pages, 4 figures. This paper has been submitted to the Journal of\n  Digital Imaging (Springer Journal) and it is now in review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As interest in applying machine learning techniques for medical images\ncontinues to grow at a rapid pace, models are starting to be developed and\ndeployed for clinical applications. In the clinical AI model development\nlifecycle (described by Lu et al. [1]), a crucial phase for machine learning\nscientists and clinicians is the proper design and collection of the data\ncohort. The ability to recognize various forms of biases and distribution\nshifts in the dataset is critical at this step. While it remains difficult to\naccount for all potential sources of bias, techniques can be developed to\nidentify specific types of bias in order to mitigate their impact. In this work\nwe analyze how the distribution of scanner manufacturers in a dataset can\ncontribute to the overall bias of deep learning models. We evaluate\nconvolutional neural networks (CNN) for both classification and segmentation\ntasks, specifically two state-of-the-art models: ResNet [2] for classification\nand U-Net [3] for segmentation. We demonstrate that CNNs can learn to\ndistinguish the imaging scanner manufacturer and that this bias can\nsubstantially impact model performance for both classification and segmentation\ntasks. By creating an original synthesis dataset of brain data mimicking the\npresence of more or less subtle lesions we also show that this bias is related\nto the difficulty of the task. Recognition of such bias is critical to develop\nrobust, generalizable models that will be crucial for clinical applications in\nreal-world data distributions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 16:05:58 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Biondetti", "Giorgio Pietro", ""], ["Gauriau", "Romane", ""], ["Bridge", "Christopher P.", ""], ["Lu", "Charles", ""], ["Andriole", "Katherine P.", ""]]}, {"id": "2008.08528", "submitter": "Boqiang Xu", "authors": "Boqiang Xu, Lingxiao He, Xingyu Liao, Wu Liu, Zhenan Sun, Tao Mei", "title": "Black Re-ID: A Head-shoulder Descriptor for the Challenging Problem of\n  Person Re-Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Person re-identification (Re-ID) aims at retrieving an input person image\nfrom a set of images captured by multiple cameras. Although recent Re-ID\nmethods have made great success, most of them extract features in terms of the\nattributes of clothing (e.g., color, texture). However, it is common for people\nto wear black clothes or be captured by surveillance systems in low light\nillumination, in which cases the attributes of the clothing are severely\nmissing. We call this problem the Black Re-ID problem. To solve this problem,\nrather than relying on the clothing information, we propose to exploit\nhead-shoulder features to assist person Re-ID. The head-shoulder adaptive\nattention network (HAA) is proposed to learn the head-shoulder feature and an\ninnovative ensemble method is designed to enhance the generalization of our\nmodel. Given the input person image, the ensemble method would focus on the\nhead-shoulder feature by assigning a larger weight if the individual insides\nthe image is in black clothing. Due to the lack of a suitable benchmark dataset\nfor studying the Black Re-ID problem, we also contribute the first Black-reID\ndataset, which contains 1274 identities in training set. Extensive evaluations\non the Black-reID, Market1501 and DukeMTMC-reID datasets show that our model\nachieves the best result compared with the state-of-the-art Re-ID methods on\nboth Black and conventional Re-ID problems. Furthermore, our method is also\nproved to be effective in dealing with person Re-ID in similar clothing. Our\ncode and dataset are avaliable on https://github.com/xbq1994/.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 16:10:36 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Xu", "Boqiang", ""], ["He", "Lingxiao", ""], ["Liao", "Xingyu", ""], ["Liu", "Wu", ""], ["Sun", "Zhenan", ""], ["Mei", "Tao", ""]]}, {"id": "2008.08565", "submitter": "Mahdi Soleymani", "authors": "Mahdi Soleymani, Hessam Mahdavifar, A. Salman Avestimehr", "title": "Analog Lagrange Coded Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distributed computing scenario is considered, where the computational power\nof a set of worker nodes is used to perform a certain computation task over a\ndataset that is dispersed among the workers. Lagrange coded computing (LCC),\nproposed by Yu et al., leverages the well-known Lagrange polynomial to perform\npolynomial evaluation of the dataset in such a scenario in an efficient\nparallel fashion while keeping the privacy of data amidst possible collusion of\nworkers. This solution relies on quantizing the data into a finite field, so\nthat Shamir's secret sharing, as one of its main building blocks, can be\nemployed. Such a solution, however, is not properly scalable with the size of\ndataset, mainly due to computation overflows. To address such a critical issue,\nwe propose a novel extension of LCC to the analog domain, referred to as analog\nLCC (ALCC). All the operations in the proposed ALCC protocol are done over the\ninfinite fields of R/C but for practical implementations floating-point numbers\nare used. We characterize the privacy of data in ALCC, against any subset of\ncolluding workers up to a certain size, in terms of the distinguishing security\n(DS) and the mutual information security (MIS) metrics. Also, the accuracy of\noutcome is characterized in a practical setting assuming operations are\nperformed using floating-point numbers. Consequently, a fundamental trade-off\nbetween the accuracy of the outcome of ALCC and its privacy level is observed\nand is numerically evaluated. Moreover, we implement the proposed scheme to\nperform matrix-matrix multiplication over a batch of matrices. It is observed\nthat ALCC is superior compared to the state-of-the-art LCC, implemented using\nfixed-point numbers, assuming both schemes use an equal number of bits to\nrepresent data symbols.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 17:47:37 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 23:42:14 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Soleymani", "Mahdi", ""], ["Mahdavifar", "Hessam", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "2008.08567", "submitter": "Wei Li", "authors": "Wei Li and Brian Mak", "title": "Transformer based Multilingual document Embedding model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the current state-of-the-art multilingual document embedding model\nLASER is based on the bidirectional LSTM neural machine translation model. This\npaper presents a transformer-based sentence/document embedding model, T-LASER,\nwhich makes three significant improvements. Firstly, the BiLSTM layers is\nreplaced by the attention-based transformer layers, which is more capable of\nlearning sequential patterns in longer texts. Secondly, due to the absence of\nrecurrence, T-LASER enables faster parallel computations in the encoder to\ngenerate the text embedding. Thirdly, we augment the NMT translation loss\nfunction with an additional novel distance constraint loss. This distance\nconstraint loss would further bring the embeddings of parallel sentences close\ntogether in the vector space; we call the T-LASER model trained with distance\nconstraint, cT-LASER. Our cT-LASER model significantly outperforms both\nBiLSTM-based LASER and the simpler transformer-based T-LASER.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 17:51:30 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 16:37:29 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Li", "Wei", ""], ["Mak", "Brian", ""]]}, {"id": "2008.08579", "submitter": "Tanishq Abraham", "authors": "Tanishq Abraham, Andrew Shaw, Daniel O'Connor, Austin Todd, Richard\n  Levenson", "title": "Slide-free MUSE Microscopy to H&E Histology Modality Conversion via\n  Unpaired Image-to-Image Translation GAN Models", "comments": "4 pages plus 1 page references. Presented at the ICML Computational\n  Biology Workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MUSE is a novel slide-free imaging technique for histological examination of\ntissues that can serve as an alternative to traditional histology. In order to\nbridge the gap between MUSE and traditional histology, we aim to convert MUSE\nimages to resemble authentic hematoxylin- and eosin-stained (H&E) images. We\nevaluated four models: a non-machine-learning-based color-mapping\nunmixing-based tool, CycleGAN, DualGAN, and GANILLA. CycleGAN and GANILLA\nprovided visually compelling results that appropriately transferred H&E style\nand preserved MUSE content. Based on training an automated critic on real and\ngenerated H&E images, we determined that CycleGAN demonstrated the best\nperformance. We have also found that MUSE color inversion may be a necessary\nstep for accurate modality conversion to H&E. We believe that our MUSE-to-H&E\nmodel can help improve adoption of novel slide-free methods by bridging a\nperceptual gap between MUSE imaging and traditional histology.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 17:59:08 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Abraham", "Tanishq", ""], ["Shaw", "Andrew", ""], ["O'Connor", "Daniel", ""], ["Todd", "Austin", ""], ["Levenson", "Richard", ""]]}, {"id": "2008.08601", "submitter": "James Halverson", "authors": "James Halverson, Anindita Maiti, and Keegan Stoner", "title": "Neural Networks and Quantum Field Theory", "comments": "v2: published in Machine Learning: Science and Technology. Additions\n  include study of N-scaling, a correction for examples, and new experimental\n  tests. 53 pages, 7 figures, and appendices", "journal-ref": null, "doi": "10.1088/2632-2153/abeca3", "report-no": null, "categories": "cs.LG cond-mat.dis-nn hep-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a theoretical understanding of neural networks in terms of\nWilsonian effective field theory. The correspondence relies on the fact that\nmany asymptotic neural networks are drawn from Gaussian processes, the analog\nof non-interacting field theories. Moving away from the asymptotic limit yields\na non-Gaussian process and corresponds to turning on particle interactions,\nallowing for the computation of correlation functions of neural network outputs\nwith Feynman diagrams. Minimal non-Gaussian process likelihoods are determined\nby the most relevant non-Gaussian terms, according to the flow in their\ncoefficients induced by the Wilsonian renormalization group. This yields a\ndirect connection between overparameterization and simplicity of neural network\nlikelihoods. Whether the coefficients are constants or functions may be\nunderstood in terms of GP limit symmetries, as expected from 't Hooft's\ntechnical naturalness. General theoretical calculations are matched to neural\nnetwork experiments in the simplest class of models allowing the\ncorrespondence. Our formalism is valid for any of the many architectures that\nbecomes a GP in an asymptotic limit, a property preserved under certain types\nof training.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 18:00:06 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 16:52:31 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Halverson", "James", ""], ["Maiti", "Anindita", ""], ["Stoner", "Keegan", ""]]}, {"id": "2008.08617", "submitter": "Ziheng Duan", "authors": "Yueyang Wang, Ziheng Duan, Yida Huang, Haoyan Xu, Jie Feng, Anni Ren", "title": "MTHetGNN: A Heterogeneous Graph Embedding Framework for Multivariate\n  Time Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series forecasting, which analyzes historical time series\nto predict future trends, can effectively help decision-making. Complex\nrelations among variables in MTS, including static, dynamic, predictable, and\nlatent relations, have made it possible to mining more features of MTS.\nModeling complex relations are not only essential in characterizing latent\ndependency as well as modeling temporal dependence, but also brings great\nchallenges in the MTS forecasting task. However, existing methods mainly focus\non modeling certain relations among MTS variables. In this paper, we propose a\nnovel end-to-end deep learning model, termed Multivariate Time Series\nForecasting via Heterogeneous Graph Neural Networks (MTHetGNN). To characterize\ncomplex relations among variables, a relation embedding module is designed in\nMTHetGNN, where each variable is regarded as a graph node, and each type of\nedge represents a specific static or dynamic relationship. Meanwhile, a\ntemporal embedding module is introduced for time series features extraction,\nwhere involving convolutional neural network (CNN) filters with different\nperception scales. Finally, a heterogeneous graph embedding module is adopted\nto handle the complex structural information generated by the two modules.\nThree benchmark datasets from the real world are used to evaluate the proposed\nMTHetGNN. The comprehensive experiments show that MTHetGNN achieves\nstate-of-the-art results in the MTS forecasting task.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 18:21:22 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 11:30:54 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 14:50:27 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wang", "Yueyang", ""], ["Duan", "Ziheng", ""], ["Huang", "Yida", ""], ["Xu", "Haoyan", ""], ["Feng", "Jie", ""], ["Ren", "Anni", ""]]}, {"id": "2008.08624", "submitter": "Akwarandu Nwachuku", "authors": "Mary Akinyemi, Chika Yinka-Banjo, Ogban-Asuquo Ugot, Akwarandu Ugo\n  Nwachuku", "title": "Estimating the time-lapse between medical insurance reimbursement with\n  non-parametric regression models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Non-parametric supervised learning algorithms represent a succinct class of\nsupervised learning algorithms where the learning parameters are highly\nflexible and whose values are directly dependent on the size of the training\ndata. In this paper, we comparatively study the properties of four\nnonparametric algorithms, K-Nearest Neighbours (KNNs), Support Vector Machines\n(SVMs), Decision trees and Random forests. The supervised learning task is a\nregression estimate of the time-lapse in medical insurance reimbursement. Our\nstudy is concerned precisely with how well each of the nonparametric regression\nmodels fits the training data. We quantify the goodness of fit using the\nR-squared metric. The results are presented with a focus on the effect of the\nsize of the training data, the feature space dimension and hyperparameter\noptimization.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 18:39:12 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Akinyemi", "Mary", ""], ["Yinka-Banjo", "Chika", ""], ["Ugot", "Ogban-Asuquo", ""], ["Nwachuku", "Akwarandu Ugo", ""]]}, {"id": "2008.08633", "submitter": "Guangyi Zhang", "authors": "Guangyi Zhang and Ali Etemad", "title": "RFNet: Riemannian Fusion Network for EEG-based Brain-Computer Interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the novel Riemannian Fusion Network (RFNet), a deep\nneural architecture for learning spatial and temporal information from\nElectroencephalogram (EEG) for a number of different EEG-based Brain Computer\nInterface (BCI) tasks and applications. The spatial information relies on\nSpatial Covariance Matrices (SCM) of multi-channel EEG, whose space form a\nRiemannian Manifold due to the Symmetric and Positive Definite structure. We\nexploit a Riemannian approach to map spatial information onto feature vectors\nin Euclidean space. The temporal information characterized by features based on\ndifferential entropy and logarithm power spectrum density is extracted from\ndifferent windows through time. Our network then learns the temporal\ninformation by employing a deep long short-term memory network with a soft\nattention mechanism. The output of the attention mechanism is used as the\ntemporal feature vector. To effectively fuse spatial and temporal information,\nwe use an effective fusion strategy, which learns attention weights applied to\nembedding-specific features for decision making. We evaluate our proposed\nframework on four public datasets from three popular fields of BCI, notably\nemotion recognition, vigilance estimation, and motor imagery classification,\ncontaining various types of tasks such as binary classification, multi-class\nclassification, and regression. RFNet approaches the state-of-the-art on one\ndataset (SEED) and outperforms other methods on the other three datasets\n(SEED-VIG, BCI-IV 2A, and BCI-IV 2B), setting new state-of-the-art values and\nshowing the robustness of our framework in EEG representation learning.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 18:56:49 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Zhang", "Guangyi", ""], ["Etemad", "Ali", ""]]}, {"id": "2008.08637", "submitter": "Weijing Tang", "authors": "Weijing Tang, Jiaqi Ma, Qiaozhu Mei, Ji Zhu", "title": "SODEN: A Scalable Continuous-Time Survival Model through Ordinary\n  Differential Equation Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a flexible model for survival analysis using neural\nnetworks along with scalable optimization algorithms. One key technical\nchallenge for directly applying maximum likelihood estimation (MLE) to censored\ndata is that evaluating the objective function and its gradients with respect\nto model parameters requires the calculation of integrals. To address this\nchallenge, we recognize that the MLE for censored data can be viewed as a\ndifferential-equation constrained optimization problem, a novel perspective.\nFollowing this connection, we model the distribution of event time through an\nordinary differential equation and utilize efficient ODE solvers and adjoint\nsensitivity analysis to numerically evaluate the likelihood and the gradients.\nUsing this approach, we are able to 1) provide a broad family of\ncontinuous-time survival distributions without strong structural assumptions,\n2) obtain powerful feature representations using neural networks, and 3) allow\nefficient estimation of the model in large-scale applications using stochastic\ngradient descent. Through both simulation studies and real-world data examples,\nwe demonstrate the effectiveness of the proposed method in comparison to\nexisting state-of-the-art deep learning survival analysis models.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 19:11:25 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Tang", "Weijing", ""], ["Ma", "Jiaqi", ""], ["Mei", "Qiaozhu", ""], ["Zhu", "Ji", ""]]}, {"id": "2008.08642", "submitter": "Shervin Rahimzadeh Arashloo", "authors": "Shervin Rahimzadeh Arashloo", "title": "$\\ell_p$-Norm Multiple Kernel One-Class Fisher Null-Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper addresses the multiple kernel learning (MKL) problem for one-class\nclassification (OCC). For this purpose, based on the Fisher null-space\none-class classification method, we present a multiple kernel learning\nalgorithm where a general $\\ell_p$-norm constraint ($p\\geq1$) on kernel weights\nis considered. The proposed approach is then extended to learn several related\none-class MKL problems jointly by constraining them to share common kernel\nweights. We pose the one-class MKL task as a min-max saddle point Lagrangian\noptimisation problem and propose an efficient alternating optimisation method\nto solve it.\n  An extensive assessment of the proposed method on ten data sets from\ndifferent application domains in one-class classification confirms its merits\nagainst the baseline and several other one-class multiple kernel learning\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 19:25:55 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Arashloo", "Shervin Rahimzadeh", ""]]}, {"id": "2008.08653", "submitter": "Julia Steinberg", "authors": "Julia Steinberg, Madhu Advani, Haim Sompolinsky", "title": "A new role for circuit expansion for learning in neural networks", "comments": "13+10 pages, 13 figures", "journal-ref": "Phys. Rev. E 103, 022404 (2021)", "doi": "10.1103/PhysRevE.103.022404", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many sensory pathways in the brain rely on sparsely active populations of\nneurons downstream from the input stimuli. The biological reason for the\noccurrence of expanded structure in the brain is unclear, but may be because\nexpansion can increase the expressive power of a neural network. In this work,\nwe show that expanding a neural network can improve its generalization\nperformance even in cases in which the expanded structure is pruned after the\nlearning period. To study this setting we use a teacher-student framework where\na perceptron teacher network generates labels which are corrupted with small\namounts of noise. We then train a student network that is structurally matched\nto the teacher and can achieve optimal accuracy if given the teacher's synaptic\nweights. We find that sparse expansion of the input of a student perceptron\nnetwork both increases its capacity and improves the generalization performance\nof the network when learning a noisy rule from a teacher perceptron when these\nexpansions are pruned after learning. We find similar behavior when the\nexpanded units are stochastic and uncorrelated with the input and analyze this\nnetwork in the mean field limit. We show by solving the mean field equations\nthat the generalization error of the stochastic expanded student network\ncontinues to drop as the size of the network increases. The improvement in\ngeneralization performance occurs despite the increased complexity of the\nstudent network relative to the teacher it is trying to learn. We show that\nthis effect is closely related to the addition of slack variables in artificial\nneural networks and suggest possible implications for artificial and biological\nneural networks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 20:00:44 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 21:34:27 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Steinberg", "Julia", ""], ["Advani", "Madhu", ""], ["Sompolinsky", "Haim", ""]]}, {"id": "2008.08662", "submitter": "Musadig Aliyev", "authors": "Musadig Aliyev, Elvin Ahmadov, Habil Gadirli, Arzu Mammadova and Emin\n  Alasgarov", "title": "Segmenting Bank Customers via RFM Model and Unsupervised Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, one of the major challenges for financial institutions is\nthe retention of their customers using new methodologies of reliable and\nprofitable segmentation. In the field of banking, the approach of offering all\nof the services to all the existing customers at the same time does not always\nwork. However, being aware of what to sell, when to sell and whom to sell makes\na huge difference in the conversion rate of the customers responding to new\nservices and buying new products. In this paper, we used RFM technique and\nvarious clustering algorithms applied to the real customer data of one of the\nlargest private banks of Azerbaijan.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 20:41:18 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Aliyev", "Musadig", ""], ["Ahmadov", "Elvin", ""], ["Gadirli", "Habil", ""], ["Mammadova", "Arzu", ""], ["Alasgarov", "Emin", ""]]}, {"id": "2008.08665", "submitter": "Hyunsung Lee", "authors": "Hyunsung Lee", "title": "Intelligent Replication Management for HDFS Using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Storage systems for cloud computing merge a large number of commodity\ncomputers into a single large storage pool. It provides high-performance\nstorage over an unreliable, and dynamic network at a lower cost than purchasing\nand maintaining large mainframe. In this paper, we examine whether it is\nfeasible to apply Reinforcement Learning(RL) to system domain problems. Our\nexperiments show that the RL model is comparable, even outperform other\nheuristics for block management problem. However, our experiments are limited\nin terms of scalability and fidelity. Even though our formulation is not very\npractical,applying Reinforcement Learning to system domain could offer good\nalternatives to existing heuristics.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 20:53:13 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Lee", "Hyunsung", ""]]}, {"id": "2008.08673", "submitter": "Md Yousuf Harun", "authors": "Md Yousuf Harun, M Arifur Rahman, Joshua Mellinger, Willy Chang,\n  Thomas Huang, Brienne Walker, Kristen Hori, and Aaron T. Ohta", "title": "Image Segmentation of Zona-Ablated Human Blastocysts", "comments": null, "journal-ref": "IEEE 13th International Conference on Nano/Molecular Medicine &\n  Engineering (NANOMED), Gwangju, Korea (South), 2019, pp. 208-213", "doi": "10.1109/NANOMED49242.2019.9130621", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automating human preimplantation embryo grading offers the potential for\nhigher success rates with in vitro fertilization (IVF) by providing new\nquantitative and objective measures of embryo quality. Current IVF procedures\ntypically use only qualitative manual grading, which is limited in the\nidentification of genetically abnormal embryos. The automatic quantitative\nassessment of blastocyst expansion can potentially improve sustained pregnancy\nrates and reduce health risks from abnormal pregnancies through a more accurate\nidentification of genetic abnormality. The expansion rate of a blastocyst is an\nimportant morphological feature to determine the quality of a developing\nembryo. In this work, a deep learning based human blastocyst image segmentation\nmethod is presented, with the goal of facilitating the challenging task of\nsegmenting irregularly shaped blastocysts. The type of blastocysts evaluated\nhere has undergone laser ablation of the zona pellucida, which is required\nprior to trophectoderm biopsy. This complicates the manual measurements of the\nexpanded blastocyst's size, which shows a correlation with genetic\nabnormalities. The experimental results on the test set demonstrate\nsegmentation greatly improves the accuracy of expansion measurements, resulting\nin up to 99.4% accuracy, 98.1% precision, 98.8% recall, a 98.4% Dice\nCoefficient, and a 96.9% Jaccard Index.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 21:20:02 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Harun", "Md Yousuf", ""], ["Rahman", "M Arifur", ""], ["Mellinger", "Joshua", ""], ["Chang", "Willy", ""], ["Huang", "Thomas", ""], ["Walker", "Brienne", ""], ["Hori", "Kristen", ""], ["Ohta", "Aaron T.", ""]]}, {"id": "2008.08675", "submitter": "Anders Johan Andreassen", "authors": "Anders Andreassen, Ethan Dyer", "title": "Asymptotics of Wide Convolutional Neural Networks", "comments": "23 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG hep-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wide neural networks have proven to be a rich class of architectures for both\ntheory and practice. Motivated by the observation that finite width\nconvolutional networks appear to outperform infinite width networks, we study\nscaling laws for wide CNNs and networks with skip connections. Following the\napproach of (Dyer & Gur-Ari, 2019), we present a simple diagrammatic recipe to\nderive the asymptotic width dependence for many quantities of interest. These\nscaling relationships provide a solvable description for the training dynamics\nof wide convolutional networks. We test these relations across a broad range of\narchitectures. In particular, we find that the difference in performance\nbetween finite and infinite width models vanishes at a definite rate with\nrespect to model width. Nonetheless, this relation is consistent with finite\nwidth models generalizing either better or worse than their infinite width\ncounterparts, and we provide examples where the relative performance depends on\nthe optimization details.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 21:22:19 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Andreassen", "Anders", ""], ["Dyer", "Ethan", ""]]}, {"id": "2008.08676", "submitter": "Md Yousuf Harun", "authors": "Md Yousuf Harun, Thomas Huang, and Aaron T. Ohta", "title": "Inner Cell Mass and Trophectoderm Segmentation in Human Blastocyst\n  Images using Deep Neural Network", "comments": null, "journal-ref": "IEEE 13th International Conference on Nano/Molecular Medicine &\n  Engineering (NANOMED), Gwangju, Korea (South), 2019, pp. 214-219", "doi": "10.1109/NANOMED49242.2019.9130618", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embryo quality assessment based on morphological attributes is important for\nachieving higher pregnancy rates from in vitro fertilization (IVF). The\naccurate segmentation of the embryo's inner cell mass (ICM) and trophectoderm\nepithelium (TE) is important, as these parameters can help to predict the\nembryo viability and live birth potential. However, segmentation of the ICM and\nTE is difficult due to variations in their shape and similarities in their\ntextures, both with each other and with their surroundings. To tackle this\nproblem, a deep neural network (DNN) based segmentation approach was\nimplemented. The DNN can identify the ICM region with 99.1% accuracy, 94.9%\nprecision, 93.8% recall, a 94.3% Dice Coefficient, and a 89.3% Jaccard Index.\nIt can extract the TE region with 98.3% accuracy, 91.8% precision, 93.2%\nrecall, a 92.5% Dice Coefficient, and a 85.3% Jaccard Index.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 21:23:16 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Harun", "Md Yousuf", ""], ["Huang", "Thomas", ""], ["Ohta", "Aaron T.", ""]]}, {"id": "2008.08685", "submitter": "Parikshit Ram", "authors": "Kaushik Sinha and Parikshit Ram", "title": "Neural Neighborhood Encoding for Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Inspired by the fruit-fly olfactory circuit, the Fly Bloom Filter [Dasgupta\net al., 2018] is able to efficiently summarize the data with a single pass and\nhas been used for novelty detection. We propose a new classifier (for binary\nand multi-class classification) that effectively encodes the different local\nneighborhoods for each class with a per-class Fly Bloom Filter. The inference\non test data requires an efficient {\\tt FlyHash} [Dasgupta, et al., 2017]\noperation followed by a high-dimensional, but {\\em sparse}, dot product with\nthe per-class Bloom Filters. The learning is trivially parallelizable. On the\ntheoretical side, we establish conditions under which the prediction of our\nproposed classifier on any test example agrees with the prediction of the\nnearest neighbor classifier with high probability. We extensively evaluate our\nproposed scheme with over $50$ data sets of varied data dimensionality to\ndemonstrate that the predictive performance of our proposed neuroscience\ninspired classifier is competitive the the nearest-neighbor classifiers and\nother single-pass classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 22:01:27 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Sinha", "Kaushik", ""], ["Ram", "Parikshit", ""]]}, {"id": "2008.08692", "submitter": "Yingtong Dou", "authors": "Yingtong Dou, Zhiwei Liu, Li Sun, Yutong Deng, Hao Peng, Philip S. Yu", "title": "Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged\n  Fraudsters", "comments": "Accepted by CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3411903", "report-no": null, "categories": "cs.SI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have been widely applied to fraud detection\nproblems in recent years, revealing the suspiciousness of nodes by aggregating\ntheir neighborhood information via different relations. However, few prior\nworks have noticed the camouflage behavior of fraudsters, which could hamper\nthe performance of GNN-based fraud detectors during the aggregation process. In\nthis paper, we introduce two types of camouflages based on recent empirical\nstudies, i.e., the feature camouflage and the relation camouflage. Existing\nGNNs have not addressed these two camouflages, which results in their poor\nperformance in fraud detection problems. Alternatively, we propose a new model\nnamed CAmouflage-REsistant GNN (CARE-GNN), to enhance the GNN aggregation\nprocess with three unique modules against camouflages. Concretely, we first\ndevise a label-aware similarity measure to find informative neighboring nodes.\nThen, we leverage reinforcement learning (RL) to find the optimal amounts of\nneighbors to be selected. Finally, the selected neighbors across different\nrelations are aggregated together. Comprehensive experiments on two real-world\nfraud datasets demonstrate the effectiveness of the RL algorithm. The proposed\nCARE-GNN also outperforms state-of-the-art GNNs and GNN-based fraud detectors.\nWe integrate all GNN-based fraud detectors as an opensource toolbox:\nhttps://github.com/safe-graph/DGFraud. The CARE-GNN code and datasets are\navailable at https://github.com/YingtongDou/CARE-GNN.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 22:33:12 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Dou", "Yingtong", ""], ["Liu", "Zhiwei", ""], ["Sun", "Li", ""], ["Deng", "Yutong", ""], ["Peng", "Hao", ""], ["Yu", "Philip S.", ""]]}, {"id": "2008.08698", "submitter": "Jianbo Jiao", "authors": "Jianbo Jiao, Ana I.L. Namburete, Aris T. Papageorghiou, J. Alison\n  Noble", "title": "Self-Supervised Ultrasound to MRI Fetal Brain Image Synthesis", "comments": "IEEE Transactions on Medical Imaging 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fetal brain magnetic resonance imaging (MRI) offers exquisite images of the\ndeveloping brain but is not suitable for second-trimester anomaly screening,\nfor which ultrasound (US) is employed. Although expert sonographers are adept\nat reading US images, MR images which closely resemble anatomical images are\nmuch easier for non-experts to interpret. Thus in this paper we propose to\ngenerate MR-like images directly from clinical US images. In medical image\nanalysis such a capability is potentially useful as well, for instance for\nautomatic US-MRI registration and fusion. The proposed model is end-to-end\ntrainable and self-supervised without any external annotations. Specifically,\nbased on an assumption that the US and MRI data share a similar anatomical\nlatent space, we first utilise a network to extract the shared latent features,\nwhich are then used for MRI synthesis. Since paired data is unavailable for our\nstudy (and rare in practice), pixel-level constraints are infeasible to apply.\nWe instead propose to enforce the distributions to be statistically\nindistinguishable, by adversarial learning in both the image domain and feature\nspace. To regularise the anatomical structures between US and MRI during\nsynthesis, we further propose an adversarial structural constraint. A new\ncross-modal attention technique is proposed to utilise non-local spatial\ninformation, by encouraging multi-modal knowledge fusion and propagation. We\nextend the approach to consider the case where 3D auxiliary information (e.g.,\n3D neighbours and a 3D location index) from volumetric data is also available,\nand show that this improves image synthesis. The proposed approach is evaluated\nquantitatively and qualitatively with comparison to real fetal MR images and\nother approaches to synthesis, demonstrating its feasibility of synthesising\nrealistic MR images.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 22:56:36 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Jiao", "Jianbo", ""], ["Namburete", "Ana I. L.", ""], ["Papageorghiou", "Aris T.", ""], ["Noble", "J. Alison", ""]]}, {"id": "2008.08710", "submitter": "Baihong Jin", "authors": "Baihong Jin, Yingshui Tan, Albert Liu, Xiangyu Yue, Yuxin Chen,\n  Alberto Sangiovanni Vincentelli", "title": "Using Ensemble Classifiers to Detect Incipient Anomalies", "comments": "Submitted to Transactions on Cyber-Physical Systems for Special Issue\n  on AI and Cyber-Physical Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incipient anomalies present milder symptoms compared to severe ones, and are\nmore difficult to detect and diagnose due to their close resemblance to normal\noperating conditions. The lack of incipient anomaly examples in the training\ndata can pose severe risks to anomaly detection methods that are built upon\nMachine Learning (ML) techniques, because these anomalies can be easily\nmistaken as normal operating conditions. To address this challenge, we propose\nto utilize the uncertainty information available from ensemble learning to\nidentify potential misclassified incipient anomalies. We show in this paper\nthat ensemble learning methods can give improved performance on incipient\nanomalies and identify common pitfalls in these models through extensive\nexperiments on two real-world datasets. Then, we discuss how to design more\neffective ensemble models for detecting incipient anomalies.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 00:00:39 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Jin", "Baihong", ""], ["Tan", "Yingshui", ""], ["Liu", "Albert", ""], ["Yue", "Xiangyu", ""], ["Chen", "Yuxin", ""], ["Vincentelli", "Alberto Sangiovanni", ""]]}, {"id": "2008.08713", "submitter": "Baihong Jin", "authors": "Yingshui Tan, Baihong Jin, Qiushi Cui, Xiangyu Yue, Alberto\n  Sangiovanni Vincentelli", "title": "Generalizing Fault Detection Against Domain Shifts Using\n  Stratification-Aware Cross-Validation", "comments": "Submitted to Transactions on Cyber-Physical Systems for Special Issue\n  on AI and Cyber-Physical Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incipient anomalies present milder symptoms compared to severe ones, and are\nmore difficult to detect and diagnose due to their close resemblance to normal\noperating conditions. The lack of incipient anomaly examples in the training\ndata can pose severe risks to anomaly detection methods that are built upon\nMachine Learning (ML) techniques, because these anomalies can be easily\nmistaken as normal operating conditions. To address this challenge, we propose\nto utilize the uncertainty information available from ensemble learning to\nidentify potential misclassified incipient anomalies. We show in this paper\nthat ensemble learning methods can give improved performance on incipient\nanomalies and identify common pitfalls in these models through extensive\nexperiments on two real-world datasets. Then, we discuss how to design more\neffective ensemble models for detecting incipient anomalies.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 00:03:09 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Tan", "Yingshui", ""], ["Jin", "Baihong", ""], ["Cui", "Qiushi", ""], ["Yue", "Xiangyu", ""], ["Vincentelli", "Alberto Sangiovanni", ""]]}, {"id": "2008.08718", "submitter": "Yaroslav Averyanov", "authors": "Yaroslav Averyanov and Alain Celisse", "title": "Minimum discrepancy principle strategy for choosing $k$ in $k$-NN\n  regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel data-driven strategy to choose the hyperparameter $k$ in\nthe $k$-NN regression estimator. We treat the problem of choosing the\nhyperparameter as an iterative procedure (over $k$) and propose using an easily\nimplemented in practice strategy based on the idea of early stopping and the\nminimum discrepancy principle. This model selection strategy is proven to be\nminimax-optimal, under the fixed-design assumption on covariates, over some\nsmoothness function classes, for instance, the Lipschitz functions class on a\nbounded domain. The novel method often improves statistical performance on\nartificial and real-world data sets in comparison to other model selection\nstrategies, such as the Hold-out method and 5-fold cross-validation. The\nnovelty of the strategy comes from reducing the computational time of the model\nselection procedure while preserving the statistical (minimax) optimality of\nthe resulting estimator. More precisely, given a sample of size $n$, assuming\nthat the nearest neighbors are already precomputed, if one should choose $k$\namong $\\left\\{ 1, \\ldots, n \\right\\}$, the strategy reduces the computational\ntime of the generalized cross-validation or Akaike's AIC criteria from\n$\\mathcal{O}\\left( n^3 \\right)$ to $\\mathcal{O}\\left( n^2 (n - k) \\right)$,\nwhere $k$ is the proposed (minimum discrepancy principle) value of the nearest\nneighbors. Code for the simulations is provided at\nhttps://github.com/YaroslavAveryanov/Minimum-discrepancy-principle-for-choosing-k.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 00:13:19 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 15:11:35 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 11:53:33 GMT"}, {"version": "v4", "created": "Wed, 5 May 2021 11:33:16 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Averyanov", "Yaroslav", ""], ["Celisse", "Alain", ""]]}, {"id": "2008.08727", "submitter": "Aparna Elangovan", "authors": "Aparna Elangovan, Melissa Davis and Karin Verspoor", "title": "Assigning function to protein-protein interactions: a weakly supervised\n  BioBERT based approach using PubMed abstracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Protein-protein interactions (PPI) are critical to the function\nof proteins in both normal and diseased cells, and many critical protein\nfunctions are mediated by interactions.Knowledge of the nature of these\ninteractions is important for the construction of networks to analyse\nbiological data. However, only a small percentage of PPIs captured in protein\ninteraction databases have annotations of function available, e.g. only 4% of\nPPI are functionally annotated in the IntAct database. Here, we aim to label\nthe function type of PPIs by extracting relationships described in PubMed\nabstracts.\n  Method: We create a weakly supervised dataset from the IntAct PPI database\ncontaining interacting protein pairs with annotated function and associated\nabstracts from the PubMed database. We apply a state-of-the-art deep learning\ntechnique for biomedical natural language processing tasks, BioBERT, to build a\nmodel - dubbed PPI-BioBERT - for identifying the function of PPIs. In order to\nextract high quality PPI functions at large scale, we use an ensemble of\nPPI-BioBERT models to improve uncertainty estimation and apply an interaction\ntype-specific threshold to counteract the effects of variations in the number\nof training samples per interaction type.\n  Results: We scan 18 million PubMed abstracts to automatically identify 3253\nnew typed PPIs, including phosphorylation and acetylation interactions, with an\noverall precision of 46% (87% for acetylation) based on a human-reviewed\nsample. This work demonstrates that analysis of biomedical abstracts for PPI\nfunction extraction is a feasible approach to substantially increasing the\nnumber of interactions annotated with function captured in online databases.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 01:42:28 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 09:57:29 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Elangovan", "Aparna", ""], ["Davis", "Melissa", ""], ["Verspoor", "Karin", ""]]}, {"id": "2008.08733", "submitter": "Zachary Feinstein", "authors": "Hamed Amini and Zachary Feinstein", "title": "Optimal Network Compression", "comments": "30 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a formulation of the optimal network compression\nproblem for financial systems. This general formulation is presented for\ndifferent levels of network compression or rerouting allowed from the initial\ninterbank network. We prove that this problem is, generically, NP-hard. We\nfocus on objective functions generated by systemic risk measures under\nsystematic shocks to the financial network. We conclude by studying the optimal\ncompression problem for specific networks; this permits us to study the\nso-called robust fragility of certain network topologies more generally as well\nas the potential benefits and costs of network compression. In particular,\nunder systematic shocks and heterogeneous financial networks the typical\nheuristics of robust fragility no longer hold generally.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 02:11:23 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2021 20:21:21 GMT"}, {"version": "v3", "created": "Thu, 8 Jul 2021 10:04:59 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Amini", "Hamed", ""], ["Feinstein", "Zachary", ""]]}, {"id": "2008.08734", "submitter": "Jing Lai", "authors": "Jing Lai, Junlin Xiong, Zhan Shu", "title": "Model-free optimal control of discrete-time systems with additive and\n  multiplicative noises", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the optimal control problem for a class of\ndiscrete-time stochastic systems subject to additive and multiplicative noises.\nA stochastic Lyapunov equation and a stochastic algebra Riccati equation are\nestablished for the existence of the optimal admissible control policy. A\nmodel-free reinforcement learning algorithm is proposed to learn the optimal\nadmissible control policy using the data of the system states and inputs\nwithout requiring any knowledge of the system matrices. It is proven that the\nlearning algorithm converges to the optimal admissible control policy. The\nimplementation of the model-free algorithm is based on batch least squares and\nnumerical average. The proposed algorithm is illustrated through a numerical\nexample, which shows our algorithm outperforms other policy iteration\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 02:18:00 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Lai", "Jing", ""], ["Xiong", "Junlin", ""], ["Shu", "Zhan", ""]]}, {"id": "2008.08743", "submitter": "Jiaying Liu", "authors": "Jiaying Liu, Tao Tang, Xiangjie Kong, Amr Tolba, Zafer AL-Makhadmeh,\n  Feng Xia", "title": "Understanding the Advisor-advisee Relationship via Scholarly Data\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advisor-advisee relationship is important in academic networks due to its\nuniversality and necessity. Despite the increasing desire to analyze the career\nof newcomers, however, the outcomes of different collaboration patterns between\nadvisors and advisees remain unknown. The purpose of this paper is to find out\nthe correlation between advisors' academic characteristics and advisees'\nacademic performance in Computer Science. Employing both quantitative and\nqualitative analysis, we find that with the increase of advisors' academic age,\nadvisees' performance experiences an initial growth, follows a sustaining\nstage, and finally ends up with a declining trend. We also discover the\nphenomenon that accomplished advisors can bring up skilled advisees. We explore\nthe conclusion from two aspects: (1) Advisees mentored by advisors with high\nacademic level have better academic performance than the rest; (2) Advisors\nwith high academic level can raise their advisees' h-index ranking. This work\nprovides new insights on promoting our understanding of the relationship\nbetween advisors' academic characteristics and advisees' performance, as well\nas on advisor choosing.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 02:57:25 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Liu", "Jiaying", ""], ["Tang", "Tao", ""], ["Kong", "Xiangjie", ""], ["Tolba", "Amr", ""], ["AL-Makhadmeh", "Zafer", ""], ["Xia", "Feng", ""]]}, {"id": "2008.08750", "submitter": "Sayed Kamaledin Ghiasi-Shirazi", "authors": "Ramin Zarei Sabzevar, Kamaledin Ghiasi-Shirazi, Ahad Harati", "title": "Prototype-based interpretation of the functionality of neurons in\n  winner-take-all neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prototype-based learning (PbL) using a winner-take-all (WTA) network based on\nminimum Euclidean distance (ED-WTA) is an intuitive approach to multiclass\nclassification. By constructing meaningful class centers, PbL provides higher\ninterpretability and generalization than hyperplane-based learning (HbL)\nmethods based on maximum Inner Product (IP-WTA) and can efficiently detect and\nreject samples that do not belong to any classes. In this paper, we first prove\nthe equivalence of IP-WTA and ED-WTA from a representational point of view.\nThen, we show that naively using this equivalence leads to unintuitive ED-WTA\nnetworks in which the centers have high distances to data that they represent.\nWe propose $\\pm$ED-WTA which models each neuron with two prototypes: one\npositive prototype representing samples that are modeled by this neuron and a\nnegative prototype representing the samples that are erroneously won by that\nneuron during training. We propose a novel training algorithm for the\n$\\pm$ED-WTA network, which cleverly switches between updating the positive and\nnegative prototypes and is essential to the emergence of interpretable\nprototypes. Unexpectedly, we observed that the negative prototype of each\nneuron is indistinguishably similar to the positive one. The rationale behind\nthis observation is that the training data that are mistaken with a prototype\nare indeed similar to it. The main finding of this paper is this interpretation\nof the functionality of neurons as computing the difference between the\ndistances to a positive and a negative prototype, which is in agreement with\nthe BCM theory. In our experiments, we show that the proposed $\\pm$ED-WTA\nmethod constructs highly interpretable prototypes that can be successfully used\nfor detecting outlier and adversarial examples.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 03:15:37 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Sabzevar", "Ramin Zarei", ""], ["Ghiasi-Shirazi", "Kamaledin", ""], ["Harati", "Ahad", ""]]}, {"id": "2008.08753", "submitter": "Chaochao Chen", "authors": "Chaochao Chen, Jun Zhou, Li Wang, Xibin Wu, Wenjing Fang, Jin Tan, Lei\n  Wang, Alex X. Liu, Hao Wang, Cheng Hong", "title": "When Homomorphic Encryption Marries Secret Sharing: Secure Large-Scale\n  Sparse Logistic Regression and Applications in Risk Control", "comments": "Accepted by KDD'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logistic Regression (LR) is the most widely used machine learning model in\nindustry for its efficiency, robustness, and interpretability. Due to the\nproblem of data isolation and the requirement of high model performance, many\napplications in industry call for building a secure and efficient LR model for\nmultiple parties. Most existing work uses either Homomorphic Encryption (HE) or\nSecret Sharing (SS) to build secure LR. HE based methods can deal with\nhigh-dimensional sparse features, but they incur potential security risks. SS\nbased methods have provable security, but they have efficiency issue under\nhigh-dimensional sparse features. In this paper, we first present CAESAR, which\ncombines HE and SS to build secure large-scale sparse logistic regression model\nand achieves both efficiency and security. We then present the distributed\nimplementation of CAESAR for scalability requirement. We have deployed CAESAR\nin a risk control task and conducted comprehensive experiments. Our\nexperimental results show that CAESAR improves the state-of-the-art model by\naround 130 times.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 03:26:51 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 08:50:25 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chen", "Chaochao", ""], ["Zhou", "Jun", ""], ["Wang", "Li", ""], ["Wu", "Xibin", ""], ["Fang", "Wenjing", ""], ["Tan", "Jin", ""], ["Wang", "Lei", ""], ["Liu", "Alex X.", ""], ["Wang", "Hao", ""], ["Hong", "Cheng", ""]]}, {"id": "2008.08755", "submitter": "Yihan Wang", "authors": "Yihan Wang, Huan Zhang, Hongge Chen, Duane Boning, Cho-Jui Hsieh", "title": "On $\\ell_p$-norm Robustness of Ensemble Stumps and Trees", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent papers have demonstrated that ensemble stumps and trees could be\nvulnerable to small input perturbations, so robustness verification and defense\nfor those models have become an important research problem. However, due to the\nstructure of decision trees, where each node makes decision purely based on one\nfeature value, all the previous works only consider the $\\ell_\\infty$ norm\nperturbation. To study robustness with respect to a general $\\ell_p$ norm\nperturbation, one has to consider the correlation between perturbations on\ndifferent features, which has not been handled by previous algorithms. In this\npaper, we study the problem of robustness verification and certified defense\nwith respect to general $\\ell_p$ norm perturbations for ensemble decision\nstumps and trees. For robustness verification of ensemble stumps, we prove that\ncomplete verification is NP-complete for $p\\in(0, \\infty)$ while polynomial\ntime algorithms exist for $p=0$ or $\\infty$. For $p\\in(0, \\infty)$ we develop\nan efficient dynamic programming based algorithm for sound verification of\nensemble stumps. For ensemble trees, we generalize the previous multi-level\nrobustness verification algorithm to $\\ell_p$ norm. We demonstrate the first\ncertified defense method for training ensemble stumps and trees with respect to\n$\\ell_p$ norm perturbations, and verify its effectiveness empirically on real\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 03:42:40 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 06:13:02 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Wang", "Yihan", ""], ["Zhang", "Huan", ""], ["Chen", "Hongge", ""], ["Boning", "Duane", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2008.08756", "submitter": "Dahuin Jung", "authors": "Dahuin Jung, Jonghyun Lee, Jihun Yi, and Sungroh Yoon", "title": "iCaps: An Interpretable Classifier via Disentangled Capsule Networks", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an interpretable Capsule Network, iCaps, for image classification.\nA capsule is a group of neurons nested inside each layer, and the one in the\nlast layer is called a class capsule, which is a vector whose norm indicates a\npredicted probability for the class. Using the class capsule, existing Capsule\nNetworks already provide some level of interpretability. However, there are two\nlimitations which degrade its interpretability: 1) the class capsule also\nincludes classification-irrelevant information, and 2) entities represented by\nthe class capsule overlap. In this work, we address these two limitations using\na novel class-supervised disentanglement algorithm and an additional\nregularizer, respectively. Through quantitative and qualitative evaluations on\nthree datasets, we demonstrate that the resulting classifier, iCaps, provides a\nprediction along with clear rationales behind it with no performance\ndegradation.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 03:44:26 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Jung", "Dahuin", ""], ["Lee", "Jonghyun", ""], ["Yi", "Jihun", ""], ["Yoon", "Sungroh", ""]]}, {"id": "2008.08757", "submitter": "Jonathan Scarlett", "authors": "Xu Cai and Jonathan Scarlett", "title": "On Lower Bounds for Standard and Robust Gaussian Process Bandit\n  Optimization", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider algorithm-independent lower bounds for the problem\nof black-box optimization of functions having a bounded norm is some\nReproducing Kernel Hilbert Space (RKHS), which can be viewed as a non-Bayesian\nGaussian process bandit problem. In the standard noisy setting, we provide a\nnovel proof technique for deriving lower bounds on the regret, with benefits\nincluding simplicity, versatility, and an improved dependence on the error\nprobability. In a robust setting in which every sampled point may be perturbed\nby a suitably-constrained adversary, we provide a novel lower bound for\ndeterministic strategies, demonstrating an inevitable joint dependence of the\ncumulative regret on the corruption level and the time horizon, in contrast\nwith existing lower bounds that only characterize the individual dependencies.\nFurthermore, in a distinct robust setting in which the final point is perturbed\nby an adversary, we strengthen an existing lower bound that only holds for\ntarget success probabilities very close to one, by allowing for arbitrary\nsuccess probabilities above $\\frac{2}{3}$.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 03:48:14 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 08:52:07 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Cai", "Xu", ""], ["Scarlett", "Jonathan", ""]]}, {"id": "2008.08766", "submitter": "Prarthana Bhattacharyya", "authors": "Prarthana Bhattacharyya and Krzysztof Czarnecki", "title": "Deformable PV-RCNN: Improving 3D Object Detection with Learned\n  Deformations", "comments": "Accepted at ECCV 2020 Workshop on Perception for Autonomous Driving", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Deformable PV-RCNN, a high-performing point-cloud based 3D object\ndetector. Currently, the proposal refinement methods used by the\nstate-of-the-art two-stage detectors cannot adequately accommodate differing\nobject scales, varying point-cloud density, part-deformation and clutter. We\npresent a proposal refinement module inspired by 2D deformable convolution\nnetworks that can adaptively gather instance-specific features from locations\nwhere informative content exists. We also propose a simple context gating\nmechanism which allows the keypoints to select relevant context information for\nthe refinement stage. We show state-of-the-art results on the KITTI dataset.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 04:11:17 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Bhattacharyya", "Prarthana", ""], ["Czarnecki", "Krzysztof", ""]]}, {"id": "2008.08808", "submitter": "Zhou Tianze", "authors": "Tianze Zhou, Fubiao Zhang, Pan Tang, Chenfei Wang", "title": "BGC: Multi-Agent Group Belief with Graph Clustering", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances have witnessed that value decomposed-based multi-agent\nreinforcement learning methods make an efficient performance in coordination\ntasks. Most current methods assume that agents can make communication to assist\ndecisions, which is impractical in some situations. In this paper, we propose a\nsemi-communication method to enable agents can exchange information without\ncommunication. Specifically, we introduce a group concept to help agents\nlearning a belief which is a type of consensus. With this consensus, adjacent\nagents tend to accomplish similar sub-tasks to achieve cooperation. We design a\nnovel agent structure named Belief in Graph Clustering(BGC), composed of an\nagent characteristic module, a belief module, and a fusion module. To represent\neach agent characteristic, we use an MLP-based characteristic module to\ngenerate agent unique features. Inspired by the neighborhood cognitive\nconsistency, we propose a group-based module to divide adjacent agents into a\nsmall group and minimize in-group agents' beliefs to accomplish similar\nsub-tasks. Finally, we use a hyper-network to merge these features and produce\nagent actions. To overcome the agent consistent problem brought by GAT, a split\nloss is introduced to distinguish different agents. Results reveal that the\nproposed method achieves a significant improvement in the SMAC benchmark.\nBecause of the group concept, our approach maintains excellent performance with\nan increase in the number of agents.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 07:07:20 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 02:34:43 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 06:46:08 GMT"}, {"version": "v4", "created": "Thu, 3 Jun 2021 09:21:33 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Zhou", "Tianze", ""], ["Zhang", "Fubiao", ""], ["Tang", "Pan", ""], ["Wang", "Chenfei", ""]]}, {"id": "2008.08817", "submitter": "Haiyue Zhu", "authors": "Haiyue Zhu, Yiting Li, Fengjun Bai, Wenjie Chen, Xiaocong Li, Jun Ma,\n  Chek Sing Teo, Pey Yuen Tao, and Wei Lin", "title": "Grasping Detection Network with Uncertainty Estimation for\n  Confidence-Driven Semi-Supervised Domain Adaptation", "comments": "6 pages, 7 figures, accepted in IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-efficient domain adaptation with only a few labelled data is desired for\nmany robotic applications, e.g., in grasping detection, the inference skill\nlearned from a grasping dataset is not universal enough to directly apply on\nvarious other daily/industrial applications. This paper presents an approach\nenabling the easy domain adaptation through a novel grasping detection network\nwith confidence-driven semi-supervised learning, where these two components\ndeeply interact with each other. The proposed grasping detection network\nspecially provides a prediction uncertainty estimation mechanism by leveraging\non Feature Pyramid Network (FPN), and the mean-teacher semi-supervised learning\nutilizes such uncertainty information to emphasizing the consistency loss only\nfor those unlabelled data with high confidence, which we referred it as the\nconfidence-driven mean teacher. This approach largely prevents the student\nmodel to learn the incorrect/harmful information from the consistency loss,\nwhich speeds up the learning progress and improves the model accuracy. Our\nresults show that the proposed network can achieve high success rate on the\nCornell grasping dataset, and for domain adaptation with very limited data, the\nconfidence-driven mean teacher outperforms the original mean teacher and direct\ntraining by more than 10% in evaluation loss especially for avoiding the\noverfitting and model diverging.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 07:42:45 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Zhu", "Haiyue", ""], ["Li", "Yiting", ""], ["Bai", "Fengjun", ""], ["Chen", "Wenjie", ""], ["Li", "Xiaocong", ""], ["Ma", "Jun", ""], ["Teo", "Chek Sing", ""], ["Tao", "Pey Yuen", ""], ["Lin", "Wei", ""]]}, {"id": "2008.08818", "submitter": "DuongNguyen Nguyen", "authors": "Duong-Nguyen Nguyen, Tien-Lam Pham, Viet-Cuong Nguyen, Hiori Kino,\n  Takashi Miyake, Hieu-Chi Dam", "title": "Ensemble learning reveals dissimilarity between rare-earth transition\n  metal binary alloys with respect to the Curie temperature", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a data-driven method to extract dissimilarity between materials,\nwith respect to a given target physical property. The technique is based on an\nensemble method with Kernel ridge regression as the predicting model; multiple\nrandom subset sampling of the materials is done to generate prediction models\nand the corresponding contributions of the reference training materials in\ndetail. The distribution of the predicted values for each material can be\napproximated by a Gaussian mixture model. The reference training materials\ncontributed to the prediction model that accurately predicts the physical\nproperty value of a specific material, are considered to be similar to that\nmaterial, or vice versa. Evaluations using synthesized data demonstrate that\nthe proposed method can effectively measure the dissimilarity between data\ninstances. An application of the analysis method on the data of Curie\ntemperature (TC) of binary 3d transition metal 4f rare earth binary alloys also\nreveals meaningful results on the relations between the materials. The proposed\nmethod can be considered as a potential tool for obtaining a deeper\nunderstanding of the structure of data, with respect to a target property, in\nparticular.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 07:46:09 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Nguyen", "Duong-Nguyen", ""], ["Pham", "Tien-Lam", ""], ["Nguyen", "Viet-Cuong", ""], ["Kino", "Hiori", ""], ["Miyake", "Takashi", ""], ["Dam", "Hieu-Chi", ""]]}, {"id": "2008.08838", "submitter": "Sitao Luan", "authors": "Sitao Luan, Mingde Zhao, Xiao-Wen Chang, Doina Precup", "title": "Training Matters: Unlocking Potentials of Deeper Graph Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance limit of Graph Convolutional Networks (GCNs) and the fact\nthat we cannot stack more of them to increase the performance, which we usually\ndo for other deep learning paradigms, are pervasively thought to be caused by\nthe limitations of the GCN layers, including insufficient expressive power,\netc. However, if so, for a fixed architecture, it would be unlikely to lower\nthe training difficulty and to improve performance by changing only the\ntraining procedure, which we show in this paper not only possible but possible\nin several ways. This paper first identify the training difficulty of GCNs from\nthe perspective of graph signal energy loss. More specifically, we find that\nthe loss of energy in the backward pass during training nullifies the learning\nof the layers closer to the input. Then, we propose several methodologies to\nmitigate the training problem by slightly modifying the GCN operator, from the\nenergy perspective. After empirical validation, we confirm that these changes\nof operator lead to significant decrease in the training difficulties and\nnotable performance boost, without changing the composition of parameters. With\nthese, we conclude that the root cause of the problem is more likely the\ntraining difficulty than the others.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 08:36:27 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Luan", "Sitao", ""], ["Zhao", "Mingde", ""], ["Chang", "Xiao-Wen", ""], ["Precup", "Doina", ""]]}, {"id": "2008.08840", "submitter": "Zachary Baum", "authors": "Zachary M C Baum, Ester Bonmati, Lorenzo Cristoni, Andrew Walden,\n  Ferran Prados, Baris Kanber, Dean C Barratt, David J Hawkes, Geoffrey J M\n  Parker, Claudia A M Gandini Wheeler-Kingshott, Yipeng Hu", "title": "Image quality assessment for closed-loop computer-assisted lung\n  ultrasound", "comments": "7 pages, 3 figures - Accepted to SPIE Medical Imaging 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel, two-stage computer assistance system for lung anomaly\ndetection using ultrasound imaging in the intensive care setting to improve\noperator performance and patient stratification during coronavirus pandemics.\nThe proposed system consists of two deep-learning-based models: a quality\nassessment module that automates predictions of image quality, and a diagnosis\nassistance module that determines the likelihood-oh-anomaly in ultrasound\nimages of sufficient quality. Our two-stage strategy uses a novelty detection\nalgorithm to address the lack of control cases available for training the\nquality assessment classifier. The diagnosis assistance module can then be\ntrained with data that are deemed of sufficient quality, guaranteed by the\nclosed-loop feedback mechanism from the quality assessment module. Using more\nthan 25000 ultrasound images from 37 COVID-19-positive patients scanned at two\nhospitals, plus 12 control cases, this study demonstrates the feasibility of\nusing the proposed machine learning approach. We report an accuracy of 86% when\nclassifying between sufficient and insufficient quality images by the quality\nassessment module. For data of sufficient quality - as determined by the\nquality assessment module - the mean classification accuracy, sensitivity, and\nspecificity in detecting COVID-19-positive cases were 0.95, 0.91, and 0.97,\nrespectively, across five holdout test data sets unseen during the training of\nany networks within the proposed system. Overall, the integration of the two\nmodules yields accurate, fast, and practical acquisition guidance and\ndiagnostic assistance for patients with suspected respiratory conditions at\npoint-of-care.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 08:38:05 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 10:48:04 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Baum", "Zachary M C", ""], ["Bonmati", "Ester", ""], ["Cristoni", "Lorenzo", ""], ["Walden", "Andrew", ""], ["Prados", "Ferran", ""], ["Kanber", "Baris", ""], ["Barratt", "Dean C", ""], ["Hawkes", "David J", ""], ["Parker", "Geoffrey J M", ""], ["Wheeler-Kingshott", "Claudia A M Gandini", ""], ["Hu", "Yipeng", ""]]}, {"id": "2008.08844", "submitter": "Sitao Luan", "authors": "Sitao Luan, Mingde Zhao, Chenqing Hua, Xiao-Wen Chang, Doina Precup", "title": "Complete the Missing Half: Augmenting Aggregation Filtering with\n  Diversification for Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The core operation of current Graph Neural Networks (GNNs) is the aggregation\nenabled by the graph Laplacian or message passing, which filters the\nneighborhood node information. Though effective for various tasks, in this\npaper, we show that they are potentially a problematic factor underlying all\nGNN methods for learning on certain datasets, as they force the node\nrepresentations similar, making the nodes gradually lose their identity and\nbecome indistinguishable. Hence, we augment the aggregation operations with\ntheir dual, i.e. diversification operators that make the node more distinct and\npreserve the identity. Such augmentation replaces the aggregation with a\ntwo-channel filtering process that, in theory, is beneficial for enriching the\nnode representations. In practice, the proposed two-channel filters can be\neasily patched on existing GNN methods with diverse training strategies,\nincluding spectral and spatial (message passing) methods. In the experiments,\nwe observe desired characteristics of the models and significant performance\nboost upon the baselines on 9 node classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 08:45:16 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 23:21:11 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 20:25:09 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Luan", "Sitao", ""], ["Zhao", "Mingde", ""], ["Hua", "Chenqing", ""], ["Chang", "Xiao-Wen", ""], ["Precup", "Doina", ""]]}, {"id": "2008.08857", "submitter": "Maciej Skorski", "authors": "Maciej Skorski", "title": "Simple Analysis of Johnson-Lindenstrauss Transform under Neuroscience\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper re-analyzes a version of the celebrated Johnson-Lindenstrauss\nLemma, in which matrices are subjected to constraints that naturally emerge\nfrom neuroscience applications: a) sparsity and b) sign-consistency. This\nparticular variant was studied first by Allen-Zhu, Gelashvili, Micali, Shavit\nand more recently by Jagadeesan (RANDOM'19).\n  The contribution of this work is a novel proof, which in contrast to previous\nworks a) uses the modern probability toolkit, particularly basics of\nsub-gaussian and sub-gamma estimates b) is self-contained, with no dependencies\non subtle third-party results c) offers explicit constants.\n  At the heart of our proof is a novel variant of Hanson-Wright Lemma (on\nconcentration of quadratic forms). Of independent interest are also auxiliary\nfacts on sub-gaussian random variables.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 09:31:52 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Skorski", "Maciej", ""]]}, {"id": "2008.08871", "submitter": "Aydogan Ozcan", "authors": "Kevin de Haan, Yijie Zhang, Tairan Liu, Anthony E. Sisk, Miguel F. P.\n  Diaz, Jonathan E. Zuckerman, Yair Rivenson, W. Dean Wallace, Aydogan Ozcan", "title": "Deep learning-based transformation of the H&E stain into special stains\n  improves kidney disease diagnosis", "comments": "22 Pages, 5 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pathology is practiced by visual inspection of histochemically stained\nslides. Most commonly, the hematoxylin and eosin (H&E) stain is used in the\ndiagnostic workflow and it is the gold standard for cancer diagnosis. However,\nin many cases, especially for non-neoplastic diseases, additional \"special\nstains\" are used to provide different levels of contrast and color to tissue\ncomponents and allow pathologists to get a clearer diagnostic picture. In this\nstudy, we demonstrate the utility of supervised learning-based computational\nstain transformation from H&E to different special stains (Masson's Trichrome,\nperiodic acid-Schiff and Jones silver stain) using tissue sections from kidney\nneedle core biopsies. Based on evaluation by three renal pathologists, followed\nby adjudication by a fourth renal pathologist, we show that the generation of\nvirtual special stains from existing H&E images improves the diagnosis in\nseveral non-neoplastic kidney diseases, sampled from 16 unique subjects.\nAdjudication of N=48 diagnoses from the three pathologists revealed that the\nvirtually generated special stains yielded 22 improvements (45.8%), 23\nconcordances (47.9%) and 3 discordances (6.3%), when compared against the use\nof H&E stained tissue only. As the virtual transformation of H&E images into\nspecial stains can be achieved in less than 1 min per patient core specimen\nslide, this stain-to-stain transformation framework can improve the quality of\nthe preliminary diagnosis when additional special stains are needed, along with\nsignificant savings in time and cost, reducing the burden on healthcare system\nand patients.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 10:12:03 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["de Haan", "Kevin", ""], ["Zhang", "Yijie", ""], ["Liu", "Tairan", ""], ["Sisk", "Anthony E.", ""], ["Diaz", "Miguel F. P.", ""], ["Zuckerman", "Jonathan E.", ""], ["Rivenson", "Yair", ""], ["Wallace", "W. Dean", ""], ["Ozcan", "Aydogan", ""]]}, {"id": "2008.08878", "submitter": "Satheesh Kumar Perepu", "authors": "Satheesh K. Perepu, Bala Shyamala Balaji, Hemanth Kumar Tanneru,\n  Sudhakar Kathari, Vivek Shankar Pinnamaraju", "title": "Reinforcement Learning based dynamic weighing of Ensemble Models for\n  Time Series Forecasting", "comments": "6 pages, 4 figures, In review for conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble models are powerful model building tools that are developed with a\nfocus to improve the accuracy of model predictions. They find applications in\ntime series forecasting in varied scenarios including but not limited to\nprocess industries, health care, and economics where a single model might not\nprovide optimal performance. It is known that if models selected for data\nmodelling are distinct (linear/non-linear, static/dynamic) and independent\n(minimally correlated models), the accuracy of the predictions is improved.\nVarious approaches suggested in the literature to weigh the ensemble models use\na static set of weights. Due to this limitation, approaches using a static set\nof weights for weighing ensemble models cannot capture the dynamic changes or\nlocal features of the data effectively. To address this issue, a Reinforcement\nLearning (RL) approach to dynamically assign and update weights of each of the\nmodels at different time instants depending on the nature of data and the\nindividual model predictions is proposed in this work. The RL method\nimplemented online, essentially learns to update the weights and reduce the\nerrors as the time progresses. Simulation studies on time series data showed\nthat the dynamic weighted approach using RL learns the weight better than\nexisting approaches. The accuracy of the proposed method is compared with an\nexisting approach of online Neural Network tuning quantitatively through\nnormalized mean square error(NMSE) values.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 10:40:42 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Perepu", "Satheesh K.", ""], ["Balaji", "Bala Shyamala", ""], ["Tanneru", "Hemanth Kumar", ""], ["Kathari", "Sudhakar", ""], ["Pinnamaraju", "Vivek Shankar", ""]]}, {"id": "2008.08879", "submitter": "Md Kamrul Islam", "authors": "Md Kamrul Islam and Sabeur Aridhi and Malika Smail-Tabbone", "title": "A comparative study of similarity-based and GNN-based link prediction\n  approaches", "comments": "GEM Workshop, ECML-PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of inferring the missing links in a graph based on its current\nstructure is referred to as link prediction. Link prediction methods that are\nbased on pairwise node similarity are well-established approaches in the\nliterature. They show good prediction performance in many real-world graphs\nthough they are heuristics and lack of universal applicability. On the other\nhand, the success of neural networks for classification tasks in various\ndomains leads researchers to study them in graphs. When a neural network can\noperate directly on the graph, then it is termed as the graph neural network\n(GNN). GNN is able to learn hidden features from graphs which can be used for\nlink prediction task in graphs. Link predictions based on GNNs have gained much\nattention of researchers due to their convincing high performance in many\nreal-world graphs. This appraisal paper studies some similarity and GNN-based\nlink prediction approaches in the domain of homogeneous graphs that consists of\na single type of (attributed) nodes and single type of pairwise links. We\nevaluate the studied approaches against several benchmark graphs with different\nproperties from various domains.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 10:41:53 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Islam", "Md Kamrul", ""], ["Aridhi", "Sabeur", ""], ["Smail-Tabbone", "Malika", ""]]}, {"id": "2008.08882", "submitter": "Jaehoon Oh", "authors": "Jaehoon Oh, Hyungjun Yoo, ChangHwan Kim, Se-Young Yun", "title": "BOIL: Towards Representation Change for Few-shot Learning", "comments": "24 pages, 26 figures, 19 tables, ICLR 2021 published", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model Agnostic Meta-Learning (MAML) is one of the most representative of\ngradient-based meta-learning algorithms. MAML learns new tasks with a few data\nsamples using inner updates from a meta-initialization point and learns the\nmeta-initialization parameters with outer updates. It has recently been\nhypothesized that representation reuse, which makes little change in efficient\nrepresentations, is the dominant factor in the performance of the\nmeta-initialized model through MAML in contrast to representation change, which\ncauses a significant change in representations. In this study, we investigate\nthe necessity of representation change for the ultimate goal of few-shot\nlearning, which is solving domain-agnostic tasks. To this aim, we propose a\nnovel meta-learning algorithm, called BOIL (Body Only update in Inner Loop),\nwhich updates only the body (extractor) of the model and freezes the head\n(classifier) during inner loop updates. BOIL leverages representation change\nrather than representation reuse. This is because feature vectors\n(representations) have to move quickly to their corresponding frozen head\nvectors. We visualize this property using cosine similarity, CKA, and empirical\nresults without the head. BOIL empirically shows significant performance\nimprovement over MAML, particularly on cross-domain tasks. The results imply\nthat representation change in gradient-based meta-learning approaches is a\ncritical component.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 10:52:23 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 05:16:52 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Oh", "Jaehoon", ""], ["Yoo", "Hyungjun", ""], ["Kim", "ChangHwan", ""], ["Yun", "Se-Young", ""]]}, {"id": "2008.08885", "submitter": "Sayak Ray Chowdhury", "authors": "Sayak Ray Chowdhury, Aditya Gopalan", "title": "No-regret Algorithms for Multi-task Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider multi-objective optimization (MOO) of an unknown vector-valued\nfunction in the non-parametric Bayesian optimization (BO) setting, with the aim\nbeing to learn points on the Pareto front of the objectives. Most existing BO\nalgorithms do not model the fact that the multiple objectives, or equivalently,\ntasks can share similarities, and even the few that do lack rigorous,\nfinite-time regret guarantees that capture explicitly inter-task structure. In\nthis work, we address this problem by modelling inter-task dependencies using a\nmulti-task kernel and develop two novel BO algorithms based on random\nscalarizations of the objectives. Our algorithms employ vector-valued kernel\nregression as a stepping stone and belong to the upper confidence bound class\nof algorithms. Under a smoothness assumption that the unknown vector-valued\nfunction is an element of the reproducing kernel Hilbert space associated with\nthe multi-task kernel, we derive worst-case regret bounds for our algorithms\nthat explicitly capture the similarities between tasks. We numerically\nbenchmark our algorithms on both synthetic and real-life MOO problems, and show\nthe advantages offered by learning with multi-task kernels.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 10:55:20 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Chowdhury", "Sayak Ray", ""], ["Gopalan", "Aditya", ""]]}, {"id": "2008.08891", "submitter": "Karen Craigie Miss", "authors": "K. Craigie, E. M. Gauger, Y. Altmann, C. Bonato (School of Engineering\n  and Physical Sciences, SUPA, Heriot-Watt University, Edinburgh, UK)", "title": "Resource-efficient adaptive Bayesian tracking of magnetic fields with a\n  quantum sensor", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": "10.1088/1361-648X/abe34f", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-spin quantum sensors, for example based on nitrogen-vacancy centres in\ndiamond, provide nanoscale mapping of magnetic fields. In applications where\nthe magnetic field may be changing rapidly, total sensing time is crucial and\nmust be minimised. Bayesian estimation and adaptive experiment optimisation can\nspeed up the sensing process by reducing the number of measurements required.\nThese protocols consist of computing and updating the probability distribution\nof the magnetic field based on measurement outcomes and of determining\noptimized acquisition settings for the next measurement. However, the\ncomputational steps feeding into the measurement settings of the next iteration\nmust be performed quickly enough to allow for real-time updates. This article\naddresses the issue of computational speed by implementing an approximate\nBayesian estimation technique, where probability distributions are approximated\nby a finite sum of Gaussian functions. Given that only three parameters are\nrequired to fully describe a Gaussian density, we find that in many cases, the\nmagnetic field probability distribution can be described by fewer than ten\nparameters, achieving a reduction in computation time by factor 10 compared to\nexisting approaches. For T2* = 1 micro second, only a small decrease in\ncomputation time is achieved. However, in these regimes, the proposed Gaussian\nprotocol outperforms the existing one in tracking accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 11:04:09 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 16:45:31 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Craigie", "K.", "", "School of Engineering\n  and Physical Sciences, SUPA, Heriot-Watt University, Edinburgh, UK"], ["Gauger", "E. M.", "", "School of Engineering\n  and Physical Sciences, SUPA, Heriot-Watt University, Edinburgh, UK"], ["Altmann", "Y.", "", "School of Engineering\n  and Physical Sciences, SUPA, Heriot-Watt University, Edinburgh, UK"], ["Bonato", "C.", "", "School of Engineering\n  and Physical Sciences, SUPA, Heriot-Watt University, Edinburgh, UK"]]}, {"id": "2008.08894", "submitter": "Tsuyoshi Kato", "authors": "Kenya Tajima, Yoshihiro Hirohashi, Esmeraldo Ronnie Rey Zara, Tsuyoshi\n  Kato", "title": "Frank-Wolfe algorithm for learning SVM-type multi-category classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-category support vector machine (MC-SVM) is one of the most popular\nmachine learning algorithms. There are lots of variants of MC-SVM, although\ndifferent optimization algorithms were developed for different learning\nmachines. In this study, we developed a new optimization algorithm that can be\napplied to many of MC-SVM variants. The algorithm is based on the Frank-Wolfe\nframework that requires two subproblems, direction finding and line search, in\neach iteration. The contribution of this study is the discovery that both\nsubproblems have a closed form solution if the Frank-Wolfe framework is applied\nto the dual problem. Additionally, the closed form solutions on both for the\ndirection finding and for the line search exist even for the Moreau envelopes\nof the loss functions. We use several large datasets to demonstrate that the\nproposed optimization algorithm converges rapidly and thereby improves the\npattern recognition performance.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 11:19:07 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Tajima", "Kenya", ""], ["Hirohashi", "Yoshihiro", ""], ["Zara", "Esmeraldo Ronnie Rey", ""], ["Kato", "Tsuyoshi", ""]]}, {"id": "2008.08903", "submitter": "Nan Gao", "authors": "Nan Gao, Hao Xue, Wei Shao, Sichen Zhao, Kyle Kai Qin, Arian Prabowo,\n  Mohammad Saiedur Rahaman, Flora D. Salim", "title": "Generative Adversarial Networks for Spatio-temporal Data: A Survey", "comments": "This paper has been accepted by ACM Transactions on Intelligent\n  Systems and Technology (TIST)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have shown remarkable success in\nproducing realistic-looking images in the computer vision area. Recently,\nGAN-based techniques are shown to be promising for spatio-temporal-based\napplications such as trajectory prediction, events generation and time-series\ndata imputation. While several reviews for GANs in computer vision have been\npresented, no one has considered addressing the practical applications and\nchallenges relevant to spatio-temporal data. In this paper, we have conducted a\ncomprehensive review of the recent developments of GANs for spatio-temporal\ndata. We summarise the application of popular GAN architectures for\nspatio-temporal data and the common practices for evaluating the performance of\nspatio-temporal applications with GANs. Finally, we point out future research\ndirections to benefit researchers in this area.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 11:05:40 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 01:30:20 GMT"}, {"version": "v3", "created": "Wed, 30 Jun 2021 06:01:17 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Gao", "Nan", ""], ["Xue", "Hao", ""], ["Shao", "Wei", ""], ["Zhao", "Sichen", ""], ["Qin", "Kyle Kai", ""], ["Prabowo", "Arian", ""], ["Rahaman", "Mohammad Saiedur", ""], ["Salim", "Flora D.", ""]]}, {"id": "2008.08912", "submitter": "Hrithwik Shalu", "authors": "Hrithwik Shalu, Harikrishnan P, Akash Das, Megdut Mandal,\n  Harshavardhan M Sali, Juned Kadiwala", "title": "A Data-Efficient Deep Learning Based Smartphone Application For\n  Detection Of Pulmonary Diseases Using Chest X-rays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a paradigm of smartphone application based disease\ndiagnostics that may completely revolutionise the way healthcare services are\nbeing provided. Although primarily aimed to assist the problems in rendering\nthe healthcare services during the coronavirus pandemic, the model can also be\nextended to identify the exact disease that the patient is caught with from a\nbroad spectrum of pulmonary diseases. The app inputs Chest X-Ray images\ncaptured from the mobile camera which is then relayed to the AI architecture in\na cloud platform, and diagnoses the disease with state of the art accuracy.\nDoctors with a smartphone can leverage the application to save the considerable\ntime that standard COVID-19 tests take for preliminary diagnosis. The scarcity\nof training data and class imbalance issues were effectively tackled in our\napproach by the use of Data Augmentation Generative Adversarial Network (DAGAN)\nand model architecture based as a Convolutional Siamese Network with attention\nmechanism. The backend model was tested for robustness us-ing publicly\navailable datasets under two different classification\nscenarios(Binary/Multiclass) with minimal and noisy data. The model achieved\npinnacle testing accuracy of 99.30% and 98.40% on the two respective scenarios,\nmaking it completely reliable for its users. On top of that a semi-live\ntraining scenario was introduced, which helps improve the app performance over\ntime as data accumulates. Overall, the problems of generalisability of complex\nmodels and data inefficiency is tackled through the model architecture. The app\nbased setting with semi live training helps in ease of access to reliable\nhealthcare in the society, as well as help ineffective research of rare\ndiseases in a minimal data setting.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 04:28:17 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Shalu", "Hrithwik", ""], ["P", "Harikrishnan", ""], ["Das", "Akash", ""], ["Mandal", "Megdut", ""], ["Sali", "Harshavardhan M", ""], ["Kadiwala", "Juned", ""]]}, {"id": "2008.08915", "submitter": "Yikai Wang", "authors": "Yikai Wang and Ying Guo", "title": "LOCUS: A Novel Decomposition Method for Brain Network Connectivity\n  Matrices using Low-rank Structure with Uniform Sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network-oriented research has been increasingly popular in many scientific\nareas. In neuroscience research, imaging-based network connectivity measures\nhave become the key for understanding brain organizations, potentially serving\nas individual neural fingerprints. There are major challenges in analyzing\nconnectivity matrices including the high dimensionality of brain networks,\nunknown latent sources underlying the observed connectivity, and the large\nnumber of brain connections leading to spurious findings. In this paper, we\npropose a novel blind source separation method with low-rank structure and\nuniform sparsity (LOCUS) as a fully data-driven decomposition method for\nnetwork measures. Compared with the existing method that vectorizes\nconnectivity matrices ignoring brain network topology, LOCUS achieves more\nefficient and accurate source separation for connectivity matrices using\nlow-rank structure. We propose a novel angle-based uniform sparsity\nregularization that demonstrates better performance than the existing sparsity\ncontrols for low-rank tensor methods. We propose a highly efficient iterative\nNode-Rotation algorithm that exploits the block multi-convexity of the\nobjective function to solve the non-convex optimization problem for learning\nLOCUS. We illustrate the advantage of LOCUS through extensive simulation\nstudies. Application of LOCUS to Philadelphia Neurodevelopmental Cohort\nneuroimaging study reveals biologically insightful connectivity traits which\nare not found using the existing method.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 05:47:12 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Wang", "Yikai", ""], ["Guo", "Ying", ""]]}, {"id": "2008.08919", "submitter": "Wissam Maamar Kouadri", "authors": "Wissam Maamar Kouadri, Salima Benbernou, Mourad Ouziri, Themis\n  Palpanas, Iheb Ben Amor", "title": "SentiQ: A Probabilistic Logic Approach to Enhance Sentiment Analysis\n  Tool Quality", "comments": "In Proceedings of the 9th KDD Workshop on Issues of Sentiment\n  Discovery and Opinion Mining (WISDOM 20). San Diego, CA, USA, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The opinion expressed in various Web sites and social-media is an essential\ncontributor to the decision making process of several organizations. Existing\nsentiment analysis tools aim to extract the polarity (i.e., positive, negative,\nneutral) from these opinionated contents. Despite the advance of the research\nin the field, sentiment analysis tools give \\textit{inconsistent} polarities,\nwhich is harmful to business decisions. In this paper, we propose SentiQ, an\nunsupervised Markov logic Network-based approach that injects the semantic\ndimension in the tools through rules. It allows to detect and solve\ninconsistencies and then improves the overall accuracy of the tools.\nPreliminary experimental results demonstrate the usefulness of SentiQ.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 14:30:00 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Kouadri", "Wissam Maamar", ""], ["Benbernou", "Salima", ""], ["Ouziri", "Mourad", ""], ["Palpanas", "Themis", ""], ["Amor", "Iheb Ben", ""]]}, {"id": "2008.08920", "submitter": "Lucca Portes Cavalheiro", "authors": "Lucca Portes Cavalheiro, Jean Paul Barddal, Alceu de Souza Britto Jr,\n  Laurent Heutte", "title": "scikit-dyn2sel -- A Dynamic Selection Framework for Data Streams", "comments": "Paper introducing scikit-dyn2sel, a dynamic selection framework for\n  data streams", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining data streams is a challenge per se. It must be ready to deal with an\nenormous amount of data and with problems not present in batch machine\nlearning, such as concept drift. Therefore, applying a batch-designed\ntechnique, such as dynamic selection of classifiers (DCS) also presents a\nchallenge. The dynamic characteristic of ensembles that deal with streams\npresents barriers to the application of traditional DCS techniques in such\nclassifiers. scikit-dyn2sel is an open-source python library tailored for\ndynamic selection techniques in streaming data. scikit-dyn2sel's development\nfollows code quality and testing standards, including PEP8 compliance and\nautomated high test coverage using codecov.io and circleci.com. Source code,\ndocumentation, and examples are made available on GitHub at\nhttps://github.com/luccaportes/Scikit-DYN2SEL.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 13:48:32 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Cavalheiro", "Lucca Portes", ""], ["Barddal", "Jean Paul", ""], ["Britto", "Alceu de Souza", "Jr"], ["Heutte", "Laurent", ""]]}, {"id": "2008.08927", "submitter": "M. Umut Isik", "authors": "Wayne Chi, Prachi Kumar, Suri Yaddanapudi, Rahul Suresh, Umut Isik", "title": "Generating Music with a Self-Correcting Non-Chronological Autoregressive\n  Model", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel approach for generating music using a self-correcting,\nnon-chronological, autoregressive model. We represent music as a sequence of\nedit events, each of which denotes either the addition or removal of a\nnote---even a note previously generated by the model. During inference, we\ngenerate one edit event at a time using direct ancestral sampling. Our approach\nallows the model to fix previous mistakes such as incorrectly sampled notes and\nprevent accumulation of errors which autoregressive models are prone to have.\nAnother benefit is a finer, note-by-note control during human and AI\ncollaborative composition. We show through quantitative metrics and human\nsurvey evaluation that our approach generates better results than orderless\nNADE and Gibbs sampling approaches.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 20:36:47 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Chi", "Wayne", ""], ["Kumar", "Prachi", ""], ["Yaddanapudi", "Suri", ""], ["Suresh", "Rahul", ""], ["Isik", "Umut", ""]]}, {"id": "2008.08930", "submitter": "Ziqiang Li", "authors": "Ziqiang Li, Xintian Wu, Muhammad Usman, Rentuo Tao, Pengfei Xia,\n  Huanhuan Chen, Bin Li", "title": "A Systematic Survey of Regularization and Normalization in GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have been widely applied in different\nscenarios thanks to the development of deep neural networks. The original GAN\nwas proposed based on the non-parametric assumption of the infinite capacity of\nnetworks. However, it is still unknown whether GANs can generate realistic\nsamples without any prior information. Due to the overconfident assumption,\nmany issues remain unaddressed in GANs' training, such as non-convergence, mode\ncollapses, gradient vanishing. Regularization and normalization are common\nmethods of introducing prior information to stabilize training and improve\ndiscrimination. Although a handful number of regularization and normalization\nmethods have been proposed for GANs, to the best of our knowledge, there exists\nno comprehensive survey which primarily focuses on objectives and development\nof these methods, apart from some in-comprehensive and limited scope studies.\nIn this work, we conduct a comprehensive survey on the regularization and\nnormalization techniques from different perspectives of GANs training. First,\nwe systematically describe different perspectives of GANs training and thus\nobtain the different objectives of regularization and normalization. Based on\nthese objectives, we propose a new taxonomy. Furthermore, we compare the\nperformance of the mainstream methods on different datasets and investigate the\nregularization and normalization techniques that have been frequently employed\nin SOTA GANs. Finally, we highlight potential future directions of research in\nthis domain.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 12:52:10 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 03:15:54 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 02:06:58 GMT"}, {"version": "v4", "created": "Sat, 29 May 2021 15:52:22 GMT"}, {"version": "v5", "created": "Mon, 21 Jun 2021 07:46:30 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Li", "Ziqiang", ""], ["Wu", "Xintian", ""], ["Usman", "Muhammad", ""], ["Tao", "Rentuo", ""], ["Xia", "Pengfei", ""], ["Chen", "Huanhuan", ""], ["Li", "Bin", ""]]}, {"id": "2008.08931", "submitter": "Liyi Guo", "authors": "Liyi Guo, Rui Lu, Haoqi Zhang, Junqi Jin, Zhenzhe Zheng, Fan Wu, Jin\n  Li, Haiyang Xu, Han Li, Wenkai Lu, Jian Xu, Kun Gai", "title": "A Deep Prediction Network for Understanding Advertiser Intent and\n  Satisfaction", "comments": null, "journal-ref": "CIKM 2020, Virtual Event, Ireland", "doi": "10.1145/3340531.3412681", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For e-commerce platforms such as Taobao and Amazon, advertisers play an\nimportant role in the entire digital ecosystem: their behaviors explicitly\ninfluence users' browsing and shopping experience; more importantly,\nadvertiser's expenditure on advertising constitutes a primary source of\nplatform revenue. Therefore, providing better services for advertisers is\nessential for the long-term prosperity for e-commerce platforms. To achieve\nthis goal, the ad platform needs to have an in-depth understanding of\nadvertisers in terms of both their marketing intents and satisfaction over the\nadvertising performance, based on which further optimization could be carried\nout to service the advertisers in the correct direction. In this paper, we\npropose a novel Deep Satisfaction Prediction Network (DSPN), which models\nadvertiser intent and satisfaction simultaneously. It employs a two-stage\nnetwork structure where advertiser intent vector and satisfaction are jointly\nlearned by considering the features of advertiser's action information and\nadvertising performance indicators. Experiments on an Alibaba advertisement\ndataset and online evaluations show that our proposed DSPN outperforms\nstate-of-the-art baselines and has stable performance in terms of AUC in the\nonline environment. Further analyses show that DSPN not only predicts\nadvertisers' satisfaction accurately but also learns an explainable advertiser\nintent, revealing the opportunities to optimize the advertising performance\nfurther.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 15:08:50 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Guo", "Liyi", ""], ["Lu", "Rui", ""], ["Zhang", "Haoqi", ""], ["Jin", "Junqi", ""], ["Zheng", "Zhenzhe", ""], ["Wu", "Fan", ""], ["Li", "Jin", ""], ["Xu", "Haiyang", ""], ["Li", "Han", ""], ["Lu", "Wenkai", ""], ["Xu", "Jian", ""], ["Gai", "Kun", ""]]}, {"id": "2008.08932", "submitter": "Justin Terry", "authors": "Justin K. Terry, Benjamin Black, Ananth Hari", "title": "SuperSuit: Simple Microwrappers for Reinforcement Learning Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, wrappers are universally used to transform the\ninformation that passes between a model and an environment. Despite their\nubiquity, no library exists with reasonable implementations of all popular\npreprocessing methods. This leads to unnecessary bugs, code inefficiencies, and\nwasted developer time. Accordingly we introduce SuperSuit, a Python library\nthat includes all popular wrappers, and wrappers that can easily apply lambda\nfunctions to the observations/actions/reward. It's compatible with the standard\nGym environment specification, as well as the PettingZoo specification for\nmulti-agent environments. The library is available at\nhttps://github.com/PettingZoo-Team/SuperSuit,and can be installed via pip.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 00:30:06 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Terry", "Justin K.", ""], ["Black", "Benjamin", ""], ["Hari", "Ananth", ""]]}, {"id": "2008.08951", "submitter": "Rahim Mammadli", "authors": "Rahim Mammadli, Ali Jannesari and Felix Wolf", "title": "Static Neural Compiler Optimization via Deep Reinforcement Learning", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The phase-ordering problem of modern compilers has received a lot of\nattention from the research community over the years, yet remains largely\nunsolved. Various optimization sequences exposed to the user are manually\ndesigned by compiler developers. In designing such a sequence developers have\nto choose the set of optimization passes, their parameters and ordering within\na sequence. Resulting sequences usually fall short of achieving optimal runtime\nfor a given source code and may sometimes even degrade the performance when\ncompared to unoptimized version. In this paper, we employ a deep reinforcement\nlearning approach to the phase-ordering problem. Provided with sub-sequences\nconstituting LLVM's O3 sequence, our agent learns to outperform the O3 sequence\non the set of source codes used for training and achieves competitive\nperformance on the validation set, gaining up to 1.32x speedup on\npreviously-unseen programs. Notably, our approach differs from autotuning\nmethods by not depending on one or more test runs of the program for making\nsuccessful optimization decisions. It has no dependence on any dynamic feature,\nbut only on the statically-attainable intermediate representation of the source\ncode. We believe that the models trained using our approach can be integrated\ninto modern compilers as neural optimization agents, at first to complement,\nand eventually replace the hand-crafted optimization sequences.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 13:16:29 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 15:10:48 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 11:31:38 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Mammadli", "Rahim", ""], ["Jannesari", "Ali", ""], ["Wolf", "Felix", ""]]}, {"id": "2008.08956", "submitter": "Manikandan Ravikiran", "authors": "Siddharth Vohra, Manikandan Ravikiran", "title": "Investigating the Effect of Intraclass Variability in Temporal\n  Ensembling", "comments": "Preliminary Results; More Experiments to be added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal Ensembling is a semi-supervised approach that allows training deep\nneural network models with a small number of labeled images. In this paper, we\npresent our preliminary study on the effect of intraclass variability on\ntemporal ensembling, with a focus on seed size and seed type, respectively.\nThrough our experiments we find that (a) there is a significant drop in\naccuracy with datasets that offer high intraclass variability, (b) more seed\nimages offer consistently higher accuracy across the datasets, and (c) seed\ntype indeed has an impact on the overall efficiency, where it produces a\nspectrum of accuracy both lower and higher. Additionally, based on our\nexperiments, we also find KMNIST to be a competitive baseline for temporal\nensembling.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 13:24:51 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 09:12:55 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Vohra", "Siddharth", ""], ["Ravikiran", "Manikandan", ""]]}, {"id": "2008.08957", "submitter": "Jinhe Shi", "authors": "Jinhe Shi, Xiangyu Gao, Chenyu Ha, Yage Wang, Guodong Gao, Yi Chen", "title": "Patient ADE Risk Prediction through Hierarchical Time-Aware Neural\n  Network Using Claim Codes", "comments": null, "journal-ref": null, "doi": "10.1109/BigData50022.2020.9378336", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adverse drug events (ADEs) are a serious health problem that can be\nlife-threatening. While a lot of studies have been performed on detect\ncorrelation between a drug and an AE, limited studies have been conducted on\npersonalized ADE risk prediction. Among treatment alternatives, avoiding the\ndrug that has high likelihood of causing severe AE can help physicians to\nprovide safer treatment to patients. Existing work on personalized ADE risk\nprediction uses the information obtained in the current medical visit. However,\non the other hand, medical history reveals each patient's unique\ncharacteristics and comprehensive medical information. The goal of this study\nis to assess personalized ADE risks that a target drug may induce on a target\npatient, based on patient medical history recorded in claims codes, which\nprovide information about diagnosis, drugs taken, related medical supplies\nbesides billing information. We developed a HTNNR model (Hierarchical\nTime-aware Neural Network for ADE Risk) that capture characteristics of claim\ncodes and their relationship. The empirical evaluation show that the proposed\nHTNNR model substantially outperforms the comparison methods, especially for\nrare drugs.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 13:24:54 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Shi", "Jinhe", ""], ["Gao", "Xiangyu", ""], ["Ha", "Chenyu", ""], ["Wang", "Yage", ""], ["Gao", "Guodong", ""], ["Chen", "Yi", ""]]}, {"id": "2008.08965", "submitter": "Evalds Urtans", "authors": "Evalds Urtans, Ariel Tabaks", "title": "asya: Mindful verbal communication using deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.HC cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  asya is a mobile application that consists of deep learning models which\nanalyze spectra of a human voice and do noise detection, speaker diarization,\ngender detection, tempo estimation, and classification of emotions using only\nvoice. All models are language agnostic and capable of running in real-time.\nOur speaker diarization models have accuracy over 95% on the test data set.\nThese models can be applied for a variety of areas like customer service\nimprovement, sales effective conversations, psychology and couples therapy.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 13:37:49 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Urtans", "Evalds", ""], ["Tabaks", "Ariel", ""]]}, {"id": "2008.08970", "submitter": "Monika Csikos", "authors": "M\\'onika Csik\\'os and Nabil H. Mustafa", "title": "Optimal Approximations Made Easy", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental result of Li, Long, and Srinivasan on approximations of set\nsystems has become a key tool across several communities such as learning\ntheory, algorithms, computational geometry, combinatorics and data analysis.\n  The goal of this paper is to give a modular, self-contained, intuitive proof\nof this result for finite set systems. The only ingredient we assume is the\nstandard Chernoff's concentration bound. This makes the proof accessible to a\nwider audience, readers not familiar with techniques from statistical learning\ntheory, and makes it possible to be covered in a single self-contained lecture\nin a geometry, algorithms or combinatorics course.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 13:58:14 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 16:16:31 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Csik\u00f3s", "M\u00f3nika", ""], ["Mustafa", "Nabil H.", ""]]}, {"id": "2008.08977", "submitter": "MingFei Wang", "authors": "Yuan Zhou, Mingfei Wang, Ruolin Wang, Shuwei Huo", "title": "Generating Adjacency Matrix for Video-Query based Video Moment Retrieval", "comments": "arXiv admin note: substantial text overlap with arXiv:2007.09877", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we continue our work on Video-Query based Video Moment\nretrieval task. Based on using graph convolution to extract intra-video and\ninter-video frame features, we improve the method by using similarity-metric\nbased graph convolution, whose weighted adjacency matrix is achieved by\ncalculating similarity metric between features of any two different timesteps\nin the graph. Experiments on ActivityNet v1.2 and Thumos14 dataset shows the\neffectiveness of this improvement, and it outperforms the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 13:52:36 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Zhou", "Yuan", ""], ["Wang", "Mingfei", ""], ["Wang", "Ruolin", ""], ["Huo", "Shuwei", ""]]}, {"id": "2008.09000", "submitter": "Yuemin Bian", "authors": "Yuemin Bian and Xiang-Qun Xie", "title": "Generative chemistry: drug discovery with deep learning generative\n  models", "comments": "29 pages, 4 tables, 5 figures", "journal-ref": null, "doi": "10.1007/s00894-021-04674-8", "report-no": null, "categories": "q-bio.BM cs.LG q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The de novo design of molecular structures using deep learning generative\nmodels introduces an encouraging solution to drug discovery in the face of the\ncontinuously increased cost of new drug development. From the generation of\noriginal texts, images, and videos, to the scratching of novel molecular\nstructures, the incredible creativity of deep learning generative models\nsurprised us about the height machine intelligence can achieve. The purpose of\nthis paper is to review the latest advances in generative chemistry which\nrelies on generative modeling to expedite the drug discovery process. This\nreview starts with a brief history of artificial intelligence in drug discovery\nto outline this emerging paradigm. Commonly used chemical databases, molecular\nrepresentations, and tools in cheminformatics and machine learning are covered\nas the infrastructure for the generative chemistry. The detailed discussions on\nutilizing cutting-edge generative architectures, including recurrent neural\nnetwork, variational autoencoder, adversarial autoencoder, and generative\nadversarial network for compound generation are focused. Challenges and future\nperspectives follow.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 14:38:21 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Bian", "Yuemin", ""], ["Xie", "Xiang-Qun", ""]]}, {"id": "2008.09010", "submitter": "Marco Maggipinto", "authors": "Marco Maggipinto and Matteo Terzi and Gian Antonio Susto", "title": "$\\beta$-Variational Classifiers Under Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural networks have gained lots of attention in recent years thanks to\nthe breakthroughs obtained in the field of Computer Vision. However, despite\ntheir popularity, it has been shown that they provide limited robustness in\ntheir predictions. In particular, it is possible to synthesise small\nadversarial perturbations that imperceptibly modify a correctly classified\ninput data, making the network confidently misclassify it. This has led to a\nplethora of different methods to try to improve robustness or detect the\npresence of these perturbations. In this paper, we perform an analysis of\n$\\beta$-Variational Classifiers, a particular class of methods that not only\nsolve a specific classification task, but also provide a generative component\nthat is able to generate new samples from the input distribution. More in\ndetails, we study their robustness and detection capabilities, together with\nsome novel insights on the generative part of the model.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 14:57:22 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Maggipinto", "Marco", ""], ["Terzi", "Matteo", ""], ["Susto", "Gian Antonio", ""]]}, {"id": "2008.09017", "submitter": "Vijay Mago", "authors": "Mekaal Swerhun, Jasmine Foley, Brandon Massop and Vijay Mago", "title": "A summary of the prevalence of Genetic Algorithms in Bioinformatics from\n  2015 onwards", "comments": "20 pages and 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, machine learning has seen an increasing presencein a large\nvariety of fields, especially in health care and bioinformatics.More\nspecifically, the field where machine learning algorithms have found most\napplications is Genetic Algorithms.The objective of this paper is to conduct a\nsurvey of articles published from 2015 onwards that deal with Genetic\nAlgorithms(GA) and how they are used in bioinformatics.To achieve the\nobjective, a scoping review was conducted that utilized Google Scholar\nalongside Publish or Perish and the Scimago Journal & CountryRank to search for\nrespectable sources. Upon analyzing 31 articles from the field of\nbioinformatics, it became apparent that genetic algorithms rarely form a full\napplication, instead they rely on other vital algorithms such as support vector\nmachines.Indeed, support vector machines were the most prevalent algorithms\nused alongside genetic algorithms; however, while the usage of such algorithms\ncontributes to the heavy focus on accuracy by GA programs, it often sidelines\ncomputation times in the process. In fact, most applications employing GAs for\nclassification and feature selectionare nearing or at 100% success rate, and\nthe focus of future GA development should be directed elsewhere.\nPopulation-based searches, like GA, are often combined with other machine\nlearning algorithms. In this scoping review, genetic algorithms combined with\nSupport Vector Machines were found to perform best. The performance metric that\nwas evaluated most often was accuracy. Measuring the accuracy avoids measuring\nthe main weakness of GAs, which is computational time. The future of genetic\nalgorithms could be open-ended evolutionary algorithms, which attempt to\nincrease complexity and find diverse solutions, rather than optimize a fitness\nfunction and converge to a single best solution from the initial population of\nsolutions.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 15:15:43 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Swerhun", "Mekaal", ""], ["Foley", "Jasmine", ""], ["Massop", "Brandon", ""], ["Mago", "Vijay", ""]]}, {"id": "2008.09018", "submitter": "Lu Duan", "authors": "Lu Duan, Haoyuan Hu, Zili Wu, Guozheng Li, Xinhang Zhang, Yu Gong,\n  Yinghui Xu", "title": "Balanced Order Batching with Task-Oriented Graph Clustering", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": "10.1145/3394486.3403355", "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Balanced order batching problem (BOBP) arises from the process of warehouse\npicking in Cainiao, the largest logistics platform in China. Batching orders\ntogether in the picking process to form a single picking route, reduces travel\ndistance. The reason for its importance is that order picking is a labor\nintensive process and, by using good batching methods, substantial savings can\nbe obtained. The BOBP is a NP-hard combinational optimization problem and\ndesigning a good problem-specific heuristic under the quasi-real-time system\nresponse requirement is non-trivial. In this paper, rather than designing\nheuristics, we propose an end-to-end learning and optimization framework named\nBalanced Task-orientated Graph Clustering Network (BTOGCN) to solve the BOBP by\nreducing it to balanced graph clustering optimization problem. In BTOGCN, a\ntask-oriented estimator network is introduced to guide the type-aware\nheterogeneous graph clustering networks to find a better clustering result\nrelated to the BOBP objective. Through comprehensive experiments on\nsingle-graph and multi-graphs, we show: 1) our balanced task-oriented graph\nclustering network can directly utilize the guidance of target signal and\noutperforms the two-stage deep embedding and deep clustering method; 2) our\nmethod obtains an average 4.57m and 0.13m picking distance (\"m\" is the\nabbreviation of the meter (the SI base unit of length)) reduction than the\nexpert-designed algorithm on single and multi-graph set and has a good\ngeneralization ability to apply in practical scenario.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 08:42:50 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Duan", "Lu", ""], ["Hu", "Haoyuan", ""], ["Wu", "Zili", ""], ["Li", "Guozheng", ""], ["Zhang", "Xinhang", ""], ["Gong", "Yu", ""], ["Xu", "Yinghui", ""]]}, {"id": "2008.09020", "submitter": "Md. Khaledur Rahman", "authors": "Md. Khaledur Rahman", "title": "Training Sensitivity in Graph Isomorphism Network", "comments": "Accepted for publication in CIKM 2020", "journal-ref": "CIKM 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Graph neural network (GNN) is a popular tool to learn the lower-dimensional\nrepresentation of a graph. It facilitates the applicability of machine learning\ntasks on graphs by incorporating domain-specific features. There are various\noptions for underlying procedures (such as optimization functions, activation\nfunctions, etc.) that can be considered in the implementation of GNN. However,\nmost of the existing tools are confined to one approach without any analysis.\nThus, this emerging field lacks a robust implementation ignoring the highly\nirregular structure of the real-world graphs. In this paper, we attempt to fill\nthis gap by studying various alternative functions for a respective module\nusing a diverse set of benchmark datasets. Our empirical results suggest that\nthe generally used underlying techniques do not always perform well to capture\nthe overall structure from a set of graphs.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 03:50:28 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Rahman", "Md. Khaledur", ""]]}, {"id": "2008.09024", "submitter": "Mariana Recamonde-Mendoza", "authors": "Marcelo Schreiber Fernandes, Weverton Cordeiro, Mariana\n  Recamonde-Mendoza", "title": "Detecting Aedes Aegypti Mosquitoes through Audio Classification with\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.compbiomed.2020.104152", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The incidence of mosquito-borne diseases is significant in under-developed\nregions, mostly due to the lack of resources to implement aggressive control\nmeasurements against mosquito proliferation. A potential strategy to raise\ncommunity awareness regarding mosquito proliferation is building a live map of\nmosquito incidences using smartphone apps and crowdsourcing. In this paper, we\nexplore the possibility of identifying Aedes aegypti mosquitoes using machine\nlearning techniques and audio analysis captured from commercially available\nsmartphones. In summary, we downsampled Aedes aegypti wingbeat recordings and\nused them to train a convolutional neural network (CNN) through supervised\nlearning. As a feature, we used the recording spectrogram to represent the\nmosquito wingbeat frequency over time visually. We trained and compared three\nclassifiers: a binary, a multiclass, and an ensemble of binary classifiers. In\nour evaluation, the binary and ensemble models achieved accuracy of 97.65%\n($\\pm$ 0.55) and 94.56% ($\\pm$ 0.77), respectively, whereas the multiclass had\nan accuracy of 78.12% ($\\pm$ 2.09). The best sensitivity was observed in the\nensemble approach (96.82% $\\pm$ 1.62), followed by the multiclass for the\nparticular case of Aedes aegypti (90.23% $\\pm$ 3.83) and the binary (88.49%\n$\\pm$ 6.68). The binary classifier and the multiclass classifier presented the\nbest balance between precision and recall, with F1-measure close to 90%.\nAlthough the ensemble classifier achieved the lowest precision, thus impairing\nits F1-measure (79.95% $\\pm$ 2.13), it was the most powerful classifier to\ndetect Aedes aegypti in our dataset.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 00:26:21 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Fernandes", "Marcelo Schreiber", ""], ["Cordeiro", "Weverton", ""], ["Recamonde-Mendoza", "Mariana", ""]]}, {"id": "2008.09037", "submitter": "Matthew Hutchinson", "authors": "Matthew Hutchinson, Siddharth Samsi, William Arcand, David Bestor,\n  Bill Bergeron, Chansup Byun, Micheal Houle, Matthew Hubbell, Micheal Jones,\n  Jeremy Kepner, Andrew Kirby, Peter Michaleas, Lauren Milechin, Julie Mullen,\n  Andrew Prout, Antonio Rosa, Albert Reuther, Charles Yee, Vijay Gadepally", "title": "Accuracy and Performance Comparison of Video Action Recognition\n  Approaches", "comments": "Accepted for publication at IEEE HPEC 2020", "journal-ref": null, "doi": "10.1109/HPEC43674.2020.9286249", "report-no": null, "categories": "cs.CV cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, there has been significant interest in video action\nrecognition systems and models. However, direct comparison of accuracy and\ncomputational performance results remain clouded by differing training\nenvironments, hardware specifications, hyperparameters, pipelines, and\ninference methods. This article provides a direct comparison between fourteen\noff-the-shelf and state-of-the-art models by ensuring consistency in these\ntraining characteristics in order to provide readers with a meaningful\ncomparison across different types of video action recognition algorithms.\nAccuracy of the models is evaluated using standard Top-1 and Top-5 accuracy\nmetrics in addition to a proposed new accuracy metric. Additionally, we compare\ncomputational performance of distributed training from two to sixty-four GPUs\non a state-of-the-art HPC system.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 15:42:37 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Hutchinson", "Matthew", ""], ["Samsi", "Siddharth", ""], ["Arcand", "William", ""], ["Bestor", "David", ""], ["Bergeron", "Bill", ""], ["Byun", "Chansup", ""], ["Houle", "Micheal", ""], ["Hubbell", "Matthew", ""], ["Jones", "Micheal", ""], ["Kepner", "Jeremy", ""], ["Kirby", "Andrew", ""], ["Michaleas", "Peter", ""], ["Milechin", "Lauren", ""], ["Mullen", "Julie", ""], ["Prout", "Andrew", ""], ["Rosa", "Antonio", ""], ["Reuther", "Albert", ""], ["Yee", "Charles", ""], ["Gadepally", "Vijay", ""]]}, {"id": "2008.09041", "submitter": "Ziqiang Li", "authors": "Ziqiang Li, Pengfei Xia, Rentuo Tao, Hongjing Niu, Bin Li", "title": "Direct Adversarial Training: An Adaptive Method to Penalize Lipschitz\n  Continuity of the Discriminator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are the most popular image generation\nmodels that have achieved remarkable performance on various tasks. However,\ntraining instability is still one of the open problems for all GAN-based\nalgorithms. In order to stabilize GANs training, some regularization and\nnormalization techniques have been proposed to make the discriminator meet the\nLipschitz continuity. In this paper, a new approach inspired by works on\nadversarial is proposed to stabilize the training process of GANs. It is found\nthat sometimes the images generated by the generator play a role just like\nadversarial examples for discriminator during the training process, which might\nbe a part of the reason for the unstable training of GANs. With this discovery,\nwe propose a Direct Adversarial Training (DAT) method for the training process\nof GANs to improve its performance. We prove that the DAT method can minimize\nthe Lipschitz constant of the discriminator adaptively. The advanced\nperformance of the proposed method is verified on multiple baseline and SOTA\nnetworks, such as DCGAN, Spectral Normalization GAN, Self-supervised GAN, and\nInformation Maximum GAN. Code will be available at\n\\url{https://github.com/iceli1007/DAT-GAN}\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 02:36:53 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 07:45:34 GMT"}, {"version": "v3", "created": "Fri, 15 Jan 2021 07:49:51 GMT"}, {"version": "v4", "created": "Thu, 6 May 2021 03:29:53 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Li", "Ziqiang", ""], ["Xia", "Pengfei", ""], ["Tao", "Rentuo", ""], ["Niu", "Hongjing", ""], ["Li", "Bin", ""]]}, {"id": "2008.09043", "submitter": "Joseph Bullock", "authors": "Alexandra Luccioni and Joseph Bullock and Katherine Hoffmann Pham and\n  Cynthia Sin Nga Lam and Miguel Luengo-Oroz", "title": "Considerations, Good Practices, Risks and Pitfalls in Developing AI\n  Solutions Against COVID-19", "comments": "4 pages, 1 figure", "journal-ref": "Harvard CRCS Workshop on AI for Social Good, United States, 2020", "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has been a major challenge to humanity, with 12.7\nmillion confirmed cases as of July 13th, 2020 [1]. In previous work, we\ndescribed how Artificial Intelligence can be used to tackle the pandemic with\napplications at the molecular, clinical, and societal scales [2]. In the\npresent follow-up article, we review these three research directions, and\nassess the level of maturity and feasibility of the approaches used, as well as\ntheir potential for operationalization. We also summarize some commonly\nencountered risks and practical pitfalls, as well as guidelines and best\npractices for formulating and deploying AI applications at different scales.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 12:37:37 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Luccioni", "Alexandra", ""], ["Bullock", "Joseph", ""], ["Pham", "Katherine Hoffmann", ""], ["Lam", "Cynthia Sin Nga", ""], ["Luengo-Oroz", "Miguel", ""]]}, {"id": "2008.09049", "submitter": "Nishant Subramani", "authors": "Nishant Subramani and Nivedita Suresh", "title": "Discovering Useful Sentence Representations from Large Pretrained\n  Language Models", "comments": "13 pages, 11 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the extensive success of pretrained language models as encoders for\nbuilding NLP systems, they haven't seen prominence as decoders for sequence\ngeneration tasks. We explore the question of whether these models can be\nadapted to be used as universal decoders. To be considered \"universal,\" a\ndecoder must have an implicit representation for any target sentence $s$, such\nthat it can recover that sentence exactly when conditioned on its\nrepresentation. For large transformer-based language models trained on vast\namounts of English text, we investigate whether such representations can be\neasily discovered using standard optimization methods. We present and compare\nthree representation injection techniques for transformer-based models and\nthree accompanying methods which map sentences to and from this representation\nspace. Experiments show that not only do representations exist for sentences\nfrom a variety of genres. More importantly, without needing complex\noptimization algorithms, our methods recover these sentences almost perfectly\nwithout fine-tuning the underlying language model at all.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 16:03:51 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Subramani", "Nishant", ""], ["Suresh", "Nivedita", ""]]}, {"id": "2008.09052", "submitter": "J. Elisenda Grigsby", "authors": "J. Elisenda Grigsby and Kathryn Lindsey", "title": "On transversality of bent hyperplane arrangements and the topological\n  expressiveness of ReLU neural networks", "comments": "38 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG cs.LG math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let F:R^n -> R be a feedforward ReLU neural network. It is well-known that\nfor any choice of parameters, F is continuous and piecewise (affine) linear. We\nlay some foundations for a systematic investigation of how the architecture of\nF impacts the geometry and topology of its possible decision regions for binary\nclassification tasks. Following the classical progression for smooth functions\nin differential topology, we first define the notion of a generic, transversal\nReLU neural network and show that almost all ReLU networks are generic and\ntransversal. We then define a partially-oriented linear 1-complex in the domain\nof F and identify properties of this complex that yield an obstruction to the\nexistence of bounded connected components of a decision region. We use this\nobstruction to prove that a decision region of a generic, transversal ReLU\nnetwork F: R^n -> R with a single hidden layer of dimension (n + 1) can have no\nmore than one bounded connected component.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 16:06:39 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Grigsby", "J. Elisenda", ""], ["Lindsey", "Kathryn", ""]]}, {"id": "2008.09061", "submitter": "Tao Yang", "authors": "Tao Yang, Shikai Fang, Shibo Li, Yulan Wang, Qingyao Ai", "title": "Analysis of Multivariate Scoring Functions for Automatic Unbiased\n  Learning to Rank", "comments": "4 pages, 2 figures. It has already been accepted and will show in\n  Proceedings of the 29th ACM International Conference on Information and\n  Knowledge Management (CIKM '20), October 19--23, 2020", "journal-ref": null, "doi": "10.1145/3340531.3412128", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Leveraging biased click data for optimizing learning to rank systems has been\na popular approach in information retrieval. Because click data is often noisy\nand biased, a variety of methods have been proposed to construct unbiased\nlearning to rank (ULTR) algorithms for the learning of unbiased ranking models.\nAmong them, automatic unbiased learning to rank (AutoULTR) algorithms that\njointly learn user bias models (i.e., propensity models) with unbiased rankers\nhave received a lot of attention due to their superior performance and low\ndeployment cost in practice. Despite their differences in theories and\nalgorithm design, existing studies on ULTR usually use uni-variate ranking\nfunctions to score each document or result independently. On the other hand,\nrecent advances in context-aware learning-to-rank models have shown that\nmultivariate scoring functions, which read multiple documents together and\npredict their ranking scores jointly, are more powerful than uni-variate\nranking functions in ranking tasks with human-annotated relevance labels.\nWhether such superior performance would hold in ULTR with noisy data, however,\nis mostly unknown. In this paper, we investigate existing multivariate scoring\nfunctions and AutoULTR algorithms in theory and prove that permutation\ninvariance is a crucial factor that determines whether a context-aware\nlearning-to-rank model could be applied to existing AutoULTR framework. Our\nexperiments with synthetic clicks on two large-scale benchmark datasets show\nthat AutoULTR models with permutation-invariant multivariate scoring functions\nsignificantly outperform those with uni-variate scoring functions and\npermutation-variant multivariate scoring functions.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 16:31:59 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Yang", "Tao", ""], ["Fang", "Shikai", ""], ["Li", "Shibo", ""], ["Wang", "Yulan", ""], ["Ai", "Qingyao", ""]]}, {"id": "2008.09072", "submitter": "Muhammad Sabih", "authors": "Muhammad Sabih, Frank Hannig and Juergen Teich", "title": "Utilizing Explainable AI for Quantization and Pruning of Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many applications, utilizing DNNs (Deep Neural Networks) requires their\nimplementation on a target architecture in an optimized manner concerning\nenergy consumption, memory requirement, throughput, etc. DNN compression is\nused to reduce the memory footprint and complexity of a DNN before its\ndeployment on hardware. Recent efforts to understand and explain AI (Artificial\nIntelligence) methods have led to a new research area, termed as explainable\nAI. Explainable AI methods allow us to understand better the inner working of\nDNNs, such as the importance of different neurons and features. The concepts\nfrom explainable AI provide an opportunity to improve DNN compression methods\nsuch as quantization and pruning in several ways that have not been\nsufficiently explored so far. In this paper, we utilize explainable AI methods:\nmainly DeepLIFT method. We use these methods for (1) pruning of DNNs; this\nincludes structured and unstructured pruning of \\ac{CNN} filters pruning as\nwell as pruning weights of fully connected layers, (2) non-uniform quantization\nof DNN weights using clustering algorithm; this is also referred to as Weight\nSharing, and (3) integer-based mixed-precision quantization; this is where each\nlayer of a DNN may use a different number of integer bits. We use typical image\nclassification datasets with common deep learning image classification models\nfor evaluation. In all these three cases, we demonstrate significant\nimprovements as well as new insights and opportunities from the use of\nexplainable AI in DNN compression.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 16:52:58 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Sabih", "Muhammad", ""], ["Hannig", "Frank", ""], ["Teich", "Juergen", ""]]}, {"id": "2008.09090", "submitter": "Rilwan Adewoyin", "authors": "Rilwan Adewoyin, Peter Dueben, Peter Watson, Yulan He, Ritabrata Dutta", "title": "TRU-NET: A Deep Learning Approach to High Resolution Prediction of\n  Rainfall", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Climate models (CM) are used to evaluate the impact of climate change on the\nrisk of floods and strong precipitation events. However, these numerical\nsimulators have difficulties representing precipitation events accurately,\nmainly due to limited spatial resolution when simulating multi-scale dynamics\nin the atmosphere. To improve the prediction of high resolution precipitation\nwe apply a Deep Learning (DL) approach using an input of CM simulations of the\nmodel fields (weather variables) that are more predictable than local\nprecipitation. To this end, we present TRU-NET (Temporal Recurrent U-Net), an\nencoder-decoder model featuring a novel 2D cross attention mechanism between\ncontiguous convolutional-recurrent layers to effectively model multi-scale\nspatio-temporal weather processes. We use a conditional-continuous loss\nfunction to capture the zero-skewed %extreme event patterns of rainfall.\nExperiments show that our model consistently attains lower RMSE and MAE scores\nthan a DL model prevalent in short term precipitation prediction and improves\nupon the rainfall predictions of a state-of-the-art dynamical weather model.\nMoreover, by evaluating the performance of our model under various, training\nand testing, data formulation strategies, we show that there is enough data for\nour deep learning approach to output robust, high-quality results across\nseasons and varying regions.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 17:27:59 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 18:30:08 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Adewoyin", "Rilwan", ""], ["Dueben", "Peter", ""], ["Watson", "Peter", ""], ["He", "Yulan", ""], ["Dutta", "Ritabrata", ""]]}, {"id": "2008.09092", "submitter": "Amlan Kar", "authors": "Jeevan Devaranjan, Amlan Kar, Sanja Fidler", "title": "Meta-Sim2: Unsupervised Learning of Scene Structure for Synthetic Data\n  Generation", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedural models are being widely used to synthesize scenes for graphics,\ngaming, and to create (labeled) synthetic datasets for ML. In order to produce\nrealistic and diverse scenes, a number of parameters governing the procedural\nmodels have to be carefully tuned by experts. These parameters control both the\nstructure of scenes being generated (e.g. how many cars in the scene), as well\nas parameters which place objects in valid configurations. Meta-Sim aimed at\nautomatically tuning parameters given a target collection of real images in an\nunsupervised way. In Meta-Sim2, we aim to learn the scene structure in addition\nto parameters, which is a challenging problem due to its discrete nature.\nMeta-Sim2 proceeds by learning to sequentially sample rule expansions from a\ngiven probabilistic scene grammar. Due to the discrete nature of the problem,\nwe use Reinforcement Learning to train our model, and design a feature space\ndivergence between our synthesized and target images that is key to successful\ntraining. Experiments on a real driving dataset show that, without any\nsupervision, we can successfully learn to generate data that captures discrete\nstructural statistics of objects, such as their frequency, in real images. We\nalso show that this leads to downstream improvement in the performance of an\nobject detector trained on our generated dataset as opposed to other baseline\nsimulation methods. Project page:\nhttps://nv-tlabs.github.io/meta-sim-structure/.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 17:28:45 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Devaranjan", "Jeevan", ""], ["Kar", "Amlan", ""], ["Fidler", "Sanja", ""]]}, {"id": "2008.09100", "submitter": "Mahsan Nourani", "authors": "Mahsan Nourani, Joanie T. King, Eric D. Ragan", "title": "The Role of Domain Expertise in User Trust and the Impact of First\n  Impressions with Intelligent Systems", "comments": "Accepted and to appear in the Proceedings of the AAAI Conference on\n  Human Computation and Crowdsourcing (HCOMP) 2020", "journal-ref": null, "doi": null, "report-no": "https://www.aaai.org/ojs/index.php/HCOMP/article/view/7469", "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain-specific intelligent systems are meant to help system users in their\ndecision-making process. Many systems aim to simultaneously support different\nusers with varying levels of domain expertise, but prior domain knowledge can\naffect user trust and confidence in detecting system errors. While it is also\nknown that user trust can be influenced by first impressions with intelligent\nsystems, our research explores the relationship between ordering bias and\ndomain expertise when encountering errors in intelligent systems. In this\npaper, we present a controlled user study to explore the role of domain\nknowledge in establishing trust and susceptibility to the influence of first\nimpressions on user trust. Participants reviewed an explainable image\nclassifier with a constant accuracy and two different orders of observing\nsystem errors (observing errors in the beginning of usage vs. in the end). Our\nfindings indicate that encountering errors early-on can cause negative first\nimpressions for domain experts, negatively impacting their trust over the\ncourse of interactions. However, encountering correct outputs early helps more\nknowledgable users to dynamically adjust their trust based on their\nobservations of system performance. In contrast, novice users suffer from\nover-reliance due to their lack of proper knowledge to detect errors.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 17:41:02 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Nourani", "Mahsan", ""], ["King", "Joanie T.", ""], ["Ragan", "Eric D.", ""]]}, {"id": "2008.09103", "submitter": "Chenglizhao Chen", "authors": "Yunxiao Li, Shuai Li, Chenglizhao Chen, Aimin Hao, Hong Qin", "title": "A Plug-and-play Scheme to Adapt Image Saliency Deep Model for Video Data", "comments": "12 pages, 10 figures, and, this paper is currently in peer review in\n  IEEE TCSVT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of deep learning techniques, image saliency deep\nmodels trained solely by spatial information have occasionally achieved\ndetection performance for video data comparable to that of the models trained\nby both spatial and temporal information. However, due to the lesser\nconsideration of temporal information, the image saliency deep models may\nbecome fragile in the video sequences dominated by temporal information. Thus,\nthe most recent video saliency detection approaches have adopted the network\narchitecture starting with a spatial deep model that is followed by an\nelaborately designed temporal deep model. However, such methods easily\nencounter the performance bottleneck arising from the single stream learning\nmethodology, so the overall detection performance is largely determined by the\nspatial deep model. In sharp contrast to the current mainstream methods, this\npaper proposes a novel plug-and-play scheme to weakly retrain a pretrained\nimage saliency deep model for video data by using the newly sensed and coded\ntemporal information. Thus, the retrained image saliency deep model will be\nable to maintain temporal saliency awareness, achieving much improved detection\nperformance. Moreover, our method is simple yet effective for adapting any\noff-the-shelf pre-trained image saliency deep model to obtain high-quality\nvideo saliency detection. Additionally, both the data and source code of our\nmethod are publicly available.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 13:23:14 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Li", "Yunxiao", ""], ["Li", "Shuai", ""], ["Chen", "Chenglizhao", ""], ["Hao", "Aimin", ""], ["Qin", "Hong", ""]]}, {"id": "2008.09106", "submitter": "Tewodros Habtegebrial", "authors": "Tewodros Habtegebrial, Varun Jampani, Orazio Gallo, Didier Stricker", "title": "Generative View Synthesis: From Single-view Semantics to Novel-view\n  Images", "comments": "Accepted at Neurips-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content creation, central to applications such as virtual reality, can be a\ntedious and time-consuming. Recent image synthesis methods simplify this task\nby offering tools to generate new views from as little as a single input image,\nor by converting a semantic map into a photorealistic image. We propose to push\nthe envelope further, and introduce Generative View Synthesis (GVS), which can\nsynthesize multiple photorealistic views of a scene given a single semantic\nmap. We show that the sequential application of existing techniques, e.g.,\nsemantics-to-image translation followed by monocular view synthesis, fail at\ncapturing the scene's structure. In contrast, we solve the semantics-to-image\ntranslation in concert with the estimation of the 3D layout of the scene, thus\nproducing geometrically consistent novel views that preserve semantic\nstructures. We first lift the input 2D semantic map onto a 3D layered\nrepresentation of the scene in feature space, thereby preserving the semantic\nlabels of 3D geometric structures. We then project the layered features onto\nthe target views to generate the final novel-view images. We verify the\nstrengths of our method and compare it with several advanced baselines on three\ndifferent datasets. Our approach also allows for style manipulation and image\nediting operations, such as the addition or removal of objects, with simple\nmanipulations of the input style images and semantic maps respectively. Visit\nthe project page at https://gvsnet.github.io.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 17:48:16 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 12:09:09 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Habtegebrial", "Tewodros", ""], ["Jampani", "Varun", ""], ["Gallo", "Orazio", ""], ["Stricker", "Didier", ""]]}, {"id": "2008.09148", "submitter": "Usman Roshan", "authors": "Yunzhe Xue, Meiyan Xie, Usman Roshan", "title": "Towards adversarial robustness with 01 loss neural networks", "comments": "arXiv admin note: text overlap with arXiv:2006.07800", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by the general robustness properties of the 01 loss we propose a\nsingle hidden layer 01 loss neural network trained with stochastic coordinate\ndescent as a defense against adversarial attacks in machine learning. One\nmeasure of a model's robustness is the minimum distortion required to make the\ninput adversarial. This can be approximated with the Boundary Attack (Brendel\net. al. 2018) and HopSkipJump (Chen et. al. 2019) methods. We compare the\nminimum distortion of the 01 loss network to the binarized neural network and\nthe standard sigmoid activation network with cross-entropy loss all trained\nwith and without Gaussian noise on the CIFAR10 benchmark binary classification\nbetween classes 0 and 1. Both with and without noise training we find our 01\nloss network to have the largest adversarial distortion of the three models by\nnon-trivial margins. To further validate these results we subject all models to\nsubstitute model black box attacks under different distortion thresholds and\nfind that the 01 loss network is the hardest to attack across all distortions.\nAt a distortion of 0.125 both sigmoid activated cross-entropy loss and\nbinarized networks have almost 0% accuracy on adversarial examples whereas the\n01 loss network is at 40%. Even though both 01 loss and the binarized network\nuse sign activations their training algorithms are different which in turn give\ndifferent solutions for robustness. Finally we compare our network to simple\nconvolutional models under substitute model black box attacks and find their\naccuracies to be comparable. Our work shows that the 01 loss network has the\npotential to defend against black box adversarial attacks better than convex\nloss and binarized networks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 18:18:49 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Xue", "Yunzhe", ""], ["Xie", "Meiyan", ""], ["Roshan", "Usman", ""]]}, {"id": "2008.09149", "submitter": "Yoni Choukroun", "authors": "Yoni Choukroun, Michael Zibulevsky, Pavel Kisilev", "title": "Primal-Dual Sequential Subspace Optimization for Saddle-point Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new sequential subspace optimization method for large-scale\nsaddle-point problems. It solves iteratively a sequence of auxiliary\nsaddle-point problems in low-dimensional subspaces, spanned by directions\nderived from first-order information over the primal \\emph{and} dual variables.\nProximal regularization is further deployed to stabilize the optimization\nprocess. Experimental results demonstrate significantly better convergence\nrelative to popular first-order methods. We analyze the influence of the\nsubspace on the convergence of the algorithm, and assess its performance in\nvarious deterministic optimization scenarios, such as bi-linear games,\nADMM-based constrained optimization and generative adversarial networks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 18:19:19 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Choukroun", "Yoni", ""], ["Zibulevsky", "Michael", ""], ["Kisilev", "Pavel", ""]]}, {"id": "2008.09153", "submitter": "Eduardo Cotilla-Sanchez", "authors": "Jun Jiang and Xuan Liu and Scott Wallace and Eduardo Cotilla-Sanchez\n  and Robert Bass and Xinghui Zhao", "title": "Defending Against Adversarial Attacks in Transmission- and\n  Distribution-level PMU Data", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phasor measurement units (PMUs) provide high-fidelity data that improve\nsituation awareness of electric power grid operations. PMU datastreams inform\nwide-area state estimation, monitor area control error, and facilitate event\ndetection in real time. As PMU data become more available and increasingly\nreliable, these devices are found in new roles within control systems, such as\nremedial action schemes and early warning detection systems. As with other\ncyber physical systems, maintaining data integrity and security pose a\nsignificant challenge for power system operators. In this paper, we present a\ncomprehensive analysis of multiple machine learning techniques to detect\nmalicious data injection within PMU data streams. The two datasets used in this\nstudy come from two PMU networks: an inter-university, research-grade\ndistribution network spanning three institutions in the U.S. Pacific Northwest,\nand a utility transmission network from the Bonneville Power Administration. We\nimplement the detection algorithms with TensorFlow, an open-source software\nlibrary for machine learning, and the results demonstrate potential for\ndistributing the training workload and achieving higher performance, while\nmaintaining effectiveness in the detection of spoofed data.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 18:44:37 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Jiang", "Jun", ""], ["Liu", "Xuan", ""], ["Wallace", "Scott", ""], ["Cotilla-Sanchez", "Eduardo", ""], ["Bass", "Robert", ""], ["Zhao", "Xinghui", ""]]}, {"id": "2008.09154", "submitter": "Athanasios Vlontzos", "authors": "Athanasios Vlontzos, Henrique Bergallo Rocha, Daniel Rueckert,\n  Bernhard Kainz", "title": "Causal Future Prediction in a Minkowski Space-Time", "comments": "Includes supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating future events is a difficult task. Unlike humans, machine learning\napproaches are not regularized by a natural understanding of physics. In the\nwild, a plausible succession of events is governed by the rules of causality,\nwhich cannot easily be derived from a finite training set. In this paper we\npropose a novel theoretical framework to perform causal future prediction by\nembedding spatiotemporal information on a Minkowski space-time. We utilize the\nconcept of a light cone from special relativity to restrict and traverse the\nlatent space of an arbitrary model. We demonstrate successful applications in\ncausal image synthesis and future video frame prediction on a dataset of\nimages. Our framework is architecture- and task-independent and comes with\nstrong theoretical guarantees of causal capabilities.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 18:45:55 GMT"}, {"version": "v2", "created": "Sun, 30 Aug 2020 17:08:17 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Vlontzos", "Athanasios", ""], ["Rocha", "Henrique Bergallo", ""], ["Rueckert", "Daniel", ""], ["Kainz", "Bernhard", ""]]}, {"id": "2008.09161", "submitter": "Praneeth Vepakomma", "authors": "Praneeth Vepakomma, Abhishek Singh, Otkrist Gupta, Ramesh Raskar", "title": "NoPeek: Information leakage reduction to share activations in\n  distributed deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For distributed machine learning with sensitive data, we demonstrate how\nminimizing distance correlation between raw data and intermediary\nrepresentations reduces leakage of sensitive raw data patterns across client\ncommunications while maintaining model accuracy. Leakage (measured using\ndistance correlation between input and intermediate representations) is the\nrisk associated with the invertibility of raw data from intermediary\nrepresentations. This can prevent client entities that hold sensitive data from\nusing distributed deep learning services. We demonstrate that our method is\nresilient to such reconstruction attacks and is based on reduction of distance\ncorrelation between raw data and learned representations during training and\ninference with image datasets. We prevent such reconstruction of raw data while\nmaintaining information required to sustain good classification accuracies.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 19:03:17 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Vepakomma", "Praneeth", ""], ["Singh", "Abhishek", ""], ["Gupta", "Otkrist", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2008.09164", "submitter": "Kevin Musgrave", "authors": "Kevin Musgrave, Serge Belongie, Ser-Nam Lim", "title": "PyTorch Metric Learning", "comments": "Code and documentation is available at\n  https://www.github.com/KevinMusgrave/pytorch-metric-learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep metric learning algorithms have a wide variety of applications, but\nimplementing these algorithms can be tedious and time consuming. PyTorch Metric\nLearning is an open source library that aims to remove this barrier for both\nresearchers and practitioners. The modular and flexible design allows users to\neasily try out different combinations of algorithms in their existing code. It\nalso comes with complete train/test workflows, for users who want results fast.\nCode and documentation is available at\nhttps://www.github.com/KevinMusgrave/pytorch-metric-learning.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 19:08:56 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Musgrave", "Kevin", ""], ["Belongie", "Serge", ""], ["Lim", "Ser-Nam", ""]]}, {"id": "2008.09165", "submitter": "Caroline Moosm\\\"uller", "authors": "Caroline Moosm\\\"uller and Alexander Cloninger", "title": "Linear Optimal Transport Embedding: Provable Wasserstein classification\n  for certain rigid transformations and perturbations", "comments": "28 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discriminating between distributions is an important problem in a number of\nscientific fields. This motivated the introduction of Linear Optimal\nTransportation (LOT), which embeds the space of distributions into an\n$L^2$-space. The transform is defined by computing the optimal transport of\neach distribution to a fixed reference distribution, and has a number of\nbenefits when it comes to speed of computation and to determining\nclassification boundaries. In this paper, we characterize a number of settings\nin which LOT embeds families of distributions into a space in which they are\nlinearly separable. This is true in arbitrary dimension, and for families of\ndistributions generated through perturbations of shifts and scalings of a fixed\ndistribution.We also prove conditions under which the $L^2$ distance of the LOT\nembedding between two distributions in arbitrary dimension is nearly isometric\nto Wasserstein-2 distance between those distributions. This is of significant\ncomputational benefit, as one must only compute $N$ optimal transport maps to\ndefine the $N^2$ pairwise distances between $N$ distributions. We demonstrate\nthe benefits of LOT on a number of distribution classification problems.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 19:09:33 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 03:17:30 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 03:48:35 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Moosm\u00fcller", "Caroline", ""], ["Cloninger", "Alexander", ""]]}, {"id": "2008.09167", "submitter": "Georgios Papagiannis", "authors": "Georgios Papagiannis and Yunpeng Li", "title": "Imitation Learning with Sinkhorn Distances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning algorithms have been interpreted as variants of divergence\nminimization problems. The ability to compare occupancy measures between\nexperts and learners is crucial in their effectiveness in learning from\ndemonstrations. In this paper, we present tractable solutions by formulating\nimitation learning as minimization of the Sinkhorn distance between occupancy\nmeasures. The formulation combines the valuable properties of optimal transport\nmetrics in comparing non-overlapping distributions with a cosine distance cost\ndefined in an adversarially learned feature space. This leads to a highly\ndiscriminative critic network and optimal transport plan that subsequently\nguide imitation learning. We evaluate the proposed approach using both the\nreward metric and the Sinkhorn distance metric on a number of MuJoCo\nexperiments.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 19:13:21 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Papagiannis", "Georgios", ""], ["Li", "Yunpeng", ""]]}, {"id": "2008.09168", "submitter": "Davide Rigoni", "authors": "Davide Rigoni, Nicol\\`o Navarin and Alessandro Sperduti", "title": "A Systematic Assessment of Deep Learning Models for Molecule Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years the scientific community has devoted much effort in the\ndevelopment of deep learning models for the generation of new molecules with\ndesirable properties (i.e. drugs). This has produced many proposals in\nliterature. However, a systematic comparison among the different VAE methods is\nstill missing. For this reason, we propose an extensive testbed for the\nevaluation of generative models for drug discovery, and we present the results\nobtained by many of the models proposed in literature.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 19:13:31 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Rigoni", "Davide", ""], ["Navarin", "Nicol\u00f2", ""], ["Sperduti", "Alessandro", ""]]}, {"id": "2008.09172", "submitter": "Matthew Middlehurst", "authors": "Matthew Middlehurst, James Large, Anthony Bagnall", "title": "The Canonical Interval Forest (CIF) Classifier for Time Series\n  Classification", "comments": null, "journal-ref": "In proceedings of the IEEE International Conference on Big Data\n  (Big Data), pages 188-195, 2020", "doi": "10.1109/BigData50022.2020.9378424", "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series classification (TSC) is home to a number of algorithm groups that\nutilise different kinds of discriminatory patterns. One of these groups\ndescribes classifiers that predict using phase dependant intervals. The time\nseries forest (TSF) classifier is one of the most well known interval methods,\nand has demonstrated strong performance as well as relative speed in training\nand predictions. However, recent advances in other approaches have left TSF\nbehind. TSF originally summarises intervals using three simple summary\nstatistics. The `catch22' feature set of 22 time series features was recently\nproposed to aid time series analysis through a concise set of diverse and\ninformative descriptive characteristics. We propose combining TSF and catch22\nto form a new classifier, the Canonical Interval Forest (CIF). We outline\nadditional enhancements to the training procedure, and extend the classifier to\ninclude multivariate classification capabilities. We demonstrate a large and\nsignificant improvement in accuracy over both TSF and catch22, and show it to\nbe on par with top performers from other algorithmic classes. By upgrading the\ninterval-based component from TSF to CIF, we also demonstrate a significant\nimprovement in the hierarchical vote collective of transformation-based\nensembles (HIVE-COTE) that combines different time series representations.\nHIVE-COTE using CIF is significantly more accurate on the UCR archive than any\nother classifier we are aware of and represents a new state of the art for TSC.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 19:26:24 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Middlehurst", "Matthew", ""], ["Large", "James", ""], ["Bagnall", "Anthony", ""]]}, {"id": "2008.09192", "submitter": "Craig Laprade", "authors": "Craig Laprade, Benjamin Bowman, H. Howie Huang", "title": "PicoDomain: A Compact High-Fidelity Cybersecurity Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Analysis of cyber relevant data has become an area of increasing focus. As\nlarger percentages of businesses and governments begin to understand the\nimplications of cyberattacks, the impetus for better cybersecurity solutions\nhas increased. Unfortunately, current cybersecurity datasets either offer no\nground truth or do so with anonymized data. The former leads to a quandary when\nverifying results and the latter can remove valuable information. Additionally,\nmost existing datasets are large enough to make them unwieldy during prototype\ndevelopment. In this paper we have developed the PicoDomain dataset, a compact\nhigh-fidelity collection of Zeek logs from a realistic intrusion using relevant\nTools, Techniques, and Procedures. While simulated on a small-scale network,\nthis dataset consists of traffic typical of an enterprise network, which can be\nutilized for rapid validation and iterative development of analytics platforms.\nWe have validated this dataset using traditional statistical analysis and\noff-the-shelf Machine Learning techniques.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 20:18:04 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Laprade", "Craig", ""], ["Bowman", "Benjamin", ""], ["Huang", "H. Howie", ""]]}, {"id": "2008.09194", "submitter": "Baiwu Zhang", "authors": "Baiwu Zhang, Jin Peng Zhou, Ilia Shumailov, Nicolas Papernot", "title": "On Attribution of Deepfakes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress in generative modelling, especially generative adversarial networks,\nhave made it possible to efficiently synthesize and alter media at scale.\nMalicious individuals now rely on these machine-generated media, or deepfakes,\nto manipulate social discourse. In order to ensure media authenticity, existing\nresearch is focused on deepfake detection. Yet, the adversarial nature of\nframeworks used for generative modeling suggests that progress towards\ndetecting deepfakes will enable more realistic deepfake generation. Therefore,\nit comes at no surprise that developers of generative models are under the\nscrutiny of stakeholders dealing with misinformation campaigns. At the same\ntime, generative models have a lot of positive applications. As such, there is\na clear need to develop tools that ensure the transparent use of generative\nmodeling, while minimizing the harm caused by malicious applications.\n  Our technique optimizes over the source of entropy of each generative model\nto probabilistically attribute a deepfake to one of the models. We evaluate our\nmethod on the seminal example of face synthesis, demonstrating that our\napproach achieves 97.62% attribution accuracy, and is less sensitive to\nperturbations and adversarial examples. We discuss the ethical implications of\nour work, identify where our technique can be used, and highlight that a more\nmeaningful legislative framework is required for a more transparent and ethical\nuse of generative modeling. Finally, we argue that model developers should be\ncapable of claiming plausible deniability and propose a second framework to do\nso -- this allows a model developer to produce evidence that they did not\nproduce media that they are being accused of having produced.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 20:25:18 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 21:41:33 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Zhang", "Baiwu", ""], ["Zhou", "Jin Peng", ""], ["Shumailov", "Ilia", ""], ["Papernot", "Nicolas", ""]]}, {"id": "2008.09202", "submitter": "Justin Engelmann", "authors": "Justin Engelmann, Stefan Lessmann", "title": "Conditional Wasserstein GAN-based Oversampling of Tabular Data for\n  Imbalanced Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class imbalance is a common problem in supervised learning and impedes the\npredictive performance of classification models. Popular countermeasures\ninclude oversampling the minority class. Standard methods like SMOTE rely on\nfinding nearest neighbours and linear interpolations which are problematic in\ncase of high-dimensional, complex data distributions. Generative Adversarial\nNetworks (GANs) have been proposed as an alternative method for generating\nartificial minority examples as they can model complex distributions. However,\nprior research on GAN-based oversampling does not incorporate recent\nadvancements from the literature on generating realistic tabular data with\nGANs. Previous studies also focus on numerical variables whereas categorical\nfeatures are common in many business applications of classification methods\nsuch as credit scoring. The paper propoes an oversampling method based on a\nconditional Wasserstein GAN that can effectively model tabular datasets with\nnumerical and categorical variables and pays special attention to the\ndown-stream classification task through an auxiliary classifier loss. We\nbenchmark our method against standard oversampling methods and the imbalanced\nbaseline on seven real-world datasets. Empirical results evidence the\ncompetitiveness of GAN-based oversampling.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 20:33:56 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Engelmann", "Justin", ""], ["Lessmann", "Stefan", ""]]}, {"id": "2008.09206", "submitter": "Zheyuan Zhu", "authors": "Joseph Ulseth, Zheyuan Zhu, Guifang Li, Shuo Pang", "title": "Training of mixed-signal optical convolutional neural network with\n  reduced quantization level", "comments": "Manuscript prepared for submission to IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2021.3072193", "report-no": null, "categories": "eess.SP cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed-signal artificial neural networks (ANNs) that employ analog\nmatrix-multiplication accelerators can achieve higher speed and improved power\nefficiency. Though analog computing is known to be susceptible to noise and\ndevice imperfections, various analog computing paradigms have been considered\nas promising solutions to address the growing computing demand in machine\nlearning applications, thanks to the robustness of ANNs. This robustness has\nbeen explored in low-precision, fixed-point ANN models, which have proven\nsuccessful on compressing ANN model size on digital computers. However, these\npromising results and network training algorithms cannot be easily migrated to\nanalog accelerators. The reason is that digital computers typically carry\nintermediate results with higher bit width, though the inputs and weights of\neach ANN layers are of low bit width; while the analog intermediate results\nhave low precision, analogous to digital signals with a reduced quantization\nlevel. Here we report a training method for mixed-signal ANN with two types of\nerrors in its analog signals, random noise, and deterministic errors\n(distortions). The results showed that mixed-signal ANNs trained with our\nproposed method can achieve an equivalent classification accuracy with noise\nlevel up to 50% of the ideal quantization step size. We have demonstrated this\ntraining method on a mixed-signal optical convolutional neural network based on\ndiffractive optics.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 20:46:22 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Ulseth", "Joseph", ""], ["Zhu", "Zheyuan", ""], ["Li", "Guifang", ""], ["Pang", "Shuo", ""]]}, {"id": "2008.09239", "submitter": "Jing Liu", "authors": "Jing Liu, Aditya Deshmukh, Venugopal V. Veeravalli", "title": "Robust Mean Estimation in High Dimensions via $\\ell_0$ Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the robust mean estimation problem in high dimensions, where $\\alpha\n<0.5$ fraction of the data points can be arbitrarily corrupted. Motivated by\ncompressive sensing, we formulate the robust mean estimation problem as the\nminimization of the $\\ell_0$-`norm' of the outlier indicator vector, under\nsecond moment constraints on the inlier data points. We prove that the global\nminimum of this objective is order optimal for the robust mean estimation\nproblem, and we propose a general framework for minimizing the objective. We\nfurther leverage the $\\ell_1$ and $\\ell_p$ $(0<p<1)$, minimization techniques\nin compressive sensing to provide computationally tractable solutions to the\n$\\ell_0$ minimization problem. Both synthetic and real data experiments\ndemonstrate that the proposed algorithms significantly outperform\nstate-of-the-art robust mean estimation methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 00:19:48 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Liu", "Jing", ""], ["Deshmukh", "Aditya", ""], ["Veeravalli", "Venugopal V.", ""]]}, {"id": "2008.09246", "submitter": "Jie Xu", "authors": "Jie Xu, Wei Zhang, Fei Wang", "title": "A(DP)$^2$SGD: Asynchronous Decentralized Parallel Stochastic Gradient\n  Descent with Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep learning models are usually massive and complex, distributed learning\nis essential for increasing training efficiency. Moreover, in many real-world\napplication scenarios like healthcare, distributed learning can also keep the\ndata local and protect privacy. A popular distributed learning strategy is\nfederated learning, where there is a central server storing the global model\nand a set of local computing nodes updating the model parameters with their\ncorresponding data. The updated model parameters will be processed and\ntransmitted to the central server, which leads to heavy communication costs.\nRecently, asynchronous decentralized distributed learning has been proposed and\ndemonstrated to be a more efficient and practical strategy where there is no\ncentral server, so that each computing node only communicates with its\nneighbors. Although no raw data will be transmitted across different local\nnodes, there is still a risk of information leak during the communication\nprocess for malicious participants to make attacks. In this paper, we present a\ndifferentially private version of asynchronous decentralized parallel SGD\n(ADPSGD) framework, or A(DP)$^2$SGD for short, which maintains communication\nefficiency of ADPSGD and prevents the inference from malicious participants.\nSpecifically, R{\\'e}nyi differential privacy is used to provide tighter privacy\nanalysis for our composite Gaussian mechanisms while the convergence rate is\nconsistent with the non-private version. Theoretical analysis shows\nA(DP)$^2$SGD also converges at the optimal $\\mathcal{O}(1/\\sqrt{T})$ rate as\nSGD. Empirically, A(DP)$^2$SGD achieves comparable model accuracy as the\ndifferentially private version of Synchronous SGD (SSGD) but runs much faster\nthan SSGD in heterogeneous computing environments.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 00:56:22 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Xu", "Jie", ""], ["Zhang", "Wei", ""], ["Wang", "Fei", ""]]}, {"id": "2008.09251", "submitter": "Yuanhao Wang", "authors": "Yuanhao Wang and Kefan Dong", "title": "Refined Analysis of FPL for Adversarial Markov Decision Processes", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the adversarial Markov Decision Process (MDP) problem, where the\nrewards for the MDP can be adversarially chosen, and the transition function\ncan be either known or unknown. In both settings, Follow-the-PerturbedLeader\n(FPL) based algorithms have been proposed in previous literature. However, the\nestablished regret bounds for FPL based algorithms are worse than algorithms\nbased on mirrordescent. We improve the analysis of FPL based algorithms in both\nsettings, matching the current best regret bounds using faster and simpler\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 01:12:10 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Wang", "Yuanhao", ""], ["Dong", "Kefan", ""]]}, {"id": "2008.09264", "submitter": "SyuSiang Wang", "authors": "Alexander Chao-Fu Kang, Kuo-Hsuan Hung, Yu-Wen Chen, You-Jin Li,\n  Ya-Hsin Lai, Kai-Chun Liu, Sze-Wei Fu, Syu-Siang Wang, Yu Tsao", "title": "CITISEN: A Deep Learning-Based Speech Signal-Processing Mobile\n  Application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a deep learning-based speech signal-processing\nmobile application, CITISEN, which can perform three functions: speech\nenhancement (SE), acoustic scene conversion (ASC), and model adaptation (MA).\nFor SE, CITISEN can effectively reduce noise components from speech signals and\naccordingly enhance their clarity and intelligibility. For ASC, CITISEN can\nconvert the current background sound to a different background sound. Finally,\nfor MA, CITISEN can effectively adapt an SE model, with a few audio files, when\nit encounters unknown speakers or noise types; the adapted SE model is used to\nenhance the upcoming noisy utterances. Experimental results confirmed the\neffectiveness of CITISEN in performing these three functions via objective\nevaluation and subjective listening tests. The promising results reveal that\nthe developed CITISEN mobile application can potentially be used as a front-end\nprocessor for various speech-related services such as voice communication,\nassistive hearing devices, and virtual reality headsets.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 02:04:12 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Kang", "Alexander Chao-Fu", ""], ["Hung", "Kuo-Hsuan", ""], ["Chen", "Yu-Wen", ""], ["Li", "You-Jin", ""], ["Lai", "Ya-Hsin", ""], ["Liu", "Kai-Chun", ""], ["Fu", "Sze-Wei", ""], ["Wang", "Syu-Siang", ""], ["Tsao", "Yu", ""]]}, {"id": "2008.09279", "submitter": "Sandamal Weerasinghe", "authors": "Sandamal Weerasinghe, Sarah M. Erfani, Tansu Alpcan, Christopher\n  Leckie, Justin Kopacz", "title": "Defending Regression Learners Against Poisoning Attacks", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regression models, which are widely used from engineering applications to\nfinancial forecasting, are vulnerable to targeted malicious attacks such as\ntraining data poisoning, through which adversaries can manipulate their\npredictions. Previous works that attempt to address this problem rely on\nassumptions about the nature of the attack/attacker or overestimate the\nknowledge of the learner, making them impractical. We introduce a novel Local\nIntrinsic Dimensionality (LID) based measure called N-LID that measures the\nlocal deviation of a given data point's LID with respect to its neighbors. We\nthen show that N-LID can distinguish poisoned samples from normal samples and\npropose an N-LID based defense approach that makes no assumptions of the\nattacker. Through extensive numerical experiments with benchmark datasets, we\nshow that the proposed defense mechanism outperforms the state of the art\ndefenses in terms of prediction accuracy (up to 76% lower MSE compared to an\nundefended ridge model) and running time.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 03:02:58 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Weerasinghe", "Sandamal", ""], ["Erfani", "Sarah M.", ""], ["Alpcan", "Tansu", ""], ["Leckie", "Christopher", ""], ["Kopacz", "Justin", ""]]}, {"id": "2008.09284", "submitter": "Sandamal Weerasinghe", "authors": "Sandamal Weerasinghe, Tansu Alpcan, Sarah M. Erfani, Christopher\n  Leckie", "title": "Defending Distributed Classifiers Against Data Poisoning Attacks", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support Vector Machines (SVMs) are vulnerable to targeted training data\nmanipulations such as poisoning attacks and label flips. By carefully\nmanipulating a subset of training samples, the attacker forces the learner to\ncompute an incorrect decision boundary, thereby cause misclassifications.\nConsidering the increased importance of SVMs in engineering and life-critical\napplications, we develop a novel defense algorithm that improves resistance\nagainst such attacks. Local Intrinsic Dimensionality (LID) is a promising\nmetric that characterizes the outlierness of data samples. In this work, we\nintroduce a new approximation of LID called K-LID that uses kernel distance in\nthe LID calculation, which allows LID to be calculated in high dimensional\ntransformed spaces. We introduce a weighted SVM against such attacks using\nK-LID as a distinguishing characteristic that de-emphasizes the effect of\nsuspicious data samples on the SVM decision boundary. Each sample is weighted\non how likely its K-LID value is from the benign K-LID distribution rather than\nthe attacked K-LID distribution. We then demonstrate how the proposed defense\ncan be applied to a distributed SVM framework through a case study on an\nSDR-based surveillance system. Experiments with benchmark data sets show that\nthe proposed defense reduces classification error rates substantially (10% on\naverage).\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 03:11:23 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Weerasinghe", "Sandamal", ""], ["Alpcan", "Tansu", ""], ["Erfani", "Sarah M.", ""], ["Leckie", "Christopher", ""]]}, {"id": "2008.09289", "submitter": "Nathaniel Bloomfield", "authors": "Nathaniel J. Bloomfield and Susan Wei and Bartholomew Woodham and\n  Peter Wilkinson and Andrew Robinson", "title": "Automating the assessment of biofouling in images using expert agreement\n  as a gold standard", "comments": "12 pages", "journal-ref": "Sci Rep 11, 2739 (2021)", "doi": "10.1038/s41598-021-81011-2", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biofouling is the accumulation of organisms on surfaces immersed in water. It\nis of particular concern to the international shipping industry because it\nincreases fuel costs and presents a biosecurity risk by providing a pathway for\nnon-indigenous marine species to establish in new areas. There is growing\ninterest within jurisdictions to strengthen biofouling risk-management\nregulations, but it is expensive to conduct in-water inspections and assess the\ncollected data to determine the biofouling state of vessel hulls. Machine\nlearning is well suited to tackle the latter challenge, and here we apply deep\nlearning to automate the classification of images from in-water inspections to\nidentify the presence and severity of fouling. We combined several datasets to\nobtain over 10,000 images collected from in-water surveys which were annotated\nby a group biofouling experts. We compared the annotations from three experts\non a 120-sample subset of these images, and found that they showed 89%\nagreement (95% CI: 87-92%). Subsequent labelling of the whole dataset by one of\nthese experts achieved similar levels of agreement with this group of experts,\nwhich we defined as performing at most 5% worse (p=0.009-0.054). Using these\nexpert labels, we were able to train a deep learning model that also agreed\nsimilarly with the group of experts (p=0.001-0.014), demonstrating that\nautomated analysis of biofouling in images is feasible and effective using this\nmethod.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 03:30:45 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 03:59:09 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Bloomfield", "Nathaniel J.", ""], ["Wei", "Susan", ""], ["Woodham", "Bartholomew", ""], ["Wilkinson", "Peter", ""], ["Robinson", "Andrew", ""]]}, {"id": "2008.09293", "submitter": "Kishor Jothimurugan", "authors": "Kishor Jothimurugan, Rajeev Alur and Osbert Bastani", "title": "A Composable Specification Language for Reinforcement Learning Tasks", "comments": null, "journal-ref": "In Advances in Neural Information Processing Systems, pp.\n  13041-13051. 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is a promising approach for learning control policies\nfor robot tasks. However, specifying complex tasks (e.g., with multiple\nobjectives and safety constraints) can be challenging, since the user must\ndesign a reward function that encodes the entire task. Furthermore, the user\noften needs to manually shape the reward to ensure convergence of the learning\nalgorithm. We propose a language for specifying complex control tasks, along\nwith an algorithm that compiles specifications in our language into a reward\nfunction and automatically performs reward shaping. We implement our approach\nin a tool called SPECTRL, and show that it outperforms several state-of-the-art\nbaselines.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 03:40:57 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 15:02:43 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Jothimurugan", "Kishor", ""], ["Alur", "Rajeev", ""], ["Bastani", "Osbert", ""]]}, {"id": "2008.09301", "submitter": "Nan Rosemary Ke", "authors": "Nan Rosemary Ke, Jane. X. Wang, Jovana Mitrovic, Martin Szummer,\n  Danilo J. Rezende", "title": "Amortized learning of neural causal representations", "comments": "ICLR 2020 causal learning for decision making workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal models can compactly and efficiently encode the data-generating\nprocess under all interventions and hence may generalize better under changes\nin distribution. These models are often represented as Bayesian networks and\nlearning them scales poorly with the number of variables. Moreover, these\napproaches cannot leverage previously learned knowledge to help with learning\nnew causal models. In order to tackle these challenges, we represent a novel\nalgorithm called \\textit{causal relational networks} (CRN) for learning causal\nmodels using neural networks. The CRN represent causal models using continuous\nrepresentations and hence could scale much better with the number of variables.\nThese models also take in previously learned information to facilitate learning\nof new causal models. Finally, we propose a decoding-based metric to evaluate\ncausal models with continuous representations. We test our method on synthetic\ndata achieving high accuracy and quick adaptation to previously unseen causal\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 04:35:06 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Ke", "Nan Rosemary", ""], ["Wang", "Jane. X.", ""], ["Mitrovic", "Jovana", ""], ["Szummer", "Martin", ""], ["Rezende", "Danilo J.", ""]]}, {"id": "2008.09306", "submitter": "Shirley Liu", "authors": "Shirley Liu, Charles Lehman and Ghassan AlRegib", "title": "Robustness and Overfitting Behavior of Implicit Background Models", "comments": "6 pages, 3 figures, accepted to IEEE International Conference on\n  Image Processing (ICIP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we examine the overfitting behavior of image classification\nmodels modified with Implicit Background Estimation (SCrIBE), which transforms\nthem into weakly supervised segmentation models that provide spatial domain\nvisualizations without affecting performance. Using the segmentation masks, we\nderive an overfit detection criterion that does not require testing labels. In\naddition, we assess the change in model performance, calibration, and\nsegmentation masks after applying data augmentations as overfitting reduction\nmeasures and testing on various types of distorted images.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 05:08:33 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Liu", "Shirley", ""], ["Lehman", "Charles", ""], ["AlRegib", "Ghassan", ""]]}, {"id": "2008.09312", "submitter": "Shiliang Zuo", "authors": "Shiliang Zuo", "title": "Near Optimal Adversarial Attack on UCB Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a stochastic multi-arm bandit problem where rewards are subject\nto adversarial corruption. We propose a novel attack strategy that manipulates\na UCB principle into pulling some non-optimal target arm $T - o(T)$ times with\na cumulative cost that scales as $\\sqrt{\\log T}$, where $T$ is the number of\nrounds. We also prove the first lower bound on the cumulative attack cost. Our\nlower bound matches our upper bound up to $\\log \\log T$ factors, showing our\nattack to be near optimal.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 05:23:47 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Zuo", "Shiliang", ""]]}, {"id": "2008.09316", "submitter": "Ninghao Liu", "authors": "Ninghao Liu, Yong Ge, Li Li, Xia Hu, Rui Chen, Soo-Hyun Choi", "title": "Explainable Recommender Systems via Resolving Learning Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems play a fundamental role in web applications in filtering\nmassive information and matching user interests. While many efforts have been\ndevoted to developing more effective models in various scenarios, the\nexploration on the explainability of recommender systems is running behind.\nExplanations could help improve user experience and discover system defects. In\nthis paper, after formally introducing the elements that are related to model\nexplainability, we propose a novel explainable recommendation model through\nimproving the transparency of the representation learning process.\nSpecifically, to overcome the representation entangling problem in traditional\nmodels, we revise traditional graph convolution to discriminate information\nfrom different layers. Also, each representation vector is factorized into\nseveral segments, where each segment relates to one semantic aspect in data.\nDifferent from previous work, in our model, factor discovery and representation\nlearning are simultaneously conducted, and we are able to handle extra\nattribute information and knowledge. In this way, the proposed model can learn\ninterpretable and meaningful representations for users and items. Unlike\ntraditional methods that need to make a trade-off between explainability and\neffectiveness, the performance of our proposed explainable model is not\nnegatively affected after considering explainability. Finally, comprehensive\nexperiments are conducted to validate the performance of our model as well as\nexplanation faithfulness.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 05:30:48 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Liu", "Ninghao", ""], ["Ge", "Yong", ""], ["Li", "Li", ""], ["Hu", "Xia", ""], ["Chen", "Rui", ""], ["Choi", "Soo-Hyun", ""]]}, {"id": "2008.09323", "submitter": "Frank Lin", "authors": "Frank Po-Chen Lin, Christopher G. Brinton, Nicol\\`o Michelusi", "title": "Federated Learning with Communication Delay in Edge Networks", "comments": "Accepted for publication at IEEE Global Communications Conference\n  (Globecom 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has received significant attention as a potential solution\nfor distributing machine learning (ML) model training through edge networks.\nThis work addresses an important consideration of federated learning at the\nnetwork edge: communication delays between the edge nodes and the aggregator. A\ntechnique called FedDelAvg (federated delayed averaging) is developed, which\ngeneralizes the standard federated averaging algorithm to incorporate a\nweighting between the current local model and the delayed global model received\nat each device during the synchronization step. Through theoretical analysis,\nan upper bound is derived on the global model loss achieved by FedDelAvg, which\nreveals a strong dependency of learning performance on the values of the\nweighting and learning rate. Experimental results on a popular ML task indicate\nsignificant improvements in terms of convergence speed when optimizing the\nweighting scheme to account for delays.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 06:21:35 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Lin", "Frank Po-Chen", ""], ["Brinton", "Christopher G.", ""], ["Michelusi", "Nicol\u00f2", ""]]}, {"id": "2008.09333", "submitter": "Zishan Ahmad", "authors": "Zishan Ahmad, Mukuntha N S, Asif Ekbal, Pushpak Bhattacharyya", "title": "Tweet to News Conversion: An Investigation into Unsupervised\n  Controllable Text Generation", "comments": "Accepted in IJCNN-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text generator systems have become extremely popular with the advent of\nrecent deep learning models such as encoder-decoder. Controlling the\ninformation and style of the generated output without supervision is an\nimportant and challenging Natural Language Processing (NLP) task. In this\npaper, we define the task of constructing a coherent paragraph from a set of\ndisaster domain tweets, without any parallel data. We tackle the problem by\nbuilding two systems in pipeline. The first system focuses on unsupervised\nstyle transfer and converts the individual tweets into news sentences. The\nsecond system stitches together the outputs from the first system to form a\ncoherent news paragraph. We also propose a novel training mechanism, by\nsplitting the sentences into propositions and training the second system to\nmerge the sentences. We create a validation and test set consisting of\ntweet-sets and their equivalent news paragraphs to perform empirical\nevaluation. In a completely unsupervised setting, our model was able to achieve\na BLEU score of 19.32, while successfully transferring styles and joining\ntweets to form a meaningful news paragraph.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 06:56:57 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Ahmad", "Zishan", ""], ["S", "Mukuntha N", ""], ["Ekbal", "Asif", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "2008.09335", "submitter": "Abhinav Arora", "authors": "Haoran Li, Abhinav Arora, Shuohui Chen, Anchit Gupta, Sonal Gupta,\n  Yashar Mehdad", "title": "MTOP: A Comprehensive Multilingual Task-Oriented Semantic Parsing\n  Benchmark", "comments": "13 pages, 2 figures, Accepted at EACL 2021", "journal-ref": "EACL 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scaling semantic parsing models for task-oriented dialog systems to new\nlanguages is often expensive and time-consuming due to the lack of available\ndatasets. Available datasets suffer from several shortcomings: a) they contain\nfew languages b) they contain small amounts of labeled examples per language c)\nthey are based on the simple intent and slot detection paradigm for\nnon-compositional queries. In this paper, we present a new multilingual\ndataset, called MTOP, comprising of 100k annotated utterances in 6 languages\nacross 11 domains. We use this dataset and other publicly available datasets to\nconduct a comprehensive benchmarking study on using various state-of-the-art\nmultilingual pre-trained models for task-oriented semantic parsing. We achieve\nan average improvement of +6.3 points on Slot F1 for the two existing\nmultilingual datasets, over best results reported in their experiments.\nFurthermore, we demonstrate strong zero-shot performance using pre-trained\nmodels combined with automatic translation and alignment, and a proposed\ndistant supervision method to reduce the noise in slot label projection.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 07:02:11 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 03:36:21 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Li", "Haoran", ""], ["Arora", "Abhinav", ""], ["Chen", "Shuohui", ""], ["Gupta", "Anchit", ""], ["Gupta", "Sonal", ""], ["Mehdad", "Yashar", ""]]}, {"id": "2008.09340", "submitter": "Sasho Nedelkoski", "authors": "Sasho Nedelkoski, Jasmin Bogatinovski, Alexander Acker, Jorge Cardoso,\n  Odej Kao", "title": "Self-Attentive Classification-Based Anomaly Detection in Unstructured\n  Logs", "comments": "11 pages, 8 figures, Accepted at ICDM 2020: 20th IEEE International\n  Conference on Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of anomalies is essential mining task for the security and\nreliability in computer systems. Logs are a common and major data source for\nanomaly detection methods in almost every computer system. They collect a range\nof significant events describing the runtime system status. Recent studies have\nfocused predominantly on one-class deep learning methods on predefined\nnon-learnable numerical log representations. The main limitation is that these\nmodels are not able to learn log representations describing the semantic\ndifferences between normal and anomaly logs, leading to a poor generalization\nof unseen logs. We propose Logsy, a classification-based method to learn log\nrepresentations in a way to distinguish between normal data from the system of\ninterest and anomaly samples from auxiliary log datasets, easily accessible via\nthe internet. The idea behind such an approach to anomaly detection is that the\nauxiliary dataset is sufficiently informative to enhance the representation of\nthe normal data, yet diverse to regularize against overfitting and improve\ngeneralization. We propose an attention-based encoder model with a new\nhyperspherical loss function. This enables learning compact log representations\ncapturing the intrinsic differences between normal and anomaly logs.\nEmpirically, we show an average improvement of 0.25 in the F1 score, compared\nto the previous methods. To investigate the properties of Logsy, we perform\nadditional experiments including evaluation of the effect of the auxiliary data\nsize, the influence of expert knowledge, and the quality of the learned log\nrepresentations. The results show that the learned representation boost the\nperformance of the previous methods such as PCA with a relative improvement of\n28.2%.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 07:26:55 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Nedelkoski", "Sasho", ""], ["Bogatinovski", "Jasmin", ""], ["Acker", "Alexander", ""], ["Cardoso", "Jorge", ""], ["Kao", "Odej", ""]]}, {"id": "2008.09368", "submitter": "Xu He", "authors": "Xu He, Bo An, Yanghua Li, Haikai Chen, Qingyu Guo, Xin Li, and Zhirong\n  Wang", "title": "Contextual User Browsing Bandits for Large-Scale Online Mobile\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online recommendation services recommend multiple commodities to users.\nNowadays, a considerable proportion of users visit e-commerce platforms by\nmobile devices. Due to the limited screen size of mobile devices, positions of\nitems have a significant influence on clicks: 1) Higher positions lead to more\nclicks for one commodity. 2) The 'pseudo-exposure' issue: Only a few\nrecommended items are shown at first glance and users need to slide the screen\nto browse other items. Therefore, some recommended items ranked behind are not\nviewed by users and it is not proper to treat this kind of items as negative\nsamples. While many works model the online recommendation as contextual bandit\nproblems, they rarely take the influence of positions into consideration and\nthus the estimation of the reward function may be biased. In this paper, we aim\nat addressing these two issues to improve the performance of online mobile\nrecommendation. Our contributions are four-fold. First, since we concern the\nreward of a set of recommended items, we model the online recommendation as a\ncontextual combinatorial bandit problem and define the reward of a recommended\nset. Second, we propose a novel contextual combinatorial bandit method called\nUBM-LinUCB to address two issues related to positions by adopting the User\nBrowsing Model (UBM), a click model for web search. Third, we provide a formal\nregret analysis and prove that our algorithm achieves sublinear regret\nindependent of the number of items. Finally, we evaluate our algorithm on two\nreal-world datasets by a novel unbiased estimator. An online experiment is also\nimplemented in Taobao, one of the most popular e-commerce platforms in the\nworld. Results on two CTR metrics show that our algorithm outperforms the other\ncontextual bandit algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 08:22:30 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["He", "Xu", ""], ["An", "Bo", ""], ["Li", "Yanghua", ""], ["Chen", "Haikai", ""], ["Guo", "Qingyu", ""], ["Li", "Xin", ""], ["Wang", "Zhirong", ""]]}, {"id": "2008.09369", "submitter": "Xu He", "authors": "Xu He, Bo An, Yanghua Li, Haikai Chen, Rundong Wang, Xinrun Wang,\n  Runsheng Yu, Xin Li, and Zhirong Wang", "title": "Learning to Collaborate in Multi-Module Recommendation via Multi-Agent\n  Reinforcement Learning without Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of online e-commerce platforms, more and more customers prefer\nto shop online. To sell more products, online platforms introduce various\nmodules to recommend items with different properties such as huge discounts. A\nweb page often consists of different independent modules. The ranking policies\nof these modules are decided by different teams and optimized individually\nwithout cooperation, which might result in competition between modules. Thus,\nthe global policy of the whole page could be sub-optimal. In this paper, we\npropose a novel multi-agent cooperative reinforcement learning approach with\nthe restriction that different modules cannot communicate. Our contributions\nare three-fold. Firstly, inspired by a solution concept in game theory named\ncorrelated equilibrium, we design a signal network to promote cooperation of\nall modules by generating signals (vectors) for different modules. Secondly, an\nentropy-regularized version of the signal network is proposed to coordinate\nagents' exploration of the optimal global policy. Furthermore, experiments\nbased on real-world e-commerce data demonstrate that our algorithm obtains\nsuperior performance over baselines.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 08:23:33 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 10:34:58 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["He", "Xu", ""], ["An", "Bo", ""], ["Li", "Yanghua", ""], ["Chen", "Haikai", ""], ["Wang", "Rundong", ""], ["Wang", "Xinrun", ""], ["Yu", "Runsheng", ""], ["Li", "Xin", ""], ["Wang", "Zhirong", ""]]}, {"id": "2008.09371", "submitter": "Neeraj Varshney", "authors": "Neeraj Varshney, Swaroop Mishra, Chitta Baral", "title": "It's better to say \"I can't answer\" than answering incorrectly: Towards\n  Safety critical NLP systems", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to make AI systems more reliable and their adoption in safety\ncritical applications possible, it is essential to impart the capability to\nabstain from answering when their prediction is likely to be incorrect and seek\nhuman intervention. Recently proposed \"selective answering\" techniques model\ncalibration as a binary classification task. We argue that, not all incorrectly\nanswered questions are incorrect to the same extent and the same is true for\ncorrectly answered questions. Hence, treating all correct predictions equally\nand all incorrect predictions equally constraints calibration. In this work, we\npropose a methodology that incorporates the degree of correctness, shifting\naway from classification labels as it directly tries to predict the probability\nof model's prediction being correct. We show the efficacy of the proposed\nmethod on existing Natural Language Inference (NLI) datasets by training on\nSNLI and evaluating on MNLI mismatched and matched datasets. Our approach\nimproves area under the curve (AUC) of risk-coverage plot by 10.22\\% and 8.06\\%\nover maxProb with respect to the maximum possible improvement on MNLI\nmismatched and matched set respectively. In order to evaluate our method on Out\nof Distribution (OOD) datasets, we propose a novel setup involving questions\nwith a variety of reasoning skills. Our setup includes a test set for each of\nthe five reasoning skills: numerical, logical, qualitative, abductive and\ncommonsense. We select confidence threshold for each of the approaches where\nthe in-domain accuracy (SNLI) is 99\\%. Our results show that, the proposed\nmethod outperforms existing approaches by abstaining on 2.6\\% more OOD\nquestions at respective confidence thresholds.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 08:46:36 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Varshney", "Neeraj", ""], ["Mishra", "Swaroop", ""], ["Baral", "Chitta", ""]]}, {"id": "2008.09377", "submitter": "Binyamin Manela", "authors": "Binyamin Manela, Armin Biess", "title": "Curriculum Learning with Hindsight Experience Replay for Sequential\n  Object Manipulation Tasks", "comments": "arXiv admin note: text overlap with arXiv:2001.03877", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning complex tasks from scratch is challenging and often impossible for\nhumans as well as for artificial agents. A curriculum can be used instead,\nwhich decomposes a complex task (target task) into a sequence of source tasks\n(the curriculum). Each source task is a simplified version of the next source\ntask with increasing complexity. Learning then occurs gradually by training on\neach source task while using knowledge from the curriculum's prior source\ntasks. In this study, we present a new algorithm that combines curriculum\nlearning with Hindsight Experience Replay (HER), to learn sequential object\nmanipulation tasks for multiple goals and sparse feedback. The algorithm\nexploits the recurrent structure inherent in many object manipulation tasks and\nimplements the entire learning process in the original simulation without\nadjusting it to each source task. We have tested our algorithm on three\nchallenging throwing tasks and show vast improvements compared to vanilla-HER.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 08:59:28 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Manela", "Binyamin", ""], ["Biess", "Armin", ""]]}, {"id": "2008.09378", "submitter": "Zihan Liu", "authors": "Peng Xu, Zihan Liu, Genta Indra Winata, Zhaojiang Lin, Pascale Fung", "title": "EmoGraph: Capturing Emotion Correlations using Graph Networks", "comments": "The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most emotion recognition methods tackle the emotion understanding task by\nconsidering individual emotion independently while ignoring their fuzziness\nnature and the interconnections among them. In this paper, we explore how\nemotion correlations can be captured and help different classification tasks.\nWe propose EmoGraph that captures the dependencies among different emotions\nthrough graph networks. These graphs are constructed by leveraging the\nco-occurrence statistics among different emotion categories. Empirical results\non two multi-label classification datasets demonstrate that EmoGraph\noutperforms strong baselines, especially for macro-F1. An additional experiment\nillustrates the captured emotion correlations can also benefit a single-label\nclassification task.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 08:59:29 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Xu", "Peng", ""], ["Liu", "Zihan", ""], ["Winata", "Genta Indra", ""], ["Lin", "Zhaojiang", ""], ["Fung", "Pascale", ""]]}, {"id": "2008.09381", "submitter": "Julia Lust", "authors": "Julia Lust and Alexandru Paul Condurache", "title": "A Survey on Assessing the Generalization Envelope of Deep Neural\n  Networks at Inference Time for Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) achieve state-of-the-art performance on numerous\napplications. However, it is difficult to tell beforehand if a DNN receiving an\ninput will deliver the correct output since their decision criteria are usually\nnontransparent. A DNN delivers the correct output if the input is within the\narea enclosed by its generalization envelope. In this case, the information\ncontained in the input sample is processed reasonably by the network. It is of\nlarge practical importance to assess at inference time if a DNN generalizes\ncorrectly. Currently, the approaches to achieve this goal are investigated in\ndifferent problem set-ups rather independently from one another, leading to\nthree main research and literature fields: predictive uncertainty,\nout-of-distribution detection and adversarial example detection. This survey\nconnects the three fields within the larger framework of investigating the\ngeneralization performance of machine learning methods and in particular DNNs.\nWe underline the common ground, point at the most promising approaches and give\na structured overview of the methods that provide at inference time means to\nestablish if the current input is within the generalization envelope of a DNN.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 09:12:52 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 19:54:19 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Lust", "Julia", ""], ["Condurache", "Alexandru Paul", ""]]}, {"id": "2008.09384", "submitter": "Florian Schaefer", "authors": "Florian Schaefer, Jan-Hendrik Menke, Martin Braun", "title": "Evaluating Machine Learning Models for the Fast Identification of\n  Contingency Cases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast approximations of power flow results are beneficial in power system\nplanning and live operation. In planning, millions of power flow calculations\nare necessary if multiple years, different control strategies or contingency\npolicies are to be considered. In live operation, grid operators must assess if\ngrid states comply with contingency requirements in a short time. In this\npaper, we compare regression and classification methods to either predict\nmulti-variable results, e.g. bus voltage magnitudes and line loadings, or\nbinary classifications of time steps to identify critical loading situations.\nWe test the methods on three realistic power systems based on time series in 15\nmin and 5 min resolution of one year. We compare different machine learning\nmodels, such as multilayer perceptrons (MLPs), decision trees, k-nearest\nneighbours, gradient boosting, and evaluate the required training time and\nprediction times as well as the prediction errors. We additionally determine\nthe amount of training data needed for each method and show results, including\nthe approximation of untrained curtailment of generation. Regarding the\ncompared methods, we identified the MLPs as most suitable for the task. The\nMLP-based models can predict critical situations with an accuracy of 97-98 %\nand a very low number of false negative predictions of 0.0-0.64 %.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 09:24:57 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Schaefer", "Florian", ""], ["Menke", "Jan-Hendrik", ""], ["Braun", "Martin", ""]]}, {"id": "2008.09396", "submitter": "Uri Shaham", "authors": "Uri Shaham and Omer Levy", "title": "Neural Machine Translation without Embeddings", "comments": "NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many NLP models operate over sequences of subword tokens produced by\nhand-crafted tokenization rules and heuristic subword induction algorithms. A\nsimple universal alternative is to represent every computerized text as a\nsequence of bytes via UTF-8, obviating the need for an embedding layer since\nthere are fewer token types (256) than dimensions. Surprisingly, replacing the\nubiquitous embedding layer with one-hot representations of each byte does not\nhurt performance; experiments on byte-to-byte machine translation from English\nto 10 different languages show a consistent improvement in BLEU, rivaling\ncharacter-level and even standard subword-level models. A deeper investigation\nreveals that the combination of embeddingless models with decoder-input dropout\namounts to token dropout, which benefits byte-to-byte models in particular.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 09:54:11 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 13:33:25 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Shaham", "Uri", ""], ["Levy", "Omer", ""]]}, {"id": "2008.09409", "submitter": "Ruo Ando", "authors": "Ruo Ando, Yoshiyasu Takefuji", "title": "A constrained recursion algorithm for batch normalization of\n  tree-sturctured LSTM", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree-structured LSTM is promising way to consider long-distance interaction\nover hierarchies. However, there have been few research efforts on the\nhyperparameter tuning of the construction and traversal of tree-structured\nLSTM. To name a few, hyperparamters such as the interval of state\ninitialization, the number of batches for normalization have been left\nunexplored specifically in applying batch normalization for reducing training\ncost and parallelization. In this paper, we propose a novel recursive algorithm\nfor traversing batch normalized tree-structured LSTM. In proposal method, we\nimpose the constraint on the recursion algorithm for the depth-first search of\nbinary tree representation of LSTM for which batch normalization is applied.\nWith our constrained recursion, we can control the hyperparameter in the\ntraversal of several tree-structured LSTMs which is generated in the process of\nbatch normalization. The tree traversal is divided into two steps. At first\nstage, the width-first search over models is applied for discover the start\npoint of the latest tree-structured LSTM block. Then, the depth-first search is\nrun to traverse tree-structured LSTM. Proposed method enables us to explore the\noptimized selection of hyperparameters of recursive neural network\nimplementation by changing the constraints of our recursion algorithm. In\nexperiment, we measure and plot the validation loss and computing time with\nchanging the length of internal of state initialization of tree-structured\nLSTM. It has been turned out that proposal method is effective for\nhyperparameter tuning such as the number of batches and length of interval of\nstate initialization of tree-structured LSTM.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 10:31:45 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Ando", "Ruo", ""], ["Takefuji", "Yoshiyasu", ""]]}, {"id": "2008.09413", "submitter": "Yiming Li", "authors": "Yiming Li, Jiawang Bai, Jiawei Li, Xue Yang, Yong Jiang, Shu-Tao Xia", "title": "Rectified Decision Trees: Exploring the Landscape of Interpretable and\n  Effective Machine Learning", "comments": "9 pages. The first two authors contribute equally to this work. arXiv\n  admin note: text overlap with arXiv:1903.05965", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability and effectiveness are two essential and indispensable\nrequirements for adopting machine learning methods in reality. In this paper,\nwe propose a knowledge distillation based decision trees extension, dubbed\nrectified decision trees (ReDT), to explore the possibility of fulfilling those\nrequirements simultaneously. Specifically, we extend the splitting criteria and\nthe ending condition of the standard decision trees, which allows training with\nsoft labels while preserving the deterministic splitting paths. We then train\nthe ReDT based on the soft label distilled from a well-trained teacher model\nthrough a novel jackknife-based method. Accordingly, ReDT preserves the\nexcellent interpretable nature of the decision trees while having a relatively\ngood performance. The effectiveness of adopting soft labels instead of hard\nones is also analyzed empirically and theoretically. Surprisingly, experiments\nindicate that the introduction of soft labels also reduces the model size\ncompared with the standard decision trees from the aspect of the total nodes\nand rules, which is an unexpected gift from the `dark knowledge' distilled from\nthe teacher model.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 10:45:25 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Li", "Yiming", ""], ["Bai", "Jiawang", ""], ["Li", "Jiawei", ""], ["Yang", "Xue", ""], ["Jiang", "Yong", ""], ["Xia", "Shu-Tao", ""]]}, {"id": "2008.09417", "submitter": "Yi Xiao", "authors": "Yi Xiao, Felipe Codevilla, Christopher Pal, Antonio M. Lopez", "title": "Action-Based Representation Learning for Autonomous Driving", "comments": "This paper has been accepted to the Conference on Robot Learning\n  (CoRL 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human drivers produce a vast amount of data which could, in principle, be\nused to improve autonomous driving systems. Unfortunately, seemingly\nstraightforward approaches for creating end-to-end driving models that map\nsensor data directly into driving actions are problematic in terms of\ninterpretability, and typically have significant difficulty dealing with\nspurious correlations. Alternatively, we propose to use this kind of\naction-based driving data for learning representations. Our experiments show\nthat an affordance-based driving model pre-trained with this approach can\nleverage a relatively small amount of weakly annotated imagery and outperform\npure end-to-end driving models, while being more interpretable. Further, we\ndemonstrate how this strategy outperforms previous methods based on learning\ninverse dynamics models as well as other methods based on heavy human\nsupervision (ImageNet).\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 10:49:13 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 15:45:26 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Xiao", "Yi", ""], ["Codevilla", "Felipe", ""], ["Pal", "Christopher", ""], ["Lopez", "Antonio M.", ""]]}, {"id": "2008.09418", "submitter": "Hemanth Nadipineni", "authors": "Hemanth Nadipineni", "title": "Method to Classify Skin Lesions using Dermoscopic images", "comments": "16 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skin cancer is the most common cancer in the existing world constituting\none-third of the cancer cases. Benign skin cancers are not fatal, can be cured\nwith proper medication. But it is not the same as the malignant skin cancers.\nIn the case of malignant melanoma, in its peak stage, the maximum life\nexpectancy is less than or equal to 5 years. But, it can be cured if detected\nin early stages. Though there are numerous clinical procedures, the accuracy of\ndiagnosis falls between 49% to 81% and is time-consuming. So, dermoscopy has\nbeen brought into the picture. It helped in increasing the accuracy of\ndiagnosis but could not demolish the error-prone behaviour. A quick and less\nerror-prone solution is needed to diagnose this majorly growing skin cancer.\nThis project deals with the usage of deep learning in skin lesion\nclassification. In this project, an automated model for skin lesion\nclassification using dermoscopic images has been developed with CNN(Convolution\nNeural Networks) as a training model. Convolution neural networks are known for\ncapturing features of an image. So, they are preferred in analyzing medical\nimages to find the characteristics that drive the model towards success.\nTechniques like data augmentation for tackling class imbalance, segmentation\nfor focusing on the region of interest and 10-fold cross-validation to make the\nmodel robust have been brought into the picture. This project also includes\nusage of certain preprocessing techniques like brightening the images using\npiece-wise linear transformation function, grayscale conversion of the image,\nresize the image. This project throws a set of valuable insights on how the\naccuracy of the model hikes with the bringing of new input strategies,\npreprocessing techniques. The best accuracy this model could achieve is 0.886\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 10:58:33 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Nadipineni", "Hemanth", ""]]}, {"id": "2008.09442", "submitter": "Sumon Bose Mr.", "authors": "Bapi Kar, Pradeep Kumar Gopalakrishnan, Sumon Kumar Bose, Mohendra\n  Roy, and Arindam Basu", "title": "ADIC: Anomaly Detection Integrated Circuit in 65nm CMOS utilizing\n  Approximate Computing", "comments": "12", "journal-ref": null, "doi": "10.1109/TVLSI.2020.3016939", "report-no": null, "categories": "eess.SP cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a low-power anomaly detection integrated circuit\n(ADIC) based on a one-class classifier (OCC) neural network. The ADIC achieves\nlow-power operation through a combination of (a) careful choice of algorithm\nfor online learning and (b) approximate computing techniques to lower average\nenergy. In particular, online pseudoinverse update method (OPIUM) is used to\ntrain a randomized neural network for quick and resource efficient learning. An\nadditional 42% energy saving can be achieved when a lighter version of OPIUM\nmethod is used for training with the same number of data samples lead to no\nsignificant compromise on the quality of inference. Instead of a single\nclassifier with large number of neurons, an ensemble of K base learner approach\nis chosen to reduce learning memory by a factor of K. This also enables\napproximate computing by dynamically varying the neural network size based on\nanomaly detection. Fabricated in 65nm CMOS, the ADIC has K = 7 Base Learners\n(BL) with 32 neurons in each BL and dissipates 11.87pJ/OP and 3.35pJ/OP during\nlearning and inference respectively at Vdd = 0.75V when all 7 BLs are enabled.\nFurther, evaluated on the NASA bearing dataset, approximately 80% of the chip\ncan be shut down for 99% of the lifetime leading to an energy efficiency of\n0.48pJ/OP, an 18.5 times reduction over full-precision computing running at Vdd\n= 1.2V throughout the lifetime.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 12:18:07 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Kar", "Bapi", ""], ["Gopalakrishnan", "Pradeep Kumar", ""], ["Bose", "Sumon Kumar", ""], ["Roy", "Mohendra", ""], ["Basu", "Arindam", ""]]}, {"id": "2008.09450", "submitter": "MyungJae Shin", "authors": "MyungJae Shin, Joongheon Kim", "title": "Adversarial Imitation Learning via Random Search", "comments": "Accepted at IJCNN 2019. arXiv admin note: text overlap with\n  arXiv:1905.05637", "journal-ref": null, "doi": "10.1109/IJCNN.2019.8852307", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing agents that can perform challenging complex tasks is the goal of\nreinforcement learning. The model-free reinforcement learning has been\nconsidered as a feasible solution. However, the state of the art research has\nbeen to develop increasingly complicated techniques. This increasing complexity\nmakes the reconstruction difficult. Furthermore, the problem of reward\ndependency is still exists. As a result, research on imitation learning, which\nlearns policy from a demonstration of experts, has begun to attract attention.\nImitation learning directly learns policy based on data on the behavior of the\nexperts without the explicit reward signal provided by the environment.\nHowever, imitation learning tries to optimize policies based on deep\nreinforcement learning such as trust region policy optimization. As a result,\ndeep reinforcement learning based imitation learning also poses a crisis of\nreproducibility. The issue of complex model-free model has received\nconsiderable critical attention. A derivative-free optimization based\nreinforcement learning and the simplification on policies obtain competitive\nperformance on the dynamic complex tasks. The simplified policies and\nderivative free methods make algorithm be simple. The reconfiguration of\nresearch demo becomes easy. In this paper, we propose an imitation learning\nmethod that takes advantage of the derivative-free optimization with simple\nlinear policies. The proposed method performs simple random search in the\nparameter space of policies and shows computational efficiency. Experiments in\nthis paper show that the proposed model, without a direct reward signal from\nthe environment, obtains competitive performance on the MuJoCo locomotion\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 12:40:03 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Shin", "MyungJae", ""], ["Kim", "Joongheon", ""]]}, {"id": "2008.09466", "submitter": "Arnab Kumar Mondal", "authors": "Arnab Kumar Mondal, Prathosh A.P", "title": "RespVAD: Voice Activity Detection via Video-Extracted Respiration\n  Patterns", "comments": "Accepted in IEEE Sensor Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice Activity Detection (VAD) refers to the task of identification of\nregions of human speech in digital signals such as audio and video. While VAD\nis a necessary first step in many speech processing systems, it poses\nchallenges when there are high levels of ambient noise during the audio\nrecording. To improve the performance of VAD in such conditions, several\nmethods utilizing the visual information extracted from the region surrounding\nthe mouth/lip region of the speakers' video recording have been proposed. Even\nthough these provide advantages over audio-only methods, they depend on\nfaithful extraction of lip/mouth regions. Motivated by these, a new paradigm\nfor VAD based on the fact that respiration forms the primary source of energy\nfor speech production is proposed. Specifically, an audio-independent VAD\ntechnique using the respiration pattern extracted from the speakers' video is\ndeveloped. The Respiration Pattern is first extracted from the video focusing\non the abdominal-thoracic region of a speaker using an optical flow based\nmethod. Subsequently, voice activity is detected from the respiration pattern\nsignal using neural sequence-to-sequence prediction models. The efficacy of the\nproposed method is demonstrated through experiments on a challenging dataset\nrecorded in real acoustic environments and compared with four previous methods\nbased on audio and visual cues.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 13:26:24 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Mondal", "Arnab Kumar", ""], ["P", "Prathosh A.", ""]]}, {"id": "2008.09469", "submitter": "Qi Wang", "authors": "Qi Wang, Herke van Hoof", "title": "Doubly Stochastic Variational Inference for Neural Processes with\n  Hierarchical Latent Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural processes (NPs) constitute a family of variational approximate models\nfor stochastic processes with promising properties in computational efficiency\nand uncertainty quantification. These processes use neural networks with latent\nvariable inputs to induce predictive distributions. However, the expressiveness\nof vanilla NPs is limited as they only use a global latent variable, while\ntarget specific local variation may be crucial sometimes. To address this\nchallenge, we investigate NPs systematically and present a new variant of NP\nmodel that we call Doubly Stochastic Variational Neural Process (DSVNP). This\nmodel combines the global latent variable and local latent variables for\nprediction. We evaluate this model in several experiments, and our results\ndemonstrate competitive prediction performance in multi-output regression and\nuncertainty estimation in classification.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 13:32:12 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 23:05:15 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Wang", "Qi", ""], ["van Hoof", "Herke", ""]]}, {"id": "2008.09470", "submitter": "Dimo Angelov", "authors": "Dimo Angelov", "title": "Top2Vec: Distributed Representations of Topics", "comments": "Implementation available at https://github.com/ddangelov/Top2Vec", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic modeling is used for discovering latent semantic structure, usually\nreferred to as topics, in a large collection of documents. The most widely used\nmethods are Latent Dirichlet Allocation and Probabilistic Latent Semantic\nAnalysis. Despite their popularity they have several weaknesses. In order to\nachieve optimal results they often require the number of topics to be known,\ncustom stop-word lists, stemming, and lemmatization. Additionally these methods\nrely on bag-of-words representation of documents which ignore the ordering and\nsemantics of words. Distributed representations of documents and words have\ngained popularity due to their ability to capture semantics of words and\ndocuments. We present $\\texttt{top2vec}$, which leverages joint document and\nword semantic embedding to find $\\textit{topic vectors}$. This model does not\nrequire stop-word lists, stemming or lemmatization, and it automatically finds\nthe number of topics. The resulting topic vectors are jointly embedded with the\ndocument and word vectors with distance between them representing semantic\nsimilarity. Our experiments demonstrate that $\\texttt{top2vec}$ finds topics\nwhich are significantly more informative and representative of the corpus\ntrained on than probabilistic generative models.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 20:58:27 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Angelov", "Dimo", ""]]}, {"id": "2008.09472", "submitter": "Mawulolo Ameko", "authors": "Mawulolo K. Ameko, Miranda L. Beltzer, Lihua Cai, Mehdi Boukhechba,\n  Bethany A. Teachman, Laura E. Barnes", "title": "Offline Contextual Multi-armed Bandits for Mobile Health Interventions:\n  A Case Study on Emotion Regulation", "comments": "Accepted at RecSys 2020", "journal-ref": null, "doi": "10.1145/3383313.3412244", "report-no": null, "categories": "cs.IR cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Delivering treatment recommendations via pervasive electronic devices such as\nmobile phones has the potential to be a viable and scalable treatment medium\nfor long-term health behavior management. But active experimentation of\ntreatment options can be time-consuming, expensive and altogether unethical in\nsome cases. There is a growing interest in methodological approaches that allow\nan experimenter to learn and evaluate the usefulness of a new treatment\nstrategy before deployment. We present the first development of a treatment\nrecommender system for emotion regulation using real-world historical mobile\ndigital data from n = 114 high socially anxious participants to test the\nusefulness of new emotion regulation strategies. We explore a number of offline\ncontextual bandits estimators for learning and propose a general framework for\nlearning algorithms. Our experimentation shows that the proposed doubly robust\noffline learning algorithms performed significantly better than baseline\napproaches, suggesting that this type of recommender algorithm could improve\nemotion regulation. Given that emotion regulation is impaired across many\nmental illnesses and such a recommender algorithm could be scaled up easily,\nthis approach holds potential to increase access to treatment for many people.\nWe also share some insights that allow us to translate contextual bandit models\nto this complex real-world data, including which contextual features appear to\nbe most important for predicting emotion regulation strategy effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 13:41:24 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Ameko", "Mawulolo K.", ""], ["Beltzer", "Miranda L.", ""], ["Cai", "Lihua", ""], ["Boukhechba", "Mehdi", ""], ["Teachman", "Bethany A.", ""], ["Barnes", "Laura E.", ""]]}, {"id": "2008.09477", "submitter": "Pietro Barbiero", "authors": "Pietro Barbiero, Gabriele Ciravegna, Vincenzo Randazzo, Giansalvo\n  Cirrincione", "title": "Topological Gradient-based Competitive Learning", "comments": "12 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological learning is a wide research area aiming at uncovering the mutual\nspatial relationships between the elements of a set. Some of the most common\nand oldest approaches involve the use of unsupervised competitive neural\nnetworks. However, these methods are not based on gradient optimization which\nhas been proven to provide striking results in feature extraction also in\nunsupervised learning. Unfortunately, by focusing mostly on algorithmic\nefficiency and accuracy, deep clustering techniques are composed of overly\ncomplex feature extractors, while using trivial algorithms in their top layer.\nThe aim of this work is to present a novel comprehensive theory aspiring at\nbridging competitive learning with gradient-based learning, thus allowing the\nuse of extremely powerful deep neural networks for feature extraction and\nprojection combined with the remarkable flexibility and expressiveness of\ncompetitive learning. In this paper we fully demonstrate the theoretical\nequivalence of two novel gradient-based competitive layers. Preliminary\nexperiments show how the dual approach, trained on the transpose of the input\nmatrix i.e. $X^T$, lead to faster convergence rate and higher training accuracy\nboth in low and high-dimensional scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 13:44:38 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Barbiero", "Pietro", ""], ["Ciravegna", "Gabriele", ""], ["Randazzo", "Vincenzo", ""], ["Cirrincione", "Giansalvo", ""]]}, {"id": "2008.09481", "submitter": "Joel Da Costa", "authors": "Joel da Costa, Tim Gebbie", "title": "Learning low-frequency temporal patterns for quantitative trading", "comments": "9 pages, 7 figures", "journal-ref": "2020 IEEE Symposium Series on Computational Intelligence (SSCI),\n  Canberra, Australia, 2020, pp. 1091-1099", "doi": "10.1109/SSCI47803.2020.9308232", "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the viability of a modularised mechanistic online machine\nlearning framework to learn signals in low-frequency financial time series\ndata. The framework is proved on daily sampled closing time-series data from\nJSE equity markets. The input patterns are vectors of pre-processed sequences\nof daily, weekly and monthly or quarterly sampled feature changes. The data\nprocessing is split into a batch processed step where features are learnt using\na stacked autoencoder via unsupervised learning, and then both batch and online\nsupervised learning are carried out using these learnt features, with the\noutput being a point prediction of measured time-series feature fluctuations.\nWeight initializations are implemented with restricted Boltzmann machine\npre-training, and variance based initializations. Historical simulations are\nthen run using an online feedforward neural network initialised with the\nweights from the batch training and validation step. The validity of results\nare considered under a rigorous assessment of backtest overfitting using both\ncombinatorially symmetrical cross validation and probabilistic and deflated\nSharpe ratios. Results are used to develop a view on the phenomenology of\nfinancial markets and the value of complex historical data-analysis for trading\nunder the unstable adaptive dynamics that characterise financial markets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 11:59:15 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["da Costa", "Joel", ""], ["Gebbie", "Tim", ""]]}, {"id": "2008.09483", "submitter": "Kevin El Haddad", "authors": "No\\'e Tits, Kevin El Haddad, Thierry Dutoit", "title": "Laughter Synthesis: Combining Seq2seq modeling with Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the growing interest for expressive speech synthesis, synthesis of\nnonverbal expressions is an under-explored area. In this paper we propose an\naudio laughter synthesis system based on a sequence-to-sequence TTS synthesis\nsystem. We leverage transfer learning by training a deep learning model to\nlearn to generate both speech and laughs from annotations. We evaluate our\nmodel with a listening test, comparing its performance to an HMM-based laughter\nsynthesis one and assess that it reaches higher perceived naturalness. Our\nsolution is a first step towards a TTS system that would be able to synthesize\nspeech with a control on amusement level with laughter integration.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 09:37:28 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Tits", "No\u00e9", ""], ["Haddad", "Kevin El", ""], ["Dutoit", "Thierry", ""]]}, {"id": "2008.09488", "submitter": "Hao Luo", "authors": "Hao Luo and Li Liu", "title": "Counterfactual-based minority oversampling for imbalanced classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge of oversampling in imbalanced classification is that the\ngeneration of new minority samples often neglects the usage of majority\nclasses, resulting in most new minority sampling spreading the whole minority\nspace. In view of this, we present a new oversampling framework based on the\ncounterfactual theory. Our framework introduces a counterfactual objective by\nleveraging the rich inherent information of majority classes and explicitly\nperturbing majority samples to generate new samples in the territory of\nminority space. It can be analytically shown that the new minority samples\nsatisfy the minimum inversion, and therefore most of them locate near the\ndecision boundary. Empirical evaluations on benchmark datasets suggest that our\napproach significantly outperforms the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 14:13:15 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 13:16:47 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Luo", "Hao", ""], ["Liu", "Li", ""]]}, {"id": "2008.09490", "submitter": "Pranjal Awasthi", "authors": "Pranjal Awasthi, Corinna Cortes, Yishay Mansour, Mehryar Mohri", "title": "Beyond Individual and Group Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new data-driven model of fairness that, unlike existing static\ndefinitions of individual or group fairness is guided by the unfairness\ncomplaints received by the system. Our model supports multiple fairness\ncriteria and takes into account their potential incompatibilities. We consider\nboth a stochastic and an adversarial setting of our model. In the stochastic\nsetting, we show that our framework can be naturally cast as a Markov Decision\nProcess with stochastic losses, for which we give efficient vanishing regret\nalgorithmic solutions. In the adversarial setting, we design efficient\nalgorithms with competitive ratio guarantees. We also report the results of\nexperiments with our algorithms and the stochastic framework on artificial\ndatasets, to demonstrate their effectiveness empirically.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 14:14:44 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Cortes", "Corinna", ""], ["Mansour", "Yishay", ""], ["Mohri", "Mehryar", ""]]}, {"id": "2008.09506", "submitter": "Xinshuo Weng", "authors": "Xinshuo Weng, Yongxin Wang, Yunze Man, and Kris Kitani", "title": "Graph Neural Networks for 3D Multi-Object Tracking", "comments": "ECCV 2020 workshop paper. Project website:\n  http://www.xinshuoweng.com/projects/GNN3DMOT. arXiv admin note: substantial\n  text overlap with arXiv:2006.07327", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MA cs.MM cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D Multi-object tracking (MOT) is crucial to autonomous systems. Recent work\noften uses a tracking-by-detection pipeline, where the feature of each object\nis extracted independently to compute an affinity matrix. Then, the affinity\nmatrix is passed to the Hungarian algorithm for data association. A key process\nof this pipeline is to learn discriminative features for different objects in\norder to reduce confusion during data association. To that end, we propose two\ninnovative techniques: (1) instead of obtaining the features for each object\nindependently, we propose a novel feature interaction mechanism by introducing\nGraph Neural Networks; (2) instead of obtaining the features from either 2D or\n3D space as in prior work, we propose a novel joint feature extractor to learn\nappearance and motion features from 2D and 3D space. Through experiments on the\nKITTI dataset, our proposed method achieves state-of-the-art 3D MOT\nperformance. Our project website is at\nhttp://www.xinshuoweng.com/projects/GNN3DMOT.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 17:55:41 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Weng", "Xinshuo", ""], ["Wang", "Yongxin", ""], ["Man", "Yunze", ""], ["Kitani", "Kris", ""]]}, {"id": "2008.09514", "submitter": "Yongfeng Zhang", "authors": "Shaoyun Shi, Hanxiong Chen, Weizhi Ma, Jiaxin Mao, Min Zhang, Yongfeng\n  Zhang", "title": "Neural Logic Reasoning", "comments": "Accepted to ACM CIKM 2020. arXiv admin note: substantial text overlap\n  with arXiv:1910.08629", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the success of deep neural networks in many\nresearch areas. The fundamental idea behind the design of most neural networks\nis to learn similarity patterns from data for prediction and inference, which\nlacks the ability of cognitive reasoning. However, the concrete ability of\nreasoning is critical to many theoretical and practical problems. On the other\nhand, traditional symbolic reasoning methods do well in making logical\ninference, but they are mostly hard rule-based reasoning, which limits their\ngeneralization ability to different tasks since difference tasks may require\ndifferent rules. Both reasoning and generalization ability are important for\nprediction tasks such as recommender systems, where reasoning provides strong\nconnection between user history and target items for accurate prediction, and\ngeneralization helps the model to draw a robust user portrait over noisy\ninputs.\n  In this paper, we propose Logic-Integrated Neural Network (LINN) to integrate\nthe power of deep learning and logic reasoning. LINN is a dynamic neural\narchitecture that builds the computational graph according to input logical\nexpressions. It learns basic logical operations such as AND, OR, NOT as neural\nmodules, and conducts propositional logical reasoning through the network for\ninference. Experiments on theoretical task show that LINN achieves significant\nperformance on solving logical equations and variables. Furthermore, we test\nour approach on the practical task of recommendation by formulating the task\ninto a logical inference problem. Experiments show that LINN significantly\noutperforms state-of-the-art recommendation models in Top-K recommendation,\nwhich verifies the potential of LINN in practice.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 14:53:23 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Shi", "Shaoyun", ""], ["Chen", "Hanxiong", ""], ["Ma", "Weizhi", ""], ["Mao", "Jiaxin", ""], ["Zhang", "Min", ""], ["Zhang", "Yongfeng", ""]]}, {"id": "2008.09524", "submitter": "Tim De Ryck", "authors": "Tim De Ryck, Maarten De Vos, Alexander Bertrand", "title": "Change Point Detection in Time Series Data using Autoencoders with a\n  Time-Invariant Representation", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2021.3087031", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Change point detection (CPD) aims to locate abrupt property changes in time\nseries data. Recent CPD methods demonstrated the potential of using deep\nlearning techniques, but often lack the ability to identify more subtle changes\nin the autocorrelation statistics of the signal and suffer from a high false\nalarm rate. To address these issues, we employ an autoencoder-based methodology\nwith a novel loss function, through which the used autoencoders learn a\npartially time-invariant representation that is tailored for CPD. The result is\na flexible method that allows the user to indicate whether change points should\nbe sought in the time domain, frequency domain or both. Detectable change\npoints include abrupt changes in the slope, mean, variance, autocorrelation\nfunction and frequency spectrum. We demonstrate that our proposed method is\nconsistently highly competitive or superior to baseline methods on diverse\nsimulated and real-life benchmark data sets. Finally, we mitigate the issue of\nfalse detection alarms through the use of a postprocessing procedure that\ncombines a matched filter and a newly proposed change point score. We show that\nthis combination drastically improves the performance of our method as well as\nall baseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 15:03:21 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 11:25:07 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["De Ryck", "Tim", ""], ["De Vos", "Maarten", ""], ["Bertrand", "Alexander", ""]]}, {"id": "2008.09559", "submitter": "Paresh Saxena", "authors": "Paresh Saxena, Mandan Naresh, Manik Gupta, Anirudh Achanta, Sastri\n  Kota and Smrati Gupta", "title": "NANCY: Neural Adaptive Network Coding methodologY for video distribution\n  over wireless networks", "comments": "Accepted in Globecom, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents NANCY, a system that generates adaptive bit rates (ABR)\nfor video and adaptive network coding rates (ANCR) using reinforcement learning\n(RL) for video distribution over wireless networks. NANCY trains a neural\nnetwork model with rewards formulated as quality of experience (QoE) metrics.\nIt performs joint optimization in order to select: (i) adaptive bit rates for\nfuture video chunks to counter variations in available bandwidth and (ii)\nadaptive network coding rates to encode the video chunk slices to counter\npacket losses in wireless networks. We present the design and implementation of\nNANCY, and evaluate its performance compared to state-of-the-art video rate\nadaptation algorithms including Pensieve and robustMPC. Our results show that\nNANCY provides 29.91% and 60.34% higher average QoE than Pensieve and\nrobustMPC, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 15:55:32 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Saxena", "Paresh", ""], ["Naresh", "Mandan", ""], ["Gupta", "Manik", ""], ["Achanta", "Anirudh", ""], ["Kota", "Sastri", ""], ["Gupta", "Smrati", ""]]}, {"id": "2008.09566", "submitter": "Wolfgang Roth", "authors": "Wolfgang Roth and Franz Pernkopf", "title": "Differentiable TAN Structure Learning for Bayesian Network Classifiers", "comments": "Accepted at PGM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the structure of Bayesian networks is a difficult combinatorial\noptimization problem. In this paper, we consider learning of tree-augmented\nnaive Bayes (TAN) structures for Bayesian network classifiers with discrete\ninput features. Instead of performing a combinatorial optimization over the\nspace of possible graph structures, the proposed method learns a distribution\nover graph structures. After training, we select the most probable structure of\nthis distribution. This allows for a joint training of the Bayesian network\nparameters along with its TAN structure using gradient-based optimization. The\nproposed method is agnostic to the specific loss and only requires that it is\ndifferentiable. We perform extensive experiments using a hybrid\ngenerative-discriminative loss based on the discriminative probabilistic\nmargin. Our method consistently outperforms random TAN structures and Chow-Liu\nTAN structures.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 16:22:47 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Roth", "Wolfgang", ""], ["Pernkopf", "Franz", ""]]}, {"id": "2008.09567", "submitter": "Md Abul Bashar", "authors": "Md Abul Bashar, Richi Nayak", "title": "TAnoGAN: Time Series Anomaly Detection with Generative Adversarial\n  Networks", "comments": "Made some minor changes. This is the accepted version of the paper at\n  AusDM'20", "journal-ref": "2020 IEEE Symposium Series on Computational Intelligence (SSCI)", "doi": "10.1109/SSCI47803.2020.9308512", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection in time series data is a significant problem faced in many\napplication areas such as manufacturing, medical imaging and cyber-security.\nRecently, Generative Adversarial Networks (GAN) have gained attention for\ngeneration and anomaly detection in image domain. In this paper, we propose a\nnovel GAN-based unsupervised method called TAnoGan for detecting anomalies in\ntime series when a small number of data points are available. We evaluate\nTAnoGan with 46 real-world time series datasets that cover a variety of\ndomains. Extensive experimental results show that TAnoGan performs better than\ntraditional and neural network models.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 16:24:51 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 01:50:33 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Bashar", "Md Abul", ""], ["Nayak", "Richi", ""]]}, {"id": "2008.09569", "submitter": "Suvodeep Majumder", "authors": "Suvodeep Majumder, Pranav Mody, Tim Menzies", "title": "Revisiting Process versus Product Metrics: a Large Scale Analysis", "comments": "36 pages, 12 figures and 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous methods can build predictive models from software data. But what\nmethods and conclusions should we endorse as we move from analytics in-the\nsmall (dealing with a handful of projects) to analytics in-the-large (dealing\nwith hundreds of projects)?\n  To answer this question, we recheck prior small scale results (about process\nversus product metrics for defect prediction and the granularity of metrics)\nusing 722,471 commits from 700 Github projects. We find that some analytics\nin-the-small conclusions still hold when scaling up to analytics in-the large.\nFor example, like prior work, we see that process metrics are better predictors\nfor defects than product metrics (best process/product-based learners\nrespectively achieve recalls of 98%/44% and AUCs of 95%/54%, median values).\n  That said, we warn that it is unwise to trust metric importance results from\nanalytics in-the-small studies since those change, dramatically when moving to\nanalytics in-the-large. Also, when reasoning in-the-large about hundreds of\nprojects, it is better to use predictions from multiple models (since single\nmodel predictions can become very confused and exhibit very high variance).\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 16:26:22 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 19:23:22 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Majumder", "Suvodeep", ""], ["Mody", "Pranav", ""], ["Menzies", "Tim", ""]]}, {"id": "2008.09570", "submitter": "Punit Rathore", "authors": "Punit Rathore, James C. Bezdek, Paolo Santi, Carlo Ratti", "title": "ConiVAT: Cluster Tendency Assessment and Clustering with Partial\n  Background Knowledge", "comments": "Submitted to IEEE Transactions on Knowledge and Data Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The VAT method is a visual technique for determining the potential cluster\nstructure and the possible number of clusters in numerical data. Its improved\nversion, iVAT, uses a path-based distance transform to improve the\neffectiveness of VAT for \"tough\" cases. Both VAT and iVAT have also been used\nin conjunction with a single-linkage(SL) hierarchical clustering algorithm.\nHowever, they are sensitive to noise and bridge points between clusters in the\ndataset, and consequently, the corresponding VAT/iVAT images are often\nin-conclusive for such cases. In this paper, we propose a constraint-based\nversion of iVAT, which we call ConiVAT, that makes use of background knowledge\nin the form of constraints, to improve VAT/iVAT for challenging and complex\ndatasets. ConiVAT uses the input constraints to learn the underlying similarity\nmetric and builds a minimum transitive dissimilarity matrix, before applying\nVAT to it. We demonstrate ConiVAT approach to visual assessment and single\nlinkage clustering on nine datasets to show that, it improves the quality of\niVAT images for complex datasets, and it also overcomes the limitation of SL\nclustering with VAT/iVAT due to \"noisy\" bridges between clusters. Extensive\nexperiment results on nine datasets suggest that ConiVAT outperforms the other\nthree semi-supervised clustering algorithms in terms of improved clustering\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 16:30:31 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 17:21:09 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Rathore", "Punit", ""], ["Bezdek", "James C.", ""], ["Santi", "Paolo", ""], ["Ratti", "Carlo", ""]]}, {"id": "2008.09579", "submitter": "Alden Bradford", "authors": "Alden Bradford, Tarun Yellamraju, and Mireille Boutin", "title": "Clustering small datasets in high-dimension by random projection", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets in high-dimension do not typically form clusters in their original\nspace; the issue is worse when the number of points in the dataset is small. We\npropose a low-computation method to find statistically significant clustering\nstructures in a small dataset. The method proceeds by projecting the data on a\nrandom line and seeking binary clusterings in the resulting one-dimensional\ndata. Non-linear separations are obtained by extending the feature space using\nmonomials of higher degrees in the original features. The statistical validity\nof the clustering structures obtained is tested in the projected\none-dimensional space, thus bypassing the challenge of statistical validation\nin high-dimension. Projecting on a random line is an extreme dimension\nreduction technique that has previously been used successfully as part of a\nhierarchical clustering method for high-dimensional data. Our experiments show\nthat with this simplified framework, statistically significant clustering\nstructures can be found with as few as 100-200 points, depending on the\ndataset. The different structures uncovered are found to persist as more points\nare added to the dataset.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 16:49:37 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Bradford", "Alden", ""], ["Yellamraju", "Tarun", ""], ["Boutin", "Mireille", ""]]}, {"id": "2008.09586", "submitter": "Daniel Michelsanti", "authors": "Daniel Michelsanti, Zheng-Hua Tan, Shi-Xiong Zhang, Yong Xu, Meng Yu,\n  Dong Yu, and Jesper Jensen", "title": "An Overview of Deep-Learning-Based Audio-Visual Speech Enhancement and\n  Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech enhancement and speech separation are two related tasks, whose purpose\nis to extract either one or more target speech signals, respectively, from a\nmixture of sounds generated by several sources. Traditionally, these tasks have\nbeen tackled using signal processing and machine learning techniques applied to\nthe available acoustic signals. Since the visual aspect of speech is\nessentially unaffected by the acoustic environment, visual information from the\ntarget speakers, such as lip movements and facial expressions, has also been\nused for speech enhancement and speech separation systems. In order to\nefficiently fuse acoustic and visual information, researchers have exploited\nthe flexibility of data-driven approaches, specifically deep learning,\nachieving strong performance. The ceaseless proposal of a large number of\ntechniques to extract features and fuse multimodal information has highlighted\nthe need for an overview that comprehensively describes and discusses\naudio-visual speech enhancement and separation based on deep learning. In this\npaper, we provide a systematic survey of this research topic, focusing on the\nmain elements that characterise the systems in the literature: acoustic\nfeatures; visual features; deep learning methods; fusion techniques; training\ntargets and objective functions. In addition, we review deep-learning-based\nmethods for speech reconstruction from silent videos and audio-visual sound\nsource separation for non-speech signals, since these methods can be more or\nless directly applied to audio-visual speech enhancement and separation.\nFinally, we survey commonly employed audio-visual speech datasets, given their\ncentral role in the development of data-driven approaches, and evaluation\nmethods, because they are generally used to compare different systems and\ndetermine their performance.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 17:24:09 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 22:27:01 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Michelsanti", "Daniel", ""], ["Tan", "Zheng-Hua", ""], ["Zhang", "Shi-Xiong", ""], ["Xu", "Yong", ""], ["Yu", "Meng", ""], ["Yu", "Dong", ""], ["Jensen", "Jesper", ""]]}, {"id": "2008.09590", "submitter": "Majid Raeis", "authors": "Majid Raeis, Ali Tizghadam and Alberto Leon-Garcia", "title": "Reinforcement Learning-based Admission Control in Delay-sensitive\n  Service Systems", "comments": "7 pages, to be presented at IEEE GLOBECOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.AI cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring quality of service (QoS) guarantees in service systems is a\nchallenging task, particularly when the system is composed of more fine-grained\nservices, such as service function chains. An important QoS metric in service\nsystems is the end-to-end delay, which becomes even more important in\ndelay-sensitive applications, where the jobs must be completed within a time\ndeadline. Admission control is one way of providing end-to-end delay guarantee,\nwhere the controller accepts a job only if it has a high probability of meeting\nthe deadline. In this paper, we propose a reinforcement learning-based\nadmission controller that guarantees a probabilistic upper-bound on the\nend-to-end delay of the service system, while minimizes the probability of\nunnecessary rejections. Our controller only uses the queue length information\nof the network and requires no knowledge about the network topology or system\nparameters. Since long-term performance metrics are of great importance in\nservice systems, we take an average-reward reinforcement learning approach,\nwhich is well suited to infinite horizon problems. Our evaluations verify that\nthe proposed RL-based admission controller is capable of providing\nprobabilistic bounds on the end-to-end delay of the network, without using\nsystem model information.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 17:33:55 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Raeis", "Majid", ""], ["Tizghadam", "Ali", ""], ["Leon-Garcia", "Alberto", ""]]}, {"id": "2008.09606", "submitter": "Raphael Tang", "authors": "Raphael Tang, Jaejun Lee, Afsaneh Razi, Julia Cambre, Ian Bicking,\n  Jofish Kaye, Jimmy Lin", "title": "Howl: A Deployed, Open-Source Wake Word Detection System", "comments": "The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We describe Howl, an open-source wake word detection toolkit with native\nsupport for open speech datasets, like Mozilla Common Voice and Google Speech\nCommands. We report benchmark results on Speech Commands and our own freely\navailable wake word detection dataset, built from MCV. We operationalize our\nsystem for Firefox Voice, a plugin enabling speech interactivity for the\nFirefox web browser. Howl represents, to the best of our knowledge, the first\nfully productionized yet open-source wake word detection toolkit with a web\nbrowser deployment target. Our codebase is at\nhttps://github.com/castorini/howl.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 17:59:01 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Tang", "Raphael", ""], ["Lee", "Jaejun", ""], ["Razi", "Afsaneh", ""], ["Cambre", "Julia", ""], ["Bicking", "Ian", ""], ["Kaye", "Jofish", ""], ["Lin", "Jimmy", ""]]}, {"id": "2008.09622", "submitter": "Changan Chen", "authors": "Changan Chen, Sagnik Majumder, Ziad Al-Halah, Ruohan Gao, Santhosh\n  Kumar Ramakrishnan, Kristen Grauman", "title": "Learning to Set Waypoints for Audio-Visual Navigation", "comments": "Accepted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In audio-visual navigation, an agent intelligently travels through a complex,\nunmapped 3D environment using both sights and sounds to find a sound source\n(e.g., a phone ringing in another room). Existing models learn to act at a\nfixed granularity of agent motion and rely on simple recurrent aggregations of\nthe audio observations. We introduce a reinforcement learning approach to\naudio-visual navigation with two key novel elements: 1) waypoints that are\ndynamically set and learned end-to-end within the navigation policy, and 2) an\nacoustic memory that provides a structured, spatially grounded record of what\nthe agent has heard as it moves. Both new ideas capitalize on the synergy of\naudio and visual data for revealing the geometry of an unmapped space. We\ndemonstrate our approach on two challenging datasets of real-world 3D scenes,\nReplica and Matterport3D. Our model improves the state of the art by a\nsubstantial margin, and our experiments reveal that learning the links between\nsights, sounds, and space is essential for audio-visual navigation. Project:\nhttp://vision.cs.utexas.edu/projects/audio_visual_waypoints.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 18:00:33 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 16:47:31 GMT"}, {"version": "v3", "created": "Thu, 11 Feb 2021 18:36:45 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Chen", "Changan", ""], ["Majumder", "Sagnik", ""], ["Al-Halah", "Ziad", ""], ["Gao", "Ruohan", ""], ["Ramakrishnan", "Santhosh Kumar", ""], ["Grauman", "Kristen", ""]]}, {"id": "2008.09623", "submitter": "Zhengdao Chen", "authors": "Zhengdao Chen, Grant M. Rotskoff, Joan Bruna, Eric Vanden-Eijnden", "title": "A Dynamical Central Limit Theorem for Shallow Neural Networks", "comments": "To appear in Advances in Neural Information Processing Systems 33\n  (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent theoretical works have characterized the dynamics of wide shallow\nneural networks trained via gradient descent in an asymptotic mean-field limit\nwhen the width tends towards infinity. At initialization, the random sampling\nof the parameters leads to deviations from the mean-field limit dictated by the\nclassical Central Limit Theorem (CLT). However, since gradient descent induces\ncorrelations among the parameters, it is of interest to analyze how these\nfluctuations evolve. Here, we use a dynamical CLT to prove that the asymptotic\nfluctuations around the mean limit remain bounded in mean square throughout\ntraining. The upper bound is given by a Monte-Carlo resampling error, with a\nvariance that that depends on the 2-norm of the underlying measure, which also\ncontrols the generalization error. This motivates the use of this 2-norm as a\nregularization term during training. Furthermore, if the mean-field dynamics\nconverges to a measure that interpolates the training data, we prove that the\nasymptotic deviation eventually vanishes in the CLT scaling. We also complement\nthese results with numerical experiments.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 18:00:50 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 16:22:30 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Chen", "Zhengdao", ""], ["Rotskoff", "Grant M.", ""], ["Bruna", "Joan", ""], ["Vanden-Eijnden", "Eric", ""]]}, {"id": "2008.09624", "submitter": "Mohammad Rasool Izadi", "authors": "Mohammad Rasool Izadi, Yihao Fang, Robert Stevenson, Lizhen Lin", "title": "Optimization of Graph Neural Networks with Natural Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose to employ information-geometric tools to optimize a\ngraph neural network architecture such as the graph convolutional networks.\nMore specifically, we develop optimization algorithms for the graph-based\nsemi-supervised learning by employing the natural gradient information in the\noptimization process. This allows us to efficiently exploit the geometry of the\nunderlying statistical model or parameter space for optimization and inference.\nTo the best of our knowledge, this is the first work that has utilized the\nnatural gradient for the optimization of graph neural networks that can be\nextended to other semi-supervised problems. Efficient computations algorithms\nare developed and extensive numerical studies are conducted to demonstrate the\nsuperior performance of our algorithms over existing algorithms such as ADAM\nand SGD.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 18:00:53 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Izadi", "Mohammad Rasool", ""], ["Fang", "Yihao", ""], ["Stevenson", "Robert", ""], ["Lin", "Lizhen", ""]]}, {"id": "2008.09641", "submitter": "Nicol\\'as Astorga", "authors": "Nicol\\'as Astorga, Pablo Huijse, Pavlos Protopapas and Pablo Est\\'evez", "title": "MPCC: Matching Priors and Conditionals for Clustering", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a fundamental task in unsupervised learning that depends\nheavily on the data representation that is used. Deep generative models have\nappeared as a promising tool to learn informative low-dimensional data\nrepresentations. We propose Matching Priors and Conditionals for Clustering\n(MPCC), a GAN-based model with an encoder to infer latent variables and cluster\ncategories from data, and a flexible decoder to generate samples from a\nconditional latent space. With MPCC we demonstrate that a deep generative model\ncan be competitive/superior against discriminative methods in clustering tasks\nsurpassing the state of the art over a diverse set of benchmark datasets. Our\nexperiments show that adding a learnable prior and augmenting the number of\nencoder updates improve the quality of the generated samples, obtaining an\ninception score of 9.49 $\\pm$ 0.15 and improving the Fr\\'echet inception\ndistance over the state of the art by a 46.9% in CIFAR10.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 18:35:40 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Astorga", "Nicol\u00e1s", ""], ["Huijse", "Pablo", ""], ["Protopapas", "Pavlos", ""], ["Est\u00e9vez", "Pablo", ""]]}, {"id": "2008.09643", "submitter": "Rachel Luo", "authors": "Rachel Luo, Shengjia Zhao, Jiaming Song, Jonathan Kuck, Stefano Ermon,\n  Silvio Savarese", "title": "Privacy Preserving Recalibration under Domain Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers deployed in high-stakes real-world applications must output\ncalibrated confidence scores, i.e. their predicted probabilities should reflect\nempirical frequencies. Recalibration algorithms can greatly improve a model's\nprobability estimates; however, existing algorithms are not applicable in\nreal-world situations where the test data follows a different distribution from\nthe training data, and privacy preservation is paramount (e.g. protecting\npatient records). We introduce a framework that abstracts out the properties of\nrecalibration problems under differential privacy constraints. This framework\nallows us to adapt existing recalibration algorithms to satisfy differential\nprivacy while remaining effective for domain-shift situations. Guided by our\nframework, we also design a novel recalibration algorithm, accuracy temperature\nscaling, that outperforms prior work on private datasets. In an extensive\nempirical study, we find that our algorithm improves calibration on\ndomain-shift benchmarks under the constraints of differential privacy. On the\n15 highest severity perturbations of the ImageNet-C dataset, our method\nachieves a median ECE of 0.029, over 2x better than the next best recalibration\nmethod and almost 5x better than without recalibration.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 18:43:37 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Luo", "Rachel", ""], ["Zhao", "Shengjia", ""], ["Song", "Jiaming", ""], ["Kuck", "Jonathan", ""], ["Ermon", "Stefano", ""], ["Savarese", "Silvio", ""]]}, {"id": "2008.09646", "submitter": "Abhinav Sagar", "authors": "Abhinav Sagar", "title": "HRVGAN: High Resolution Video Generation using Spatio-Temporal GAN", "comments": "The design of neural network was based on assumptions which was found\n  to be wrong", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel network for high resolution video\ngeneration. Our network uses ideas from Wasserstein GANs by enforcing\nk-Lipschitz constraint on the loss term and Conditional GANs using class labels\nfor training and testing. We present Generator and Discriminator network\nlayerwise details along with the combined network architecture, optimization\ndetails and algorithm used in this work. Our network uses a combination of two\nloss terms: mean square pixel loss and an adversarial loss. The datasets used\nfor training and testing our network are UCF101, Golf and Aeroplane Datasets.\nUsing Inception Score and Fr\\'echet Inception Distance as the evaluation\nmetrics, our network outperforms previous state of the art networks on\nunsupervised video generation.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 20:45:59 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 05:47:07 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Sagar", "Abhinav", ""]]}, {"id": "2008.09655", "submitter": "Elizaveta Logacheva", "authors": "Elizaveta Logacheva, Roman Suvorov, Oleg Khomenko, Anton Mashikhin and\n  Victor Lempitsky", "title": "DeepLandscape: Adversarial Modeling of Landscape Video", "comments": "Accepted at ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build a new model of landscape videos that can be trained on a mixture of\nstatic landscape images as well as landscape animations. Our architecture\nextends StyleGAN model by augmenting it with parts that allow to model dynamic\nchanges in a scene. Once trained, our model can be used to generate realistic\ntime-lapse landscape videos with moving objects and time-of-the-day changes.\nFurthermore, by fitting the learned models to a static landscape image, the\nlatter can be reenacted in a realistic way. We propose simple but necessary\nmodifications to StyleGAN inversion procedure, which lead to in-domain latent\ncodes and allow to manipulate real images. Quantitative comparisons and user\nstudies suggest that our model produces more compelling animations of given\nphotographs than previously proposed methods. The results of our approach\nincluding comparisons with prior art can be seen in supplementary materials and\non the project page https://saic-mdal.github.io/deep-landscape\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 19:14:19 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Logacheva", "Elizaveta", ""], ["Suvorov", "Roman", ""], ["Khomenko", "Oleg", ""], ["Mashikhin", "Anton", ""], ["Lempitsky", "Victor", ""]]}, {"id": "2008.09657", "submitter": "Arnab Bhattacharya", "authors": "Sunil Nishad and Shubhangi Agarwal and Arnab Bhattacharya and Sayan\n  Ranu", "title": "GraphReach: Position-Aware Graph Neural Network using Reachability\n  Estimations", "comments": null, "journal-ref": "IJCAI 2021", "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Majority of the existing graph neural networks (GNN) learn node embeddings\nthat encode their local neighborhoods but not their positions. Consequently,\ntwo nodes that are vastly distant but located in similar local neighborhoods\nmap to similar embeddings in those networks. This limitation prevents accurate\nperformance in predictive tasks that rely on position information. In this\npaper,we develop GraphReach, a position-aware inductive GNN that captures the\nglobal positions of nodes through reachability estimations with respect to a\nset of anchor nodes. The anchors are strategically selected so that\nreachability estimations across all the nodes are maximized. We show that this\ncombinatorial anchor selection problem is NP-hard and, consequently, develop a\ngreedy (1-1/e) approximation heuristic. Empirical evaluation against\nstate-of-the-art GNN architectures reveal that GraphReach provides up to 40%\nrelative improvement in accuracy. In addition, it is more robust to adversarial\nattacks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 14:30:03 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 11:51:31 GMT"}, {"version": "v3", "created": "Thu, 20 May 2021 10:00:36 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Nishad", "Sunil", ""], ["Agarwal", "Shubhangi", ""], ["Bhattacharya", "Arnab", ""], ["Ranu", "Sayan", ""]]}, {"id": "2008.09662", "submitter": "Alhabib Abbas", "authors": "Alhabib Abbas and Yiannis Andreopoulos", "title": "Biased Mixtures Of Experts: Enabling Computer Vision Inference Under\n  Data Transfer Limitations", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2020.3005508", "report-no": null, "categories": "cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel mixture-of-experts class to optimize computer vision\nmodels in accordance with data transfer limitations at test time. Our approach\npostulates that the minimum acceptable amount of data allowing for\nhighly-accurate results can vary for different input space partitions.\nTherefore, we consider mixtures where experts require different amounts of\ndata, and train a sparse gating function to divide the input space for each\nexpert. By appropriate hyperparameter selection, our approach is able to bias\nmixtures of experts towards selecting specific experts over others. In this\nway, we show that the data transfer optimization between visual sensing and\nprocessing can be solved as a convex optimization problem.To demonstrate the\nrelation between data availability and performance, we evaluate biased mixtures\non a range of mainstream computer vision problems, namely: (i) single shot\ndetection, (ii) image super resolution, and (iii) realtime video action\nclassification. For all cases, and when experts constitute modified baselines\nto meet different limits on allowed data utility, biased mixtures significantly\noutperform previous work optimized to meet the same constraints on available\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 19:38:26 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Abbas", "Alhabib", ""], ["Andreopoulos", "Yiannis", ""]]}, {"id": "2008.09667", "submitter": "Xiao Li", "authors": "Xiao Li and Weili Wu", "title": "A Blockchain Transaction Graph based Machine Learning Method for Bitcoin\n  Price Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin, as one of the most popular cryptocurrency, is recently attracting\nmuch attention of investors. Bitcoin price prediction task is consequently a\nrising academic topic for providing valuable insights and suggestions. Existing\nbitcoin prediction works mostly base on trivial feature engineering, that\nmanually designs features or factors from multiple areas, including Bticoin\nBlockchain information, finance and social media sentiments. The feature\nengineering not only requires much human effort, but the effectiveness of the\nintuitively designed features can not be guaranteed. In this paper, we aim to\nmining the abundant patterns encoded in bitcoin transactions, and propose\nk-order transaction graph to reveal patterns under different scope. We propose\nthe transaction graph based feature to automatically encode the patterns. A\nnovel prediction method is proposed to accept the features and make price\nprediction, which can take advantage from particular patterns from different\nhistory period. The results of comparison experiments demonstrate that the\nproposed method outperforms the most recent state-of-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 20:08:17 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Li", "Xiao", ""], ["Wu", "Weili", ""]]}, {"id": "2008.09680", "submitter": "Ryan Bernstein", "authors": "Ryan Bernstein, Matthijs V\\'ak\\'ar, Jeannette Wing", "title": "Transforming Probabilistic Programs for Model Checking", "comments": "To be published in Proceedings of the 2020 ACM-IMS Foundations of\n  Data Science Conference", "journal-ref": null, "doi": "10.1145/3412815.3416896", "report-no": null, "categories": "cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic programming is perfectly suited to reliable and transparent\ndata science, as it allows the user to specify their models in a high-level\nlanguage without worrying about the complexities of how to fit the models.\nStatic analysis of probabilistic programs presents even further opportunities\nfor enabling a high-level style of programming, by automating time-consuming\nand error-prone tasks. We apply static analysis to probabilistic programs to\nautomate large parts of two crucial model checking methods: Prior Predictive\nChecks and Simulation-Based Calibration. Our method transforms a probabilistic\nprogram specifying a density function into an efficient forward-sampling form.\nTo achieve this transformation, we extract a factor graph from a probabilistic\nprogram using static analysis, generate a set of proposal directed acyclic\ngraphs using a SAT solver, select a graph which will produce provably correct\nsampling code, then generate one or more sampling programs. We allow minimal\nuser interaction to broaden the scope of application beyond what is possible\nwith static analysis alone. We present an implementation targeting the popular\nStan probabilistic programming language, automating large parts of a robust\nBayesian workflow for a wide community of probabilistic programming users.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 21:06:34 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Bernstein", "Ryan", ""], ["V\u00e1k\u00e1r", "Matthijs", ""], ["Wing", "Jeannette", ""]]}, {"id": "2008.09685", "submitter": "Rafael Pinto", "authors": "Rafael Pinto", "title": "Model-Free Episodic Control with State Aggregation", "comments": "8 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Episodic control provides a highly sample-efficient method for reinforcement\nlearning while enforcing high memory and computational requirements. This work\nproposes a simple heuristic for reducing these requirements, and an application\nto Model-Free Episodic Control (MFEC) is presented. Experiments on Atari games\nshow that this heuristic successfully reduces MFEC computational demands while\nproducing no significant loss of performance when conservative choices of\nhyperparameters are used. Consequently, episodic control becomes a more\nfeasible option when dealing with reinforcement learning tasks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 21:20:49 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Pinto", "Rafael", ""]]}, {"id": "2008.09695", "submitter": "Huiqi Deng", "authors": "Huiqi Deng, Na Zou, Mengnan Du, Weifu Chen, Guocan Feng, and Xia Hu", "title": "A Unified Taylor Framework for Revisiting Attribution Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribution methods have been developed to understand the decision-making\nprocess of machine learning models, especially deep neural networks, by\nassigning importance scores to individual features. Existing attribution\nmethods often built upon empirical intuitions and heuristics. There still lacks\na general and theoretical framework that not only can unify these attribution\nmethods, but also theoretically reveal their rationales, fidelity, and\nlimitations. To bridge the gap, in this paper, we propose a Taylor attribution\nframework and reformulate seven mainstream attribution methods into the\nframework. Based on reformulations, we analyze the attribution methods in terms\nof rationale, fidelity, and limitation. Moreover, We establish three principles\nfor a good attribution in the Taylor attribution framework, i.e., low\napproximation error, correct contribution assignment, and unbiased baseline\nselection. Finally, we empirically validate the Taylor reformulations and\nreveal a positive correlation between the attribution performance and the\nnumber of principles followed by the attribution method via benchmarking on\nreal-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 22:07:06 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 11:38:08 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 09:00:51 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Deng", "Huiqi", ""], ["Zou", "Na", ""], ["Du", "Mengnan", ""], ["Chen", "Weifu", ""], ["Feng", "Guocan", ""], ["Hu", "Xia", ""]]}, {"id": "2008.09713", "submitter": "Arshad Khan Dr", "authors": "Muhammad Aleem, Rahul Raj and Arshad Khan", "title": "Comparative performance analysis of the ResNet backbones of Mask RCNN to\n  segment the signs of COVID-19 in chest CT scans", "comments": "11 pages, 10 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 has been detrimental in terms of the number of fatalities and rising\nnumber of critical patients across the world. According to the UNDP (United\nNational Development Programme) Socio-Economic programme, aimed at the COVID-19\ncrisis, the pandemic is far more than a health crisis: it is affecting\nsocieties and economies at their core. There has been greater developments\nrecently in the chest X-ray-based imaging technique as part of the COVID-19\ndiagnosis especially using Convolution Neural Networks (CNN) for recognising\nand classifying images. However, given the limitation of supervised labelled\nimaging data, the classification and predictive risk modelling of medical\ndiagnosis tend to compromise. This paper aims to identify and monitor the\neffects of COVID-19 on the human lungs by employing Deep Neural Networks on\naxial CT (Chest Computed Tomography) scan of lungs. We have adopted Mask RCNN,\nwith ResNet50 and ResNet101 as its backbone, to segment the regions, affected\nby COVID-19 coronavirus. Using the regions of human lungs, where symptoms have\nmanifested, the model classifies condition of the patient as either \"Mild\" or\n\"Alarming\". Moreover, the model is deployed on the Google Cloud Platform (GCP)\nto simulate the online usage of the model for performance evaluation and\naccuracy improvement. The ResNet101 backbone model produces an F1 score of 0.85\nand faster prediction scores with an average time of 9.04 seconds per\ninference.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 23:42:08 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Aleem", "Muhammad", ""], ["Raj", "Rahul", ""], ["Khan", "Arshad", ""]]}, {"id": "2008.09727", "submitter": "Thien Q. Tran", "authors": "Thien Q. Tran, Jun Sakuma", "title": "Seasonal-adjustment Based Feature Selection Method for Large-scale\n  Search Engine Logs", "comments": "The 25th ACM SIGKDD Conference on Knowledge Discovery and Data Mining\n  (KDD '19)", "journal-ref": null, "doi": "10.1145/3292500.3330766", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search engine logs have a great potential in tracking and predicting\noutbreaks of infectious disease. More precisely, one can use the search volume\nof some search terms to predict the infection rate of an infectious disease in\nnearly real-time. However, conducting accurate and stable prediction of\noutbreaks using search engine logs is a challenging task due to the following\ntwo-way instability characteristics of the search logs. First, the search\nvolume of a search term may change irregularly in the short-term, for example,\ndue to environmental factors such as the amount of media or news. Second, the\nsearch volume may also change in the long-term due to the demographic change of\nthe search engine. That is to say, if a model is trained with such search logs\nwith ignoring such characteristic, the resulting prediction would contain\nserious mispredictions when these changes occur.\n  In this work, we proposed a novel feature selection method to overcome this\ninstability problem. In particular, we employ a seasonal-adjustment method that\ndecomposes each time series into three components: seasonal, trend and\nirregular component and build prediction models for each component\nindividually. We also carefully design a feature selection method to select\nproper search terms to predict each component. We conducted comprehensive\nexperiments on ten different kinds of infectious diseases. The experimental\nresults show that the proposed method outperforms all comparative methods in\nprediction accuracy for seven of ten diseases, in both now-casting and\nforecasting setting. Also, the proposed method is more successful in selecting\nsearch terms that are semantically related to target diseases.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 01:35:25 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Tran", "Thien Q.", ""], ["Sakuma", "Jun", ""]]}, {"id": "2008.09728", "submitter": "Sumit Mandal", "authors": "Sumit K. Mandal, Umit Y. Ogras, Janardhan Rao Doppa, Raid Z. Ayoub,\n  Michael Kishinevsky, Partha P. Pande", "title": "Online Adaptive Learning for Runtime Resource Management of\n  Heterogeneous SoCs", "comments": "This paper appeared in the Proceedings of Design Automation\n  Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic resource management has become one of the major areas of research in\nmodern computer and communication system design due to lower power consumption\nand higher performance demands. The number of integrated cores, level of\nheterogeneity and amount of control knobs increase steadily. As a result, the\nsystem complexity is increasing faster than our ability to optimize and\ndynamically manage the resources. Moreover, offline approaches are sub-optimal\ndue to workload variations and large volume of new applications unknown at\ndesign time. This paper first reviews recent online learning techniques for\npredicting system performance, power, and temperature. Then, we describe the\nuse of predictive models for online control using two modern approaches:\nimitation learning (IL) and an explicit nonlinear model predictive control\n(NMPC). Evaluations on a commercial mobile platform with 16 benchmarks show\nthat the IL approach successfully adapts the control policy to unknown\napplications. The explicit NMPC provides 25% energy savings compared to a\nstate-of-the-art algorithm for multi-variable power management of modern GPU\nsub-systems.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 01:39:32 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Mandal", "Sumit K.", ""], ["Ogras", "Umit Y.", ""], ["Doppa", "Janardhan Rao", ""], ["Ayoub", "Raid Z.", ""], ["Kishinevsky", "Michael", ""], ["Pande", "Partha P.", ""]]}, {"id": "2008.09733", "submitter": "Junyu Cao", "authors": "Junyu Cao, Wei Sun, Zuo-Jun (Max) Shen, Markus Ettl", "title": "Fatigue-aware Bandits for Dependent Click Models", "comments": null, "journal-ref": "AAAI. 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As recommender systems send a massive amount of content to keep users\nengaged, users may experience fatigue which is contributed by 1) an\noverexposure to irrelevant content, 2) boredom from seeing too many similar\nrecommendations. To address this problem, we consider an online learning\nsetting where a platform learns a policy to recommend content that takes user\nfatigue into account. We propose an extension of the Dependent Click Model\n(DCM) to describe users' behavior. We stipulate that for each piece of content,\nits attractiveness to a user depends on its intrinsic relevance and a discount\nfactor which measures how many similar contents have been shown. Users view the\nrecommended content sequentially and click on the ones that they find\nattractive. Users may leave the platform at any time, and the probability of\nexiting is higher when they do not like the content. Based on user's feedback,\nthe platform learns the relevance of the underlying content as well as the\ndiscounting effect due to content fatigue. We refer to this learning task as\n\"fatigue-aware DCM Bandit\" problem. We consider two learning scenarios\ndepending on whether the discounting effect is known. For each scenario, we\npropose a learning algorithm which simultaneously explores and exploits, and\ncharacterize its regret bound.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 02:18:15 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Cao", "Junyu", "", "Max"], ["Sun", "Wei", "", "Max"], ["Zuo-Jun", "", "", "Max"], ["Shen", "", ""], ["Ettl", "Markus", ""]]}, {"id": "2008.09747", "submitter": "Zeeshan Ahmad", "authors": "Zeeshan Ahmad and Naimul Khan", "title": "Towards Improved Human Action Recognition Using Convolutional Neural\n  Networks and Multimodal Fusion of Depth and Inertial Sensor Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper attempts at improving the accuracy of Human Action Recognition\n(HAR) by fusion of depth and inertial sensor data. Firstly, we transform the\ndepth data into Sequential Front view Images(SFI) and fine-tune the pre-trained\nAlexNet on these images. Then, inertial data is converted into Signal Images\n(SI) and another convolutional neural network (CNN) is trained on these images.\nFinally, learned features are extracted from both CNN, fused together to make a\nshared feature layer, and these features are fed to the classifier. We\nexperiment with two classifiers, namely Support Vector Machines (SVM) and\nsoftmax classifier and compare their performances. The recognition accuracies\nof each modality, depth data alone and sensor data alone are also calculated\nand compared with fusion based accuracies to highlight the fact that fusion of\nmodalities yields better results than individual modalities. Experimental\nresults on UTD-MHAD and Kinect 2D datasets show that proposed method achieves\nstate of the art results when compared to other recently proposed\nvisual-inertial action recognition methods.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 03:41:34 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Ahmad", "Zeeshan", ""], ["Khan", "Naimul", ""]]}, {"id": "2008.09748", "submitter": "Zeeshan Ahmad", "authors": "Zeeshan Ahmad and Naimul Khan", "title": "Multidomain Multimodal Fusion For Human Action Recognition Using\n  Inertial Sensors", "comments": null, "journal-ref": null, "doi": "10.1109/BigMM.2019.00074", "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the major reasons for misclassification of multiplex actions during\naction recognition is the unavailability of complementary features that provide\nthe semantic information about the actions. In different domains these features\nare present with different scales and intensities. In existing literature,\nfeatures are extracted independently in different domains, but the benefits\nfrom fusing these multidomain features are not realized. To address this\nchallenge and to extract complete set of complementary information, in this\npaper, we propose a novel multidomain multimodal fusion framework that extracts\ncomplementary and distinct features from different domains of the input\nmodality. We transform input inertial data into signal images, and then make\nthe input modality multidomain and multimodal by transforming spatial domain\ninformation into frequency and time-spectrum domain using Discrete Fourier\nTransform (DFT) and Gabor wavelet transform (GWT) respectively. Features in\ndifferent domains are extracted by Convolutional Neural networks (CNNs) and\nthen fused by Canonical Correlation based Fusion (CCF) for improving the\naccuracy of human action recognition. Experimental results on three inertial\ndatasets show the superiority of the proposed method when compared to the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 03:46:12 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Ahmad", "Zeeshan", ""], ["Khan", "Naimul", ""]]}, {"id": "2008.09763", "submitter": "Jiaqing Xie", "authors": "Hongyuan Dong, Jiaqing Xie, Zhi Jing, Dexin Ren", "title": "Variational Autoencoder for Anti-Cancer Drug Response Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cancer is a primary cause of human death, but discovering drugs and tailoring\ncancer therapies are expensive and time-consuming. We seek to facilitate the\ndiscovery of new drugs and treatment strategies for cancer using variational\nautoencoders (VAEs) and multi-layer perceptrons (MLPs) to predict anti-cancer\ndrug responses. Our model takes as input gene expression data of cancer cell\nlines and anti-cancer drug molecular data and encodes these data with our {\\sc\n{GeneVae}} model, which is an ordinary VAE model, and a rectified junction tree\nvariational autoencoder ({\\sc JTVae}) model, respectively. A multi-layer\nperceptron processes these encoded features to produce a final prediction. Our\ntests show our system attains a high average coefficient of determination\n($R^{2} = 0.83$) in predicting drug responses for breast cancer cell lines and\nan average $R^{2} = 0.845$ for pan-cancer cell lines. Additionally, we show\nthat our model can generates effective drug compounds not previously used for\nspecific cancer cell lines.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 06:03:22 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 15:00:42 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 12:32:32 GMT"}, {"version": "v4", "created": "Tue, 29 Sep 2020 13:10:25 GMT"}, {"version": "v5", "created": "Sat, 7 Nov 2020 02:10:01 GMT"}, {"version": "v6", "created": "Wed, 25 Nov 2020 04:36:14 GMT"}, {"version": "v7", "created": "Thu, 15 Apr 2021 09:08:43 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Dong", "Hongyuan", ""], ["Xie", "Jiaqing", ""], ["Jing", "Zhi", ""], ["Ren", "Dexin", ""]]}, {"id": "2008.09768", "submitter": "Yuying Liu", "authors": "Yuying Liu, J. Nathan Kutz, Steven L. Brunton", "title": "Hierarchical Deep Learning of Multiscale Differential Equation\n  Time-Steppers", "comments": "22 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear differential equations rarely admit closed-form solutions, thus\nrequiring numerical time-stepping algorithms to approximate solutions. Further,\nmany systems characterized by multiscale physics exhibit dynamics over a vast\nrange of timescales, making numerical integration computationally expensive due\nto numerical stiffness. In this work, we develop a hierarchy of deep neural\nnetwork time-steppers to approximate the flow map of the dynamical system over\na disparate range of time-scales. The resulting model is purely data-driven and\nleverages features of the multiscale dynamics, enabling numerical integration\nand forecasting that is both accurate and highly efficient. Moreover, similar\nideas can be used to couple neural network-based models with classical\nnumerical time-steppers. Our multiscale hierarchical time-stepping scheme\nprovides important advantages over current time-stepping algorithms, including\n(i) circumventing numerical stiffness due to disparate time-scales, (ii)\nimproved accuracy in comparison with leading neural-network architectures,\n(iii) efficiency in long-time simulation/forecasting due to explicit training\nof slow time-scale dynamics, and (iv) a flexible framework that is\nparallelizable and may be integrated with standard numerical time-stepping\nalgorithms. The method is demonstrated on a wide range of nonlinear dynamical\nsystems, including the Van der Pol oscillator, the Lorenz system, the\nKuramoto-Sivashinsky equation, and fluid flow pass a cylinder; audio and video\nsignals are also explored. On the sequence generation examples, we benchmark\nour algorithm against state-of-the-art methods, such as LSTM, reservoir\ncomputing, and clockwork RNN. Despite the structural simplicity of our method,\nit outperforms competing methods on numerical integration.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 07:16:53 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Liu", "Yuying", ""], ["Kutz", "J. Nathan", ""], ["Brunton", "Steven L.", ""]]}, {"id": "2008.09775", "submitter": "Qiang Liu", "authors": "Zhaocheng Liu and Qiang Liu and Haoli Zhang and Yuntian Chen", "title": "DNN2LR: Interpretation-inspired Feature Crossing for Real-world Tabular\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For sake of reliability, it is necessary for models in real-world\napplications to be both powerful and globally interpretable. Simple\nclassifiers, e.g., Logistic Regression (LR), are globally interpretable, but\nnot powerful enough to model complex nonlinear interactions among features in\ntabular data. Meanwhile, Deep Neural Networks (DNNs) have shown great\neffectiveness for modeling tabular data, but is not globally interpretable. In\nthis work, we find local piece-wise interpretations in DNN of a specific\nfeature are usually inconsistent in different samples, which is caused by\nfeature interactions in the hidden layers. Accordingly, we can design an\nautomatic feature crossing method to find feature interactions in DNN, and use\nthem as cross features in LR. We give definition of the interpretation\ninconsistency in DNN, based on which a novel feature crossing method called\nDNN2LR is proposed. Extensive experiments have been conducted on four public\ndatasets and two real-world datasets. The final model, i.e., a LR model\nempowered with cross features, generated by DNN2LR can outperform the complex\nDNN model, as well as several state-of-the-art feature crossing methods. The\nexperimental results strongly verify the effectiveness and efficiency of\nDNN2LR, especially on real-world datasets with large numbers of feature fields.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 08:03:15 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 08:28:48 GMT"}, {"version": "v3", "created": "Tue, 10 Nov 2020 04:55:49 GMT"}, {"version": "v4", "created": "Wed, 16 Dec 2020 10:30:34 GMT"}, {"version": "v5", "created": "Tue, 19 Jan 2021 06:54:36 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Liu", "Zhaocheng", ""], ["Liu", "Qiang", ""], ["Zhang", "Haoli", ""], ["Chen", "Yuntian", ""]]}, {"id": "2008.09777", "submitter": "Julien Siems", "authors": "Julien Siems, Lucas Zimmer, Arber Zela, Jovita Lukasik, Margret\n  Keuper, Frank Hutter", "title": "NAS-Bench-301 and the Case for Surrogate Benchmarks for Neural\n  Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most significant barrier to the advancement of Neural Architecture Search\n(NAS) is its demand for large computational resources, which hinders\nscientifically sound empirical evaluations. As a remedy, several tabular NAS\nbenchmarks were proposed to simulate runs of NAS methods in seconds. However,\nall existing tabular NAS benchmarks are limited to extremely small\narchitectural spaces since they rely on exhaustive evaluations of the space.\nThis leads to unrealistic results that do not transfer to larger search spaces.\nTo overcome this fundamental limitation, we propose NAS-Bench-301, the first\nsurrogate NAS benchmark, using a search space containing $10^{18}$\narchitectures, many orders of magnitude larger than any previous tabular NAS\nbenchmark. After motivating the benefits of a surrogate benchmark over a\ntabular one, we fit various regression models on our dataset, which consists of\n$\\sim$60k architecture evaluations, and build surrogates via deep ensembles to\nalso model uncertainty. We benchmark a wide range of NAS algorithms using\nNAS-Bench-301 and obtain comparable results to the true benchmark at a fraction\nof the real cost. Finally, we show how NAS-Bench-301 can be used to generate\nnew scientific insights.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 08:15:52 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 09:32:18 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2020 20:47:10 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Siems", "Julien", ""], ["Zimmer", "Lucas", ""], ["Zela", "Arber", ""], ["Lukasik", "Jovita", ""], ["Keuper", "Margret", ""], ["Hutter", "Frank", ""]]}, {"id": "2008.09820", "submitter": "Nirant K", "authors": "Meghana Bhange and Nirant Kasliwal", "title": "HinglishNLP: Fine-tuned Language Models for Hinglish Sentiment Detection", "comments": "SemEval 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis for code-mixed social media text continues to be an\nunder-explored area. This work adds two common approaches: fine-tuning large\ntransformer models and sample efficient methods like ULMFiT. Prior work\ndemonstrates the efficacy of classical ML methods for polarity detection.\nFine-tuned general-purpose language representation models, such as those of the\nBERT family are benchmarked along with classical machine learning and ensemble\nmethods. We show that NB-SVM beats RoBERTa by 6.2% (relative) F1. The best\nperforming model is a majority-vote ensemble which achieves an F1 of 0.707. The\nleaderboard submission was made under the codalab username nirantk, with F1 of\n0.689.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 12:01:44 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Bhange", "Meghana", ""], ["Kasliwal", "Nirant", ""]]}, {"id": "2008.09824", "submitter": "Iman Saberi", "authors": "Iman Saberi, Fathiyeh Faghih", "title": "Self-Competitive Neural Networks", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have improved the accuracy of classification\nproblems in lots of applications. One of the challenges in training a DNN is\nits need to be fed by an enriched dataset to increase its accuracy and avoid it\nsuffering from overfitting. One way to improve the generalization of DNNs is to\naugment the training data with new synthesized adversarial samples. Recently,\nresearchers have worked extensively to propose methods for data augmentation.\nIn this paper, we generate adversarial samples to refine the Domains of\nAttraction (DoAs) of each class. In this approach, at each stage, we use the\nmodel learned by the primary and generated adversarial data (up to that stage)\nto manipulate the primary data in a way that look complicated to the DNN. The\nDNN is then retrained using the augmented data and then it again generates\nadversarial data that are hard to predict for itself. As the DNN tries to\nimprove its accuracy by competing with itself (generating hard samples and then\nlearning them), the technique is called Self-Competitive Neural Network (SCNN).\nTo generate such samples, we pose the problem as an optimization task, where\nthe network weights are fixed and use a gradient descent based method to\nsynthesize adversarial samples that are on the boundary of their true labels\nand the nearest wrong labels. Our experimental results show that data\naugmentation using SCNNs can significantly increase the accuracy of the\noriginal network. As an example, we can mention improving the accuracy of a CNN\ntrained with 1000 limited training data of MNIST dataset from 94.26% to 98.25%.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 12:28:35 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Saberi", "Iman", ""], ["Faghih", "Fathiyeh", ""]]}, {"id": "2008.09842", "submitter": "Florian Toqu\\'e", "authors": "Florian Toqu\\'e, Etienne C\\^ome, Martin Tr\\'epanier and Latifa\n  Oukhellou", "title": "Forecasting of the Montreal Subway Smart Card Entry Logs with Event Data", "comments": "18 pages, 13 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major goals of transport operators is to adapt the transport\nsupply scheduling to the passenger demand for existing transport networks\nduring each specific period. Another problem mentioned by operators is\naccurately estimating the demand for disposable ticket or pass to adapt ticket\navailability to passenger demand. In this context, we propose generic data\nshaping, allowing the use of well-known regression models (basic, statistical\nand machine learning models) for the long-term forecasting of passenger demand\nwith fine-grained temporal resolution. Specifically, this paper investigates\nthe forecasting until one year ahead of the number of passengers entering each\nstation of a transport network with a quarter-hour aggregation by taking\nplanned events into account (e.g., concerts, shows, and so forth). To compare\nthe models and the quality of the prediction, we use a real smart card and\nevent data set from the city of Montr\\'eal, Canada, that span a three-year\nperiod with two years for training and one year for testing.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 14:08:57 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Toqu\u00e9", "Florian", ""], ["C\u00f4me", "Etienne", ""], ["Tr\u00e9panier", "Martin", ""], ["Oukhellou", "Latifa", ""]]}, {"id": "2008.09845", "submitter": "Hongbin Liu", "authors": "Hongbin Liu, Jinyuan Jia, Neil Zhenqiang Gong", "title": "On the Intrinsic Differential Privacy of Bagging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentially private machine learning trains models while protecting\nprivacy of the sensitive training data. The key to obtain differentially\nprivate models is to introduce noise/randomness to the training process. In\nparticular, existing differentially private machine learning methods add noise\nto the training data, the gradients, the loss function, and/or the model\nitself. Bagging, a popular ensemble learning framework, randomly creates some\nsubsamples of the training data, trains a base model for each subsample using a\nbase learner, and takes majority vote among the base models when making\npredictions. Bagging has intrinsic randomness in the training process as it\nrandomly creates subsamples. Our major theoretical results show that such\nintrinsic randomness already makes Bagging differentially private without the\nneeds of additional noise. In particular, we prove that, for any base learner,\nBagging with and without replacement respectively achieves $\\left(N\\cdot k\n\\cdot \\ln{\\frac{n+1}{n}},1- (\\frac{n-1}{n})^{N\\cdot k}\\right)$-differential\nprivacy and $\\left(\\ln{\\frac{n+1}{n+1-N\\cdot k}}, \\frac{N\\cdot k}{n}\n\\right)$-differential privacy, where $n$ is the training data size, $k$ is the\nsubsample size, and $N$ is the number of base models. Moreover, we prove that\nif no assumptions about the base learner are made, our derived privacy\nguarantees are tight. We empirically evaluate Bagging on MNIST and CIFAR10. Our\nexperimental results demonstrate that Bagging achieves significantly higher\naccuracies than state-of-the-art differentially private machine learning\nmethods with the same privacy budgets.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 14:17:55 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Liu", "Hongbin", ""], ["Jia", "Jinyuan", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "2008.09848", "submitter": "Vladimir Joukov", "authors": "Vladimir Joukov and Dana Kuli\\'c", "title": "Fast Approximate Multi-output Gaussian Processes", "comments": "10 pages, 9 figures, 3 tables, will be submitted to IEEE Transactions\n  on Pattern Analysis and Machine Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes regression models are an appealing machine learning method\nas they learn expressive non-linear models from exemplar data with minimal\nparameter tuning and estimate both the mean and covariance of unseen points.\nHowever, exponential computational complexity growth with the number of\ntraining samples has been a long standing challenge. During training, one has\nto compute and invert an $N \\times N$ kernel matrix at every iteration.\nRegression requires computation of an $m \\times N$ kernel where $N$ and $m$ are\nthe number of training and test points respectively. In this work we show how\napproximating the covariance kernel using eigenvalues and functions leads to an\napproximate Gaussian process with significant reduction in training and\nregression complexity. Training with the proposed approach requires computing\nonly a $N \\times n$ eigenfunction matrix and a $n \\times n$ inverse where $n$\nis a selected number of eigenvalues. Furthermore, regression now only requires\nan $m \\times n$ matrix. Finally, in a special case the hyperparameter\noptimization is completely independent form the number of training samples. The\nproposed method can regress over multiple outputs, estimate the derivative of\nthe regressor of any order, and learn the correlations between them. The\ncomputational complexity reduction, regression capabilities, and multioutput\ncorrelation learning are demonstrated in simulation examples.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 14:34:45 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Joukov", "Vladimir", ""], ["Kuli\u0107", "Dana", ""]]}, {"id": "2008.09858", "submitter": "Ankit Sharma", "authors": "Ankit Sharma, Garima Gupta, Ranjitha Prasad, Arnab Chatterjee,\n  Lovekesh Vig, Gautam Shroff", "title": "Hi-CI: Deep Causal Inference in High Dimensions", "comments": "23 pages, 5 figures, Accepted in Causal Discovery Workshop - KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of counterfactual regression using causal inference\n(CI) in observational studies consisting of high dimensional covariates and\nhigh cardinality treatments. Confounding bias, which leads to inaccurate\ntreatment effect estimation, is attributed to covariates that affect both\ntreatments and outcome. The presence of high-dimensional co-variates\nexacerbates the impact of bias as it is harder to isolate and measure the\nimpact of these confounders. In the presence of high-cardinality treatment\nvariables, CI is rendered ill-posed due to the increase in the number of\ncounterfactual outcomes to be predicted. We propose Hi-CI, a deep neural\nnetwork (DNN) based framework for estimating causal effects in the presence of\nlarge number of covariates, and high-cardinal and continuous treatment\nvariables. The proposed architecture comprises of a decorrelation network and\nan outcome prediction network. In the decorrelation network, we learn a data\nrepresentation in lower dimensions as compared to the original covariates and\naddresses confounding bias alongside. Subsequently, in the outcome prediction\nnetwork, we learn an embedding of high-cardinality and continuous treatments,\njointly with the data representation. We demonstrate the efficacy of causal\neffect prediction of the proposed Hi-CI network using synthetic and real-world\nNEWS datasets.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 15:41:59 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 10:52:23 GMT"}, {"version": "v3", "created": "Fri, 9 Apr 2021 11:56:02 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Sharma", "Ankit", ""], ["Gupta", "Garima", ""], ["Prasad", "Ranjitha", ""], ["Chatterjee", "Arnab", ""], ["Vig", "Lovekesh", ""], ["Shroff", "Gautam", ""]]}, {"id": "2008.09859", "submitter": "Sam Tureski", "authors": "Verena Blaschke, Maxim Korniyenko, Sam Tureski", "title": "CyberWallE at SemEval-2020 Task 11: An Analysis of Feature Engineering\n  for Ensemble Models for Propaganda Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes our participation in the SemEval-2020 task Detection of\nPropaganda Techniques in News Articles. We participate in both subtasks: Span\nIdentification (SI) and Technique Classification (TC). We use a bi-LSTM\narchitecture in the SI subtask and train a complex ensemble model for the TC\nsubtask. Our architectures are built using embeddings from BERT in combination\nwith additional lexical features and extensive label post-processing. Our\nsystems achieve a rank of 8 out of 35 teams in the SI subtask (F1-score:\n43.86%) and 8 out of 31 teams in the TC subtask (F1-score: 57.37%).\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 15:51:16 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Blaschke", "Verena", ""], ["Korniyenko", "Maxim", ""], ["Tureski", "Sam", ""]]}, {"id": "2008.09864", "submitter": "Wenbing Huang", "authors": "Wenbing Huang, Yu Rong, Tingyang Xu, Fuchun Sun, Junzhou Huang", "title": "Tackling Over-Smoothing for General Graph Convolutional Networks", "comments": "Submitted to TPAMI, 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing the depth of GCN, which is expected to permit more expressivity,\nis shown to incur performance detriment especially on node classification. The\nmain cause of this lies in over-smoothing. The over-smoothing issue drives the\noutput of GCN towards a space that contains limited distinguished information\namong nodes, leading to poor expressivity. Several works on refining the\narchitecture of deep GCN have been proposed, but it is still unknown in theory\nwhether or not these refinements are able to relieve over-smoothing. In this\npaper, we first theoretically analyze how general GCNs act with the increase in\ndepth, including generic GCN, GCN with bias, ResGCN, and APPNP. We find that\nall these models are characterized by a universal process: all nodes converging\nto a cuboid. Upon this theorem, we propose DropEdge to alleviate over-smoothing\nby randomly removing a certain number of edges at each training epoch.\nTheoretically, DropEdge either reduces the convergence speed of over-smoothing\nor relieves the information loss caused by dimension collapse. Experimental\nevaluations on simulated dataset have visualized the difference in\nover-smoothing between different GCNs. Moreover, extensive experiments on\nseveral real benchmarks support that DropEdge consistently improves the\nperformance on a variety of both shallow and deep GCNs.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 16:14:01 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 08:36:13 GMT"}, {"version": "v3", "created": "Tue, 8 Sep 2020 09:19:11 GMT"}, {"version": "v4", "created": "Mon, 29 Mar 2021 07:02:59 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Huang", "Wenbing", ""], ["Rong", "Yu", ""], ["Xu", "Tingyang", ""], ["Sun", "Fuchun", ""], ["Huang", "Junzhou", ""]]}, {"id": "2008.09869", "submitter": "Nadezhda Ganzherli", "authors": "Elena Mikhalkova, Nadezhda Ganzherli, Anna Glazkova, Yuliya Bidulya", "title": "UTMN at SemEval-2020 Task 11: A Kitchen Solution to Automatic Propaganda\n  Detection", "comments": "5 pages -- the article proper; 2 pages -- references; 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The article describes a fast solution to propaganda detection at SemEval-2020\nTask 11, based onfeature adjustment. We use per-token vectorization of features\nand a simple Logistic Regressionclassifier to quickly test different hypotheses\nabout our data. We come up with what seems to usthe best solution, however, we\nare unable to align it with the result of the metric suggested by theorganizers\nof the task. We test how our system handles class and feature imbalance by\nvarying thenumber of samples of two classes (Propaganda and None) in the\ntraining set, the size of a contextwindow in which a token is vectorized and\ncombination of vectorization means. The result of oursystem at SemEval2020 Task\n11 is F-score=0.37.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 16:31:01 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Mikhalkova", "Elena", ""], ["Ganzherli", "Nadezhda", ""], ["Glazkova", "Anna", ""], ["Bidulya", "Yuliya", ""]]}, {"id": "2008.09872", "submitter": "Xuanji Xiao", "authors": "Xuanji Xiao, Huabin Chen, Yuzhen Liu, Xing Yao, Pei Liu, Chaosheng\n  Fan, Nian Ji, Xirong Jiang", "title": "LT4REC:A Lottery Ticket Hypothesis Based Multi-task Practice for Video\n  Recommendation System", "comments": "6 pages,4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate prediction (CTR) and post-click conversion rate prediction\n(CVR) play key roles across all industrial ranking systems, such as\nrecommendation systems, online advertising, and search engines. Different from\nthe extensive research on CTR, there is much less research on CVR estimation,\nwhose main challenge is extreme data sparsity with one or two orders of\nmagnitude reduction in the number of samples than CTR. People try to solve this\nproblem with the paradigm of multi-task learning with the sufficient samples of\nCTR, but the typical hard sharing method can't effectively solve this problem,\nbecause it is difficult to analyze which parts of network components can be\nshared and which parts are in conflict, i.e., there is a large inaccuracy with\nartificially designed neurons sharing. In this paper, we model CVR in a\nbrand-new method by adopting the lottery-ticket-hypothesis-based sparse sharing\nmulti-task learning, which can automatically and flexibly learn which neuron\nweights to be shared without artificial experience. Experiments on the dataset\ngathered from traffic logs of Tencent video's recommendation system demonstrate\nthat sparse sharing in the CVR model significantly outperforms competitive\nmethods. Due to the nature of weight sparsity in sparse sharing, it can also\nsignificantly reduce computational complexity and memory usage which are very\nimportant in the industrial recommendation system.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 16:48:08 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Xiao", "Xuanji", ""], ["Chen", "Huabin", ""], ["Liu", "Yuzhen", ""], ["Yao", "Xing", ""], ["Liu", "Pei", ""], ["Fan", "Chaosheng", ""], ["Ji", "Nian", ""], ["Jiang", "Xirong", ""]]}, {"id": "2008.09874", "submitter": "Jongwon Kim", "authors": "Jongwon Kim, Sungho Shin, Yeonguk Yu, Junseok Lee, Kyoobin Lee", "title": "Multiple Classification with Split Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Privacy issues were raised in the process of training deep learning in\nmedical, mobility, and other fields. To solve this problem, we present\nprivacy-preserving distributed deep learning method that allow clients to learn\na variety of data without direct exposure. We divided a single deep learning\narchitecture into a common extractor, a cloud model and a local classifier for\nthe distributed learning. First, the common extractor, which is used by local\nclients, extracts secure features from the input data. The secure features also\ntake the role that the cloud model can employ various task and diverse types of\ndata. The feature contain the most important information that helps to proceed\nvarious task. Second, the cloud model including most parts of the whole\ntraining model gets the embedded features from the massive local clients, and\nperforms most of deep learning operations which takes severe computing cost.\nAfter the operations in cloud model finished, outputs of the cloud model send\nback to local clients. Finally, the local classifier determined classification\nresults and delivers the results to local clients. When clients train models,\nour model does not directly expose sensitive information to exterior network.\nDuring the test, the average performance improvement was 2.63% over the\nexisting local training model. However, in a distributed environment, there is\na possibility of inversion attack due to exposed features. For this reason, we\nexperimented with the common extractor to prevent data restoration. The quality\nof restoration of the original image was tested by adjusting the depth of the\ncommon extractor. As a result, we found that the deeper the common extractor,\nthe restoration score decreased to 89.74.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 16:54:42 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 02:59:45 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 05:18:33 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Kim", "Jongwon", ""], ["Shin", "Sungho", ""], ["Yu", "Yeonguk", ""], ["Lee", "Junseok", ""], ["Lee", "Kyoobin", ""]]}, {"id": "2008.09878", "submitter": "Gurpreet Singh", "authors": "Gurpreet Singh, Soumyajit Gupta, Clint N. Dawson", "title": "Prevention is Better than Cure: Handling Basis Collapse and Transparency\n  in Dense Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense nets are an integral part of any classification and regression problem.\nRecently, these networks have found a new application as solvers for known\nrepresentations in various domains. However, one crucial issue with dense nets\nis it's feature interpretation and lack of reproducibility over multiple\ntraining runs. In this work, we identify a basis collapse issue as a primary\ncause and propose a modified loss function that circumvents this problem. We\nalso provide a few general guidelines relating the choice of activations to\nloss surface roughness and appropriate scaling for designing low-weight dense\nnets. We demonstrate through carefully chosen numerical experiments that the\nbasis collapse issue leads to the design of massively redundant networks. Our\napproach results in substantially concise nets, having $100 \\times$ fewer\nparameters, while achieving a much lower $(10\\times)$ MSE loss at scale than\nreported in prior works. Further, we show that the width of a dense net is\nacutely dependent on the feature complexity. This is in contrast to the\ndimension dependent width choice reported in prior theoretical works. To the\nbest of our knowledge, this is the first time these issues and contradictions\nhave been reported and experimentally verified. With our design guidelines we\nrender transparency in terms of a low-weight network design. We share our codes\nfor full reproducibility available at\nhttps://github.com/smjtgupta/Dense_Net_Regress.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 17:09:54 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Singh", "Gurpreet", ""], ["Gupta", "Soumyajit", ""], ["Dawson", "Clint N.", ""]]}, {"id": "2008.09879", "submitter": "Vasilis Margonis", "authors": "Vasilis Margonis, Athanasios Davvetas, Iraklis A. Klampanos", "title": "WeLa-VAE: Learning Alternative Disentangled Representations Using Weak\n  Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning disentangled representations without supervision or inductive\nbiases, often leads to non-interpretable or undesirable representations. On the\nother hand, strict supervision requires detailed knowledge of the true\ngenerative factors, which is not always possible. In this paper, we consider\nweak supervision by means of high-level labels that are not assumed to be\nexplicitly related to the ground truth factors. Such labels, while being easier\nto acquire, can also be used as inductive biases for algorithms to learn more\ninterpretable or alternative disentangled representations. To this end, we\npropose WeLa-VAE, a variational inference framework where observations and\nlabels share the same latent variables, which involves the maximization of a\nmodified variational lower bound and total correlation regularization. Our\nmethod is a generalization of TCVAE, adding only one extra hyperparameter. We\nexperiment on a dataset generated by Cartesian coordinates and we show that,\nwhile a TCVAE learns a factorized Cartesian representation, given weak labels\nof distance and angle, WeLa-VAE is able to learn and disentangle a polar\nrepresentation. This is achieved without the need of refined labels or having\nto adjust the number of layers, the optimization parameters, or the total\ncorrelation hyperparameter.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 17:13:05 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Margonis", "Vasilis", ""], ["Davvetas", "Athanasios", ""], ["Klampanos", "Iraklis A.", ""]]}, {"id": "2008.09887", "submitter": "Ayush Maheshwari", "authors": "Ayush Maheshwari, Oishik Chatterjee, KrishnaTeja Killamsetty, Ganesh\n  Ramakrishnan, Rishabh Iyer", "title": "Semi-Supervised Data Programming with Subset Selection", "comments": "Findings of ACL, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paradigm of data programming, which uses weak supervision in the form of\nrules/labelling functions, and semi-supervised learning, which augments small\namounts of labelled data with a large unlabelled dataset, have shown great\npromise in several text classification scenarios. In this work, we argue that\nby not using any labelled data, data programming based approaches can yield\nsub-optimal performances, particularly when the labelling functions are noisy.\nThe first contribution of this work is an introduction of a framework, \\model\nwhich is a semi-supervised data programming paradigm that learns a \\emph{joint\nmodel} that effectively uses the rules/labelling functions along with\nsemi-supervised loss functions on the feature space. Next, we also study\n\\modelss which additionally does subset selection on top of the joint\nsemi-supervised data programming objective and \\emph{selects} a set of examples\nthat can be used as the labelled set by \\model. The goal of \\modelss is to\nensure that the labelled data can \\emph{complement} the labelling functions,\nthereby benefiting from both data-programming as well as appropriately selected\ndata for human labelling. We demonstrate that by effectively combining\nsemi-supervision, data-programming, and subset selection paradigms, we\nsignificantly outperform the current state-of-the-art on seven publicly\navailable datasets. \\footnote{The source code is available at\n\\url{https://github.com/ayushbits/Semi-Supervised-LFs-Subset-Selection}}\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 17:53:16 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 09:32:57 GMT"}, {"version": "v3", "created": "Sat, 12 Jun 2021 17:01:00 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Maheshwari", "Ayush", ""], ["Chatterjee", "Oishik", ""], ["Killamsetty", "KrishnaTeja", ""], ["Ramakrishnan", "Ganesh", ""], ["Iyer", "Rishabh", ""]]}, {"id": "2008.09903", "submitter": "Leonardo Enzo Brito Da Silva", "authors": "Leonardo Enzo Brito da Silva and Nagasharath Rayapati and Donald C.\n  Wunsch II", "title": "iCVI-ARTMAP: Accelerating and improving clustering using adaptive\n  resonance theory predictive mapping and incremental cluster validity indices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an adaptive resonance theory predictive mapping (ARTMAP)\nmodel which uses incremental cluster validity indices (iCVIs) to perform\nunsupervised learning, namely iCVI-ARTMAP. Incorporating iCVIs to the\ndecision-making and many-to-one mapping capabilities of ARTMAP can improve the\nchoices of clusters to which samples are incrementally assigned. These\nimprovements are accomplished by intelligently performing the operations of\nswapping sample assignments between clusters, splitting and merging clusters,\nand caching the values of variables when iCVI values need to be recomputed.\nUsing recursive formulations enables iCVI-ARTMAP to considerably reduce the\ncomputational burden associated with cluster validity index (CVI)-based offline\nclustering. Depending on the iCVI and the data set, it can achieve running\ntimes up to two orders of magnitude shorter than when using batch CVI\ncomputations. In this work, the incremental versions of Calinski-Harabasz,\nWB-index, Xie-Beni, Davies-Bouldin, Pakhira-Bandyopadhyay-Maulik, and\nnegentropy increment were integrated into fuzzy ARTMAP. Experimental results\nshow that, with proper choice of iCVI, iCVI-ARTMAP outperformed fuzzy adaptive\nresonance theory (ART), dual vigilance fuzzy ART, kmeans, spectral clustering,\nGaussian mixture models and hierarchical agglomerative clustering algorithms in\nmost of the synthetic benchmark data sets. It also performed competitively on\nreal world image benchmark data sets when clustering on projections and on\nlatent spaces generated by a deep clustering model. Naturally, the performance\nof iCVI-ARTMAP is subject to the selected iCVI and its suitability to the data\nat hand; fortunately, it is a general model wherein other iCVIs can be easily\nembedded.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 19:37:01 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["da Silva", "Leonardo Enzo Brito", ""], ["Rayapati", "Nagasharath", ""], ["Wunsch", "Donald C.", "II"]]}, {"id": "2008.09912", "submitter": "Dongjie Wang", "authors": "Dongjie Wang, Yanjie Fu, Pengyang Wang, Bo Huang, Chang-Tien Lu", "title": "Reimagining City Configuration: Automated Urban Planning via Adversarial\n  Learning", "comments": "Proceedings of the 28th International Conference on Advances in\n  Geographic Information Systems (2020)", "journal-ref": "SIGSPATIAL/GIS 2020: 497-506", "doi": "10.1145/3397536.3422268", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban planning refers to the efforts of designing land-use configurations.\nEffective urban planning can help to mitigate the operational and social\nvulnerability of a urban system, such as high tax, crimes, traffic congestion\nand accidents, pollution, depression, and anxiety. Due to the high complexity\nof urban systems, such tasks are mostly completed by professional planners.\nBut, human planners take longer time. The recent advance of deep learning\nmotivates us to ask: can machines learn at a human capability to automatically\nand quickly calculate land-use configuration, so human planners can finally\nadjust machine-generated plans for specific needs? To this end, we formulate\nthe automated urban planning problem into a task of learning to configure\nland-uses, given the surrounding spatial contexts. To set up the task, we\ndefine a land-use configuration as a longitude-latitude-channel tensor, where\neach channel is a category of POIs and the value of an entry is the number of\nPOIs. The objective is then to propose an adversarial learning framework that\ncan automatically generate such tensor for an unplanned area. In particular, we\nfirst characterize the contexts of surrounding areas of an unplanned area by\nlearning representations from spatial graphs using geographic and human\nmobility data. Second, we combine each unplanned area and its surrounding\ncontext representation as a tuple, and categorize all the tuples into positive\n(well-planned areas) and negative samples (poorly-planned areas). Third, we\ndevelop an adversarial land-use configuration approach, where the surrounding\ncontext representation is fed into a generator to generate a land-use\nconfiguration, and a discriminator learns to distinguish among positive and\nnegative samples.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 21:15:39 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 16:52:19 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Wang", "Dongjie", ""], ["Fu", "Yanjie", ""], ["Wang", "Pengyang", ""], ["Huang", "Bo", ""], ["Lu", "Chang-Tien", ""]]}, {"id": "2008.09915", "submitter": "Sai Ravela", "authors": "Margaret Trautner and Gabriel Margolis and Sai Ravela", "title": "Informative Neural Ensemble Kalman Learning", "comments": "ten pages; accepted for presentation in DDDAS-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In stochastic systems, informative approaches select key measurement or\ndecision variables that maximize information gain to enhance the efficacy of\nmodel-related inferences. Neural Learning also embodies stochastic dynamics,\nbut informative Learning is less developed. Here, we propose Informative\nEnsemble Kalman Learning, which replaces backpropagation with an adaptive\nEnsemble Kalman Filter to quantify uncertainty and enables maximizing\ninformation gain during Learning. After demonstrating Ensemble Kalman\nLearning's competitive performance on standard datasets, we apply the\ninformative approach to neural structure learning. In particular, we show that\nwhen trained from the Lorenz-63 system's simulations, the efficaciously learned\nstructure recovers the dynamical equations. To the best of our knowledge,\nInformative Ensemble Kalman Learning is new. Results suggest that this approach\nto optimized Learning is promising.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 21:30:41 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Trautner", "Margaret", ""], ["Margolis", "Gabriel", ""], ["Ravela", "Sai", ""]]}, {"id": "2008.09916", "submitter": "Ting-Wu Chin", "authors": "Ting-Wu Chin, Pierce I-Jen Chuang, Vikas Chandra, Diana Marculescu", "title": "One Weight Bitwidth to Rule Them All", "comments": "Accepted at ECCV 2020 Embedded Vision Workshop (Best paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight quantization for deep ConvNets has shown promising results for\napplications such as image classification and semantic segmentation and is\nespecially important for applications where memory storage is limited. However,\nwhen aiming for quantization without accuracy degradation, different tasks may\nend up with different bitwidths. This creates complexity for software and\nhardware support and the complexity accumulates when one considers\nmixed-precision quantization, in which case each layer's weights use a\ndifferent bitwidth. Our key insight is that optimizing for the least bitwidth\nsubject to no accuracy degradation is not necessarily an optimal strategy. This\nis because one cannot decide optimality between two bitwidths if one has a\nsmaller model size while the other has better accuracy. In this work, we take\nthe first step to understand if some weight bitwidth is better than others by\naligning all to the same model size using a width-multiplier. Under this\nsetting, somewhat surprisingly, we show that using a single bitwidth for the\nwhole network can achieve better accuracy compared to mixed-precision\nquantization targeting zero accuracy degradation when both have the same model\nsize. In particular, our results suggest that when the number of channels\nbecomes a target hyperparameter, a single weight bitwidth throughout the\nnetwork shows superior results for model compression.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 21:40:22 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 18:49:48 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Chin", "Ting-Wu", ""], ["Chuang", "Pierce I-Jen", ""], ["Chandra", "Vikas", ""], ["Marculescu", "Diana", ""]]}, {"id": "2008.09922", "submitter": "Shashi Bhushan Jha", "authors": "Shashi Bhushan Jha, Vijay Pandey, Rajesh Kumar Jha, Radu F. Babiceanu", "title": "Machine Learning Approaches to Real Estate Market Prediction Problem: A\n  Case Study", "comments": "20 pages, 21 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Home sale prices are formed given the transaction actors economic interests,\nwhich include government, real estate dealers, and the general public who buy\nor sell properties. Generating an accurate property price prediction model is a\nmajor challenge for the real estate market. This work develops a property price\nclassification model using a ten year actual dataset, from January 2010 to\nNovember 2019. The real estate dataset is publicly available and was retrieved\nfrom Volusia County Property Appraiser of Florida website. In addition,\nsocio-economic factors such as Gross Domestic Product, Consumer Price Index,\nProducer Price Index, House Price Index, and Effective Federal Funds Rate are\ncollected and used in the prediction model. To solve this case study problem,\nseveral powerful machine learning algorithms, namely, Logistic Regression,\nRandom Forest, Voting Classifier, and XGBoost, are employed. They are\nintegrated with target encoding to develop an accurate property sale price\nprediction model with the aim to predict whether the closing sale price is\ngreater than or less than the listing sale price. To assess the performance of\nthe models, the accuracy, precision, recall, classification F1 score, and error\nrate of the models are determined. Among the four studied machine learning\nalgorithms, XGBoost delivers superior results and robustness of the model\ncompared to other models. The developed model can facilitate real estate\ninvestors, mortgage lenders and financial institutions to make better informed\ndecisions.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 22:28:58 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Jha", "Shashi Bhushan", ""], ["Pandey", "Vijay", ""], ["Jha", "Rajesh Kumar", ""], ["Babiceanu", "Radu F.", ""]]}, {"id": "2008.09951", "submitter": "Junjie Zhang", "authors": "Junjie Zhang, Cong Zhang, Neal N. Xiong", "title": "DSP: A Differential Spatial Prediction Scheme for Comprehensive real\n  industrial datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse Distance Weighted models (IDW) have been widely used for predicting\nand modeling multidimensional space in multimodal industrial processes.\nHowever, the more complex the structure of multidimensional space, the lower\nthe performance of IDW models, and real industrial datasets tend to have more\ncomplex spatial structure. To solve this problem, a new framework for spatial\nprediction and modeling based on deep reinforcement learning network is\nproposed. In the proposed framework, the internal relationship between state\nand action is enhanced by reusing the state values in the Q network, and the\nconvergence rate and stability of the deep reinforcement learning network are\nimproved. The improved deep reinforcement learning network is then used to\nsearch for and learn the hyperparameters of each sample point in the inverse\ndistance weighted model. These hyperparameters can reflect the spatial\nstructure of the current industrial dataset to some extent. Then a spatial\ndistribution of hyperparameters is constructed based on the learned\nhyperparameters. Each interpolation point obtains corresponding hyperparameters\nfrom the hyperparametric spatial distribution and brings them into the\nclassical IDW models for prediction, thus achieving differential spatial\nprediction and modeling. The simulation results show that the proposed\nframework is suitable for real industrial datasets with complex spatial\nstructure characteristics and is more accurate than current IDW models in\nspatial prediction.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 03:30:07 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Zhang", "Junjie", ""], ["Zhang", "Cong", ""], ["Xiong", "Neal N.", ""]]}, {"id": "2008.09983", "submitter": "Sahaana Suri", "authors": "Sahaana Suri, Raghuveer Chanda, Neslihan Bulut, Pradyumna Narayana,\n  Yemao Zeng, Peter Bailis, Sugato Basu, Girija Narlikar, Christopher Re, and\n  Abishek Sethi", "title": "Leveraging Organizational Resources to Adapt Models to New Data\n  Modalities", "comments": null, "journal-ref": "PVLDB,13(12): 3396-3410, 2020", "doi": "10.14778/3415478.3415559", "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As applications in large organizations evolve, the machine learning (ML)\nmodels that power them must adapt the same predictive tasks to newly arising\ndata modalities (e.g., a new video content launch in a social media application\nrequires existing text or image models to extend to video). To solve this\nproblem, organizations typically create ML pipelines from scratch. However,\nthis fails to utilize the domain expertise and data they have cultivated from\ndeveloping tasks for existing modalities. We demonstrate how organizational\nresources, in the form of aggregate statistics, knowledge bases, and existing\nservices that operate over related tasks, enable teams to construct a common\nfeature space that connects new and existing data modalities. This allows teams\nto apply methods for training data curation (e.g., weak supervision and label\npropagation) and model training (e.g., forms of multi-modal learning) across\nthese different data modalities. We study how this use of organizational\nresources composes at production scale in over 5 classification tasks at\nGoogle, and demonstrate how it reduces the time needed to develop models for\nnew modalities from months to weeks to days.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 07:29:00 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Suri", "Sahaana", ""], ["Chanda", "Raghuveer", ""], ["Bulut", "Neslihan", ""], ["Narayana", "Pradyumna", ""], ["Zeng", "Yemao", ""], ["Bailis", "Peter", ""], ["Basu", "Sugato", ""], ["Narlikar", "Girija", ""], ["Re", "Christopher", ""], ["Sethi", "Abishek", ""]]}, {"id": "2008.09990", "submitter": "Yukai Shi", "authors": "Junpeng Tan, Yukai Shi, Zhijing Yang, Caizhen Wen, Liang Lin", "title": "Unsupervised Multi-view Clustering by Squeezing Hybrid Knowledge from\n  Cross View and Each View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-view clustering methods have been a focus in recent years because of\ntheir superiority in clustering performance. However, typical traditional\nmulti-view clustering algorithms still have shortcomings in some aspects, such\nas removal of redundant information, utilization of various views and fusion of\nmulti-view features. In view of these problems, this paper proposes a new\nmulti-view clustering method, low-rank subspace multi-view clustering based on\nadaptive graph regularization. We construct two new data matrix decomposition\nmodels into a unified optimization model. In this framework, we address the\nsignificance of the common knowledge shared by the cross view and the unique\nknowledge of each view by presenting new low-rank and sparse constraints on the\nsparse subspace matrix. To ensure that we achieve effective sparse\nrepresentation and clustering performance on the original data matrix, adaptive\ngraph regularization and unsupervised clustering constraints are also\nincorporated in the proposed model to preserve the internal structural features\nof the data. Finally, the proposed method is compared with several\nstate-of-the-art algorithms. Experimental results for five widely used\nmulti-view benchmarks show that our proposed algorithm surpasses other\nstate-of-the-art methods by a clear margin.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 08:25:06 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Tan", "Junpeng", ""], ["Shi", "Yukai", ""], ["Yang", "Zhijing", ""], ["Wen", "Caizhen", ""], ["Lin", "Liang", ""]]}, {"id": "2008.09994", "submitter": "You-Wei Luo", "authors": "Chuan-Xian Ren, You-Wei Luo, Xiao-Lin Xu, Dao-Qing Dai and Hong Yan", "title": "Discriminative Residual Analysis for Image Set Classification with\n  Posture and Age Variations", "comments": null, "journal-ref": "IEEE Transactions on Image Processing, vol. 29, pp. 2875-2888,\n  2020", "doi": "10.1109/TIP.2019.2954176", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image set recognition has been widely applied in many practical problems like\nreal-time video retrieval and image caption tasks. Due to its superior\nperformance, it has grown into a significant topic in recent years. However,\nimages with complicated variations, e.g., postures and human ages, are\ndifficult to address, as these variations are continuous and gradual with\nrespect to image appearance. Consequently, the crucial point of image set\nrecognition is to mine the intrinsic connection or structural information from\nthe image batches with variations. In this work, a Discriminant Residual\nAnalysis (DRA) method is proposed to improve the classification performance by\ndiscovering discriminant features in related and unrelated groups.\nSpecifically, DRA attempts to obtain a powerful projection which casts the\nresidual representations into a discriminant subspace. Such a projection\nsubspace is expected to magnify the useful information of the input space as\nmuch as possible, then the relation between the training set and the test set\ndescribed by the given metric or distance will be more precise in the\ndiscriminant subspace. We also propose a nonfeasance strategy by defining\nanother approach to construct the unrelated groups, which help to reduce\nfurthermore the cost of sampling errors. Two regularization approaches are used\nto deal with the probable small sample size problem. Extensive experiments are\nconducted on benchmark databases, and the results show superiority and\nefficiency of the new methods.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 08:53:06 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Ren", "Chuan-Xian", ""], ["Luo", "You-Wei", ""], ["Xu", "Xiao-Lin", ""], ["Dai", "Dao-Qing", ""], ["Yan", "Hong", ""]]}, {"id": "2008.10003", "submitter": "Ziyue Qiao", "authors": "Ziyue Qiao, Pengyang Wang, Yanjie Fu, Yi Du, Pengfei Wang, Yuanchun\n  Zhou", "title": "Tree Structure-Aware Graph Representation Learning via Integrated\n  Hierarchical Aggregation and Relational Metric Learning", "comments": "accepted by ICDM 2020 as regular paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Graph Neural Network (GNN) has shown superiority in learning node\nrepresentations of homogeneous graphs, leveraging GNN on heterogeneous graphs\nremains a challenging problem. The dominating reason is that GNN learns node\nrepresentations by aggregating neighbors' information regardless of node types.\nSome work is proposed to alleviate such issue by exploiting relations or\nmeta-path to sample neighbors with distinct categories, then use attention\nmechanism to learn different importance for different categories. However, one\nlimitation is that the learned representations for different types of nodes\nshould own different feature spaces, while all the above work still project\nnode representations into one feature space. Moreover, after exploring massive\nheterogeneous graphs, we identify a fact that multiple nodes with the same type\nalways connect to a node with another type, which reveals the many-to-one\nschema, a.k.a. the hierarchical tree structure. But all the above work cannot\npreserve such tree structure, since the exact multi-hop path correlation from\nneighbors to the target node would be erased through aggregation. Therefore, to\novercome the limitations of the literature, we propose T-GNN, a tree\nstructure-aware graph neural network model for graph representation learning.\nSpecifically, the proposed T-GNN consists of two modules: (1) the integrated\nhierarchical aggregation module and (2) the relational metric learning module.\nThe integrated hierarchical aggregation module aims to preserve the tree\nstructure by combining GNN with Gated Recurrent Unit to integrate the\nhierarchical and sequential neighborhood information on the tree structure to\nnode representations. The relational metric learning module aims to preserve\nthe heterogeneity by embedding each type of nodes into a type-specific space\nwith distinct distribution based on similarity metrics.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 09:41:19 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 05:59:43 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Qiao", "Ziyue", ""], ["Wang", "Pengyang", ""], ["Fu", "Yanjie", ""], ["Du", "Yi", ""], ["Wang", "Pengfei", ""], ["Zhou", "Yuanchun", ""]]}, {"id": "2008.10010", "submitter": "Prajwal K R", "authors": "K R Prajwal, Rudrabha Mukhopadhyay, Vinay Namboodiri, C V Jawahar", "title": "A Lip Sync Expert Is All You Need for Speech to Lip Generation In The\n  Wild", "comments": "9 pages (including references), 3 figures, Accepted in ACM\n  Multimedia, 2020", "journal-ref": null, "doi": "10.1145/3394171.3413532", "report-no": null, "categories": "cs.CV cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the problem of lip-syncing a talking face video\nof an arbitrary identity to match a target speech segment. Current works excel\nat producing accurate lip movements on a static image or videos of specific\npeople seen during the training phase. However, they fail to accurately morph\nthe lip movements of arbitrary identities in dynamic, unconstrained talking\nface videos, resulting in significant parts of the video being out-of-sync with\nthe new audio. We identify key reasons pertaining to this and hence resolve\nthem by learning from a powerful lip-sync discriminator. Next, we propose new,\nrigorous evaluation benchmarks and metrics to accurately measure lip\nsynchronization in unconstrained videos. Extensive quantitative evaluations on\nour challenging benchmarks show that the lip-sync accuracy of the videos\ngenerated by our Wav2Lip model is almost as good as real synced videos. We\nprovide a demo video clearly showing the substantial impact of our Wav2Lip\nmodel and evaluation benchmarks on our website:\n\\url{cvit.iiit.ac.in/research/projects/cvit-projects/a-lip-sync-expert-is-all-you-need-for-speech-to-lip-generation-in-the-wild}.\nThe code and models are released at this GitHub repository:\n\\url{github.com/Rudrabha/Wav2Lip}. You can also try out the interactive demo at\nthis link: \\url{bhaasha.iiit.ac.in/lipsync}.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 11:01:25 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Prajwal", "K R", ""], ["Mukhopadhyay", "Rudrabha", ""], ["Namboodiri", "Vinay", ""], ["Jawahar", "C V", ""]]}, {"id": "2008.10014", "submitter": "Jos\\'e Vicente Egas-L\\'opez", "authors": "Jos\\'e Vicente Egas-L\\'opez", "title": "They are wearing a mask! Identification of Subjects Wearing a Surgical\n  Mask from their Speech by means of x-vectors and Fisher Vectors", "comments": "INTERSPEECH CONFERENCE FORMAT. 5 pages, 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Challenges based on Computational Paralinguistics in the INTERSPEECH\nConference have always had a good reception among the attendees owing to its\ncompetitive academic and research demands. This year, the INTERSPEECH 2020\nComputational Paralinguistics Challenge offers three different problems; here,\nthe Mask Sub-Challenge is of specific interest. This challenge involves the\nclassification of speech recorded from subjects while wearing a surgical mask.\nIn this study, to address the above-mentioned problem we employ two different\ntypes of feature extraction methods. The x-vectors embeddings, which is the\ncurrent state-of-the-art approach for Speaker Recognition; and the Fisher\nVector (FV), that is a method originally intended for Image Recognition, but\nhere we utilize it to discriminate utterances. These approaches employ distinct\nframe-level representations: MFCC and PLP. Using Support Vector Machines (SVM)\nas the classifier, we perform a technical comparison between the performances\nof the FV encodings and the x-vector embeddings for this particular\nclassification task. We find that the Fisher vector encodings provide better\nrepresentations of the utterances than the x-vectors do for this specific\ndataset. Moreover, we show that a fusion of our best configurations outperforms\nall the baseline scores of the Mask Sub-Challenge.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 11:27:11 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Egas-L\u00f3pez", "Jos\u00e9 Vicente", ""]]}, {"id": "2008.10020", "submitter": "Vikram Krishnamurthy", "authors": "Vikram Krishnamurthy and George Yin", "title": "Multi-kernel Passive Stochastic Gradient Algorithms and Transfer\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SP eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a novel passive stochastic gradient algorithm. In passive\nstochastic approximation, the stochastic gradient algorithm does not have\ncontrol over the location where noisy gradients of the cost function are\nevaluated. Classical passive stochastic gradient algorithms use a kernel that\napproximates a Dirac delta to weigh the gradients based on how far they are\nevaluated from the desired point. In this paper we construct a multi-kernel\npassive stochastic gradient algorithm. The algorithm performs substantially\nbetter in high dimensional problems and incorporates variance reduction. We\nanalyze the weak convergence of the multi-kernel algorithm and its rate of\nconvergence. In numerical examples, we study the multi-kernel version of the\npassive least mean squares (LMS) algorithm for transfer learning to compare the\nperformance with the classical passive version.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 11:55:19 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 03:34:03 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Krishnamurthy", "Vikram", ""], ["Yin", "George", ""]]}, {"id": "2008.10021", "submitter": "Jinsong Li", "authors": "Jinsong Li, Jianhua Peng, Shuxin Liu, Lintianran Weng, Cong Li", "title": "TSAM: Temporal Link Prediction in Directed Networks based on\n  Self-Attention Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of graph neural networks (GCN) makes it possible to learn\nstructural features from evolving complex networks. Even though a wide range of\nrealistic networks are directed ones, few existing works investigated the\nproperties of directed and temporal networks. In this paper, we address the\nproblem of temporal link prediction in directed networks and propose a deep\nlearning model based on GCN and self-attention mechanism, namely TSAM. The\nproposed model adopts an autoencoder architecture, which utilizes graph\nattentional layers to capture the structural feature of neighborhood nodes, as\nwell as a set of graph convolutional layers to capture motif features. A graph\nrecurrent unit layer with self-attention is utilized to learn temporal\nvariations in the snapshot sequence. We run comparative experiments on four\nrealistic networks to validate the effectiveness of TSAM. Experimental results\nshow that TSAM outperforms most benchmarks under two evaluation metrics.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 11:56:40 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Li", "Jinsong", ""], ["Peng", "Jianhua", ""], ["Liu", "Shuxin", ""], ["Weng", "Lintianran", ""], ["Li", "Cong", ""]]}, {"id": "2008.10030", "submitter": "You-Wei Luo", "authors": "You-Wei Luo, Chuan-Xian Ren, Dao-Qing Dai and Hong Yan", "title": "Unsupervised Domain Adaptation via Discriminative Manifold Propagation", "comments": "To be published in IEEE Transactions on Pattern Analysis and Machine\n  Intelligence", "journal-ref": null, "doi": "10.1109/TPAMI.2020.3014218", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation is effective in leveraging rich information\nfrom a labeled source domain to an unlabeled target domain. Though deep\nlearning and adversarial strategy made a significant breakthrough in the\nadaptability of features, there are two issues to be further studied. First,\nhard-assigned pseudo labels on the target domain are arbitrary and error-prone,\nand direct application of them may destroy the intrinsic data structure.\nSecond, batch-wise training of deep learning limits the characterization of the\nglobal structure. In this paper, a Riemannian manifold learning framework is\nproposed to achieve transferability and discriminability simultaneously. For\nthe first issue, this framework establishes a probabilistic discriminant\ncriterion on the target domain via soft labels. Based on pre-built prototypes,\nthis criterion is extended to a global approximation scheme for the second\nissue. Manifold metric alignment is adopted to be compatible with the embedding\nspace. The theoretical error bounds of different alignment metrics are derived\nfor constructive guidance. The proposed method can be used to tackle a series\nof variants of domain adaptation problems, including both vanilla and partial\nsettings. Extensive experiments have been conducted to investigate the method\nand a comparative study shows the superiority of the discriminative manifold\nlearning framework.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 12:31:37 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Luo", "You-Wei", ""], ["Ren", "Chuan-Xian", ""], ["Dai", "Dao-Qing", ""], ["Yan", "Hong", ""]]}, {"id": "2008.10031", "submitter": "Ali Shariq Imran", "authors": "Ali Shariq Imran, Sher Mohammad Doudpota, Zenun Kastrati, Rakhi Bhatra", "title": "Cross-Cultural Polarity and Emotion Detection Using Sentiment Analysis\n  and Deep Learning -- a Case Study on COVID-19", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How different cultures react and respond given a crisis is predominant in a\nsociety's norms and political will to combat the situation. Often the decisions\nmade are necessitated by events, social pressure, or the need of the hour,\nwhich may not represent the will of the nation. While some are pleased with it,\nothers might show resentment. Coronavirus (COVID-19) brought a mix of similar\nemotions from the nations towards the decisions taken by their respective\ngovernments. Social media was bombarded with posts containing both positive and\nnegative sentiments on the COVID-19, pandemic, lockdown, hashtags past couple\nof months. Despite geographically close, many neighboring countries reacted\ndifferently to one another. For instance, Denmark and Sweden, which share many\nsimilarities, stood poles apart on the decision taken by their respective\ngovernments. Yet, their nation's support was mostly unanimous, unlike the South\nAsian neighboring countries where people showed a lot of anxiety and\nresentment. This study tends to detect and analyze sentiment polarity and\nemotions demonstrated during the initial phase of the pandemic and the lockdown\nperiod employing natural language processing (NLP) and deep learning techniques\non Twitter posts. Deep long short-term memory (LSTM) models used for estimating\nthe sentiment polarity and emotions from extracted tweets have been trained to\nachieve state-of-the-art accuracy on the sentiment140 dataset. The use of\nemoticons showed a unique and novel way of validating the supervised deep\nlearning models on tweets extracted from Twitter.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 12:43:26 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Imran", "Ali Shariq", ""], ["Doudpota", "Sher Mohammad", ""], ["Kastrati", "Zenun", ""], ["Bhatra", "Rakhi", ""]]}, {"id": "2008.10040", "submitter": "Taisuke Kobayashi", "authors": "Taisuke Kobayashi", "title": "Adaptive and Multiple Time-scale Eligibility Traces for Online Deep\n  Reinforcement Learning", "comments": "12 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) is one of the promising approaches to make\nrobots accomplish complicated tasks. In the robotic problems with time-varying\nenvironment, online DRL is required since the methods that directly reuse the\nstored experience data cannot follow the change of the environment. Eligibility\ntraces method is well known as an online learning technique to improve sample\nefficiency in the traditional reinforcement learning with linear regressors,\nnot DRL. The one reason why the eligibility traces are not integrated with DRL\nis because dependencies between parameters of deep neural networks would\ndestroy the eligibility traces. To mitigate this problem, this study proposes a\nnew eligibility traces method that makes it possible to be applied even into\nDRL. The eligibility traces in DRL accumulate gradients computed based on the\npast parameters, which are different from that computed based on the latest\nparameters. Hence, the proposed method considers the divergence between the\npast and latest parameters to adaptively decay the eligibility traces. Instead\nof that divergence directly, Bregman divergences between outputs computed by\nthe past and latest parameters, which are computationally feasible, are\nexploited. In addition, inspired by the replacing eligibility traces, a\ngeneralized method with multiple time-scale traces are newly designed. In\nbenchmark tasks on a dynamic robotic simulator, the proposed method\noutperformed the conventional methods in terms of the learning speed and the\nquality of the tasks by the learned policy. A real-robot demonstration verified\nthe importance of online DRL and the adaptability of the proposed method to the\ntime-varying environment.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 13:35:50 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Kobayashi", "Taisuke", ""]]}, {"id": "2008.10041", "submitter": "Krzysztof Maziarz", "authors": "Zbigniew Wojna, Krzysztof Maziarz, {\\L}ukasz Jocz, Robert Pa{\\l}uba,\n  Robert Kozikowski, Iasonas Kokkinos", "title": "Holistic Multi-View Building Analysis in the Wild with Projection\n  Pooling", "comments": "Accepted for publication at the 35th AAAI Conference on Artificial\n  Intelligence (AAAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address six different classification tasks related to fine-grained\nbuilding attributes: construction type, number of floors, pitch and geometry of\nthe roof, facade material, and occupancy class. Tackling such a remote building\nanalysis problem became possible only recently due to growing large-scale\ndatasets of urban scenes. To this end, we introduce a new benchmarking dataset,\nconsisting of 49426 images (top-view and street-view) of 9674 buildings. These\nphotos are further assembled, together with the geometric metadata. The dataset\nshowcases various real-world challenges, such as occlusions, blur, partially\nvisible objects, and a broad spectrum of buildings. We propose a new projection\npooling layer, creating a unified, top-view representation of the top-view and\nthe side views in a high-dimensional space. It allows us to utilize the\nbuilding and imagery metadata seamlessly. Introducing this layer improves\nclassification accuracy -- compared to highly tuned baseline models --\nindicating its suitability for building analysis.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 13:49:22 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 23:04:21 GMT"}, {"version": "v3", "created": "Sat, 19 Dec 2020 20:59:07 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Wojna", "Zbigniew", ""], ["Maziarz", "Krzysztof", ""], ["Jocz", "\u0141ukasz", ""], ["Pa\u0142uba", "Robert", ""], ["Kozikowski", "Robert", ""], ["Kokkinos", "Iasonas", ""]]}, {"id": "2008.10053", "submitter": "Arash Mehrjou", "authors": "Arash Mehrjou, Andrea Iannelli, Bernhard Sch\\\"olkopf", "title": "Learning Dynamical Systems using Local Stability Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A coupled computational approach to simultaneously learn a vector field and\nthe region of attraction of an equilibrium point from generated trajectories of\nthe system is proposed. The nonlinear identification leverages the local\nstability information as a prior on the system, effectively endowing the\nestimate with this important structural property. In addition, the knowledge of\nthe region of attraction plays an experiment design role by informing the\nselection of initial conditions from which trajectories are generated and by\nenabling the use of a Lyapunov function of the system as a regularization term.\nNumerical results show that the proposed method allows efficient sampling and\nprovides an accurate estimate of the dynamics in an inner approximation of its\nregion of attraction.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 14:51:22 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Mehrjou", "Arash", ""], ["Iannelli", "Andrea", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2008.10054", "submitter": "Behzad Khamidehi", "authors": "Behzad Khamidehi and Elvino S. Sousa", "title": "Federated Learning for Cellular-connected UAVs: Radio Mapping and Path\n  Planning", "comments": "to appear in IEEE GLOBECOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To prolong the lifetime of the unmanned aerial vehicles (UAVs), the UAVs need\nto fulfill their missions in the shortest possible time. In addition to this\nrequirement, in many applications, the UAVs require a reliable internet\nconnection during their flights. In this paper, we minimize the travel time of\nthe UAVs, ensuring that a probabilistic connectivity constraint is satisfied.\nTo solve this problem, we need a global model of the outage probability in the\nenvironment. Since the UAVs have different missions and fly over different\nareas, their collected data carry local information on the network's\nconnectivity. As a result, the UAVs can not rely on their own experiences to\nbuild the global model. This issue affects the path planning of the UAVs. To\naddress this concern, we utilize a two-step approach. In the first step, by\nusing Federated Learning (FL), the UAVs collaboratively build a global model of\nthe outage probability in the environment. In the second step, by using the\nglobal model obtained in the first step and rapidly-exploring random trees\n(RRTs), we propose an algorithm to optimize UAVs' paths. Simulation results\nshow the effectiveness of this two-step approach for UAV networks.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 14:55:37 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Khamidehi", "Behzad", ""], ["Sousa", "Elvino S.", ""]]}, {"id": "2008.10065", "submitter": "Xingyue Pu", "authors": "Xingyue Pu, Siu Lun Chau, Xiaowen Dong and Dino Sejdinovic", "title": "Kernel-based Graph Learning from Smooth Signals: A Functional Viewpoint", "comments": "13 pages, with extra 3-page appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of graph learning concerns the construction of an explicit\ntopological structure revealing the relationship between nodes representing\ndata entities, which plays an increasingly important role in the success of\nmany graph-based representations and algorithms in the field of machine\nlearning and graph signal processing. In this paper, we propose a novel graph\nlearning framework that incorporates the node-side and observation-side\ninformation, and in particular the covariates that help to explain the\ndependency structures in graph signals. To this end, we consider graph signals\nas functions in the reproducing kernel Hilbert space associated with a\nKronecker product kernel, and integrate functional learning with\nsmoothness-promoting graph learning to learn a graph representing the\nrelationship between nodes. The functional learning increases the robustness of\ngraph learning against missing and incomplete information in the graph signals.\nIn addition, we develop a novel graph-based regularisation method which, when\ncombined with the Kronecker product kernel, enables our model to capture both\nthe dependency explained by the graph and the dependency due to graph signals\nobserved under different but related circumstances, e.g. different points in\ntime. The latter means the graph signals are free from the i.i.d. assumptions\nrequired by the classical graph learning models. Experiments on both synthetic\nand real-world data show that our methods outperform the state-of-the-art\nmodels in learning a meaningful graph topology from graph signals, in\nparticular under heavy noise, missing values, and multiple dependency.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 16:04:23 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Pu", "Xingyue", ""], ["Chau", "Siu Lun", ""], ["Dong", "Xiaowen", ""], ["Sejdinovic", "Dino", ""]]}, {"id": "2008.10066", "submitter": "Harshit Sikchi", "authors": "Harshit Sikchi, Wenxuan Zhou, David Held", "title": "Learning Off-Policy with Online Planning", "comments": "In submission. Previously presented in ICML BIG workshop, July 18\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) in low-data and risk-sensitive domains requires\nperformant and flexible deployment policies that can readily incorporate\nconstraints during deployment. One such class of policies are the\nsemi-parametric H-step lookahead policies, which select actions using\ntrajectory optimization over a dynamics model for a fixed horizon with a\nterminal value function. In this work, we investigate a novel instantiation of\nH-step lookahead with a learned model and a terminal value function learned by\na model-free off-policy algorithm, named Learning Off-Policy with Online\nPlanning (LOOP). We provide a theoretical analysis of this method, suggesting a\ntradeoff between model errors and value function errors and empirically\ndemonstrate this tradeoff to be beneficial in deep reinforcement learning.\nFurthermore, we identify the \"Actor Divergence\" issue in this framework and\npropose Actor Regularized Control (ARC), a modified trajectory optimization\nprocedure. We evaluate our method on a set of robotic tasks for Offline and\nOnline RL and demonstrate improved performance. We also show the flexibility of\nLOOP to incorporate safety constraints during deployment with a set of\nnavigation environments. We demonstrate that LOOP is a desirable framework for\nrobotics applications based on its strong performance in various important RL\nsettings.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 16:18:44 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 19:11:59 GMT"}, {"version": "v3", "created": "Tue, 29 Jun 2021 17:37:00 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Sikchi", "Harshit", ""], ["Zhou", "Wenxuan", ""], ["Held", "David", ""]]}, {"id": "2008.10077", "submitter": "Qing Sun", "authors": "Qing Sun and James Cross", "title": "Learn to Talk via Proactive Knowledge Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Transfer has been applied in solving a wide variety of problems.\nFor example, knowledge can be transferred between tasks (e.g., learning to\nhandle novel situations by leveraging prior knowledge) or between agents (e.g.,\nlearning from others without direct experience). Without loss of generality, we\nrelate knowledge transfer to KL-divergence minimization, i.e., matching the\n(belief) distributions of learners and teachers. The equivalence gives us a new\nperspective in understanding variants of the KL-divergence by looking at how\nlearners structure their interaction with teachers in order to acquire\nknowledge. In this paper, we provide an in-depth analysis of KL-divergence\nminimization in Forward and Backward orders, which shows that learners are\nreinforced via on-policy learning in Backward. In contrast, learners are\nsupervised in Forward. Moreover, our analysis is gradient-based, so it can be\ngeneralized to arbitrary tasks and help to decide which order to minimize given\nthe property of the task. By replacing Forward with Backward in Knowledge\nDistillation, we observed +0.7-1.1 BLEU gains on the WMT'17 De-En and IWSLT'15\nTh-En machine translation tasks.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 17:46:04 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Sun", "Qing", ""], ["Cross", "James", ""]]}, {"id": "2008.10085", "submitter": "Leo Lopez", "authors": "L\\'eo Pio-Lopez, Alberto Valdeolivas, Laurent Tichit, \\'Elisabeth\n  Remy, Ana\\\"is Baudot", "title": "MultiVERSE: a multiplex and multiplex-heterogeneous network embedding\n  approach", "comments": "29 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding approaches are gaining momentum to analyse a large variety\nof networks. Indeed, these approaches have demonstrated their efficiency for\ntasks such as community detection, node classification, and link prediction.\nHowever, very few network embedding methods have been specifically designed to\nhandle multiplex networks, i.e. networks composed of different layers sharing\nthe same set of nodes but having different types of edges. Moreover, to our\nknowledge, existing approaches cannot embed multiple nodes from\nmultiplex-heterogeneous networks, i.e. networks composed of several layers\ncontaining both different types of nodes and edges. In this study, we propose\nMultiVERSE, an extension of the VERSE method with Random Walks with Restart on\nMultiplex (RWR-M) and Multiplex-Heterogeneous (RWR-MH) networks. MultiVERSE is\na fast and scalable method to learn node embeddings from multiplex and\nmultiplex-heterogeneous networks. We evaluate MultiVERSE on several biological\nand social networks and demonstrate its efficiency. MultiVERSE indeed\noutperforms most of the other methods in the tasks of link prediction and\nnetwork reconstruction for multiplex network embedding, and is also efficient\nin the task of link prediction for multiplex-heterogeneous network embedding.\nFinally, we apply MultiVERSE to study rare disease-gene associations using link\nprediction and clustering. MultiVERSE is freely available on github at\nhttps://github.com/Lpiol/MultiVERSE.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 18:18:54 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 10:20:34 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Pio-Lopez", "L\u00e9o", ""], ["Valdeolivas", "Alberto", ""], ["Tichit", "Laurent", ""], ["Remy", "\u00c9lisabeth", ""], ["Baudot", "Ana\u00efs", ""]]}, {"id": "2008.10086", "submitter": "Reid McIlroy-Young", "authors": "Reid McIlroy-Young, Russell Wang, Siddhartha Sen, Jon Kleinberg,\n  Ashton Anderson", "title": "Learning Personalized Models of Human Behavior in Chess", "comments": "The current version of the paper corrects data processing problems\n  present in the previous version. 21 pages, 13 figures, 7 tables (one very\n  long)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even when machine learning systems surpass human ability in a domain, there\nare many reasons why AI systems that capture human-like behavior would be\ndesirable: humans may want to learn from them, they may need to collaborate\nwith them, or they may expect them to serve as partners in an extended\ninteraction. Motivated by this goal of human-like AI systems, the problem of\npredicting human actions -- as opposed to predicting optimal actions -- has\nbecome an increasingly useful task. We extend this line of work by developing\nhighly accurate personalized models of human behavior in the context of chess.\nChess is a rich domain for exploring these questions, since it combines a set\nof appealing features: AI systems have achieved superhuman performance but\nstill interact closely with human chess players both as opponents and\npreparation tools, and there is an enormous amount of recorded data on\nindividual players. Starting with an open-source version of AlphaZero trained\non a population of human players, we demonstrate that we can significantly\nimprove prediction of a particular player's moves by applying a series of\nfine-tuning adjustments. Furthermore, we can accurately perform stylometry --\npredicting who made a given set of actions -- indicating that our personalized\nmodels capture human decision-making at an individual level.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 18:24:21 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 20:10:22 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["McIlroy-Young", "Reid", ""], ["Wang", "Russell", ""], ["Sen", "Siddhartha", ""], ["Kleinberg", "Jon", ""], ["Anderson", "Ashton", ""]]}, {"id": "2008.10087", "submitter": "Li Wenliang", "authors": "Li K. Wenliang", "title": "Blindness of score-based methods to isolated components and mixing\n  proportions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A large family of score-based methods are developed recently to solve\nunsupervised learning problems including density estimation, statistical\ntesting and variational inference. These methods are attractive because they\nexploit the derivative of the log density, which is independent of the\nnormaliser, and are thus suitable for tasks involving unnormalised densities.\nDespite the theoretical guarantees on the performance, here we illustrate a\ncommon practical issue suffered by these methods when the unnormalised\ndistribution of interest has isolated components. In particular, we study the\nbehaviour of some popular score-based methods on tasks involving 1-D mixture of\nGaussian. These methods fail to identify appropriate mixing proportions when\nthe unnormalised distribution is multimodal. Finally, some directions for\nfinding a remedy are discussed in light of recent successes in specific tasks.\nWe hope to bring the attention of theoreticians and practitioners to this issue\nwhen developing new algorithms and applications.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 18:24:42 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Wenliang", "Li K.", ""]]}, {"id": "2008.10103", "submitter": "Shuang Qiu", "authors": "Shuang Qiu, Zhuoran Yang, Xiaohan Wei, Jieping Ye, Zhaoran Wang", "title": "Single-Timescale Stochastic Nonconvex-Concave Optimization for Smooth\n  Nonlinear TD Learning", "comments": "45 pages; initial draft submitted in Feb, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal-Difference (TD) learning with nonlinear smooth function\napproximation for policy evaluation has achieved great success in modern\nreinforcement learning. It is shown that such a problem can be reformulated as\na stochastic nonconvex-strongly-concave optimization problem, which is\nchallenging as naive stochastic gradient descent-ascent algorithm suffers from\nslow convergence. Existing approaches for this problem are based on\ntwo-timescale or double-loop stochastic gradient algorithms, which may also\nrequire sampling large-batch data. However, in practice, a single-timescale\nsingle-loop stochastic algorithm is preferred due to its simplicity and also\nbecause its step-size is easier to tune. In this paper, we propose two\nsingle-timescale single-loop algorithms which require only one data point each\nstep. Our first algorithm implements momentum updates on both primal and dual\nvariables achieving an $O(\\varepsilon^{-4})$ sample complexity, which shows the\nimportant role of momentum in obtaining a single-timescale algorithm. Our\nsecond algorithm improves upon the first one by applying variance reduction on\ntop of momentum, which matches the best known $O(\\varepsilon^{-3})$ sample\ncomplexity in existing works. Furthermore, our variance-reduction algorithm\ndoes not require a large-batch checkpoint. Moreover, our theoretical results\nfor both algorithms are expressed in a tighter form of simultaneous primal and\ndual side convergence.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 20:36:49 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Qiu", "Shuang", ""], ["Yang", "Zhuoran", ""], ["Wei", "Xiaohan", ""], ["Ye", "Jieping", ""], ["Wang", "Zhaoran", ""]]}, {"id": "2008.10105", "submitter": "Benedikt Boenninghoff", "authors": "Benedikt Boenninghoff and Julian Rupp and Robert M. Nickel and\n  Dorothea Kolossa", "title": "Deep Bayes Factor Scoring for Authorship Verification", "comments": "CLEF 2020 Labs and Workshops, Notebook Papers, September 2020.\n  CEUR-WS.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The PAN 2020 authorship verification (AV) challenge focuses on a\ncross-topic/closed-set AV task over a collection of fanfiction texts.\nFanfiction is a fan-written extension of a storyline in which a so-called\nfandom topic describes the principal subject of the document. The data provided\nin the PAN 2020 AV task is quite challenging because authors of texts across\nmultiple/different fandom topics are included. In this work, we present a\nhierarchical fusion of two well-known approaches into a single end-to-end\nlearning procedure: A deep metric learning framework at the bottom aims to\nlearn a pseudo-metric that maps a document of variable length onto a\nfixed-sized feature vector. At the top, we incorporate a probabilistic layer to\nperform Bayes factor scoring in the learned metric space. We also provide text\npreprocessing strategies to deal with the cross-topic issue.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 21:00:33 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Boenninghoff", "Benedikt", ""], ["Rupp", "Julian", ""], ["Nickel", "Robert M.", ""], ["Kolossa", "Dorothea", ""]]}, {"id": "2008.10109", "submitter": "Raaz Dwivedi", "authors": "Raaz Dwivedi, Yan Shuo Tan, Briton Park, Mian Wei, Kevin Horgan, David\n  Madigan, Bin Yu", "title": "Stable discovery of interpretable subgroups via calibration in causal\n  studies", "comments": "Raaz Dwivedi and Yan Shuo Tan are joint first authors and contributed\n  equally to this work. 52 pages, 8 Figures, 9 Tables. To appear in\n  International Statistical Review, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on Yu and Kumbier's PCS framework and for randomized experiments, we\nintroduce a novel methodology for Stable Discovery of Interpretable Subgroups\nvia Calibration (StaDISC), with large heterogeneous treatment effects. StaDISC\nwas developed during our re-analysis of the 1999-2000 VIGOR study, an 8076\npatient randomized controlled trial (RCT), that compared the risk of adverse\nevents from a then newly approved drug, Rofecoxib (Vioxx), to that from an\nolder drug Naproxen. Vioxx was found to, on average and in comparison to\nNaproxen, reduce the risk of gastrointestinal (GI) events but increase the risk\nof thrombotic cardiovascular (CVT) events. Applying StaDISC, we fit 18 popular\nconditional average treatment effect (CATE) estimators for both outcomes and\nuse calibration to demonstrate their poor global performance. However, they are\nlocally well-calibrated and stable, enabling the identification of patient\ngroups with larger than (estimated) average treatment effects. In fact, StaDISC\ndiscovers three clinically interpretable subgroups each for the GI outcome\n(totaling 29.4% of the study size) and the CVT outcome (totaling 11.0%).\nComplementary analyses of the found subgroups using the 2001-2004 APPROVe\nstudy, a separate independently conducted RCT with 2587 patients, provides\nfurther supporting evidence for the promise of StaDISC.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 21:35:37 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 02:55:05 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Dwivedi", "Raaz", ""], ["Tan", "Yan Shuo", ""], ["Park", "Briton", ""], ["Wei", "Mian", ""], ["Horgan", "Kevin", ""], ["Madigan", "David", ""], ["Yu", "Bin", ""]]}, {"id": "2008.10112", "submitter": "Abhinav Valada", "authors": "Rohit Mohan and Abhinav Valada", "title": "Robust Vision Challenge 2020 -- 1st Place Report for Panoptic\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this technical report, we present key details of our winning panoptic\nsegmentation architecture EffPS_b1bs4_RVC. Our network is a lightweight version\nof our state-of-the-art EfficientPS architecture that consists of our proposed\nshared backbone with a modified EfficientNet-B5 model as the encoder, followed\nby the 2-way FPN to learn semantically rich multi-scale features. It consists\nof two task-specific heads, a modified Mask R-CNN instance head and our novel\nsemantic segmentation head that processes features of different scales with\nspecialized modules for coherent feature refinement. Finally, our proposed\npanoptic fusion module adaptively fuses logits from each of the heads to yield\nthe panoptic segmentation output. The Robust Vision Challenge 2020 benchmarking\nresults show that our model is ranked #1 on Microsoft COCO, VIPER and WildDash,\nand is ranked #2 on Cityscapes and Mapillary Vistas, thereby achieving the\noverall rank #1 for the panoptic segmentation task.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 21:41:43 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Mohan", "Rohit", ""], ["Valada", "Abhinav", ""]]}, {"id": "2008.10117", "submitter": "Robin M. Schmidt", "authors": "Robin M. Schmidt, Moritz Hahn", "title": "Collaborative Filtering under Model Uncertainty", "comments": "v2: small display fix in affiliation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In their work, Dean, Rich, and Recht create a model to research recourse and\navailability of items in a recommender system. We used the definition of\npredictive multiplicity by Marx, Pin Calmon, and Ustun to examine different\nvariations of this model, using different values for two model parameters.\nPairwise comparison of their models show, that most of these models produce\nvery similar results in terms of discrepancy and ambiguity for the availability\nand only in some cases the availability sets differ significantly.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 22:09:31 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 02:10:59 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Schmidt", "Robin M.", ""], ["Hahn", "Moritz", ""]]}, {"id": "2008.10122", "submitter": "Varun Badrinath Krishna", "authors": "Varun Badrinath Krishna", "title": "Ballroom Dance Movement Recognition Using a Smart Watch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inertial Measurement Unit (IMU) sensors are being increasingly used to detect\nhuman gestures and movements. Using a single IMU sensor, whole body movement\nrecognition remains a hard problem because movements may not be adequately\ncaptured by the sensor. In this paper, we present a whole body movement\ndetection study using a single smart watch in the context of ballroom dancing.\nDeep learning representations are used to classify well-defined sequences of\nmovements, called \\emph{figures}. Those representations are found to outperform\nensembles of random forests and hidden Markov models. The classification\naccuracy of 85.95\\% was improved to 92.31\\% by modeling a dance as a\nfirst-order Markov chain of figures and correcting estimates of the immediately\npreceding figure.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 22:36:28 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 05:25:56 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Krishna", "Varun Badrinath", ""]]}, {"id": "2008.10134", "submitter": "Salman Maqbool", "authors": "Salman Maqbool, Aqsa Riaz, Hasan Sajid, Osman Hasan", "title": "m2caiSeg: Semantic Segmentation of Laparoscopic Images using\n  Convolutional Neural Networks", "comments": "16 pages, 5 figures, Code available at:\n  https://github.com/salmanmaq/segmentationNetworks, Dataset available at:\n  https://www.kaggle.com/salmanmaq/m2caiseg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Autonomous surgical procedures, in particular minimal invasive surgeries, are\nthe next frontier for Artificial Intelligence research. However, the existing\nchallenges include precise identification of the human anatomy and the surgical\nsettings, and modeling the environment for training of an autonomous agent. To\naddress the identification of human anatomy and the surgical settings, we\npropose a deep learning based semantic segmentation algorithm to identify and\nlabel the tissues and organs in the endoscopic video feed of the human torso\nregion. We present an annotated dataset, m2caiSeg, created from endoscopic\nvideo feeds of real-world surgical procedures. Overall, the data consists of\n307 images, each of which is annotated for the organs and different surgical\ninstruments present in the scene. We propose and train a deep convolutional\nneural network for the semantic segmentation task. To cater for the low\nquantity of annotated data, we use unsupervised pre-training and data\naugmentation. The trained model is evaluated on an independent test set of the\nproposed dataset. We obtained a F1 score of 0.33 while using all the labeled\ncategories for the semantic segmentation task. Secondly, we labeled all\ninstruments into an 'Instruments' superclass to evaluate the model's\nperformance on discerning the various organs and obtained a F1 score of 0.57.\nWe propose a new dataset and a deep learning method for pixel level\nidentification of various organs and instruments in a endoscopic surgical\nscene. Surgical scene understanding is one of the first steps towards\nautomating surgical procedures.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 23:30:15 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 21:34:59 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Maqbool", "Salman", ""], ["Riaz", "Aqsa", ""], ["Sajid", "Hasan", ""], ["Hasan", "Osman", ""]]}, {"id": "2008.10135", "submitter": "Bachir El Khadir", "authors": "Amir Ali Ahmadi, Bachir El Khadir", "title": "Learning Dynamical Systems with Side Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a mathematical and computational framework for the problem of\nlearning a dynamical system from noisy observations of a few trajectories and\nsubject to side information. Side information is any knowledge we might have\nabout the dynamical system we would like to learn besides trajectory data. It\nis typically inferred from domain-specific knowledge or basic principles of a\nscientific discipline. We are interested in explicitly integrating side\ninformation into the learning process in order to compensate for scarcity of\ntrajectory observations. We identify six types of side information that arise\nnaturally in many applications and lead to convex constraints in the learning\nproblem. First, we show that when our model for the unknown dynamical system is\nparameterized as a polynomial, one can impose our side information constraints\ncomputationally via semidefinite programming. We then demonstrate the added\nvalue of side information for learning the dynamics of basic models in physics\nand cell biology, as well as for learning and controlling the dynamics of a\nmodel in epidemiology. Finally, we study how well polynomial dynamical systems\ncan approximate continuously-differentiable ones while satisfying side\ninformation (either exactly or approximately). Our overall learning methodology\ncombines ideas from convex optimization, real algebra, dynamical systems, and\nfunctional approximation theory, and can potentially lead to new synergies\nbetween these areas.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 23:30:48 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Ahmadi", "Amir Ali", ""], ["Khadir", "Bachir El", ""]]}, {"id": "2008.10138", "submitter": "Sayedmasoud Hashemi Amroabadi", "authors": "Masoud Hashemi, Ali Fathi", "title": "PermuteAttack: Counterfactual Explanation of Machine Learning Credit\n  Scorecards", "comments": "16 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a note on new directions and methodologies for validation and\nexplanation of Machine Learning (ML) models employed for retail credit scoring\nin finance. Our proposed framework draws motivation from the field of\nArtificial Intelligence (AI) security and adversarial ML where the need for\ncertifying the performance of the ML algorithms in the face of their\noverwhelming complexity poses a need for rethinking the traditional notions of\nmodel architecture selection, sensitivity analysis and stress testing. Our\npoint of view is that the phenomenon of adversarial perturbations when detached\nfrom the AI security domain, has purely algorithmic roots and fall within the\nscope of model risk assessment. We propose a model criticism and explanation\nframework based on adversarially generated counterfactual examples for tabular\ndata. A counterfactual example to a given instance in this context is defined\nas a synthetically generated data point sampled from the estimated data\ndistribution which is treated differently by a model. The counterfactual\nexamples can be used to provide a black-box instance-level explanation of the\nmodel behaviour as well as studying the regions in the input space where the\nmodel performance deteriorates. Adversarial example generating algorithms are\nextensively studied in the image and natural language processing (NLP) domains.\nHowever, most financial data come in tabular format and naive application of\nthe existing techniques on this class of datasets generates unrealistic\nsamples. In this paper, we propose a counterfactual example generation method\ncapable of handling tabular data including discrete and categorical variables.\nOur proposed algorithm uses a gradient-free optimization based on genetic\nalgorithms and therefore is applicable to any classification model.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 00:05:13 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 18:06:46 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Hashemi", "Masoud", ""], ["Fathi", "Ali", ""]]}, {"id": "2008.10148", "submitter": "Md. Shirajum Munir", "authors": "Md. Shirajum Munir, Sarder Fakhrul Abedin, Ki Tae Kim, Do Hyeon Kim,\n  Md. Golam Rabiul Alam, and Choong Seon Hong", "title": "Drive Safe: Cognitive-Behavioral Mining for Intelligent Transportation\n  Cyber-Physical System", "comments": "Submitted to IEEE Transactions on Intelligent Transportation Systems,\n  Special Issue on Technologies for risk mitigation and support of impaired\n  drivers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a cognitive behavioral-based driver mood repairment\nplatform in intelligent transportation cyber-physical systems (IT-CPS) for road\nsafety. In particular, we propose a driving safety platform for distracted\ndrivers, namely \\emph{drive safe}, in IT-CPS. The proposed platform recognizes\nthe distracting activities of the drivers as well as their emotions for mood\nrepair. Further, we develop a prototype of the proposed drive safe platform to\nestablish proof-of-concept (PoC) for the road safety in IT-CPS. In the\ndeveloped driving safety platform, we employ five AI and statistical-based\nmodels to infer a vehicle driver's cognitive-behavioral mining to ensure safe\ndriving during the drive. Especially, capsule network (CN), maximum likelihood\n(ML), convolutional neural network (CNN), Apriori algorithm, and Bayesian\nnetwork (BN) are deployed for driver activity recognition, environmental\nfeature extraction, mood recognition, sequential pattern mining, and content\nrecommendation for affective mood repairment of the driver, respectively.\nBesides, we develop a communication module to interact with the systems in\nIT-CPS asynchronously. Thus, the developed drive safe PoC can guide the vehicle\ndrivers when they are distracted from driving due to the cognitive-behavioral\nfactors. Finally, we have performed a qualitative evaluation to measure the\nusability and effectiveness of the developed drive safe platform. We observe\nthat the P-value is 0.0041 (i.e., < 0.05) in the ANOVA test. Moreover, the\nconfidence interval analysis also shows significant gains in prevalence value\nwhich is around 0.93 for a 95% confidence level. The aforementioned statistical\nresults indicate high reliability in terms of driver's safety and mental state.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 01:19:40 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Munir", "Md. Shirajum", ""], ["Abedin", "Sarder Fakhrul", ""], ["Kim", "Ki Tae", ""], ["Kim", "Do Hyeon", ""], ["Alam", "Md. Golam Rabiul", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2008.10149", "submitter": "Charles Thornton", "authors": "Charles E. Thornton, R. Michael Buehrer, Anthony F. Martone", "title": "Efficient Online Learning for Cognitive Radar-Cellular Coexistence via\n  Contextual Thompson Sampling", "comments": "6 pages, 6 Figures, To Appear in Proc. IEEE GLOBECOM 2020, Taipei\n  Taiwan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a sequential, or online, learning scheme for adaptive\nradar transmissions that facilitate spectrum sharing with a non-cooperative\ncellular network. First, the interference channel between the radar and a\nspatially distant cellular network is modeled. Then, a linear Contextual Bandit\n(CB) learning framework is applied to drive the radar's behavior. The\nfundamental trade-off between exploration and exploitation is balanced by a\nproposed Thompson Sampling (TS) algorithm, a pseudo-Bayesian approach which\nselects waveform parameters based on the posterior probability that a specific\nwaveform is optimal, given discounted channel information as context. It is\nshown that the contextual TS approach converges more rapidly to behavior that\nminimizes mutual interference and maximizes spectrum utilization than\ncomparable contextual bandit algorithms. Additionally, we show that the TS\nlearning scheme results in a favorable SINR distribution compared to other\nonline learning algorithms. Finally, the proposed TS algorithm is compared to a\ndeep reinforcement learning model. We show that the TS algorithm maintains\ncompetitive performance with a more complex Deep Q-Network (DQN).\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 01:20:58 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Thornton", "Charles E.", ""], ["Buehrer", "R. Michael", ""], ["Martone", "Anthony F.", ""]]}, {"id": "2008.10150", "submitter": "Daniel Hsu", "authors": "Christopher Tosh, Akshay Krishnamurthy, Daniel Hsu", "title": "Contrastive learning, multi-view redundancy, and linear models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning is an empirically successful approach to\nunsupervised learning based on creating artificial supervised learning\nproblems. A popular self-supervised approach to representation learning is\ncontrastive learning, which leverages naturally occurring pairs of similar and\ndissimilar data points, or multiple views of the same data. This work provides\na theoretical analysis of contrastive learning in the multi-view setting, where\ntwo views of each datum are available. The main result is that linear functions\nof the learned representations are nearly optimal on downstream prediction\ntasks whenever the two views provide redundant information about the label.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 01:31:47 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 19:19:55 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Tosh", "Christopher", ""], ["Krishnamurthy", "Akshay", ""], ["Hsu", "Daniel", ""]]}, {"id": "2008.10151", "submitter": "Iman Niazazari", "authors": "Iman Niazazari, Amir Ghasemkhani, Yunchuan Liu, Shuchismita Biswas,\n  Hanif Livani, Lei Yang, Virgilio Centeno", "title": "Deep Neural Network based Wide-Area Event Classification in Power\n  Systems", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a wide-area event classification in transmission power\ngrids. The deep neural network (DNN) based classifier is developed based on the\navailability of data from time-synchronized phasor measurement units (PMUs).\nThe proposed DNN is trained using Bayesian optimization to search for the best\nhyperparameters. The effectiveness of the proposed event classification is\nvalidated through the real-world dataset of the U.S. transmission grids. This\ndataset includes line outage, transformer outage, frequency event, and\noscillation events. The validation process also includes different PMU outputs,\nsuch as voltage magnitude, angle, current magnitude, frequency, and rate of\nchange of frequency (ROCOF). The simulation results show that ROCOF as input\nfeature gives the best classification performance. In addition, it is shown\nthat the classifier trained with higher sampling rate PMUs and a larger dataset\nhas higher accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 01:32:57 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Niazazari", "Iman", ""], ["Ghasemkhani", "Amir", ""], ["Liu", "Yunchuan", ""], ["Biswas", "Shuchismita", ""], ["Livani", "Hanif", ""], ["Yang", "Lei", ""], ["Centeno", "Virgilio", ""]]}, {"id": "2008.10159", "submitter": "Dongxiao Zhang", "authors": "Miao Rong, Dongxiao Zhang, Nanzhe Wang", "title": "A Lagrangian Dual-based Theory-guided Deep Neural Network", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory-guided neural network (TgNN) is a kind of method which improves\nthe effectiveness and efficiency of neural network architectures by\nincorporating scientific knowledge or physical information. Despite its great\nsuccess, the theory-guided (deep) neural network possesses certain limits when\nmaintaining a tradeoff between training data and domain knowledge during the\ntraining process. In this paper, the Lagrangian dual-based TgNN (TgNN-LD) is\nproposed to improve the effectiveness of TgNN. We convert the original loss\nfunction into a constrained form with fewer items, in which partial\ndifferential equations (PDEs), engineering controls (ECs), and expert knowledge\n(EK) are regarded as constraints, with one Lagrangian variable per constraint.\nThese Lagrangian variables are incorporated to achieve an equitable tradeoff\nbetween observation data and corresponding constraints, in order to improve\nprediction accuracy, and conserve time and computational resources adjusted by\nan ad-hoc procedure. To investigate the performance of the proposed method, the\noriginal TgNN model with a set of optimized weight values adjusted by ad-hoc\nprocedures is compared on a subsurface flow problem, with their L2 error, R\nsquare (R2), and computational time being analyzed. Experimental results\ndemonstrate the superiority of the Lagrangian dual-based TgNN.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 02:06:19 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Rong", "Miao", ""], ["Zhang", "Dongxiao", ""], ["Wang", "Nanzhe", ""]]}, {"id": "2008.10174", "submitter": "Egor Zakharov", "authors": "Egor Zakharov, Aleksei Ivakhnenko, Aliaksandra Shysheya, Victor\n  Lempitsky", "title": "Fast Bi-layer Neural Synthesis of One-Shot Realistic Head Avatars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural rendering-based system that creates head avatars from a\nsingle photograph. Our approach models a person's appearance by decomposing it\ninto two layers. The first layer is a pose-dependent coarse image that is\nsynthesized by a small neural network. The second layer is defined by a\npose-independent texture image that contains high-frequency details. The\ntexture image is generated offline, warped and added to the coarse image to\nensure a high effective resolution of synthesized head views. We compare our\nsystem to analogous state-of-the-art systems in terms of visual quality and\nspeed. The experiments show significant inference speedup over previous neural\nhead avatar models for a given visual quality. We also report on a real-time\nsmartphone-based implementation of our system.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 03:23:59 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Zakharov", "Egor", ""], ["Ivakhnenko", "Aleksei", ""], ["Shysheya", "Aliaksandra", ""], ["Lempitsky", "Victor", ""]]}, {"id": "2008.10183", "submitter": "Skyler Seto", "authors": "Skyler Seto, Martin T. Wells, Wenyu Zhang", "title": "HALO: Learning to Prune Neural Networks with Shrinkage", "comments": "Accepted at SDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks achieve state-of-the-art performance in a variety of\ntasks by extracting a rich set of features from unstructured data, however this\nperformance is closely tied to model size. Modern techniques for inducing\nsparsity and reducing model size are (1) network pruning, (2) training with a\nsparsity inducing penalty, and (3) training a binary mask jointly with the\nweights of the network. We study different sparsity inducing penalties from the\nperspective of Bayesian hierarchical models and present a novel penalty called\nHierarchical Adaptive Lasso (HALO) which learns to adaptively sparsify weights\nof a given network via trainable parameters. When used to train\nover-parametrized networks, our penalty yields small subnetworks with high\naccuracy without fine-tuning. Empirically, on image recognition tasks, we find\nthat HALO is able to learn highly sparse network (only 5% of the parameters)\nwith significant gains in performance over state-of-the-art magnitude pruning\nmethods at the same level of sparsity. Code is available at\nhttps://github.com/skyler120/sparsity-halo.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 04:08:48 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 01:47:29 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 04:26:09 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Seto", "Skyler", ""], ["Wells", "Martin T.", ""], ["Zhang", "Wenyu", ""]]}, {"id": "2008.10208", "submitter": "Youwei Liang", "authors": "Youwei Liang, Dong Huang, Chang-Dong Wang, and Philip S. Yu", "title": "Multi-view Graph Learning by Joint Modeling of Consistency and\n  Inconsistency", "comments": "Preprint, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph learning has emerged as a promising technique for multi-view clustering\nwith its ability to learn a unified and robust graph from multiple views.\nHowever, existing graph learning methods mostly focus on the multi-view\nconsistency issue, yet often neglect the inconsistency across multiple views,\nwhich makes them vulnerable to possibly low-quality or noisy datasets. To\novercome this limitation, we propose a new multi-view graph learning framework,\nwhich for the first time simultaneously and explicitly models multi-view\nconsistency and multi-view inconsistency in a unified objective function,\nthrough which the consistent and inconsistent parts of each single-view graph\nas well as the unified graph that fuses the consistent parts can be iteratively\nlearned. Though optimizing the objective function is NP-hard, we design a\nhighly efficient optimization algorithm which is able to obtain an approximate\nsolution with linear time complexity in the number of edges in the unified\ngraph. Furthermore, our multi-view graph learning approach can be applied to\nboth similarity graphs and dissimilarity graphs, which lead to two graph\nfusion-based variants in our framework. Experiments on twelve multi-view\ndatasets have demonstrated the robustness and efficiency of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 06:11:29 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 10:02:51 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Liang", "Youwei", ""], ["Huang", "Dong", ""], ["Wang", "Chang-Dong", ""], ["Yu", "Philip S.", ""]]}, {"id": "2008.10224", "submitter": "Cristian Camilo Beltran Hernandez", "authors": "Cristian C. Beltran-Hernandez, Damien Petit, Ixchel G.\n  Ramirez-Alpizar, Kensuke Harada", "title": "Variable Compliance Control for Robotic Peg-in-Hole Assembly: A Deep\n  Reinforcement Learning Approach", "comments": "17 pages,12 figures, supplemental video https://youtu.be/v4fREpMk7kU", "journal-ref": "Appl. Sci. 2020, 10(19), 6923", "doi": "10.3390/app10196923", "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial robot manipulators are playing a more significant role in modern\nmanufacturing industries. Though peg-in-hole assembly is a common industrial\ntask which has been extensively researched, safely solving complex high\nprecision assembly in an unstructured environment remains an open problem.\nReinforcement Learning (RL) methods have been proven successful in solving\nmanipulation tasks autonomously. However, RL is still not widely adopted on\nreal robotic systems because working with real hardware entails additional\nchallenges, especially when using position-controlled manipulators. The main\ncontribution of this work is a learning-based method to solve peg-in-hole tasks\nwith position uncertainty of the hole. We proposed the use of an off-policy\nmodel-free reinforcement learning method and bootstrap the training speed by\nusing several transfer learning techniques (sim2real) and domain randomization.\nOur proposed learning framework for position-controlled robots was extensively\nevaluated on contact-rich insertion tasks on a variety of environments.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 06:53:19 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 00:27:23 GMT"}, {"version": "v3", "created": "Sat, 21 Nov 2020 04:05:04 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Beltran-Hernandez", "Cristian C.", ""], ["Petit", "Damien", ""], ["Ramirez-Alpizar", "Ixchel G.", ""], ["Harada", "Kensuke", ""]]}, {"id": "2008.10247", "submitter": "Mallikarjun Byrasandra Ramalinga Reddy", "authors": "Mallikarjun B R. (1), Ayush Tewari (1), Tae-Hyun Oh (2), Tim Weyrich\n  (3), Bernd Bickel (4), Hans-Peter Seidel (1), Hanspeter Pfister (5), Wojciech\n  Matusik (6), Mohamed Elgharib (1), Christian Theobalt (1) ((1) Max Planck\n  Institute for Informatics, Saarland Informatics Campus, (2) POSTECH, (3)\n  University College London, (4) IST Austria, (5) Harvard University, (6) MIT\n  CSAIL)", "title": "Monocular Reconstruction of Neural Face Reflectance Fields", "comments": "Project page -\n  http://gvv.mpi-inf.mpg.de/projects/FaceReflectanceFields/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reflectance field of a face describes the reflectance properties\nresponsible for complex lighting effects including diffuse, specular,\ninter-reflection and self shadowing. Most existing methods for estimating the\nface reflectance from a monocular image assume faces to be diffuse with very\nfew approaches adding a specular component. This still leaves out important\nperceptual aspects of reflectance as higher-order global illumination effects\nand self-shadowing are not modeled. We present a new neural representation for\nface reflectance where we can estimate all components of the reflectance\nresponsible for the final appearance from a single monocular image. Instead of\nmodeling each component of the reflectance separately using parametric models,\nour neural representation allows us to generate a basis set of faces in a\ngeometric deformation-invariant space, parameterized by the input light\ndirection, viewpoint and face geometry. We learn to reconstruct this\nreflectance field of a face just from a monocular image, which can be used to\nrender the face from any viewpoint in any light condition. Our method is\ntrained on a light-stage training dataset, which captures 300 people\nilluminated with 150 light conditions from 8 viewpoints. We show that our\nmethod outperforms existing monocular reflectance reconstruction methods, in\nterms of photorealism due to better capturing of physical premitives, such as\nsub-surface scattering, specularities, self-shadows and other higher-order\neffects.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 08:19:05 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["R.", "Mallikarjun B", ""], ["Tewari", "Ayush", ""], ["Oh", "Tae-Hyun", ""], ["Weyrich", "Tim", ""], ["Bickel", "Bernd", ""], ["Seidel", "Hans-Peter", ""], ["Pfister", "Hanspeter", ""], ["Matusik", "Wojciech", ""], ["Elgharib", "Mohamed", ""], ["Theobalt", "Christian", ""]]}, {"id": "2008.10271", "submitter": "Bharath Comandur", "authors": "Bharath Comandur and Avinash C. Kak", "title": "Semantic Labeling of Large-Area Geographic Regions Using Multi-View and\n  Multi-Date Satellite Images and Noisy OSM Training Labels", "comments": "This work has been accepted by the IEEE for publication. Copyright\n  may be transferred without notice, after which this version may no longer be\n  accessible", "journal-ref": null, "doi": "10.1109/JSTARS.2021.3066944", "report-no": null, "categories": "cs.CV cs.DC cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel multi-view training framework and CNN architecture for\ncombining information from multiple overlapping satellite images and noisy\ntraining labels derived from OpenStreetMap (OSM) to semantically label\nbuildings and roads across large geographic regions (100 km$^2$). Our approach\nto multi-view semantic segmentation yields a 4-7% improvement in the per-class\nIoU scores compared to the traditional approaches that use the views\nindependently of one another. A unique (and, perhaps, surprising) property of\nour system is that modifications that are added to the tail-end of the CNN for\nlearning from the multi-view data can be discarded at the time of inference\nwith a relatively small penalty in the overall performance. This implies that\nthe benefits of training using multiple views are absorbed by all the layers of\nthe network. Additionally, our approach only adds a small overhead in terms of\nthe GPU-memory consumption even when training with as many as 32 views per\nscene. The system we present is end-to-end automated, which facilitates\ncomparing the classifiers trained directly on true orthophotos vis-a-vis first\ntraining them on the off-nadir images and subsequently translating the\npredicted labels to geographical coordinates. With no human supervision, our\nIoU scores for the buildings and roads classes are 0.8 and 0.64 respectively\nwhich are better than state-of-the-art approaches that use OSM labels and that\nare not completely automated.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 09:03:31 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 14:17:24 GMT"}, {"version": "v3", "created": "Sat, 28 Nov 2020 15:43:32 GMT"}, {"version": "v4", "created": "Thu, 1 Apr 2021 07:10:30 GMT"}, {"version": "v5", "created": "Sun, 27 Jun 2021 02:50:21 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Comandur", "Bharath", ""], ["Kak", "Avinash C.", ""]]}, {"id": "2008.10277", "submitter": "Abhay Shukla", "authors": "Abhay Shukla, Jairaj Sathyanarayana, Dipyaman Banerjee", "title": "Sample-Rank: Weak Multi-Objective Recommendations Using Rejection\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online food ordering marketplaces are multi-stakeholder systems where\nrecommendations impact the experience and growth of each participant in the\nsystem. A recommender system in this setting has to encapsulate the objectives\nand constraints of different stakeholders in order to find utility of an item\nfor recommendation. Constrained-optimization based approaches to this problem\ntypically involve complex formulations and have high computational complexity\nin production settings involving millions of entities. Simplifications and\nrelaxation techniques (for example, scalarization) help but introduce\nsub-optimality and can be time-consuming due to the amount of tuning needed. In\nthis paper, we introduce a method involving multi-goal sampling followed by\nranking for user-relevance (Sample-Rank), to nudge recommendations towards\nmulti-objective (MO) goals of the marketplace. The proposed method's novelty is\nthat it reduces the MO recommendation problem to sampling from a desired\nmulti-goal distribution then using it to build a production-friendly\nlearning-to-rank (LTR) model. In offline experiments we show that we are able\nto bias recommendations towards MO criteria with acceptable trade-offs in\nmetrics like AUC and NDCG. We also show results from a large-scale online A/B\nexperiment where this approach gave a statistically significant lift of 2.64%\nin average revenue per order (RPO) (objective #1) with no drop in conversion\nrate (CR) (objective #2) while holding the average last-mile traversed flat\n(objective #3), vs. the baseline ranking method. This method also significantly\nreduces time to model development and deployment in MO settings and allows for\ntrivial extensions to more objectives and other types of LTR models.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 09:17:18 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Shukla", "Abhay", ""], ["Sathyanarayana", "Jairaj", ""], ["Banerjee", "Dipyaman", ""]]}, {"id": "2008.10293", "submitter": "Dimitrios Bariamis", "authors": "Armin Runge (1) and Thomas Wenzel (2) and Dimitrios Bariamis (2) and\n  Benedikt Sebastian Staffler (3) and Lucas Rego Drumond (2) and Michael\n  Pfeiffer (3) ((1) Department of Advanced Digital Technologies, Bosch\n  Corporate Research, Renningen, Germany, (2) Computer Vision Lab, Bosch\n  Corporate Research, Hildesheim, Germany, (3) Bosch Center for Artificial\n  Intelligence, Renningen, Germany)", "title": "Bosch Deep Learning Hardware Benchmark", "comments": "Presented in MLBench: Workshop on Benchmarking Machine Learning\n  Workloads (https://sites.google.com/g.harvard.edu/mlbench/home)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread use of Deep Learning (DL) applications in science and industry\nhas created a large demand for efficient inference systems. This has resulted\nin a rapid increase of available Hardware Accelerators (HWAs) making comparison\nchallenging and laborious. To address this, several DL hardware benchmarks have\nbeen proposed aiming at a comprehensive comparison for many models, tasks, and\nhardware platforms. Here, we present our DL hardware benchmark which has been\nspecifically developed for inference on embedded HWAs and tasks required for\nautonomous driving. In addition to previous benchmarks, we propose a new\ngranularity level to evaluate common submodules of DL models, a twofold\nbenchmark procedure that accounts for hardware and model optimizations done by\nHWA manufacturers, and an extended set of performance indicators that can help\nto identify a mismatch between a HWA and the DL models used in our benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 09:50:24 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Runge", "Armin", ""], ["Wenzel", "Thomas", ""], ["Bariamis", "Dimitrios", ""], ["Staffler", "Benedikt Sebastian", ""], ["Drumond", "Lucas Rego", ""], ["Pfeiffer", "Michael", ""]]}, {"id": "2008.10298", "submitter": "Robin Kips", "authors": "Robin Kips, Pietro Gori, Matthieu Perrot, Isabelle Bloch", "title": "CA-GAN: Weakly Supervised Color Aware GAN for Controllable Makeup\n  Transfer", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-67070-2_17", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While existing makeup style transfer models perform an image synthesis whose\nresults cannot be explicitly controlled, the ability to modify makeup color\ncontinuously is a desirable property for virtual try-on applications. We\npropose a new formulation for the makeup style transfer task, with the\nobjective to learn a color controllable makeup style synthesis. We introduce\nCA-GAN, a generative model that learns to modify the color of specific objects\n(e.g. lips or eyes) in the image to an arbitrary target color while preserving\nbackground. Since color labels are rare and costly to acquire, our method\nleverages weakly supervised learning for conditional GANs. This enables to\nlearn a controllable synthesis of complex objects, and only requires a weak\nproxy of the image attribute that we desire to modify. Finally, we present for\nthe first time a quantitative analysis of makeup style transfer and color\ncontrol performance.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 10:11:17 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Kips", "Robin", ""], ["Gori", "Pietro", ""], ["Perrot", "Matthieu", ""], ["Bloch", "Isabelle", ""]]}, {"id": "2008.10312", "submitter": "Evgenii Zheltonozhskii", "authors": "Evgenii Zheltonozhskii, Chaim Baskin, Alex M. Bronstein, Avi Mendelson", "title": "Self-Supervised Learning for Large-Scale Unsupervised Image Clustering", "comments": "accepted to NeurIPS 2020 Workshop: Self-Supervised Learning - Theory\n  and Practice", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Unsupervised learning has always been appealing to machine learning\nresearchers and practitioners, allowing them to avoid an expensive and\ncomplicated process of labeling the data. However, unsupervised learning of\ncomplex data is challenging, and even the best approaches show much weaker\nperformance than their supervised counterparts. Self-supervised deep learning\nhas become a strong instrument for representation learning in computer vision.\nHowever, those methods have not been evaluated in a fully unsupervised setting.\nIn this paper, we propose a simple scheme for unsupervised classification based\non self-supervised representations. We evaluate the proposed approach with\nseveral recent self-supervised methods showing that it achieves competitive\nresults for ImageNet classification (39% accuracy on ImageNet with 1000\nclusters and 46% with overclustering). We suggest adding the unsupervised\nevaluation to a set of standard benchmarks for self-supervised learning. The\ncode is available at https://github.com/Randl/kmeans_selfsuper\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 10:39:19 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 16:14:04 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Zheltonozhskii", "Evgenii", ""], ["Baskin", "Chaim", ""], ["Bronstein", "Alex M.", ""], ["Mendelson", "Avi", ""]]}, {"id": "2008.10325", "submitter": "Pavan A", "authors": "Pavan A, Adithya Bennur, Mohit Gaggar, Shylaja S S", "title": "LCA-Net: Light Convolutional Autoencoder for Image Dehazing", "comments": "4 pages, 7 figures in .pdf format and 1 figure in .jpg format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image dehazing is a crucial image pre-processing task aimed at removing the\nincoherent noise generated by haze to improve the visual appeal of the image.\nThe existing models use sophisticated networks and custom loss functions which\nare computationally inefficient and requires heavy hardware to run. Time is of\nthe essence in image pre-processing since real time outputs can be obtained\ninstantly. To overcome these problems, our proposed generic model uses a very\nlight convolutional encoder-decoder network which does not depend on any\natmospheric models. The network complexity-image quality trade off is handled\nwell in this neural network and the performance of this network is not limited\nby low-spec systems. This network achieves optimum dehazing performance at a\nmuch faster rate, on several standard datasets, comparable to the\nstate-of-the-art methods in terms of image quality.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 11:20:52 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["A", "Pavan", ""], ["Bennur", "Adithya", ""], ["Gaggar", "Mohit", ""], ["S", "Shylaja S", ""]]}, {"id": "2008.10327", "submitter": "Chengyu Wang", "authors": "Taolin Zhang, Chengyu Wang, Minghui Qiu, Bite Yang, Xiaofeng He, Jun\n  Huang", "title": "Knowledge-Empowered Representation Learning for Chinese Medical Reading\n  Comprehension: Task, Model and Resources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Reading Comprehension (MRC) aims to extract answers to questions\ngiven a passage. It has been widely studied recently, especially in open\ndomains. However, few efforts have been made on closed-domain MRC, mainly due\nto the lack of large-scale training data. In this paper, we introduce a\nmulti-target MRC task for the medical domain, whose goal is to predict answers\nto medical questions and the corresponding support sentences from medical\ninformation sources simultaneously, in order to ensure the high reliability of\nmedical knowledge serving. A high-quality dataset is manually constructed for\nthe purpose, named Multi-task Chinese Medical MRC dataset (CMedMRC), with\ndetailed analysis conducted. We further propose the Chinese medical BERT model\nfor the task (CMedBERT), which fuses medical knowledge into pre-trained\nlanguage models by the dynamic fusion mechanism of heterogeneous features and\nthe multi-task learning strategy. Experiments show that CMedBERT consistently\noutperforms strong baselines by fusing context-aware and knowledge-aware token\nrepresentations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 11:23:28 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Zhang", "Taolin", ""], ["Wang", "Chengyu", ""], ["Qiu", "Minghui", ""], ["Yang", "Bite", ""], ["He", "Xiaofeng", ""], ["Huang", "Jun", ""]]}, {"id": "2008.10349", "submitter": "Varun Pandey", "authors": "Varun Pandey, Alexander van Renen, Andreas Kipf, Ibrahim Sabek, Jialin\n  Ding, Alfons Kemper", "title": "The Case for Learned Spatial Indexes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spatial data is ubiquitous. Massive amounts of data are generated every day\nfrom billions of GPS-enabled devices such as cell phones, cars, sensors, and\nvarious consumer-based applications such as Uber, Tinder, location-tagged posts\nin Facebook, Twitter, Instagram, etc. This exponential growth in spatial data\nhas led the research community to focus on building systems and applications\nthat can process spatial data efficiently. In the meantime, recent research has\nintroduced learned index structures. In this work, we use techniques proposed\nfrom a state-of-the art learned multi-dimensional index structure (namely,\nFlood) and apply them to five classical multi-dimensional indexes to be able to\nanswer spatial range queries. By tuning each partitioning technique for optimal\nperformance, we show that (i) machine learned search within a partition is\nfaster by 11.79\\% to 39.51\\% than binary search when using filtering on one\ndimension, (ii) the bottleneck for tree structures is index lookup, which could\npotentially be improved by linearizing the indexed partitions (iii) filtering\non one dimension and refining using machine learned indexes is 1.23x to 1.83x\ntimes faster than closest competitor which filters on two dimensions, and (iv)\nlearned indexes can have a significant impact on the performance of low\nselectivity queries while being less effective under higher selectivities.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 12:09:55 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Pandey", "Varun", ""], ["van Renen", "Alexander", ""], ["Kipf", "Andreas", ""], ["Sabek", "Ibrahim", ""], ["Ding", "Jialin", ""], ["Kemper", "Alfons", ""]]}, {"id": "2008.10351", "submitter": "Lucas Hu", "authors": "Lucas Hu, Caleb Robinson, Bistra Dilkina", "title": "Model Generalization in Deep Learning Applications for Land Cover\n  Mapping", "comments": "9 pages, 7 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that deep learning models can be used to classify\nland-use data from geospatial satellite imagery. We show that when these deep\nlearning models are trained on data from specific continents/seasons, there is\na high degree of variability in model performance on out-of-sample\ncontinents/seasons. This suggests that just because a model accurately predicts\nland-use classes in one continent or season does not mean that the model will\naccurately predict land-use classes in a different continent or season. We then\nuse clustering techniques on satellite imagery from different continents to\nvisualize the differences in landscapes that make geospatial generalization\nparticularly difficult, and summarize our takeaways for future satellite\nimagery-related applications.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 01:50:52 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 02:04:42 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 19:04:16 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Hu", "Lucas", ""], ["Robinson", "Caleb", ""], ["Dilkina", "Bistra", ""]]}, {"id": "2008.10365", "submitter": "Ravi Vadlamani", "authors": "Sarveswararao Vangala, Ravi Vadlamani", "title": "ATM Cash demand forecasting in an Indian Bank with chaos and deep\n  learning", "comments": "20 pages; 6 figures and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper proposes to model chaos in the ATM cash withdrawal time series of\na big Indian bank and forecast the withdrawals using deep learning methods. It\nalso considers the importance of day-of-the-week and includes it as a dummy\nexogenous variable. We first modelled the chaos present in the withdrawal time\nseries by reconstructing the state space of each series using the lag, and\nembedding dimension found using an auto-correlation function and Cao's method.\nThis process converts the uni-variate time series into multi variate time\nseries. The \"day-of-the-week\" is converted into seven features with the help of\none-hot encoding. Then these seven features are augmented to the multivariate\ntime series. For forecasting the future cash withdrawals, using algorithms\nnamely ARIMA, random forest (RF), support vector regressor (SVR), multi-layer\nperceptron (MLP), group method of data handling (GMDH), general regression\nneural network (GRNN), long short term memory neural network and 1-dimensional\nconvolutional neural network. We considered a daily cash withdrawals data set\nfrom an Indian commercial bank. After modelling chaos and adding exogenous\nfeatures to the data set, we observed improvements in the forecasting for all\nmodels. Even though the random forest (RF) yielded better Symmetric Mean\nAbsolute Percentage Error (SMAPE) value, deep learning algorithms, namely LSTM\nand 1D CNN, showed similar performance compared to RF, based on t-test.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 12:23:07 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Vangala", "Sarveswararao", ""], ["Vadlamani", "Ravi", ""]]}, {"id": "2008.10380", "submitter": "Gang Mei", "authors": "Gang Mei, Jingzhi Tu, Lei Xiao, Francesco Piccialli", "title": "KCoreMotif: An Efficient Graph Clustering Algorithm for Large Networks\n  by Exploiting k-core Decomposition and Motifs", "comments": "33 pages; 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering analysis has been widely used in trust evaluation on various\ncomplex networks such as wireless sensors networks and online social networks.\nSpectral clustering is one of the most commonly used algorithms for\ngraph-structured data (networks). However, the conventional spectral clustering\nis inherently difficult to work with large-scale networks due to the fact that\nit needs computationally expensive matrix manipulations. To deal with large\nnetworks, in this paper, we propose an efficient graph clustering algorithm,\nKCoreMotif, specifically for large networks by exploiting k-core decomposition\nand motifs. The essential idea behind the proposed clustering algorithm is to\nperform the efficient motif-based spectral clustering algorithm on k-core\nsubgraphs, rather than on the entire graph. More specifically, (1) we first\nconduct the k-core decomposition of the large input network; (2) we then\nperform the motif-based spectral clustering for the top k-core subgraphs; (3)\nwe group the remaining vertices in the rest (k-1)-core subgraphs into\npreviously found clusters; and finally obtain the desired clusters of the large\ninput network. To evaluate the performance of the proposed graph clustering\nalgorithm KCoreMotif, we use both the conventional and the motif-based spectral\nclustering algorithms as the baselines and compare our algorithm with them for\n18 groups of real-world datasets. Comparative results demonstrate that the\nproposed graph clustering algorithm is accurate yet efficient for large\nnetworks, which also means that it can be further used to evaluate the\nintra-cluster and inter-cluster trusts on large networks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 12:21:05 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Mei", "Gang", ""], ["Tu", "Jingzhi", ""], ["Xiao", "Lei", ""], ["Piccialli", "Francesco", ""]]}, {"id": "2008.10383", "submitter": "Kazi Zainab Khanam", "authors": "Kazi Zainab Khanam, Gautam Srivastava, Vijay Mago", "title": "The Homophily Principle in Social Network Analysis", "comments": "27 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, social media has become a ubiquitous and integral part of\nsocial networking. One of the major attentions made by social researchers is\nthe tendency of like-minded people to interact with one another in social\ngroups, a concept which is known as Homophily. The study of homophily can\nprovide eminent insights into the flow of information and behaviors within a\nsociety and this has been extremely useful in analyzing the formations of\nonline communities. In this paper, we review and survey the effect of homophily\nin social networks and summarize the state of art methods that has been\nproposed in the past years to identify and measure the effect of homophily in\nmultiple types of social networks and we conclude with a critical discussion of\nopen challenges and directions for future research.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 05:43:59 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Khanam", "Kazi Zainab", ""], ["Srivastava", "Gautam", ""], ["Mago", "Vijay", ""]]}, {"id": "2008.10399", "submitter": "Abhinav Sagar", "authors": "Abhinav Sagar", "title": "Generate High Resolution Images With Generative Variational Autoencoder", "comments": "The network architecture used in this paper while training the model\n  is not correct", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a novel neural network to generate high resolution\nimages. We replace the decoder of VAE with a discriminator while using the\nencoder as it is. The encoder is fed data from a normal distribution while the\ngenerator is fed from a gaussian distribution. The combination from both is\ngiven to a discriminator which tells whether the generated image is correct or\nnot. We evaluate our network on 3 different datasets: MNIST, LSUN and CelebA\ndataset. Our network beats the previous state of the art using MMD, SSIM, log\nlikelihood, reconstruction error, ELBO and KL divergence as the evaluation\nmetrics while generating much sharper images. This work is potentially very\nexciting as we are able to combine the advantages of generative models and\ninference models in a principled bayesian manner.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 20:15:34 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 17:08:46 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 18:15:20 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Sagar", "Abhinav", ""]]}, {"id": "2008.10400", "submitter": "Sanghyeon An", "authors": "Sanghyeon An, Minjun Lee, Sanglee Park, Heerin Yang, Jungmin So", "title": "An Ensemble of Simple Convolutional Neural Network Models for MNIST\n  Digit Recognition", "comments": "10 pages, 12 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report that a very high accuracy on the MNIST test set can be achieved by\nusing simple convolutional neural network (CNN) models. We use three different\nmodels with 3x3, 5x5, and 7x7 kernel size in the convolution layers. Each model\nconsists of a set of convolution layers followed by a single fully connected\nlayer. Every convolution layer uses batch normalization and ReLU activation,\nand pooling is not used. Rotation and translation is used to augment training\ndata, which is frequently used in most image classification tasks. A majority\nvoting using the three models independently trained on the training data set\ncan achieve up to 99.87% accuracy on the test set, which is one of the\nstate-of-the-art results. A two-layer ensemble, a heterogeneous ensemble of\nthree homogeneous ensemble networks, can achieve up to 99.91% test accuracy.\nThe results can be reproduced by using the code at:\nhttps://github.com/ansh941/MnistSimpleCNN\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 09:27:05 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 03:49:48 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["An", "Sanghyeon", ""], ["Lee", "Minjun", ""], ["Park", "Sanglee", ""], ["Yang", "Heerin", ""], ["So", "Jungmin", ""]]}, {"id": "2008.10413", "submitter": "Nicolas Riche", "authors": "Augustin Arnault and Nicolas Riche", "title": "CRNNs for Urban Sound Tagging with spatiotemporal context", "comments": "4 pages, 5 figures, DCASE2020 Challenge - DCASE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes CRNNs we used to participate in Task 5 of the DCASE 2020\nchallenge. This task focuses on hierarchical multilabel urban sound tagging\nwith spatiotemporal context. The code is available on our GitHub repository at\nhttps://github.com/multitel-ai/urban-sound-tagging.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 13:16:47 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 14:53:06 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Arnault", "Augustin", ""], ["Riche", "Nicolas", ""]]}, {"id": "2008.10419", "submitter": "Amine Dadoun", "authors": "Amine Dadoun (1 and 2), Ismail Harrando (1), Pasquale Lisena (1),\n  Alison Reboud (1), Raphael Troncy (1) ((1) Eurecom, (2) Amadeus SAS)", "title": "Two Stages Approach for Tweet Engagement Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the approach proposed by the D2KLab team for the 2020\nRecSys Challenge on the task of predicting user engagement facing tweets. This\napproach relies on two distinct stages. First, relevant features are learned\nfrom the challenge dataset. These features are heterogeneous and are the\nresults of different learning modules such as handcrafted features, knowledge\ngraph embeddings, sentiment analysis features and BERT word embeddings. Second,\nthese features are provided in input to an ensemble system based on XGBoost.\nThis approach, only trained on a subset of the entire challenge dataset, ranked\n22 in the final leaderboard.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 13:18:10 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Dadoun", "Amine", "", "1 and 2"], ["Harrando", "Ismail", "", "Eurecom"], ["Lisena", "Pasquale", "", "Eurecom"], ["Reboud", "Alison", "", "Eurecom"], ["Troncy", "Raphael", "", "Eurecom"]]}, {"id": "2008.10422", "submitter": "Hongchang Gao", "authors": "Hongchang Gao, Heng Huang", "title": "Adaptive Serverless Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of distributed data, training machine learning models in\nthe serverless manner has attracted increasing attention in recent years.\nNumerous training approaches have been proposed in this regime, such as\ndecentralized SGD. However, all existing decentralized algorithms only focus on\nstandard SGD. It might not be suitable for some applications, such as deep\nfactorization machine in which the feature is highly sparse and categorical so\nthat the adaptive training algorithm is needed. In this paper, we propose a\nnovel adaptive decentralized training approach, which can compute the learning\nrate from data dynamically. To the best of our knowledge, this is the first\nadaptive decentralized training approach. Our theoretical results reveal that\nthe proposed algorithm can achieve linear speedup with respect to the number of\nworkers. Moreover, to reduce the communication-efficient overhead, we further\npropose a communication-efficient adaptive decentralized training approach,\nwhich can also achieve linear speedup with respect to the number of workers. At\nlast, extensive experiments on different tasks have confirmed the effectiveness\nof our proposed two approaches.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 13:23:02 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Gao", "Hongchang", ""], ["Huang", "Heng", ""]]}, {"id": "2008.10425", "submitter": "Ajay Patrikar", "authors": "Ajay M. Patrikar", "title": "Efficient Design of Neural Networks with Random Weights", "comments": "5 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single layer feedforward networks with random weights are known for their\nnon-iterative and fast training algorithms and are successful in a variety of\nclassification and regression problems. A major drawback of these networks is\nthat they require a large number of hidden units. In this paper, we propose a\ntechnique to reduce the number of hidden units substantially without affecting\nthe accuracy of the networks significantly. We introduce the concept of primary\nand secondary hidden units. The weights for the primary hidden units are chosen\nrandomly while the secondary hidden units are derived using pairwise\ncombinations of the primary hidden units. Using this technique, we show that\nthe number of hidden units can be reduced by at least one order of magnitude.\nWe experimentally show that this technique leads to significant drop in\ncomputations at inference time and has only a minor impact on network accuracy.\nA huge reduction in computations is possible if slightly lower accuracy is\nacceptable.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 13:24:25 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Patrikar", "Ajay M.", ""]]}, {"id": "2008.10433", "submitter": "Pantelis Vlachas", "authors": "Francesco Varoli, Guido Novati, Pantelis R. Vlachas, Petros\n  Koumoutsakos", "title": "Improved Memories Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Improved Memories Learning (IMeL), a novel algorithm that turns\nreinforcement learning (RL) into a supervised learning (SL) problem and\ndelimits the role of neural networks (NN) to interpolation. IMeL consists of\ntwo components. The first is a reservoir of experiences. Each experience is\nupdated based on a non-parametric procedural improvement of the policy,\ncomputed as a bounded one-sample Monte Carlo estimate. The second is a NN\nregressor, which receives as input improved experiences from the reservoir\n(context points) and computes the policy by interpolation. The NN learns to\nmeasure the similarity between states in order to compute long-term forecasts\nby averaging experiences, rather than by encoding the problem structure in the\nNN parameters. We present preliminary results and propose IMeL as a baseline\nmethod for assessing the merits of more complex models and inductive biases.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 13:37:15 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Varoli", "Francesco", ""], ["Novati", "Guido", ""], ["Vlachas", "Pantelis R.", ""], ["Koumoutsakos", "Petros", ""]]}, {"id": "2008.10435", "submitter": "Hongchang Gao", "authors": "Hongchang Gao, Heng Huang", "title": "Periodic Stochastic Gradient Descent with Momentum for Decentralized\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized training has been actively studied in recent years. Although a\nwide variety of methods have been proposed, yet the decentralized momentum SGD\nmethod is still underexplored. In this paper, we propose a novel periodic\ndecentralized momentum SGD method, which employs the momentum schema and\nperiodic communication for decentralized training. With these two strategies,\nas well as the topology of the decentralized training system, the theoretical\nconvergence analysis of our proposed method is difficult. We address this\nchallenging problem and provide the condition under which our proposed method\ncan achieve the linear speedup regarding the number of workers. Furthermore, we\nalso introduce a communication-efficient variant to reduce the communication\ncost in each communication round. The condition for achieving the linear\nspeedup is also provided for this variant. To the best of our knowledge, these\ntwo methods are all the first ones achieving these theoretical results in their\ncorresponding domain. We conduct extensive experiments to verify the\nperformance of our proposed two methods, and both of them have shown superior\nperformance over existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 13:38:22 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Gao", "Hongchang", ""], ["Huang", "Heng", ""]]}, {"id": "2008.10444", "submitter": "Hui Wen", "authors": "Hui Wen, Yue Wu, Chenming Yang, Jingjing Li, Yue Zhu, Xu Jiang,\n  Hancong Duan", "title": "Transferring Inter-Class Correlation", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Teacher-Student (T-S) framework is widely utilized in the classification\ntasks, through which the performance of one neural network (the student) can be\nimproved by transferring knowledge from another trained neural network (the\nteacher). Since the transferring knowledge is related to the network capacities\nand structures between the teacher and the student, how to define efficient\nknowledge remains an open question. To address this issue, we design a novel\ntransferring knowledge, the Self-Attention based Inter-Class Correlation (ICC)\nmap in the output layer, and propose our T-S framework, Inter-Class Correlation\nTransfer (ICCT).\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 13:24:44 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Wen", "Hui", ""], ["Wu", "Yue", ""], ["Yang", "Chenming", ""], ["Li", "Jingjing", ""], ["Zhu", "Yue", ""], ["Jiang", "Xu", ""], ["Duan", "Hancong", ""]]}, {"id": "2008.10450", "submitter": "Akshansh Gupta", "authors": "Hanuman Verma, Akshansh Gupta and Utkarsh Niranjan", "title": "Analysis of COVID-19 cases in India through Machine Learning: A Study of\n  Intervention", "comments": "27 Pages, 26 Figures, 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.soc-ph q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To combat the coronavirus disease 2019 (COVID-19) pandemic, the world has\nvaccination, plasma therapy, herd immunity, and epidemiological interventions\nas few possible options. The COVID-19 vaccine development is underway and it\nmay take a significant amount of time to develop the vaccine and after\ndevelopment, it will take time to vaccinate the entire population, and plasma\ntherapy has some limitations. Herd immunity can be a plausible option to fight\nCOVID-19 for small countries. But for a country with huge population like\nIndia, herd immunity is not a plausible option, because to acquire herd\nimmunity approximately 67% of the population has to be recovered from COVID-19\ninfection, which will put an extra burden on medical system of the country and\nwill result in a huge loss of human life. Thus epidemiological interventions\n(complete lockdown, partial lockdown, quarantine, isolation, social distancing,\netc.) are some suitable strategies in India to slow down the COVID-19 spread\nuntil the vaccine development. In this work, we have suggested the SIR model\nwith intervention, which incorporates the epidemiological interventions in the\nclassical SIR model. To model the effect of the interventions, we have\nintroduced \\r{ho} as the intervention parameter. \\r{ho} is a cumulative\nquantity which covers all type of intervention. We have also discussed the\nsupervised machine learning approach to estimate the transmission rate\n(\\b{eta}) for the SIR model with intervention from the prevalence of COVID-19\ndata in India and some states of India. To validate our model, we present a\ncomparison between the actual and model-predicted number of COVID-19 cases.\nUsing our model, we also present predicted numbers of active and recovered\nCOVID-19 cases till Sept 30, 2020, for entire India and some states of India\nand also estimate the 95% and 99% confidence interval for the predicted cases.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 05:45:50 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Verma", "Hanuman", ""], ["Gupta", "Akshansh", ""], ["Niranjan", "Utkarsh", ""]]}, {"id": "2008.10460", "submitter": "Violet Xinying Chen", "authors": "Violet Xinying Chen, Fatma K{\\i}l{\\i}n\\c{c}-Karzan", "title": "Online Convex Optimization Perspective for Learning from Dynamically\n  Revealed Preferences", "comments": "34 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of online learning (OL) from revealed preferences: a\nlearner wishes to learn a non-strategic agent's private utility function\nthrough observing the agent's utility-maximizing actions in a changing\nenvironment. We adopt an online inverse optimization setup, where the learner\nobserves a stream of agent's actions in an online fashion and the learning\nperformance is measured by regret associated with a loss function. We first\ncharacterize a special but broad class of agent's utility functions, then\nutilize this structure in designing a new convex loss function. We establish\nthat the regret with respect to our new loss function also bounds the regret\nwith respect to all other usual loss functions in the literature. This allows\nus to design a flexible OL framework that enables a unified treatment of loss\nfunctions and supports a variety of online convex optimization algorithms. We\ndemonstrate with theoretical and empirical evidence that our framework based on\nthe new loss function (in particular online Mirror Descent) has significant\nadvantages in terms of regret performance and solution time over other OL\nalgorithms from the literature and bypasses the previous technical assumptions\nas well.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 14:05:13 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 13:10:05 GMT"}, {"version": "v3", "created": "Fri, 4 Jun 2021 13:31:11 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Chen", "Violet Xinying", ""], ["K\u0131l\u0131n\u00e7-Karzan", "Fatma", ""]]}, {"id": "2008.10471", "submitter": "Leonel Rozo", "authors": "Leonel Rozo, Meng Guo, Andras G. Kupcsik, Marco Todescato, Philipp\n  Schillinger, Markus Giftthaler, Matthias Ochs, Markus Spies, Nicolai Waniek,\n  Patrick Kesper, Mathias B\\\"uerger", "title": "Learning and Sequencing of Object-Centric Manipulation Skills for\n  Industrial Tasks", "comments": "First three authors equally contributed. Pre-print accepted for\n  publication in IROS'2020. Video: https://youtu.be/dRGLadt32o4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enabling robots to quickly learn manipulation skills is an important, yet\nchallenging problem. Such manipulation skills should be flexible, e.g., be able\nadapt to the current workspace configuration. Furthermore, to accomplish\ncomplex manipulation tasks, robots should be able to sequence several skills\nand adapt them to changing situations. In this work, we propose a rapid robot\nskill-sequencing algorithm, where the skills are encoded by object-centric\nhidden semi-Markov models. The learned skill models can encode multimodal\n(temporal and spatial) trajectory distributions. This approach significantly\nreduces manual modeling efforts, while ensuring a high degree of flexibility\nand re-usability of learned skills. Given a task goal and a set of generic\nskills, our framework computes smooth transitions between skill instances. To\ncompute the corresponding optimal end-effector trajectory in task space we rely\non Riemannian optimal controller. We demonstrate this approach on a 7 DoF robot\narm for industrial assembly tasks.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 14:20:05 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Rozo", "Leonel", ""], ["Guo", "Meng", ""], ["Kupcsik", "Andras G.", ""], ["Todescato", "Marco", ""], ["Schillinger", "Philipp", ""], ["Giftthaler", "Markus", ""], ["Ochs", "Matthias", ""], ["Spies", "Markus", ""], ["Waniek", "Nicolai", ""], ["Kesper", "Patrick", ""], ["B\u00fcerger", "Mathias", ""]]}, {"id": "2008.10491", "submitter": "Cal Peyser", "authors": "Cal Peyser, Sepand Mavandadi, Tara N. Sainath, James Apfel, Ruoming\n  Pang, Shankar Kumar", "title": "Improving Tail Performance of a Deliberation E2E ASR Model Using a Large\n  Text Corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end (E2E) automatic speech recognition (ASR) systems lack the distinct\nlanguage model (LM) component that characterizes traditional speech systems.\nWhile this simplifies the model architecture, it complicates the task of\nincorporating text-only data into training, which is important to the\nrecognition of tail words that do not occur often in audio-text pairs. While\nshallow fusion has been proposed as a method for incorporating a pre-trained LM\ninto an E2E model at inference time, it has not yet been explored for very\nlarge text corpora, and it has been shown to be very sensitive to\nhyperparameter settings in the beam search. In this work, we apply shallow\nfusion to incorporate a very large text corpus into a state-of-the-art E2EASR\nmodel. We explore the impact of model size and show that intelligent pruning of\nthe training set can be more effective than increasing the parameter count.\nAdditionally, we show that incorporating the LM in minimum word error rate\n(MWER) fine tuning makes shallow fusion far less dependent on optimal\nhyperparameter settings, reducing the difficulty of that tuning problem.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 14:53:10 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 12:50:55 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Peyser", "Cal", ""], ["Mavandadi", "Sepand", ""], ["Sainath", "Tara N.", ""], ["Apfel", "James", ""], ["Pang", "Ruoming", ""], ["Kumar", "Shankar", ""]]}, {"id": "2008.10498", "submitter": "Yuzuru Sato", "authors": "Yuzuru Sato, Daiji Tsutsui, and Akio Fujiwara", "title": "Noise-induced degeneration in online learning", "comments": "16 pages, 5 figures, submitted to Physica D", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to elucidate the plateau phenomena caused by vanishing gradient, we\nherein analyse stability of stochastic gradient descent near degenerated\nsubspaces in a multi-layer perceptron. In stochastic gradient descent for\nFukumizu-Amari model, which is the minimal multi-layer perceptron showing\nnon-trivial plateau phenomena, we show that (1) attracting regions exist in\nmultiply degenerated subspaces, (2) a strong plateau phenomenon emerges as a\nnoise-induced synchronisation, which is not observed in deterministic gradient\ndescent, (3) an optimal fluctuation exists to minimise the escape time from the\ndegenerated subspace. The noise-induced degeneration observed herein is\nexpected to be found in a broad class of machine learning via neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 15:03:58 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 16:33:57 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2020 04:06:18 GMT"}, {"version": "v4", "created": "Sat, 21 Nov 2020 03:20:47 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Sato", "Yuzuru", ""], ["Tsutsui", "Daiji", ""], ["Fujiwara", "Akio", ""]]}, {"id": "2008.10516", "submitter": "David Armstrong", "authors": "David J. Armstrong, Jevgenij Gamper, Theodoros Damoulas", "title": "Exoplanet Validation with Machine Learning: 50 new validated Kepler\n  planets", "comments": "Accepted by MNRAS (advance access version:\n  https://academic.oup.com/mnras/advance-article-abstract/doi/10.1093/mnras/staa2498/5894933)", "journal-ref": null, "doi": "10.1093/mnras/staa2498", "report-no": null, "categories": "astro-ph.EP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over 30% of the ~4000 known exoplanets to date have been discovered using\n'validation', where the statistical likelihood of a transit arising from a\nfalse positive (FP), non-planetary scenario is calculated. For the large\nmajority of these validated planets calculations were performed using the vespa\nalgorithm (Morton et al. 2016). Regardless of the strengths and weaknesses of\nvespa, it is highly desirable for the catalogue of known planets not to be\ndependent on a single method. We demonstrate the use of machine learning\nalgorithms, specifically a gaussian process classifier (GPC) reinforced by\nother models, to perform probabilistic planet validation incorporating prior\nprobabilities for possible FP scenarios. The GPC can attain a mean log-loss per\nsample of 0.54 when separating confirmed planets from FPs in the Kepler\nthreshold crossing event (TCE) catalogue. Our models can validate thousands of\nunseen candidates in seconds once applicable vetting metrics are calculated,\nand can be adapted to work with the active TESS mission, where the large number\nof observed targets necessitates the use of automated algorithms. We discuss\nthe limitations and caveats of this methodology, and after accounting for\npossible failure modes newly validate 50 Kepler candidates as planets, sanity\nchecking the validations by confirming them with vespa using up to date stellar\ninformation. Concerning discrepancies with vespa arise for many other\ncandidates, which typically resolve in favour of our models. Given such issues,\nwe caution against using single-method planet validation with either method\nuntil the discrepancies are fully understood.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 15:35:21 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Armstrong", "David J.", ""], ["Gamper", "Jevgenij", ""], ["Damoulas", "Theodoros", ""]]}, {"id": "2008.10526", "submitter": "Saeed Ghadimi", "authors": "Krishnakumar Balasubramanian, Saeed Ghadimi, Anthony Nguyen", "title": "Stochastic Multi-level Composition Optimization Algorithms with\n  Level-Independent Convergence Rates", "comments": "Refined the convergence analysis in Section 3 under weaker\n  assumptions", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study smooth stochastic multi-level composition\noptimization problems, where the objective function is a nested composition of\n$T$ functions. We assume access to noisy evaluations of the functions and their\ngradients, through a stochastic first-order oracle. For solving this class of\nproblems, we propose two algorithms using moving-average stochastic estimates,\nand analyze their convergence to an $\\epsilon$-stationary point of the problem.\nWe show that the first algorithm, which is a generalization of\n\\cite{GhaRuswan20} to the $T$ level case, can achieve a sample complexity of\n$\\mathcal{O}(1/\\epsilon^6)$ by using mini-batches of samples in each iteration.\nBy modifying this algorithm using linearized stochastic estimates of the\nfunction values, we improve the sample complexity to\n$\\mathcal{O}(1/\\epsilon^4)$. {\\color{black}This modification not only removes\nthe requirement of having a mini-batch of samples in each iteration, but also\nmakes the algorithm parameter-free and easy to implement}. To the best of our\nknowledge, this is the first time that such an online algorithm designed for\nthe (un)constrained multi-level setting, obtains the same sample complexity of\nthe smooth single-level setting, under standard assumptions (unbiasedness and\nboundedness of the second moments) on the stochastic first-order oracle.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 15:57:50 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 15:59:02 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 04:36:11 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Balasubramanian", "Krishnakumar", ""], ["Ghadimi", "Saeed", ""], ["Nguyen", "Anthony", ""]]}, {"id": "2008.10530", "submitter": "Liam Jones", "authors": "Liam Dowling Jones, Malik Magdon-Ismail, Laura Mersini-Houghton and\n  Steven Meshnick", "title": "A New Mathematical Model for Controlled Pandemics Like COVID-19 : AI\n  Implemented Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new mathematical model to explicitly capture the effects that\nthe three restriction measures: the lockdown date and duration, social\ndistancing and masks, and, schools and border closing, have in controlling the\nspread of COVID-19 infections $i(r, t)$. Before restrictions were introduced,\nthe random spread of infections as described by the SEIR model grew\nexponentially. The addition of control measures introduces a mixing of order\nand disorder in the system's evolution which fall under a different\nmathematical class of models that can eventually lead to critical phenomena. A\ngeneric analytical solution is hard to obtain. We use machine learning to solve\nthe new equations for $i(r,t)$, the infections $i$ in any region $r$ at time\n$t$ and derive predictions for the spread of infections over time as a function\nof the strength of the specific measure taken and their duration. The machine\nis trained in all of the COVID-19 published data for each region, county,\nstate, and country in the world. It utilizes optimization to learn the best-fit\nvalues of the model's parameters from past data in each region in the world,\nand it updates the predicted infections curves for any future restrictions that\nmay be added or relaxed anywhere. We hope this interdisciplinary effort, a new\nmathematical model that predicts the impact of each measure in slowing down\ninfection spread combined with the solving power of machine learning, is a\nuseful tool in the fight against the current pandemic and potentially future\nones.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 16:07:00 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Jones", "Liam Dowling", ""], ["Magdon-Ismail", "Malik", ""], ["Mersini-Houghton", "Laura", ""], ["Meshnick", "Steven", ""]]}, {"id": "2008.10532", "submitter": "Claire Heaney", "authors": "Toby Phillips, Claire E. Heaney, Paul N. Smith, Christopher C. Pain", "title": "An autoencoder-based reduced-order model for eigenvalue problems with\n  application to neutron diffusion", "comments": "35 pages, 33 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using an autoencoder for dimensionality reduction, this paper presents a\nnovel projection-based reduced-order model for eigenvalue problems.\nReduced-order modelling relies on finding suitable basis functions which define\na low-dimensional space in which a high-dimensional system is approximated.\nProper orthogonal decomposition (POD) and singular value decomposition (SVD)\nare often used for this purpose and yield an optimal linear subspace.\nAutoencoders provide a nonlinear alternative to POD/SVD, that may capture, more\nefficiently, features or patterns in the high-fidelity model results.\n  Reduced-order models based on an autoencoder and a novel hybrid\nSVD-autoencoder are developed. These methods are compared with the standard\nPOD-Galerkin approach and are applied to two test cases taken from the field of\nnuclear reactor physics.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 16:52:26 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Phillips", "Toby", ""], ["Heaney", "Claire E.", ""], ["Smith", "Paul N.", ""], ["Pain", "Christopher C.", ""]]}, {"id": "2008.10546", "submitter": "Lingkai Kong", "authors": "Lingkai Kong, Jimeng Sun and Chao Zhang", "title": "SDE-Net: Equipping Deep Neural Networks with Uncertainty Estimates", "comments": "ICML2020. Code is available through\n  https://github.com/Lingkai-Kong/SDE-Net", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty quantification is a fundamental yet unsolved problem for deep\nlearning. The Bayesian framework provides a principled way of uncertainty\nestimation but is often not scalable to modern deep neural nets (DNNs) that\nhave a large number of parameters. Non-Bayesian methods are simple to implement\nbut often conflate different sources of uncertainties and require huge\ncomputing resources. We propose a new method for quantifying uncertainties of\nDNNs from a dynamical system perspective. The core of our method is to view DNN\ntransformations as state evolution of a stochastic dynamical system and\nintroduce a Brownian motion term for capturing epistemic uncertainty. Based on\nthis perspective, we propose a neural stochastic differential equation model\n(SDE-Net) which consists of (1) a drift net that controls the system to fit the\npredictive function; and (2) a diffusion net that captures epistemic\nuncertainty. We theoretically analyze the existence and uniqueness of the\nsolution to SDE-Net. Our experiments demonstrate that the SDE-Net model can\noutperform existing uncertainty estimation methods across a series of tasks\nwhere uncertainty plays a fundamental role.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 16:33:54 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Kong", "Lingkai", ""], ["Sun", "Jimeng", ""], ["Zhang", "Chao", ""]]}, {"id": "2008.10547", "submitter": "William Stephenson", "authors": "William T. Stephenson, Madeleine Udell, Tamara Broderick", "title": "Approximate Cross-Validation with Low-Rank Data in High Dimensions", "comments": "19 pages, 6 figures", "journal-ref": "Advances in Neural Information Processing Systems 33 (NeurIPS\n  2020)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent advances in machine learning are driven by a challenging\ntrifecta: large data size $N$; high dimensions; and expensive algorithms. In\nthis setting, cross-validation (CV) serves as an important tool for model\nassessment. Recent advances in approximate cross validation (ACV) provide\naccurate approximations to CV with only a single model fit, avoiding\ntraditional CV's requirement for repeated runs of expensive algorithms.\nUnfortunately, these ACV methods can lose both speed and accuracy in high\ndimensions -- unless sparsity structure is present in the data. Fortunately,\nthere is an alternative type of simplifying structure that is present in most\ndata: approximate low rank (ALR). Guided by this observation, we develop a new\nalgorithm for ACV that is fast and accurate in the presence of ALR data. Our\nfirst key insight is that the Hessian matrix -- whose inverse forms the\ncomputational bottleneck of existing ACV methods -- is ALR. We show that,\ndespite our use of the \\emph{inverse} Hessian, a low-rank approximation using\nthe largest (rather than the smallest) matrix eigenvalues enables fast,\nreliable ACV. Our second key insight is that, in the presence of ALR data,\nerror in existing ACV methods roughly grows with the (approximate, low) rank\nrather than with the (full, high) dimension. These insights allow us to prove\ntheoretical guarantees on the quality of our proposed algorithm -- along with\nfast-to-compute upper bounds on its error. We demonstrate the speed and\naccuracy of our method, as well as the usefulness of our bounds, on a range of\nreal and simulated data sets.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 16:34:05 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Stephenson", "William T.", ""], ["Udell", "Madeleine", ""], ["Broderick", "Tamara", ""]]}, {"id": "2008.10549", "submitter": "Alireza Heidari", "authors": "Alireza Heidari, Shrinu Kushagra, Ihab F. Ilyas", "title": "On sampling from data with duplicate records", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data deduplication is the task of detecting records in a database that\ncorrespond to the same real-world entity. Our goal is to develop a procedure\nthat samples uniformly from the set of entities present in the database in the\npresence of duplicates. We accomplish this by a two-stage process. In the first\nstep, we estimate the frequencies of all the entities in the database. In the\nsecond step, we use rejection sampling to obtain a (approximately) uniform\nsample from the set of entities. However, efficiently estimating the frequency\nof all the entities is a non-trivial task and not attainable in the general\ncase. Hence, we consider various natural properties of the data under which\nsuch frequency estimation (and consequently uniform sampling) is possible.\nUnder each of those assumptions, we provide sampling algorithms and give proofs\nof the complexity (both statistical and computational) of our approach. We\ncomplement our study by conducting extensive experiments on both real and\nsynthetic datasets.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 16:41:47 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Heidari", "Alireza", ""], ["Kushagra", "Shrinu", ""], ["Ilyas", "Ihab F.", ""]]}, {"id": "2008.10579", "submitter": "Oscar Leong", "authors": "Paul Hand, Oscar Leong, Vladislav Voroninski", "title": "Compressive Phase Retrieval: Optimal Sample Complexity with Deep\n  Generative Priors", "comments": "62 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.OC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in compressive sensing provided reconstruction algorithms of sparse\nsignals from linear measurements with optimal sample complexity, but natural\nextensions of this methodology to nonlinear inverse problems have been met with\npotentially fundamental sample complexity bottlenecks. In particular, tractable\nalgorithms for compressive phase retrieval with sparsity priors have not been\nable to achieve optimal sample complexity. This has created an open problem in\ncompressive phase retrieval: under generic, phaseless linear measurements, are\nthere tractable reconstruction algorithms that succeed with optimal sample\ncomplexity? Meanwhile, progress in machine learning has led to the development\nof new data-driven signal priors in the form of generative models, which can\noutperform sparsity priors with significantly fewer measurements. In this work,\nwe resolve the open problem in compressive phase retrieval and demonstrate that\ngenerative priors can lead to a fundamental advance by permitting optimal\nsample complexity by a tractable algorithm in this challenging nonlinear\ninverse problem. We additionally provide empirics showing that exploiting\ngenerative priors in phase retrieval can significantly outperform sparsity\npriors. These results provide support for generative priors as a new paradigm\nfor signal recovery in a variety of contexts, both empirically and\ntheoretically. The strengths of this paradigm are that (1) generative priors\ncan represent some classes of natural signals more concisely than sparsity\npriors, (2) generative priors allow for direct optimization over the natural\nsignal manifold, which is intractable under sparsity priors, and (3) the\nresulting non-convex optimization problems with generative priors can admit\nbenign optimization landscapes at optimal sample complexity, perhaps\nsurprisingly, even in cases of nonlinear measurements.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 17:40:04 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Hand", "Paul", ""], ["Leong", "Oscar", ""], ["Voroninski", "Vladislav", ""]]}, {"id": "2008.10581", "submitter": "Aman Sinha", "authors": "Aman Sinha, Matthew O'Kelly, Russ Tedrake, John Duchi", "title": "Neural Bridge Sampling for Evaluating Safety-Critical Autonomous Systems", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based methodologies increasingly find applications in\nsafety-critical domains like autonomous driving and medical robotics. Due to\nthe rare nature of dangerous events, real-world testing is prohibitively\nexpensive and unscalable. In this work, we employ a probabilistic approach to\nsafety evaluation in simulation, where we are concerned with computing the\nprobability of dangerous events. We develop a novel rare-event simulation\nmethod that combines exploration, exploitation, and optimization techniques to\nfind failure modes and estimate their rate of occurrence. We provide rigorous\nguarantees for the performance of our method in terms of both statistical and\ncomputational efficiency. Finally, we demonstrate the efficacy of our approach\non a variety of scenarios, illustrating its usefulness as a tool for rapid\nsensitivity analysis and model comparison that are essential to developing and\ntesting safety-critical autonomous systems.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 17:46:27 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 19:53:33 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Sinha", "Aman", ""], ["O'Kelly", "Matthew", ""], ["Tedrake", "Russ", ""], ["Duchi", "John", ""]]}, {"id": "2008.10587", "submitter": "Siddhesh Khandelwal", "authors": "Siddhesh Khandelwal, William Qi, Jagjeet Singh, Andrew Hartnett, Deva\n  Ramanan", "title": "What-If Motion Prediction for Autonomous Driving", "comments": "16 pages, 6 tables, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting the long-term future motion of road actors is a core challenge to\nthe deployment of safe autonomous vehicles (AVs). Viable solutions must account\nfor both the static geometric context, such as road lanes, and dynamic social\ninteractions arising from multiple actors. While recent deep architectures have\nachieved state-of-the-art performance on distance-based forecasting metrics,\nthese approaches produce forecasts that are predicted without regard to the\nAV's intended motion plan. In contrast, we propose a recurrent graph-based\nattentional approach with interpretable geometric (actor-lane) and social\n(actor-actor) relationships that supports the injection of counterfactual\ngeometric goals and social contexts. Our model can produce diverse predictions\nconditioned on hypothetical or \"what-if\" road lanes and multi-actor\ninteractions. We show that such an approach could be used in the planning loop\nto reason about unobserved causes or unlikely futures that are directly\nrelevant to the AV's intended route.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 17:49:30 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Khandelwal", "Siddhesh", ""], ["Qi", "William", ""], ["Singh", "Jagjeet", ""], ["Hartnett", "Andrew", ""], ["Ramanan", "Deva", ""]]}, {"id": "2008.10592", "submitter": "Benjamin Wilson", "authors": "Benjamin Wilson, Zsolt Kira, James Hays", "title": "3D for Free: Crossmodal Transfer Learning using HD Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D object detection is a core perceptual challenge for robotics and\nautonomous driving. However, the class-taxonomies in modern autonomous driving\ndatasets are significantly smaller than many influential 2D detection datasets.\nIn this work, we address the long-tail problem by leveraging both the large\nclass-taxonomies of modern 2D datasets and the robustness of state-of-the-art\n2D detection methods. We proceed to mine a large, unlabeled dataset of images\nand LiDAR, and estimate 3D object bounding cuboids, seeded from an\noff-the-shelf 2D instance segmentation model. Critically, we constrain this\nill-posed 2D-to-3D mapping by using high-definition maps and object size\npriors. The result of the mining process is 3D cuboids with varying confidence.\nThis mining process is itself a 3D object detector, although not especially\naccurate when evaluated as such. However, we then train a 3D object detection\nmodel on these cuboids, consistent with other recent observations in the deep\nlearning literature, we find that the resulting model is fairly robust to the\nnoisy supervision that our mining process provides. We mine a collection of\n1151 unlabeled, multimodal driving logs from an autonomous vehicle and use the\ndiscovered objects to train a LiDAR-based object detector. We show that\ndetector performance increases as we mine more unlabeled data. With our full,\nunlabeled dataset, our method performs competitively with fully supervised\nmethods, even exceeding the performance for certain object categories, without\nany human 3D annotations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 17:54:51 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Wilson", "Benjamin", ""], ["Kira", "Zsolt", ""], ["Hays", "James", ""]]}, {"id": "2008.10599", "submitter": "William Peebles", "authors": "William Peebles, John Peebles, Jun-Yan Zhu, Alexei Efros, Antonio\n  Torralba", "title": "The Hessian Penalty: A Weak Prior for Unsupervised Disentanglement", "comments": "ECCV 2020 (Spotlight). Code available at\n  https://github.com/wpeebles/hessian_penalty . Project page and videos\n  available at https://www.wpeebles.com/hessian-penalty", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing disentanglement methods for deep generative models rely on\nhand-picked priors and complex encoder-based architectures. In this paper, we\npropose the Hessian Penalty, a simple regularization term that encourages the\nHessian of a generative model with respect to its input to be diagonal. We\nintroduce a model-agnostic, unbiased stochastic approximation of this term\nbased on Hutchinson's estimator to compute it efficiently during training. Our\nmethod can be applied to a wide range of deep generators with just a few lines\nof code. We show that training with the Hessian Penalty often causes\naxis-aligned disentanglement to emerge in latent space when applied to ProGAN\non several datasets. Additionally, we use our regularization term to identify\ninterpretable directions in BigGAN's latent space in an unsupervised fashion.\nFinally, we provide empirical evidence that the Hessian Penalty encourages\nsubstantial shrinkage when applied to over-parameterized latent spaces.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 17:59:56 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Peebles", "William", ""], ["Peebles", "John", ""], ["Zhu", "Jun-Yan", ""], ["Efros", "Alexei", ""], ["Torralba", "Antonio", ""]]}, {"id": "2008.10631", "submitter": "Matthias M\\\"uller", "authors": "Matthias M\\\"uller, Vladlen Koltun", "title": "OpenBot: Turning Smartphones into Robots", "comments": "Accepted at ICRA'21. Documentation and code are available at\n  www.openbot.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current robots are either expensive or make significant compromises on\nsensory richness, computational power, and communication capabilities. We\npropose to leverage smartphones to equip robots with extensive sensor suites,\npowerful computational abilities, state-of-the-art communication channels, and\naccess to a thriving software ecosystem. We design a small electric vehicle\nthat costs $50 and serves as a robot body for standard Android smartphones. We\ndevelop a software stack that allows smartphones to use this body for mobile\noperation and demonstrate that the system is sufficiently powerful to support\nadvanced robotics workloads such as person following and real-time autonomous\nnavigation in unstructured environments. Controlled experiments demonstrate\nthat the presented approach is robust across different smartphones and robot\nbodies. A video of our work is available at\nhttps://www.youtube.com/watch?v=qc8hFLyWDOM\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 18:04:50 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 19:08:00 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["M\u00fcller", "Matthias", ""], ["Koltun", "Vladlen", ""]]}, {"id": "2008.10633", "submitter": "Thomas Carroll", "authors": "Thomas L. Carroll", "title": "Adding Filters to Improve Reservoir Computer Performance", "comments": null, "journal-ref": null, "doi": "10.1016/j.physd.2020.132798", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir computers are a type of neuromorphic computer that may be built a\nan analog system, potentially creating powerful computers that are small, light\nand consume little power. Typically a reservoir computer is build by connecting\ntogether a set of nonlinear nodes into a network; connecting the nonlinear\nnodes may be difficult or expensive, however. This work shows how a reservoir\ncomputer may be expanded by adding functions to its output. The particular\nfunctions described here are linear filters, but other functions are possible.\nThe design and construction of linear filters is well known, and such filters\nmay be easily implemented in hardware such as field programmable gate arrays\n(FPGA's). The effect of adding filters on the reservoir computer performance is\nsimulated for a signal fitting problem, a prediction problem and a signal\nclassification problem.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 18:10:27 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 12:03:17 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Carroll", "Thomas L.", ""]]}, {"id": "2008.10653", "submitter": "Liu Yang", "authors": "Xiaoli Chen, Liu Yang, Jinqiao Duan, George Em Karniadakis", "title": "Solving Inverse Stochastic Problems from Discrete Particle Observations\n  Using the Fokker-Planck Equation and Physics-informed Neural Networks", "comments": "The first two authors contributed equally to this paper.\n  Corresponding author: George Em Karniadakis", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fokker-Planck (FP) equation governing the evolution of the probability\ndensity function (PDF) is applicable to many disciplines but it requires\nspecification of the coefficients for each case, which can be functions of\nspace-time and not just constants, hence requiring the development of a\ndata-driven modeling approach. When the data available is directly on the PDF,\nthen there exist methods for inverse problems that can be employed to infer the\ncoefficients and thus determine the FP equation and subsequently obtain its\nsolution. Herein, we address a more realistic scenario, where only sparse data\nare given on the particles' positions at a few time instants, which are not\nsufficient to accurately construct directly the PDF even at those times from\nexisting methods, e.g., kernel estimation algorithms. To this end, we develop a\ngeneral framework based on physics-informed neural networks (PINNs) that\nintroduces a new loss function using the Kullback-Leibler divergence to connect\nthe stochastic samples with the FP equation, to simultaneously learn the\nequation and infer the multi-dimensional PDF at all times. In particular, we\nconsider two types of inverse problems, type I where the FP equation is known\nbut the initial PDF is unknown, and type II in which, in addition to unknown\ninitial PDF, the drift and diffusion terms are also unknown. In both cases, we\ninvestigate problems with either Brownian or Levy noise or a combination of\nboth. We demonstrate the new PINN framework in detail in the one-dimensional\ncase (1D) but we also provide results for up to 5D demonstrating that we can\ninfer both the FP equation and} dynamics simultaneously at all times with high\naccuracy using only very few discrete observations of the particles.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 18:51:56 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Chen", "Xiaoli", ""], ["Yang", "Liu", ""], ["Duan", "Jinqiao", ""], ["Karniadakis", "George Em", ""]]}, {"id": "2008.10678", "submitter": "Josef Lorenz Rumberger", "authors": "Josef Lorenz Rumberger, Lisa Mais, Dagmar Kainmueller", "title": "Probabilistic Deep Learning for Instance Segmentation", "comments": "ECCV 2020 BioImage Computing Workshop", "journal-ref": null, "doi": "10.1007/978-3-030-66415-2_29", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic convolutional neural networks, which predict distributions of\npredictions instead of point estimates, led to recent advances in many areas of\ncomputer vision, from image reconstruction to semantic segmentation. Besides\nstate of the art benchmark results, these networks made it possible to quantify\nlocal uncertainties in the predictions. These were used in active learning\nframeworks to target the labeling efforts of specialist annotators or to assess\nthe quality of a prediction in a safety-critical environment. However, for\ninstance segmentation problems these methods are not frequently used so far. We\nseek to close this gap by proposing a generic method to obtain model-inherent\nuncertainty estimates within proposal-free instance segmentation models.\nFurthermore, we analyze the quality of the uncertainty estimates with a metric\nadapted from semantic segmentation. We evaluate our method on the BBBC010 C.\\\nelegans dataset, where it yields competitive performance while also predicting\nuncertainty estimates that carry information about object-level inaccuracies\nlike false splits and false merges. We perform a simulation to show the\npotential use of such uncertainty estimates in guided proofreading.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 19:51:48 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 11:38:42 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Rumberger", "Josef Lorenz", ""], ["Mais", "Lisa", ""], ["Kainmueller", "Dagmar", ""]]}, {"id": "2008.10706", "submitter": "Ranjani Srinivasan", "authors": "Ranjani Srinivasan, Jaron Lee, Rohit Bhattacharya, Narges Ahmidi, Ilya\n  Shpitser", "title": "Path Dependent Structural Equation Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal analyses of longitudinal data generally assume that the qualitative\ncausal structure relating variables remains invariant over time. In structured\nsystems that transition between qualitatively different states in discrete time\nsteps, such an approach is deficient on two fronts. First, time-varying\nvariables may have state-specific causal relationships that need to be\ncaptured. Second, an intervention can result in state transitions downstream of\nthe intervention different from those actually observed in the data. In other\nwords, interventions may counterfactually alter the subsequent temporal\nevolution of the system. We introduce a generalization of causal graphical\nmodels, Path Dependent Structural Equation Models (PDSEMs), that can describe\nsuch systems. We show how causal inference may be performed in such models and\nillustrate its use in simulations and data obtained from a septoplasty surgical\nprocedure.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 21:05:04 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 04:35:31 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Srinivasan", "Ranjani", ""], ["Lee", "Jaron", ""], ["Bhattacharya", "Rohit", ""], ["Ahmidi", "Narges", ""], ["Shpitser", "Ilya", ""]]}, {"id": "2008.10707", "submitter": "Yangruibo Ding", "authors": "Yangruibo Ding, Baishakhi Ray, Premkumar Devanbu, Vincent J.\n  Hellendoorn", "title": "Patching as Translation: the Data and the Metaphor", "comments": null, "journal-ref": null, "doi": "10.1145/3324884.3416587", "report-no": null, "categories": "cs.SE cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning models from other fields, like Computational Linguistics,\nhave been transplanted to Software Engineering tasks, often quite successfully.\nYet a transplanted model's initial success at a given task does not necessarily\nmean it is well-suited for the task. In this work, we examine a common example\nof this phenomenon: the conceit that \"software patching is like language\ntranslation\". We demonstrate empirically that there are subtle, but critical\ndistinctions between sequence-to-sequence models and translation model: while\nprogram repair benefits greatly from the former, general modeling architecture,\nit actually suffers from design decisions built into the latter, both in terms\nof translation accuracy and diversity. Given these findings, we demonstrate how\na more principled approach to model design, based on our empirical findings and\ngeneral knowledge of software development, can lead to better solutions. Our\nfindings also lend strong support to the recent trend towards synthesizing\nedits of code conditional on the buggy context, to repair bugs. We implement\nsuch models ourselves as \"proof-of-concept\" tools and empirically confirm that\nthey behave in a fundamentally different, more effective way than the studied\ntranslation-based architectures. Overall, our results demonstrate the merit of\nstudying the intricacies of machine learned models in software engineering: not\nonly can this help elucidate potential issues that may be overshadowed by\nincreases in accuracy; it can also help innovate on these models to raise the\nstate-of-the-art further. We will publicly release our replication data and\nmaterials at https://github.com/ARiSE-Lab/Patch-as-translation.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 21:05:27 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 02:33:19 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Ding", "Yangruibo", ""], ["Ray", "Baishakhi", ""], ["Devanbu", "Premkumar", ""], ["Hellendoorn", "Vincent J.", ""]]}, {"id": "2008.10713", "submitter": "Shuai Zheng", "authors": "Chi Zhang, Philip Odonkor, Shuai Zheng, Hamed Khorasgani, Susumu\n  Serita, Chetan Gupta", "title": "Dynamic Dispatching for Large-Scale Heterogeneous Fleet via Multi-agent\n  Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic dispatching is one of the core problems for operation optimization in\ntraditional industries such as mining, as it is about how to smartly allocate\nthe right resources to the right place at the right time. Conventionally, the\nindustry relies on heuristics or even human intuitions which are often\nshort-sighted and sub-optimal solutions. Leveraging the power of AI and\nInternet of Things (IoT), data-driven automation is reshaping this area.\nHowever, facing its own challenges such as large-scale and heterogenous trucks\nrunning in a highly dynamic environment, it can barely adopt methods developed\nin other domains (e.g., ride-sharing). In this paper, we propose a novel Deep\nReinforcement Learning approach to solve the dynamic dispatching problem in\nmining. We first develop an event-based mining simulator with parameters\ncalibrated in real mines. Then we propose an experience-sharing Deep Q Network\nwith a novel abstract state/action representation to learn memories from\nheterogeneous agents altogether and realizes learning in a centralized way. We\ndemonstrate that the proposed methods significantly outperform the most widely\nadopted approaches in the industry by $5.56\\%$ in terms of productivity. The\nproposed approach has great potential in a broader range of industries (e.g.,\nmanufacturing, logistics) which have a large-scale of heterogenous equipment\nworking in a highly dynamic environment, as a general framework for dynamic\nresource allocation.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 21:29:56 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Zhang", "Chi", ""], ["Odonkor", "Philip", ""], ["Zheng", "Shuai", ""], ["Khorasgani", "Hamed", ""], ["Serita", "Susumu", ""], ["Gupta", "Chetan", ""]]}, {"id": "2008.10719", "submitter": "Tianchang Shen", "authors": "Tianchang Shen, Jun Gao, Amlan Kar, Sanja Fidler", "title": "Interactive Annotation of 3D Object Geometry using 2D Scribbles", "comments": "Accepted to ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring detailed 3D geometry of the scene is crucial for robotics\napplications, simulation, and 3D content creation. However, such information is\nhard to obtain, and thus very few datasets support it. In this paper, we\npropose an interactive framework for annotating 3D object geometry from both\npoint cloud data and RGB imagery. The key idea behind our approach is to\nexploit strong priors that humans have about the 3D world in order to\ninteractively annotate complete 3D shapes. Our framework targets naive users\nwithout artistic or graphics expertise. We introduce two simple-to-use\ninteraction modules. First, we make an automatic guess of the 3D shape and\nallow the user to provide feedback about large errors by drawing scribbles in\ndesired 2D views. Next, we aim to correct minor errors, in which users drag and\ndrop mesh vertices, assisted by a neural interactive module implemented as a\nGraph Convolutional Network. Experimentally, we show that only a few user\ninteractions are needed to produce good quality 3D shapes on popular benchmarks\nsuch as ShapeNet, Pix3D and ScanNet. We implement our framework as a web\nservice and conduct a user study, where we show that user annotated data using\nour method effectively facilitates real-world learning tasks. Web service:\nhttp://www.cs.toronto.edu/~shenti11/scribble3d.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 21:51:29 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 02:43:19 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Shen", "Tianchang", ""], ["Gao", "Jun", ""], ["Kar", "Amlan", ""], ["Fidler", "Sanja", ""]]}, {"id": "2008.10726", "submitter": "Kyle Ross", "authors": "Kyle Ross, Paul Hungler, Ali Etemad", "title": "Unsupervised Multi-Modal Representation Learning for Affective Computing\n  with Multi-Corpus Wearable Data", "comments": "16 pages,5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With recent developments in smart technologies, there has been a growing\nfocus on the use of artificial intelligence and machine learning for affective\ncomputing to further enhance the user experience through emotion recognition.\nTypically, machine learning models used for affective computing are trained\nusing manually extracted features from biological signals. Such features may\nnot generalize well for large datasets and may be sub-optimal in capturing the\ninformation from the raw input data. One approach to address this issue is to\nuse fully supervised deep learning methods to learn latent representations of\nthe biosignals. However, this method requires human supervision to label the\ndata, which may be unavailable or difficult to obtain. In this work we propose\nan unsupervised framework reduce the reliance on human supervision. The\nproposed framework utilizes two stacked convolutional autoencoders to learn\nlatent representations from wearable electrocardiogram (ECG) and electrodermal\nactivity (EDA) signals. These representations are utilized within a random\nforest model for binary arousal classification. This approach reduces human\nsupervision and enables the aggregation of datasets allowing for higher\ngeneralizability. To validate this framework, an aggregated dataset comprised\nof the AMIGOS, ASCERTAIN, CLEAS, and MAHNOB-HCI datasets is created. The\nresults of our proposed method are compared with using convolutional neural\nnetworks, as well as methods that employ manual extraction of hand-crafted\nfeatures. The methodology used for fusing the two modalities is also\ninvestigated. Lastly, we show that our method outperforms current\nstate-of-the-art results that have performed arousal detection on the same\ndatasets using ECG and EDA biosignals. The results show the wide-spread\napplicability for stacked convolutional autoencoders to be used with machine\nlearning for affective computing.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 22:01:55 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Ross", "Kyle", ""], ["Hungler", "Paul", ""], ["Etemad", "Ali", ""]]}, {"id": "2008.10736", "submitter": "Ovi Paul", "authors": "Abu Bakar Siddik Nayem, Anis Sarker, Ovi Paul, Amin Ali, Md. Ashraful\n  Amin and AKM Mahbubur Rahman", "title": "LULC Segmentation of RGB Satellite Image Using FCN-8", "comments": "Accepted paper at 3rd SLAAI-International Conference on Artificial\n  Intelligence; 13 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents use of Fully Convolutional Network (FCN-8) for semantic\nsegmentation of high-resolution RGB earth surface satel-lite images into land\nuse land cover (LULC) categories. Specically, we propose a non-overlapping\ngrid-based approach to train a Fully Convo-lutional Network (FCN-8) with vgg-16\nweights to segment satellite im-ages into four (forest, built-up, farmland and\nwater) classes. The FCN-8 semantically projects the discriminating features in\nlower resolution learned by the encoder onto the pixel space in higher\nresolution to get a dense classi cation. We experimented the proposed system\nwith Gaofen-2 image dataset, that contains 150 images of over 60 di erent\ncities in china. For comparison, we used available ground-truth along with\nimages segmented using a widely used commeriial GIS software called\neCogni-tion. With the proposed non-overlapping grid-based approach, FCN-8\nobtains signi cantly improved performance, than the eCognition soft-ware. Our\nmodel achieves average accuracy of 91.0% and average Inter-section over Union\n(IoU) of 0.84. In contrast, eCognitions average accu-racy is 74.0% and IoU is\n0.60. This paper also reports a detail analysis of errors occurred at the LULC\nboundary.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 22:32:30 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Nayem", "Abu Bakar Siddik", ""], ["Sarker", "Anis", ""], ["Paul", "Ovi", ""], ["Ali", "Amin", ""], ["Amin", "Md. Ashraful", ""], ["Rahman", "AKM Mahbubur", ""]]}, {"id": "2008.10740", "submitter": "Steven Brunton", "authors": "Steven L. Brunton, J. Nathan Kutz, Krithika Manohar, Aleksandr Y.\n  Aravkin, Kristi Morgansen, Jennifer Klemisch, Nicholas Goebel, James\n  Buttrick, Jeffrey Poskin, Agnes Blom-Schieber, Thomas Hogan, Darren McDonald", "title": "Data-Driven Aerospace Engineering: Reframing the Industry with Machine\n  Learning", "comments": "35 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data science, and machine learning in particular, is rapidly transforming the\nscientific and industrial landscapes. The aerospace industry is poised to\ncapitalize on big data and machine learning, which excels at solving the types\nof multi-objective, constrained optimization problems that arise in aircraft\ndesign and manufacturing. Indeed, emerging methods in machine learning may be\nthought of as data-driven optimization techniques that are ideal for\nhigh-dimensional, non-convex, and constrained, multi-objective optimization\nproblems, and that improve with increasing volumes of data. In this review, we\nwill explore the opportunities and challenges of integrating data-driven\nscience and engineering into the aerospace industry. Importantly, we will focus\non the critical need for interpretable, generalizeable, explainable, and\ncertifiable machine learning techniques for safety-critical applications. This\nreview will include a retrospective, an assessment of the current\nstate-of-the-art, and a roadmap looking forward. Recent algorithmic and\ntechnological trends will be explored in the context of critical challenges in\naerospace design, manufacturing, verification, validation, and services. In\naddition, we will explore this landscape through several case studies in the\naerospace industry. This document is the result of close collaboration between\nUW and Boeing to summarize past efforts and outline future opportunities.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 22:40:26 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Brunton", "Steven L.", ""], ["Kutz", "J. Nathan", ""], ["Manohar", "Krithika", ""], ["Aravkin", "Aleksandr Y.", ""], ["Morgansen", "Kristi", ""], ["Klemisch", "Jennifer", ""], ["Goebel", "Nicholas", ""], ["Buttrick", "James", ""], ["Poskin", "Jeffrey", ""], ["Blom-Schieber", "Agnes", ""], ["Hogan", "Thomas", ""], ["McDonald", "Darren", ""]]}, {"id": "2008.10741", "submitter": "Arjun Kodialam", "authors": "Arjun Kodialam", "title": "Efficient Detection Of Infected Individuals using Two Stage Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group testing is an efficient method for testing a large population to detect\ninfected individuals. In this paper, we consider an efficient adaptive two\nstage group testing scheme. Using a straightforward analysis, we characterize\nthe efficiency of several two stage group testing algorithms. We determine how\nto pick the parameters of the tests optimally for three schemes with different\ntypes of randomization, and show that the performance of two stage testing\ndepends on the type of randomization employed. Seemingly similar randomization\nprocedures lead to different expected number of tests to detect all infected\nindividuals, we determine what kinds of randomization are necessary to achieve\noptimal performance. We further show that in the optimal setting, our testing\nscheme is robust to errors in the input parameters.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 23:05:10 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Kodialam", "Arjun", ""]]}, {"id": "2008.10748", "submitter": "Marco Comuzzi", "authors": "Bayu Adhi Tama and Marco Comuzzi and Jonghyeon Ko", "title": "An empirical investigation of different classifiers, encoding and\n  ensemble schemes for next event prediction using business process event logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing need for empirical benchmarks that support researchers and\npractitioners in selecting the best machine learning technique for given\nprediction tasks. In this paper, we consider the next event prediction task in\nbusiness process predictive monitoring and we extend our previously published\nbenchmark by studying the impact on the performance of different encoding\nwindows and of using ensemble schemes. The choice of whether to use ensembles\nand which scheme to use often depends on the type of data and classification\ntask. While there is a general understanding that ensembles perform well in\npredictive monitoring of business processes, next event prediction is a task\nfor which no other benchmarks involving ensembles are available. The proposed\nbenchmark helps researchers to select a high performing individual classifier\nor ensemble scheme given the variability at the case level of the event log\nunder consideration. Experimental results show that choosing an optimal number\nof events for feature encoding is challenging, resulting in the need to\nconsider each event log individually when selecting an optimal value. Ensemble\nschemes improve the performance of low performing classifiers in this task,\nsuch as SVM, whereas high performing classifiers, such as tree-based\nclassifiers, are not better off when ensemble schemes are considered.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 23:44:06 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Tama", "Bayu Adhi", ""], ["Comuzzi", "Marco", ""], ["Ko", "Jonghyeon", ""]]}, {"id": "2008.10749", "submitter": "Federico Albanese", "authors": "Federico Albanese, Leandro Lombardi, Esteban Feuerstein, Pablo\n  Balenzuela", "title": "Predicting Shifting Individuals Using Text Mining and Graph Machine\n  Learning on Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The formation of majorities in public discussions often depends on\nindividuals who shift their opinion over time. The detection and\ncharacterization of these type of individuals is therefore extremely important\nfor political analysis of social networks. In this paper, we study changes in\nindividual's affiliations on Twitter using natural language processing\ntechniques and graph machine learning algorithms. In particular, we collected 9\nmillion Twitter messages from 1.5 million users and constructed the retweet\nnetworks. We identified communities with explicit political orientation and\ntopics of discussion associated to them which provide the topological\nrepresentation of the political map on Twitter in the analyzed periods. With\nthat data, we present a machine learning framework for social media users\nclassification which efficiently detects \"shifting users\" (i.e. users that may\nchange their affiliation over time). Moreover, this machine learning framework\nallows us to identify not only which topics are more persuasive (using low\ndimensional topic embedding), but also which individuals are more likely to\nchange their affiliation given their topological properties in a Twitter graph.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 23:44:51 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Albanese", "Federico", ""], ["Lombardi", "Leandro", ""], ["Feuerstein", "Esteban", ""], ["Balenzuela", "Pablo", ""]]}, {"id": "2008.10753", "submitter": "Yashesh Dhebar", "authors": "Yashesh Dhebar, Sparsh Gupta and Kalyanmoy Deb", "title": "Evaluating Nonlinear Decision Trees for Binary Classification Tasks with\n  Other Existing Methods", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification of datasets into two or more distinct classes is an important\nmachine learning task. Many methods are able to classify binary classification\ntasks with a very high accuracy on test data, but cannot provide any easily\ninterpretable explanation for users to have a deeper understanding of reasons\nfor the split of data into two classes. In this paper, we highlight and\nevaluate a recently proposed nonlinear decision tree approach with a number of\ncommonly used classification methods on a number of datasets involving a few to\na large number of features. The study reveals key issues such as effect of\nclassification on the method's parameter values, complexity of the classifier\nversus achieved accuracy, and interpretability of resulting classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 00:00:23 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Dhebar", "Yashesh", ""], ["Gupta", "Sparsh", ""], ["Deb", "Kalyanmoy", ""]]}, {"id": "2008.10755", "submitter": "Siawpeng Er", "authors": "David Munzer, Siawpeng Er, Minshuo Chen, Yan Li, Naga S. Mannem, Tuo\n  Zhao, Hua Wang", "title": "Residual Network Based Direct Synthesis of EM Structures: A Study on\n  One-to-One Transformers", "comments": "IEEE Radio Frequency Integrated Circuits Symposium (RFIC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SP eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose using machine learning models for the direct synthesis of on-chip\nelectromagnetic (EM) passive structures to enable rapid or even automated\ndesigns and optimizations of RF/mm-Wave circuits. As a proof of concept, we\ndemonstrate the direct synthesis of a 1:1 transformer on a 45nm SOI process\nusing our proposed neural network model. Using pre-existing transformer\ns-parameter files and their geometric design training samples, the model\npredicts target geometric designs.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 00:20:59 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Munzer", "David", ""], ["Er", "Siawpeng", ""], ["Chen", "Minshuo", ""], ["Li", "Yan", ""], ["Mannem", "Naga S.", ""], ["Zhao", "Tuo", ""], ["Wang", "Hua", ""]]}, {"id": "2008.10766", "submitter": "Dong Lao", "authors": "Dong Lao, Peihao Zhu, Peter Wonka, Ganesh Sundaramoorthi", "title": "Channel-Directed Gradients for Optimization of Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce optimization methods for convolutional neural networks that can\nbe used to improve existing gradient-based optimization in terms of\ngeneralization error. The method requires only simple processing of existing\nstochastic gradients, can be used in conjunction with any optimizer, and has\nonly a linear overhead (in the number of parameters) compared to computation of\nthe stochastic gradient. The method works by computing the gradient of the loss\nfunction with respect to output-channel directed re-weighted L2 or Sobolev\nmetrics, which has the effect of smoothing components of the gradient across a\ncertain direction of the parameter tensor. We show that defining the gradients\nalong the output channel direction leads to a performance boost, while other\ndirections can be detrimental. We present the continuum theory of such\ngradients, its discretization, and application to deep networks. Experiments on\nbenchmark datasets, several networks and baseline optimizers show that\noptimizers can be improved in generalization error by simply computing the\nstochastic gradient with respect to output-channel directed metrics.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 00:44:09 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Lao", "Dong", ""], ["Zhu", "Peihao", ""], ["Wonka", "Peter", ""], ["Sundaramoorthi", "Ganesh", ""]]}, {"id": "2008.10769", "submitter": "Chiwoo Park", "authors": "Chiwoo Park, David J. Borth, Nicholas S. Wilson and Chad N. Hunter", "title": "Variable selection for Gaussian process regression through a sparse\n  projection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new variable selection approach integrated with\nGaussian process (GP) regression. We consider a sparse projection of input\nvariables and a general stationary covariance model that depends on the\nEuclidean distance between the projected features. The sparse projection matrix\nis considered as an unknown parameter. We propose a forward stagewise approach\nwith embedded gradient descent steps to co-optimize the parameter with other\ncovariance parameters based on the maximization of a non-convex marginal\nlikelihood function with a concave sparsity penalty, and some convergence\nproperties of the algorithm are provided. The proposed model covers a broader\nclass of stationary covariance functions than the existing automatic relevance\ndetermination approaches, and the solution approach is more computationally\nfeasible than the existing MCMC sampling procedures for the automatic relevance\nparameter estimation with a sparsity prior. The approach is evaluated for a\nlarge number of simulated scenarios. The choice of tuning parameters and the\naccuracy of the parameter estimation are evaluated with the simulation study.\nIn the comparison to some chosen benchmark approaches, the proposed approach\nhas provided a better accuracy in the variable selection. It is applied to an\nimportant problem of identifying environmental factors that affect an\natmospheric corrosion of metal alloys.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 01:06:10 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Park", "Chiwoo", ""], ["Borth", "David J.", ""], ["Wilson", "Nicholas S.", ""], ["Hunter", "Chad N.", ""]]}, {"id": "2008.10774", "submitter": "Saeed Anwar", "authors": "Saeed Anwar, Muhammad Tahir, Chongyi Li, Ajmal Mian, Fahad Shahbaz\n  Khan, Abdul Wahab Muzaffar", "title": "Image Colorization: A Survey and Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Image colorization is an essential image processing and computer vision\nbranch to colorize images and videos. Recently, deep learning techniques\nprogressed notably for image colorization. This article presents a\ncomprehensive survey of recent state-of-the-art colorization using deep\nlearning algorithms, describing their fundamental block architectures in terms\nof skip connections, input etc. as well as optimizers, loss functions, training\nprotocols, and training data etc. Generally, we can roughly categorize the\nexisting colorization techniques into seven classes. Besides, we also provide\nsome additional essential issues, such as benchmark datasets and evaluation\nmetrics. We also introduce a new dataset specific to colorization and perform\nan experimental evaluation of the publicly available methods. In the last\nsection, we discuss the limitations, possible solutions, and future research\ndirections of the rapidly evolving topic of deep image colorization that the\ncommunity should further address. Dataset and Codes for evaluation will be\npublicly available at https://github.com/saeed-anwar/ColorSurvey\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 01:22:52 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 11:44:35 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Anwar", "Saeed", ""], ["Tahir", "Muhammad", ""], ["Li", "Chongyi", ""], ["Mian", "Ajmal", ""], ["Khan", "Fahad Shahbaz", ""], ["Muzaffar", "Abdul Wahab", ""]]}, {"id": "2008.10779", "submitter": "William Cheung", "authors": "William Cheung and Sudip Vhaduri", "title": "Continuous Authentication of Wearable Device Users from Heart Rate,\n  Gait, and Breathing Data", "comments": "6 pages, 3 figures, Accepted at IEEE Biomedical Robotics &\n  Biomechatronics (BioRob)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The security of private information is becoming the bedrock of an\nincreasingly digitized society. While the users are flooded with passwords and\nPINs, these gold-standard explicit authentications are becoming less popular\nand valuable. Recent biometric-based authentication methods, such as facial or\nfinger recognition, are getting popular due to their higher accuracy. However,\nthese hard-biometric-based systems require dedicated devices with powerful\nsensors and authentication models, which are often limited to most of the\nmarket wearables. Still, market wearables are collecting various private\ninformation of a user and are becoming an integral part of life: accessing\ncars, bank accounts, etc. Therefore, time demands a burden-free implicit\nauthentication mechanism for wearables using the less-informative\nsoft-biometric data that are easily obtainable from modern market wearables. In\nthis work, we present a context-dependent soft-biometric-based authentication\nsystem for wearables devices using heart rate, gait, and breathing audio\nsignals. From our detailed analysis using the \"leave-one-out\" validation, we\nfind that a lighter $k$-Nearest Neighbor ($k$-NN) model with $k = 2$ can obtain\nan average accuracy of $0.93 \\pm 0.06$, $F_1$ score $0.93 \\pm 0.03$, and {\\em\nfalse positive rate} (FPR) below $0.08$ at 50\\% level of confidence, which\nshows the promise of this work.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 01:55:07 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Cheung", "William", ""], ["Vhaduri", "Sudip", ""]]}, {"id": "2008.10781", "submitter": "Burak Aksar", "authors": "Emre Ates, Burak Aksar, Vitus J. Leung, Ayse K. Coskun", "title": "Counterfactual Explanations for Machine Learning on Multivariate Time\n  Series Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Applying machine learning (ML) on multivariate time series data has growing\npopularity in many application domains, including in computer system\nmanagement. For example, recent high performance computing (HPC) research\nproposes a variety of ML frameworks that use system telemetry data in the form\nof multivariate time series so as to detect performance variations, perform\nintelligent scheduling or node allocation, and improve system security. Common\nbarriers for adoption for these ML frameworks include the lack of user trust\nand the difficulty of debugging. These barriers need to be overcome to enable\nthe widespread adoption of ML frameworks in production systems. To address this\nchallenge, this paper proposes a novel explainability technique for providing\ncounterfactual explanations for supervised ML frameworks that use multivariate\ntime series data. The proposed method outperforms state-of-the-art\nexplainability methods on several different ML frameworks and data sets in\nmetrics such as faithfulness and robustness. The paper also demonstrates how\nthe proposed method can be used to debug ML frameworks and gain a better\nunderstanding of HPC system telemetry data.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 02:04:59 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Ates", "Emre", ""], ["Aksar", "Burak", ""], ["Leung", "Vitus J.", ""], ["Coskun", "Ayse K.", ""]]}, {"id": "2008.10786", "submitter": "Chiwoo Park", "authors": "Chiwoo Park, Sang Do Noh and Anuj Srivastava", "title": "Data Science for Motion and Time Analysis with Modern Motion Sensor Data", "comments": "Keywords: motion and time study, motion sensors, Riemannian manifold,\n  probability distribution on manifold, temporal evolution of probability\n  distributions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The motion-and-time analysis has been a popular research topic in operations\nresearch, especially for analyzing work performances in manufacturing and\nservice operations. It is regaining attention as continuous improvement tools\nfor lean manufacturing and smart factory. This paper develops a framework for\ndata-driven analysis of work motions and studies their correlations to work\nspeeds or execution rates, using data collected from modern motion sensors. The\npast analyses largely relied on manual steps involving time-consuming\nstop-watching and video-taping, followed by manual data analysis. While modern\nsensing devices have automated the collection of motion data, the motion\nanalytics that transform the new data into knowledge are largely\nunderdeveloped. Unsolved technical questions include: How the motion and time\ninformation can be extracted from the motion sensor data, how work motions and\nexecution rates are statistically modeled and compared, and what are the\nstatistical correlations of motions to the rates? In this paper, we develop a\nnovel mathematical framework for motion and time analysis with motion sensor\ndata, by defining new mathematical representation spaces of human motions and\nexecution rates and by developing statistical tools on these new spaces. This\nmethodological research is demonstrated using five use cases applied to\nmanufacturing motion data.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 02:33:33 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Park", "Chiwoo", ""], ["Noh", "Sang Do", ""], ["Srivastava", "Anuj", ""]]}, {"id": "2008.10789", "submitter": "A H M Jakaria", "authors": "A H M Jakaria, Md Mosharaf Hossain, Mohammad Ashiqur Rahman", "title": "Smart Weather Forecasting Using Machine Learning:A Case Study in\n  Tennessee", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, weather predictions are performed with the help of large\ncomplex models of physics, which utilize different atmospheric conditions over\na long period of time. These conditions are often unstable because of\nperturbations of the weather system, causing the models to provide inaccurate\nforecasts. The models are generally run on hundreds of nodes in a large High\nPerformance Computing (HPC) environment which consumes a large amount of\nenergy. In this paper, we present a weather prediction technique that utilizes\nhistorical data from multiple weather stations to train simple machine learning\nmodels, which can provide usable forecasts about certain weather conditions for\nthe near future within a very short period of time. The models can be run on\nmuch less resource intensive environments. The evaluation results show that the\naccuracy of the models is good enough to be used alongside the current\nstate-of-the-art techniques. Furthermore, we show that it is beneficial to\nleverage the weather station data from multiple neighboring areas over the data\nof only the area for which weather forecasting is being performed.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 02:41:32 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Jakaria", "A H M", ""], ["Hossain", "Md Mosharaf", ""], ["Rahman", "Mohammad Ashiqur", ""]]}, {"id": "2008.10797", "submitter": "Susan Wei", "authors": "Susan Wei, Marc Niethammer", "title": "The Fairness-Accuracy Pareto Front", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mitigating bias in machine learning is a challenging task, due in large part\nto the presence of competing objectives. Namely, a fair algorithm often comes\nat the cost of lower predictive accuracy, and vice versa, a highly predictive\nalgorithm may be one that incurs high bias. This work presents a methodology\nfor estimating the fairness-accuracy Pareto front of a fully-connected\nfeedforward neural network, for any accuracy measure and any fairness measure.\nOur experiments firstly reveal that for training data already exhibiting\ndisparities, a newly introduced causal notion of fairness may be capable of\ntraversing a greater part of the fairness-accuracy space, relative to more\nstandard measures such as demographic parity and conditional parity. The\nexperiments also reveal that tools from multi-objective optimisation are\ncrucial in efficiently estimating the Pareto front (i.e., by finding more\nnon-dominated points), relative to other sensible but ad-hoc approaches.\nFinally, the work serves to highlight possible synergy between deep learning\nand multi-objective optimisation. Given that deep learning is increasingly\ndeployed in real-world decision making, the Pareto front can provide a formal\nway to reason about inherent conflicts.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 03:32:15 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Wei", "Susan", ""], ["Niethammer", "Marc", ""]]}, {"id": "2008.10805", "submitter": "Kartikeya Bhardwaj", "authors": "Kartikeya Bhardwaj, Wei Chen, Radu Marculescu", "title": "New Directions in Distributed Deep Learning: Bringing the Network at\n  Forefront of IoT Design", "comments": "This preprint is for personal use only. The official article will\n  appear in proceedings of Design Automation Conference (DAC), 2020. This work\n  was presented at the DAC 2020 special session on Edge-to-Cloud Neural\n  Networks for Machine Learning Applications in Future IoT Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we first highlight three major challenges to large-scale\nadoption of deep learning at the edge: (i) Hardware-constrained IoT devices,\n(ii) Data security and privacy in the IoT era, and (iii) Lack of network-aware\ndeep learning algorithms for distributed inference across multiple IoT devices.\nWe then provide a unified view targeting three research directions that\nnaturally emerge from the above challenges: (1) Federated learning for training\ndeep networks, (2) Data-independent deployment of learning algorithms, and (3)\nCommunication-aware distributed inference. We believe that the above research\ndirections need a network-centric approach to enable the edge intelligence and,\ntherefore, fully exploit the true potential of IoT.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 04:08:10 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Bhardwaj", "Kartikeya", ""], ["Chen", "Wei", ""], ["Marculescu", "Radu", ""]]}, {"id": "2008.10806", "submitter": "Lingwei Zhu", "authors": "Lingwei Zhu and Takamitsu Matsubara", "title": "Ensuring Monotonic Policy Improvement in Entropy-regularized Value-based\n  Reinforcement Learning", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to establish an entropy-regularized value-based reinforcement\nlearning method that can ensure the monotonic improvement of policies at each\npolicy update. Unlike previously proposed lower-bounds on policy improvement in\ngeneral infinite-horizon MDPs, we derive an entropy-regularization aware lower\nbound. Since our bound only requires the expected policy advantage function to\nbe estimated, it is scalable to large-scale (continuous) state-space problems.\nWe propose a novel reinforcement learning algorithm that exploits this\nlower-bound as a criterion for adjusting the degree of a policy update for\nalleviating policy oscillation. We demonstrate the effectiveness of our\napproach in both discrete-state maze and continuous-state inverted pendulum\ntasks using a linear function approximator for value estimation.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 04:09:18 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Zhu", "Lingwei", ""], ["Matsubara", "Takamitsu", ""]]}, {"id": "2008.10838", "submitter": "Yan Kang", "authors": "Yan Kang, Yang Liu, Tianjian Chen", "title": "FedMVT: Semi-supervised Vertical Federated Learning with MultiView\n  Training", "comments": "International Workshop on Federated Learning for User Privacy and\n  Data Confidentiality in Conjunction with IJCAI 2020 (FL-IJCAI'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning allows many parties to collaboratively build a model\nwithout exposing data. Particularly, vertical federated learning (VFL) enables\nparties to build a robust shared machine learning model based upon distributed\nfeatures about the same samples. However, VFL requires all parties to share a\nsufficient amount of overlapping samples. In reality, the set of overlapping\nsamples may be small, leaving the majority of the non-overlapping data\nunutilized. In this paper, we propose Federated Multi-View Training (FedMVT), a\nsemi-supervised learning approach that improves the performance of VFL with\nlimited overlapping samples. FedMVT estimates representations for missing\nfeatures and predicts pseudo-labels for unlabeled samples to expand training\nset, and trains three classifiers jointly based upon different views of the\ninput to improve model's representation learning. FedMVT does not require\nparties to share their original data and model parameters, thus preserving data\nprivacy. We conduct experiments on the NUS-WIDE and the CIFAR10. The\nexperimental results demonstrate that FedMVT significantly outperforms vanilla\nVFL that only utilizes overlapping samples, and improves the performance of the\nlocal model in the party that owns labels.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 06:20:31 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Kang", "Yan", ""], ["Liu", "Yang", ""], ["Chen", "Tianjian", ""]]}, {"id": "2008.10845", "submitter": "Dilruk Perera", "authors": "Dilruk Perera and Roger Zimmermann", "title": "CnGAN: Generative Adversarial Networks for Cross-network user preference\n  generation for non-overlapped users", "comments": null, "journal-ref": "The World Wide Web Conference, 2019 (WWW'19)", "doi": "10.1145/3308558.3313733", "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major drawback of cross-network recommender solutions is that they can only\nbe applied to users that are overlapped across networks. Thus, the\nnon-overlapped users, which form the majority of users are ignored. As a\nsolution, we propose CnGAN, a novel multi-task learning based,\nencoder-GAN-recommender architecture. The proposed model synthetically\ngenerates source network user preferences for non-overlapped users by learning\nthe mapping from target to source network preference manifolds. The resultant\nuser preferences are used in a Siamese network based neural recommender\narchitecture. Furthermore, we propose a novel user based pairwise loss function\nfor recommendations using implicit interactions to better guide the generation\nprocess in the multi-task learning environment.We illustrate our solution by\ngenerating user preferences on the Twitter source network for recommendations\non the YouTube target network. Extensive experiments show that the generated\npreferences can be used to improve recommendations for non-overlapped users.\nThe resultant recommendations achieve superior performance compared to the\nstate-of-the-art cross-network recommender solutions in terms of accuracy,\nnovelty and diversity.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 06:47:44 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Perera", "Dilruk", ""], ["Zimmermann", "Roger", ""]]}, {"id": "2008.10846", "submitter": "Ahmet M. Elbir", "authors": "Ahmet M. Elbir and Sinem Coleri", "title": "Federated Learning for Channel Estimation in Conventional and\n  IRS-Assisted Massive MIMO", "comments": "13 pages. submitted to IEEE journals", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) has attracted a great research interest for the\nproblems in the physical layer of wireless communications, such as channel\nestimation, thanks to its low computational complexity and robustness against\nimperfect channel data. Channel estimation via ML requires model training on a\ndataset, which usually includes the received pilot signals as input and channel\ndata as output. In previous works, model training is mostly done in a\ncentralized manner, where the whole training dataset is collected from the\nusers at the base station (BS). This approach introduces huge transmission\noverhead for data collection from the users. In this paper, to address this\nchallenge, we propose a federated learning (FL) framework for channel\nestimation. We design a convolutional neural network (CNN) trained on the local\ndatasets of the users without sending them to the BS. We develop FL-based\nchannel estimation schemes for both conventional and IRS (intelligent\nreflecting surface) assisted massive MIMO (multiple-input multiple-output)\nsystems, where a single CNN is trained for two different datasets for both\nscenarios. Even if the IRS-assisted massive MIMO includes two different\nchannels, namely the direct and cascaded channels, their estimation is\nperformed with a single CNN, without using multiple CNNs for each task. Via\nnumerical simulations, we evaluate the performance for noisy and quantized\nmodel transmission and show that the proposed approach provides approximately\n16 times lower transmission overhead than the centralized learning (CL)\nschemes, while maintaining satisfactory channel estimation performance close to\nCL. Furthermore, the proposed CNN architecture exhibits lower estimation error\nthan the state-of-the-art ML-based channel estimation schemes.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 06:51:18 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Elbir", "Ahmet M.", ""], ["Coleri", "Sinem", ""]]}, {"id": "2008.10847", "submitter": "Tianyi Chen", "authors": "Tianyi Chen, Yuejiao Sun, Wotao Yin", "title": "Solving Stochastic Compositional Optimization is Nearly as Easy as\n  Solving Stochastic Optimization", "comments": "Accepted in IEEE Transactions on Signal Processing. The short version\n  of this paper has been awarded the IEEE ICASSP Best Student Paper Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic compositional optimization generalizes classic (non-compositional)\nstochastic optimization to the minimization of compositions of functions. Each\ncomposition may introduce an additional expectation. The series of expectations\nmay be nested. Stochastic compositional optimization is gaining popularity in\napplications such as reinforcement learning and meta learning. This paper\npresents a new Stochastically Corrected Stochastic Compositional gradient\nmethod (SCSC). SCSC runs in a single-time scale with a single loop, uses a\nfixed batch size, and guarantees to converge at the same rate as the stochastic\ngradient descent (SGD) method for non-compositional stochastic optimization.\nThis is achieved by making a careful improvement to a popular stochastic\ncompositional gradient method. It is easy to apply SGD-improvement techniques\nto accelerate SCSC. This helps SCSC achieve state-of-the-art performance for\nstochastic compositional optimization. In particular, we apply Adam to SCSC,\nand the exhibited rate of convergence matches that of the original Adam on\nnon-compositional stochastic optimization. We test SCSC using the portfolio\nmanagement and model-agnostic meta-learning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 06:54:00 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 04:54:59 GMT"}, {"version": "v3", "created": "Fri, 18 Jun 2021 04:56:36 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Chen", "Tianyi", ""], ["Sun", "Yuejiao", ""], ["Yin", "Wotao", ""]]}, {"id": "2008.10849", "submitter": "Dilruk Perera", "authors": "Dilruk Perera and Roger Zimmermann", "title": "LSTM Networks for Online Cross-Network Recommendations", "comments": null, "journal-ref": "International Joint Conference on Artificial Intelligence, 2018\n  (IJCAI-18)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-network recommender systems use auxiliary information from multiple\nsource networks to create holistic user profiles and improve recommendations in\na target network. However, we find two major limitations in existing\ncross-network solutions that reduce overall recommender performance. Existing\nmodels (1) fail to capture complex non-linear relationships in user\ninteractions, and (2) are designed for offline settings hence, not updated\nonline with incoming interactions to capture the dynamics in the recommender\nenvironment. We propose a novel multi-layered Long Short-Term Memory (LSTM)\nnetwork based online solution to mitigate these issues. The proposed model\ncontains three main extensions to the standard LSTM: First, an attention gated\nmechanism to capture long-term user preference changes. Second, a higher order\ninteraction layer to alleviate data sparsity. Third, time aware LSTM cell gates\nto capture irregular time intervals between user interactions. We illustrate\nour solution using auxiliary information from Twitter and Google Plus to\nimprove recommendations on YouTube. Extensive experiments show that the\nproposed model consistently outperforms state-of-the-art in terms of accuracy,\ndiversity and novelty.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 07:10:24 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 09:34:10 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Perera", "Dilruk", ""], ["Zimmermann", "Roger", ""]]}, {"id": "2008.10857", "submitter": "Carlo Ciliberto", "authors": "Giulia Denevi, Massimiliano Pontil, Carlo Ciliberto", "title": "The Advantage of Conditional Meta-Learning for Biased Regularization and\n  Fine-Tuning", "comments": "34 pages; 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biased regularization and fine-tuning are two recent meta-learning\napproaches. They have been shown to be effective to tackle distributions of\ntasks, in which the tasks' target vectors are all close to a common\nmeta-parameter vector. However, these methods may perform poorly on\nheterogeneous environments of tasks, where the complexity of the tasks'\ndistribution cannot be captured by a single meta-parameter vector. We address\nthis limitation by conditional meta-learning, inferring a conditioning function\nmapping task's side information into a meta-parameter vector that is\nappropriate for that task at hand. We characterize properties of the\nenvironment under which the conditional approach brings a substantial advantage\nover standard meta-learning and we highlight examples of environments, such as\nthose with multiple clusters, satisfying these properties. We then propose a\nconvex meta-algorithm providing a comparable advantage also in practice.\nNumerical experiments confirm our theoretical findings.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 07:32:16 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Denevi", "Giulia", ""], ["Pontil", "Massimiliano", ""], ["Ciliberto", "Carlo", ""]]}, {"id": "2008.10858", "submitter": "Saadullah Amin", "authors": "Saadullah Amin, Stalin Varanasi, Katherine Ann Dunfield, G\\\"unter\n  Neumann", "title": "LowFER: Low-rank Bilinear Pooling for Link Prediction", "comments": "Accepted by ICML'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs are incomplete by nature, with only a limited number of\nobserved facts from the world knowledge being represented as structured\nrelations between entities. To partly address this issue, an important task in\nstatistical relational learning is that of link prediction or knowledge graph\ncompletion. Both linear and non-linear models have been proposed to solve the\nproblem. Bilinear models, while expressive, are prone to overfitting and lead\nto quadratic growth of parameters in number of relations. Simpler models have\nbecome more standard, with certain constraints on bilinear map as relation\nparameters. In this work, we propose a factorized bilinear pooling model,\ncommonly used in multi-modal learning, for better fusion of entities and\nrelations, leading to an efficient and constraint-free model. We prove that our\nmodel is fully expressive, providing bounds on the embedding dimensionality and\nfactorization rank. Our model naturally generalizes Tucker decomposition based\nTuckER model, which has been shown to generalize other models, as efficient\nlow-rank approximation without substantially compromising the performance. Due\nto low-rank approximation, the model complexity can be controlled by the\nfactorization rank, avoiding the possible cubic growth of TuckER. Empirically,\nwe evaluate on real-world datasets, reaching on par or state-of-the-art\nperformance. At extreme low-ranks, model preserves the performance while\nstaying parameter efficient.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 07:33:52 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Amin", "Saadullah", ""], ["Varanasi", "Stalin", ""], ["Dunfield", "Katherine Ann", ""], ["Neumann", "G\u00fcnter", ""]]}, {"id": "2008.10861", "submitter": "Taisuke Kobayashi", "authors": "Taisuke Kobayashi and Wendyam Eric Lionel Ilboudo", "title": "t-Soft Update of Target Network for Deep Reinforcement Learning", "comments": "11 pages, 7 figures", "journal-ref": "Neural Networks, 2021", "doi": "10.1016/j.neunet.2020.12.023", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new robust update rule of target network for deep\nreinforcement learning (DRL), to replace the conventional update rule, given as\nan exponential moving average. The target network is for smoothly generating\nthe reference signals for a main network in DRL, thereby reducing learning\nvariance. The problem with its conventional update rule is the fact that all\nthe parameters are smoothly copied with the same speed from the main network,\neven when some of them are trying to update toward the wrong directions. This\nbehavior increases the risk of generating the wrong reference signals. Although\nslowing down the overall update speed is a naive way to mitigate wrong updates,\nit would decrease learning speed. To robustly update the parameters while\nkeeping learning speed, a t-soft update method, which is inspired by student-t\ndistribution, is derived with reference to the analogy between the exponential\nmoving average and the normal distribution. Through the analysis of the derived\nt-soft update, we show that it takes over the properties of the student-t\ndistribution. Specifically, with a heavy-tailed property of the student-t\ndistribution, the t-soft update automatically excludes extreme updates that\ndiffer from past experiences. In addition, when the updates are similar to the\npast experiences, it can mitigate the learning delay by increasing the amount\nof updates. In PyBullet robotics simulations for DRL, an online actor-critic\nalgorithm with the t-soft update outperformed the conventional methods in terms\nof the obtained return and/or its variance. From the training process by the\nt-soft update, we found that the t-soft update is globally consistent with the\nstandard soft update, and the update rates are locally adjusted for\nacceleration or suppression.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 07:41:47 GMT"}, {"version": "v2", "created": "Fri, 25 Dec 2020 01:56:12 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Kobayashi", "Taisuke", ""], ["Ilboudo", "Wendyam Eric Lionel", ""]]}, {"id": "2008.10863", "submitter": "Jan Neerbek", "authors": "Jan Neerbek", "title": "Sensitive Information Detection: Recursive Neural Networks for Encoding\n  Context", "comments": "PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The amount of data for processing and categorization grows at an ever\nincreasing rate. At the same time the demand for collaboration and transparency\nin organizations, government and businesses, drives the release of data from\ninternal repositories to the public or 3rd party domain. This in turn increase\nthe potential of sharing sensitive information. The leak of sensitive\ninformation can potentially be very costly, both financially for organizations,\nbut also for individuals. In this work we address the important problem of\nsensitive information detection. Specially we focus on detection in\nunstructured text documents.\n  We show that simplistic, brittle rule sets for detecting sensitive\ninformation only find a small fraction of the actual sensitive information.\nFurthermore we show that previous state-of-the-art approaches have been\nimplicitly tailored to such simplistic scenarios and thus fail to detect actual\nsensitive content. We develop a novel family of sensitive information detection\napproaches which only assumes access to labeled examples, rather than\nunrealistic assumptions such as access to a set of generating rules or\ndescriptive topical seed words. Our approaches are inspired by the current\nstate-of-the-art for paraphrase detection and we adapt deep learning approaches\nover recursive neural networks to the problem of sensitive information\ndetection. We show that our context-based approaches significantly outperforms\nthe family of previous state-of-the-art approaches for sensitive information\ndetection, so-called keyword-based approaches, on real-world data and with\nhuman labeled examples of sensitive and non-sensitive documents.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 07:49:46 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Neerbek", "Jan", ""]]}, {"id": "2008.10866", "submitter": "Dilruk Perera", "authors": "Dilruk Perera and Roger Zimmermann", "title": "Exploring the use of Time-Dependent Cross-Network Information for\n  Personalized Recommendations", "comments": null, "journal-ref": "ACM Multimedia 2017, (MM'17)", "doi": "10.1145/3123266.3123447", "report-no": null, "categories": "cs.LG cs.IR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overwhelming volume and complexity of information in online applications\nmake recommendation essential for users to find information of interest.\nHowever, two major limitations that coexist in real world applications (1)\nincomplete user profiles, and (2) the dynamic nature of user preferences\ncontinue to degrade recommender quality in aspects such as timeliness,\naccuracy, diversity and novelty. To address both the above limitations in a\nsingle solution, we propose a novel cross-network time aware recommender\nsolution. The solution first learns historical user models in the target\nnetwork by aggregating user preferences from multiple source networks. Second,\nuser level time aware latent factors are learnt to develop current user models\nfrom the historical models and conduct timely recommendations. We illustrate\nour solution by using auxiliary information from the Twitter source network to\nimprove recommendations for the YouTube target network. Experiments conducted\nusing multiple time aware and cross-network baselines under different time\ngranularities show that the proposed solution achieves superior performance in\nterms of accuracy, novelty and diversity.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 07:52:47 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Perera", "Dilruk", ""], ["Zimmermann", "Roger", ""]]}, {"id": "2008.10870", "submitter": "Arunselvan Ramaswamy Dr.", "authors": "Arunselvan Ramaswamy, Eyke H\\\"ullermeier", "title": "Deep Q-Learning: Theoretical Insights from an Asymptotic Analysis", "comments": "4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Q-Learning is an important reinforcement learning algorithm, which\ninvolves training a deep neural network, called Deep Q-Network (DQN), to\napproximate the well-known Q-function. Although wildly successful under\nlaboratory conditions, serious gaps between theory and practice as well as a\nlack of formal guarantees prevent its use in the real world. Adopting a\ndynamical systems perspective, we provide a theoretical analysis of a popular\nversion of Deep Q-Learning under realistic and verifiable assumptions. More\nspecifically, we prove an important result on the convergence of the algorithm,\ncharacterizing the asymptotic behavior of the learning process. Our result\nsheds light on hitherto unexplained properties of the algorithm and helps\nunderstand empirical observations, such as performance inconsistencies even\nafter training. Unlike previous theories, our analysis accommodates state\nMarkov processes with multiple stationary distributions. In spite of the focus\non Deep Q-Learning, we believe that our theory may be applied to understand\nother deep learning algorithms\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 07:59:20 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 08:53:38 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Ramaswamy", "Arunselvan", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2008.10880", "submitter": "Rik Helwegen MSc", "authors": "Rik Helwegen, Christos Louizos and Patrick Forr\\'e", "title": "Improving Fair Predictions Using Variational Inference In Causal Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of algorithmic fairness grows with the increasing impact\nmachine learning has on people's lives. Recent work on fairness metrics shows\nthe need for causal reasoning in fairness constraints. In this work, a\npractical method named FairTrade is proposed for creating flexible prediction\nmodels which integrate fairness constraints on sensitive causal paths. The\nmethod uses recent advances in variational inference in order to account for\nunobserved confounders. Further, a method outline is proposed which uses the\ncausal mechanism estimates to audit black box models. Experiments are conducted\non simulated data and on a real dataset in the context of detecting unlawful\nsocial welfare. This research aims to contribute to machine learning techniques\nwhich honour our ethical and legal boundaries.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 08:27:11 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Helwegen", "Rik", ""], ["Louizos", "Christos", ""], ["Forr\u00e9", "Patrick", ""]]}, {"id": "2008.10893", "submitter": "Guozhi Dong", "authors": "Guozhi Dong, Michael Hintermueller and Kostas Papafitsoros", "title": "Optimization with learning-informed differential equation constraints\n  and its applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.AP math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by applications in optimal control of semilinear elliptic partial\ndifferential equations and physics-integrated imaging, differential equation\nconstrained optimization problems with constituents that are only accessible\nthrough data-driven techniques are studied. A particular focus is on the\nanalysis and on numerical methods for problems with machine-learned components.\nFor a rather general context, an error analysis is provided, and particular\nproperties resulting from artificial neural network based approximations are\naddressed. Moreover, for each of the two inspiring applications analytical\ndetails are presented and numerical results are provided.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 09:05:55 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Dong", "Guozhi", ""], ["Hintermueller", "Michael", ""], ["Papafitsoros", "Kostas", ""]]}, {"id": "2008.10898", "submitter": "Zhize Li", "authors": "Zhize Li, Hongyan Bao, Xiangliang Zhang, Peter Richt\\'arik", "title": "PAGE: A Simple and Optimal Probabilistic Gradient Estimator for\n  Nonconvex Optimization", "comments": "25 pages; accepted by ICML 2021 (long talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel stochastic gradient estimator --\nProbAbilistic Gradient Estimator (PAGE) -- for nonconvex optimization. PAGE is\neasy to implement as it is designed via a small adjustment to vanilla SGD: in\neach iteration, PAGE uses the vanilla minibatch SGD update with probability\n$p_t$ or reuses the previous gradient with a small adjustment, at a much lower\ncomputational cost, with probability $1-p_t$. We give a simple formula for the\noptimal choice of $p_t$. Moreover, we prove the first tight lower bound\n$\\Omega(n+\\frac{\\sqrt{n}}{\\epsilon^2})$ for nonconvex finite-sum problems,\nwhich also leads to a tight lower bound $\\Omega(b+\\frac{\\sqrt{b}}{\\epsilon^2})$\nfor nonconvex online problems, where $b:= \\min\\{\\frac{\\sigma^2}{\\epsilon^2},\nn\\}$. Then, we show that PAGE obtains the optimal convergence results\n$O(n+\\frac{\\sqrt{n}}{\\epsilon^2})$ (finite-sum) and\n$O(b+\\frac{\\sqrt{b}}{\\epsilon^2})$ (online) matching our lower bounds for both\nnonconvex finite-sum and online problems. Besides, we also show that for\nnonconvex functions satisfying the Polyak-\\L{}ojasiewicz (PL) condition, PAGE\ncan automatically switch to a faster linear convergence rate $O(\\cdot\\log\n\\frac{1}{\\epsilon})$. Finally, we conduct several deep learning experiments\n(e.g., LeNet, VGG, ResNet) on real datasets in PyTorch showing that PAGE not\nonly converges much faster than SGD in training but also achieves the higher\ntest accuracy, validating the optimal theoretical results and confirming the\npractical superiority of PAGE.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 09:11:31 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 18:25:41 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 21:37:35 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Li", "Zhize", ""], ["Bao", "Hongyan", ""], ["Zhang", "Xiangliang", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "2008.10916", "submitter": "Shuxin Qin", "authors": "Shuxin Qin and Sijiang Liu", "title": "Towards End-to-end Car License Plate Location and Recognition in\n  Unconstrained Scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benefiting from the rapid development of convolutional neural networks, the\nperformance of car license plate detection and recognition has been largely\nimproved. Nonetheless, challenges still exist especially for real-world\napplications. In this paper, we present an efficient and accurate framework to\nsolve the license plate detection and recognition tasks simultaneously. It is a\nlightweight and unified deep neural network, that can be optimized end-to-end\nand work in real-time. Specifically, for unconstrained scenarios, an\nanchor-free method is adopted to efficiently detect the bounding box and four\ncorners of a license plate, which are used to extract and rectify the target\nregion features. Then, a novel convolutional neural network branch is designed\nto further extract features of characters without segmentation. Finally,\nrecognition task is treated as sequence labelling problems, which are solved by\nConnectionist Temporal Classification (CTC) directly. Several public datasets\nincluding images collected from different scenarios under various conditions\nare chosen for evaluation. A large number of experiments indicate that the\nproposed method significantly outperforms the previous state-of-the-art methods\nin both speed and precision.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 09:51:33 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Qin", "Shuxin", ""], ["Liu", "Sijiang", ""]]}, {"id": "2008.10936", "submitter": "Tom Beer", "authors": "Tom Beer, Bar Eini-Porat, Sebastian Goodfellow, Danny Eytan and Uri\n  Shalit", "title": "Using Deep Networks for Scientific Discovery in Physiological Signals", "comments": "2020 Machine Learning for Healthcare Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) have shown remarkable success in the\nclassification of physiological signals. In this study we propose a method for\nexamining to what extent does a DNN's performance rely on rediscovering\nexisting features of the signals, as opposed to discovering genuinely new\nfeatures. Moreover, we offer a novel method of \"removing\" a hand-engineered\nfeature from the network's hypothesis space, thus forcing it to try and learn\nrepresentations which are different from known ones, as a method of scientific\nexploration. We then build on existing work in the field of interpretability,\nspecifically class activation maps, to try and infer what new features the\nnetwork has learned. We demonstrate this approach using ECG and EEG signals.\nWith respect to ECG signals we show that for the specific task of classifying\natrial fibrillation, DNNs are likely rediscovering known features. We also show\nhow our method could be used to discover new features, by selectively removing\nsome ECG features and \"rediscovering\" them. We further examine how could our\nmethod be used as a tool for examining scientific hypotheses. We simulate this\nscenario by looking into the importance of eye movements in classifying sleep\nfrom EEG. We show that our tool can successfully focus a researcher's attention\nby bringing to light patterns in the data that would be hidden otherwise.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 10:55:25 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Beer", "Tom", ""], ["Eini-Porat", "Bar", ""], ["Goodfellow", "Sebastian", ""], ["Eytan", "Danny", ""], ["Shalit", "Uri", ""]]}, {"id": "2008.10960", "submitter": "Julien Despois", "authors": "Julien Despois, Frederic Flament, Matthieu Perrot", "title": "AgingMapGAN (AMGAN): High-Resolution Controllable Face Aging with\n  Spatially-Aware Conditional GANs", "comments": "Project page: https://despoisj.github.io/AgingMapGAN/", "journal-ref": null, "doi": "10.1007/978-3-030-67070-2_37", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches and datasets for face aging produce results skewed\ntowards the mean, with individual variations and expression wrinkles often\ninvisible or overlooked in favor of global patterns such as the fattening of\nthe face. Moreover, they offer little to no control over the way the faces are\naged and can difficultly be scaled to large images, thus preventing their usage\nin many real-world applications. To address these limitations, we present an\napproach to change the appearance of a high-resolution image using\nethnicity-specific aging information and weak spatial supervision to guide the\naging process. We demonstrate the advantage of our proposed method in terms of\nquality, control, and how it can be used on high-definition images while\nlimiting the computational overhead.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 12:35:48 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 09:51:12 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Despois", "Julien", ""], ["Flament", "Frederic", ""], ["Perrot", "Matthieu", ""]]}, {"id": "2008.10982", "submitter": "Esa Ollila", "authors": "Esa Ollila and Ammar Mian", "title": "Block-wise Minimization-Majorization algorithm for Huber's criterion:\n  sparse learning and applications", "comments": "To appear in International Workshop on Machine Learning for Signal\n  Processing (MLSP), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Huber's criterion can be used for robust joint estimation of regression and\nscale parameters in the linear model. Huber's (Huber, 1981) motivation for\nintroducing the criterion stemmed from non-convexity of the joint maximum\nlikelihood objective function as well as non-robustness (unbounded influence\nfunction) of the associated ML-estimate of scale. In this paper, we illustrate\nhow the original algorithm proposed by Huber can be set within the block-wise\nminimization majorization framework. In addition, we propose novel\ndata-adaptive step sizes for both the location and scale, which are further\nimproving the convergence. We then illustrate how Huber's criterion can be used\nfor sparse learning of underdetermined linear model using the iterative hard\nthresholding approach. We illustrate the usefulness of the algorithms in an\nimage denoising application and simulation studies.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 13:18:07 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Ollila", "Esa", ""], ["Mian", "Ammar", ""]]}, {"id": "2008.10989", "submitter": "Hao Zhou", "authors": "Jorge Laval and Hao Zhou", "title": "Congested Urban Networks Tend to Be Insensitive to Signal Settings:\n  Implications for Learning-Based Control", "comments": "arXiv admin note: substantial text overlap with arXiv:1908.02673", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper highlights several properties of large urban networks that can\nhave an impact on machine learning methods applied to traffic signal control.\nIn particular, we show that the average network flow tends to be independent of\nthe signal control policy as density increases. This property, which so far has\nremained under the radar, implies that deep reinforcement learning (DRL)\nmethods becomes ineffective when trained under congested conditions, and might\nexplain DRL's limited success for traffic signal control. Our results apply to\nall possible grid networks thanks to a parametrization based on two network\nparameters: the ratio of the expected distance between consecutive traffic\nlights to the expected green time, and the turning probability at\nintersections. Networks with different parameters exhibit very different\nresponses to traffic signal control. Notably, we found that no control (i.e.\nrandom policy) can be an effective control strategy for a surprisingly large\nfamily of networks. The impact of the turning probability turned out to be very\nsignificant both for baseline and for DRL policies. It also explains the loss\nof symmetry observed for these policies, which is not captured by existing\ntheories that rely on corridor approximations without turns. Our findings also\nsuggest that supervised learning methods have enormous potential as they\nrequire very little examples to produce excellent policies.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 18:55:11 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Laval", "Jorge", ""], ["Zhou", "Hao", ""]]}, {"id": "2008.11007", "submitter": "Julien Siebert", "authors": "Julien Siebert, Lisa Joeckel, Jens Heidrich, Koji Nakamichi, Kyoko\n  Ohashi, Isao Namba, Rieko Yamamoto, Mikio Aoyama", "title": "Towards Guidelines for Assessing Qualities of Machine Learning Systems", "comments": "Has been accepted at the 13th International Conference on the Quality\n  of Information and Communications Technology QUATIC2020\n  (https://2020.quatic.org/). QUATIC 2020 proceedings will be included in a\n  volume of Springer CCIS Series (Communications in Computer and Information\n  Science)", "journal-ref": "Proceedings of the 13th International Conference on the Quality of\n  Information and Communications Technology QUATIC2020\n  (https://2020.quatic.org/). Springer CCIS Series (Communications in Computer\n  and Information Science)", "doi": "10.1007/978-3-030-58793-2_2", "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, systems containing components based on machine learning (ML)\nmethods are becoming more widespread. In order to ensure the intended behavior\nof a software system, there are standards that define necessary quality aspects\nof the system and its components (such as ISO/IEC 25010). Due to the different\nnature of ML, we have to adjust quality aspects or add additional ones (such as\ntrustworthiness) and be very precise about which aspect is really relevant for\nwhich object of interest (such as completeness of training data), and how to\nobjectively assess adherence to quality requirements. In this article, we\npresent the construction of a quality model (i.e., evaluation objects, quality\naspects, and metrics) for an ML system based on an industrial use case. This\nquality model enables practitioners to specify and assess quality requirements\nfor such kinds of ML systems objectively. In the future, we want to learn how\nthe term quality differs between different types of ML systems and come up with\ngeneral guidelines for specifying and assessing qualities of ML systems.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 13:45:54 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Siebert", "Julien", ""], ["Joeckel", "Lisa", ""], ["Heidrich", "Jens", ""], ["Nakamichi", "Koji", ""], ["Ohashi", "Kyoko", ""], ["Namba", "Isao", ""], ["Yamamoto", "Rieko", ""], ["Aoyama", "Mikio", ""]]}, {"id": "2008.11010", "submitter": "David Honz\\'atko", "authors": "David Honz\\'atko, Siavash A. Bigdeli, Engin T\\\"uretken, L. Andrea\n  Dunbar", "title": "Efficient Blind-Spot Neural Network Architecture for Image Denoising", "comments": null, "journal-ref": "2020 7th Swiss Conference on Data Science (SDS), Luzern,\n  Switzerland, 2020, pp. 59-60", "doi": "10.1109/SDS49233.2020.00022", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image denoising is an essential tool in computational photography. Standard\ndenoising techniques, which use deep neural networks at their core, require\npairs of clean and noisy images for its training. If we do not possess the\nclean samples, we can use blind-spot neural network architectures, which\nestimate the pixel value based on the neighbouring pixels only. These networks\nthus allow training on noisy images directly, as they by-design avoid trivial\nsolutions. Nowadays, the blind-spot is mostly achieved using shifted\nconvolutions or serialization. We propose a novel fully convolutional network\narchitecture that uses dilations to achieve the blind-spot property. Our\nnetwork improves the performance over the prior work and achieves\nstate-of-the-art results on established datasets.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 13:48:40 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Honz\u00e1tko", "David", ""], ["Bigdeli", "Siavash A.", ""], ["T\u00fcretken", "Engin", ""], ["Dunbar", "L. Andrea", ""]]}, {"id": "2008.11036", "submitter": "Ananda Theertha Suresh", "authors": "Corinna Cortes and Mehryar Mohri and Ananda Theertha Suresh and\n  Ningshan Zhang", "title": "A Discriminative Technique for Multiple-Source Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new discriminative technique for the multiple-source adaptation,\nMSA, problem. Unlike previous work, which relies on density estimation for each\nsource domain, our solution only requires conditional probabilities that can\neasily be accurately estimated from unlabeled data from the source domains. We\ngive a detailed analysis of our new technique, including general guarantees\nbased on R\\'enyi divergences, and learning bounds when conditional Maxent is\nused for estimating conditional probabilities for a point to belong to a source\ndomain. We show that these guarantees compare favorably to those that can be\nderived for the generative solution, using kernel density estimation. Our\nexperiments with real-world applications further demonstrate that our new\ndiscriminative MSA algorithm outperforms the previous generative solution as\nwell as other domain adaptation baselines.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 14:06:15 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 15:39:58 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Cortes", "Corinna", ""], ["Mohri", "Mehryar", ""], ["Suresh", "Ananda Theertha", ""], ["Zhang", "Ningshan", ""]]}, {"id": "2008.11037", "submitter": "Jiawei Ren", "authors": "Jiawei Ren, Cunjun Yu, Zhongang Cai, Haiyu Zhao", "title": "Balanced Activation for Long-tailed Visual Recognition", "comments": "LVIS Challenge Workshop at ECCV 2020 Spotlight. arXiv admin note:\n  substantial text overlap with arXiv:2007.10740", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep classifiers have achieved great success in visual recognition. However,\nreal-world data is long-tailed by nature, leading to the mismatch between\ntraining and testing distributions. In this report, we introduce Balanced\nActivation (Balanced Softmax and Balanced Sigmoid), an elegant unbiased, and\nsimple extension of Sigmoid and Softmax activation function, to accommodate the\nlabel distribution shift between training and testing in object detection. We\nderive the generalization bound for multiclass Softmax regression and show our\nloss minimizes the bound. In our experiments, we demonstrate that Balanced\nActivation generally provides ~3% gain in terms of mAP on LVIS-1.0 and\noutperforms the current state-of-the-art methods without introducing any extra\nparameters.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 11:36:10 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Ren", "Jiawei", ""], ["Yu", "Cunjun", ""], ["Cai", "Zhongang", ""], ["Zhao", "Haiyu", ""]]}, {"id": "2008.11045", "submitter": "No\\'e Tits", "authors": "No\\'e Tits, Kevin El Haddad and Thierry Dutoit", "title": "ICE-Talk: an Interface for a Controllable Expressive Talking Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ICE-Talk is an open source web-based GUI that allows the use of a TTS system\nwith controllable parameters via a text field and a clickable 2D plot. It\nenables the study of latent spaces for controllable TTS. Moreover it is\nimplemented as a module that can be used as part of a Human-Agent interaction.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 14:17:10 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Tits", "No\u00e9", ""], ["Haddad", "Kevin El", ""], ["Dutoit", "Thierry", ""]]}, {"id": "2008.11062", "submitter": "Haotao Wang", "authors": "Haotao Wang, Shupeng Gui, Haichuan Yang, Ji Liu, Zhangyang Wang", "title": "GAN Slimming: All-in-One GAN Compression by A Unified Optimization\n  Framework", "comments": "ECCV 2020 spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have gained increasing popularity in\nvarious computer vision applications, and recently start to be deployed to\nresource-constrained mobile devices. Similar to other deep models,\nstate-of-the-art GANs suffer from high parameter complexities. That has\nrecently motivated the exploration of compressing GANs (usually generators).\nCompared to the vast literature and prevailing success in compressing deep\nclassifiers, the study of GAN compression remains in its infancy, so far\nleveraging individual compression techniques instead of more sophisticated\ncombinations. We observe that due to the notorious instability of training\nGANs, heuristically stacking different compression techniques will result in\nunsatisfactory results. To this end, we propose the first unified optimization\nframework combining multiple compression means for GAN compression, dubbed GAN\nSlimming (GS). GS seamlessly integrates three mainstream compression\ntechniques: model distillation, channel pruning and quantization, together with\nthe GAN minimax objective, into one unified optimization form, that can be\nefficiently optimized from end to end. Without bells and whistles, GS largely\noutperforms existing options in compressing image-to-image translation GANs.\nSpecifically, we apply GS to compress CartoonGAN, a state-of-the-art style\ntransfer network, by up to 47 times, with minimal visual quality degradation.\nCodes and pre-trained models can be found at\nhttps://github.com/TAMU-VITA/GAN-Slimming.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 14:39:42 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Wang", "Haotao", ""], ["Gui", "Shupeng", ""], ["Yang", "Haichuan", ""], ["Liu", "Ji", ""], ["Wang", "Zhangyang", ""]]}, {"id": "2008.11070", "submitter": "Tan Jing Yu Denis", "authors": "Denis Tan Jing Yu, Adrian Law Wing-Keung", "title": "An Economic Perspective on Predictive Maintenance of Filtration Units", "comments": "7 pages, 3 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides an economic perspective on the predictive maintenance of\nfiltration units. The rise of predictive maintenance is possible due to the\ngrowing trend of industry 4.0 and the availability of inexpensive sensors.\nHowever, the adoption rate for predictive maintenance by companies remains low.\nThe majority of companies are sticking to corrective and preventive\nmaintenance. This is not due to a lack of information on the technical\nimplementation of predictive maintenance, with an abundance of research papers\non state-of-the-art machine learning algorithms that can be used effectively.\nThe main issue is that most upper management has not yet been fully convinced\nof the idea of predictive maintenance. The economic value of the implementation\nhas to be linked to the predictive maintenance program for better justification\nby the management. In this study, three machine learning models were trained to\ndemonstrate the economic value of predictive maintenance. Data was collected\nfrom a testbed located at the Singapore University of Technology and Design.\nThe testbed closely resembles a real-world water treatment plant. A\ncost-benefit analysis coupled with Monte Carlo simulation was proposed. It\nprovided a structured approach to document potential costs and savings by\nimplementing a predictive maintenance program. The simulation incorporated\nreal-world risk into a financial model. Financial figures were adapted from\nCITIC Envirotech Ltd, a leading membrane-based integrated environmental\nsolutions provider. Two scenarios were used to elaborate on the economic values\nof predictive maintenance. Overall, this study seeks to bridge the gap between\ntechnical and business domains of predictive maintenance.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 14:43:30 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Yu", "Denis Tan Jing", ""], ["Wing-Keung", "Adrian Law", ""]]}, {"id": "2008.11081", "submitter": "Amanuel Alambo", "authors": "Amanuel Alambo, Ryan Andrew, Sid Gollarahalli, Jacqueline Vaughn,\n  Tanvi Banerjee, Krishnaprasad Thirunarayan, Daniel Abrams, Nirmish Shah", "title": "Measuring Pain in Sickle Cell Disease using Clinical Text", "comments": "The 42nd Annual International Conference of the IEEE Engineering in\n  Medicine and Biology Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sickle Cell Disease (SCD) is a hereditary disorder of red blood cells in\nhumans. Complications such as pain, stroke, and organ failure occur in SCD as\nmalformed, sickled red blood cells passing through small blood vessels get\ntrapped. Particularly, acute pain is known to be the primary symptom of SCD.\nThe insidious and subjective nature of SCD pain leads to challenges in pain\nassessment among Medical Practitioners (MPs). Thus, accurate identification of\nmarkers of pain in patients with SCD is crucial for pain management.\nClassifying clinical notes of patients with SCD based on their pain level\nenables MPs to give appropriate treatment. We propose a binary classification\nmodel to predict pain relevance of clinical notes and a multiclass\nclassification model to predict pain level. While our four binary machine\nlearning (ML) classifiers are comparable in their performance, Decision Trees\nhad the best performance for the multiclass classification task achieving 0.70\nin F-measure. Our results show the potential clinical text analysis and machine\nlearning offer to pain management in sickle cell patients.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 23:39:57 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Alambo", "Amanuel", ""], ["Andrew", "Ryan", ""], ["Gollarahalli", "Sid", ""], ["Vaughn", "Jacqueline", ""], ["Banerjee", "Tanvi", ""], ["Thirunarayan", "Krishnaprasad", ""], ["Abrams", "Daniel", ""], ["Shah", "Nirmish", ""]]}, {"id": "2008.11087", "submitter": "Chuheng Zhang", "authors": "Wei Shen, Xiaonan He, Chuheng Zhang, Qiang Ni, Wanchun Dou, Yan Wang", "title": "Auxiliary-task Based Deep Reinforcement Learning for Participant\n  Selection Problem in Mobile Crowdsourcing", "comments": "Accepted by CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3411913", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mobile crowdsourcing (MCS), the platform selects participants to complete\nlocation-aware tasks from the recruiters aiming to achieve multiple goals\n(e.g., profit maximization, energy efficiency, and fairness). However,\ndifferent MCS systems have different goals and there are possibly conflicting\ngoals even in one MCS system. Therefore, it is crucial to design a participant\nselection algorithm that applies to different MCS systems to achieve multiple\ngoals. To deal with this issue, we formulate the participant selection problem\nas a reinforcement learning problem and propose to solve it with a novel\nmethod, which we call auxiliary-task based deep reinforcement learning (ADRL).\nWe use transformers to extract representations from the context of the MCS\nsystem and a pointer network to deal with the combinatorial optimization\nproblem. To improve the sample efficiency, we adopt an auxiliary-task training\nprocess that trains the network to predict the imminent tasks from the\nrecruiters, which facilitates the embedding learning of the deep learning\nmodel. Additionally, we release a simulated environment on a specific MCS task,\nthe ride-sharing task, and conduct extensive performance evaluations in this\nenvironment. The experimental results demonstrate that ADRL outperforms and\nimproves sample efficiency over other well-recognized baselines in various\nsettings.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 15:02:54 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 00:55:05 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Shen", "Wei", ""], ["He", "Xiaonan", ""], ["Zhang", "Chuheng", ""], ["Ni", "Qiang", ""], ["Dou", "Wanchun", ""], ["Wang", "Yan", ""]]}, {"id": "2008.11088", "submitter": "Prateek Mishra", "authors": "Prateek Mishra", "title": "Few Shot Text-Independent speaker verification using 3D-CNN", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial recognition system is one of the major successes of Artificial\nintelligence and has been used a lot over the last years. But, images are not\nthe only biometric present: audio is another possible biometric that can be\nused as an alternative to the existing recognition systems. However, the\ntext-independent audio data is not always available for tasks like speaker\nverification and also no work has been done in the past for text-independent\nspeaker verification assuming very little training data. Therefore, In this\npaper, we have proposed a novel method to verify the identity of the claimed\nspeaker using very few training data. To achieve this we are using a Siamese\nneural network with center loss and speaker bias loss. Experiments conducted on\nthe VoxCeleb1 dataset show that the proposed model accuracy even on training\nwith very few data is near to the state of the art model on text-independent\nspeaker verification\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 15:03:29 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Mishra", "Prateek", ""]]}, {"id": "2008.11089", "submitter": "Yinghua Zhang", "authors": "Yinghua Zhang, Yangqiu Song, Jian Liang, Kun Bai, Qiang Yang", "title": "Two Sides of the Same Coin: White-box and Black-box Attacks for Transfer\n  Learning", "comments": null, "journal-ref": null, "doi": "10.1145/3394486.3403349", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning has become a common practice for training deep learning\nmodels with limited labeled data in a target domain. On the other hand, deep\nmodels are vulnerable to adversarial attacks. Though transfer learning has been\nwidely applied, its effect on model robustness is unclear. To figure out this\nproblem, we conduct extensive empirical evaluations to show that fine-tuning\neffectively enhances model robustness under white-box FGSM attacks. We also\npropose a black-box attack method for transfer learning models which attacks\nthe target model with the adversarial examples produced by its source model. To\nsystematically measure the effect of both white-box and black-box attacks, we\npropose a new metric to evaluate how transferable are the adversarial examples\nproduced by a source model to a target model. Empirical results show that the\nadversarial examples are more transferable when fine-tuning is used than they\nare when the two networks are trained independently.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 15:04:32 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Zhang", "Yinghua", ""], ["Song", "Yangqiu", ""], ["Liang", "Jian", ""], ["Bai", "Kun", ""], ["Yang", "Qiang", ""]]}, {"id": "2008.11091", "submitter": "Tuyen Truong", "authors": "Tuyen Trung Truong", "title": "Unconstrained optimisation on Riemannian manifolds", "comments": "29 pages. Some experimental results (on singular cost functions on\n  Euclidean spaces, and on minimum on the closed unit ball in the Euclidean\n  spaces) are given. References updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.DG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we give explicit descriptions of versions of (Local-)\nBacktracking Gradient Descent and New Q-Newton's method to the Riemannian\nsetting.Here are some easy to state consequences of results in this paper,\nwhere X is a general Riemannian manifold of finite dimension and\n$f:X\\rightarrow \\mathbb{R}$ a $C^2$ function which is Morse (that is, all its\ncritical points are non-degenerate).\n  {\\bf Theorem.} For random choices of the hyperparameters in the Riemanian\nLocal Backtracking Gradient Descent algorithm and for random choices of the\ninitial point $x_0$, the sequence $\\{x_n\\}$ constructed by the algorithm either\n(i) converges to a local minimum of $f$ or (ii) eventually leaves every compact\nsubsets of $X$ (in other words, diverges to infinity on $X$). If $f$ has\ncompact sublevels, then only the former alternative happens. The convergence\nrate is the same as in the classical paper by Armijo.\n  {\\bf Theorem.} Assume that $f$ is $C^3$. For random choices of the\nhyperparametes in the Riemannian New Q-Newton's method, if the sequence\nconstructed by the algorithm converges, then the limit is a critical point of\n$f$. We have a local Stable-Center manifold theorem, near saddle points of $f$,\nfor the dynamical system associated to the algorithm. If the limit point is a\nnon-degenerate minimum point, then the rate of convergence is quadratic. If\nmoreover $X$ is an open subset of a Lie group and the initial point $x_0$ is\nchosen randomly, then we can globally avoid saddle points.\n  As an application, we propose a general method using Riemannian Backtracking\nGD to find minimum of a function on a bounded ball in a Euclidean space, and do\nexplicit calculations for calculating the smallest eigenvalue of a symmetric\nsquare matrix.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 15:10:21 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 11:00:51 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Truong", "Tuyen Trung", ""]]}, {"id": "2008.11092", "submitter": "Damien Garreau", "authors": "Damien Garreau, Ulrike von Luxburg", "title": "Looking Deeper into Tabular LIME", "comments": "63 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability of machine learning algorithms is an urgent need. Numerous\nmethods appeared in recent years, but do their explanations make sense? In this\npaper, we present a thorough theoretical analysis of one of these methods,\nLIME, in the case of tabular data. We prove that in the large sample limit, the\ninterpretable coefficients provided by Tabular LIME can be computed in an\nexplicit way as a function of the algorithm parameters and some expectation\ncomputations related to the black-box model. When the function to explain has\nsome nice algebraic structure (linear, multiplicative, or sparsely depending on\na subset of the coordinates), our analysis provides interesting insights into\nthe explanations provided by LIME. These can be applied to a range of machine\nlearning models including Gaussian kernels or CART random forests. As an\nexample, for linear functions we show that LIME has the desirable property to\nprovide explanations that are proportional to the coefficients of the function\nto explain and to ignore coordinates that are not used by the function to\nexplain. For partition-based regressors, on the other side, we show that LIME\nproduces undesired artifacts that may provide misleading explanations.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 15:10:57 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 09:35:15 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Garreau", "Damien", ""], ["von Luxburg", "Ulrike", ""]]}, {"id": "2008.11104", "submitter": "Malik Aqeel Anwar", "authors": "Aqeel Anwar, Arijit Raychowdhury", "title": "Masked Face Recognition for Secure Authentication", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent world-wide COVID-19 pandemic, using face masks have become an\nimportant part of our lives. People are encouraged to cover their faces when in\npublic area to avoid the spread of infection. The use of these face masks has\nraised a serious question on the accuracy of the facial recognition system used\nfor tracking school/office attendance and to unlock phones. Many organizations\nuse facial recognition as a means of authentication and have already developed\nthe necessary datasets in-house to be able to deploy such a system.\nUnfortunately, masked faces make it difficult to be detected and recognized,\nthereby threatening to make the in-house datasets invalid and making such\nfacial recognition systems inoperable. This paper addresses a methodology to\nuse the current facial datasets by augmenting it with tools that enable masked\nfaces to be recognized with low false-positive rates and high overall accuracy,\nwithout requiring the user dataset to be recreated by taking new pictures for\nauthentication. We present an open-source tool, MaskTheFace to mask faces\neffectively creating a large dataset of masked faces. The dataset generated\nwith this tool is then used towards training an effective facial recognition\nsystem with target accuracy for masked faces. We report an increase of 38% in\nthe true positive rate for the Facenet system. We also test the accuracy of\nre-trained system on a custom real-world dataset MFR2 and report similar\naccuracy.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 15:33:59 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Anwar", "Aqeel", ""], ["Raychowdhury", "Arijit", ""]]}, {"id": "2008.11109", "submitter": "Qiaoying Huang", "authors": "Qiaoying Huang, Eric Z. Chen, Hanchao Yu, Yimo Guo, Terrence Chen,\n  Dimitris Metaxas, Shanhui Sun", "title": "Measure Anatomical Thickness from Cardiac MRI with Deep Neural Networks", "comments": "Accepted by STACOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate estimation of shape thickness from medical images is crucial in\nclinical applications. For example, the thickness of myocardium is one of the\nkey to cardiac disease diagnosis. While mathematical models are available to\nobtain accurate dense thickness estimation, they suffer from heavy\ncomputational overhead due to iterative solvers. To this end, we propose novel\nmethods for dense thickness estimation, including a fast solver that estimates\nthickness from binary annular shapes and an end-to-end network that estimates\nthickness directly from raw cardiac images.We test the proposed models on three\ncardiac datasets and one synthetic dataset, achieving impressive results and\ngeneralizability on all. Thickness estimation is performed without iterative\nsolvers or manual correction, which is 100 times faster than the mathematical\nmodel. We also analyze thickness patterns on different cardiac pathologies with\na standard clinical model and the results demonstrate the potential clinical\nvalue of our method for thickness based cardiac disease diagnosis.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 15:37:57 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Huang", "Qiaoying", ""], ["Chen", "Eric Z.", ""], ["Yu", "Hanchao", ""], ["Guo", "Yimo", ""], ["Chen", "Terrence", ""], ["Metaxas", "Dimitris", ""], ["Sun", "Shanhui", ""]]}, {"id": "2008.11117", "submitter": "Jonathan Ashbrock", "authors": "Jonathan Ashbrock, Alexander M. Powell", "title": "Stochastic Markov Gradient Descent and Training Low-Bit Neural Networks", "comments": "19 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The massive size of modern neural networks has motivated substantial recent\ninterest in neural network quantization. We introduce Stochastic Markov\nGradient Descent (SMGD), a discrete optimization method applicable to training\nquantized neural networks. The SMGD algorithm is designed for settings where\nmemory is highly constrained during training. We provide theoretical guarantees\nof algorithm performance as well as encouraging numerical results.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 15:48:15 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 15:48:20 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Ashbrock", "Jonathan", ""], ["Powell", "Alexander M.", ""]]}, {"id": "2008.11136", "submitter": "Amine Dadoun", "authors": "Amine Dadoun (1 and 2), Raphael Troncy (1) ((1) Eurecom, (2) Amadeus\n  SAS)", "title": "Many-to-one Recurrent Neural Network for Session-based Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the D2KLab team's approach to the RecSys Challenge 2019\nwhich focuses on the task of recommending accommodations based on user\nsessions. What is the feeling of a person who says \"Rooms of the hotel are\nenormous, staff are friendly and efficient\"? It is positive. Similarly to the\nsequence of words in a sentence where one can affirm what the feeling is,\nanalysing a sequence of actions performed by a user in a website can lead to\npredict what will be the item the user will add to his basket at the end of the\nshopping session. We propose to use a many-to-one recurrent neural network that\nlearns the probability that a user will click on an accommodation based on the\nsequence of actions he has performed during his browsing session. More\nspecifically, we combine a rule-based algorithm with a Gated Recurrent Unit RNN\nin order to sort the list of accommodations that is shown to the user. We\noptimized the RNN on a validation set, tuning the hyper-parameters such as the\nlearning rate, the batch-size and the accommodation embedding size. This\nanalogy with the sentiment analysis task gives promising results. However, it\nis computationally demanding in the training phase and it needs to be further\ntuned.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 16:07:23 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Dadoun", "Amine", "", "1 and 2"], ["Troncy", "Raphael", ""]]}, {"id": "2008.11141", "submitter": "Mohammad Mohammadi Amiri Dr.", "authors": "Mohammad Mohammadi Amiri, Deniz Gunduz, Sanjeev R. Kulkarni, H.\n  Vincent Poor", "title": "Convergence of Federated Learning over a Noisy Downlink", "comments": "submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study federated learning (FL), where power-limited wireless devices\nutilize their local datasets to collaboratively train a global model with the\nhelp of a remote parameter server (PS). The PS has access to the global model\nand shares it with the devices for local training, and the devices return the\nresult of their local updates to the PS to update the global model. This\nframework requires downlink transmission from the PS to the devices and uplink\ntransmission from the devices to the PS. The goal of this study is to\ninvestigate the impact of the bandwidth-limited shared wireless medium in both\nthe downlink and uplink on the performance of FL with a focus on the downlink.\nTo this end, the downlink and uplink channels are modeled as fading broadcast\nand multiple access channels, respectively, both with limited bandwidth. For\ndownlink transmission, we first introduce a digital approach, where a\nquantization technique is employed at the PS to broadcast the global model\nupdate at a common rate such that all the devices can decode it. Next, we\npropose analog downlink transmission, where the global model is broadcast by\nthe PS in an uncoded manner. We consider analog transmission over the uplink in\nboth cases. We further analyze the convergence behavior of the proposed analog\napproach assuming that the uplink transmission is error-free. Numerical\nexperiments show that the analog downlink approach provides significant\nimprovement over the digital one, despite a significantly lower transmit power\nat the PS. The experimental results corroborate the convergence results, and\nshow that a smaller number of local iterations should be used when the data\ndistribution is more biased, and also when the devices have a better estimate\nof the global model in the analog downlink approach.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 16:15:05 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Amiri", "Mohammad Mohammadi", ""], ["Gunduz", "Deniz", ""], ["Kulkarni", "Sanjeev R.", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2008.11149", "submitter": "Akshat Gupta", "authors": "Akshat Gupta, Milan Desai, Wusheng Liang, Magesh Kannan", "title": "Spatiotemporal Action Recognition in Restaurant Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatiotemporal action recognition is the task of locating and classifying\nactions in videos. Our project applies this task to analyzing video footage of\nrestaurant workers preparing food, for which potential applications include\nautomated checkout and inventory management. Such videos are quite different\nfrom the standardized datasets that researchers are used to, as they involve\nsmall objects, rapid actions, and notoriously unbalanced data classes. We\nexplore two approaches. The first approach involves the familiar object\ndetector You Only Look Once, and another applying a recently proposed analogue\nfor action recognition, You Only Watch Once. In the first, we design and\nimplement a novel, recurrent modification of YOLO using convolutional LSTMs and\nexplore the various subtleties in the training of such a network. In the\nsecond, we study the ability of YOWOs three dimensional convolutions to capture\nthe spatiotemporal features of our unique dataset\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 16:30:01 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Gupta", "Akshat", ""], ["Desai", "Milan", ""], ["Liang", "Wusheng", ""], ["Kannan", "Magesh", ""]]}, {"id": "2008.11151", "submitter": "Feiyan Hu", "authors": "Feiyan Hu and Kevin McGuinness", "title": "FastSal: a Computationally Efficient Network for Visual Saliency\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the problem of visual saliency prediction, predicting\nregions of an image that tend to attract human visual attention, under a\nconstrained computational budget. We modify and test various recent efficient\nconvolutional neural network architectures like EfficientNet and MobileNetV2\nand compare them with existing state-of-the-art saliency models such as SalGAN\nand DeepGaze II both in terms of standard accuracy metrics like AUC and NSS,\nand in terms of the computational complexity and model size. We find that\nMobileNetV2 makes an excellent backbone for a visual saliency model and can be\neffective even without a complex decoder. We also show that knowledge transfer\nfrom a more computationally expensive model like DeepGaze II can be achieved\nvia pseudo-labelling an unlabelled dataset, and that this approach gives result\non-par with many state-of-the-art algorithms with a fraction of the\ncomputational cost and model size. Source code is available at\nhttps://github.com/feiyanhu/FastSal.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 16:32:33 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Hu", "Feiyan", ""], ["McGuinness", "Kevin", ""]]}, {"id": "2008.11155", "submitter": "Andr\\'e Mas", "authors": "Cl\\'{e]ment Carr\\'e and Andr\\'e Mas", "title": "Prediction of Hilbertian autoregressive processes : a Recurrent Neural\n  Network approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The autoregressive Hilbertian model (ARH) was introduced in the early 90's by\nDenis Bosq. It was the subject of a vast literature and gave birth to numerous\nextensions. The model generalizes the classical multidimensional autoregressive\nmodel, widely used in Time Series Analysis. It was successfully applied in\nnumerous fields such as finance, industry, biology. We propose here to compare\nthe classical prediction methodology based on the estimation of the\nautocorrelation operator with a neural network learning approach. The latter is\nbased on a popular version of Recurrent Neural Networks : the Long Short Term\nMemory networks. The comparison is carried out through simulations and real\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 16:43:24 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Carr\u00e9", "Cl\\'{e]ment", ""], ["Mas", "Andr\u00e9", ""]]}, {"id": "2008.11159", "submitter": "Damian Pascual", "authors": "Lukas Faber, Sandro Luck, Damian Pascual, Andreas Roth, Gino Brunner\n  and Roger Wattenhofer", "title": "Medley2K: A Dataset of Medley Transitions", "comments": "MML 2020 - 13th Int. Workshop on Machine Learning and Music at\n  ECML-PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic generation of medleys, i.e., musical pieces formed by different\nsongs concatenated via smooth transitions, is not well studied in the current\nliterature. To facilitate research on this topic, we make available a dataset\ncalled Medley2K that consists of 2,000 medleys and 7,712 labeled transitions.\nOur dataset features a rich variety of song transitions across different music\ngenres. We provide a detailed description of this dataset and validate it by\ntraining a state-of-the-art generative model in the task of generating\ntransitions between songs.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 16:46:56 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Faber", "Lukas", ""], ["Luck", "Sandro", ""], ["Pascual", "Damian", ""], ["Roth", "Andreas", ""], ["Brunner", "Gino", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "2008.11174", "submitter": "Robin Strudel", "authors": "Robin Strudel, Ricardo Garcia, Justin Carpentier, Jean-Paul Laumond,\n  Ivan Laptev, Cordelia Schmid", "title": "Learning Obstacle Representations for Neural Motion Planning", "comments": "CoRL 2020. See the project webpage at\n  https://www.di.ens.fr/willow/research/nmp_repr/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motion planning and obstacle avoidance is a key challenge in robotics\napplications. While previous work succeeds to provide excellent solutions for\nknown environments, sensor-based motion planning in new and dynamic\nenvironments remains difficult. In this work we address sensor-based motion\nplanning from a learning perspective. Motivated by recent advances in visual\nrecognition, we argue the importance of learning appropriate representations\nfor motion planning. We propose a new obstacle representation based on the\nPointNet architecture and train it jointly with policies for obstacle\navoidance. We experimentally evaluate our approach for rigid body motion\nplanning in challenging environments and demonstrate significant improvements\nof the state of the art in terms of accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 17:12:32 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 16:51:26 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 15:58:40 GMT"}, {"version": "v4", "created": "Sat, 7 Nov 2020 11:30:09 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Strudel", "Robin", ""], ["Garcia", "Ricardo", ""], ["Carpentier", "Justin", ""], ["Laumond", "Jean-Paul", ""], ["Laptev", "Ivan", ""], ["Schmid", "Cordelia", ""]]}, {"id": "2008.11193", "submitter": "Tijana Zrnic", "authors": "Vitaly Feldman and Tijana Zrnic", "title": "Individual Privacy Accounting via a Renyi Filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a sequential setting in which a single dataset of individuals is\nused to perform adaptively-chosen analyses, while ensuring that the\ndifferential privacy loss of each participant does not exceed a pre-specified\nprivacy budget. The standard approach to this problem relies on bounding a\nworst-case estimate of the privacy loss over all individuals and all possible\nvalues of their data, for every single analysis. Yet, in many scenarios this\napproach is overly conservative, especially for \"typical\" data points which\nincur little privacy loss by participation in most of the analyses. In this\nwork, we give a method for tighter privacy loss accounting based on the value\nof a personalized privacy loss estimate for each individual in each analysis.\nTo implement the accounting method we design a filter for R\\'enyi differential\nprivacy. A filter is a tool that ensures that the privacy parameter of a\ncomposed sequence of algorithms with adaptively-chosen privacy parameters does\nnot exceed a pre-specified budget. Our filter is simpler and tighter than the\nknown filter for $(\\epsilon,\\delta)$-differential privacy by Rogers et al. We\napply our results to the analysis of noisy gradient descent and show that\npersonalized accounting can be practical, easy to implement, and can only make\nthe privacy-utility tradeoff tighter.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 17:49:48 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 15:02:45 GMT"}, {"version": "v3", "created": "Mon, 28 Jun 2021 15:34:21 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Feldman", "Vitaly", ""], ["Zrnic", "Tijana", ""]]}, {"id": "2008.11203", "submitter": "Yun-Chun Chen", "authors": "Yun-Chun Chen, Chao-Te Chou, Yu-Chiang Frank Wang", "title": "Learning to Learn in a Semi-Supervised Fashion", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address semi-supervised learning from both labeled and unlabeled data, we\npresent a novel meta-learning scheme. We particularly consider that labeled and\nunlabeled data share disjoint ground truth label sets, which can be seen tasks\nlike in person re-identification or image retrieval. Our learning scheme\nexploits the idea of leveraging information from labeled to unlabeled data.\nInstead of fitting the associated class-wise similarity scores as most\nmeta-learning algorithms do, we propose to derive semantics-oriented similarity\nrepresentations from labeled data, and transfer such representation to\nunlabeled ones. Thus, our strategy can be viewed as a self-supervised learning\nscheme, which can be applied to fully supervised learning tasks for improved\nperformance. Our experiments on various tasks and settings confirm the\neffectiveness of our proposed approach and its superiority over the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 17:59:53 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Chen", "Yun-Chun", ""], ["Chou", "Chao-Te", ""], ["Wang", "Yu-Chiang Frank", ""]]}, {"id": "2008.11226", "submitter": "Ce Zhang Mr.", "authors": "Ce Zhang, Azim Eskandarian", "title": "A Survey and Tutorial of EEG-Based Brain Monitoring for Driver State\n  Analysis", "comments": "Accepted by IEEE/CAA Journal of Automatica Sinica", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drivers cognitive and physiological states affect their ability to control\ntheir vehicles. Thus, these driver states are important to the safety of\nautomobiles. The design of advanced driver assistance systems (ADAS) or\nautonomous vehicles will depend on their ability to interact effectively with\nthe driver. A deeper understanding of the driver state is, therefore,\nparamount. EEG is proven to be one of the most effective methods for driver\nstate monitoring and human error detection. This paper discusses EEG-based\ndriver state detection systems and their corresponding analysis algorithms over\nthe last three decades. First, the commonly used EEG system setup for driver\nstate studies is introduced. Then, the EEG signal preprocessing, feature\nextraction, and classification algorithms for driver state detection are\nreviewed. Finally, EEG-based driver state monitoring research is reviewed\nin-depth, and its future development is discussed. It is concluded that the\ncurrent EEG-based driver state monitoring algorithms are promising for safety\napplications. However, many improvements are still required in EEG artifact\nreduction, real-time processing, and between-subject classification accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 18:21:35 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Zhang", "Ce", ""], ["Eskandarian", "Azim", ""]]}, {"id": "2008.11227", "submitter": "Ce Zhang Mr.", "authors": "Ce Zhang, Azim Eskandarian", "title": "A Computationally Efficient Multiclass Time-Frequency Common Spatial\n  Pattern Analysis on EEG Motor Imagery", "comments": "Accepted by 42nd Annual International Conferences of the IEEE\n  Engineering in Medicine and Biology Society in conjunction with the 43rd\n  Annual Conference of the Canadian Medical and Biological Engineering Society,\n  2020", "journal-ref": null, "doi": "10.1109/EMBC44109.2020.9176705", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common spatial pattern (CSP) is a popular feature extraction method for\nelectroencephalogram (EEG) motor imagery (MI). This study modifies the\nconventional CSP algorithm to improve the multi-class MI classification\naccuracy and ensure the computation process is efficient. The EEG MI data is\ngathered from the Brain-Computer Interface (BCI) Competition IV. At first, a\nbandpass filter and a time-frequency analysis are performed for each experiment\ntrial. Then, the optimal EEG signals for every experiment trials are selected\nbased on the signal energy for CSP feature extraction. In the end, the\nextracted features are classified by three classifiers, linear discriminant\nanalysis (LDA), na\\\"ive Bayes (NVB), and support vector machine (SVM), in\nparallel for classification accuracy comparison. The experiment results show\nthe proposed algorithm average computation time is 37.22% less than the FBCSP\n(1st winner in the BCI Competition IV) and 4.98% longer than the conventional\nCSP method. For the classification rate, the proposed algorithm kappa value\nachieved 2nd highest compared with the top 3 winners in BCI Competition IV.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 18:23:50 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Zhang", "Ce", ""], ["Eskandarian", "Azim", ""]]}, {"id": "2008.11228", "submitter": "Anna Kruspe", "authors": "Anna Kruspe", "title": "A simple method for domain adaptation of sentence embeddings", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.22173.26085", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained sentence embeddings have been shown to be very useful for a\nvariety of NLP tasks. Due to the fact that training such embeddings requires a\nlarge amount of data, they are commonly trained on a variety of text data. An\nadaptation to specific domains could improve results in many cases, but such a\nfinetuning is usually problem-dependent and poses the risk of over-adapting to\nthe data used for adaptation. In this paper, we present a simple universal\nmethod for finetuning Google's Universal Sentence Encoder (USE) using a Siamese\narchitecture. We demonstrate how to use this approach for a variety of data\nsets and present results on different data sets representing similar problems.\nThe approach is also compared to traditional finetuning on these data sets. As\na further advantage, the approach can be used for combining data sets with\ndifferent annotations. We also present an embedding finetuned on all data sets\nin parallel.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 18:31:08 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Kruspe", "Anna", ""]]}, {"id": "2008.11230", "submitter": "Zhe Jiang", "authors": "Zhe Jiang, Arpan Man Sainju", "title": "Flood Extent Mapping based on High Resolution Aerial Imagery and DEM: A\n  Hidden Markov Tree Approach", "comments": null, "journal-ref": null, "doi": "10.1080/01431161.2020.1823514", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flood extent mapping plays a crucial role in disaster management and national\nwater forecasting. In recent years, high-resolution optical imagery becomes\nincreasingly available with the deployment of numerous small satellites and\ndrones. However, analyzing such imagery data to extract flood extent poses\nunique challenges due to the rich noise and shadows, obstacles (e.g., tree\ncanopies, clouds), and spectral confusion between pixel classes (flood, dry)\ndue to spatial heterogeneity. Existing machine learning techniques often focus\non spectral and spatial features from raster images without fully incorporating\nthe geographic terrain within classification models. In contrast, we recently\nproposed a novel machine learning model called geographical hidden Markov tree\nthat integrates spectral features of pixels and topographic constraints from\nDigital Elevation Model (DEM) data (i.e., water flow directions) in a holistic\nmanner. This paper evaluates the model through case studies on high-resolution\naerial imagery from the National Oceanic and Atmospheric Administration (NOAA)\nNational Geodetic Survey together with DEM. Three scenes are selected in\nheavily vegetated floodplains near the cities of Grimesland and Kinston in\nNorth Carolina during Hurricane Matthew floods in 2016. Results show that the\nproposed hidden Markov tree model outperforms several state of the art machine\nlearning algorithms (e.g., random forests, gradient boosted model) by an\nimprovement of F-score (the harmonic mean of the user's accuracy and producer's\naccuracy) from around 70% to 80% to over 95% on our datasets.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 18:35:28 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 22:40:58 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Jiang", "Zhe", ""], ["Sainju", "Arpan Man", ""]]}, {"id": "2008.11244", "submitter": "Xavier Garcia", "authors": "Xavier Garcia and Adrian Rodriguez-Herrera", "title": "Machine learning applied in the multi-scale 3D stress modelling", "comments": "15 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a methodology to estimate stress in the subsurface by a\nhybrid method combining finite element modeling and neural networks. This\nmethodology exploits the idea of obtaining a multi-frequency solution in the\nnumerical modeling of systems whose behavior involves a wide span of length\nscales. One low-frequency solution is obtained via inexpensive finite element\nmodeling at a coarse scale. The second solution provides the fine-grained\ndetails introduced by the heterogeneity of the free parameters at the fine\nscale. This high-frequency solution is estimated via neural networks -trained\nwith partial solutions obtained in high-resolution finite-element models. When\nthe coarse finite element solutions are combined with the neural network\nestimates, the results are within a 2\\% error of the results that would be\ncomputed with high-resolution finite element models. This paper discusses the\nbenefits and drawbacks of the method and illustrates their applicability via a\nworked example.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 19:17:38 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Garcia", "Xavier", ""], ["Rodriguez-Herrera", "Adrian", ""]]}, {"id": "2008.11245", "submitter": "Sam Buchanan", "authors": "Sam Buchanan, Dar Gilboa, John Wright", "title": "Deep Networks and the Multiple Manifold Problem", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the multiple manifold problem, a binary classification task modeled\non applications in machine vision, in which a deep fully-connected neural\nnetwork is trained to separate two low-dimensional submanifolds of the unit\nsphere. We provide an analysis of the one-dimensional case, proving for a\nsimple manifold configuration that when the network depth $L$ is large relative\nto certain geometric and statistical properties of the data, the network width\n$n$ grows as a sufficiently large polynomial in $L$, and the number of i.i.d.\nsamples from the manifolds is polynomial in $L$, randomly-initialized gradient\ndescent rapidly learns to classify the two manifolds perfectly with high\nprobability. Our analysis demonstrates concrete benefits of depth and width in\nthe context of a practically-motivated model problem: the depth acts as a\nfitting resource, with larger depths corresponding to smoother networks that\ncan more readily separate the class manifolds, and the width acts as a\nstatistical resource, enabling concentration of the randomly-initialized\nnetwork and its gradients. The argument centers around the neural tangent\nkernel and its role in the nonasymptotic analysis of training overparameterized\nneural networks; to this literature, we contribute essentially optimal rates of\nconcentration for the neural tangent kernel of deep fully-connected networks,\nrequiring width $n \\gtrsim L\\,\\mathrm{poly}(d_0)$ to achieve uniform\nconcentration of the initial kernel over a $d_0$-dimensional submanifold of the\nunit sphere $\\mathbb{S}^{n_0-1}$, and a nonasymptotic framework for\nestablishing generalization of networks trained in the NTK regime with\nstructured data. The proof makes heavy use of martingale concentration to\noptimally treat statistical dependencies across layers of the initial random\nnetwork. This approach should be of use in establishing similar results for\nother network architectures.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 19:20:00 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 06:55:39 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Buchanan", "Sam", ""], ["Gilboa", "Dar", ""], ["Wright", "John", ""]]}, {"id": "2008.11249", "submitter": "Elena Khusainova", "authors": "Elena Khusainova, Emily Dodwell, Ritwik Mitra", "title": "SOAR: Simultaneous Or of And Rules for Classification of Positive &\n  Negative Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic decision making has proliferated and now impacts our daily lives\nin both mundane and consequential ways. Machine learning practitioners make use\nof a myriad of algorithms for predictive models in applications as diverse as\nmovie recommendations, medical diagnoses, and parole recommendations without\ndelving into the reasons driving specific predictive decisions. Machine\nlearning algorithms in such applications are often chosen for their superior\nperformance, however popular choices such as random forest and deep neural\nnetworks fail to provide an interpretable understanding of the predictive\nmodel. In recent years, rule-based algorithms have been used to address this\nissue. Wang et al. (2017) presented an or-of-and (disjunctive normal form)\nbased classification technique that allows for classification rule mining of a\nsingle class in a binary classification; this method is also shown to perform\ncomparably to other modern algorithms. In this work, we extend this idea to\nprovide classification rules for both classes simultaneously. That is, we\nprovide a distinct set of rules for both positive and negative classes. In\ndescribing this approach, we also present a novel and complete taxonomy of\nclassifications that clearly capture and quantify the inherent ambiguity in\nnoisy binary classifications in the real world. We show that this approach\nleads to a more granular formulation of the likelihood model and a\nsimulated-annealing based optimization achieves classification performance\ncompetitive with comparable techniques. We apply our method to synthetic as\nwell as real world data sets to compare with other related methods that\ndemonstrate the utility of our proposal.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 20:00:27 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 00:24:04 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Khusainova", "Elena", ""], ["Dodwell", "Emily", ""], ["Mitra", "Ritwik", ""]]}, {"id": "2008.11269", "submitter": "Zhe Jiang", "authors": "Wenchong He, Arpan Man Sainju, Zhe Jiang and Da Yan", "title": "Deep Neural Network for 3D Surface Segmentation based on Contour Tree\n  Hierarchy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a 3D surface defined by an elevation function on a 2D grid as well as\nnon-spatial features observed at each pixel, the problem of surface\nsegmentation aims to classify pixels into contiguous classes based on both\nnon-spatial features and surface topology. The problem has important\napplications in hydrology, planetary science, and biochemistry but is uniquely\nchallenging for several reasons. First, the spatial extent of class segments\nfollows surface contours in the topological space, regardless of their spatial\nshapes and directions. Second, the topological structure exists in multiple\nspatial scales based on different surface resolutions. Existing widely\nsuccessful deep learning models for image segmentation are often not applicable\ndue to their reliance on convolution and pooling operations to learn regular\nstructural patterns on a grid. In contrast, we propose to represent surface\ntopological structure by a contour tree skeleton, which is a polytree capturing\nthe evolution of surface contours at different elevation levels. We further\ndesign a graph neural network based on the contour tree hierarchy to model\nsurface topological structure at different spatial scales. Experimental\nevaluations based on real-world hydrological datasets show that our model\noutperforms several baseline methods in classification accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 20:54:27 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["He", "Wenchong", ""], ["Sainju", "Arpan Man", ""], ["Jiang", "Zhe", ""], ["Yan", "Da", ""]]}, {"id": "2008.11273", "submitter": "Xi-Lin Li", "authors": "Xi-Lin Li", "title": "Independent Vector Analysis with Deep Neural Network Source Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the density priors for independent vector analysis (IVA)\nwith convolutive speech mixture separation as the exemplary application. Most\nexisting source priors for IVA are too simplified to capture the fine\nstructures of speeches. Here, we first time show that it is possible to\nefficiently estimate the derivative of speech density with universal\napproximators like deep neural networks (DNN) by optimizing certain proxy\nseparation related performance indices. Experimental results suggest that the\nresultant neural network density priors consistently outperform previous ones\nin convergence speed for online implementation and signal-to-interference ratio\n(SIR) for batch implementation.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 17:13:55 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 17:43:06 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Li", "Xi-Lin", ""]]}, {"id": "2008.11278", "submitter": "Yi Li", "authors": "Yi Li, Jing Lin, and Kaiqi Xiong", "title": "An Adversarial Attack Defending System for Securing In-Vehicle Networks", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In a modern vehicle, there are over seventy Electronics Control Units (ECUs).\nFor an in-vehicle network, ECUs communicate with each other by following a\nstandard communication protocol, such as Controller Area Network (CAN).\nHowever, an attacker can easily access the in-vehicle network to compromise\nECUs through a WLAN or Bluetooth. Though there are various deep learning (DL)\nmethods suggested for securing in-vehicle networks, recent studies on\nadversarial examples have shown that attackers can easily fool DL models. In\nthis research, we further explore adversarial examples in an in-vehicle\nnetwork. We first discover and implement two adversarial attack models that are\nharmful to a Long Short Term Memory (LSTM)-based detection model used in the\nin-vehicle network. Then, we propose an Adversarial Attack Defending System\n(AADS) for securing an in-vehicle network. Specifically, we focus on\nbrake-related ECUs in an in-vehicle network. Our experimental results\ndemonstrate that adversaries can easily attack the LSTM-based detection model\nwith a success rate of over 98%, and the proposed AADS achieves over 99%\naccuracy for detecting adversarial attacks.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 21:23:49 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 17:19:09 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Li", "Yi", ""], ["Lin", "Jing", ""], ["Xiong", "Kaiqi", ""]]}, {"id": "2008.11281", "submitter": "Dimitris Stripelis", "authors": "Dimitris Stripelis and Jose Luis Ambite", "title": "Accelerating Federated Learning in Heterogeneous Data and Computational\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are situations where data relevant to a machine learning problem are\ndistributed among multiple locations that cannot share the data due to\nregulatory, competitiveness, or privacy reasons. For example, data present in\nusers' cellphones, manufacturing data of companies in a given industrial\nsector, or medical records located at different hospitals. Moreover,\nparticipating sites often have different data distributions and computational\ncapabilities. Federated Learning provides an approach to learn a joint model\nover all the available data in these environments. In this paper, we introduce\na novel distributed validation weighting scheme (DVW), which evaluates the\nperformance of a learner in the federation against a distributed validation\nset. Each learner reserves a small portion (e.g., 5%) of its local training\nexamples as a validation dataset and allows other learners models to be\nevaluated against it. We empirically show that DVW results in better\nperformance compared to established methods, such as FedAvg, both under\nsynchronous and asynchronous communication protocols in data and\ncomputationally heterogeneous environments.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 21:28:38 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Stripelis", "Dimitris", ""], ["Ambite", "Jose Luis", ""]]}, {"id": "2008.11282", "submitter": "Andrew Wentzel", "authors": "Andrew Wentzel, Guadalupe Canahuate, Lisanne van Dijk, Abdallah\n  Mohamed, Clifton David Fuller, G.Elisabeta Marai", "title": "Explainable Spatial Clustering: Leveraging Spatial Data in Radiation\n  Oncology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in data collection in radiation therapy have led to an abundance of\nopportunities for applying data mining and machine learning techniques to\npromote new data-driven insights. In light of these advances, supporting\ncollaboration between machine learning experts and clinicians is important for\nfacilitating better development and adoption of these models. Although many\nmedical use-cases rely on spatial data, where understanding and visualizing the\nunderlying structure of the data is important, little is known about the\ninterpretability of spatial clustering results by clinical audiences. In this\nwork, we reflect on the design of visualizations for explaining novel\napproaches to clustering complex anatomical data from head and neck cancer\npatients. These visualizations were developed, through participatory design,\nfor clinical audiences during a multi-year collaboration with radiation\noncologists and statisticians. We distill this collaboration into a set of\nlessons learned for creating visual and explainable spatial clustering for\nclinical users.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 21:31:41 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 21:38:25 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Wentzel", "Andrew", ""], ["Canahuate", "Guadalupe", ""], ["van Dijk", "Lisanne", ""], ["Mohamed", "Abdallah", ""], ["Fuller", "Clifton David", ""], ["Marai", "G. Elisabeta", ""]]}, {"id": "2008.11290", "submitter": "Athar Sefid", "authors": "Athar Sefid, Clyde Lee Giles, Prasenjit Mitra", "title": "Extractive Summarizer for Scholarly Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an extractive method that will summarize long scientific papers.\nOur model uses presentation slides provided by the authors of the papers as the\ngold summary standard to label the sentences. The sentences are ranked based on\ntheir novelty and their importance as estimated by deep neural networks. Our\nwindow-based extractive labeling of sentences results in the improvement of at\nleast 4 ROUGE1-Recall points.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 22:08:34 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Sefid", "Athar", ""], ["Giles", "Clyde Lee", ""], ["Mitra", "Prasenjit", ""]]}, {"id": "2008.11297", "submitter": "Malik Boudiaf", "authors": "Malik Boudiaf, Ziko Imtiaz Masud, J\\'er\\^ome Rony, Jos\\'e Dolz, Pablo\n  Piantanida, Ismail Ben Ayed", "title": "Transductive Information Maximization For Few-Shot Learning", "comments": "NeurIPS 2020. Code available at https://github.com/mboudiaf/TIM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Transductive Infomation Maximization (TIM) for few-shot\nlearning. Our method maximizes the mutual information between the query\nfeatures and their label predictions for a given few-shot task, in conjunction\nwith a supervision loss based on the support set. Furthermore, we propose a new\nalternating-direction solver for our mutual-information loss, which\nsubstantially speeds up transductive-inference convergence over gradient-based\noptimization, while yielding similar accuracy. TIM inference is modular: it can\nbe used on top of any base-training feature extractor. Following standard\ntransductive few-shot settings, our comprehensive experiments demonstrate that\nTIM outperforms state-of-the-art methods significantly across various datasets\nand networks, while used on top of a fixed feature extractor trained with\nsimple cross-entropy on the base classes, without resorting to complex\nmeta-learning schemes. It consistently brings between 2% and 5% improvement in\naccuracy over the best performing method, not only on all the well-established\nfew-shot benchmarks but also on more challenging scenarios,with domain shifts\nand larger numbers of classes.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 22:38:41 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 02:43:51 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 17:36:19 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Boudiaf", "Malik", ""], ["Masud", "Ziko Imtiaz", ""], ["Rony", "J\u00e9r\u00f4me", ""], ["Dolz", "Jos\u00e9", ""], ["Piantanida", "Pablo", ""], ["Ayed", "Ismail Ben", ""]]}, {"id": "2008.11300", "submitter": "Fu Lin", "authors": "Fu Lin, Rohit Mittapalli, Prithvijit Chattopadhyay, Daniel Bolya, Judy\n  Hoffman", "title": "Likelihood Landscapes: A Unifying Principle Behind Many Adversarial\n  Defenses", "comments": "ECCV 2020 Workshop on Adversarial Robustness in the Real World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks have been shown to be vulnerable to adversarial\nexamples, which are known to locate in subspaces close to where normal data\nlies but are not naturally occurring and of low probability. In this work, we\ninvestigate the potential effect defense techniques have on the geometry of the\nlikelihood landscape - likelihood of the input images under the trained model.\nWe first propose a way to visualize the likelihood landscape leveraging an\nenergy-based model interpretation of discriminative classifiers. Then we\nintroduce a measure to quantify the flatness of the likelihood landscape. We\nobserve that a subset of adversarial defense techniques results in a similar\neffect of flattening the likelihood landscape. We further explore directly\nregularizing towards a flat landscape for adversarial robustness.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 22:51:51 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Lin", "Fu", ""], ["Mittapalli", "Rohit", ""], ["Chattopadhyay", "Prithvijit", ""], ["Bolya", "Daniel", ""], ["Hoffman", "Judy", ""]]}, {"id": "2008.11329", "submitter": "Alan Chan", "authors": "Alan Chan, Kris de Asis, Richard S. Sutton", "title": "Inverse Policy Evaluation for Value-based Sequential Decision-making", "comments": "Submitted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value-based methods for reinforcement learning lack generally applicable ways\nto derive behavior from a value function. Many approaches involve approximate\nvalue iteration (e.g., $Q$-learning), and acting greedily with respect to the\nestimates with an arbitrary degree of entropy to ensure that the state-space is\nsufficiently explored. Behavior based on explicit greedification assumes that\nthe values reflect those of \\textit{some} policy, over which the greedy policy\nwill be an improvement. However, value-iteration can produce value functions\nthat do not correspond to \\textit{any} policy. This is especially relevant in\nthe function-approximation regime, when the true value function can't be\nperfectly represented. In this work, we explore the use of \\textit{inverse\npolicy evaluation}, the process of solving for a likely policy given a value\nfunction, for deriving behavior from a value function. We provide theoretical\nand empirical results to show that inverse policy evaluation, combined with an\napproximate value iteration algorithm, is a feasible method for value-based\ncontrol.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 01:31:38 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Chan", "Alan", ""], ["de Asis", "Kris", ""], ["Sutton", "Richard S.", ""]]}, {"id": "2008.11331", "submitter": "Yuan Xue", "authors": "Jiarong Ye, Yuan Xue, L. Rodney Long, Sameer Antani, Zhiyun Xue, Keith\n  Cheng, Xiaolei Huang", "title": "Synthetic Sample Selection via Reinforcement Learning", "comments": "MICCAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthesizing realistic medical images provides a feasible solution to the\nshortage of training data in deep learning based medical image recognition\nsystems. However, the quality control of synthetic images for data augmentation\npurposes is under-investigated, and some of the generated images are not\nrealistic and may contain misleading features that distort data distribution\nwhen mixed with real images. Thus, the effectiveness of those synthetic images\nin medical image recognition systems cannot be guaranteed when they are being\nadded randomly without quality assurance. In this work, we propose a\nreinforcement learning (RL) based synthetic sample selection method that learns\nto choose synthetic images containing reliable and informative features. A\ntransformer based controller is trained via proximal policy optimization (PPO)\nusing the validation classification accuracy as the reward. The selected images\nare mixed with the original training data for improved training of image\nrecognition systems. To validate our method, we take the pathology image\nrecognition as an example and conduct extensive experiments on two\nhistopathology image datasets. In experiments on a cervical dataset and a lymph\nnode dataset, the image classification performance is improved by 8.1% and\n2.3%, respectively, when utilizing high-quality synthetic images selected by\nour RL framework. Our proposed synthetic sample selection method is general and\nhas great potential to boost the performance of various medical image\nrecognition systems given limited annotation.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 01:34:19 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Ye", "Jiarong", ""], ["Xue", "Yuan", ""], ["Long", "L. Rodney", ""], ["Antani", "Sameer", ""], ["Xue", "Zhiyun", ""], ["Cheng", "Keith", ""], ["Huang", "Xiaolei", ""]]}, {"id": "2008.11332", "submitter": "Izumi Karino", "authors": "Izumi Karino, Yoshiyuki Ohmura, Yasuo Kuniyoshi", "title": "Identifying Critical States by the Action-Based Variance of Expected\n  Return", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": "10.1007/978-3-030-61609-0_29", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The balance of exploration and exploitation plays a crucial role in\naccelerating reinforcement learning (RL). To deploy an RL agent in human\nsociety, its explainability is also essential. However, basic RL approaches\nhave difficulties in deciding when to choose exploitation as well as in\nextracting useful points for a brief explanation of its operation. One reason\nfor the difficulties is that these approaches treat all states the same way.\nHere, we show that identifying critical states and treating them specially is\ncommonly beneficial to both problems. These critical states are the states at\nwhich the action selection changes the potential of success and failure\nsubstantially. We propose to identify the critical states using the variance in\nthe Q-function for the actions and to perform exploitation with high\nprobability on the identified states. These simple methods accelerate RL in a\ngrid world with cliffs and two baseline tasks of deep RL. Our results also\ndemonstrate that the identified critical states are intuitively interpretable\nregarding the crucial nature of the action selection. Furthermore, our analysis\nof the relationship between the timing of the identification of especially\ncritical states and the rapid progress of learning suggests there are a few\nespecially critical states that have important information for accelerating RL\nrapidly.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 01:38:58 GMT"}, {"version": "v2", "created": "Sun, 8 Nov 2020 10:54:34 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Karino", "Izumi", ""], ["Ohmura", "Yoshiyuki", ""], ["Kuniyoshi", "Yasuo", ""]]}, {"id": "2008.11340", "submitter": "Federico Larroca", "authors": "Antonio Bracco, Federico Grunwald, Agustin Navcevich, Germ\\'an\n  Capdehourat, Federico Larroca", "title": "Museum Accessibility Through Wi-Fi Indoor Positioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accessibility has long been a primary concern for major museums around the\nworld. This is no exception for the Museo Nacional de Artes Visuales (MNAV,\nNational Museum of Visual Arts) in Uruguay. Having a special interest in\nachieving accessibility for visually impaired visitors, the MNAV sought to\nimplement a new system to allow these visitors a seamless tour around a new\nexhibit. We present here the system we developed and the lessons we learned\nfrom its deployment and usage. In particular, we used Wi-Fi indoor positioning\ntechniques, so that visually impaired visitors could hear relevant audios\nthrough an Android app from their own smartphones based on their location\ninside the museum. The system was further adapted and used to assist the\ngeneral public during their visits, allowing access to texts, audios and images\naccording to their position. We furthermore share the complete source code and\nthe dataset used to train the system.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 02:10:16 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Bracco", "Antonio", ""], ["Grunwald", "Federico", ""], ["Navcevich", "Agustin", ""], ["Capdehourat", "Germ\u00e1n", ""], ["Larroca", "Federico", ""]]}, {"id": "2008.11343", "submitter": "Hanlin Tang", "authors": "Hanlin Tang, Shaoduo Gan, Samyam Rajbhandari, Xiangru Lian, Ji Liu,\n  Yuxiong He, Ce Zhang", "title": "APMSqueeze: A Communication Efficient Adam-Preconditioned Momentum SGD\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adam is the important optimization algorithm to guarantee efficiency and\naccuracy for training many important tasks such as BERT and ImageNet. However,\nAdam is generally not compatible with information (gradient) compression\ntechnology. Therefore, the communication usually becomes the bottleneck for\nparallelizing Adam. In this paper, we propose a communication efficient {\\bf\nA}DAM {\\bf p}reconditioned {\\bf M}omentum SGD algorithm-- named APMSqueeze--\nthrough an error compensated method compressing gradients. The proposed\nalgorithm achieves a similar convergence efficiency to Adam in term of epochs,\nbut significantly reduces the running time per epoch. In terms of end-to-end\nperformance (including the full-precision pre-condition step), APMSqueeze is\nable to provide {sometimes by up to $2-10\\times$ speed-up depending on network\nbandwidth.} We also conduct theoretical analysis on the convergence and\nefficiency.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 02:20:23 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 03:59:08 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Tang", "Hanlin", ""], ["Gan", "Shaoduo", ""], ["Rajbhandari", "Samyam", ""], ["Lian", "Xiangru", ""], ["Liu", "Ji", ""], ["He", "Yuxiong", ""], ["Zhang", "Ce", ""]]}, {"id": "2008.11348", "submitter": "Shisheng Cui", "authors": "Shisheng Cui and Uday V. Shanbhag", "title": "Variance-Reduced Proximal and Splitting Schemes for Monotone Stochastic\n  Generalized Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider monotone inclusion problems where the operators may be\nexpectation-valued. A direct application of proximal and splitting schemes is\ncomplicated by resolving problems with expectation-valued maps at each step, a\nconcern that is addressed by using sampling. Accordingly, we propose avenues\nfor addressing uncertainty in the mapping. (i) Variance-reduced stochastic\nproximal point method (vr-SPP). We develop amongst the first variance-reduced\nstochastic proximal-point schemes that achieves deterministic rates of\nconvergence in terms of solving proximal-point problems. In addition, it is\nshown that the schemes are characterized by either optimal or near-optimal\noracle (or sample) complexity guarantees. Finally, the generated sequences are\nshown to be convergent to a solution in an almost-sure sense in both monotone\nand strongly monotone regimes; (ii) Variance-reduced stochastic modified\nforward-backward splitting scheme (vr-SMFBS). In constrained settings, we\nconsider structured settings when the map can be decomposed into an\nexpectation-valued map $A$ and a maximal monotone map $B$ with a tractable\nresolvent. Akin to (i), we show that the proposed schemes are equipped with\na.s. convergence guarantees, linear (strongly monotone $A$) and\n$\\mathcal{O}(1/k)$ (monotone $A$) rates of convergence while achieving optimal\noracle complexity bounds. Of these, the rate statements in monotone regimes\nrely on leveraging the Fitzpatrick gap function for monotone inclusions.\nFurthermore, the schemes rely on weaker moment requirements on noise as well as\nallow for weakening unbiasedness requirements on oracles in strongly monotone\nregimes. Preliminary numerics reflect these findings and show that the\nvariance-reduced schemes outperform stochastic approximation schemes,\nstochastic splitting and proximal point schemes, and sample-average\napproximation approaches.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 02:33:27 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 00:28:38 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Cui", "Shisheng", ""], ["Shanbhag", "Uday V.", ""]]}, {"id": "2008.11350", "submitter": "Maythem Abbas", "authors": "Maythem K. Abbas, Mohd Noh Karsiti, Madzlan Napiah, Samir Brahim", "title": "Integrated Self-Organized Traffic Light Controllers for Signalized\n  Intersections", "comments": null, "journal-ref": "International Review of Automatic Control 2013", "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting emergency vehicles arrival on roads has been the focus for many\nresearchers. It is quite important to detect the emergency vehicles (e.g;\nambulance) arrival to traffic light to give the green light for it to pass\nthrough. Many researchers have suggested and patented emergency vehicles\ndetection systems however, according to our knowledge, none of them considered\nsolving the effect of giving extra green time to a road while the queues are\nbeing built on others. This paper considers the problem of finding a better\ntraffic light phase plan to stabilize/recover the situation at an effected\nintersection after solving an emergency vehicle existence. A hardware setup and\na novel messaging protocol have been suggested to be set on roads and vehicles\nto collect roads real time data. In addition, a novel decision making protocol\nhas been created to make the use of the collected data for making a better\ntraffic light phase plan for an intersection. The phase plan has two main\ndecisions to be made; which light has a higher priority to be green in the next\nphase, and how long the green phase should be. After simulating the proposed\nsystem using our customized simulator written in Matlab programing language and\ncomparing its performance with other related works, significant enhancements\nhave been observed in terms of stabilizing the queue lengths at an intersection\nafter solving an emergency case.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 02:41:46 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Abbas", "Maythem K.", ""], ["Karsiti", "Mohd Noh", ""], ["Napiah", "Madzlan", ""], ["Brahim", "Samir", ""]]}, {"id": "2008.11355", "submitter": "Fatemeh Ganji", "authors": "Fatemeh Ganji and Shahin Tajik", "title": "Physically Unclonable Functions and AI: Two Decades of Marriage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The current chapter aims at establishing a relationship between artificial\nintelligence (AI) and hardware security. Such a connection between AI and\nsoftware security has been confirmed and well-reviewed in the relevant\nliterature. The main focus here is to explore the methods borrowed from AI to\nassess the security of a hardware primitive, namely physically unclonable\nfunctions (PUFs), which has found applications in cryptographic protocols,\ne.g., authentication and key generation. Metrics and procedures devised for\nthis are further discussed. Moreover, By reviewing PUFs designed by applying AI\ntechniques, we give insight into future research directions in this area.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 02:53:40 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 16:32:35 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Ganji", "Fatemeh", ""], ["Tajik", "Shahin", ""]]}, {"id": "2008.11359", "submitter": "Yuwei Hu", "authors": "Yuwei Hu, Zihao Ye, Minjie Wang, Jiali Yu, Da Zheng, Mu Li, Zheng\n  Zhang, Zhiru Zhang, Yida Wang", "title": "FeatGraph: A Flexible and Efficient Backend for Graph Neural Network\n  Systems", "comments": "SC'20; changed all figures to type 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are gaining increasing popularity as a promising\napproach to machine learning on graphs. Unlike traditional graph workloads\nwhere each vertex/edge is associated with a scalar, GNNs attach a feature\ntensor to each vertex/edge. This additional feature dimension, along with\nconsequently more complex vertex- and edge-wise computations, has enormous\nimplications on locality and parallelism, which existing graph processing\nsystems fail to exploit.\n  This paper proposes FeatGraph to accelerate GNN workloads by co-optimizing\ngraph traversal and feature dimension computation. FeatGraph provides a\nflexible programming interface to express diverse GNN models by composing\ncoarse-grained sparse templates with fine-grained user-defined functions (UDFs)\non each vertex/edge. FeatGraph incorporates optimizations for graph traversal\ninto the sparse templates and allows users to specify optimizations for UDFs\nwith a feature dimension schedule (FDS). FeatGraph speeds up end-to-end GNN\ntraining and inference by up to 32x on CPU and 7x on GPU.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 03:17:05 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 17:36:15 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Hu", "Yuwei", ""], ["Ye", "Zihao", ""], ["Wang", "Minjie", ""], ["Yu", "Jiali", ""], ["Zheng", "Da", ""], ["Li", "Mu", ""], ["Zhang", "Zheng", ""], ["Zhang", "Zhiru", ""], ["Wang", "Yida", ""]]}, {"id": "2008.11363", "submitter": "Ilke Demir", "authors": "Umur Aybars Ciftci and Ilke Demir and Lijun Yin", "title": "How Do the Hearts of Deep Fakes Beat? Deep Fake Source Detection via\n  Interpreting Residuals with Biological Signals", "comments": "To be published in the proceedings of 2020 IEEE/IAPR International\n  Joint Conference on Biometrics (IJCB)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fake portrait video generation techniques have been posing a new threat to\nthe society with photorealistic deep fakes for political propaganda, celebrity\nimitation, forged evidences, and other identity related manipulations.\nFollowing these generation techniques, some detection approaches have also been\nproved useful due to their high classification accuracy. Nevertheless, almost\nno effort was spent to track down the source of deep fakes. We propose an\napproach not only to separate deep fakes from real videos, but also to discover\nthe specific generative model behind a deep fake. Some pure deep learning based\napproaches try to classify deep fakes using CNNs where they actually learn the\nresiduals of the generator. We believe that these residuals contain more\ninformation and we can reveal these manipulation artifacts by disentangling\nthem with biological signals. Our key observation yields that the\nspatiotemporal patterns in biological signals can be conceived as a\nrepresentative projection of residuals. To justify this observation, we extract\nPPG cells from real and fake videos and feed these to a state-of-the-art\nclassification network for detecting the generative model per video. Our\nresults indicate that our approach can detect fake videos with 97.29% accuracy,\nand the source model with 93.39% accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 03:35:47 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Ciftci", "Umur Aybars", ""], ["Demir", "Ilke", ""], ["Yin", "Lijun", ""]]}, {"id": "2008.11364", "submitter": "Yaoqing Yang", "authors": "Zhengming Zhang, Yaoqing Yang, Zhewei Yao, Yujun Yan, Joseph E.\n  Gonzalez, Michael W. Mahoney", "title": "Improving Semi-supervised Federated Learning by Reducing the Gradient\n  Diversity of Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a promising way to use the computing power of\nmobile devices while maintaining the privacy of users. Current work in FL,\nhowever, makes the unrealistic assumption that the users have ground-truth\nlabels on their devices, while also assuming that the server has neither data\nnor labels. In this work, we consider the more realistic scenario where the\nusers have only unlabeled data, while the server has some labeled data, and\nwhere the amount of labeled data is smaller than the amount of unlabeled data.\nWe call this learning problem semi-supervised federated learning (SSFL). For\nSSFL, we demonstrate that a critical issue that affects the test accuracy is\nthe large gradient diversity of the models from different users. Based on this,\nwe investigate several design choices. First, we find that the so-called\nconsistency regularization loss (CRL), which is widely used in semi-supervised\nlearning, performs reasonably well but has large gradient diversity. Second, we\nfind that Batch Normalization (BN) increases gradient diversity. Replacing BN\nwith the recently-proposed Group Normalization (GN) can reduce gradient\ndiversity and improve test accuracy. Third, we show that CRL combined with GN\nstill has a large gradient diversity when the number of users is large. Based\non these results, we propose a novel grouping-based model averaging method to\nreplace the FedAvg averaging method. Overall, our grouping-based averaging,\ncombined with GN and CRL, achieves better test accuracy than not just a\ncontemporary paper on SSFL in the same settings (>10\\%), but also four\nsupervised FL algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 03:36:07 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 04:03:44 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Zhang", "Zhengming", ""], ["Yang", "Yaoqing", ""], ["Yao", "Zhewei", ""], ["Yan", "Yujun", ""], ["Gonzalez", "Joseph E.", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2008.11370", "submitter": "Bogdan Petrenko V.", "authors": "Chad Kelterborn, Marcin Mazur, and Bogdan V. Petrenko", "title": "Gravilon: Applications of a New Gradient Descent Method to Machine\n  Learning", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent algorithms have been used in countless applications since\nthe inception of Newton's method. The explosion in the number of applications\nof neural networks has re-energized efforts in recent years to improve the\nstandard gradient descent method in both efficiency and accuracy. These methods\nmodify the effect of the gradient in updating the values of the parameters.\nThese modifications often incorporate hyperparameters: additional variables\nwhose values must be specified at the outset of the program. We provide, below,\na novel gradient descent algorithm, called Gravilon, that uses the geometry of\nthe hypersurface to modify the length of the step in the direction of the\ngradient. Using neural networks, we provide promising experimental results\ncomparing the accuracy and efficiency of the Gravilon method against commonly\nused gradient descent algorithms on MNIST digit classification.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 04:02:02 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 19:15:31 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Kelterborn", "Chad", ""], ["Mazur", "Marcin", ""], ["Petrenko", "Bogdan V.", ""]]}, {"id": "2008.11376", "submitter": "Raha Moraffah", "authors": "Raha Moraffah, Bahman Moraffah, Mansooreh Karami, Adrienne Raglin,\n  Huan Liu", "title": "Causal Adversarial Network for Learning Conditional and Interventional\n  Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generative Causal Adversarial Network (CAN) for learning and\nsampling from conditional and interventional distributions. In contrast to the\nexisting CausalGAN which requires the causal graph to be given, our proposed\nframework learns the causal relations from the data and generates samples\naccordingly. The proposed CAN comprises a two-fold process namely Label\nGeneration Network (LGN) and Conditional Image Generation Network (CIGN). The\nLGN is a GAN-based architecture which learns and samples from the causal model\nover labels. The sampled labels are then fed to CIGN, a conditional GAN\narchitecture, which learns the relationships amongst labels and pixels and\npixels themselves and generates samples based on them. This framework is\nequipped with an intervention mechanism which enables. the model to generate\nsamples from interventional distributions. We quantitatively and qualitatively\nassess the performance of CAN and empirically show that our model is able to\ngenerate both interventional and conditional samples without having access to\nthe causal graph for the application of face generation on CelebA data.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 05:08:38 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 19:14:03 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Moraffah", "Raha", ""], ["Moraffah", "Bahman", ""], ["Karami", "Mansooreh", ""], ["Raglin", "Adrienne", ""], ["Liu", "Huan", ""]]}, {"id": "2008.11384", "submitter": "Yiliang Zhang", "authors": "Li Zeng, Zhaolong Yu, Yiliang Zhang, Hongyu Zhao", "title": "A general kernel boosting framework integrating pathways for predictive\n  modeling based on genomic data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive modeling based on genomic data has gained popularity in biomedical\nresearch and clinical practice by allowing researchers and clinicians to\nidentify biomarkers and tailor treatment decisions more efficiently. Analysis\nincorporating pathway information can boost discovery power and better connect\nnew findings with biological mechanisms. In this article, we propose a general\nframework, Pathway-based Kernel Boosting (PKB), which incorporates clinical\ninformation and prior knowledge about pathways for prediction of binary,\ncontinuous and survival outcomes. We introduce appropriate loss functions and\noptimization procedures for different outcome types. Our prediction algorithm\nincorporates pathway knowledge by constructing kernel function spaces from the\npathways and use them as base learners in the boosting procedure. Through\nextensive simulations and case studies in drug response and cancer survival\ndatasets, we demonstrate that PKB can substantially outperform other competing\nmethods, better identify biological pathways related to drug response and\npatient survival, and provide novel insights into cancer pathogenesis and\ntreatment response.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 05:54:23 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 22:56:33 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Zeng", "Li", ""], ["Yu", "Zhaolong", ""], ["Zhang", "Yiliang", ""], ["Zhao", "Hongyu", ""]]}, {"id": "2008.11400", "submitter": "Flora D. Salim", "authors": "Manpreet Kaur, Flora D. Salim, Yongli Ren, Jeffrey Chan, Martin Tomko,\n  Mark Sanderson", "title": "Joint Modelling of Cyber Activities and Physical Context to Improve\n  Prediction of Visitor Behaviors", "comments": "Accepted in ACM Transactions on Sensor Networks, 2020", "journal-ref": "ACM Transactions on Sensor Networks, 2020", "doi": "10.1145/3393692", "report-no": null, "categories": "cs.IR cs.DC cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the Cyber-Physical behavior of users in a large\nindoor shopping mall by leveraging anonymized (opt in) Wi-Fi association and\nbrowsing logs recorded by the mall operators. Our analysis shows that many\nusers exhibit a high correlation between their cyber activities and their\nphysical context. To find this correlation, we propose a mechanism to\nsemantically label a physical space with rich categorical information from\nDBPedia concepts and compute a contextual similarity that represents a user's\nactivities with the mall context. We demonstrate the application of\ncyber-physical contextual similarity in two situations: user visit intent\nclassification and future location prediction. The experimental results\ndemonstrate that exploitation of contextual similarity significantly improves\nthe accuracy of such applications.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 06:37:43 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Kaur", "Manpreet", ""], ["Salim", "Flora D.", ""], ["Ren", "Yongli", ""], ["Chan", "Jeffrey", ""], ["Tomko", "Martin", ""], ["Sanderson", "Mark", ""]]}, {"id": "2008.11406", "submitter": "Darius Afchar", "authors": "Darius Afchar and Romain Hennequin", "title": "Making Neural Networks Interpretable with Attribution: Application to\n  Implicit Signals Prediction", "comments": "14th ACM Conference on Recommender Systems (RecSys '20)", "journal-ref": null, "doi": "10.1145/3383313.3412253", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining recommendations enables users to understand whether recommended\nitems are relevant to their needs and has been shown to increase their trust in\nthe system. More generally, if designing explainable machine learning models is\nkey to check the sanity and robustness of a decision process and improve their\nefficiency, it however remains a challenge for complex architectures,\nespecially deep neural networks that are often deemed \"black-box\". In this\npaper, we propose a novel formulation of interpretable deep neural networks for\nthe attribution task. Differently to popular post-hoc methods, our approach is\ninterpretable by design. Using masked weights, hidden features can be deeply\nattributed, split into several input-restricted sub-networks and trained as a\nboosted mixture of experts. Experimental results on synthetic data and\nreal-world recommendation tasks demonstrate that our method enables to build\nmodels achieving close predictive performances to their non-interpretable\ncounterparts, while providing informative attribution interpretations.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 06:46:49 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Afchar", "Darius", ""], ["Hennequin", "Romain", ""]]}, {"id": "2008.11416", "submitter": "Xu Chen", "authors": "Xu Chen and Ya Zhang and Ivor Tsang and Yuangang Pan", "title": "Learning Robust Node Representations on Graphs", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNN), as a popular methodology for node representation\nlearning on graphs, currently mainly focus on preserving the smoothness and\nidentifiability of node representations. A robust node representation on graphs\nshould further hold the stability property which means a node representation is\nresistant to slight perturbations on the input. In this paper, we introduce the\nstability of node representations in addition to the smoothness and\nidentifiability, and develop a novel method called contrastive graph neural\nnetworks (CGNN) that learns robust node representations in an unsupervised\nmanner. Specifically, CGNN maintains the stability and identifiability by a\ncontrastive learning objective, while preserving the smoothness with existing\nGNN models. Furthermore, the proposed method is a generic framework that can be\nequipped with many other backbone models (e.g. GCN, GraphSage and GAT).\nExtensive experiments on four benchmarks under both transductive and inductive\nlearning setups demonstrate the effectiveness of our method in comparison with\nrecent supervised and unsupervised models.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 07:11:01 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 03:04:42 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Chen", "Xu", ""], ["Zhang", "Ya", ""], ["Tsang", "Ivor", ""], ["Pan", "Yuangang", ""]]}, {"id": "2008.11421", "submitter": "Mohamed Wahib", "authors": "Mohamed Wahib, Haoyu Zhang, Truong Thao Nguyen, Aleksandr Drozd, Jens\n  Domke, Lingqi Zhang, Ryousei Takano, Satoshi Matsuoka", "title": "Scaling Distributed Deep Learning Workloads beyond the Memory Capacity\n  with KARMA", "comments": "ACM/IEEE Proceedings of the International Conference for High\n  Performance Computing, Networking, Storage and Analysis (SC'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dedicated memory of hardware accelerators can be insufficient to store\nall weights and/or intermediate states of large deep learning models. Although\nmodel parallelism is a viable approach to reduce the memory pressure issue,\nsignificant modification of the source code and considerations for algorithms\nare required. An alternative solution is to use out-of-core methods instead of,\nor in addition to, data parallelism. We propose a performance model based on\nthe concurrency analysis of out-of-core training behavior, and derive a\nstrategy that combines layer swapping and redundant recomputing. We achieve an\naverage of 1.52x speedup in six different models over the state-of-the-art\nout-of-core methods. We also introduce the first method to solve the\nchallenging problem of out-of-core multi-node training by carefully pipelining\ngradient exchanges and performing the parameter updates on the host. Our data\nparallel out-of-core solution can outperform complex hybrid model parallelism\nin training large models, e.g. Megatron-LM and Turning-NLG.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 07:24:34 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Wahib", "Mohamed", ""], ["Zhang", "Haoyu", ""], ["Nguyen", "Truong Thao", ""], ["Drozd", "Aleksandr", ""], ["Domke", "Jens", ""], ["Zhang", "Lingqi", ""], ["Takano", "Ryousei", ""], ["Matsuoka", "Satoshi", ""]]}, {"id": "2008.11426", "submitter": "Ozan Ozdenizci", "authors": "Mo Han, Ozan Ozdenizci, Ye Wang, Toshiaki Koike-Akino, Deniz Erdogmus", "title": "Disentangled Adversarial Autoencoder for Subject-Invariant Physiological\n  Feature Extraction", "comments": "Accepted for publication by IEEE Signal Processing Letters", "journal-ref": "IEEE Signal Processing Letters, 2020", "doi": "10.1109/LSP.2020.3020215", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in biosignal processing have enabled users to exploit\ntheir physiological status for manipulating devices in a reliable and safe\nmanner. One major challenge of physiological sensing lies in the variability of\nbiosignals across different users and tasks. To address this issue, we propose\nan adversarial feature extractor for transfer learning to exploit disentangled\nuniversal representations. We consider the trade-off between task-relevant\nfeatures and user-discriminative information by introducing additional\nadversary and nuisance networks in order to manipulate the latent\nrepresentations such that the learned feature extractor is applicable to\nunknown users and various tasks. Results on cross-subject transfer evaluations\nexhibit the benefits of the proposed framework, with up to 8.8% improvement in\naverage accuracy of classification, and demonstrate adaptability to a broader\nrange of subjects.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 07:45:24 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Han", "Mo", ""], ["Ozdenizci", "Ozan", ""], ["Wang", "Ye", ""], ["Koike-Akino", "Toshiaki", ""], ["Erdogmus", "Deniz", ""]]}, {"id": "2008.11432", "submitter": "Mar\\'ia N. Moreno Garc\\'ia", "authors": "Diego S\\'anchez-Moreno, Yong Zheng and Mar\\'ia N. Moreno-Garc\\'ia", "title": "Time-Aware Music Recommender Systems: Modeling the Evolution of Implicit\n  User Preferences and User Listening Habits in A Collaborative Filtering\n  Approach", "comments": null, "journal-ref": "Applied Sciences, 10(15), 5324, 33 pages, 2020", "doi": "10.3390/app10155324", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Online streaming services have become the most popular way of listening to\nmusic. The majority of these services are endowed with recommendation\nmechanisms that help users to discover songs and artists that may interest them\nfrom the vast amount of music available. However, many are not reliable as they\nmay not take into account contextual aspects or the ever-evolving user\nbehavior. Therefore, it is necessary to develop systems that consider these\naspects. In the field of music, time is one of the most important factors\ninfluencing user preferences and managing its effects, and is the motivation\nbehind the work presented in this paper. Here, the temporal information\nregarding when songs are played is examined. The purpose is to model both the\nevolution of user preferences in the form of evolving implicit ratings and user\nlistening behavior. In the collaborative filtering method proposed in this\nwork, daily listening habits are captured in order to characterize users and\nprovide them with more reliable recommendations. The results of the validation\nprove that this approach outperforms other methods in generating both\ncontext-aware and context-free recommendations\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 08:00:11 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["S\u00e1nchez-Moreno", "Diego", ""], ["Zheng", "Yong", ""], ["Moreno-Garc\u00eda", "Mar\u00eda N.", ""]]}, {"id": "2008.11433", "submitter": "Ajitabh Kumar", "authors": "Ajitabh Kumar", "title": "Uncertainty-Aware Surrogate Model For Oilfield Reservoir Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks have gained increased attention in machine learning, but\nthey are limited by the fact that many such regression and classification\nmodels do not capture prediction uncertainty. Though this might be acceptable\nfor certain non-critical applications, it is not so for oil and gas industry\napplications where business and economic consequences of wrong or even\nsub-optimal decision is quite high. In this work I discuss the application of\ndeep neural networks as a framework for approximate Bayesian inference in\noilfield reservoir simulation study. Surrogate models with different neural\nnetwork architecture are proposed to speed up compute- and labor-intensive\nsimulation workflow. Regularization tools such as dropout and batch\nnormalization, variational autoencoder for regression, and probabilistic\ndistribution layers are used to quantify prediction uncertainty. Monte-Carlo\ndropout approach is further applied to estimate uncertainty given by standard\ndeviation values for the predictions. Probabilistic distribution layers are\nused to compare its efficacy in capturing the model prediction uncertainty with\nrespect to deterministic neural layers. Deep ensemble approach is also used to\ntrain multiple surrogates which capture uncertainty. Among different models\ntested, VAE based regression model with multivariate-normal latent features\nworks best for prediction uncertainty assessment. Compute time required by\nsurrogate model for prediction is a small fraction of that for full-physics\nreservoir simulator. Prediction uncertainty information can be used in various\nsimulation workflows to decide when to use surrogate model and when to further\nexplore the solution space using reservoir simulator, thus reducing total\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 08:03:03 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Kumar", "Ajitabh", ""]]}, {"id": "2008.11440", "submitter": "Sungho Suh", "authors": "Sungho Suh, Paul Lukowicz and Yong Oh Lee", "title": "Fusion of Global-Local Features for Image Quality Inspection of Shipping\n  Label", "comments": "Accepted at ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The demands of automated shipping address recognition and verification have\nincreased to handle a large number of packages and to save costs associated\nwith misdelivery. A previous study proposed a deep learning system where the\nshipping address is recognized and verified based on a camera image capturing\nthe shipping address and barcode area. Because the system performance depends\non the input image quality, inspection of input image quality is necessary for\nimage preprocessing. In this paper, we propose an input image quality\nverification method combining global and local features. Object detection and\nscale-invariant feature transform in different feature spaces are developed to\nextract global and local features from several independent convolutional neural\nnetworks. The conditions of shipping label images are classified by fully\nconnected fusion layers with concatenated global and local features. The\nexperimental results regarding real captured and generated images show that the\nproposed method achieves better performance than other methods. These results\nare expected to improve the shipping address recognition and verification\nsystem by applying different image preprocessing steps based on the classified\nconditions.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 08:25:34 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Suh", "Sungho", ""], ["Lukowicz", "Paul", ""], ["Lee", "Yong Oh", ""]]}, {"id": "2008.11450", "submitter": "Jason Armitage", "authors": "Jason Armitage, Shramana Thakur, Rishi Tripathi, Jens Lehmann, and\n  Maria Maleshkova", "title": "Training Multimodal Systems for Classification with Multiple Objectives", "comments": null, "journal-ref": "Proceedings of the 1st International Workshop on Cross-lingual\n  Event-centric Open Analytics co-located with the 17th Extended Semantic Web\n  Conference (ESWC 2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We learn about the world from a diverse range of sensory information.\nAutomated systems lack this ability as investigation has centred on processing\ninformation presented in a single form. Adapting architectures to learn from\nmultiple modalities creates the potential to learn rich representations of the\nworld - but current multimodal systems only deliver marginal improvements on\nunimodal approaches. Neural networks learn sampling noise during training with\nthe result that performance on unseen data is degraded. This research\nintroduces a second objective over the multimodal fusion process learned with\nvariational inference. Regularisation methods are implemented in the inner\ntraining loop to control variance and the modular structure stabilises\nperformance as additional neurons are added to layers. This framework is\nevaluated on a multilabel classification task with textual and visual inputs to\ndemonstrate the potential for multiple objectives and probabilistic methods to\nlower variance and improve generalisation.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 09:05:40 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Armitage", "Jason", ""], ["Thakur", "Shramana", ""], ["Tripathi", "Rishi", ""], ["Lehmann", "Jens", ""], ["Maleshkova", "Maria", ""]]}, {"id": "2008.11463", "submitter": "Thilo Hagendorff", "authors": "Thilo Hagendorff", "title": "Ethical behavior in humans and machines -- Evaluating training data\n  quality for beneficial machine learning", "comments": "30 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine behavior that is based on learning algorithms can be significantly\ninfluenced by the exposure to data of different qualities. Up to now, those\nqualities are solely measured in technical terms, but not in ethical ones,\ndespite the significant role of training and annotation data in supervised\nmachine learning. This is the first study to fill this gap by describing new\ndimensions of data quality for supervised machine learning applications. Based\non the rationale that different social and psychological backgrounds of\nindividuals correlate in practice with different modes of\nhuman-computer-interaction, the paper describes from an ethical perspective how\nvarying qualities of behavioral data that individuals leave behind while using\ndigital technologies have socially relevant ramification for the development of\nmachine learning applications. The specific objective of this study is to\ndescribe how training data can be selected according to ethical assessments of\nthe behavior it originates from, establishing an innovative filter regime to\ntransition from the big data rationale n = all to a more selective way of\nprocessing data for training sets in machine learning. The overarching aim of\nthis research is to promote methods for achieving beneficial machine learning\napplications that could be widely useful for industry as well as academia.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 09:48:38 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Hagendorff", "Thilo", ""]]}, {"id": "2008.11478", "submitter": "Pengyi Zhang", "authors": "Pengyi Zhang, Yunxin Zhong, Yulin Deng, Xiaoying Tang, Xiaoqiong Li", "title": "DRR4Covid: Learning Automated COVID-19 Infection Segmentation from\n  Digitally Reconstructed Radiographs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automated infection measurement and COVID-19 diagnosis based on Chest X-ray\n(CXR) imaging is important for faster examination. We propose a novel approach,\ncalled DRR4Covid, to learn automated COVID-19 diagnosis and infection\nsegmentation on CXRs from digitally reconstructed radiographs (DRRs). DRR4Covid\ncomprises of an infection-aware DRR generator, a classification and/or\nsegmentation network, and a domain adaptation module. The infection-aware DRR\ngenerator is able to produce DRRs with adjustable strength of radiological\nsigns of COVID-19 infection, and generate pixel-level infection annotations\nthat match the DRRs precisely. The domain adaptation module is introduced to\nreduce the domain discrepancy between DRRs and CXRs by training networks on\nunlabeled real CXRs and labeled DRRs together.We provide a simple but effective\nimplementation of DRR4Covid by using a domain adaptation module based on\nMaximum Mean Discrepancy (MMD), and a FCN-based network with a classification\nheader and a segmentation header. Extensive experiment results have confirmed\nthe efficacy of our method; specifically, quantifying the performance by\naccuracy, AUC and F1-score, our network without using any annotations from CXRs\nhas achieved a classification score of (0.954, 0.989, 0.953) and a segmentation\nscore of (0.957, 0.981, 0.956) on a test set with 794 normal cases and 794\npositive cases. Besides, we estimate the sensitive of X-ray images in detecting\nCOVID-19 infection by adjusting the strength of radiological signs of COVID-19\ninfection in synthetic DRRs. The estimated detection limit of the proportion of\ninfected voxels in the lungs is 19.43%, and the estimated lower bound of the\ncontribution rate of infected voxels is 20.0% for significant radiological\nsigns of COVID-19 infection. Our codes will be made publicly available at\nhttps://github.com/PengyiZhang/DRR4Covid.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 10:34:45 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Zhang", "Pengyi", ""], ["Zhong", "Yunxin", ""], ["Deng", "Yulin", ""], ["Tang", "Xiaoying", ""], ["Li", "Xiaoqiong", ""]]}, {"id": "2008.11491", "submitter": "Sam Blakeman", "authors": "Sam Blakeman, Denis Mareschal", "title": "Selective Particle Attention: Visual Feature-Based Attention in Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human brain uses selective attention to filter perceptual input so that\nonly the components that are useful for behaviour are processed using its\nlimited computational resources. We focus on one particular form of visual\nattention known as feature-based attention, which is concerned with identifying\nfeatures of the visual input that are important for the current task regardless\nof their spatial location. Visual feature-based attention has been proposed to\nimprove the efficiency of Reinforcement Learning (RL) by reducing the\ndimensionality of state representations and guiding learning towards relevant\nfeatures. Despite achieving human level performance in complex perceptual-motor\ntasks, Deep RL algorithms have been consistently criticised for their poor\nefficiency and lack of flexibility. Visual feature-based attention therefore\nrepresents one option for addressing these criticisms. Nevertheless, it is\nstill an open question how the brain is able to learn which features to attend\nto during RL. To help answer this question we propose a novel algorithm, termed\nSelective Particle Attention (SPA), which imbues a Deep RL agent with the\nability to perform selective feature-based attention. SPA learns which\ncombinations of features to attend to based on their bottom-up saliency and how\naccurately they predict future reward. We evaluate SPA on a multiple choice\ntask and a 2D video game that both involve raw pixel input and dynamic changes\nto the task structure. We show various benefits of SPA over approaches that\nnaively attend to either all or random subsets of features. Our results\ndemonstrate (1) how visual feature-based attention in Deep RL models can\nimprove their learning efficiency and ability to deal with sudden changes in\ntask structure and (2) that particle filters may represent a viable\ncomputational account of how visual feature-based attention occurs in the\nbrain.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 11:07:50 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Blakeman", "Sam", ""], ["Mareschal", "Denis", ""]]}, {"id": "2008.11533", "submitter": "Xueyuan Han", "authors": "Xueyuan Han, Xiao Yu, Thomas Pasquier, Ding Li, Junghwan Rhee, James\n  Mickens, Margo Seltzer, Haifeng Chen", "title": "SIGL: Securing Software Installations Through Deep Graph Learning", "comments": "18 pages, to appear in the 30th USENIX Security Symposium (USENIX\n  Security '21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many users implicitly assume that software can only be exploited after it is\ninstalled. However, recent supply-chain attacks demonstrate that application\nintegrity must be ensured during installation itself. We introduce SIGL, a new\ntool for detecting malicious behavior during software installation. SIGL\ncollects traces of system call activity, building a data provenance graph that\nit analyzes using a novel autoencoder architecture with a graph long short-term\nmemory network (graph LSTM) for the encoder and a standard multilayer\nperceptron for the decoder. SIGL flags suspicious installations as well as the\nspecific installation-time processes that are likely to be malicious. Using a\ntest corpus of 625 malicious installers containing real-world malware, we\ndemonstrate that SIGL has a detection accuracy of 96%, outperforming similar\nsystems from industry and academia by up to 87% in precision and recall and 45%\nin accuracy. We also demonstrate that SIGL can pinpoint the processes most\nlikely to have triggered malicious behavior, works on different audit platforms\nand operating systems, and is robust to training data contamination and\nadversarial attack. It can be used with application-specific models, even in\nthe presence of new software versions, as well as application-agnostic\nmeta-models that encompass a wide range of applications and installers.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 12:52:34 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 23:29:44 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Han", "Xueyuan", ""], ["Yu", "Xiao", ""], ["Pasquier", "Thomas", ""], ["Li", "Ding", ""], ["Rhee", "Junghwan", ""], ["Mickens", "James", ""], ["Seltzer", "Margo", ""], ["Chen", "Haifeng", ""]]}, {"id": "2008.11546", "submitter": "Yu Li", "authors": "Yu Li", "title": "Towards Structured Prediction in Bioinformatics with Deep Learning", "comments": "PhD dissertatation", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using machine learning, especially deep learning, to facilitate biological\nresearch is a fascinating research direction. However, in addition to the\nstandard classification or regression problems, in bioinformatics, we often\nneed to predict more complex structured targets, such as 2D images and 3D\nmolecular structures. The above complex prediction tasks are referred to as\nstructured prediction. Structured prediction is more complicated than the\ntraditional classification but has much broader applications, considering that\nmost of the original bioinformatics problems have complex output objects. Due\nto the properties of those structured prediction problems, such as having\nproblem-specific constraints and dependency within the labeling space, the\nstraightforward application of existing deep learning models can lead to\nunsatisfactory results. Here, we argue that the following ideas can help\nresolve structured prediction problems in bioinformatics. Firstly, we can\ncombine deep learning with other classic algorithms, such as probabilistic\ngraphical models, which model the problem structure explicitly. Secondly, we\ncan design the problem-specific deep learning architectures or methods by\nconsidering the structured labeling space and problem constraints, either\nexplicitly or implicitly. We demonstrate our ideas with six projects from four\nbioinformatics subfields, including sequencing analysis, structure prediction,\nfunction annotation, and network analysis. The structured outputs cover 1D\nsignals, 2D images, 3D structures, hierarchical labeling, and heterogeneous\nnetworks. With the help of the above ideas, all of our methods can achieve SOTA\nperformance on the corresponding problems. The success of these projects\nmotivates us to extend our work towards other more challenging but important\nproblems, such as health-care problems, which can directly benefit people's\nhealth and wellness.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 02:52:18 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Li", "Yu", ""]]}, {"id": "2008.11560", "submitter": "Weiming Zhuang", "authors": "Weiming Zhuang, Yonggang Wen, Xuesen Zhang, Xin Gan, Daiying Yin,\n  Dongzhan Zhou, Shuai Zhang, Shuai Yi", "title": "Performance Optimization for Federated Person Re-identification via\n  Benchmark Analysis", "comments": "ACMMM'20", "journal-ref": null, "doi": "10.1145/3394171.3413814", "report-no": null, "categories": "cs.CV cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a privacy-preserving machine learning technique that\nlearns a shared model across decentralized clients. It can alleviate privacy\nconcerns of personal re-identification, an important computer vision task. In\nthis work, we implement federated learning to person re-identification\n(FedReID) and optimize its performance affected by statistical heterogeneity in\nthe real-world scenario. We first construct a new benchmark to investigate the\nperformance of FedReID. This benchmark consists of (1) nine datasets with\ndifferent volumes sourced from different domains to simulate the heterogeneous\nsituation in reality, (2) two federated scenarios, and (3) an enhanced\nfederated algorithm for FedReID. The benchmark analysis shows that the\nclient-edge-cloud architecture, represented by the federated-by-dataset\nscenario, has better performance than client-server architecture in FedReID. It\nalso reveals the bottlenecks of FedReID under the real-world scenario,\nincluding poor performance of large datasets caused by unbalanced weights in\nmodel aggregation and challenges in convergence. Then we propose two\noptimization methods: (1) To address the unbalanced weight problem, we propose\na new method to dynamically change the weights according to the scale of model\nchanges in clients in each training round; (2) To facilitate convergence, we\nadopt knowledge distillation to refine the server model with knowledge\ngenerated from client models on a public dataset. Experiment results\ndemonstrate that our strategies can achieve much better convergence with\nsuperior performance on all datasets. We believe that our work will inspire the\ncommunity to further explore the implementation of federated learning on more\ncomputer vision tasks in real-world scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 13:41:20 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 17:57:52 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Zhuang", "Weiming", ""], ["Wen", "Yonggang", ""], ["Zhang", "Xuesen", ""], ["Gan", "Xin", ""], ["Yin", "Daiying", ""], ["Zhou", "Dongzhan", ""], ["Zhang", "Shuai", ""], ["Yi", "Shuai", ""]]}, {"id": "2008.11567", "submitter": "Jieming Zhu", "authors": "Kelong Mao, Xi Xiao, Jieming Zhu, Biao Lu, Ruiming Tang, Xiuqiang He", "title": "Item Tagging for Information Retrieval: A Tripartite Graph Neural\n  Network based Approach", "comments": "Accepted by SIGIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tagging has been recognized as a successful practice to boost relevance\nmatching for information retrieval (IR), especially when items lack rich\ntextual descriptions. A lot of research has been done for either multi-label\ntext categorization or image annotation. However, there is a lack of published\nwork that targets at item tagging specifically for IR. Directly applying a\ntraditional multi-label classification model for item tagging is sub-optimal,\ndue to the ignorance of unique characteristics in IR. In this work, we propose\nto formulate item tagging as a link prediction problem between item nodes and\ntag nodes. To enrich the representation of items, we leverage the query logs\navailable in IR tasks, and construct a query-item-tag tripartite graph. This\nformulation results in a TagGNN model that utilizes heterogeneous graph neural\nnetworks with multiple types of nodes and edges. Different from previous\nresearch, we also optimize both full tag prediction and partial tag completion\ncases in a unified framework via a primary-dual loss mechanism. Experimental\nresults on both open and industrial datasets show that our TagGNN approach\noutperforms the state-of-the-art multi-label classification approaches.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 13:58:19 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Mao", "Kelong", ""], ["Xiao", "Xi", ""], ["Zhu", "Jieming", ""], ["Lu", "Biao", ""], ["Tang", "Ruiming", ""], ["He", "Xiuqiang", ""]]}, {"id": "2008.11572", "submitter": "Beatriz Garcia Santa Cruz", "authors": "Beatriz Garcia Santa Cruz, Jan S\\\"olter, Matias Nicolas Bossa and\n  Andreas Dominik Husch", "title": "On the Composition and Limitations of Publicly Available COVID-19 X-Ray\n  Imaging Datasets", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning based methods for diagnosis and progression prediction of\nCOVID-19 from imaging data have gained significant attention in the last\nmonths, in particular by the use of deep learning models. In this context\nhundreds of models where proposed with the majority of them trained on public\ndatasets. Data scarcity, mismatch between training and target population, group\nimbalance, and lack of documentation are important sources of bias, hindering\nthe applicability of these models to real-world clinical practice. Considering\nthat datasets are an essential part of model building and evaluation, a deeper\nunderstanding of the current landscape is needed. This paper presents an\noverview of the currently public available COVID-19 chest X-ray datasets. Each\ndataset is briefly described and potential strength, limitations and\ninteractions between datasets are identified. In particular, some key\nproperties of current datasets that could be potential sources of bias,\nimpairing models trained on them are pointed out. These descriptions are useful\nfor model building on those datasets, to choose the best dataset according the\nmodel goal, to take into account the specific limitations to avoid reporting\noverconfident benchmark results, and to discuss their impact on the\ngeneralisation capabilities in a specific clinical setting\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 14:16:01 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Cruz", "Beatriz Garcia Santa", ""], ["S\u00f6lter", "Jan", ""], ["Bossa", "Matias Nicolas", ""], ["Husch", "Andreas Dominik", ""]]}, {"id": "2008.11573", "submitter": "Selim F{\\i}rat Y{\\i}lmaz", "authors": "Selim F. Yilmaz, E. Batuhan Kaynak, Aykut Ko\\c{c}, Hamdi\n  Dibeklio\\u{g}lu and Suleyman S. Kozat", "title": "Multi-Label Sentiment Analysis on 100 Languages with Dynamic Weighting\n  for Label Imbalance", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate cross-lingual sentiment analysis, which has attracted\nsignificant attention due to its applications in various areas including market\nresearch, politics and social sciences. In particular, we introduce a sentiment\nanalysis framework in multi-label setting as it obeys Plutchik wheel of\nemotions. We introduce a novel dynamic weighting method that balances the\ncontribution from each class during training, unlike previous static weighting\nmethods that assign non-changing weights based on their class frequency.\nMoreover, we adapt the focal loss that favors harder instances from\nsingle-label object recognition literature to our multi-label setting.\nFurthermore, we derive a method to choose optimal class-specific thresholds\nthat maximize the macro-f1 score in linear time complexity. Through an\nextensive set of experiments, we show that our method obtains the\nstate-of-the-art performance in 7 of 9 metrics in 3 different languages using a\nsingle model compared to the common baselines and the best-performing methods\nin the SemEval competition. We publicly share our code for our model, which can\nperform sentiment analysis in 100 languages, to facilitate further research.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 14:16:02 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Yilmaz", "Selim F.", ""], ["Kaynak", "E. Batuhan", ""], ["Ko\u00e7", "Aykut", ""], ["Dibeklio\u011flu", "Hamdi", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "2008.11576", "submitter": "Mehul S. Raval", "authors": "Rupal Agravat, Mehul S Raval", "title": "3D Semantic Segmentation of Brain Tumor for Overall Survival Prediction", "comments": "11 pages, 3 figures, BRaTS 2020. arXiv admin note: text overlap with\n  arXiv:1909.09399", "journal-ref": "LNCS, Springer, 2021", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Glioma, the malignant brain tumor, requires immediate treatment to improve\nthe survival of patients. Gliomas heterogeneous nature makes the segmentation\ndifficult, especially for sub-regions like necrosis, enhancing tumor,\nnon-enhancing tumor, and Edema. Deep neural networks like full convolution\nneural networks and ensemble of fully convolution neural networks are\nsuccessful for Glioma segmentation. The paper demonstrates the use of a 3D\nfully convolution neural network with a three layer encoder decoder approach\nfor layer arrangement. The encoder blocks include the dense modules, and\ndecoder blocks include convolution modules. The input to the network is 3D\npatches. The loss function combines dice loss and focal loss functions. The\nvalidation set dice score of the network is 0.74, 0.88, and 0.73 for enhancing\ntumor, whole tumor, and tumor core, respectively. The Random Forest Regressor\nuses shape, volumetric, and age features extracted from ground truth for\noverall survival prediction. The regressor achieves an accuracy of 44.8% on the\nvalidation set.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 04:32:29 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 04:59:08 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Agravat", "Rupal", ""], ["Raval", "Mehul S", ""]]}, {"id": "2008.11582", "submitter": "Iman Niazazari", "authors": "Iman Niazazari, Hanif Livani, Amir Ghasemkhani, Yunchuan Liu, and Lei\n  Yang", "title": "Event Cause Analysis in Distribution Networks using Synchro Waveform\n  Measurements", "comments": "5 pages. arXiv admin note: text overlap with arXiv:1903.04486", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a machine learning method for event cause analysis to\nenhance situational awareness in distribution networks. The data streams are\ncaptured using time-synchronized high sampling rates synchro waveform\nmeasurement units (SWMU). The proposed method is formulated based on a machine\nlearning method, the convolutional neural network (CNN). This method is capable\nof capturing the spatiotemporal feature of the measurements effectively and\nperform the event cause analysis. Several events are considered in this paper\nto encompass a range of possible events in real distribution networks,\nincluding capacitor bank switching, transformer energization, fault, and high\nimpedance fault (HIF). The dataset for our study is generated using the\nreal-time digital simulator (RTDS) to simulate real-world events. The event\ncause analysis is performed using only one cycle of the voltage waveforms after\nthe event is detected. The simulation results show the effectiveness of the\nproposed machine learning-based method compared to the state-of-the-art\nclassifiers.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 01:25:59 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Niazazari", "Iman", ""], ["Livani", "Hanif", ""], ["Ghasemkhani", "Amir", ""], ["Liu", "Yunchuan", ""], ["Yang", "Lei", ""]]}, {"id": "2008.11592", "submitter": "Bo Pang", "authors": "Bo Pang and Zhong-Ping Jiang", "title": "Robust Reinforcement Learning: A Case Study in Linear Quadratic\n  Regulation", "comments": "arXiv admin note: text overlap with arXiv:2005.09528", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the robustness of reinforcement learning algorithms to\nerrors in the learning process. Specifically, we revisit the benchmark problem\nof discrete-time linear quadratic regulation (LQR) and study the long-standing\nopen question: Under what conditions is the policy iteration method robustly\nstable from a dynamical systems perspective? Using advanced stability results\nin control theory, it is shown that policy iteration for LQR is inherently\nrobust to small errors in the learning process and enjoys small-disturbance\ninput-to-state stability: whenever the error in each iteration is bounded and\nsmall, the solutions of the policy iteration algorithm are also bounded, and,\nmoreover, enter and stay in a small neighbourhood of the optimal LQR solution.\nAs an application, a novel off-policy optimistic least-squares policy iteration\nfor the LQR problem is proposed, when the system dynamics are subjected to\nadditive stochastic disturbances. The proposed new results in robust\nreinforcement learning are validated by a numerical example.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 11:11:28 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 02:42:10 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 04:57:01 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Pang", "Bo", ""], ["Jiang", "Zhong-Ping", ""]]}, {"id": "2008.11598", "submitter": "Xinshuo Weng", "authors": "Xinshuo Weng, Ye Yuan, Kris Kitani", "title": "End-to-End 3D Multi-Object Tracking and Trajectory Forecasting", "comments": "Extended abstract. The first two authors contributed equally. Project\n  website: http://www.xinshuoweng.com/projects/GNNTrkForecast. arXiv admin\n  note: substantial text overlap with arXiv:2003.07847", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D multi-object tracking (MOT) and trajectory forecasting are two critical\ncomponents in modern 3D perception systems. We hypothesize that it is\nbeneficial to unify both tasks under one framework to learn a shared feature\nrepresentation of agent interaction. To evaluate this hypothesis, we propose a\nunified solution for 3D MOT and trajectory forecasting which also incorporates\ntwo additional novel computational units. First, we employ a feature\ninteraction technique by introducing Graph Neural Networks (GNNs) to capture\nthe way in which multiple agents interact with one another. The GNN is able to\nmodel complex hierarchical interactions, improve the discriminative feature\nlearning for MOT association, and provide socially-aware context for trajectory\nforecasting. Second, we use a diversity sampling function to improve the\nquality and diversity of our forecasted trajectories. The learned sampling\nfunction is trained to efficiently extract a variety of outcomes from a\ngenerative trajectory distribution and helps avoid the problem of generating\nmany duplicate trajectory samples. We show that our method achieves\nstate-of-the-art performance on the KITTI dataset. Our project website is at\nhttp://www.xinshuoweng.com/projects/GNNTrkForecast.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 16:54:46 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Weng", "Xinshuo", ""], ["Yuan", "Ye", ""], ["Kitani", "Kris", ""]]}, {"id": "2008.11600", "submitter": "Chirag Agarwal", "authors": "Chirag Agarwal, Sara Hooker", "title": "Estimating Example Difficulty Using Variance of Gradients", "comments": "Preliminary results accepted to Workshop on Human Interpretability in\n  Machine Learning (WHI), ICML, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, a question of great interest is understanding what\nexamples are challenging for a model to classify. Identifying atypical examples\nhelps inform safe deployment of models, isolates examples that require further\nhuman inspection, and provides interpretability into model behavior. In this\nwork, we propose Variance of Gradients ($VOG$) as a valuable and efficient\nproxy metric for detecting outliers in the data distribution. We provide\nquantitative and qualitative support that $VOG$ is a meaningful way to rank\ndata by difficulty and to surface a tractable subset of the most challenging\nexamples for human-in-the-loop auditing. Data points with high $VOG$ scores are\nfar more difficult for the model to learn and over-index on corrupted or\nmemorized examples.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 14:53:24 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 01:48:27 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Agarwal", "Chirag", ""], ["Hooker", "Sara", ""]]}, {"id": "2008.11618", "submitter": "Mohammad Esmaeilpour", "authors": "Raymel Alfonso Sallo, Mohammad Esmaeilpour, Patrick Cardinal", "title": "Adversarially Training for Audio Classifiers", "comments": "Paper accepted to International Conference on Pattern Recognition\n  (ICPR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the potential effect of the adversarially\ntraining on the robustness of six advanced deep neural networks against a\nvariety of targeted and non-targeted adversarial attacks. We firstly show that,\nthe ResNet-56 model trained on the 2D representation of the discrete wavelet\ntransform appended with the tonnetz chromagram outperforms other models in\nterms of recognition accuracy. Then we demonstrate the positive impact of\nadversarially training on this model as well as other deep architectures\nagainst six types of attack algorithms (white and black-box) with the cost of\nthe reduced recognition accuracy and limited adversarial perturbation. We run\nour experiments on two benchmarking environmental sound datasets and show that\nwithout any imposed limitations on the budget allocations for the adversary,\nthe fooling rate of the adversarially trained models can exceed 90\\%. In other\nwords, adversarial attacks exist in any scales, but they might require higher\nadversarial perturbations compared to non-adversarially trained models.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 15:15:32 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 17:43:52 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Sallo", "Raymel Alfonso", ""], ["Esmaeilpour", "Mohammad", ""], ["Cardinal", "Patrick", ""]]}, {"id": "2008.11632", "submitter": "Weizhe Hua", "authors": "Weizhe Hua, Muhammad Umar, Zhiru Zhang, G. Edward Suh", "title": "GuardNN: Secure DNN Accelerator for Privacy-Preserving Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes GuardNN, a secure deep neural network (DNN) accelerator,\nwhich provides strong hardware-based protection for user data and model\nparameters even in an untrusted environment. GuardNN shows that the\narchitecture and protection can be customized for a specific application to\nprovide strong confidentiality and integrity protection with negligible\noverhead. The design of the GuardNN instruction set reduces the TCB to just the\naccelerator and enables confidentiality protection without the overhead of\nintegrity protection. GuardNN also introduces a new application-specific memory\nprotection scheme to minimize the overhead of memory encryption and integrity\nverification. The scheme shows that most of the off-chip meta-data in today's\nstate-of-the-art memory protection can be removed by exploiting the known\nmemory access patterns of a DNN accelerator. GuardNN is implemented as an FPGA\nprototype, which demonstrates effective protection with less than 2%\nperformance overhead for inference over a variety of modern DNN models.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 15:43:50 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Hua", "Weizhe", ""], ["Umar", "Muhammad", ""], ["Zhang", "Zhiru", ""], ["Suh", "G. Edward", ""]]}, {"id": "2008.11634", "submitter": "Alvaro Cabrejas Egea", "authors": "Alvaro Cabrejas-Egea, Shaun Howell, Maksis Knutins and Colm\n  Connaughton", "title": "Assessment of Reward Functions for Reinforcement Learning Traffic Signal\n  Control under Real-World Limitations", "comments": "Conference paper, 13 pages, 7 figures, 1 table", "journal-ref": null, "doi": "10.1109/SMC42975.2020.9283498", "report-no": null, "categories": "cs.AI cs.LG cs.NE cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive traffic signal control is one key avenue for mitigating the growing\nconsequences of traffic congestion. Incumbent solutions such as SCOOT and SCATS\nrequire regular and time-consuming calibration, can't optimise well for\nmultiple road use modalities, and require the manual curation of many\nimplementation plans. A recent alternative to these approaches are deep\nreinforcement learning algorithms, in which an agent learns how to take the\nmost appropriate action for a given state of the system. This is guided by\nneural networks approximating a reward function that provides feedback to the\nagent regarding the performance of the actions taken, making it sensitive to\nthe specific reward function chosen. Several authors have surveyed the reward\nfunctions used in the literature, but attributing outcome differences to reward\nfunction choice across works is problematic as there are many uncontrolled\ndifferences, as well as different outcome metrics. This paper compares the\nperformance of agents using different reward functions in a simulation of a\njunction in Greater Manchester, UK, across various demand profiles, subject to\nreal world constraints: realistic sensor inputs, controllers, calibrated\ndemand, intergreen times and stage sequencing. The reward metrics considered\nare based on the time spent stopped, lost time, change in lost time, average\nspeed, queue length, junction throughput and variations of these magnitudes.\nThe performance of these reward functions is compared in terms of total waiting\ntime. We find that speed maximisation resulted in the lowest average waiting\ntimes across all demand levels, displaying significantly better performance\nthan other rewards previously introduced in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 15:47:15 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 16:00:15 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Cabrejas-Egea", "Alvaro", ""], ["Howell", "Shaun", ""], ["Knutins", "Maksis", ""], ["Connaughton", "Colm", ""]]}, {"id": "2008.11638", "submitter": "Ujjal Kr Dutta", "authors": "Abhinav Ravi, Sandeep Repakula, Ujjal Kr Dutta, Maulik Parmar", "title": "Buy Me That Look: An Approach for Recommending Similar Fashion Products", "comments": "Accepted at the IEEE International Conference on Multimedia\n  Information Processing and Retrieval (MIPR) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Have you ever looked at an Instagram model, or a model in a fashion\ne-commerce web-page, and thought \\textit{\"Wish I could get a list of fashion\nitems similar to the ones worn by the model!\"}. This is what we address in this\npaper, where we propose a novel computer vision based technique called\n\\textbf{ShopLook} to address the challenging problem of recommending similar\nfashion products. The proposed method has been evaluated at Myntra\n(www.myntra.com), a leading online fashion e-commerce platform. In particular,\ngiven a user query and the corresponding Product Display Page (PDP) against the\nquery, the goal of our method is to recommend similar fashion products\ncorresponding to the entire set of fashion articles worn by a model in the PDP\nfull-shot image (the one showing the entire model from head to toe). The\nnovelty and strength of our method lies in its capability to recommend similar\narticles for all the fashion items worn by the model, in addition to the\nprimary article corresponding to the query. This is not only important to\npromote cross-sells for boosting revenue, but also for improving customer\nexperience and engagement. In addition, our approach is also capable of\nrecommending similar products for User Generated Content (UGC), eg., fashion\narticle images uploaded by users. Formally, our proposed method consists of the\nfollowing components (in the same order): i) Human keypoint detection, ii) Pose\nclassification, iii) Article localisation and object detection, along with\nactive learning feedback, and iv) Triplet network based image embedding model.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 16:01:00 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 13:05:30 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Ravi", "Abhinav", ""], ["Repakula", "Sandeep", ""], ["Dutta", "Ujjal Kr", ""], ["Parmar", "Maulik", ""]]}, {"id": "2008.11639", "submitter": "Samir Yadav S", "authors": "Samir S. Yadav, Jasminder Kaur Sandhu, Mininath R. Bendre, Pratap S.\n  Vikhe, Amandeep Kaur", "title": "A comparison of deep machine learning algorithms in COVID-19 disease\n  diagnosis", "comments": "16 pages, 10 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of the work is to use deep neural network models for solving the\nproblem of image recognition. These days, every human being is threatened by a\nharmful coronavirus disease, also called COVID-19 disease. The spread of\ncoronavirus affects the economy of many countries in the world. To find\nCOVID-19 patients early is very essential to avoid the spread and harm to\nsociety. Pathological tests and Chromatography(CT) scans are helpful for the\ndiagnosis of COVID-19. However, these tests are having drawbacks such as a\nlarge number of false positives, and cost of these tests are so expensive.\nHence, it requires finding an easy, accurate, and less expensive way for the\ndetection of the harmful COVID-19 disease. Chest-x-ray can be useful for the\ndetection of this disease. Therefore, in this work chest, x-ray images are used\nfor the diagnosis of suspected COVID-19 patients using modern machine learning\ntechniques. The analysis of the results is carried out and conclusions are made\nabout the effectiveness of deep machine learning algorithms in image\nrecognition problems.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 10:51:54 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 07:25:26 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Yadav", "Samir S.", ""], ["Sandhu", "Jasminder Kaur", ""], ["Bendre", "Mininath R.", ""], ["Vikhe", "Pratap S.", ""], ["Kaur", "Amandeep", ""]]}, {"id": "2008.11643", "submitter": "Sam Verboven", "authors": "Sam Verboven, Muhammad Hafeez Chaudhary, Jeroen Berrevoets, Wouter\n  Verbeke", "title": "HydaLearn: Highly Dynamic Task Weighting for Multi-task Learning with\n  Auxiliary Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning (MTL) can improve performance on a task by sharing\nrepresentations with one or more related auxiliary-tasks. Usually, MTL-networks\nare trained on a composite loss function formed by a constant weighted\ncombination of the separate task losses. In practice, constant loss weights\nlead to poor results for two reasons: (i) the relevance of the auxiliary tasks\ncan gradually drift throughout the learning process; (ii) for mini-batch based\noptimisation, the optimal task weights vary significantly from one update to\nthe next depending on mini-batch sample composition. We introduce HydaLearn, an\nintelligent weighting algorithm that connects main-task gain to the individual\ntask gradients, in order to inform dynamic loss weighting at the mini-batch\nlevel, addressing i and ii. Using HydaLearn, we report performance increases on\nsynthetic data, as well as on two supervised learning domains.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 16:04:02 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Verboven", "Sam", ""], ["Chaudhary", "Muhammad Hafeez", ""], ["Berrevoets", "Jeroen", ""], ["Verbeke", "Wouter", ""]]}, {"id": "2008.11646", "submitter": "Tingyu Wang", "authors": "Tingyu Wang, Zhedong Zheng, Chenggang Yan, Jiyong Zhang, Yaoqi Sun,\n  Bolun Zheng, and Yi Yang", "title": "Each Part Matters: Local Patterns Facilitate Cross-view Geo-localization", "comments": "accepted by TCSVT", "journal-ref": null, "doi": "10.1109/TCSVT.2021.3061265", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-view geo-localization is to spot images of the same geographic target\nfrom different platforms, e.g., drone-view cameras and satellites. It is\nchallenging in the large visual appearance changes caused by extreme viewpoint\nvariations. Existing methods usually concentrate on mining the fine-grained\nfeature of the geographic target in the image center, but underestimate the\ncontextual information in neighbor areas. In this work, we argue that neighbor\nareas can be leveraged as auxiliary information, enriching discriminative clues\nfor geolocalization. Specifically, we introduce a simple and effective deep\nneural network, called Local Pattern Network (LPN), to take advantage of\ncontextual information in an end-to-end manner. Without using extra part\nestimators, LPN adopts a square-ring feature partition strategy, which provides\nthe attention according to the distance to the image center. It eases the part\nmatching and enables the part-wise representation learning. Owing to the\nsquare-ring partition design, the proposed LPN has good scalability to rotation\nvariations and achieves competitive results on three prevailing benchmarks,\ni.e., University-1652, CVUSA and CVACT. Besides, we also show the proposed LPN\ncan be easily embedded into other frameworks to further boost performance.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 16:06:11 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 06:49:51 GMT"}, {"version": "v3", "created": "Sun, 6 Jun 2021 02:46:25 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Wang", "Tingyu", ""], ["Zheng", "Zhedong", ""], ["Yan", "Chenggang", ""], ["Zhang", "Jiyong", ""], ["Sun", "Yaoqi", ""], ["Zheng", "Bolun", ""], ["Yang", "Yi", ""]]}, {"id": "2008.11647", "submitter": "Javier Lorenzo D\\'iaz", "authors": "Javier Lorenzo, Ignacio Parra, Florian Wirth, Christoph Stiller, David\n  Fernandez Llorca and Miguel Angel Sotelo", "title": "RNN-based Pedestrian Crossing Prediction using Activity and Pose-related\n  Features", "comments": "6 pages, 5 figures. This work has been accepted for publication at\n  IEEE Intelligent Vehicle Symposium 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pedestrian crossing prediction is a crucial task for autonomous driving.\nNumerous studies show that an early estimation of the pedestrian's intention\ncan decrease or even avoid a high percentage of accidents. In this paper,\ndifferent variations of a deep learning system are proposed to attempt to solve\nthis problem. The proposed models are composed of two parts: a CNN-based\nfeature extractor and an RNN module. All the models were trained and tested on\nthe JAAD dataset. The results obtained indicate that the choice of the features\nextraction method, the inclusion of additional variables such as pedestrian\ngaze direction and discrete orientation, and the chosen RNN type have a\nsignificant impact on the final performance.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 16:06:24 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Lorenzo", "Javier", ""], ["Parra", "Ignacio", ""], ["Wirth", "Florian", ""], ["Stiller", "Christoph", ""], ["Llorca", "David Fernandez", ""], ["Sotelo", "Miguel Angel", ""]]}, {"id": "2008.11652", "submitter": "Huan Zhao Dr.", "authors": "Huan Zhao and Lanning Wei and Quanming Yao", "title": "Simplifying Architecture Search for Graph Neural Network", "comments": "CIKM 2020 Workshop: 1st Workshop Combining Symbolic and Subsymbolic\n  Methods and their Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the popularity of Graph Neural Networks (GNN) in\nvarious scenarios. To obtain optimal data-specific GNN architectures,\nresearchers turn to neural architecture search (NAS) methods, which have made\nimpressive progress in discovering effective architectures in convolutional\nneural networks. Two preliminary works, GraphNAS and Auto-GNN, have made first\nattempt to apply NAS methods to GNN. Despite the promising results, there are\nseveral drawbacks in expressive capability and search efficiency of GraphNAS\nand Auto-GNN due to the designed search space. To overcome these drawbacks, we\npropose the SNAG framework (Simplified Neural Architecture search for Graph\nneural networks), consisting of a novel search space and a reinforcement\nlearning based search algorithm. Extensive experiments on real-world datasets\ndemonstrate the effectiveness of the SNAG framework compared to human-designed\nGNNs and NAS methods, including GraphNAS and Auto-GNN.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 16:24:03 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 12:06:14 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Zhao", "Huan", ""], ["Wei", "Lanning", ""], ["Yao", "Quanming", ""]]}, {"id": "2008.11655", "submitter": "Jacques Wainer", "authors": "Jacques Wainer and Pablo Fonseca", "title": "How to tune the RBF SVM hyperparameters?: An empirical evaluation of 18\n  search algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SVM with an RBF kernel is usually one of the best classification algorithms\nfor most data sets, but it is important to tune the two hyperparameters $C$ and\n$\\gamma$ to the data itself. In general, the selection of the hyperparameters\nis a non-convex optimization problem and thus many algorithms have been\nproposed to solve it, among them: grid search, random search, Bayesian\noptimization, simulated annealing, particle swarm optimization, Nelder Mead,\nand others. There have also been proposals to decouple the selection of\n$\\gamma$ and $C$. We empirically compare 18 of these proposed search algorithms\n(with different parameterizations for a total of 47 combinations) on 115\nreal-life binary data sets. We find (among other things) that trees of Parzen\nestimators and particle swarm optimization select better hyperparameters with\nonly a slight increase in computation time with respect to a grid search with\nthe same number of evaluations. We also find that spending too much\ncomputational effort searching the hyperparameters will not likely result in\nbetter performance for future data and that there are no significant\ndifferences among the different procedures to select the best set of\nhyperparameters when more than one is found by the search algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 16:28:48 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Wainer", "Jacques", ""], ["Fonseca", "Pablo", ""]]}, {"id": "2008.11659", "submitter": "Xing Lin", "authors": "Tiankuang Zhou, Xing Lin, Jiamin Wu, Yitong Chen, Hao Xie, Yipeng Li,\n  Jintao Fan, Huaqiang Wu, Lu Fang and Qionghai Dai", "title": "Large-scale neuromorphic optoelectronic computing with a reconfigurable\n  diffractive processing unit", "comments": null, "journal-ref": null, "doi": "10.1038/s41566-021-00796-w", "report-no": null, "categories": "eess.IV cs.LG cs.NE physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Application-specific optical processors have been considered disruptive\ntechnologies for modern computing that can fundamentally accelerate the\ndevelopment of artificial intelligence (AI) by offering substantially improved\ncomputing performance. Recent advancements in optical neural network\narchitectures for neural information processing have been applied to perform\nvarious machine learning tasks. However, the existing architectures have\nlimited complexity and performance; and each of them requires its own dedicated\ndesign that cannot be reconfigured to switch between different neural network\nmodels for different applications after deployment. Here, we propose an\noptoelectronic reconfigurable computing paradigm by constructing a diffractive\nprocessing unit (DPU) that can efficiently support different neural networks\nand achieve a high model complexity with millions of neurons. It allocates\nalmost all of its computational operations optically and achieves extremely\nhigh speed of data modulation and large-scale network parameter updating by\ndynamically programming optical modulators and photodetectors. We demonstrated\nthe reconfiguration of the DPU to implement various diffractive feedforward and\nrecurrent neural networks and developed a novel adaptive training approach to\ncircumvent the system imperfections. We applied the trained networks for\nhigh-speed classifying of handwritten digit images and human action videos over\nbenchmark datasets, and the experimental results revealed a comparable\nclassification accuracy to the electronic computing approaches. Furthermore,\nour prototype system built with off-the-shelf optoelectronic components\nsurpasses the performance of state-of-the-art graphics processing units (GPUs)\nby several times on computing speed and more than an order of magnitude on\nsystem energy efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 16:34:58 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Zhou", "Tiankuang", ""], ["Lin", "Xing", ""], ["Wu", "Jiamin", ""], ["Chen", "Yitong", ""], ["Xie", "Hao", ""], ["Li", "Yipeng", ""], ["Fan", "Jintao", ""], ["Wu", "Huaqiang", ""], ["Fang", "Lu", ""], ["Dai", "Qionghai", ""]]}, {"id": "2008.11668", "submitter": "Anurag Chowdhury", "authors": "Anurag Chowdhury, Arun Ross", "title": "DeepVOX: Discovering Features from Raw Audio for Speaker Recognition in\n  Degraded Audio Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speaker recognition algorithms typically use pre-defined\nfilterbanks, such as Mel-Frequency and Gammatone filterbanks, for\ncharacterizing speech audio. The design of these filterbanks is based on\ndomain-knowledge and limited empirical observations. The resultant features,\ntherefore, may not generalize well to different types of audio degradation. In\nthis work, we propose a deep learning-based technique to induce the filterbank\ndesign from vast amounts of speech audio. The purpose of such a filterbank is\nto extract features robust to degradations in the input audio. To this effect,\na 1D convolutional neural network is designed to learn a time-domain filterbank\ncalled DeepVOX directly from raw speech audio. Secondly, an adaptive triplet\nmining technique is developed to efficiently mine the data samples best suited\nto train the filterbank. Thirdly, a detailed ablation study of the DeepVOX\nfilterbanks reveals the presence of both vocal source and vocal tract\ncharacteristics in the extracted features. Experimental results on VOXCeleb2,\nNIST SRE 2008 and 2010, and Fisher speech datasets demonstrate the efficacy of\nthe DeepVOX features across a variety of audio degradations, multi-lingual\nspeech data, and varying-duration speech audio. The DeepVOX features also\nimprove the performance of existing speaker recognition algorithms, such as the\nxVector-PLDA and the iVector-PLDA.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 16:50:26 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Chowdhury", "Anurag", ""], ["Ross", "Arun", ""]]}, {"id": "2008.11672", "submitter": "Mahdi Rezaei", "authors": "Mahdi Rezaei, Mohsen Azarmi", "title": "DeepSOCIAL: Social Distancing Monitoring and Infection Risk Assessment\n  in COVID-19 Pandemic", "comments": null, "journal-ref": "Applied Sciences. 2020, 10, 7514", "doi": "10.3390/app10217514", "report-no": null, "categories": "cs.CV cs.LG eess.IV physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social distancing is a recommended solution by the World Health Organisation\n(WHO) to minimise the spread of COVID-19 in public places. The majority of\ngovernments and national health authorities have set the 2-meter physical\ndistancing as a mandatory safety measure in shopping centres, schools and other\ncovered areas. In this research, we develop a hybrid Computer Vision and\nYOLOv4-based Deep Neural Network model for automated people detection in the\ncrowd in indoor and outdoor environments using common CCTV security cameras.\nThe proposed DNN model in combination with an adapted inverse perspective\nmapping (IPM) technique and SORT tracking algorithm leads to a robust people\ndetection and social distancing monitoring. The model has been trained against\ntwo most comprehensive datasets by the time of the research the Microsoft\nCommon Objects in Context (MS COCO) and Google Open Image datasets. The system\nhas been evaluated against the Oxford Town Centre dataset with superior\nperformance compared to three state-of-the-art methods. The evaluation has been\nconducted in challenging conditions, including occlusion, partial visibility,\nand under lighting variations with the mean average precision of 99.8% and the\nreal-time speed of 24.1 fps. We also provide an online infection risk\nassessment scheme by statistical analysis of the Spatio-temporal data from\npeople's moving trajectories and the rate of social distancing violations. The\ndeveloped model is a generic and accurate people detection and tracking\nsolution that can be applied in many other fields such as autonomous vehicles,\nhuman action recognition, anomaly detection, sports, crowd analysis, or any\nother research areas where the human detection is in the centre of attention.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 16:56:57 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 22:05:27 GMT"}, {"version": "v3", "created": "Sat, 28 Nov 2020 13:46:27 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Rezaei", "Mahdi", ""], ["Azarmi", "Mohsen", ""]]}, {"id": "2008.11687", "submitter": "Hanie Sedghi", "authors": "Behnam Neyshabur and Hanie Sedghi and Chiyuan Zhang", "title": "What is being transferred in transfer learning?", "comments": "Equal contribution, authors ordered randomly", "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One desired capability for machines is the ability to transfer their\nknowledge of one domain to another where data is (usually) scarce. Despite\nample adaptation of transfer learning in various deep learning applications, we\nyet do not understand what enables a successful transfer and which part of the\nnetwork is responsible for that. In this paper, we provide new tools and\nanalyses to address these fundamental questions. Through a series of analyses\non transferring to block-shuffled images, we separate the effect of feature\nreuse from learning low-level statistics of data and show that some benefit of\ntransfer learning comes from the latter. We present that when training from\npre-trained weights, the model stays in the same basin in the loss landscape\nand different instances of such model are similar in feature space and close in\nparameter space.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 17:23:40 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 20:32:39 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Neyshabur", "Behnam", ""], ["Sedghi", "Hanie", ""], ["Zhang", "Chiyuan", ""]]}, {"id": "2008.11689", "submitter": "Yanyu Zhang", "authors": "Yanyu Zhang, Osama Alshaykh", "title": "5G Utility Pole Planner Using Google Street View and Mask R-CNN", "comments": "4 pages, 7 figures", "journal-ref": "2020 IEEE International Conference on Electro Information\n  Technology (EIT)", "doi": "10.1109/EIT48999.2020.9208333", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advances of fifth-generation (5G) cellular networks technology, many\nstudies and work have been carried out on how to build 5G networks for smart\ncities. In the previous research, street lighting poles and smart light poles\nare capable of being a 5G access point. In order to determine the position of\nthe points, this paper discusses a new way to identify poles based on Mask\nR-CNN, which extends Fast R-CNNs by making it employ recursive Bayesian\nfiltering and perform proposal propagation and reuse. The dataset contains\n3,000 high-resolution images from google map. To make training faster, we used\na very efficient GPU implementation of the convolution operation. We achieved a\ntrain error rate of 7.86% and a test error rate of 32.03%. At last, we used the\nimmune algorithm to set 5G poles in the smart cities.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 17:27:52 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Zhang", "Yanyu", ""], ["Alshaykh", "Osama", ""]]}, {"id": "2008.11700", "submitter": "Thomas Lew", "authors": "Thomas Lew, Apoorva Sharma, James Harrison, Andrew Bylard, Marco\n  Pavone", "title": "Safe Active Dynamics Learning and Control: A Sequential\n  Exploration-Exploitation Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safe deployment of autonomous robots in diverse scenarios requires agents\nthat are capable of efficiently adapting to new environments while satisfying\nconstraints. In this work, we propose a practical and theoretically-justified\napproach to maintaining safety in the presence of dynamics uncertainty. Our\napproach leverages Bayesian meta-learning with last-layer adaptation: the\nexpressiveness of neural-network features trained offline, paired with\nefficient last-layer online adaptation, enables the derivation of tight\nconfidence sets which contract around the true dynamics as the model adapts\nonline. We exploit these confidence sets to plan trajectories that guarantee\nthe safety of the system. Our approach handles problems with high dynamics\nuncertainty where reaching the goal safely is initially infeasible by first\nexploring to gather data and reduce uncertainty, before autonomously exploiting\nthe acquired information to safely perform the task. Under reasonable\nassumptions, we prove that our framework has high-probability guarantees of\nsatisfying all constraints at all times jointly. This analysis also motivates\ntwo regularizers of last-layer meta-learners that improve online adaptation\ncapabilities as well as performance by reducing the size of the confidence\nsets. We extensively demonstrate our approach in simulation and on hardware.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 17:39:58 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 20:04:24 GMT"}, {"version": "v3", "created": "Thu, 3 Jun 2021 17:32:12 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Lew", "Thomas", ""], ["Sharma", "Apoorva", ""], ["Harrison", "James", ""], ["Bylard", "Andrew", ""], ["Pavone", "Marco", ""]]}, {"id": "2008.11702", "submitter": "Jiahao Xie", "authors": "Jiahao Xie, Xiaohang Zhan, Ziwei Liu, Yew Soon Ong, Chen Change Loy", "title": "Delving into Inter-Image Invariance for Unsupervised Visual\n  Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive learning has recently shown immense potential in unsupervised\nvisual representation learning. Existing studies in this track mainly focus on\nintra-image invariance learning. The learning typically uses rich intra-image\ntransformations to construct positive pairs and then maximizes agreement using\na contrastive loss. The merits of inter-image invariance, conversely, remain\nmuch less explored. One major obstacle to exploit inter-image invariance is\nthat it is unclear how to reliably construct inter-image positive pairs, and\nfurther derive effective supervision from them since there are no pair\nannotations available. In this work, we present a rigorous and comprehensive\nstudy on inter-image invariance learning from three main constituting\ncomponents: pseudo-label maintenance, sampling strategy, and decision boundary\ndesign. Through carefully-designed comparisons and analysis, we propose a\nunified and generic framework that supports the integration of unsupervised\nintra- and inter-image invariance learning. With all the obtained recipes, our\nfinal model, namely InterCLR, shows consistent improvements over\nstate-of-the-art intra-image invariance learning methods on multiple standard\nbenchmarks. Codes will be released at\nhttps://github.com/open-mmlab/OpenSelfSup.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 17:44:23 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 17:03:15 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Xie", "Jiahao", ""], ["Zhan", "Xiaohang", ""], ["Liu", "Ziwei", ""], ["Ong", "Yew Soon", ""], ["Loy", "Chen Change", ""]]}, {"id": "2008.11707", "submitter": "Zheyuan Ryan Shi", "authors": "Zheyuan Ryan Shi, Zhiwei Steven Wu, Rayid Ghani, Fei Fang", "title": "Bandit Data-driven Optimization: AI for Social Good and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of machine learning (ML) systems in real-world applications entails\nmore than just a prediction algorithm. AI for social good applications, and\nmany real-world ML tasks in general, feature an iterative process which joins\nprediction, optimization, and data acquisition happen in a loop. We introduce\nbandit data-driven optimization, the first iterative prediction-prescription\nframework to formally analyze this practical routine. Bandit data-driven\noptimization combines the advantages of online bandit learning and offline\npredictive analytics in an integrated framework. It offers a flexible setup to\nreason about unmodeled policy objectives and unforeseen consequences. We\npropose PROOF, the first algorithm for this framework and show that it achieves\nno-regret. Using numerical simulations, we show that PROOF achieves superior\nperformance over existing baseline.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 17:50:49 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Shi", "Zheyuan Ryan", ""], ["Wu", "Zhiwei Steven", ""], ["Ghani", "Rayid", ""], ["Fang", "Fei", ""]]}, {"id": "2008.11708", "submitter": "Yiding Wang", "authors": "Yiding Wang, Zhenyi Wang, Chenghao Li, Yilin Zhang, Haizhou Wang", "title": "A Multitask Deep Learning Approach for User Depression Detection on Sina\n  Weibo", "comments": "23 pages, 32 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, due to the mental burden of depression, the number of people\nwho endanger their lives has been increasing rapidly. The online social network\n(OSN) provides researchers with another perspective for detecting individuals\nsuffering from depression. However, existing studies of depression detection\nbased on machine learning still leave relatively low classification\nperformance, suggesting that there is significant improvement potential for\nimprovement in their feature engineering. In this paper, we manually build a\nlarge dataset on Sina Weibo (a leading OSN with the largest number of active\nusers in the Chinese community), namely Weibo User Depression Detection Dataset\n(WU3D). It includes more than 20,000 normal users and more than 10,000\ndepressed users, both of which are manually labeled and rechecked by\nprofessionals. By analyzing the user's text, social behavior, and posted\npictures, ten statistical features are concluded and proposed. In the meantime,\ntext-based word features are extracted using the popular pretrained model\nXLNet. Moreover, a novel deep neural network classification model, i.e.\nFusionNet (FN), is proposed and simultaneously trained with the above-extracted\nfeatures, which are seen as multiple classification tasks. The experimental\nresults show that FusionNet achieves the highest F1-Score of 0.9772 on the test\ndataset. Compared to existing studies, our proposed method has better\nclassification performance and robustness for unbalanced training samples. Our\nwork also provides a new way to detect depression on other OSN platforms.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 17:53:17 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Wang", "Yiding", ""], ["Wang", "Zhenyi", ""], ["Li", "Chenghao", ""], ["Zhang", "Yilin", ""], ["Wang", "Haizhou", ""]]}, {"id": "2008.11721", "submitter": "Hua Shen", "authors": "Hua Shen and Ting-Hao Kenneth Huang", "title": "How Useful Are the Machine-Generated Interpretations to General Users? A\n  Human Evaluation on Guessing the Incorrectly Predicted Labels", "comments": "Accepted by The 8th AAAI Conference on Human Computation and\n  Crowdsourcing (HCOMP 2020) https://github.com/huashen218/GuessWrongLabel", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining to users why automated systems make certain mistakes is important\nand challenging. Researchers have proposed ways to automatically produce\ninterpretations for deep neural network models. However, it is unclear how\nuseful these interpretations are in helping users figure out why they are\ngetting an error. If an interpretation effectively explains to users how the\nunderlying deep neural network model works, people who were presented with the\ninterpretation should be better at predicting the model's outputs than those\nwho were not. This paper presents an investigation on whether or not showing\nmachine-generated visual interpretations helps users understand the incorrectly\npredicted labels produced by image classifiers. We showed the images and the\ncorrect labels to 150 online crowd workers and asked them to select the\nincorrectly predicted labels with or without showing them the machine-generated\nvisual interpretations. The results demonstrated that displaying the visual\ninterpretations did not increase, but rather decreased, the average guessing\naccuracy by roughly 10%.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 14:02:05 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 02:42:23 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Shen", "Hua", ""], ["Huang", "Ting-Hao Kenneth", ""]]}, {"id": "2008.11752", "submitter": "Shounak Datta", "authors": "Sankha Subhra Mullick and Shounak Datta and Sourish Gunesh Dhekane and\n  Swagatam Das", "title": "Appropriateness of Performance Indices for Imbalanced Data\n  Classification: An Analysis", "comments": "Published in Pattern Recognition (Elsevier)", "journal-ref": "Pattern Recognition, 102, p.107197 (2020)", "doi": "10.1016/j.patcog.2020.107197", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indices quantifying the performance of classifiers under class-imbalance,\noften suffer from distortions depending on the constitution of the test set or\nthe class-specific classification accuracy, creating difficulties in assessing\nthe merit of the classifier. We identify two fundamental conditions that a\nperformance index must satisfy to be respectively resilient to altering number\nof testing instances from each class and the number of classes in the test set.\nIn light of these conditions, under the effect of class imbalance, we\ntheoretically analyze four indices commonly used for evaluating binary\nclassifiers and five popular indices for multi-class classifiers. For indices\nviolating any of the conditions, we also suggest remedial modification and\nnormalization. We further investigate the capability of the indices to retain\ninformation about the classification performance over all the classes, even\nwhen the classifier exhibits extreme performance on some classes. Simulation\nstudies are performed on high dimensional deep representations of subset of the\nImageNet dataset using four state-of-the-art classifiers tailored for handling\nclass imbalance. Finally, based on our theoretical findings and empirical\nevidence, we recommend the appropriate indices that should be used to evaluate\nthe performance of classifiers in presence of class-imbalance.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 18:23:36 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Mullick", "Sankha Subhra", ""], ["Datta", "Shounak", ""], ["Dhekane", "Sourish Gunesh", ""], ["Das", "Swagatam", ""]]}, {"id": "2008.11757", "submitter": "Ashley Davey", "authors": "Ashley Davey, Harry Zheng", "title": "Deep Learning for Constrained Utility Maximisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes two algorithms for solving stochastic control problems\nwith deep reinforcement learning, with a focus on the utility maximisation\nproblem. The first algorithm solves Markovian problems via the Hamilton Jacobi\nBellman (HJB) equation. We solve this highly nonlinear partial differential\nequation (PDE) with a second order backward stochastic differential equation\n(2BSDE) formulation. The convex structure of the problem allows us to describe\na dual problem that can either verify the original primal approach or bypass\nsome of the complexity. The second algorithm utilises the full power of the\nduality method to solve non-Markovian problems, which are often beyond the\nscope of stochastic control solvers in the existing literature. We solve an\nadjoint BSDE that satisfies the dual optimality conditions. We apply these\nalgorithms to problems with power, log and non-HARA utilities in the\nBlack-Scholes, the Heston stochastic volatility, and path dependent volatility\nmodels. Numerical experiments show highly accurate results with low\ncomputational cost, supporting our proposed algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 18:40:57 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Davey", "Ashley", ""], ["Zheng", "Harry", ""]]}, {"id": "2008.11783", "submitter": "Taesup Kim", "authors": "Taesup Kim, Sungwoong Kim, Yoshua Bengio", "title": "Visual Concept Reasoning Networks", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A split-transform-merge strategy has been broadly used as an architectural\nconstraint in convolutional neural networks for visual recognition tasks. It\napproximates sparsely connected networks by explicitly defining multiple\nbranches to simultaneously learn representations with different visual concepts\nor properties. Dependencies or interactions between these representations are\ntypically defined by dense and local operations, however, without any\nadaptiveness or high-level reasoning. In this work, we propose to exploit this\nstrategy and combine it with our Visual Concept Reasoning Networks (VCRNet) to\nenable reasoning between high-level visual concepts. We associate each branch\nwith a visual concept and derive a compact concept state by selecting a few\nlocal descriptors through an attention module. These concept states are then\nupdated by graph-based interaction and used to adaptively modulate the local\ndescriptors. We describe our proposed model by\nsplit-transform-attend-interact-modulate-merge stages, which are implemented by\nopting for a highly modularized architecture. Extensive experiments on visual\nrecognition tasks such as image classification, semantic segmentation, object\ndetection, scene recognition, and action recognition show that our proposed\nmodel, VCRNet, consistently improves the performance by increasing the number\nof parameters by less than 1%.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 20:02:40 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Kim", "Taesup", ""], ["Kim", "Sungwoong", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2008.11788", "submitter": "Hongmei He Ph.D", "authors": "Linyu Zheng and Hongmei He", "title": "Share Price Prediction of Aerospace Relevant Companies with Recurrent\n  Neural Networks based on PCA", "comments": "38 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capital market plays a vital role in marketing operations for aerospace\nindustry. However, due to the uncertainty and complexity of the stock market\nand many cyclical factors, the stock prices of listed aerospace companies\nfluctuate significantly. This makes the share price prediction challengeable.\nTo improve the prediction of share price for aerospace industry sector and well\nunderstand the impact of various indicators on stock prices, we provided a\nhybrid prediction model by the combination of Principal Component Analysis\n(PCA) and Recurrent Neural Networks. We investigated two types of aerospace\nindustries (manufacturer and operator). The experimental results show that PCA\ncould improve both accuracy and efficiency of prediction. Various factors could\ninfluence the performance of prediction models, such as finance data, extracted\nfeatures, optimisation algorithms, and parameters of the prediction model. The\nselection of features may depend on the stability of historical data: technical\nfeatures could be the first option when the share price is stable, whereas\nfundamental features could be better when the share price has high fluctuation.\nThe delays of RNN also depend on the stability of historical data for different\ntypes of companies. It would be more accurate through using short-term\nhistorical data for aerospace manufacturers, whereas using long-term historical\ndata for aerospace operating airlines. The developed model could be an\nintelligent agent in an automatic stock prediction system, with which, the\nfinancial industry could make a prompt decision for their economic strategies\nand business activities in terms of predicted future share price, thus\nimproving the return on investment. Currently, COVID-19 severely influences\naerospace industries. The developed approach can be used to predict the share\nprice of aerospace industries at post COVID-19 time.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 20:16:33 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Zheng", "Linyu", ""], ["He", "Hongmei", ""]]}, {"id": "2008.11790", "submitter": "Daniel Berman", "authors": "Daniel S. Berman (1), Craig Howser (1), Thomas Mehoke (1), Jared D.\n  Evans (1) ((1) Johns Hopkins Applied Physics Laboratory, Laurel, United\n  States)", "title": "MutaGAN: A Seq2seq GAN Framework to Predict Mutations of Evolving\n  Protein Populations", "comments": "28 pages, 9 figures, 2 tables, Daniel S. Berman and Craig Howser\n  contributed equally to this work. This paper was submitted to Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The ability to predict the evolution of a pathogen would significantly\nimprove the ability to control, prevent, and treat disease. Despite significant\nprogress in other problem spaces, deep learning has yet to contribute to the\nissue of predicting mutations of evolving populations. To address this gap, we\ndeveloped a novel machine learning framework using generative adversarial\nnetworks (GANs) with recurrent neural networks (RNNs) to accurately predict\ngenetic mutations and evolution of future biological populations. Using a\ngeneralized time-reversible phylogenetic model of protein evolution with\nbootstrapped maximum likelihood tree estimation, we trained a\nsequence-to-sequence generator within an adversarial framework, named MutaGAN,\nto generate complete protein sequences augmented with possible mutations of\nfuture virus populations. Influenza virus sequences were identified as an ideal\ntest case for this deep learning framework because it is a significant human\npathogen with new strains emerging annually and global surveillance efforts\nhave generated a large amount of publicly available data from the National\nCenter for Biotechnology Information's (NCBI) Influenza Virus Resource (IVR).\nMutaGAN generated \"child\" sequences from a given \"parent\" protein sequence with\na median Levenshtein distance of 2.00 amino acids. Additionally, the generator\nwas able to augment the majority of parent proteins with at least one mutation\nidentified within the global influenza virus population. These results\ndemonstrate the power of the MutaGAN framework to aid in pathogen forecasting\nwith implications for broad utility in evolutionary prediction for any protein\npopulation.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 20:20:30 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Berman", "Daniel S.", ""], ["Howser", "Craig", ""], ["Mehoke", "Thomas", ""], ["Evans", "Jared D.", ""]]}, {"id": "2008.11796", "submitter": "Yu Xie", "authors": "Yu Xie, Jonathan Vandermause, Lixin Sun, Andrea Cepellotti and Boris\n  Kozinsky", "title": "Bayesian Force Fields from Active Learning for Simulation of\n  Inter-Dimensional Transformation of Stanene", "comments": "30 pages of main text, 14 pages of supplementary materials, 9 figures\n  in total", "journal-ref": "npj Comput Mater 7, 40 (2021)", "doi": "10.1038/s41524-021-00510-y", "report-no": null, "categories": "physics.comp-ph cond-mat.mtrl-sci cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a way to dramatically accelerate Gaussian process models for\ninteratomic force fields based on many-body kernels by mapping both forces and\nuncertainties onto functions of low-dimensional features. This allows for\nautomated active learning of models combining near-quantum accuracy, built-in\nuncertainty, and constant cost of evaluation that is comparable to classical\nanalytical models, capable of simulating millions of atoms. Using this\napproach, we perform large scale molecular dynamics simulations of the\nstability of the stanene monolayer. We discover an unusual phase transformation\nmechanism of 2D stanene, where ripples lead to nucleation of bilayer defects,\ndensification into a disordered multilayer structure, followed by formation of\nbulk liquid at high temperature or nucleation and growth of the 3D bcc crystal\nat low temperature. The presented method opens possibilities for rapid\ndevelopment of fast accurate uncertainty-aware models for simulating long-time\nlarge-scale dynamics of complex materials.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 20:27:19 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 19:16:04 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Xie", "Yu", ""], ["Vandermause", "Jonathan", ""], ["Sun", "Lixin", ""], ["Cepellotti", "Andrea", ""], ["Kozinsky", "Boris", ""]]}, {"id": "2008.11804", "submitter": "Brighter Agyemang", "authors": "Brighter Agyemang, Wei-Ping Wu, Daniel Addo, Michael Y. Kpiebaareh,\n  Ebenezer Nanor, Charles Roland Haruna", "title": "Deep Inverse Reinforcement Learning for Structural Evolution of Small\n  Molecules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The size and quality of chemical libraries to the drug discovery pipeline are\ncrucial for developing new drugs or repurposing existing drugs. Existing\ntechniques such as combinatorial organic synthesis and High-Throughput\nScreening usually make the process extraordinarily tough and complicated since\nthe search space of synthetically feasible drugs is exorbitantly huge. While\nreinforcement learning has been mostly exploited in the literature for\ngenerating novel compounds, the requirement of designing a reward function that\nsuccinctly represents the learning objective could prove daunting in certain\ncomplex domains. Generative Adversarial Network-based methods also mostly\ndiscard the discriminator after training and could be hard to train. In this\nstudy, we propose a framework for training a compound generator and learning a\ntransferable reward function based on the entropy maximization inverse\nreinforcement learning paradigm. We show from our experiments that the inverse\nreinforcement learning route offers a rational alternative for generating\nchemical compounds in domains where reward function engineering may be less\nappealing or impossible while data exhibiting the desired objective is readily\navailable.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 17:21:59 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 11:20:01 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Agyemang", "Brighter", ""], ["Wu", "Wei-Ping", ""], ["Addo", "Daniel", ""], ["Kpiebaareh", "Michael Y.", ""], ["Nanor", "Ebenezer", ""], ["Haruna", "Charles Roland", ""]]}, {"id": "2008.11811", "submitter": "Harsh Satija", "authors": "Harsh Satija, Philip Amortila, Joelle Pineau", "title": "Constrained Markov Decision Processes via Backward Value Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Reinforcement Learning (RL) algorithms have found tremendous success\nin simulated domains, they often cannot directly be applied to physical\nsystems, especially in cases where there are hard constraints to satisfy (e.g.\non safety or resources). In standard RL, the agent is incentivized to explore\nany behavior as long as it maximizes rewards, but in the real world, undesired\nbehavior can damage either the system or the agent in a way that breaks the\nlearning process itself. In this work, we model the problem of learning with\nconstraints as a Constrained Markov Decision Process and provide a new\non-policy formulation for solving it. A key contribution of our approach is to\ntranslate cumulative cost constraints into state-based constraints. Through\nthis, we define a safe policy improvement method which maximizes returns while\nensuring that the constraints are satisfied at every step. We provide\ntheoretical guarantees under which the agent converges while ensuring safety\nover the course of training. We also highlight the computational advantages of\nthis approach. The effectiveness of our approach is demonstrated on safe\nnavigation tasks and in safety-constrained versions of MuJoCo environments,\nwith deep neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 20:56:16 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Satija", "Harsh", ""], ["Amortila", "Philip", ""], ["Pineau", "Joelle", ""]]}, {"id": "2008.11824", "submitter": "Filip Hanzely", "authors": "Filip Hanzely", "title": "Optimization for Supervised Machine Learning: Randomized Algorithms for\n  Data and Parameters", "comments": "PhD thesis, 425 pages, 75 figures", "journal-ref": null, "doi": "10.25781/KAUST-4F2DH", "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many key problems in machine learning and data science are routinely modeled\nas optimization problems and solved via optimization algorithms. With the\nincrease of the volume of data and the size and complexity of the statistical\nmodels used to formulate these often ill-conditioned optimization tasks, there\nis a need for new efficient algorithms able to cope with these challenges. In\nthis thesis, we deal with each of these sources of difficulty in a different\nway. To efficiently address the big data issue, we develop new methods which in\neach iteration examine a small random subset of the training data only. To\nhandle the big model issue, we develop methods which in each iteration update a\nrandom subset of the model parameters only. Finally, to deal with\nill-conditioned problems, we devise methods that incorporate either\nhigher-order information or Nesterov's acceleration/momentum. In all cases,\nrandomness is viewed as a powerful algorithmic tool that we tune, both in\ntheory and in experiments, to achieve the best results. Our algorithms have\ntheir primary application in training supervised machine learning models via\nregularized empirical risk minimization, which is the dominant paradigm for\ntraining such models. However, due to their generality, our methods can be\napplied in many other fields, including but not limited to data science,\nengineering, scientific computing, and statistics.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 21:15:18 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Hanzely", "Filip", ""]]}, {"id": "2008.11825", "submitter": "Wei Zhao", "authors": "Wei Zhao, Tarun Joshi, Vijayan N. Nair, and Agus Sudjianto", "title": "SHAP values for Explaining CNN-based Text Classification Models", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are increasingly used in natural language processing\n(NLP) models. However, the need to interpret and explain the results from\ncomplex algorithms are limiting their widespread adoption in regulated\nindustries such as banking. There has been recent work on interpretability of\nmachine learning algorithms with structured data. But there are only limited\ntechniques for NLP applications where the problem is more challenging due to\nthe size of the vocabulary, high-dimensional nature, and the need to consider\ntextual coherence and language structure. This paper develops a methodology to\ncompute SHAP values for local explainability of CNN-based text classification\nmodels. The approach is also extended to compute global scores to assess the\nimportance of features. The results are illustrated on sentiment analysis of\nAmazon Electronic Review data.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 21:28:41 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 01:27:41 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Zhao", "Wei", ""], ["Joshi", "Tarun", ""], ["Nair", "Vijayan N.", ""], ["Sudjianto", "Agus", ""]]}, {"id": "2008.11827", "submitter": "Wenqian Dong", "authors": "Wenqian Dong, Zhen Xie, Gokcen Kestor and Dong Li", "title": "Smart-PGSim: Using Neural Network to Accelerate AC-OPF Power Grid\n  Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimal power flow (OPF) problem is one of the most important\noptimization problems for the operation of the power grid. It calculates the\noptimum scheduling of the committed generation units. In this paper, we develop\na neural network approach to the problem of accelerating the current optimal\npower flow (AC-OPF) by generating an intelligent initial solution. The high\nquality of the initial solution and guidance of other outputs generated by the\nneural network enables faster convergence to the solution without losing\noptimality of final solution as computed by traditional methods. Smart-PGSim\ngenerates a novel multitask-learning neural network model to accelerate the\nAC-OPF simulation. Smart-PGSim also imposes the physical constraints of the\nsimulation on the neural network automatically. Smart-PGSim brings an average\nof 49.2% performance improvement (up to 91%), computed over 10,000 problem\nsimulations, with respect to the original AC-OPF implementation, without losing\nthe optimality of the final solution.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 21:31:08 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Dong", "Wenqian", ""], ["Xie", "Zhen", ""], ["Kestor", "Gokcen", ""], ["Li", "Dong", ""]]}, {"id": "2008.11828", "submitter": "Dilip K. Prasad", "authors": "Rohit Agarwal and Arif Ahmed Sekh and Krishna Agarwal and Dilip K.\n  Prasad", "title": "Auxiliary Network: Scalable and agile online learning for dynamic system\n  with inconsistently available inputs", "comments": "under review at NIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Streaming classification methods assume the number of input features is fixed\nand always received. But in many real-world scenarios demand is some input\nfeatures are reliable while others are unreliable or inconsistent. In this\npaper, we propose a novel deep learning-based model called Auxiliary Network\n(Aux-Net), which is scalable and agile. It employs a weighted ensemble of\nclassifiers to give a final outcome. The Aux-Net model is based on the hedging\nalgorithm and online gradient descent. It employs a model of varying depth in\nan online setting using single pass learning. Aux-Net is a foundational work\ntowards scalable neural network model for a dynamic complex environment\nrequiring ad hoc or inconsistent input data. The efficacy of Aux-Net is shown\non public dataset.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 21:37:24 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Agarwal", "Rohit", ""], ["Sekh", "Arif Ahmed", ""], ["Agarwal", "Krishna", ""], ["Prasad", "Dilip K.", ""]]}, {"id": "2008.11830", "submitter": "Hammond Pearce", "authors": "Hammond Pearce, Xin Yang, Partha S. Roop, Marc Katzef, T\\'orur\n  Biskopst{\\o} Str{\\o}m", "title": "Designing Neural Networks for Real-Time Systems", "comments": "4 pages, 2 figures. IEEE Embedded Systems Letters, 2020", "journal-ref": null, "doi": "10.1109/LES.2020.3009910", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Networks (ANNs) are increasingly being used within\nsafety-critical Cyber-Physical Systems (CPSs). They are often co-located with\ntraditional embedded software, and may perform advisory or control-based roles.\nIt is important to validate both the timing and functional correctness of these\nsystems. However, most approaches in the literature consider guaranteeing only\nthe functionality of ANN based controllers. This issue stems largely from the\nimplementation strategies used within common neural network frameworks -- their\nunderlying source code is often simply unsuitable for formal techniques such as\nstatic timing analysis. As a result, developers of safety-critical CPS must\nrely on informal techniques such as measurement based approaches to prove\ncorrectness, techniques that provide weak guarantees at best. In this work we\naddress this challenge. We propose a design pipeline whereby neural networks\ntrained using the popular deep learning framework Keras are compiled to\nfunctionally equivalent C code. This C code is restricted to simple constructs\nthat may be analysed by existing static timing analysis tools. As a result, if\ncompiled to a suitable time-predictable platform all execution bounds may be\nstatically derived. To demonstrate the benefits of our approach we execute an\nANN trained to drive an autonomous vehicle around a race track. We compile the\nANN to the Patmos time-predictable controller, and show that we can derive\nworst case execution timings.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 21:41:37 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Pearce", "Hammond", ""], ["Yang", "Xin", ""], ["Roop", "Partha S.", ""], ["Katzef", "Marc", ""], ["Str\u00f8m", "T\u00f3rur Biskopst\u00f8", ""]]}, {"id": "2008.11832", "submitter": "Wenqian Dong", "authors": "Wenqian Dong, Jie Liu, Zhen Xie and Dong Li", "title": "Adaptive Neural Network-Based Approximation to Accelerate Eulerian Fluid\n  Simulation", "comments": null, "journal-ref": null, "doi": "10.1145/3295500.3356147", "report-no": null, "categories": "cs.LG cs.DC physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Eulerian fluid simulation is an important HPC application. The neural\nnetwork has been applied to accelerate it. The current methods that accelerate\nthe fluid simulation with neural networks lack flexibility and generalization.\nIn this paper, we tackle the above limitation and aim to enhance the\napplicability of neural networks in the Eulerian fluid simulation. We introduce\nSmartfluidnet, a framework that automates model generation and application.\nGiven an existing neural network as input, Smartfluidnet generates multiple\nneural networks before the simulation to meet the execution time and simulation\nquality requirement. During the simulation, Smartfluidnet dynamically switches\nthe neural networks to make the best efforts to reach the user requirement on\nsimulation quality. Evaluating with 20,480 input problems, we show that\nSmartfluidnet achieves 1.46x and 590x speedup comparing with a state-of-the-art\nneural network model and the original fluid simulation respectively on an\nNVIDIA Titan X Pascal GPU, while providing better simulation quality than the\nstate-of-the-art model.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 21:44:44 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Dong", "Wenqian", ""], ["Liu", "Jie", ""], ["Xie", "Zhen", ""], ["Li", "Dong", ""]]}, {"id": "2008.11835", "submitter": "Rylan Perumal", "authors": "Rylan Perumal and Terence L van Zyl", "title": "Surrogate Assisted Methods for the Parameterisation of Agent-Based\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter calibration is a major challenge in agent-based modelling and\nsimulation (ABMS). As the complexity of agent-based models (ABMs) increase, the\nnumber of parameters required to be calibrated grows. This leads to the ABMS\nequivalent of the \\say{curse of dimensionality}. We propose an ABMS framework\nwhich facilitates the effective integration of different sampling methods and\nsurrogate models (SMs) in order to evaluate how these strategies affect\nparameter calibration and exploration. We show that surrogate assisted methods\nperform better than the standard sampling methods. In addition, we show that\nthe XGBoost and Decision Tree SMs are most optimal overall with regards to our\nanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 21:47:02 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Perumal", "Rylan", ""], ["van Zyl", "Terence L", ""]]}, {"id": "2008.11845", "submitter": "Shlomo Chazan", "authors": "Hodaya Hammer and Shlomo E. Chazan and Jacob Goldberger and Sharon\n  Gannot", "title": "FCN Approach for Dynamically Locating Multiple Speakers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a deep neural network-based online multi-speaker\nlocalisation algorithm. Following the W-disjoint orthogonality principle in the\nspectral domain, each time-frequency (TF) bin is dominated by a single speaker,\nand hence by a single direction of arrival (DOA). A fully convolutional network\nis trained with instantaneous spatial features to estimate the DOA for each TF\nbin. The high resolution classification enables the network to accurately and\nsimultaneously localize and track multiple speakers, both static and dynamic.\nElaborated experimental study using both simulated and real-life recordings in\nstatic and dynamic scenarios, confirms that the proposed algorithm outperforms\nboth classic and recent deep-learning-based algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 22:21:29 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Hammer", "Hodaya", ""], ["Chazan", "Shlomo E.", ""], ["Goldberger", "Jacob", ""], ["Gannot", "Sharon", ""]]}, {"id": "2008.11846", "submitter": "Habib Asseiss Neto", "authors": "Habib Asseiss Neto and Ronnie C. O. Alves and Sergio V. A. Campos", "title": "NASirt: AutoML based learning with instance-level complexity information", "comments": "to be published", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Designing adequate and precise neural architectures is a challenging task,\noften done by highly specialized personnel. AutoML is a machine learning field\nthat aims to generate good performing models in an automated way. Spectral data\nsuch as those obtained from biological analysis have generally a lot of\nimportant information, and these data are specifically well suited to\nConvolutional Neural Networks (CNN) due to their image-like shape. In this work\nwe present NASirt, an AutoML methodology based on Neural Architecture Search\n(NAS) that finds high accuracy CNN architectures for spectral datasets. The\nproposed methodology relies on the Item Response Theory (IRT) for obtaining\ncharacteristics from an instance level, such as discrimination and difficulty,\nand it is able to define a rank of top performing submodels. Several\nexperiments are performed in order to demonstrate the methodology's performance\nwith different spectral datasets. Accuracy results are compared to other\nbenchmarks methods, such as a high performing, manually crafted CNN and the\nAuto-Keras AutoML tool. The results show that our method performs, in most\ncases, better than the benchmarks, achieving average accuracy as high as\n97.40%.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 22:21:44 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 18:17:52 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Neto", "Habib Asseiss", ""], ["Alves", "Ronnie C. O.", ""], ["Campos", "Sergio V. A.", ""]]}, {"id": "2008.11849", "submitter": "Ziheng Wang", "authors": "Ziheng Wang", "title": "SparseRT: Accelerating Unstructured Sparsity on GPUs for Deep Learning\n  Inference", "comments": "Accepted for publication at PACT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been a flurry of research in deep neural network\npruning and compression. Early approaches prune weights individually. However,\nit is difficult to take advantage of the resulting unstructured sparsity\npatterns on modern hardware like GPUs. As a result, pruning strategies which\nimpose sparsity structures in the weights have become more popular.\nHowever,these structured pruning approaches typically lead to higher losses in\naccuracy than unstructured pruning. In this paper, we present SparseRT, a code\ngenerator that leverage unstructured sparsity to accelerate sparse linear\nalgebra operations in deep learning inference on GPUs. For 1x1 convolutions and\nfully connected layers, we demonstrate geometric mean of speedups of 3.4x over\nthe equivalent dense computation at 90% sparsity and 5.4x at 95% sparsity when\nevaluated on hundreds of test cases in deep learning. For sparse 3x3\nconvolutions, we show speedups of over 5x on use cases in ResNet-50.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 22:36:12 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Wang", "Ziheng", ""]]}, {"id": "2008.11852", "submitter": "Teng Liu", "authors": "Teng Liu, Hong Wang, Bing Lu, Jun Li, Dongpu Cao", "title": "Decision-making for Autonomous Vehicles on Highway: Deep Reinforcement\n  Learning with Continuous Action Horizon", "comments": "9 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-making strategy for autonomous vehicles de-scribes a sequence of\ndriving maneuvers to achieve a certain navigational mission. This paper\nutilizes the deep reinforcement learning (DRL) method to address the\ncontinuous-horizon decision-making problem on the highway. First, the vehicle\nkinematics and driving scenario on the freeway are introduced. The running\nobjective of the ego automated vehicle is to execute an efficient and smooth\npolicy without collision. Then, the particular algorithm named proximal policy\noptimization (PPO)-enhanced DRL is illustrated. To overcome the challenges in\ntardy training efficiency and sample inefficiency, this applied algorithm could\nrealize high learning efficiency and excellent control performance. Finally,\nthe PPO-DRL-based decision-making strategy is estimated from multiple\nperspectives, including the optimality, learning efficiency, and adaptability.\nIts potential for online application is discussed by applying it to similar\ndriving scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 22:49:27 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Liu", "Teng", ""], ["Wang", "Hong", ""], ["Lu", "Bing", ""], ["Li", "Jun", ""], ["Cao", "Dongpu", ""]]}, {"id": "2008.11856", "submitter": "Mohammad Jafar Mashhadi Ebrahim", "authors": "Mohammad Jafar Mashhadi and Hadi Hemmati", "title": "Hybrid Deep Neural Networks to Infer State Models of Black-Box Systems", "comments": "11 Pages, ASE '20 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Inferring behavior model of a running software system is quite useful for\nseveral automated software engineering tasks, such as program comprehension,\nanomaly detection, and testing. Most existing dynamic model inference\ntechniques are white-box, i.e., they require source code to be instrumented to\nget run-time traces. However, in many systems, instrumenting the entire source\ncode is not possible (e.g., when using black-box third-party libraries) or\nmight be very costly. Unfortunately, most black-box techniques that detect\nstates over time are either univariate, or make assumptions on the data\ndistribution, or have limited power for learning over a long period of past\nbehavior. To overcome the above issues, in this paper, we propose a hybrid deep\nneural network that accepts as input a set of time series, one per input/output\nsignal of the system, and applies a set of convolutional and recurrent layers\nto learn the non-linear correlations between signals and the patterns, over\ntime. We have applied our approach on a real UAV auto-pilot solution from our\nindustry partner with half a million lines of C code. We ran 888 random recent\nsystem-level test cases and inferred states, over time. Our comparison with\nseveral traditional time series change point detection techniques showed that\nour approach improves their performance by up to 102%, in terms of finding\nstate change points, measured by F1 score. We also showed that our state\nclassification algorithm provides on average 90.45% F1 score, which improves\ntraditional classification algorithms by up to 17%.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 23:24:34 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Mashhadi", "Mohammad Jafar", ""], ["Hemmati", "Hadi", ""]]}, {"id": "2008.11865", "submitter": "Vardan Papyan", "authors": "Vardan Papyan", "title": "Traces of Class/Cross-Class Structure Pervade Deep Learning Spectra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous researchers recently applied empirical spectral analysis to the\nstudy of modern deep learning classifiers. We identify and discuss an important\nformal class/cross-class structure and show how it lies at the origin of the\nmany visually striking features observed in deepnet spectra, some of which were\nreported in recent articles, others are unveiled here for the first time. These\ninclude spectral outliers, \"spikes\", and small but distinct continuous\ndistributions, \"bumps\", often seen beyond the edge of a \"main bulk\".\n  The significance of the cross-class structure is illustrated in three ways:\n(i) we prove the ratio of outliers to bulk in the spectrum of the Fisher\ninformation matrix is predictive of misclassification, in the context of\nmultinomial logistic regression; (ii) we demonstrate how, gradually with depth,\na network is able to separate class-distinctive information from class\nvariability, all while orthogonalizing the class-distinctive information; and\n(iii) we propose a correction to KFAC, a well-known second-order optimization\nalgorithm for training deepnets.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 00:08:49 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Papyan", "Vardan", ""]]}, {"id": "2008.11869", "submitter": "Xinsong Zhang", "authors": "Xinsong Zhang, Pengshuai Li, and Hang Li", "title": "AMBERT: A Pre-trained Language Model with Multi-Grained Tokenization", "comments": "To be appeared in Findings of ACL2021. In this version, we develop a\n  simplified method to improve the efficiency of AMBERT in inference, which\n  still performs better than BERT with the same computational cost as BERT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models such as BERT have exhibited remarkable\nperformances in many tasks in natural language understanding (NLU). The tokens\nin the models are usually fine-grained in the sense that for languages like\nEnglish they are words or sub-words and for languages like Chinese they are\ncharacters. In English, for example, there are multi-word expressions which\nform natural lexical units and thus the use of coarse-grained tokenization also\nappears to be reasonable. In fact, both fine-grained and coarse-grained\ntokenizations have advantages and disadvantages for learning of pre-trained\nlanguage models. In this paper, we propose a novel pre-trained language model,\nreferred to as AMBERT (A Multi-grained BERT), on the basis of both fine-grained\nand coarse-grained tokenizations. For English, AMBERT takes both the sequence\nof words (fine-grained tokens) and the sequence of phrases (coarse-grained\ntokens) as input after tokenization, employs one encoder for processing the\nsequence of words and the other encoder for processing the sequence of the\nphrases, utilizes shared parameters between the two encoders, and finally\ncreates a sequence of contextualized representations of the words and a\nsequence of contextualized representations of the phrases. Experiments have\nbeen conducted on benchmark datasets for Chinese and English, including CLUE,\nGLUE, SQuAD and RACE. The results show that AMBERT can outperform BERT in all\ncases, particularly the improvements are significant for Chinese. We also\ndevelop a method to improve the efficiency of AMBERT in inference, which still\nperforms better than BERT with the same computational cost as BERT.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 00:23:48 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 05:29:27 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 06:53:33 GMT"}, {"version": "v4", "created": "Thu, 27 May 2021 10:39:47 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Zhang", "Xinsong", ""], ["Li", "Pengshuai", ""], ["Li", "Hang", ""]]}, {"id": "2008.11880", "submitter": "Martin Khannouz", "authors": "Martin Khannouz and Tristan Glatard", "title": "A benchmark of data stream classification for human activity recognition\n  on connected objects", "comments": "8 pages, 9 figures, for a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper evaluates data stream classifiers from the perspective of\nconnected devices, focusing on the use case of HAR. We measure both\nclassification performance and resource consumption (runtime, memory, and\npower) of five usual stream classification algorithms, implemented in a\nconsistent library, and applied to two real human activity datasets and to\nthree synthetic datasets. Regarding classification performance, results show an\noverall superiority of the HT, the MF, and the NB classifiers over the FNN and\nthe Micro Cluster Nearest Neighbor (MCNN) classifiers on 4 datasets out of 6,\nincluding the real ones. In addition, the HT, and to some extent MCNN, are the\nonly classifiers that can recover from a concept drift. Overall, the three\nleading classifiers still perform substantially lower than an offline\nclassifier on the real datasets. Regarding resource consumption, the HT and the\nMF are the most memory intensive and have the longest runtime, however, no\ndifference in power consumption is found between classifiers. We conclude that\nstream learning for HAR on connected objects is challenged by two factors which\ncould lead to interesting future work: a high memory consumption and low F1\nscores overall.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 01:42:07 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Khannouz", "Martin", ""], ["Glatard", "Tristan", ""]]}, {"id": "2008.11881", "submitter": "Parth Mannan", "authors": "Parth Mannan, Ananda Samajdar and Tushar Krishna", "title": "CLAN: Continuous Learning using Asynchronous Neuroevolution on Commodity\n  Edge Devices", "comments": "Accepted and appears in ISPASS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in machine learning algorithms, especially the\ndevelopment of Deep Neural Networks (DNNs) have transformed the landscape of\nArtificial Intelligence (AI). With every passing day, deep learning based\nmethods are applied to solve new problems with exceptional results. The portal\nto the real world is the edge. The true impact of AI can only be fully realized\nif we can have AI agents continuously interacting with the real world and\nsolving everyday problems. Unfortunately, high compute and memory requirements\nof DNNs acts a huge barrier towards this vision. Today we circumvent this\nproblem by deploying special purpose inference hardware on the edge while\nprocuring trained models from the cloud. This approach, however, relies on\nconstant interaction with the cloud for transmitting all the data, training on\nmassive GPU clusters, and downloading updated models. This is challenging for\nbandwidth, privacy, and constant connectivity concerns that autonomous agents\nmay exhibit. In this paper we evaluate techniques for enabling adaptive\nintelligence on edge devices with zero interaction with any high-end\ncloud/server. We build a prototype distributed system of Raspberry Pis\ncommunicating via WiFi running NeuroEvolutionary (NE) learning and inference.\nWe evaluate the performance of such a collaborative system and detail the\ncompute/communication characteristics of different arrangements of the system\nthat trade-off parallelism versus communication. Using insights from our\nanalysis, we also propose algorithmic modifications to reduce communication by\nup to 3.6x during the learning phase to enhance scalability even further and\nmatch performance of higher end computing devices at scale. We believe that\nthese insights will enable algorithm-hardware co-design efforts for enabling\ncontinuous learning on the edge.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 01:49:21 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Mannan", "Parth", ""], ["Samajdar", "Ananda", ""], ["Krishna", "Tushar", ""]]}, {"id": "2008.11901", "submitter": "Fang-Chieh Chou", "authors": "Sudeep Fadadu, Shreyash Pandey, Darshan Hegde, Yi Shi, Fang-Chieh\n  Chou, Nemanja Djuric, Carlos Vallespi-Gonzalez", "title": "Multi-View Fusion of Sensor Data for Improved Perception and Prediction\n  in Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end method for object detection and trajectory\nprediction utilizing multi-view representations of LiDAR returns. Our method\nbuilds on a state-of-the-art Bird's-Eye View (BEV) network that fuses voxelized\nfeatures from a sequence of historical LiDAR data as well as rasterized\nhigh-definition map to perform detection and prediction tasks. We extend the\nBEV network with additional LiDAR Range-View (RV) features that use the raw\nLiDAR information in its native, non-quantized representation. The RV feature\nmap is projected into BEV and fused with the BEV features computed from LiDAR\nand high-definition map. The fused features are then further processed to\noutput the final detections and trajectories, within a single end-to-end\ntrainable network. In addition, using this framework the RV fusion of LiDAR and\ncamera is performed in a straightforward and computational efficient manner.\nThe proposed approach improves the state-of-the-art on proprietary large-scale\nreal-world data collected by a fleet of self-driving vehicles, as well as on\nthe public nuScenes data set.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 03:32:25 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Fadadu", "Sudeep", ""], ["Pandey", "Shreyash", ""], ["Hegde", "Darshan", ""], ["Shi", "Yi", ""], ["Chou", "Fang-Chieh", ""], ["Djuric", "Nemanja", ""], ["Vallespi-Gonzalez", "Carlos", ""]]}, {"id": "2008.11908", "submitter": "Nasser Ghadiri", "authors": "Ensieh Davoodijam, Nasser Ghadiri, Maryam Lotfi Shahreza, Fabio\n  Rinaldi", "title": "MultiGBS: A multi-layer graph approach to biomedical summarization", "comments": null, "journal-ref": "Journal of Biomedical Informatics, Available online 18 February\n  2021, 103706", "doi": "10.1016/j.jbi.2021.103706", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic text summarization methods generate a shorter version of the input\ntext to assist the reader in gaining a quick yet informative gist. Existing\ntext summarization methods generally focus on a single aspect of text when\nselecting sentences, causing the potential loss of essential information. In\nthis study, we propose a domain-specific method that models a document as a\nmulti-layer graph to enable multiple features of the text to be processed at\nthe same time. The features we used in this paper are word similarity, semantic\nsimilarity, and co-reference similarity, which are modelled as three different\nlayers. The unsupervised method selects sentences from the multi-layer graph\nbased on the MultiRank algorithm and the number of concepts. The proposed\nMultiGBS algorithm employs UMLS and extracts the concepts and relationships\nusing different tools such as SemRep, MetaMap, and OGER. Extensive evaluation\nby ROUGE and BERTScore shows increased F-measure values.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 04:22:37 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 18:24:13 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Davoodijam", "Ensieh", ""], ["Ghadiri", "Nasser", ""], ["Shahreza", "Maryam Lotfi", ""], ["Rinaldi", "Fabio", ""]]}, {"id": "2008.11911", "submitter": "Nimit Kalra", "authors": "Brady Zhou, Nimit Kalra, Philipp Kr\\\"ahenb\\\"uhl", "title": "Domain Adaptation Through Task Distillation", "comments": "Published in European Conference on Computer Vision (ECCV 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks devour millions of precisely annotated images to build their\ncomplex and powerful representations. Unfortunately, tasks like autonomous\ndriving have virtually no real-world training data. Repeatedly crashing a car\ninto a tree is simply too expensive. The commonly prescribed solution is\nsimple: learn a representation in simulation and transfer it to the real world.\nHowever, this transfer is challenging since simulated and real-world visual\nexperiences vary dramatically. Our core observation is that for certain tasks,\nsuch as image recognition, datasets are plentiful. They exist in any\ninteresting domain, simulated or real, and are easy to label and extend. We use\nthese recognition datasets to link up a source and target domain to transfer\nmodels between them in a task distillation framework. Our method can\nsuccessfully transfer navigation policies between drastically different\nsimulators: ViZDoom, SuperTuxKart, and CARLA. Furthermore, it shows promising\nresults on standard domain adaptation benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 04:44:49 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Zhou", "Brady", ""], ["Kalra", "Nimit", ""], ["Kr\u00e4henb\u00fchl", "Philipp", ""]]}, {"id": "2008.11918", "submitter": "Zhimei Ren", "authors": "Zhimei Ren and Zhengyuan Zhou", "title": "Dynamic Batch Learning in High-Dimensional Sparse Linear Contextual\n  Bandits", "comments": "36 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of dynamic batch learning in high-dimensional sparse\nlinear contextual bandits, where a decision maker can only adapt decisions at a\nbatch level. In particular, the decision maker, only observing rewards at the\nend of each batch, dynamically decides how many individuals to include in the\nnext batch (at the current batch's end) and what personalized action-selection\nscheme to adopt within the batch. Such batch constraints are ubiquitous in a\nvariety of practical contexts, including personalized product offerings in\nmarketing and medical treatment selection in clinical trials. We characterize\nthe fundamental learning limit in this problem via a novel lower bound analysis\nand provide a simple, exploration-free algorithm that uses the LASSO estimator,\nwhich achieves the minimax optimal performance characterized by the lower bound\n(up to log factors). To our best knowledge, our work provides the first inroad\ninto a rigorous understanding of dynamic batch learning with high-dimensional\ncovariates. We also demonstrate the efficacy of our algorithm on both synthetic\ndata and the Warfarin medical dosing data. The empirical results show that with\nthree batches (hence only two opportunities to adapt), our algorithm already\nperforms comparably (in terms of statistical performance) to the\nstate-of-the-art fully online high-dimensional linear contextual bandits\nalgorithm. As an added bonus, since our algorithm operates in batches, it is\norders of magnitudes faster than fully online learning algorithms. As such, our\nalgorithm provides a desirable candidate for practical data-driven personalized\ndecision making problems, where limited adaptivity is often a hard constraint.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 05:34:34 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 01:03:55 GMT"}, {"version": "v3", "created": "Wed, 30 Jun 2021 19:40:59 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Ren", "Zhimei", ""], ["Zhou", "Zhengyuan", ""]]}, {"id": "2008.11922", "submitter": "Maxim Naumov", "authors": "Tigran Ishkhanov, Maxim Naumov, Xianjie Chen, Yan Zhu, Yuan Zhong,\n  Alisson Gusatti Azzolini, Chonglin Sun, Frank Jiang, Andrey Malevich and\n  Liang Xiong", "title": "Time-based Sequence Model for Personalization and Recommendation Systems", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a novel recommendation model that explicitly\nincorporates time information. The model relies on an embedding layer and TSL\nattention-like mechanism with inner products in different vector spaces, that\ncan be thought of as a modification of multi-headed attention. This mechanism\nallows the model to efficiently treat sequences of user behavior of different\nlength. We study the properties of our state-of-the-art model on statistically\ndesigned data set. Also, we show that it outperforms more complex models with\nlonger sequence length on the Taobao User Behavior dataset.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 05:46:47 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Ishkhanov", "Tigran", ""], ["Naumov", "Maxim", ""], ["Chen", "Xianjie", ""], ["Zhu", "Yan", ""], ["Zhong", "Yuan", ""], ["Azzolini", "Alisson Gusatti", ""], ["Sun", "Chonglin", ""], ["Jiang", "Frank", ""], ["Malevich", "Andrey", ""], ["Xiong", "Liang", ""]]}, {"id": "2008.11930", "submitter": "Przemek Mroz", "authors": "Przemek Mroz", "title": "Identifying microlensing events using neural networks", "comments": "submitted", "journal-ref": "Acta Astron., 70, 169 (2020)", "doi": "10.32023/0001-5237/70.3.1", "report-no": null, "categories": "astro-ph.IM astro-ph.EP astro-ph.SR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current gravitational microlensing surveys are observing hundreds of millions\nof stars in the Galactic bulge - which makes finding rare microlensing events a\nchallenging tasks. In almost all previous works, microlensing events have been\ndetected either by applying very strict selection cuts or manually inspecting\ntens of thousands of light curves. However, the number of microlensing events\nexpected in the future space-based microlensing experiments forces us to\nconsider fully-automated approaches. They are especially important for\nselecting binary-lens events that often exhibit complex light curve\nmorphologies and are otherwise difficult to find. There are no dedicated\nselection algorithms for binary-lens events in the literature, which hampers\ntheir statistical studies. Here, we present two simple neural-network-based\nclassifiers for detecting single and binary microlensing events. We demonstrate\ntheir robustness using OGLE-III and OGLE-IV data sets and show they perform\nwell on microlensing events detected in data from the Zwicky Transient Facility\n(ZTF). Classifiers are able to correctly recognize ~98% of single-lens events\nand 80-85% of binary-lens events.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 06:18:44 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Mroz", "Przemek", ""]]}, {"id": "2008.11944", "submitter": "Thomas Bonald", "authors": "Nathan de Lara (IP Paris), Thomas Bonald (IP Paris)", "title": "A Consistent Diffusion-Based Algorithm for Semi-Supervised\n  Classification on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised classification on graphs aims at assigning labels to all\nnodes of a graph based on the labels known for a few nodes, called the seeds.\nThe most popular algorithm relies on the principle of heat diffusion, where the\nlabels of the seeds are spread by thermo-conductance and the temperature of\neach node is used as a score function for each label. Using a simple block\nmodel, we prove that this algorithm is not consistent unless the temperatures\nof the nodes are centered before classification. We show that this simple\nmodification of the algorithm is enough to get significant performance gains on\nreal data.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 06:52:13 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["de Lara", "Nathan", "", "IP Paris"], ["Bonald", "Thomas", "", "IP Paris"]]}, {"id": "2008.11945", "submitter": "Yongquan Yang", "authors": "Yongquan Yang and Zhongxi Zheng", "title": "Moderately supervised learning: definition and framework", "comments": "7pages,2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning (SL) has achieved remarkable success in numerous\nartificial intelligence applications. In the current literature, by referring\nto the properties of the ground-truth labels prepared for a training data set,\nSL is roughly categorized as fully supervised learning (FSL) and weakly\nsupervised learning (WSL). However, solutions for various FSL tasks have shown\nthat the given ground-truth labels are not always learnable, and the target\ntransformation from the given ground-truth labels to learnable targets can\nsignificantly affect the performance of the final FSL solutions. Without\nconsidering the properties of the target transformation from the given\nground-truth labels to learnable targets, the roughness of the FSL category\nconceals some details that can be critical to building the optimal solutions\nfor some specific FSL tasks. Thus, it is desirable to reveal these details.\nThis article attempts to achieve this goal by expanding the categorization of\nFSL and investigating the subtype that plays the central role in FSL. Taking\ninto consideration the properties of the target transformation from the given\nground-truth labels to learnable targets, we first categorize FSL into three\nnarrower subtypes. Then, we focus on the subtype moderately supervised learning\n(MSL). MSL concerns the situation where the given ground-truth labels are\nideal, but due to the simplicity in annotation of the given ground-truth\nlabels, careful designs are required to transform the given ground-truth labels\ninto learnable targets. From the perspectives of definition and framework, we\ncomprehensively illustrate MSL to reveal what details are concealed by the\nroughness of the FSL category. Finally, discussions on the revealed details\nsuggest that MSL should be given more attention.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 06:53:53 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Yang", "Yongquan", ""], ["Zheng", "Zhongxi", ""]]}, {"id": "2008.11966", "submitter": "Xiaosheng Zhuang", "authors": "Yuchen Xiao and Xiaosheng Zhuang", "title": "Adaptive directional Haar tight framelets on bounded domains for digraph\n  signal representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on hierarchical partitions, we provide the construction of Haar-type\ntight framelets on any compact set $K\\subseteq \\mathbb{R}^d$. In particular, on\nthe unit block $[0,1]^d$, such tight framelets can be built to be with\nadaptivity and directionality. We show that the adaptive directional Haar tight\nframelet systems can be used for digraph signal representations. Some examples\nare provided to illustrate results in this paper.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 07:45:46 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Xiao", "Yuchen", ""], ["Zhuang", "Xiaosheng", ""]]}, {"id": "2008.11979", "submitter": "Ayoub Bagheri Dr.", "authors": "Ayoub Bagheri, T. Katrien J. Groenhof, Wouter B. Veldhuis, Pim A. de\n  Jong, Folkert W. Asselbergs, Daniel L. Oberski", "title": "Multimodal Learning for Cardiovascular Risk Prediction using EHR Data", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health records (EHRs) contain structured and unstructured data of\nsignificant clinical and research value. Various machine learning approaches\nhave been developed to employ information in EHRs for risk prediction. The\nmajority of these attempts, however, focus on structured EHR fields and lose\nthe vast amount of information in the unstructured texts. To exploit the\npotential information captured in EHRs, in this study we propose a multimodal\nrecurrent neural network model for cardiovascular risk prediction that\nintegrates both medical texts and structured clinical information. The proposed\nmultimodal bidirectional long short-term memory (BiLSTM) model concatenates\nword embeddings to classical clinical predictors before applying them to a\nfinal fully connected neural network. In the experiments, we compare\nperformance of different deep neural network (DNN) architectures including\nconvolutional neural network and long short-term memory in scenarios of using\nclinical variables and chest X-ray radiology reports. Evaluated on a data set\nof real world patients with manifest vascular disease or at high-risk for\ncardiovascular disease, the proposed BiLSTM model demonstrates state-of-the-art\nperformance and outperforms other DNN baseline architectures.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 08:09:02 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Bagheri", "Ayoub", ""], ["Groenhof", "T. Katrien J.", ""], ["Veldhuis", "Wouter B.", ""], ["de Jong", "Pim A.", ""], ["Asselbergs", "Folkert W.", ""], ["Oberski", "Daniel L.", ""]]}, {"id": "2008.11988", "submitter": "Guang Yu", "authors": "Guang Yu, Siqi Wang, Zhiping Cai, En Zhu, Chuanfu Xu, Jianping Yin,\n  Marius Kloft", "title": "Cloze Test Helps: Effective Video Anomaly Detection via Learning to\n  Complete Video Events", "comments": "To be published as an oral paper in Proceedings of the 28th ACM\n  International Conference on Multimedia (ACM MM '20). 9 pages, 7 figures", "journal-ref": null, "doi": "10.1145/3394171.3413973", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a vital topic in media content interpretation, video anomaly detection\n(VAD) has made fruitful progress via deep neural network (DNN). However,\nexisting methods usually follow a reconstruction or frame prediction routine.\nThey suffer from two gaps: (1) They cannot localize video activities in a both\nprecise and comprehensive manner. (2) They lack sufficient abilities to utilize\nhigh-level semantics and temporal context information. Inspired by\nfrequently-used cloze test in language study, we propose a brand-new VAD\nsolution named Video Event Completion (VEC) to bridge gaps above: First, we\npropose a novel pipeline to achieve both precise and comprehensive enclosure of\nvideo activities. Appearance and motion are exploited as mutually complimentary\ncues to localize regions of interest (RoIs). A normalized spatio-temporal cube\n(STC) is built from each RoI as a video event, which lays the foundation of VEC\nand serves as a basic processing unit. Second, we encourage DNN to capture\nhigh-level semantics by solving a visual cloze test. To build such a visual\ncloze test, a certain patch of STC is erased to yield an incomplete event (IE).\nThe DNN learns to restore the original video event from the IE by inferring the\nmissing patch. Third, to incorporate richer motion dynamics, another DNN is\ntrained to infer erased patches' optical flow. Finally, two ensemble strategies\nusing different types of IE and modalities are proposed to boost VAD\nperformance, so as to fully exploit the temporal context and modality\ninformation for VAD. VEC can consistently outperform state-of-the-art methods\nby a notable margin (typically 1.5%-5% AUROC) on commonly-used VAD benchmarks.\nOur codes and results can be verified at github.com/yuguangnudt/VEC_VAD.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 08:32:51 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Yu", "Guang", ""], ["Wang", "Siqi", ""], ["Cai", "Zhiping", ""], ["Zhu", "En", ""], ["Xu", "Chuanfu", ""], ["Yin", "Jianping", ""], ["Kloft", "Marius", ""]]}, {"id": "2008.11990", "submitter": "Yatin Nandwani", "authors": "Yatin Nandwani, Deepanshu Jindal, Mausam and Parag Singla", "title": "Neural Learning of One-of-Many Solutions for Combinatorial Problems in\n  Structured Output Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has proposed neural architectures for solving combinatorial\nproblems in structured output spaces. In many such problems, there may exist\nmultiple solutions for a given input, e.g. a partially filled Sudoku puzzle may\nhave many completions satisfying all constraints. Further, we are often\ninterested in finding any one of the possible solutions, without any preference\nbetween them. Existing approaches completely ignore this solution multiplicity.\nIn this paper, we argue that being oblivious to the presence of multiple\nsolutions can severely hamper their training ability. Our contribution is two\nfold. First, we formally define the task of learning one-of-many solutions for\ncombinatorial problems in structured output spaces, which is applicable for\nsolving several problems of interest such as N-Queens, and Sudoku. Second, we\npresent a generic learning framework that adapts an existing prediction network\nfor a combinatorial problem to handle solution multiplicity. Our framework uses\na selection module, whose goal is to dynamically determine, for every input,\nthe solution that is most effective for training the network parameters in any\ngiven learning iteration. We propose an RL based approach to jointly train the\nselection module with the prediction network. Experiments on three different\ndomains, and using two different prediction networks, demonstrate that our\nframework significantly improves the accuracy in our setting, obtaining up to\n21 pt gain over the baselines.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 08:37:01 GMT"}, {"version": "v2", "created": "Sun, 4 Apr 2021 15:36:05 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Nandwani", "Yatin", ""], ["Jindal", "Deepanshu", ""], ["Mausam", "", ""], ["Singla", "Parag", ""]]}, {"id": "2008.12001", "submitter": "Wei Fan", "authors": "Wei Fan, Kunpeng Liu, Hao Liu, Pengyang Wang, Yong Ge and Yanjie Fu", "title": "AutoFS: Automated Feature Selection via Diversity-aware Interactive\n  Reinforcement Learning", "comments": "Accepted by ICDM 2020. In this version, we revised some typos or\n  mistakes for camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of balancing effectiveness and efficiency\nin automated feature selection. Feature selection is a fundamental intelligence\nfor machine learning and predictive analysis. After exploring many feature\nselection methods, we observe a computational dilemma: 1) traditional feature\nselection methods (e.g., mRMR) are mostly efficient, but difficult to identify\nthe best subset; 2) the emerging reinforced feature selection methods\nautomatically navigate feature space to explore the best subset, but are\nusually inefficient. Are automation and efficiency always apart from each\nother? Can we bridge the gap between effectiveness and efficiency under\nautomation? Motivated by such a computational dilemma, this study is to develop\na novel feature space navigation method. To that end, we propose an Interactive\nReinforced Feature Selection (IRFS) framework that guides agents by not just\nself-exploration experience, but also diverse external skilled trainers to\naccelerate learning for feature exploration. Specifically, we formulate the\nfeature selection problem into an interactive reinforcement learning framework.\nIn this framework, we first model two trainers skilled at different searching\nstrategies: (1) KBest based trainer; (2) Decision Tree based trainer. We then\ndevelop two strategies: (1) to identify assertive and hesitant agents to\ndiversify agent training, and (2) to enable the two trainers to take the\nteaching role in different stages to fuse the experiences of the trainers and\ndiversify teaching process. Such a hybrid teaching strategy can help agents to\nlearn broader knowledge, and, thereafter, be more effective. Finally, we\npresent extensive experiments on real-world datasets to demonstrate the\nimproved performances of our method: more efficient than existing reinforced\nselection and more effective than classic selection.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 09:11:30 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 05:15:32 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 08:12:04 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Fan", "Wei", ""], ["Liu", "Kunpeng", ""], ["Liu", "Hao", ""], ["Wang", "Pengyang", ""], ["Ge", "Yong", ""], ["Fu", "Yanjie", ""]]}, {"id": "2008.12003", "submitter": "Nikolaos Tziortziotis", "authors": "Yang Qiu, Nikolaos Tziortziotis, Martial Hue, Michalis Vazirgiannis", "title": "Predicting conversions in display advertising based on URL embeddings", "comments": "Accepted at AdKDD 2020 workshop at KDD'20 conference, San Diego, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online display advertising is growing rapidly in recent years thanks to the\nautomation of the ad buying process. Real-time bidding (RTB) allows the\nautomated trading of ad impressions between advertisers and publishers through\nreal-time auctions. In order to increase the effectiveness of their campaigns,\nadvertisers should deliver ads to the users who are highly likely to be\nconverted (i.e., purchase, registration, website visit, etc.) in the near\nfuture. In this study, we introduce and examine different models for estimating\nthe probability of a user converting, given their history of visited URLs.\nInspired by natural language processing, we introduce three URL embedding\nmodels to compute semantically meaningful URL representations. To demonstrate\nthe effectiveness of the different proposed representation and conversion\nprediction models, we have conducted experiments on real logged events\ncollected from an advertising platform.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 09:14:28 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 09:09:26 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Qiu", "Yang", ""], ["Tziortziotis", "Nikolaos", ""], ["Hue", "Martial", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "2008.12005", "submitter": "Raoul Heese", "authors": "Raoul Heese, Michael Bortz", "title": "Adaptive Sampling of Pareto Frontiers with Binary Constraints Using\n  Regression and Classification", "comments": "10 pages, 7 figures, 2 tables; International Conference on Pattern\n  Recognition (ICPR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel adaptive optimization algorithm for black-box\nmulti-objective optimization problems with binary constraints on the foundation\nof Bayes optimization. Our method is based on probabilistic regression and\nclassification models, which act as a surrogate for the optimization goals and\nallow us to suggest multiple design points at once in each iteration. The\nproposed acquisition function is intuitively understandable and can be tuned to\nthe demands of the problems at hand. We also present a novel ellipsoid\ntruncation method to speed up the expected hypervolume calculation in a\nstraightforward way for regression models with a normal probability density. We\nbenchmark our approach with an evolutionary algorithm on multiple test\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 09:15:02 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 10:10:49 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Heese", "Raoul", ""], ["Bortz", "Michael", ""]]}, {"id": "2008.12010", "submitter": "Ivan Lee", "authors": "Shuo Yu, Feng Xia, Jin Xu, Zhikui Chen and Ivan Lee", "title": "OFFER: A Motif Dimensional Framework for Network Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aiming at better representing multivariate relationships, this paper\ninvestigates a motif dimensional framework for higher-order graph learning. The\ngraph learning effectiveness can be improved through OFFER. The proposed\nframework mainly aims at accelerating and improving higher-order graph learning\nresults. We apply the acceleration procedure from the dimensional of network\nmotifs. Specifically, the refined degree for nodes and edges are conducted in\ntwo stages: (1) employ motif degree of nodes to refine the adjacency matrix of\nthe network; and (2) employ motif degree of edges to refine the transition\nprobability matrix in the learning process. In order to assess the efficiency\nof the proposed framework, four popular network representation algorithms are\nmodified and examined. By evaluating the performance of OFFER, both link\nprediction results and clustering results demonstrate that the graph\nrepresentation learning algorithms enhanced with OFFER consistently outperform\nthe original algorithms with higher efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 09:27:31 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Yu", "Shuo", ""], ["Xia", "Feng", ""], ["Xu", "Jin", ""], ["Chen", "Zhikui", ""], ["Lee", "Ivan", ""]]}, {"id": "2008.12016", "submitter": "Deboleena Roy", "authors": "Deboleena Roy, Indranil Chakraborty, Timur Ibrayev and Kaushik Roy", "title": "On the Intrinsic Robustness of NVM Crossbars Against Adversarial Attacks", "comments": "to appear in Proceedings of DAC, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing computational demand of Deep Learning has propelled research\nin special-purpose inference accelerators based on emerging non-volatile memory\n(NVM) technologies. Such NVM crossbars promise fast and energy-efficient\nin-situ Matrix Vector Multiplication (MVM) thus alleviating the long-standing\nvon Neuman bottleneck in today's digital hardware. However, the analog nature\nof computing in these crossbars is inherently approximate and results in\ndeviations from ideal output values, which reduces the overall performance of\nDeep Neural Networks (DNNs) under normal circumstances. In this paper, we study\nthe impact of these non-idealities under adversarial circumstances. We show\nthat the non-ideal behavior of analog computing lowers the effectiveness of\nadversarial attacks, in both Black-Box and White-Box attack scenarios. In a\nnon-adaptive attack, where the attacker is unaware of the analog hardware, we\nobserve that analog computing offers a varying degree of intrinsic robustness,\nwith a peak adversarial accuracy improvement of 35.34%, 22.69%, and 9.90% for\nwhite box PGD (epsilon=1/255, iter=30) for CIFAR-10, CIFAR-100, and ImageNet\nrespectively. We also demonstrate \"Hardware-in-Loop\" adaptive attacks that\ncircumvent this robustness by utilizing the knowledge of the NVM model.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 09:36:50 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 19:48:27 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Roy", "Deboleena", ""], ["Chakraborty", "Indranil", ""], ["Ibrayev", "Timur", ""], ["Roy", "Kaushik", ""]]}, {"id": "2008.12020", "submitter": "Sayantari Ghosh", "authors": "Sayantari Ghosh and Saumik Bhattacharya", "title": "A Data-driven Understanding of COVID-19 Dynamics Using Sequential\n  Genetic Algorithm Based Probabilistic Cellular Automata", "comments": "27 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG cs.NE nlin.CG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 pandemic is severely impacting the lives of billions across the\nglobe. Even after taking massive protective measures like nation-wide\nlockdowns, discontinuation of international flight services, rigorous testing\netc., the infection spreading is still growing steadily, causing thousands of\ndeaths and serious socio-economic crisis. Thus, the identification of the major\nfactors of this infection spreading dynamics is becoming crucial to minimize\nimpact and lifetime of COVID-19 and any future pandemic. In this work, a\nprobabilistic cellular automata based method has been employed to model the\ninfection dynamics for a significant number of different countries. This study\nproposes that for an accurate data-driven modeling of this infection spread,\ncellular automata provides an excellent platform, with a sequential genetic\nalgorithm for efficiently estimating the parameters of the dynamics. To the\nbest of our knowledge, this is the first attempt to understand and interpret\nCOVID-19 data using optimized cellular automata, through genetic algorithm. It\nhas been demonstrated that the proposed methodology can be flexible and robust\nat the same time, and can be used to model the daily active cases, total number\nof infected people and total death cases through systematic parameter\nestimation. Elaborate analyses for COVID-19 statistics of forty countries from\ndifferent continents have been performed, with markedly divergent time\nevolution of the infection spreading because of demographic and socioeconomic\nfactors. The substantial predictive power of this model has been established\nwith conclusions on the key players in this pandemic dynamics.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 09:53:21 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Ghosh", "Sayantari", ""], ["Bhattacharya", "Saumik", ""]]}, {"id": "2008.12025", "submitter": "\\'Alvar Arnaiz-Gonz\\'alez", "authors": "Ludmila I. Kuncheva, Clare E. Matthews, \\'Alvar Arnaiz-Gonz\\'alez,\n  Juan J. Rodr\\'iguez", "title": "Feature Selection from High-Dimensional Data with Very Low Sample Size:\n  A Cautionary Tale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classification problems, the purpose of feature selection is to identify a\nsmall, highly discriminative subset of the original feature set. In many\napplications, the dataset may have thousands of features and only a few dozens\nof samples (sometimes termed `wide'). This study is a cautionary tale\ndemonstrating why feature selection in such cases may lead to undesirable\nresults. In view to highlight the sample size issue, we derive the required\nsample size for declaring two features different. Using an example, we\nillustrate the heavy dependency between feature set and classifier, which poses\na question to classifier-agnostic feature selection methods. However, the\nchoice of a good selector-classifier pair is hampered by the low correlation\nbetween estimated and true error rate, as illustrated by another example. While\nprevious studies raising similar issues validate their message with mostly\nsynthetic data, here we carried out an experiment with 20 real datasets. We\ncreated an exaggerated scenario whereby we cut a very small portion of the data\n(10 instances per class) for feature selection and used the rest of the data\nfor testing. The results reinforce the caution and suggest that it may be\nbetter to refrain from feature selection from very wide datasets rather than\nreturn misleading output to the user.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 10:00:58 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Kuncheva", "Ludmila I.", ""], ["Matthews", "Clare E.", ""], ["Arnaiz-Gonz\u00e1lez", "\u00c1lvar", ""], ["Rodr\u00edguez", "Juan J.", ""]]}, {"id": "2008.12037", "submitter": "Ekaterina Iakovleva", "authors": "Ekaterina Iakovleva, Jakob Verbeek, Karteek Alahari", "title": "Meta-Learning with Shared Amortized Variational Inference", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel amortized variational inference scheme for an empirical\nBayes meta-learning model, where model parameters are treated as latent\nvariables. We learn the prior distribution over model parameters conditioned on\nlimited training data using a variational autoencoder approach. Our framework\nproposes sharing the same amortized inference network between the conditional\nprior and variational posterior distributions over the model parameters. While\nthe posterior leverages both the labeled support and query data, the\nconditional prior is based only on the labeled support data. We show that in\nearlier work, relying on Monte-Carlo approximation, the conditional prior\ncollapses to a Dirac delta function. In contrast, our variational approach\nprevents this collapse and preserves uncertainty over the model parameters. We\nevaluate our approach on the miniImageNet, CIFAR-FS and FC100 datasets, and\npresent results demonstrating its advantages over previous work.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 10:28:13 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Iakovleva", "Ekaterina", ""], ["Verbeek", "Jakob", ""], ["Alahari", "Karteek", ""]]}, {"id": "2008.12050", "submitter": "Diego  Porras", "authors": "Samuel Fern\\'andez-Lorenzo, Diego Porras, Juan Jos\\'e Garc\\'ia-Ripoll", "title": "Hybrid quantum-classical optimization for financial index tracking", "comments": "24 pages, 12 figures", "journal-ref": "Quantum Sci. Technol. 6 034010 (2021)", "doi": "10.1088/2058-9565/abf9af", "report-no": null, "categories": "quant-ph cs.LG q-fin.CP q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tracking a financial index boils down to replicating its trajectory of\nreturns for a well-defined time span by investing in a weighted subset of the\nsecurities included in the benchmark. Picking the optimal combination of assets\nbecomes a challenging NP-hard problem even for moderately large indices\nconsisting of dozens or hundreds of assets, thereby requiring heuristic methods\nto find approximate solutions. Hybrid quantum-classical optimization with\nvariational gate-based quantum circuits arises as a plausible method to improve\nperformance of current schemes. In this work we introduce a heuristic pruning\nalgorithm to find weighted combinations of assets subject to cardinality\nconstraints. We further consider different strategies to respect such\nconstraints and compare the performance of relevant quantum ans\\\"{a}tze and\nclassical optimizers through numerical simulations.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 10:59:21 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Fern\u00e1ndez-Lorenzo", "Samuel", ""], ["Porras", "Diego", ""], ["Garc\u00eda-Ripoll", "Juan Jos\u00e9", ""]]}, {"id": "2008.12065", "submitter": "Md Abul Bashar", "authors": "Md Abul Bashar, Astin-Walmsley Kieren, Heath Kerina, Richi Nayak", "title": "Propensity-to-Pay: Machine Learning for Estimating Prediction\n  Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting a customer's propensity-to-pay at an early point in the revenue\ncycle can provide organisations many opportunities to improve the customer\nexperience, reduce hardship and reduce the risk of impaired cash flow and\noccurrence of bad debt. With the advancements in data science; machine learning\ntechniques can be used to build models to accurately predict a customer's\npropensity-to-pay. Creating effective machine learning models without access to\nlarge and detailed datasets presents some significant challenges. This paper\npresents a case-study, conducted on a dataset from an energy organisation, to\nexplore the uncertainty around the creation of machine learning models that are\nable to predict residential customers entering financial hardship which then\nreduces their ability to pay energy bills. Incorrect predictions can result in\ninefficient resource allocation and vulnerable customers not being proactively\nidentified. This study investigates machine learning models' ability to\nconsider different contexts and estimate the uncertainty in the prediction.\nSeven models from four families of machine learning algorithms are investigated\nfor their novel utilisation. A novel concept of utilising a Baysian Neural\nNetwork to the binary classification problem of propensity-to-pay energy bills\nis proposed and explored for deployment.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 11:49:25 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Bashar", "Md Abul", ""], ["Kieren", "Astin-Walmsley", ""], ["Kerina", "Heath", ""], ["Nayak", "Richi", ""]]}, {"id": "2008.12080", "submitter": "Jason T. L. Wang", "authors": "Haodi Jiang, Jiasheng Wang, Chang Liu, Ju Jing, Hao Liu, Jason T. L.\n  Wang, Haimin Wang", "title": "Identifying and Tracking Solar Magnetic Flux Elements with Deep Learning", "comments": "17 pages, 12 figures", "journal-ref": "The Astrophysical Journal Supplement Series, 250:5 (13pp), 2020", "doi": "10.3847/1538-4365/aba4aa", "report-no": null, "categories": "astro-ph.SR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has drawn a lot of interest in recent years due to its\neffectiveness in processing big and complex observational data gathered from\ndiverse instruments. Here we propose a new deep learning method, called\nSolarUnet, to identify and track solar magnetic flux elements or features in\nobserved vector magnetograms based on the Southwest Automatic Magnetic\nIdentification Suite (SWAMIS). Our method consists of a data pre-processing\ncomponent that prepares training data from the SWAMIS tool, a deep learning\nmodel implemented as a U-shaped convolutional neural network for fast and\naccurate image segmentation, and a post-processing component that prepares\ntracking results. SolarUnet is applied to data from the 1.6 meter Goode Solar\nTelescope at the Big Bear Solar Observatory. When compared to the widely used\nSWAMIS tool, SolarUnet is faster while agreeing mostly with SWAMIS on feature\nsize and flux distributions, and complementing SWAMIS in tracking long-lifetime\nfeatures. Thus, the proposed physics-guided deep learning-based tool can be\nconsidered as an alternative method for solar magnetic tracking.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 12:23:18 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Jiang", "Haodi", ""], ["Wang", "Jiasheng", ""], ["Liu", "Chang", ""], ["Jing", "Ju", ""], ["Liu", "Hao", ""], ["Wang", "Jason T. L.", ""], ["Wang", "Haimin", ""]]}, {"id": "2008.12085", "submitter": "Juan Diego Ortega", "authors": "Juan Diego Ortega, Neslihan Kose, Paola Ca\\~nas, Min-An Chao,\n  Alexander Unnervik, Marcos Nieto, Oihana Otaegui, Luis Salgado", "title": "DMD: A Large-Scale Multi-Modal Driver Monitoring Dataset for Attention\n  and Alertness Analysis", "comments": "Accepted to ECCV 2020 workshop - Assistive Computer Vision and\n  Robotics", "journal-ref": null, "doi": "10.1007/978-3-030-66823-5_23", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Vision is the richest and most cost-effective technology for Driver\nMonitoring Systems (DMS), especially after the recent success of Deep Learning\n(DL) methods. The lack of sufficiently large and comprehensive datasets is\ncurrently a bottleneck for the progress of DMS development, crucial for the\ntransition of automated driving from SAE Level-2 to SAE Level-3. In this paper,\nwe introduce the Driver Monitoring Dataset (DMD), an extensive dataset which\nincludes real and simulated driving scenarios: distraction, gaze allocation,\ndrowsiness, hands-wheel interaction and context data, in 41 hours of RGB, depth\nand IR videos from 3 cameras capturing face, body and hands of 37 drivers. A\ncomparison with existing similar datasets is included, which shows the DMD is\nmore extensive, diverse, and multi-purpose. The usage of the DMD is illustrated\nby extracting a subset of it, the dBehaviourMD dataset, containing 13\ndistraction activities, prepared to be used in DL training processes.\nFurthermore, we propose a robust and real-time driver behaviour recognition\nsystem targeting a real-world application that can run on cost-efficient\nCPU-only platforms, based on the dBehaviourMD. Its performance is evaluated\nwith different types of fusion strategies, which all reach enhanced accuracy\nstill providing real-time response.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 12:33:54 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Ortega", "Juan Diego", ""], ["Kose", "Neslihan", ""], ["Ca\u00f1as", "Paola", ""], ["Chao", "Min-An", ""], ["Unnervik", "Alexander", ""], ["Nieto", "Marcos", ""], ["Otaegui", "Oihana", ""], ["Salgado", "Luis", ""]]}, {"id": "2008.12094", "submitter": "Benlin Liu", "authors": "Benlin Liu, Yongming Rao, Jiwen Lu, Jie Zhou, Cho-jui Hsieh", "title": "MetaDistiller: Network Self-Boosting via Meta-Learned Top-Down\n  Distillation", "comments": "Accepted by ECCV2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Distillation (KD) has been one of the most popu-lar methods to\nlearn a compact model. However, it still suffers from highdemand in time and\ncomputational resources caused by sequential train-ing pipeline. Furthermore,\nthe soft targets from deeper models do notoften serve as good cues for the\nshallower models due to the gap of com-patibility. In this work, we consider\nthese two problems at the same time.Specifically, we propose that better soft\ntargets with higher compatibil-ity can be generated by using a label generator\nto fuse the feature mapsfrom deeper stages in a top-down manner, and we can\nemploy the meta-learning technique to optimize this label generator. Utilizing\nthe softtargets learned from the intermediate feature maps of the model, we\ncanachieve better self-boosting of the network in comparison with the\nstate-of-the-art. The experiments are conducted on two standard\nclassificationbenchmarks, namely CIFAR-100 and ILSVRC2012. We test various\nnet-work architectures to show the generalizability of our MetaDistiller.\nTheexperiments results on two datasets strongly demonstrate the effective-ness\nof our method.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 13:04:27 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Liu", "Benlin", ""], ["Rao", "Yongming", ""], ["Lu", "Jiwen", ""], ["Zhou", "Jie", ""], ["Hsieh", "Cho-jui", ""]]}, {"id": "2008.12095", "submitter": "Katya Kudashkina", "authors": "Katya Kudashkina, Patrick M. Pilarski, Richard S. Sutton", "title": "Document-editing Assistants and Model-based Reinforcement Learning as a\n  Path to Conversational AI", "comments": "Currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent assistants that follow commands or answer simple questions, such\nas Siri and Google search, are among the most economically important\napplications of AI. Future conversational AI assistants promise even greater\ncapabilities and a better user experience through a deeper understanding of the\ndomain, the user, or the user's purposes. But what domain and what methods are\nbest suited to researching and realizing this promise? In this article we argue\nfor the domain of voice document editing and for the methods of model-based\nreinforcement learning. The primary advantages of voice document editing are\nthat the domain is tightly scoped and that it provides something for the\nconversation to be about (the document) that is delimited and fully accessible\nto the intelligent assistant. The advantages of reinforcement learning in\ngeneral are that its methods are designed to learn from interaction without\nexplicit instruction and that it formalizes the purposes of the assistant.\nModel-based reinforcement learning is needed in order to genuinely understand\nthe domain of discourse and thereby work efficiently with the user to achieve\ntheir goals. Together, voice document editing and model-based reinforcement\nlearning comprise a promising research direction for achieving conversational\nAI.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 13:05:51 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Kudashkina", "Katya", ""], ["Pilarski", "Patrick M.", ""], ["Sutton", "Richard S.", ""]]}, {"id": "2008.12103", "submitter": "Syed Ali Hassan", "authors": "Farooque Hassan Kumbhar, Syed Ali Hassan, Soo Young Shin", "title": "New Normal: Cooperative Paradigm for Covid-19 Timely Detection and\n  Containment using Internet of Things and Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spread of the novel coronavirus (COVID-19) has caused trillions of\ndollars in damages to the governments and health authorities by affecting the\nglobal economies. The purpose of this study is to introduce a connected smart\nparadigm that not only detects the possible spread of viruses but also helps to\nrestart businesses/economies, and resume social life. We are proposing a\nconnected Internet of Things ( IoT) based paradigm that makes use of object\ndetection based on convolution neural networks (CNN), smart wearable and\nconnected e-health to avoid current and future outbreaks. First, connected\nsurveillance cameras feed continuous video stream to the server where we detect\nthe inter-object distance to identify any social distancing violations. A\nviolation activates area-based monitoring of active smartphone users and their\ncurrent state of illness. In case a confirmed patient or a person with high\nsymptoms is present, the system tracks exposed and infected people and\nappropriate measures are put into actions. We evaluated the proposed scheme for\nsocial distancing violation detection using YOLO (you only look once) v2 and\nv3, and for infection spread tracing using Python simulation.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 14:33:53 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Kumbhar", "Farooque Hassan", ""], ["Hassan", "Syed Ali", ""], ["Shin", "Soo Young", ""]]}, {"id": "2008.12138", "submitter": "Galit Shmueli", "authors": "Galit Shmueli", "title": "\"Improving\" prediction of human behavior using behavior modification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fields of statistics and machine learning design algorithms, models, and\napproaches to improve prediction. Larger and richer behavioral data increase\npredictive power, as evident from recent advances in behavioral prediction\ntechnology. Large internet platforms that collect behavioral big data predict\nuser behavior for internal purposes and for third parties (advertisers,\ninsurers, security forces, political consulting firms) who utilize the\npredictions for personalization, targeting and other decision-making. While\nstandard data collection and modeling efforts are directed at improving\npredicted values, internet platforms can minimize prediction error by \"pushing\"\nusers' actions towards their predicted values using behavior modification\ntechniques. The better the platform can make users conform to their predicted\noutcomes, the more it can boast its predictive accuracy and ability to induce\nbehavior change. Hence, platforms are strongly incentivized to \"make\npredictions true\". This strategy is absent from the ML and statistics\nliterature. Investigating its properties requires incorporating causal notation\ninto the correlation-based predictive environment---an integration currently\nmissing. To tackle this void, we integrate Pearl's causal do(.) operator into\nthe predictive framework. We then decompose the expected prediction error given\nbehavior modification, and identify the components impacting predictive power.\nOur derivation elucidates the implications of such behavior modification to\ndata scientists, platforms, their clients, and the humans whose behavior is\nmanipulated. Behavior modification can make users' behavior more predictable\nand even more homogeneous; yet this apparent predictability might not\ngeneralize when clients use predictions in practice. Outcomes pushed towards\ntheir predictions can be at odds with clients' intentions, and harmful to\nmanipulated users.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 12:39:35 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Shmueli", "Galit", ""]]}, {"id": "2008.12141", "submitter": "Sherin Muckatira", "authors": "Sherin Muckatira", "title": "Properties Of Winning Tickets On Skin Lesion Classification", "comments": "11 pages, 11 figures, presented at WiCV workshop at ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skin cancer affects a large population every year -- automated skin cancer\ndetection algorithms can thus greatly help clinicians. Prior efforts involving\ndeep learning models have high detection accuracy. However, most of the models\nhave a large number of parameters, with some works even using an ensemble of\nmodels to achieve good accuracy. In this paper, we investigate a recently\nproposed pruning technique called Lottery Ticket Hypothesis. We find that\niterative pruning of the network resulted in improved accuracy, compared to\nthat of the unpruned network, implying that -- the lottery ticket hypothesis\ncan be applied to the problem of skin cancer detection and this hypothesis can\nresult in a smaller network for inference. We also examine the accuracy across\nsub-groups -- created by gender and age -- and it was found that some\nsub-groups show a larger increase in accuracy than others.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 21:36:56 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Muckatira", "Sherin", ""]]}, {"id": "2008.12145", "submitter": "William Cheung", "authors": "William Cheung and Sudip Vhaduri", "title": "Context-Dependent Implicit Authentication for Wearable Device User", "comments": "7 pages, 5 figures, accepted at IEEE International Symposium on\n  Personal, Indoor and Mobile Radio Communications (PIMRC). arXiv admin note:\n  substantial text overlap with arXiv:2008.10779", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As market wearables are becoming popular with a range of services, including\nmaking financial transactions, accessing cars, etc. that they provide based on\nvarious private information of a user, security of this information is becoming\nvery important. However, users are often flooded with PINs and passwords in\nthis internet of things (IoT) world. Additionally, hard-biometric, such as\nfacial or finger recognition, based authentications are not adaptable for\nmarket wearables due to their limited sensing and computation capabilities.\nTherefore, it is a time demand to develop a burden-free implicit authentication\nmechanism for wearables using the less-informative soft-biometric data that are\neasily obtainable from the market wearables. In this work, we present a\ncontext-dependent soft-biometric-based wearable authentication system utilizing\nthe heart rate, gait, and breathing audio signals. From our detailed analysis,\nwe find that a binary support vector machine (SVM) with radial basis function\n(RBF) kernel can achieve an average accuracy of $0.94 \\pm 0.07$, $F_1$ score of\n$0.93 \\pm 0.08$, an equal error rate (EER) of about $0.06$ at a lower\nconfidence threshold of 0.52, which shows the promise of this work.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 04:34:19 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Cheung", "William", ""], ["Vhaduri", "Sudip", ""]]}, {"id": "2008.12152", "submitter": "Rodrigo Rivera-Castro", "authors": "Aiusha Sangadiev, Rodrigo Rivera-Castro, Kirill Stepanov, Andrey\n  Poddubny, Kirill Bubenchikov, Nikita Bekezin, Polina Pilyugina and Evgeny\n  Burnaev", "title": "DeepFolio: Convolutional Neural Networks for Portfolios with Limit Order\n  Book Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.TR stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes DeepFolio, a new model for deep portfolio management based\non data from limit order books (LOB). DeepFolio solves problems found in the\nstate-of-the-art for LOB data to predict price movements. Our evaluation\nconsists of two scenarios using a large dataset of millions of time series. The\nimprovements deliver superior results both in cases of abundant as well as\nscarce data. The experiments show that DeepFolio outperforms the\nstate-of-the-art on the benchmark FI-2010 LOB. Further, we use DeepFolio for\noptimal portfolio allocation of crypto-assets with rebalancing. For this\npurpose, we use two loss-functions - Sharpe ratio loss and minimum volatility\nrisk. We show that DeepFolio outperforms widely used portfolio allocation\ntechniques in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 14:28:18 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Sangadiev", "Aiusha", ""], ["Rivera-Castro", "Rodrigo", ""], ["Stepanov", "Kirill", ""], ["Poddubny", "Andrey", ""], ["Bubenchikov", "Kirill", ""], ["Bekezin", "Nikita", ""], ["Pilyugina", "Polina", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "2008.12161", "submitter": "Xinyi Xu Mr", "authors": "Lingjuan Lyu, Xinyi Xu, and Qian Wang", "title": "Collaborative Fairness in Federated Learning", "comments": "accepted to FL-IJCAI'20 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In current deep learning paradigms, local training or the Standalone\nframework tends to result in overfitting and thus poor generalizability. This\nproblem can be addressed by Distributed or Federated Learning (FL) that\nleverages a parameter server to aggregate model updates from individual\nparticipants. However, most existing Distributed or FL frameworks have\noverlooked an important aspect of participation: collaborative fairness. In\nparticular, all participants can receive the same or similar models, regardless\nof their contributions. To address this issue, we investigate the collaborative\nfairness in FL, and propose a novel Collaborative Fair Federated Learning\n(CFFL) framework which utilizes reputation to enforce participants to converge\nto different models, thus achieving fairness without compromising the\npredictive performance. Extensive experiments on benchmark datasets demonstrate\nthat CFFL achieves high fairness, delivers comparable accuracy to the\nDistributed framework, and outperforms the Standalone framework.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 14:39:09 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 01:06:55 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Lyu", "Lingjuan", ""], ["Xu", "Xinyi", ""], ["Wang", "Qian", ""]]}, {"id": "2008.12170", "submitter": "Jeffrey Zhang", "authors": "Jeffrey Zhang", "title": "Complexity Aspects of Fundamental Questions in Polynomial Optimization", "comments": "196 pages, 11 figures, PhD Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, we settle the computational complexity of some fundamental\nquestions in polynomial optimization. These include the questions of (i)\nfinding a local minimum, (ii) testing local minimality of a point, and (iii)\ndeciding attainment of the optimal value. Our results characterize the\ncomplexity of these three questions for all degrees of the defining polynomials\nleft open by prior literature.\n  Regarding (i) and (ii), we show that unless P=NP, there cannot be a\npolynomial-time algorithm that finds a point within Euclidean distance $c^n$\n(for any constant $c$) of a local minimum of an $n$-variate quadratic program.\nBy contrast, we show that a local minimum of a cubic polynomial can be found\nefficiently by semidefinite programming (SDP). We prove that second-order\npoints of cubic polynomials admit an efficient semidefinite representation,\neven though their critical points are NP-hard to find. We also give an\nefficiently-checkable necessary and sufficient condition for local minimality\nof a point for a cubic polynomial.\n  Regarding (iii), we prove that testing whether a quadratically constrained\nquadratic program with a finite optimal value has an optimal solution is\nNP-hard. We also show that testing coercivity of the objective function,\ncompactness of the feasible set, and the Archimedean property associated with\nthe description of the feasible set are all NP-hard. We also give a new\ncharacterization of coercive polynomials that lends itself to a hierarchy of\nSDPs.\n  In our final chapter, we present an SDP relaxation for finding approximate\nNash equilibria in bimatrix games. We show that for a symmetric game, a\n$1/3$-Nash equilibrium can be efficiently recovered from any rank-2 solution to\nthis relaxation. We also propose SDP relaxations for NP-hard problems related\nto Nash equilibria, such as that of finding the highest achievable welfare\nunder any Nash equilibrium.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 14:58:02 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Zhang", "Jeffrey", ""]]}, {"id": "2008.12187", "submitter": "Shengli Jiang", "authors": "Shengli Jiang, Prasanna Balaprakash", "title": "Graph Neural Network Architecture Search for Molecular Property\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the properties of a molecule from its structure is a challenging\ntask. Recently, deep learning methods have improved the state of the art for\nthis task because of their ability to learn useful features from the given\ndata. By treating molecule structure as graphs, where atoms and bonds are\nmodeled as nodes and edges, graph neural networks (GNNs) have been widely used\nto predict molecular properties. However, the design and development of GNNs\nfor a given data set rely on labor-intensive design and tuning of the network\narchitectures. Neural architecture search (NAS) is a promising approach to\ndiscover high-performing neural network architectures automatically. To that\nend, we develop an NAS approach to automate the design and development of GNNs\nfor molecular property prediction. Specifically, we focus on automated\ndevelopment of message-passing neural networks (MPNNs) to predict the molecular\nproperties of small molecules in quantum mechanics and physical chemistry data\nsets from the MoleculeNet benchmark. We demonstrate the superiority of the\nautomatically discovered MPNNs by comparing them with manually designed GNNs\nfrom the MoleculeNet benchmark. We study the relative importance of the choices\nin the MPNN search space, demonstrating that customizing the architecture is\ncritical to enhancing performance in molecular property prediction and that the\nproposed approach can perform customization automatically with minimal manual\neffort.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 15:30:57 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Jiang", "Shengli", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "2008.12190", "submitter": "Akshunna S. Dogra", "authors": "Akshunna S. Dogra, William T Redman", "title": "Local error quantification for Neural Network Differential Equation\n  solvers", "comments": "6 pages, 3 figures, 2 Tables, 1 appendix with a new proposed\n  algorithm. Modifications in the statement and proof of Equation 7 compared to\n  the previous version. Text overlap with arXiv:2004.11826", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been identified as powerful tools for the study of\ncomplex systems. A noteworthy example is the neural network differential\nequation (NN DE) solver, which can provide functional approximations to the\nsolutions of a wide variety of differential equations. Such solvers produce\nrobust functional expressions, are well suited for further manipulations on the\nquantities of interest (for example, taking derivatives), and capable of\nleveraging the modern advances in parallelization and computing power. However,\nthere is a lack of work on the role precise error quantification can play in\ntheir predictions: usually, the focus is on ambiguous and/or global measures of\nperformance like the loss function and/or obtaining global bounds on the errors\nassociated with the predictions. Precise, local error quantification is seldom\npossible without external means or outright knowledge of the true solution. We\naddress these concerns in the context of dynamical system NN DE solvers,\nleveraging learnt information within the NN DE solvers to develop methods that\nallow them to be more accurate and efficient, while still pursuing an\nunsupervised approach that does not rely on external tools or data. We achieve\nthis via methods that can precisely estimate NN DE solver prediction errors\npoint-wise, thus allowing the user the capacity for efficient and targeted\nerror correction. We exemplify the utility of our methods by testing them on a\nnonlinear and a chaotic system each.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 08:22:58 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 16:24:05 GMT"}, {"version": "v3", "created": "Thu, 28 Jan 2021 09:44:13 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Dogra", "Akshunna S.", ""], ["Redman", "William T", ""]]}, {"id": "2008.12193", "submitter": "Geert Heyman", "authors": "Geert Heyman and Tom Van Cutsem", "title": "Neural Code Search Revisited: Enhancing Code Snippet Retrieval through\n  Natural Language Intent", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose and study annotated code search: the retrieval of\ncode snippets paired with brief descriptions of their intent using natural\nlanguage queries. On three benchmark datasets, we investigate how code\nretrieval systems can be improved by leveraging descriptions to better capture\nthe intents of code snippets. Building on recent progress in transfer learning\nand natural language processing, we create a domain-specific retrieval model\nfor code annotated with a natural language description. We find that our model\nyields significantly more relevant search results (with absolute gains up to\n20.6% in mean reciprocal rank) compared to state-of-the-art code retrieval\nmethods that do not use descriptions but attempt to compute the intent of\nsnippets solely from unannotated code.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 15:39:09 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Heyman", "Geert", ""], ["Van Cutsem", "Tom", ""]]}, {"id": "2008.12224", "submitter": "Ping Li", "authors": "Jerry Chee and Ping Li", "title": "Understanding and Detecting Convergence for Stochastic Gradient Descent\n  with Momentum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convergence detection of iterative stochastic optimization methods is of\ngreat practical interest. This paper considers stochastic gradient descent\n(SGD) with a constant learning rate and momentum. We show that there exists a\ntransient phase in which iterates move towards a region of interest, and a\nstationary phase in which iterates remain bounded in that region around a\nminimum point. We construct a statistical diagnostic test for convergence to\nthe stationary phase using the inner product between successive gradients and\ndemonstrate that the proposed diagnostic works well. We theoretically and\nempirically characterize how momentum can affect the test statistic of the\ndiagnostic, and how the test statistic captures a relatively sparse signal\nwithin the gradients in convergence. Finally, we demonstrate an application to\nautomatically tune the learning rate by reducing it each time stationarity is\ndetected, and show the procedure is robust to mis-specified initial rates.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 16:24:18 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Chee", "Jerry", ""], ["Li", "Ping", ""]]}, {"id": "2008.12228", "submitter": "Tim Hertweck", "authors": "Roland Hafner, Tim Hertweck, Philipp Kl\\\"oppner, Michael Bloesch,\n  Michael Neunert, Markus Wulfmeier, Saran Tunyasuvunakool, Nicolas Heess,\n  Martin Riedmiller", "title": "Towards General and Autonomous Learning of Core Skills: A Case Study in\n  Locomotion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern Reinforcement Learning (RL) algorithms promise to solve difficult\nmotor control problems directly from raw sensory inputs. Their attraction is\ndue in part to the fact that they can represent a general class of methods that\nallow to learn a solution with a reasonably set reward and minimal prior\nknowledge, even in situations where it is difficult or expensive for a human\nexpert. For RL to truly make good on this promise, however, we need algorithms\nand learning setups that can work across a broad range of problems with minimal\nproblem specific adjustments or engineering. In this paper, we study this idea\nof generality in the locomotion domain. We develop a learning framework that\ncan learn sophisticated locomotion behavior for a wide spectrum of legged\nrobots, such as bipeds, tripeds, quadrupeds and hexapods, including wheeled\nvariants. Our learning framework relies on a data-efficient, off-policy\nmulti-task RL algorithm and a small set of reward functions that are\nsemantically identical across robots. To underline the general applicability of\nthe method, we keep the hyper-parameter settings and reward definitions\nconstant across experiments and rely exclusively on on-board sensing. For nine\ndifferent types of robots, including a real-world quadruped robot, we\ndemonstrate that the same algorithm can rapidly learn diverse and reusable\nlocomotion skills without any platform specific adjustments or additional\ninstrumentation of the learning setup.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 08:23:55 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Hafner", "Roland", ""], ["Hertweck", "Tim", ""], ["Kl\u00f6ppner", "Philipp", ""], ["Bloesch", "Michael", ""], ["Neunert", "Michael", ""], ["Wulfmeier", "Markus", ""], ["Tunyasuvunakool", "Saran", ""], ["Heess", "Nicolas", ""], ["Riedmiller", "Martin", ""]]}, {"id": "2008.12234", "submitter": "Audrunas Gruslys", "authors": "Audr\\=unas Gruslys, Marc Lanctot, R\\'emi Munos, Finbarr Timbers,\n  Martin Schmid, Julien Perolat, Dustin Morrill, Vinicius Zambaldi,\n  Jean-Baptiste Lespiau, John Schultz, Mohammad Gheshlaghi Azar, Michael\n  Bowling, and Karl Tuyls", "title": "The Advantage Regret-Matching Actor-Critic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regret minimization has played a key role in online learning, equilibrium\ncomputation in games, and reinforcement learning (RL). In this paper, we\ndescribe a general model-free RL method for no-regret learning based on\nrepeated reconsideration of past behavior. We propose a model-free RL\nalgorithm, the AdvantageRegret-Matching Actor-Critic (ARMAC): rather than\nsaving past state-action data, ARMAC saves a buffer of past policies, replaying\nthrough them to reconstruct hindsight assessments of past behavior. These\nretrospective value estimates are used to predict conditional advantages which,\ncombined with regret matching, produces a new policy. In particular, ARMAC\nlearns from sampled trajectories in a centralized training setting, without\nrequiring the application of importance sampling commonly used in Monte Carlo\ncounterfactual regret (CFR) minimization; hence, it does not suffer from\nexcessive variance in large environments. In the single-agent setting, ARMAC\nshows an interesting form of exploration by keeping past policies intact. In\nthe multiagent setting, ARMAC in self-play approaches Nash equilibria on some\npartially-observable zero-sum benchmarks. We provide exploitability estimates\nin the significantly larger game of betting-abstracted no-limit Texas Hold'em.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 16:30:17 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Gruslys", "Audr\u016bnas", ""], ["Lanctot", "Marc", ""], ["Munos", "R\u00e9mi", ""], ["Timbers", "Finbarr", ""], ["Schmid", "Martin", ""], ["Perolat", "Julien", ""], ["Morrill", "Dustin", ""], ["Zambaldi", "Vinicius", ""], ["Lespiau", "Jean-Baptiste", ""], ["Schultz", "John", ""], ["Azar", "Mohammad Gheshlaghi", ""], ["Bowling", "Michael", ""], ["Tuyls", "Karl", ""]]}, {"id": "2008.12247", "submitter": "Emily Clark", "authors": "Emily Clark, Angelie Vincent, J. Nathan Kutz, and Steven L. Brunton", "title": "Bracketing brackets with bras and kets", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brackets are an essential component in aircraft manufacture and design,\njoining parts together, supporting weight, holding wires, and strengthening\njoints. Hundreds or thousands of unique brackets are used in every aircraft,\nbut manufacturing a large number of distinct brackets is inefficient and\nexpensive. Fortunately, many so-called \"different\" brackets are in fact very\nsimilar or even identical to each other. In this manuscript, we present a\ndata-driven framework for constructing a comparatively small group of\nrepresentative brackets from a large catalog of current brackets, based on\nhierarchical clustering of bracket data. We find that for a modern commercial\naircraft, the full set of brackets can be reduced by 30\\% while still\ndescribing half of the test set sufficiently accurately. This approach is based\non designing an inner product that quantifies a multi-objective similarity\nbetween two brackets, which are the \"bra\" and the \"ket\" of the inner product.\nAlthough we demonstrate this algorithm to reduce the number of brackets in\naerospace manufacturing, it may be generally applied to any large-scale\ncomponent standardization effort.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 22:19:00 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Clark", "Emily", ""], ["Vincent", "Angelie", ""], ["Kutz", "J. Nathan", ""], ["Brunton", "Steven L.", ""]]}, {"id": "2008.12248", "submitter": "Yunhao Yang", "authors": "Yunhao Yang, Andrew Whinston", "title": "A Survey on Reinforcement Learning for Combinatorial Optimization", "comments": "manuscript submitted to Management Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives a detailed review of reinforcement learning in combinatorial\noptimization, introduces the history of combinatorial optimization starting in\nthe 1960s, and compares it with the reinforcement learning algorithms in recent\nyears. We explicitly look at a famous combinatorial problem known as the\nTraveling Salesperson Problem (TSP). We compare the approach of the modern\nreinforcement learning algorithms on TSP with an approach published in 1970.\nThen, we discuss the similarities between these algorithms and how the approach\nof reinforcement learning changes due to the evolution of machine learning\ntechniques and computing power. We also mention the deep learning approach on\nthe TSP, which is named Deep Reinforcement Learning. We argue that deep\nlearning is a generic approach that can be integrated with traditional\nreinforcement learning algorithms and optimize the outcomes of the TSP.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 16:08:55 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 18:52:22 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Yang", "Yunhao", ""], ["Whinston", "Andrew", ""]]}, {"id": "2008.12249", "submitter": "Soojung Yang", "authors": "Seokhyun Moon, Wonho Zhung, Soojung Yang, Jaechang Lim and Woo Youn\n  Kim", "title": "PIGNet: A physics-informed deep learning model toward generalized\n  drug-target interaction predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep neural network (DNN)-based drug-target interaction (DTI)\nmodels are highlighted for their high accuracy with affordable computational\ncosts. Yet, the models' insufficient generalization remains a challenging\nproblem in the practice of in-silico drug discovery. We propose two key\nstrategies to enhance generalization in the DTI model. The first one is to\nintegrate physical models into DNN models. Our model, PIGNet, predicts the\natom-atom pairwise interactions via physics-informed equations parameterized\nwith neural networks and provides the total binding affinity of a\nprotein-ligand complex as their sum. We further improved the model\ngeneralization by augmenting a wider range of binding poses and ligands to\ntraining data. PIGNet achieved a significant improvement in docking success\nrate, screening enhancement factor, and screening success rate by up to 2.01,\n10.78, 14.0 times, respectively, compared to the previous DNN models. The\nphysics-informed model also enables the interpretation of predicted binding\naffinities by visualizing the energy contribution of ligand substructures,\nproviding insights for ligand optimization. Finally, we devised the uncertainty\nestimator of our model's prediction to qualify the outcomes and reduce the\nfalse positive rates.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 14:29:58 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Moon", "Seokhyun", ""], ["Zhung", "Wonho", ""], ["Yang", "Soojung", ""], ["Lim", "Jaechang", ""], ["Kim", "Woo Youn", ""]]}, {"id": "2008.12258", "submitter": "Tianyu Li", "authors": "Hao Gong and Qifang Zhao and Tianyu Li and Derek Cho and DuyKhuong\n  Nguyen", "title": "Learning to Profile: User Meta-Profile Network for Few-Shot Learning", "comments": "8-page Applied Research Paper accepted by CIKM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Meta-learning approaches have shown great success in vision and language\ndomains. However, few studies discuss the practice of meta-learning for\nlarge-scale industrial applications. Although e-commerce companies have spent\nmany efforts on learning representations to provide a better user experience,\nwe argue that such efforts cannot be stopped at this step. In addition to\nlearning a strong profile, the challenging question about how to effectively\ntransfer the learned representation is raised simultaneously. This paper\nintroduces the contributions that we made to address these challenges from\nthree aspects. 1) Meta-learning model: In the context of representation\nlearning with e-commerce user behavior data, we propose a meta-learning\nframework called the Meta-Profile Network, which extends the ideas of matching\nnetwork and relation network for knowledge transfer and fast adaptation; 2)\nEncoding strategy: To keep high fidelity of large-scale long-term sequential\nbehavior data, we propose a time-heatmap encoding strategy that allows the\nmodel to encode data effectively; 3) Deep network architecture: A multi-modal\nmodel combined with multi-task learning architecture is utilized to address the\ncross-domain knowledge learning and insufficient label problems. Moreover, we\nargue that an industrial model should not only have good performance in terms\nof accuracy, but also have better robustness and uncertainty performance under\nextreme conditions. We evaluate the performance of our model with extensive\ncontrol experiments in various extreme scenarios, i.e. out-of-distribution\ndetection, data insufficiency and class imbalance scenarios. The Meta-Profile\nNetwork shows significant improvement in the model performance when compared to\nbaseline models.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 03:01:16 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 08:06:26 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Gong", "Hao", ""], ["Zhao", "Qifang", ""], ["Li", "Tianyu", ""], ["Cho", "Derek", ""], ["Nguyen", "DuyKhuong", ""]]}, {"id": "2008.12260", "submitter": "Aurick Qiao", "authors": "Aurick Qiao, Sang Keun Choe, Suhas Jayaram Subramanya, Willie\n  Neiswanger, Qirong Ho, Hao Zhang, Gregory R. Ganger, Eric P. Xing", "title": "Pollux: Co-adaptive Cluster Scheduling for Goodput-Optimized Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pollux improves scheduling performance in deep learning (DL) clusters by\nadaptively co-optimizing inter-dependent factors both at the per-job level and\nat the cluster-wide level. Most existing schedulers expect users to specify the\nnumber of resources for each job, often leading to inefficient resource use.\nSome recent schedulers choose job resources for users, but do so without\nawareness of how DL training can be re-optimized to better utilize the provided\nresources.\n  Pollux simultaneously considers both aspects. By monitoring the status of\neach job during training, Pollux models how their goodput (a novel metric we\nintroduce that combines system throughput with statistical efficiency) would\nchange by adding or removing resources. Leveraging these information, Pollux\ndynamically (re-)assigns resources to improve cluster-wide goodput, while\nrespecting fairness and continually optimizing each DL job to better utilize\nthose resources.\n  In experiments with real DL jobs and with trace-driven simulations, Pollux\nreduces average job completion times by 37-50% relative to state-of-the-art DL\nschedulers, even when they are provided with ideal resource and training\nconfigurations for every job. Pollux promotes fairness among DL jobs competing\nfor resources based on a more meaningful measure of useful job progress, and\nreveals a new opportunity for reducing DL cost in cloud environments. Pollux is\nimplemented and publicly available as part of an open-source project at\nhttps://github.com/petuum/adaptdl.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 16:56:48 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 06:08:21 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Qiao", "Aurick", ""], ["Choe", "Sang Keun", ""], ["Subramanya", "Suhas Jayaram", ""], ["Neiswanger", "Willie", ""], ["Ho", "Qirong", ""], ["Zhang", "Hao", ""], ["Ganger", "Gregory R.", ""], ["Xing", "Eric P.", ""]]}, {"id": "2008.12262", "submitter": "Yuval Nirkin", "authors": "Yuval Nirkin, Lior Wolf, Yosi Keller and Tal Hassner", "title": "DeepFake Detection Based on the Discrepancy Between the Face and its\n  Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for detecting face swapping and other identity\nmanipulations in single images. Face swapping methods, such as DeepFake,\nmanipulate the face region, aiming to adjust the face to the appearance of its\ncontext, while leaving the context unchanged. We show that this modus operandi\nproduces discrepancies between the two regions. These discrepancies offer\nexploitable telltale signs of manipulation. Our approach involves two networks:\n(i) a face identification network that considers the face region bounded by a\ntight semantic segmentation, and (ii) a context recognition network that\nconsiders the face context (e.g., hair, ears, neck). We describe a method which\nuses the recognition signals from our two networks to detect such\ndiscrepancies, providing a complementary detection signal that improves\nconventional real vs. fake classifiers commonly used for detecting fake images.\nOur method achieves state of the art results on the FaceForensics++,\nCeleb-DF-v2, and DFDC benchmarks for face manipulation detection, and even\ngeneralizes to detect fakes produced by unseen methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 17:04:46 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Nirkin", "Yuval", ""], ["Wolf", "Lior", ""], ["Keller", "Yosi", ""], ["Hassner", "Tal", ""]]}, {"id": "2008.12282", "submitter": "Saskia Nu\\~nez von Voigt", "authors": "Saskia Nu\\~nez von Voigt, Mira Pauli, Johanna Reichert, Florian\n  Tschorsch", "title": "Every Query Counts: Analyzing the Privacy Loss of Exploratory Data\n  Analyses", "comments": "Accepted Paper for DPM 2020 co-located ESORICS 2020", "journal-ref": null, "doi": "10.1007/978-3-030-66172-4_17", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An exploratory data analysis is an essential step for every data analyst to\ngain insights, evaluate data quality and (if required) select a machine\nlearning model for further processing. While privacy-preserving machine\nlearning is on the rise, more often than not this initial analysis is not\ncounted towards the privacy budget. In this paper, we quantify the privacy loss\nfor basic statistical functions and highlight the importance of taking it into\naccount when calculating the privacy-loss budget of a machine learning\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 17:40:29 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["von Voigt", "Saskia Nu\u00f1ez", ""], ["Pauli", "Mira", ""], ["Reichert", "Johanna", ""], ["Tschorsch", "Florian", ""]]}, {"id": "2008.12284", "submitter": "S\\'ebastien Arnold", "authors": "S\\'ebastien M. R. Arnold, Praateek Mahajan, Debajyoti Datta, Ian\n  Bunner, Konstantinos Saitas Zarkias", "title": "learn2learn: A Library for Meta-Learning Research", "comments": "Software available at: https://github.com/learnables/learn2learn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Meta-learning researchers face two fundamental issues in their empirical\nwork: prototyping and reproducibility. Researchers are prone to make mistakes\nwhen prototyping new algorithms and tasks because modern meta-learning methods\nrely on unconventional functionalities of machine learning frameworks. In turn,\nreproducing existing results becomes a tedious endeavour -- a situation\nexacerbated by the lack of standardized implementations and benchmarks. As a\nresult, researchers spend inordinate amounts of time on implementing software\nrather than understanding and developing new ideas.\n  This manuscript introduces learn2learn, a library for meta-learning research\nfocused on solving those prototyping and reproducibility issues. learn2learn\nprovides low-level routines common across a wide-range of meta-learning\ntechniques (e.g. meta-descent, meta-reinforcement learning, few-shot learning),\nand builds standardized interfaces to algorithms and benchmarks on top of them.\nIn releasing learn2learn under a free and open source license, we hope to\nfoster a community around standardized software for meta-learning research.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 17:41:34 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 03:48:50 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Arnold", "S\u00e9bastien M. R.", ""], ["Mahajan", "Praateek", ""], ["Datta", "Debajyoti", ""], ["Bunner", "Ian", ""], ["Zarkias", "Konstantinos Saitas", ""]]}, {"id": "2008.12315", "submitter": "Magda Amiridi", "authors": "Magda Amiridi, Nikos Kargas, Nicholas D. Sidiropoulos", "title": "Low-rank Characteristic Tensor Density Estimation Part I: Foundations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective non-parametric density estimation is a key challenge in\nhigh-dimensional multivariate data analysis. In this paper,we propose a novel\napproach that builds upon tensor factorization tools. Any multivariate density\ncan be represented by its characteristic function, via the Fourier transform.\nIf the sought density is compactly supported, then its characteristic function\ncan be approximated, within controllable error, by a finite tensor of leading\nFourier coefficients, whose size de-pends on the smoothness of the underlying\ndensity. This tensor can be naturally estimated from observed realizations of\nthe random vector of interest, via sample averaging. In order to circumvent the\ncurse of dimensionality, we introduce a low-rank model of this characteristic\ntensor, which significantly improves the density estimate especially for\nhigh-dimensional data and/or in the sample-starved regime. By virtue of\nuniqueness of low-rank tensor decomposition, under certain conditions, our\nmethod enables learning the true data-generating distribution. We demonstrate\nthe very promising performance of the proposed method using several measured\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 18:06:19 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 03:06:33 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Amiridi", "Magda", ""], ["Kargas", "Nikos", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "2008.12330", "submitter": "Ralph Foorthuis", "authors": "Ralph Foorthuis", "title": "The Impact of Discretization Method on the Detection of Six Types of\n  Anomalies in Datasets", "comments": "16 pages, 5 figures, 2 tables. Presented at the 30th Benelux\n  Conference on Artificial Intelligence (BNAIC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is the process of identifying cases, or groups of cases,\nthat are in some way unusual and do not fit the general patterns present in the\ndataset. Numerous algorithms use discretization of numerical data in their\ndetection processes. This study investigates the effect of the discretization\nmethod on the unsupervised detection of each of the six anomaly types\nacknowledged in a recent typology of data anomalies. To this end, experiments\nare conducted with various datasets and SECODA, a general-purpose algorithm for\nunsupervised non-parametric anomaly detection in datasets with numerical and\ncategorical attributes. This algorithm employs discretization of continuous\nattributes, exponentially increasing weights and discretization cut points, and\na pruning heuristic to detect anomalies with an optimal number of iterations.\nThe results demonstrate that standard SECODA can detect all six types, but that\ndifferent discretization methods favor the discovery of certain anomaly types.\nThe main findings also hold for other detection techniques using\ndiscretization.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 18:43:55 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Foorthuis", "Ralph", ""]]}, {"id": "2008.12332", "submitter": "Sarah Dean", "authors": "Sarah Dean and Benjamin Recht", "title": "Certainty Equivalent Perception-Based Control", "comments": "to appear at L4DC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to certify performance and safety, feedback control requires precise\ncharacterization of sensor errors. In this paper, we provide guarantees on such\nfeedback systems when sensors are characterized by solving a supervised\nlearning problem. We show a uniform error bound on nonparametric kernel\nregression under a dynamically-achievable dense sampling scheme. This allows\nfor a finite-time convergence rate on the sub-optimality of using the regressor\nin closed-loop for waypoint tracking. We demonstrate our results in simulation\nwith simplified unmanned aerial vehicle and autonomous driving examples.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 18:45:40 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 19:45:35 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Dean", "Sarah", ""], ["Recht", "Benjamin", ""]]}, {"id": "2008.12333", "submitter": "Marcus Badgeley", "authors": "Gabe Schamberg, Marcus Badgeley, and Emery N. Brown", "title": "Controlling Level of Unconsciousness by Titrating Propofol with Deep\n  Reinforcement Learning", "comments": "International Conference on Artificial Intelligence in Medicine 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) can be used to fit a mapping from patient state\nto a medication regimen. Prior studies have used deterministic and value-based\ntabular learning to learn a propofol dose from an observed anesthetic state.\nDeep RL replaces the table with a deep neural network and has been used to\nlearn medication regimens from registry databases. Here we perform the first\napplication of deep RL to closed-loop control of anesthetic dosing in a\nsimulated environment. We use the cross-entropy method to train a deep neural\nnetwork to map an observed anesthetic state to a probability of infusing a\nfixed propofol dosage. During testing, we implement a deterministic policy that\ntransforms the probability of infusion to a continuous infusion rate. The model\nis trained and tested on simulated pharmacokinetic/pharmacodynamic models with\nrandomized parameters to ensure robustness to patient variability. The deep RL\nagent significantly outperformed a proportional-integral-derivative controller\n(median absolute performance error 1.7% +/- 0.6 and 3.4% +/- 1.2). Modeling\ncontinuous input variables instead of a table affords more robust pattern\nrecognition and utilizes our prior domain knowledge. Deep RL learned a smooth\npolicy with a natural interpretation to data scientists and anesthesia care\nproviders alike.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 18:47:08 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 14:24:47 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Schamberg", "Gabe", ""], ["Badgeley", "Marcus", ""], ["Brown", "Emery N.", ""]]}, {"id": "2008.12335", "submitter": "Vahid Noroozi", "authors": "Vahid Noroozi, Yang Zhang, Evelina Bakhturina, Tomasz Kornuta", "title": "A Fast and Robust BERT-based Dialogue State Tracker for Schema-Guided\n  Dialogue Dataset", "comments": "Accepted to the Workshop on Conversational Systems Towards Mainstream\n  Adoption at KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog State Tracking (DST) is one of the most crucial modules for\ngoal-oriented dialogue systems. In this paper, we introduce FastSGT (Fast\nSchema Guided Tracker), a fast and robust BERT-based model for state tracking\nin goal-oriented dialogue systems. The proposed model is designed for the\nSchema-Guided Dialogue (SGD) dataset which contains natural language\ndescriptions for all the entities including user intents, services, and slots.\nThe model incorporates two carry-over procedures for handling the extraction of\nthe values not explicitly mentioned in the current user utterance. It also uses\nmulti-head attention projections in some of the decoders to have a better\nmodelling of the encoder outputs. In the conducted experiments we compared\nFastSGT to the baseline model for the SGD dataset. Our model keeps the\nefficiency in terms of computational and memory consumption while improving the\naccuracy significantly. Additionally, we present ablation studies measuring the\nimpact of different parts of the model on its performance. We also show the\neffectiveness of data augmentation for improving the accuracy without\nincreasing the amount of computational resources.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 18:51:18 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Noroozi", "Vahid", ""], ["Zhang", "Yang", ""], ["Bakhturina", "Evelina", ""], ["Kornuta", "Tomasz", ""]]}, {"id": "2008.12338", "submitter": "Gauri Jagatap", "authors": "Gauri Jagatap, Ameya Joshi, Animesh Basak Chowdhury, Siddharth Garg,\n  Chinmay Hegde", "title": "Adversarially Robust Learning via Entropic Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new family of algorithms, ATENT, for training\nadversarially robust deep neural networks. We formulate a new loss function\nthat is equipped with an additional entropic regularization. Our loss function\nconsiders the contribution of adversarial samples that are drawn from a\nspecially designed distribution in the data space that assigns high probability\nto points with high loss and in the immediate neighborhood of training samples.\nOur proposed algorithms optimize this loss to seek adversarially robust valleys\nof the loss landscape. Our approach achieves competitive (or better)\nperformance in terms of robust classification accuracy as compared to several\nstate-of-the-art robust learning approaches on benchmark datasets such as MNIST\nand CIFAR-10.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 18:54:43 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 15:39:02 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Jagatap", "Gauri", ""], ["Joshi", "Ameya", ""], ["Chowdhury", "Animesh Basak", ""], ["Garg", "Siddharth", ""], ["Hegde", "Chinmay", ""]]}, {"id": "2008.12340", "submitter": "Tianyang Xie", "authors": "Tianyang Xie, Jie Ding", "title": "Forecasting with Multiple Seasonality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An emerging number of modern applications involve forecasting time series\ndata that exhibit both short-time dynamics and long-time seasonality.\nSpecifically, time series with multiple seasonality is a difficult task with\ncomparatively fewer discussions. In this paper, we propose a two-stage method\nfor time series with multiple seasonality, which does not require\npre-determined seasonality periods. In the first stage, we generalize the\nclassical seasonal autoregressive moving average (ARMA) model in multiple\nseasonality regime. In the second stage, we utilize an appropriate criterion\nfor lag order selection. Simulation and empirical studies show the excellent\npredictive performance of our method, especially compared to a recently popular\n`Facebook Prophet' model for time series.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 19:08:30 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Xie", "Tianyang", ""], ["Ding", "Jie", ""]]}, {"id": "2008.12350", "submitter": "Junggab Son", "authors": "Tejaswini Mallavarapu, Luke Cranfill, Junggab Son, Eun Hye Kim, Reza\n  M. Parizi, and John Morris", "title": "A Federated Approach for Fine-Grained Classification of Fashion Apparel", "comments": "11 pages, 4 figures, 5 tables, submitted to IEEE ACCESS (under\n  review)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As online retail services proliferate and are pervasive in modern lives,\napplications for classifying fashion apparel features from image data are\nbecoming more indispensable. Online retailers, from leading companies to\nstart-ups, can leverage such applications in order to increase profit margin\nand enhance the consumer experience. Many notable schemes have been proposed to\nclassify fashion items, however, the majority of which focused upon classifying\nbasic-level categories, such as T-shirts, pants, skirts, shoes, bags, and so\nforth. In contrast to most prior efforts, this paper aims to enable an in-depth\nclassification of fashion item attributes within the same category. Beginning\nwith a single dress, we seek to classify the type of dress hem, the hem length,\nand the sleeve length. The proposed scheme is comprised of three major stages:\n(a) localization of a target item from an input image using semantic\nsegmentation, (b) detection of human key points (e.g., point of shoulder) using\na pre-trained CNN and a bounding box, and (c) three phases to classify the\nattributes using a combination of algorithmic approaches and deep neural\nnetworks. The experimental results demonstrate that the proposed scheme is\nhighly effective, with all categories having average precision of above 93.02%,\nand outperforms existing Convolutional Neural Networks (CNNs)-based schemes.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 19:44:43 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Mallavarapu", "Tejaswini", ""], ["Cranfill", "Luke", ""], ["Son", "Junggab", ""], ["Kim", "Eun Hye", ""], ["Parizi", "Reza M.", ""], ["Morris", "John", ""]]}, {"id": "2008.12353", "submitter": "Connor Heaton", "authors": "Connor T. Heaton, Prasenjit Mitra", "title": "Repurposing TREC-COVID Annotations to Answer the Key Questions of\n  CORD-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novel coronavirus disease 2019 (COVID-19) began in Wuhan, China in late\n2019 and to date has infected over 14M people worldwide, resulting in over\n750,000 deaths. On March 10, 2020 the World Health Organization (WHO) declared\nthe outbreak a global pandemic. Many academics and researchers, not restricted\nto the medical domain, began publishing papers describing new discoveries.\nHowever, with the large influx of publications, it was hard for these\nindividuals to sift through the large amount of data and make sense of the\nfindings. The White House and a group of industry research labs, lead by the\nAllen Institute for AI, aggregated over 200,000 journal articles related to a\nvariety of coronaviruses and tasked the community with answering key questions\nrelated to the corpus, releasing the dataset as CORD-19. The information\nretrieval (IR) community repurposed the journal articles within CORD-19 to more\nclosely resemble a classic TREC-style competition, dubbed TREC-COVID, with\nhuman annotators providing relevancy judgements at the end of each round of\ncompetition. Seeing the related endeavors, we set out to repurpose the\nrelevancy annotations for TREC-COVID tasks to identify journal articles in\nCORD-19 which are relevant to the key questions posed by CORD-19. A BioBERT\nmodel trained on this repurposed dataset prescribes relevancy annotations for\nCORD-19 tasks that have an overall agreement of 0.4430 with majority human\nannotations in terms of Cohen's kappa. We present the methodology used to\nconstruct the new dataset and describe the decision process used throughout.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 19:51:07 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Heaton", "Connor T.", ""], ["Mitra", "Prasenjit", ""]]}, {"id": "2008.12380", "submitter": "Alvaro Gomariz", "authors": "Alvaro Gomariz, Tiziano Portenier, Patrick M. Helbling, Stephan\n  Isringhausen, Ute Suessbier, C\\'esar Nombela-Arrieta, Orcun Goksel", "title": "Modality Attention and Sampling Enables Deep Learning with Heterogeneous\n  Marker Combinations in Fluorescence Microscopy", "comments": "Main: 21 pages, 6 figures, 1 table. Supplementary: 5 pages, 7\n  figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fluorescence microscopy allows for a detailed inspection of cells, cellular\nnetworks, and anatomical landmarks by staining with a variety of\ncarefully-selected markers visualized as color channels. Quantitative\ncharacterization of structures in acquired images often relies on automatic\nimage analysis methods. Despite the success of deep learning methods in other\nvision applications, their potential for fluorescence image analysis remains\nunderexploited. One reason lies in the considerable workload required to train\naccurate models, which are normally specific for a given combination of\nmarkers, and therefore applicable to a very restricted number of experimental\nsettings. We herein propose Marker Sampling and Excite, a neural network\napproach with a modality sampling strategy and a novel attention module that\ntogether enable (i) flexible training with heterogeneous datasets with\ncombinations of markers and (ii) successful utility of learned models on\narbitrary subsets of markers prospectively. We show that our single neural\nnetwork solution performs comparably to an upper bound scenario where an\nensemble of many networks is na\\\"ively trained for each possible marker\ncombination separately. In addition, we demonstrate the feasibility of this\nframework in high-throughput biological analysis by revising a recent\nquantitative characterization of bone marrow vasculature in 3D confocal\nmicroscopy datasets and further confirm the validity of our approach on an\nadditional, significantly different dataset of microvessels in fetal liver\ntissues. Not only can our work substantially ameliorate the use of deep\nlearning in fluorescence microscopy analysis, but it can also be utilized in\nother fields with incomplete data acquisitions and missing modalities.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 21:57:07 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 19:37:38 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Gomariz", "Alvaro", ""], ["Portenier", "Tiziano", ""], ["Helbling", "Patrick M.", ""], ["Isringhausen", "Stephan", ""], ["Suessbier", "Ute", ""], ["Nombela-Arrieta", "C\u00e9sar", ""], ["Goksel", "Orcun", ""]]}, {"id": "2008.12388", "submitter": "Matthew Jones", "authors": "Matthew Jones, Huy L\\^e Nguyen, Thy Nguyen", "title": "Differentially Private Clustering via Maximum Coverage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of clustering in metric spaces while\npreserving the privacy of individual data. Specifically, we examine\ndifferentially private variants of the k-medians and Euclidean k-means\nproblems. We present polynomial algorithms with constant multiplicative error\nand lower additive error than the previous state-of-the-art for each problem.\nAdditionally, our algorithms use a clustering algorithm without differential\nprivacy as a black-box. This allows practitioners to control the trade-off\nbetween runtime and approximation factor by choosing a suitable clustering\nalgorithm to use.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 22:11:18 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Jones", "Matthew", ""], ["Nguyen", "Huy L\u00ea", ""], ["Nguyen", "Thy", ""]]}, {"id": "2008.12401", "submitter": "John Thomson", "authors": "Sizhe Yuen, John D. Thomson, Oliver Don", "title": "Automatic Player Identification in Dota 2", "comments": "11 pages, 13 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dota 2 is a popular, multiplayer online video game. Like many online games,\nplayers are mostly anonymous, being tied only to online accounts which can be\nreadily obtained, sold and shared between multiple people. This makes it\ndifficult to track or ban players who exhibit unwanted behavior online. In this\npaper, we present a machine learning approach to identify players based a\n`digital fingerprint' of how they play the game, rather than by account. We use\ndata on mouse movements, in-game statistics and game strategy extracted from\nmatch replays and show that for best results, all of these are necessary. We\nare able to obtain an accuracy of prediction of 95\\% for the problem of\npredicting if two different matches were played by the same player.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 22:58:01 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Yuen", "Sizhe", ""], ["Thomson", "John D.", ""], ["Don", "Oliver", ""]]}, {"id": "2008.12408", "submitter": "Akshay Gadde", "authors": "Sam John, Akshay Gadde and Balu Adsumilli", "title": "Rate distortion optimization over large scale video corpus with machine\n  learning", "comments": "Accepted in 2020 IEEE International Conference on Image Processing\n  (ICIP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient codec-agnostic method for bitrate allocation over a\nlarge scale video corpus with the goal of minimizing the average bitrate\nsubject to constraints on average and minimum quality. Our method clusters the\nvideos in the corpus such that videos within one cluster have similar\nrate-distortion (R-D) characteristics. We train a support vector machine\nclassifier to predict the R-D cluster of a video using simple video complexity\nfeatures that are computationally easy to obtain. The model allows us to\nclassify a large sample of the corpus in order to estimate the distribution of\nthe number of videos in each of the clusters. We use this distribution to find\nthe optimal encoder operating point for each R-D cluster. Experiments with AV1\nencoder show that our method can achieve the same average quality over the\ncorpus with $22\\%$ less average bitrate.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 23:40:22 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["John", "Sam", ""], ["Gadde", "Akshay", ""], ["Adsumilli", "Balu", ""]]}, {"id": "2008.12410", "submitter": "Niharika Shimona D'Souza", "authors": "Niharika Shimona D'Souza, Mary Beth Nebel, Deana Crocetti, Nicholas\n  Wymbs, Joshua Robinson, Stewart H. Mostofsky, Archana Venkataraman", "title": "Deep sr-DDL: Deep Structurally Regularized Dynamic Dictionary Learning\n  to Integrate Multimodal and Dynamic Functional Connectomics data for\n  Multidimensional Clinical Characterizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel integrated framework that jointly models complementary\ninformation from resting-state functional MRI (rs-fMRI) connectivity and\ndiffusion tensor imaging (DTI) tractography to extract biomarkers of brain\nconnectivity predictive of behavior. Our framework couples a generative model\nof the connectomics data with a deep network that predicts behavioral scores.\nThe generative component is a structurally-regularized Dynamic Dictionary\nLearning (sr-DDL) model that decomposes the dynamic rs-fMRI correlation\nmatrices into a collection of shared basis networks and time varying\nsubject-specific loadings. We use the DTI tractography to regularize this\nmatrix factorization and learn anatomically informed functional connectivity\nprofiles. The deep component of our framework is an LSTM-ANN block, which uses\nthe temporal evolution of the subject-specific sr-DDL loadings to predict\nmultidimensional clinical characterizations. Our joint optimization strategy\ncollectively estimates the basis networks, the subject-specific time-varying\nloadings, and the neural network weights. We validate our framework on a\ndataset of neurotypical individuals from the Human Connectome Project (HCP)\ndatabase to map to cognition and on a separate multi-score prediction task on\nindividuals diagnosed with Autism Spectrum Disorder (ASD) in a five-fold cross\nvalidation setting. Our hybrid model outperforms several state-of-the-art\napproaches at clinical outcome prediction and learns interpretable multimodal\nneural signatures of brain organization.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 23:43:56 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["D'Souza", "Niharika Shimona", ""], ["Nebel", "Mary Beth", ""], ["Crocetti", "Deana", ""], ["Wymbs", "Nicholas", ""], ["Robinson", "Joshua", ""], ["Mostofsky", "Stewart H.", ""], ["Venkataraman", "Archana", ""]]}, {"id": "2008.12413", "submitter": "Gautam Gare", "authors": "Gautam Rajendrakumar Gare, Jiayuan Li, Rohan Joshi, Mrunal Prashant\n  Vaze, Rishikesh Magar, Michael Yousefpour, Ricardo Luis Rodriguez and John\n  Micheal Galeotti", "title": "W-Net: Dense Semantic Segmentation of Subcutaneous Tissue in Ultrasound\n  Images by Expanding U-Net to Incorporate Ultrasound RF Waveform Data", "comments": "The paper is currently under review for publication in a\n  peer-reviewed journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present W-Net, a novel Convolution Neural Network (CNN) framework that\nemploys raw ultrasound waveforms from each A-scan, typically referred to as\nultrasound Radio Frequency (RF) data, in addition to the gray ultrasound image\nto semantically segment and label tissues. Unlike prior work, we seek to label\nevery pixel in the image, without the use of a background class. To the best of\nour knowledge, this is also the first deep-learning or CNN approach for\nsegmentation that analyses ultrasound raw RF data along with the gray image.\nInternational patent(s) pending [PCT/US20/37519]. We chose subcutaneous tissue\n(SubQ) segmentation as our initial clinical goal since it has diverse\nintermixed tissues, is challenging to segment, and is an underrepresented\nresearch area. SubQ potential applications include plastic surgery, adipose\nstem-cell harvesting, lymphatic monitoring, and possibly detection/treatment of\ncertain types of tumors. A custom dataset consisting of hand-labeled images by\nan expert clinician and trainees are used for the experimentation, currently\nlabeled into the following categories: skin, fat, fat fascia/stroma, muscle and\nmuscle fascia. We compared our results with U-Net and Attention U-Net. Our\nnovel \\emph{W-Net}'s RF-Waveform input and architecture increased mIoU accuracy\n(averaged across all tissue classes) by 4.5\\% and 4.9\\% compared to regular\nU-Net and Attention U-Net, respectively. We present analysis as to why the\nMuscle fascia and Fat fascia/stroma are the most difficult tissues to label.\nMuscle fascia in particular, the most difficult anatomic class to recognize for\nboth humans and AI algorithms, saw mIoU improvements of 13\\% and 16\\% from our\nW-Net vs U-Net and Attention U-Net respectively.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 23:53:20 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 09:14:27 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Gare", "Gautam Rajendrakumar", ""], ["Li", "Jiayuan", ""], ["Joshi", "Rohan", ""], ["Vaze", "Mrunal Prashant", ""], ["Magar", "Rishikesh", ""], ["Yousefpour", "Michael", ""], ["Rodriguez", "Ricardo Luis", ""], ["Galeotti", "John Micheal", ""]]}, {"id": "2008.12416", "submitter": "Yu-Huan Wu", "authors": "Yu-Huan Wu, Yun Liu, Le Zhang, Wang Gao, and Ming-Ming Cheng", "title": "Regularized Densely-connected Pyramid Network for Salient Instance\n  Segmentation", "comments": "Accepted in IEEE Transactions on Image Processing. Code:\n  https://github.com/yuhuan-wu/RDPNet", "journal-ref": null, "doi": "10.1109/TIP.2021.3065822", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Much of the recent efforts on salient object detection (SOD) have been\ndevoted to producing accurate saliency maps without being aware of their\ninstance labels. To this end, we propose a new pipeline for end-to-end salient\ninstance segmentation (SIS) that predicts a class-agnostic mask for each\ndetected salient instance. To better use the rich feature hierarchies in deep\nnetworks and enhance the side predictions, we propose the regularized dense\nconnections, which attentively promote informative features and suppress\nnon-informative ones from all feature pyramids. A novel multi-level RoIAlign\nbased decoder is introduced to adaptively aggregate multi-level features for\nbetter mask predictions. Such strategies can be well-encapsulated into the Mask\nR-CNN pipeline. Extensive experiments on popular benchmarks demonstrate that\nour design significantly outperforms existing \\sArt competitors by 6.3\\%\n(58.6\\% vs. 52.3\\%) in terms of the AP metric.The code is available at\nhttps://github.com/yuhuan-wu/RDPNet.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 00:13:30 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 03:21:50 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Wu", "Yu-Huan", ""], ["Liu", "Yun", ""], ["Zhang", "Le", ""], ["Gao", "Wang", ""], ["Cheng", "Ming-Ming", ""]]}, {"id": "2008.12435", "submitter": "Md Abul Bashar", "authors": "Md Abul Bashar, Richi Nayak, Thirunavukarasu Balasubramaniam", "title": "Topic, Sentiment and Impact Analysis: COVID19 Information Seeking on\n  Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When people notice something unusual, they discuss it on social media. They\nleave traces of their emotions via text expressions. A systematic collection,\nanalysis, and interpretation of social media data across time and space can\ngive insights on local outbreaks, mental health, and social issues. Such timely\ninsights can help in developing strategies and resources with an appropriate\nand efficient response. This study analysed a large Spatio-temporal tweet\ndataset of the Australian sphere related to COVID19. The methodology included a\nvolume analysis, dynamic topic modelling, sentiment detection, and semantic\nbrand score to obtain an insight on the COVID19 pandemic outbreak and public\ndiscussion in different states and cities of Australia over time. The obtained\ninsights are compared with independently observed phenomena such as government\nreported instances.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 02:03:18 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Bashar", "Md Abul", ""], ["Nayak", "Richi", ""], ["Balasubramaniam", "Thirunavukarasu", ""]]}, {"id": "2008.12438", "submitter": "Weijun Xie", "authors": "Yongchun Li and Weijun Xie", "title": "Exact and Approximation Algorithms for Sparse PCA", "comments": "49 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse PCA (SPCA) is a fundamental model in machine learning and data\nanalytics, which has witnessed a variety of application areas such as finance,\nmanufacturing, biology, healthcare. To select a prespecified-size principal\nsubmatrix from a covariance matrix to maximize its largest eigenvalue for the\nbetter interpretability purpose, SPCA advances the conventional PCA with both\nfeature selection and dimensionality reduction. This paper proposes two exact\nmixed-integer SDPs (MISDPs) by exploiting the spectral decomposition of the\ncovariance matrix and the properties of the largest eigenvalues. We then\nanalyze the theoretical optimality gaps of their continuous relaxation values\nand prove that they are stronger than that of the state-of-art one. We further\nshow that the continuous relaxations of two MISDPs can be recast as saddle\npoint problems without involving semi-definite cones, and thus can be\neffectively solved by first-order methods such as the subgradient method. Since\noff-the-shelf solvers, in general, have difficulty in solving MISDPs, we\napproximate SPCA with arbitrary accuracy by a mixed-integer linear program\n(MILP) of a similar size as MISDPs. To be more scalable, we also analyze greedy\nand local search algorithms, prove their first-known approximation ratios, and\nshow that the approximation ratios are tight. Our numerical study demonstrates\nthat the continuous relaxation values of the proposed MISDPs are quite close to\noptimality, the proposed MILP model can solve small and medium-size instances\nto optimality, and the approximation algorithms work very well for all the\ninstances. Finally, we extend the analyses to Rank-one Sparse SVD (R1-SSVD)\nwith non-symmetric matrices and Sparse Fair PCA (SFPCA) when there are multiple\ncovariance matrices, each corresponding to a protected group.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 02:07:08 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Li", "Yongchun", ""], ["Xie", "Weijun", ""]]}, {"id": "2008.12442", "submitter": "Zhe Jiang", "authors": "Wenchong He and Zhe Jiang", "title": "Semi-supervised Learning with the EM Algorithm: A Comparative Study\n  between Unstructured and Structured Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning aims to learn prediction models from both labeled\nand unlabeled samples. There has been extensive research in this area. Among\nexisting work, generative mixture models with Expectation-Maximization (EM) is\na popular method due to clear statistical properties. However, existing\nliterature on EM-based semi-supervised learning largely focuses on unstructured\nprediction, assuming that samples are independent and identically distributed.\nStudies on EM-based semi-supervised approach in structured prediction is\nlimited. This paper aims to fill the gap through a comparative study between\nunstructured and structured methods in EM-based semi-supervised learning.\nSpecifically, we compare their theoretical properties and find that both\nmethods can be considered as a generalization of self-training with soft class\nassignment of unlabeled samples, but the structured method additionally\nconsiders structural constraint in soft class assignment. We conducted a case\nstudy on real-world flood mapping datasets to compare the two methods. Results\nshow that structured EM is more robust to class confusion caused by noise and\nobstacles in features in the context of the flood mapping application.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 02:20:05 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["He", "Wenchong", ""], ["Jiang", "Zhe", ""]]}, {"id": "2008.12448", "submitter": "Md Abul Bashar", "authors": "Md Abul Bashar, Richi Nayak", "title": "QutNocturnal@HASOC'19: CNN for Hate Speech and Offensive Content\n  Identification in Hindi Language", "comments": null, "journal-ref": "CEUR Workshop Proceedings. Working Notes of FIRE 2019 - Forum for\n  Information Retrieval Evaluation. Vol. 2517. Sun SITE Central Europe,\n  Germany, pp. 237-245", "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our top-team solution to Task 1 for Hindi in the HASOC contest\norganised by FIRE 2019. The task is to identify hate speech and offensive\nlanguage in Hindi. More specifically, it is a binary classification problem\nwhere a system is required to classify tweets into two classes: (a) \\emph{Hate\nand Offensive (HOF)} and (b) \\emph{Not Hate or Offensive (NOT)}. In contrast to\nthe popular idea of pretraining word vectors (a.k.a. word embedding) with a\nlarge corpus from a general domain such as Wikipedia, we used a relatively\nsmall collection of relevant tweets (i.e. random and sarcasm tweets in Hindi\nand Hinglish) for pretraining. We trained a Convolutional Neural Network (CNN)\non top of the pretrained word vectors. This approach allowed us to be ranked\nfirst for this task out of all teams. Our approach could easily be adapted to\nother applications where the goal is to predict class of a text when the\nprovided context is limited.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 02:44:17 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Bashar", "Md Abul", ""], ["Nayak", "Richi", ""]]}, {"id": "2008.12450", "submitter": "Xu Chen", "authors": "Xu Chen and Jiangchao Yao and Maosen Li and Ya zhang and Yanfeng Wang", "title": "Decoupled Variational Embedding for Signed Directed Networks", "comments": "This paper is accepted by ACM Transactions on the WEB, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Node representation learning for signed directed networks has received\nconsiderable attention in many real-world applications such as link sign\nprediction, node classification and node recommendation. The challenge lies in\nhow to adequately encode the complex topological information of the networks.\nRecent studies mainly focus on preserving the first-order network topology\nwhich indicates the closeness relationships of nodes. However, these methods\ngenerally fail to capture the high-order topology which indicates the local\nstructures of nodes and serves as an essential characteristic of the network\ntopology. In addition, for the first-order topology, the additional value of\nnon-existent links is largely ignored. In this paper, we propose to learn more\nrepresentative node embeddings by simultaneously capturing the first-order and\nhigh-order topology in signed directed networks. In particular, we reformulate\nthe representation learning problem on signed directed networks from a\nvariational auto-encoding perspective and further develop a decoupled\nvariational embedding (DVE) method. DVE leverages a specially designed\nauto-encoder structure to capture both the first-order and high-order topology\nof signed directed networks, and thus learns more representative node\nembedding. Extensive experiments are conducted on three widely used real-world\ndatasets. Comprehensive results on both link sign prediction and node\nrecommendation task demonstrate the effectiveness of DVE. Qualitative results\nand analysis are also given to provide a better understanding of DVE.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 02:48:15 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Chen", "Xu", ""], ["Yao", "Jiangchao", ""], ["Li", "Maosen", ""], ["zhang", "Ya", ""], ["Wang", "Yanfeng", ""]]}, {"id": "2008.12451", "submitter": "Fei Ye", "authors": "Fei Ye, Pin Wang, Ching-Yao Chan and Jiucai Zhang", "title": "Meta Reinforcement Learning-Based Lane Change Strategy for Autonomous\n  Vehicles", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in supervised learning and reinforcement learning have\nprovided new opportunities to apply related methodologies to automated driving.\nHowever, there are still challenges to achieve automated driving maneuvers in\ndynamically changing environments. Supervised learning algorithms such as\nimitation learning can generalize to new environments by training on a large\namount of labeled data, however, it can be often impractical or\ncost-prohibitive to obtain sufficient data for each new environment. Although\nreinforcement learning methods can mitigate this data-dependency issue by\ntraining the agent in a trial-and-error way, they still need to re-train\npolicies from scratch when adapting to new environments. In this paper, we thus\npropose a meta reinforcement learning (MRL) method to improve the agent's\ngeneralization capabilities to make automated lane-changing maneuvers at\ndifferent traffic environments, which are formulated as different traffic\ncongestion levels. Specifically, we train the model at light to moderate\ntraffic densities and test it at a new heavy traffic density condition. We use\nboth collision rate and success rate to quantify the safety and effectiveness\nof the proposed model. A benchmark model is developed based on a pretraining\nmethod, which uses the same network structure and training tasks as our\nproposed model for fair comparison. The simulation results shows that the\nproposed method achieves an overall success rate up to 20% higher than the\nbenchmark model when it is generalized to the new environment of heavy traffic\ndensity. The collision rate is also reduced by up to 18% than the benchmark\nmodel. Finally, the proposed model shows more stable and efficient\ngeneralization capabilities adapting to the new environment, and it can achieve\n100% successful rate and 0% collision rate with only a few steps of gradient\nupdates.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 02:57:11 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Ye", "Fei", ""], ["Wang", "Pin", ""], ["Chan", "Ching-Yao", ""], ["Zhang", "Jiucai", ""]]}, {"id": "2008.12452", "submitter": "Md Abul Bashar", "authors": "Md Abul Bashar, Richi Nayak, Nicolas Suzor, Bridget Weir", "title": "Misogynistic Tweet Detection: Modelling CNN with Small Datasets", "comments": null, "journal-ref": "Australasian Conference on Data Mining. Springer. 3--16, 2018", "doi": "10.1007/978-981-13-6661-1_1", "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online abuse directed towards women on the social media platform Twitter has\nattracted considerable attention in recent years. An automated method to\neffectively identify misogynistic abuse could improve our understanding of the\npatterns, driving factors, and effectiveness of responses associated with\nabusive tweets over a sustained time period. However, training a neural network\n(NN) model with a small set of labelled data to detect misogynistic tweets is\ndifficult. This is partly due to the complex nature of tweets which contain\nmisogynistic content, and the vast number of parameters needed to be learned in\na NN model. We have conducted a series of experiments to investigate how to\ntrain a NN model to detect misogynistic tweets effectively. In particular, we\nhave customised and regularised a Convolutional Neural Network (CNN)\narchitecture and shown that the word vectors pre-trained on a task-specific\ndomain can be used to train a CNN model effectively when a small set of\nlabelled data is available. A CNN model trained in this way yields an improved\naccuracy over the state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 02:59:22 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Bashar", "Md Abul", ""], ["Nayak", "Richi", ""], ["Suzor", "Nicolas", ""], ["Weir", "Bridget", ""]]}, {"id": "2008.12463", "submitter": "Xu Ouyang", "authors": "Xu Ouyang, Gady Agam", "title": "Accelerated WGAN update strategy with loss change rate balancing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing the discriminator in Generative Adversarial Networks (GANs) to\ncompletion in the inner training loop is computationally prohibitive, and on\nfinite datasets would result in overfitting. To address this, a common update\nstrategy is to alternate between k optimization steps for the discriminator D\nand one optimization step for the generator G. This strategy is repeated in\nvarious GAN algorithms where k is selected empirically. In this paper, we show\nthat this update strategy is not optimal in terms of accuracy and convergence\nspeed, and propose a new update strategy for Wasserstein GANs (WGAN) and other\nGANs using the WGAN loss(e.g. WGAN-GP, Deblur GAN, and Super-resolution GAN).\nThe proposed update strategy is based on a loss change ratio comparison of G\nand D. We demonstrate that the proposed strategy improves both convergence\nspeed and accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 03:29:09 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 01:45:11 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Ouyang", "Xu", ""], ["Agam", "Gady", ""]]}, {"id": "2008.12466", "submitter": "Farhad Farokhi", "authors": "Farhad Farokhi", "title": "Deconvoluting Kernel Density Estimation and Regression for Locally\n  Differentially Private Data", "comments": "updated reference list, deeper numerical analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CR cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local differential privacy has become the gold-standard of privacy literature\nfor gathering or releasing sensitive individual data points in a\nprivacy-preserving manner. However, locally differential data can twist the\nprobability density of the data because of the additive noise used to ensure\nprivacy. In fact, the density of privacy-preserving data (no matter how many\nsamples we gather) is always flatter in comparison with the density function of\nthe original data points due to convolution with privacy-preserving noise\ndensity function. The effect is especially more pronounced when using\nslow-decaying privacy-preserving noises, such as the Laplace noise. This can\nresult in under/over-estimation of the heavy-hitters. This is an important\nchallenge facing social scientists due to the use of differential privacy in\nthe 2020 Census in the United States. In this paper, we develop density\nestimation methods using smoothing kernels. We use the framework of\ndeconvoluting kernel density estimators to remove the effect of\nprivacy-preserving noise. This approach also allows us to adapt the results\nfrom non-parameteric regression with errors-in-variables to develop regression\nmodels based on locally differentially private data. We demonstrate the\nperformance of the developed methods on financial and demographic datasets.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 03:39:17 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 03:32:15 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Farokhi", "Farhad", ""]]}, {"id": "2008.12471", "submitter": "Taehyun Kim", "authors": "Taehyun Kim, Hyomin Shin, Hyung Ju Hwang, Seungwon Jeong", "title": "Posting Bot Detection on Blockchain-based Social Media Platform using\n  Machine Learning Techniques", "comments": "ICWSM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steemit is a blockchain-based social media platform, where authors can get\nauthor rewards in the form of cryptocurrencies called STEEM and SBD (Steem\nBlockchain Dollars) if their posts are upvoted. Interestingly, curators (or\nvoters) can also get rewards by voting others' posts, which is called a\ncuration reward. A reward is proportional to a curator's STEEM stakes.\nThroughout this process, Steemit hopes \"good\" content will be automatically\ndiscovered by users in a decentralized way, which is known as the\nProof-of-Brain (PoB). However, there are many bot accounts programmed to post\nautomatically and get rewards, which discourages real human users from creating\ngood content. We call this type of bot a posting bot. While there are many\npapers that studied bots on traditional centralized social media platforms such\nas Facebook and Twitter, we are the first to study posting bots on a\nblockchain-based social media platform. Compared with the bot detection on the\nusual social media platforms, the features we created have an advantage that\nposting bots can be detected without limiting the number or length of posts. We\ncan extract the features of posts by clustering distances between blog data or\nreplies. These features are obtained from the Minimum Average Cluster from\nClustering Distance between Frequent words and Articles (MAC-CDFA), which is\nnot used in any of the previous social media research. Based on the enriched\nfeatures, we enhanced the quality of classification tasks. Comparing the\nF1-scores, the features we created outperformed the features used for bot\ndetection on Facebook and Twitter.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 04:00:54 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Kim", "Taehyun", ""], ["Shin", "Hyomin", ""], ["Hwang", "Hyung Ju", ""], ["Jeong", "Seungwon", ""]]}, {"id": "2008.12473", "submitter": "Xianggen Liu", "authors": "Xianggen Liu, Yunan Luo, Sen Song and Jian Peng", "title": "Pre-training of Graph Neural Network for Modeling Effects of Mutations\n  on Protein-Protein Binding Affinity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling the effects of mutations on the binding affinity plays a crucial\nrole in protein engineering and drug design. In this study, we develop a novel\ndeep learning based framework, named GraphPPI, to predict the binding affinity\nchanges upon mutations based on the features provided by a graph neural network\n(GNN). In particular, GraphPPI first employs a well-designed pre-training\nscheme to enforce the GNN to capture the features that are predictive of the\neffects of mutations on binding affinity in an unsupervised manner and then\nintegrates these graphical features with gradient-boosting trees to perform the\nprediction. Experiments showed that, without any annotated signals, GraphPPI\ncan capture meaningful patterns of the protein structures. Also, GraphPPI\nachieved new state-of-the-art performance in predicting the binding affinity\nchanges upon both single- and multi-point mutations on five benchmark datasets.\nIn-depth analyses also showed GraphPPI can accurately estimate the effects of\nmutations on the binding affinity between SARS-CoV-2 and its neutralizing\nantibodies. These results have established GraphPPI as a powerful and useful\ncomputational tool in the studies of protein design.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 04:07:39 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Liu", "Xianggen", ""], ["Luo", "Yunan", ""], ["Song", "Sen", ""], ["Peng", "Jian", ""]]}, {"id": "2008.12478", "submitter": "Alessandro Achille", "authors": "Luca Zancato, Alessandro Achille, Avinash Ravichandran, Rahul Bhotika,\n  Stefano Soatto", "title": "Predicting Training Time Without Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of predicting the number of optimization steps that a\npre-trained deep network needs to converge to a given value of the loss\nfunction. To do so, we leverage the fact that the training dynamics of a deep\nnetwork during fine-tuning are well approximated by those of a linearized\nmodel. This allows us to approximate the training loss and accuracy at any\npoint during training by solving a low-dimensional Stochastic Differential\nEquation (SDE) in function space. Using this result, we are able to predict the\ntime it takes for Stochastic Gradient Descent (SGD) to fine-tune a model to a\ngiven loss without having to perform any training. In our experiments, we are\nable to predict training time of a ResNet within a 20% error margin on a\nvariety of datasets and hyper-parameters, at a 30 to 45-fold reduction in cost\ncompared to actual training. We also discuss how to further reduce the\ncomputational and memory cost of our method, and in particular we show that by\nexploiting the spectral properties of the gradients' matrix it is possible\npredict training time on a large dataset while processing only a subset of the\nsamples.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 04:29:54 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Zancato", "Luca", ""], ["Achille", "Alessandro", ""], ["Ravichandran", "Avinash", ""], ["Bhotika", "Rahul", ""], ["Soatto", "Stefano", ""]]}, {"id": "2008.12483", "submitter": "Majid Ashouri", "authors": "Majid Ashouri and Alireza Hashemi", "title": "A transfer learning metamodel using artificial neural networks applied\n  to natural convection flows in enclosures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we employed a transfer learning technique to predict the\nNusselt number for natural convection flows in enclosures. Specifically, we\nconsidered the benchmark problem of a two-dimensional square enclosure with\nisolated horizontal walls and vertical walls at constant temperatures. The\nRayleigh and Prandtl numbers are sufficient parameters to simulate this problem\nnumerically. We adopted two approaches to this problem: Firstly, we made use of\na multi-grid dataset in order to train our artificial neural network in a\ncost-effective manner. By monitoring the training losses for this dataset, we\ndetected any significant anomalies that stemmed from an insufficient grid size,\nwhich we further corrected by altering the grid size or adding more data.\nSecondly, we sought to endow our metamodel with the ability to account for\nadditional input features by performing transfer learning using deep neural\nnetworks. We trained a neural network with a single input feature (Rayleigh)\nand extended it to incorporate the effects of a second feature (Prandtl). We\nalso considered the case of hollow enclosures, demonstrating that our learning\nframework can be applied to systems with higher physical complexity, while\nbringing the computational and training costs down.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 04:51:20 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 06:18:51 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Ashouri", "Majid", ""], ["Hashemi", "Alireza", ""]]}, {"id": "2008.12496", "submitter": "Geonuk Kim", "authors": "Geonuk Kim, Hong-Gyu Jung, Seong-Whan Lee", "title": "Few-Shot Object Detection via Knowledge Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional methods for object detection usually require substantial amounts\nof training data and annotated bounding boxes. If there are only a few training\ndata and annotations, the object detectors easily overfit and fail to\ngeneralize. It exposes the practical weakness of the object detectors. On the\nother hand, human can easily master new reasoning rules with only a few\ndemonstrations using previously learned knowledge. In this paper, we introduce\na few-shot object detection via knowledge transfer, which aims to detect\nobjects from a few training examples. Central to our method is prototypical\nknowledge transfer with an attached meta-learner. The meta-learner takes\nsupport set images that include the few examples of the novel categories and\nbase categories, and predicts prototypes that represent each category as a\nvector. Then, the prototypes reweight each RoI (Region-of-Interest) feature\nvector from a query image to remodels R-CNN predictor heads. To facilitate the\nremodeling process, we predict the prototypes under a graph structure, which\npropagates information of the correlated base categories to the novel\ncategories with explicit guidance of prior knowledge that represents\ncorrelations among categories. Extensive experiments on the PASCAL VOC dataset\nverifies the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 06:35:27 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Kim", "Geonuk", ""], ["Jung", "Hong-Gyu", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2008.12504", "submitter": "Rohde David", "authors": "Otmane Sakhi, Stephen Bonner, David Rohde, Flavian Vasile", "title": "BLOB : A Probabilistic Model for Recommendation that Combines Organic\n  and Bandit Signals", "comments": "26th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,\n  Aug 2020, San Diego, United States", "journal-ref": null, "doi": "10.1145/3394486.3403121", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common task for recommender systems is to build a pro le of the interests\nof a user from items in their browsing history and later to recommend items to\nthe user from the same catalog. The users' behavior consists of two parts: the\nsequence of items that they viewed without intervention (the organic part) and\nthe sequences of items recommended to them and their outcome (the bandit part).\nIn this paper, we propose Bayesian Latent Organic Bandit model (BLOB), a\nprobabilistic approach to combine the 'or-ganic' and 'bandit' signals in order\nto improve the estimation of recommendation quality. The bandit signal is\nvaluable as it gives direct feedback of recommendation performance, but the\nsignal quality is very uneven, as it is highly concentrated on the\nrecommendations deemed optimal by the past version of the recom-mender system.\nIn contrast, the organic signal is typically strong and covers most items, but\nis not always relevant to the recommendation task. In order to leverage the\norganic signal to e ciently learn the bandit signal in a Bayesian model we\nidentify three fundamental types of distances, namely action-history,\naction-action and history-history distances. We implement a scalable\napproximation of the full model using variational auto-encoders and the local\nre-paramerization trick. We show using extensive simulation studies that our\nmethod out-performs or matches the value of both state-of-the-art organic-based\nrecommendation algorithms, and of bandit-based methods (both value and\npolicy-based) both in organic and bandit-rich environments.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 06:57:10 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Sakhi", "Otmane", ""], ["Bonner", "Stephen", ""], ["Rohde", "David", ""], ["Vasile", "Flavian", ""]]}, {"id": "2008.12522", "submitter": "Genggeng Liu", "authors": "Genggeng Liu, Canyang Guo, Lin Xie, Wenxi Liu, Naixue Xiong and\n  Guolong Chen", "title": "An Intelligent CNN-VAE Text Representation Technology Based on Text\n  Semantics for Comprehensive Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of big data, a large number of text data generated by the Internet\nhas given birth to a variety of text representation methods. In natural\nlanguage processing (NLP), text representation transforms text into vectors\nthat can be processed by computer without losing the original semantic\ninformation. However, these methods are difficult to effectively extract the\nsemantic features among words and distinguish polysemy in language. Therefore,\na text feature representation model based on convolutional neural network (CNN)\nand variational autoencoder (VAE) is proposed to extract the text features and\napply the obtained text feature representation on the text classification\ntasks. CNN is used to extract the features of text vector to get the semantics\namong words and VAE is introduced to make the text feature space more\nconsistent with Gaussian distribution. In addition, the output of the improved\nword2vec model is employed as the input of the proposed model to distinguish\ndifferent meanings of the same word in different contexts. The experimental\nresults show that the proposed model outperforms in k-nearest neighbor (KNN),\nrandom forest (RF) and support vector machine (SVM) classification algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 07:39:45 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Liu", "Genggeng", ""], ["Guo", "Canyang", ""], ["Xie", "Lin", ""], ["Liu", "Wenxi", ""], ["Xiong", "Naixue", ""], ["Chen", "Guolong", ""]]}, {"id": "2008.12534", "submitter": "Lingxiao Li", "authors": "Lingxiao Li, Aude Genevay, Mikhail Yurochkin, Justin Solomon", "title": "Continuous Regularized Wasserstein Barycenters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wasserstein barycenters provide a geometrically meaningful way to aggregate\nprobability distributions, built on the theory of optimal transport. They are\ndifficult to compute in practice, however, leading previous work to restrict\ntheir supports to finite sets of points. Leveraging a new dual formulation for\nthe regularized Wasserstein barycenter problem, we introduce a stochastic\nalgorithm that constructs a continuous approximation of the barycenter. We\nestablish strong duality and use the corresponding primal-dual relationship to\nparametrize the barycenter implicitly using the dual potentials of regularized\ntransport problems. The resulting problem can be solved with stochastic\ngradient descent, which yields an efficient online algorithm to approximate the\nbarycenter of continuous distributions given sample access. We demonstrate the\neffectiveness of our approach and compare against previous work on synthetic\nexamples and real-world applications.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 08:28:06 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 01:09:18 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Li", "Lingxiao", ""], ["Genevay", "Aude", ""], ["Yurochkin", "Mikhail", ""], ["Solomon", "Justin", ""]]}, {"id": "2008.12537", "submitter": "Paraskevi Chasani", "authors": "Paraskevi Chasani and Aristidis Likas", "title": "The UU-test for Statistical Modeling of Unimodal Data", "comments": "19 pages, 15 figures, 5 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deciding on the unimodality of a dataset is an important problem in data\nanalysis and statistical modeling. It allows to obtain knowledge about the\nstructure of the dataset, ie. whether data points have been generated by a\nprobability distribution with a single or more than one peaks. Such knowledge\nis very useful for several data analysis problems, such as for deciding on the\nnumber of clusters and determining unimodal projections. We propose a technique\ncalled UU-test (Unimodal Uniform test) to decide on the unimodality of a\none-dimensional dataset. The method operates on the empirical cumulative\ndensity function (ecdf) of the dataset. It attempts to build a piecewise linear\napproximation of the ecdf that is unimodal and models the data sufficiently in\nthe sense that the data corresponding to each linear segment follows the\nuniform distribution. A unique feature of this approach is that in the case of\nunimodality, it also provides a statistical model of the data in the form of a\nUniform Mixture Model. We present experimental results in order to assess the\nability of the method to decide on unimodality and perform comparisons with the\nwell-known dip-test approach. In addition, in the case of unimodal datasets we\nevaluate the Uniform Mixture Models provided by the proposed method using the\ntest set log-likelihood and the two-sample Kolmogorov-Smirnov (KS) test.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 08:34:28 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Chasani", "Paraskevi", ""], ["Likas", "Aristidis", ""]]}, {"id": "2008.12544", "submitter": "Maria Wimmer", "authors": "Theresa Neubauer, Maria Wimmer, Astrid Berg, David Major, Dimitrios\n  Lenis, Thomas Beyer, Jelena Saponjski, Katja B\\\"uhler", "title": "Soft Tissue Sarcoma Co-Segmentation in Combined MRI and PET/CT Data", "comments": "Accepted for publication at Multimodal Learning for Clinical Decision\n  Support Workshop at MICCAI 2020 (edit: corrected typos and model name in Fig.\n  3, added missing circles in Table 1)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tumor segmentation in multimodal medical images has seen a growing trend\ntowards deep learning based methods. Typically, studies dealing with this topic\nfuse multimodal image data to improve the tumor segmentation contour for a\nsingle imaging modality. However, they do not take into account that tumor\ncharacteristics are emphasized differently by each modality, which affects the\ntumor delineation. Thus, the tumor segmentation is modality- and\ntask-dependent. This is especially the case for soft tissue sarcomas, where,\ndue to necrotic tumor tissue, the segmentation differs vastly. Closing this\ngap, we develop a modalityspecific sarcoma segmentation model that utilizes\nmultimodal image data to improve the tumor delineation on each individual\nmodality. We propose a simultaneous co-segmentation method, which enables\nmultimodal feature learning through modality-specific encoder and decoder\nbranches, and the use of resource-effcient densely connected convolutional\nlayers. We further conduct experiments to analyze how different input\nmodalities and encoder-decoder fusion strategies affect the segmentation\nresult. We demonstrate the effectiveness of our approach on public soft tissue\nsarcoma data, which comprises MRI (T1 and T2 sequence) and PET/CT scans. The\nresults show that our multimodal co-segmentation model provides better\nmodality-specific tumor segmentation than models using only the PET or MRI (T1\nand T2) scan as input.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 09:15:42 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 09:10:17 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Neubauer", "Theresa", ""], ["Wimmer", "Maria", ""], ["Berg", "Astrid", ""], ["Major", "David", ""], ["Lenis", "Dimitrios", ""], ["Beyer", "Thomas", ""], ["Saponjski", "Jelena", ""], ["B\u00fchler", "Katja", ""]]}, {"id": "2008.12552", "submitter": "Yashank Singh", "authors": "Yashank Singh, Niladri Chatterjee", "title": "Temporal Random Indexing of Context Vectors Applied to Event Detection", "comments": "8 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore new representations for encoding language data. The\ngeneral method of one-hot encoding grows linearly with the size of the word\ncorpus in space-complexity. We address this by using Random Indexing(RI) of\ncontext vectors with non-zero entries. We propose a novel RI representation\nwhere we exploit the effect imposing a probability distribution on the number\nof randomized entries which leads to a class of RI representations. We also\npropose an algorithm that is log linear in the size of word corpus to track the\nsemantic relationship of the query word to other words for suggesting the\nevents that are relevant to the word in question. Finally we run simulations on\nthe novel RI representations using the proposed algorithms for tweets relevant\nto the word \"iPhone\" and present results. The RI representation is shown to be\nfaster and space efficient as compared to BoW embeddings.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 09:37:39 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 13:51:27 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Singh", "Yashank", ""], ["Chatterjee", "Niladri", ""]]}, {"id": "2008.12559", "submitter": "Yong-Chan Park", "authors": "Yong-chan Park, Jun-Gi Jang, U Kang", "title": "Fast Partial Fourier Transform", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a time series vector, how can we efficiently compute a specified part\nof Fourier coefficients? Fast Fourier transform (FFT) is a widely used\nalgorithm that computes the discrete Fourier transform in many machine learning\napplications. Despite its pervasive use, all known FFT algorithms do not\nprovide a fine-tuning option for the user to specify one's demand, that is, the\noutput size (the number of Fourier coefficients to be computed) is\nalgorithmically determined by the input size. This matters because not every\napplication using FFT requires the whole spectrum of the frequency domain,\nresulting in an inefficiency due to extra computation. In this paper, we\npropose a fast Partial Fourier Transform (PFT), a careful modification of the\nCooley-Tukey algorithm that enables one to specify an arbitrary consecutive\nrange where the coefficients should be computed. We derive the asymptotic time\ncomplexity of PFT with respect to input and output sizes, as well as its\nnumerical accuracy. Experimental results show that our algorithm outperforms\nthe state-of-the-art FFT algorithms, with an order of magnitude of speedup for\nsufficiently small output sizes without sacrificing accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 10:01:49 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Park", "Yong-chan", ""], ["Jang", "Jun-Gi", ""], ["Kang", "U", ""]]}, {"id": "2008.12571", "submitter": "Waheeda Saib", "authors": "Waheeda Saib, David Sengeh, Gcininwe Dlamini, Elvira Singh", "title": "Hierarchical Deep Learning Ensemble to Automate the Classification of\n  Breast Cancer Pathology Reports by ICD-O Topography", "comments": "Accepted to KDD workshop on Machine Learning for Medicine and\n  Healthcare, August 2018, London UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like most global cancer registries, the National Cancer Registry in South\nAfrica employs expert human coders to label pathology reports using appropriate\nInternational Classification of Disease for Oncology (ICD-O) codes spanning 42\ndifferent cancer types. The annotation is extensive for the large volume of\ncancer pathology reports the registry receives annually from public and private\nsector institutions. This manual process, coupled with other challenges results\nin a significant 4-year lag in reporting of annual cancer statistics in South\nAfrica. We present a hierarchical deep learning ensemble method incorporating\nstate of the art convolutional neural network models for the automatic\nlabelling of 2201 de-identified, free text pathology reports, with appropriate\nICD-O breast cancer topography codes across 8 classes. Our results show an\nimprovement in primary site classification over the state of the art CNN model\nby greater than 14% for F1 micro and 55% for F1 macro scores. We demonstrate\nthat the hierarchical deep learning ensemble improves on state-of-the-art\nmodels for ICD-O topography classification in comparison to a flat multiclass\nmodel for predicting ICD-O topography codes for pathology reports.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 10:29:56 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Saib", "Waheeda", ""], ["Sengeh", "David", ""], ["Dlamini", "Gcininwe", ""], ["Singh", "Elvira", ""]]}, {"id": "2008.12577", "submitter": "Marco Rudolph", "authors": "Marco Rudolph and Bastian Wandt and Bodo Rosenhahn", "title": "Same Same But DifferNet: Semi-Supervised Defect Detection with\n  Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of manufacturing errors is crucial in fabrication processes to\nensure product quality and safety standards. Since many defects occur very\nrarely and their characteristics are mostly unknown a priori, their detection\nis still an open research question. To this end, we propose DifferNet: It\nleverages the descriptiveness of features extracted by convolutional neural\nnetworks to estimate their density using normalizing flows. Normalizing flows\nare well-suited to deal with low dimensional data distributions. However, they\nstruggle with the high dimensionality of images. Therefore, we employ a\nmulti-scale feature extractor which enables the normalizing flow to assign\nmeaningful likelihoods to the images. Based on these likelihoods we develop a\nscoring function that indicates defects. Moreover, propagating the score back\nto the image enables pixel-wise localization. To achieve a high robustness and\nperformance we exploit multiple transformations in training and evaluation. In\ncontrast to most other methods, ours does not require a large number of\ntraining samples and performs well with as low as 16 images. We demonstrate the\nsuperior performance over existing approaches on the challenging and newly\nproposed MVTec AD and Magnetic Tile Defects datasets.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 10:49:28 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Rudolph", "Marco", ""], ["Wandt", "Bastian", ""], ["Rosenhahn", "Bodo", ""]]}, {"id": "2008.12578", "submitter": "Tien Huu Do", "authors": "Tien Huu Do, Duc Minh Nguyen, Giannis Bekoulis, Adrian Munteanu, Nikos\n  Deligiannis", "title": "Graph Convolutional Neural Networks with Node Transition\n  Probability-based Message Passing and DropNode Regularization", "comments": "Expert Systems with Applications, graph-based deep learning, graph\n  neural networks, document classification", "journal-ref": "Expert Systems with Applications, 174 (2021), Elsevier", "doi": "10.1016/j.eswa.2021.114711", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional neural networks (GCNNs) have received much attention\nrecently, owing to their capability in handling graph-structured data. Among\nthe existing GCNNs, many methods can be viewed as instances of a neural message\npassing motif; features of nodes are passed around their neighbors, aggregated\nand transformed to produce better nodes' representations. Nevertheless, these\nmethods seldom use node transition probabilities, a measure that has been found\nuseful in exploring graphs. Furthermore, when the transition probabilities are\nused, their transition direction is often improperly considered in the feature\naggregation step, resulting in an inefficient weighting scheme. In addition,\nalthough a great number of GCNN models with increasing level of complexity have\nbeen introduced, the GCNNs often suffer from over-fitting when being trained on\nsmall graphs. Another issue of the GCNNs is over-smoothing, which tends to make\nnodes' representations indistinguishable. This work presents a new method to\nimprove the message passing process based on node transition probabilities by\nproperly considering the transition direction, leading to a better weighting\nscheme in nodes' features aggregation compared to the existing counterpart.\nMoreover, we propose a novel regularization method termed DropNode to address\nthe over-fitting and over-smoothing issues simultaneously. DropNode randomly\ndiscards part of a graph, thus it creates multiple deformed versions of the\ngraph, leading to data augmentation regularization effect. Additionally,\nDropNode lessens the connectivity of the graph, mitigating the effect of\nover-smoothing in deep GCNNs. Extensive experiments on eight benchmark datasets\nfor node and graph classification tasks demonstrate the effectiveness of the\nproposed methods in comparison with the state of the art.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 10:51:03 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 13:48:49 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Do", "Tien Huu", ""], ["Nguyen", "Duc Minh", ""], ["Bekoulis", "Giannis", ""], ["Munteanu", "Adrian", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "2008.12589", "submitter": "Arian Balouchestani", "authors": "Saeed Khalilian, Yeganeh Hallaj, Arian Balouchestani, Hossein\n  Karshenas, Amir Mohammadi", "title": "PCB Defect Detection Using Denoising Convolutional Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Printed Circuit boards (PCBs) are one of the most important stages in making\nelectronic products. A small defect in PCBs can cause significant flaws in the\nfinal product. Hence, detecting all defects in PCBs and locating them is\nessential. In this paper, we propose an approach based on denoising\nconvolutional autoencoders for detecting defective PCBs and to locate the\ndefects. Denoising autoencoders take a corrupted image and try to recover the\nintact image. We trained our model with defective PCBs and forced it to repair\nthe defective parts. Our model not only detects all kinds of defects and\nlocates them, but it can also repair them as well. By subtracting the repaired\noutput from the input, the defective parts are located. The experimental\nresults indicate that our model detects the defective PCBs with high accuracy\n(97.5%) compare to state of the art works.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 11:38:09 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Khalilian", "Saeed", ""], ["Hallaj", "Yeganeh", ""], ["Balouchestani", "Arian", ""], ["Karshenas", "Hossein", ""], ["Mohammadi", "Amir", ""]]}, {"id": "2008.12595", "submitter": "Xavier Alameda-Pineda", "authors": "Laurent Girin and Simon Leglaive and Xiaoyu Bie and Julien Diard and\n  Thomas Hueber and Xavier Alameda-Pineda", "title": "Dynamical Variational Autoencoders: A Comprehensive Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Variational Autoencoder (VAE) is a powerful deep generative model that is\nnow extensively used to represent high-dimensional complex data via a\nlow-dimensional latent space learned in an unsupervised manner. In the original\nVAE model, input data vectors are processed independently. In recent years, a\nseries of papers have presented different extensions of the VAE to process\nsequential data, that not only model the latent space, but also model the\ntemporal dependencies within a sequence of data vectors and corresponding\nlatent vectors, relying on recurrent neural networks or state space models. In\nthis paper we perform an extensive literature review of these models.\nImportantly, we introduce and discuss a general class of models called\nDynamical Variational Autoencoders (DVAEs) that encompasses a large subset of\nthese temporal VAE extensions. Then we present in detail seven different\ninstances of DVAE that were recently proposed in the literature, with an effort\nto homogenize the notations and presentation lines, as well as to relate these\nmodels with existing classical temporal models. We reimplemented those seven\nDVAE models and we present the results of an experimental benchmark conducted\non the speech analysis-resynthesis task (the PyTorch code is made publicly\navailable). The paper is concluded with an extensive discussion on important\nissues concerning the DVAE class of models and future research guidelines.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 11:49:33 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 16:17:22 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Girin", "Laurent", ""], ["Leglaive", "Simon", ""], ["Bie", "Xiaoyu", ""], ["Diard", "Julien", ""], ["Hueber", "Thomas", ""], ["Alameda-Pineda", "Xavier", ""]]}, {"id": "2008.12603", "submitter": "Alzayat Saleh", "authors": "Alzayat Saleh, Issam H. Laradji, Dmitry A. Konovalov, Michael Bradley,\n  David Vazquez, and Marcus Sheaves", "title": "A Realistic Fish-Habitat Dataset to Evaluate Algorithms for Underwater\n  Visual Analysis", "comments": "10 pages, 5 figures, 3 tables, Accepted for Publication in Scientific\n  Reports (Nature) 14 August 2020", "journal-ref": null, "doi": "10.1038/s41598-020-71639-x", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual analysis of complex fish habitats is an important step towards\nsustainable fisheries for human consumption and environmental protection. Deep\nLearning methods have shown great promise for scene analysis when trained on\nlarge-scale datasets. However, current datasets for fish analysis tend to focus\non the classification task within constrained, plain environments which do not\ncapture the complexity of underwater fish habitats. To address this limitation,\nwe present DeepFish as a benchmark suite with a large-scale dataset to train\nand test methods for several computer vision tasks. The dataset consists of\napproximately 40 thousand images collected underwater from 20 \\green{habitats\nin the} marine-environments of tropical Australia. The dataset originally\ncontained only classification labels. Thus, we collected point-level and\nsegmentation labels to have a more comprehensive fish analysis benchmark. These\nlabels enable models to learn to automatically monitor fish count, identify\ntheir locations, and estimate their sizes. Our experiments provide an in-depth\nanalysis of the dataset characteristics, and the performance evaluation of\nseveral state-of-the-art approaches based on our benchmark. Although models\npre-trained on ImageNet have successfully performed on this benchmark, there is\nstill room for improvement. Therefore, this benchmark serves as a testbed to\nmotivate further development in this challenging domain of underwater computer\nvision. Code is available at: https://github.com/alzayats/DeepFish\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 12:20:59 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Saleh", "Alzayat", ""], ["Laradji", "Issam H.", ""], ["Konovalov", "Dmitry A.", ""], ["Bradley", "Michael", ""], ["Vazquez", "David", ""], ["Sheaves", "Marcus", ""]]}, {"id": "2008.12610", "submitter": "Jorge Pe\\~na Queralta", "authors": "Jorge Pe\\~na Queralta, Jussi Taipalmaa, Bilge Can Pullinen, Victor\n  Kathan Sarker, Tuan Nguyen Gia, Hannu Tenhunen, Moncef Gabbouj, Jenni\n  Raitoharju, Tomi Westerlund", "title": "Collaborative Multi-Robot Systems for Search and Rescue: Coordination\n  and Perception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous or teleoperated robots have been playing increasingly important\nroles in civil applications in recent years. Across the different civil domains\nwhere robots can support human operators, one of the areas where they can have\nmore impact is in search and rescue (SAR) operations. In particular,\nmulti-robot systems have the potential to significantly improve the efficiency\nof SAR personnel with faster search of victims, initial assessment and mapping\nof the environment, real-time monitoring and surveillance of SAR operations, or\nestablishing emergency communication networks, among other possibilities. SAR\noperations encompass a wide variety of environments and situations, and\ntherefore heterogeneous and collaborative multi-robot systems can provide the\nmost advantages. In this paper, we review and analyze the existing approaches\nto multi-robot SAR support, from an algorithmic perspective and putting an\nemphasis on the methods enabling collaboration among the robots as well as\nadvanced perception through machine vision and multi-agent active perception.\nFurthermore, we put these algorithms in the context of the different challenges\nand constraints that various types of robots (ground, aerial, surface or\nunderwater) encounter in different SAR environments (maritime, urban,\nwilderness or other post-disaster scenarios). This is, to the best of our\nknowledge, the first review considering heterogeneous SAR robots across\ndifferent environments, while giving two complimentary points of view: control\nmechanisms and machine perception. Based on our review of the state-of-the-art,\nwe discuss the main open research questions, and outline our insights on the\ncurrent approaches that have potential to improve the real-world performance of\nmulti-robot SAR systems.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 12:28:32 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Queralta", "Jorge Pe\u00f1a", ""], ["Taipalmaa", "Jussi", ""], ["Pullinen", "Bilge Can", ""], ["Sarker", "Victor Kathan", ""], ["Gia", "Tuan Nguyen", ""], ["Tenhunen", "Hannu", ""], ["Gabbouj", "Moncef", ""], ["Raitoharju", "Jenni", ""], ["Westerlund", "Tomi", ""]]}, {"id": "2008.12618", "submitter": "Dongjie Wang", "authors": "Dongjie Wang, Pengyang Wang, Jingbo Zhou, Leilei Sun, Bowen Du, Yanjie\n  Fu", "title": "Defending Water Treatment Networks: Exploiting Spatio-temporal Effects\n  for Cyber Attack Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Water Treatment Networks (WTNs) are critical infrastructures for local\ncommunities and public health, WTNs are vulnerable to cyber attacks. Effective\ndetection of attacks can defend WTNs against discharging contaminated water,\ndenying access, destroying equipment, and causing public fear. While there are\nextensive studies in WTNs attack detection, they only exploit the data\ncharacteristics partially to detect cyber attacks. After preliminary exploring\nthe sensing data of WTNs, we find that integrating spatio-temporal knowledge,\nrepresentation learning, and detection algorithms can improve attack detection\naccuracy. To this end, we propose a structured anomaly detection framework to\ndefend WTNs by modeling the spatio-temporal characteristics of cyber attacks in\nWTNs. In particular, we propose a spatio-temporal representation framework\nspecially tailored to cyber attacks after separating the sensing data of WTNs\ninto a sequence of time segments. This framework has two key components. The\nfirst component is a temporal embedding module to preserve temporal patterns\nwithin a time segment by projecting the time segment of a sensor into a\ntemporal embedding vector. We then construct Spatio-Temporal Graphs (STGs),\nwhere a node is a sensor and an attribute is the temporal embedding vector of\nthe sensor, to describe the state of the WTNs. The second component is a\nspatial embedding module, which learns the final fused embedding of the WTNs\nfrom STGs. In addition, we devise an improved one class-SVM model that utilizes\na new designed pairwise kernel to detect cyber attacks. The devised pairwise\nkernel augments the distance between normal and attack patterns in the fused\nembedding space. Finally, we conducted extensive experimental evaluations with\nreal-world data to demonstrate the effectiveness of our framework.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 15:56:55 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Wang", "Dongjie", ""], ["Wang", "Pengyang", ""], ["Zhou", "Jingbo", ""], ["Sun", "Leilei", ""], ["Du", "Bowen", ""], ["Fu", "Yanjie", ""]]}, {"id": "2008.12623", "submitter": "Smitha Milli", "authors": "Smitha Milli, Luca Belli, Moritz Hardt", "title": "From Optimizing Engagement to Measuring Value", "comments": "Published at FAccT'21", "journal-ref": null, "doi": "10.1145/3442188.3445933", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most recommendation engines today are based on predicting user engagement,\ne.g. predicting whether a user will click on an item or not. However, there is\npotentially a large gap between engagement signals and a desired notion of\n\"value\" that is worth optimizing for. We use the framework of measurement\ntheory to (a) confront the designer with a normative question about what the\ndesigner values, (b) provide a general latent variable model approach that can\nbe used to operationalize the target construct and directly optimize for it,\nand (c) guide the designer in evaluating and revising their operationalization.\nWe implement our approach on the Twitter platform on millions of users. In line\nwith established approaches to assessing the validity of measurements, we\nperform a qualitative evaluation of how well our model captures a desired\nnotion of \"value\".\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 03:10:45 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 16:32:49 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Milli", "Smitha", ""], ["Belli", "Luca", ""], ["Hardt", "Moritz", ""]]}, {"id": "2008.12624", "submitter": "Pedro Braga", "authors": "Hansenclever F. Bassani, Renie A. Delgado, Jos\\'e Nilton de O. Lima\n  Junior, Heitor R. Medeiros, Pedro H. M. Braga, Mateus G. Machado, Lucas H. C.\n  Santos and Alain Tapp", "title": "A Framework for Studying Reinforcement Learning and Sim-to-Real in Robot\n  Soccer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This article introduces an open framework, called VSSS-RL, for studying\nReinforcement Learning (RL) and sim-to-real in robot soccer, focusing on the\nIEEE Very Small Size Soccer (VSSS) league. We propose a simulated environment\nin which continuous or discrete control policies can be trained to control the\ncomplete behavior of soccer agents and a sim-to-real method based on domain\nadaptation to adapt the obtained policies to real robots. Our results show that\nthe trained policies learned a broad repertoire of behaviors that are difficult\nto implement with handcrafted control policies. With VSSS-RL, we were able to\nbeat human-designed policies in the 2019 Latin American Robotics Competition\n(LARC), achieving 4th place out of 21 teams, being the first to apply\nReinforcement Learning (RL) successfully in this competition. Both environment\nand hardware specifications are available open-source to allow reproducibility\nof our results and further studies.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 23:52:32 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Bassani", "Hansenclever F.", ""], ["Delgado", "Renie A.", ""], ["Junior", "Jos\u00e9 Nilton de O. Lima", ""], ["Medeiros", "Heitor R.", ""], ["Braga", "Pedro H. M.", ""], ["Machado", "Mateus G.", ""], ["Santos", "Lucas H. C.", ""], ["Tapp", "Alain", ""]]}, {"id": "2008.12625", "submitter": "Berent {\\AA}nund Str{\\o}mnes Lunde", "authors": "Berent {\\AA}nund Str{\\o}mnes Lunde, Tore Selland Kleppe", "title": "agtboost: Adaptive and Automatic Gradient Tree Boosting Computations", "comments": "16 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  agtboost is an R package implementing fast gradient tree boosting\ncomputations in a manner similar to other established frameworks such as\nxgboost and LightGBM, but with significant decreases in computation time and\nrequired mathematical and technical knowledge. The package automatically takes\ncare of split/no-split decisions and selects the number of trees in the\ngradient tree boosting ensemble, i.e., agtboost adapts the complexity of the\nensemble automatically to the information in the data. All of this is done\nduring a single training run, which is made possible by utilizing developments\nin information theory for tree algorithms {\\tt arXiv:2008.05926v1 [stat.ME]}.\nagtboost also comes with a feature importance function that eliminates the\ncommon practice of inserting noise features. Further, a useful model validation\nfunction performs the Kolmogorov-Smirnov test on the learned distribution.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 12:42:19 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Lunde", "Berent \u00c5nund Str\u00f8mnes", ""], ["Kleppe", "Tore Selland", ""]]}, {"id": "2008.12629", "submitter": "Umberto Michelucci", "authors": "Umberto Michelucci, Michael Baumgartner, Francesca Venturini", "title": "Optical oxygen sensing with artificial intelligence", "comments": "15 pages", "journal-ref": null, "doi": "10.3390/s19040777", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Luminescence-based sensors for measuring oxygen concentration are widely used\nboth in industry and research due to the practical advantages and sensitivity\nof this type of sensing. The measuring principle is the luminescence quenching\nby oxygen molecules, which results in a change of the luminescence decay time\nand intensity. In the classical approach, this change is related to an oxygen\nconcentration using the Stern-Volmer equation. This equation, which in most of\nthe cases is non-linear, is parametrized through device-specific constants.\nTherefore, to determine these parameters every sensor needs to be precisely\ncalibrated at one or more known concentrations. This work explores an entirely\nnew artificial intelligence approach and demonstrates the feasibility of oxygen\nsensing through machine learning. The specifically developed neural network\nlearns very efficiently to relate the input quantities to the oxygen\nconcentration. The results show a mean deviation of the predicted from the\nmeasured concentration of 0.5 percent air, comparable to many commercial and\nlow-cost sensors. Since the network was trained using synthetically generated\ndata, the accuracy of the model predictions is limited by the ability of the\ngenerated data to describe the measured data, opening up future possibilities\nfor significant improvement by using a large number of experimental\nmeasurements for training. The approach described in this work demonstrates the\napplicability of artificial intelligence to sensing of sensors.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 20:59:38 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Michelucci", "Umberto", ""], ["Baumgartner", "Michael", ""], ["Venturini", "Francesca", ""]]}, {"id": "2008.12642", "submitter": "Maan Qraitem", "authors": "Maan Qraitem, Dhanushka Kularatne, Eric Forgoston, M. Ani Hsieh", "title": "Bridging the Gap: Machine Learning to Resolve Improperly Modeled\n  Dynamics", "comments": null, "journal-ref": null, "doi": "10.1016/j.physd.2020.132736", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a data-driven modeling strategy to overcome improperly modeled\ndynamics for systems exhibiting complex spatio-temporal behaviors. We propose a\nDeep Learning framework to resolve the differences between the true dynamics of\nthe system and the dynamics given by a model of the system that is either\ninaccurately or inadequately described. Our machine learning strategy leverages\ndata generated from the improper system model and observational data from the\nactual system to create a neural network to model the dynamics of the actual\nsystem. We evaluate the proposed framework using numerical solutions obtained\nfrom three increasingly complex dynamical systems. Our results show that our\nsystem is capable of learning a data-driven model that provides accurate\nestimates of the system states both in previously unobserved regions as well as\nfor future states. Our results show the power of state-of-the-art machine\nlearning frameworks in estimating an accurate prior of the system's true\ndynamics that can be used for prediction up to a finite horizon.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 04:57:02 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Qraitem", "Maan", ""], ["Kularatne", "Dhanushka", ""], ["Forgoston", "Eric", ""], ["Hsieh", "M. Ani", ""]]}, {"id": "2008.12646", "submitter": "Yun Peng", "authors": "Yun Peng, Byron Choi, Jianliang Xu", "title": "Graph Learning for Combinatorial Optimization: A Survey of\n  State-of-the-Art", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs have been widely used to represent complex data in many applications.\nEfficient and effective analysis of graphs is important for graph-based\napplications. However, most graph analysis tasks are combinatorial optimization\n(CO) problems, which are NP-hard. Recent studies have focused a lot on the\npotential of using machine learning (ML) to solve graph-based CO problems. Most\nrecent methods follow the two-stage framework. The first stage is graph\nrepresentation learning, which embeds the graphs into low-dimension vectors.\nThe second stage uses ML to solve the CO problems using the embeddings of the\ngraphs learned in the first stage. The works for the first stage can be\nclassified into two categories, graph embedding (GE) methods and end-to-end\n(E2E) learning methods. For GE methods, learning graph embedding has its own\nobjective, which may not rely on the CO problems to be solved. The CO problems\nare solved by independent downstream tasks. For E2E learning methods, the\nlearning of graph embeddings does not have its own objective and is an\nintermediate step of the learning procedure of solving the CO problems. The\nworks for the second stage can also be classified into two categories,\nnon-autoregressive methods and autoregressive methods. Non-autoregressive\nmethods predict a solution for a CO problem in one shot. A non-autoregressive\nmethod predicts a matrix that denotes the probability of each node/edge being a\npart of a solution of the CO problem. The solution can be computed from the\nmatrix. Autoregressive methods iteratively extend a partial solution step by\nstep. At each step, an autoregressive method predicts a node/edge conditioned\nto current partial solution, which is used to its extension. In this survey, we\nprovide a thorough overview of recent studies of the graph learning-based CO\nmethods. The survey ends with several remarks on future research directions.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 09:56:30 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 08:47:03 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 02:07:09 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Peng", "Yun", ""], ["Choi", "Byron", ""], ["Xu", "Jianliang", ""]]}, {"id": "2008.12647", "submitter": "Yiren Lu", "authors": "Yiren Lu, Jonathan Tompson", "title": "ADAIL: Adaptive Adversarial Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the ADaptive Adversarial Imitation Learning (ADAIL) algorithm for\nlearning adaptive policies that can be transferred between environments of\nvarying dynamics, by imitating a small number of demonstrations collected from\na single source domain. This is an important problem in robotic learning\nbecause in real world scenarios 1) reward functions are hard to obtain, 2)\nlearned policies from one domain are difficult to deploy in another due to\nvarying source to target domain statistics, 3) collecting expert demonstrations\nin multiple environments where the dynamics are known and controlled is often\ninfeasible. We address these constraints by building upon recent advances in\nadversarial imitation learning; we condition our policy on a learned dynamics\nembedding and we employ a domain-adversarial loss to learn a dynamics-invariant\ndiscriminator. The effectiveness of our method is demonstrated on simulated\ncontrol tasks with varying environment dynamics and the learned adaptive agent\noutperforms several recent baselines.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 06:11:00 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Lu", "Yiren", ""], ["Tompson", "Jonathan", ""]]}, {"id": "2008.12649", "submitter": "Youssef Mroueh", "authors": "Rapha\\\"el Pestourie, Youssef Mroueh, Thanh V. Nguyen, Payel Das,\n  Steven G. Johnson", "title": "Active learning of deep surrogates for PDEs: Application to metasurface\n  design", "comments": "submitted to npj", "journal-ref": "npj Computational Materials (2020)6:164", "doi": "10.1038/s41524-020-00431-2", "report-no": null, "categories": "cs.LG physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surrogate models for partial-differential equations are widely used in the\ndesign of meta-materials to rapidly evaluate the behavior of composable\ncomponents. However, the training cost of accurate surrogates by machine\nlearning can rapidly increase with the number of variables. For photonic-device\nmodels, we find that this training becomes especially challenging as design\nregions grow larger than the optical wavelength. We present an active learning\nalgorithm that reduces the number of training points by more than an order of\nmagnitude for a neural-network surrogate model of optical-surface components\ncompared to random samples. Results show that the surrogate evaluation is over\ntwo orders of magnitude faster than a direct solve, and we demonstrate how this\ncan be exploited to accelerate large-scale engineering optimization.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 17:14:13 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Pestourie", "Rapha\u00ebl", ""], ["Mroueh", "Youssef", ""], ["Nguyen", "Thanh V.", ""], ["Das", "Payel", ""], ["Johnson", "Steven G.", ""]]}, {"id": "2008.12650", "submitter": "Peter Meer", "authors": "Peter Meer", "title": "Are Deep Neural Networks \"Robust\"?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separating outliers from inliers is the definition of robustness in computer\nvision. This essay delineates how deep neural networks are different than\ntypical robust estimators. Deep neural networks not robust by this traditional\ndefinition.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 16:57:19 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Meer", "Peter", ""]]}, {"id": "2008.12679", "submitter": "Weidong Yin", "authors": "Weidong Yin, Ziwei Liu, Leonid Sigal", "title": "Person-in-Context Synthesiswith Compositional Structural Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant progress, controlled generation of complex images with\ninteracting people remains difficult. Existing layout generation methods fall\nshort of synthesizing realistic person instances; while pose-guided generation\napproaches focus on a single person and assume simple or known backgrounds. To\ntackle these limitations, we propose a new problem, \\textbf{Persons in Context\nSynthesis}, which aims to synthesize diverse person instance(s) in consistent\ncontexts, with user control over both. The context is specified by the bounding\nbox object layout which lacks shape information, while pose of the person(s) by\nkeypoints which are sparsely annotated. To handle the stark difference in input\nstructures, we proposed two separate neural branches to attentively composite\nthe respective (context/person) inputs into shared ``compositional structural\nspace'', which encodes shape, location and appearance information for both\ncontext and person structures in a disentangled manner. This structural space\nis then decoded to the image space using multi-level feature modulation\nstrategy, and learned in a self supervised manner from image collections and\ntheir corresponding inputs. Extensive experiments on two large-scale datasets\n(COCO-Stuff \\cite{caesar2018cvpr} and Visual Genome \\cite{krishna2017visual})\ndemonstrate that our framework outperforms state-of-the-art methods w.r.t.\nsynthesis quality.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 14:33:28 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Yin", "Weidong", ""], ["Liu", "Ziwei", ""], ["Sigal", "Leonid", ""]]}, {"id": "2008.12680", "submitter": "Jyotirmay Senapati", "authors": "J. Senapati, A. Guha Roy, S. P\\\"olsterl, D. Gutmann, S. Gatidis, C.\n  Schlett, A. Peters, F. Bamberg, C. Wachinger", "title": "Bayesian Neural Networks for Uncertainty Estimation of Imaging\n  Biomarkers", "comments": "MICCAI-MLMI 2020 Workshop Paper (Accepted)", "journal-ref": null, "doi": "10.1007/978-3-030-59861-7_28", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image segmentation enables to extract quantitative measures from scans that\ncan serve as imaging biomarkers for diseases. However, segmentation quality can\nvary substantially across scans, and therefore yield unfaithful estimates in\nthe follow-up statistical analysis of biomarkers. The core problem is that\nsegmentation and biomarker analysis are performed independently. We propose to\npropagate segmentation uncertainty to the statistical analysis to account for\nvariations in segmentation confidence. To this end, we evaluate four Bayesian\nneural networks to sample from the posterior distribution and estimate the\nuncertainty. We then assign confidence measures to the biomarker and propose\nstatistical models for its integration in group analysis and disease\nclassification. Our results for segmenting the liver in patients with diabetes\nmellitus clearly demonstrate the improvement of integrating biomarker\nuncertainty in the statistical inference.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 14:34:12 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 23:22:54 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Senapati", "J.", ""], ["Roy", "A. Guha", ""], ["P\u00f6lsterl", "S.", ""], ["Gutmann", "D.", ""], ["Gatidis", "S.", ""], ["Schlett", "C.", ""], ["Peters", "A.", ""], ["Bamberg", "F.", ""], ["Wachinger", "C.", ""]]}, {"id": "2008.12683", "submitter": "Mohammad Ali Moni", "authors": "Sakifa Aktar, Ashis Talukder, Md. Martuza Ahamad, A. H. M. Kamal,\n  Jahidur Rahman Khan, Md. Protikuzzaman, Nasif Hossain, Julian M.W. Quinn,\n  Mathew A. Summers, Teng Liaw, Valsamma Eapen, Mohammad Ali Moni", "title": "Machine Learning and Meta-Analysis Approach to Identify Patient\n  Comorbidities and Symptoms that Increased Risk of Mortality in COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background: Providing appropriate care for people suffering from COVID-19,\nthe disease caused by the pandemic SARS-CoV-2 virus is a significant global\nchallenge. Many individuals who become infected have pre-existing conditions\nthat may interact with COVID-19 to increase symptom severity and mortality\nrisk. COVID-19 patient comorbidities are likely to be informative about\nindividual risk of severe illness and mortality. Accurately determining how\ncomorbidities are associated with severe symptoms and mortality would thus\ngreatly assist in COVID-19 care planning and provision.\n  Methods: To assess the interaction of patient comorbidities with COVID-19\nseverity and mortality we performed a meta-analysis of the published global\nliterature, and machine learning predictive analysis using an aggregated\nCOVID-19 global dataset.\n  Results: Our meta-analysis identified chronic obstructive pulmonary disease\n(COPD), cerebrovascular disease (CEVD), cardiovascular disease (CVD), type 2\ndiabetes, malignancy, and hypertension as most significantly associated with\nCOVID-19 severity in the current published literature. Machine learning\nclassification using novel aggregated cohort data similarly found COPD, CVD,\nCKD, type 2 diabetes, malignancy and hypertension, as well as asthma, as the\nmost significant features for classifying those deceased versus those who\nsurvived COVID-19. While age and gender were the most significant predictor of\nmortality, in terms of symptom-comorbidity combinations, it was observed that\nPneumonia-Hypertension, Pneumonia-Diabetes and Acute Respiratory Distress\nSyndrome (ARDS)-Hypertension showed the most significant effects on COVID-19\nmortality.\n  Conclusions: These results highlight patient cohorts most at risk of COVID-19\nrelated severe morbidity and mortality which have implications for\nprioritization of hospital resources.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 12:31:54 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Aktar", "Sakifa", ""], ["Talukder", "Ashis", ""], ["Ahamad", "Md. Martuza", ""], ["Kamal", "A. H. M.", ""], ["Khan", "Jahidur Rahman", ""], ["Protikuzzaman", "Md.", ""], ["Hossain", "Nasif", ""], ["Quinn", "Julian M. W.", ""], ["Summers", "Mathew A.", ""], ["Liaw", "Teng", ""], ["Eapen", "Valsamma", ""], ["Moni", "Mohammad Ali", ""]]}, {"id": "2008.12686", "submitter": "Yang Chen Dr.", "authors": "Yang Chen, Nami Ashizawa, Seanglidet Yean, Chai Kiat Yeo, Naoto Yanai", "title": "Self-Organizing Map assisted Deep Autoencoding Gaussian Mixture Model\n  for Intrusion Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the information age, a secure and stable network environment is essential\nand hence intrusion detection is critical for any networks. In this paper, we\npropose a self-organizing map assisted deep autoencoding Gaussian mixture model\n(SOMDAGMM) supplemented with well-preserved input space topology for more\naccurate network intrusion detection. The deep autoencoding Gaussian mixture\nmodel comprises a compression network and an estimation network which is able\nto perform unsupervised joint training. However, the code generated by the\nautoencoder is inept at preserving the topology of the input space, which is\nrooted in the bottleneck of the adopted deep structure. A self-organizing map\nhas been introduced to construct SOMDAGMM for addressing this issue. The\nsuperiority of the proposed SOM-DAGMM is empirically demonstrated with\nextensive experiments conducted upon two datasets. Experimental results show\nthat SOM-DAGMM outperforms state-of-the-art DAGMM on all tests, and achieves up\nto 15.58% improvement in F1 score and with better stability.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 14:41:18 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Chen", "Yang", ""], ["Ashizawa", "Nami", ""], ["Yean", "Seanglidet", ""], ["Yeo", "Chai Kiat", ""], ["Yanai", "Naoto", ""]]}, {"id": "2008.12690", "submitter": "Junchi Li", "authors": "Chris Junchi Li, Wenlong Mou, Martin J. Wainwright, Michael I. Jordan", "title": "ROOT-SGD: Sharp Nonasymptotics and Asymptotic Efficiency in a Single\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory and practice of stochastic optimization has focused on stochastic\ngradient descent (SGD) in recent years, retaining the basic first-order\nstochastic nature of SGD while aiming to improve it via mechanisms such as\naveraging, momentum, and variance reduction. Improvement can be measured along\nvarious dimensions, however, and it has proved difficult to achieve\nimprovements both in terms of nonasymptotic measures of convergence rate and\nasymptotic measures of distributional tightness. In this work, we consider\nfirst-order stochastic optimization from a general statistical point of view,\nmotivating a specific form of recursive averaging of past stochastic gradients.\nThe resulting algorithm, which we refer to as \\emph{Recursive One-Over-T SGD}\n(ROOT-SGD), matches the state-of-the-art convergence rate among online\nvariance-reduced stochastic approximation methods. Moreover, under slightly\nstronger distributional assumptions, the rescaled last-iterate of ROOT-SGD\nconverges to a zero-mean Gaussian distribution that achieves near-optimal\ncovariance.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 14:46:56 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Li", "Chris Junchi", ""], ["Mou", "Wenlong", ""], ["Wainwright", "Martin J.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2008.12691", "submitter": "Melih Yesilli", "authors": "Melih C. Yesilli, Firas A. Khasawneh", "title": "On Transfer Learning of Traditional Frequency and Time Domain Features\n  in Turning", "comments": null, "journal-ref": null, "doi": "10.1115/MSEC2020-8274", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an increasing interest in leveraging machine learning tools\nfor chatter prediction and diagnosis in discrete manufacturing processes. Some\nof the most common features for studying chatter include traditional signal\nprocessing tools such as Fast Fourier Transform (FFT), Power Spectral Density\n(PSD), and the Auto-correlation Function (ACF). In this study, we use these\ntools in a supervised learning setting to identify chatter in accelerometer\nsignals obtained from a turning experiment. The experiment is performed using\nfour different tool overhang lengths with varying cutting speed and the depth\nof cut. We then examine the resulting signals and tag them as either chatter or\nchatter-free. The tagged signals are then used to train a classifier. The\nclassification methods include the most common algorithms: Support Vector\nMachine (SVM), Logistic Regression (LR), Random Forest (RF), and Gradient Boost\n(GB). Our results show that features extracted from the Fourier spectrum are\nthe most informative when training a classifier and testing on data from the\nsame cutting configuration yielding accuracy as high as %96. However, the\naccuracy drops significantly when training and testing on two different\nconfigurations with different structural eigenfrequencies. Thus, we conclude\nthat while these traditional features can be highly tuned to a certain process,\ntheir transfer learning ability is limited. We also compare our results against\ntwo other methods with rising popularity in the literature: Wavelet Packet\nTransform (WPT) and Ensemble Empirical Mode Decomposition (EEMD). The latter\ntwo methods, especially EEMD, show better transfer learning capabilities for\nour dataset.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 14:47:57 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Yesilli", "Melih C.", ""], ["Khasawneh", "Firas A.", ""]]}, {"id": "2008.12693", "submitter": "Trevor McInroe", "authors": "Trevor A. McInroe", "title": "Sample Efficiency in Sparse Reinforcement Learning: Or Your Money Back", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sparse rewards present a difficult problem in reinforcement learning and may\nbe inevitable in certain domains with complex dynamics such as real-world\nrobotics. Hindsight Experience Replay (HER) is a recent replay memory\ndevelopment that allows agents to learn in sparse settings by altering memories\nto show them as successful even though they may not be. While, empirically, HER\nhas shown some success, it does not provide guarantees around the makeup of\nsamples drawn from an agent's replay memory. This may result in minibatches\nthat contain only memories with zero-valued rewards or agents learning an\nundesirable policy that completes HER-adjusted goals instead of the actual\ngoal.\n  In this paper, we introduce Or Your Money Back (OYMB), a replay memory\nsampler designed to work with HER. OYMB improves training efficiency in sparse\nsettings by providing a direct interface to the agent's replay memory that\nallows for control over minibatch makeup, as well as a preferential lookup\nscheme that prioritizes real-goal memories before HER-adjusted memories. We\ntest our approach on five tasks across three unique environments. Our results\nshow that using HER in combination with OYMB outperforms using HER alone and\nleads to agents that learn to complete the real goal more quickly.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 14:48:48 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["McInroe", "Trevor A.", ""]]}, {"id": "2008.12702", "submitter": "Andrey Sarychev", "authors": "Andrei Agrachev, Andrey Sarychev", "title": "Control on the Manifolds of Mappings with a View to the Deep Learning", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning of the Artificial Neural Networks (ANN) can be treated as a\nparticular class of interpolation problems. The goal is to find a neural\nnetwork whose input-output map approximates well the desired map on a finite or\nan infinite training set. Our idea consists of taking as an approximant the\ninput-output map, which arises from a nonlinear continuous-time control system.\nIn the limit such control system can be seen as a network with a continuum of\nlayers, each one labelled by the time variable. The values of the controls at\neach instant of time are the parameters of the layer.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 15:21:19 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 12:54:08 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Agrachev", "Andrei", ""], ["Sarychev", "Andrey", ""]]}, {"id": "2008.12735", "submitter": "Donald Honeycutt", "authors": "Donald R. Honeycutt, Mahsan Nourani, Eric D. Ragan", "title": "Soliciting Human-in-the-Loop User Feedback for Interactive Machine\n  Learning Reduces User Trust and Impressions of Model Accuracy", "comments": "Accepted and to appear in the Proceedings of the AAAI Conference on\n  Human Computation and Crowdsourcing (HCOMP) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed-initiative systems allow users to interactively provide feedback to\npotentially improve system performance. Human feedback can correct model errors\nand update model parameters to dynamically adapt to changing data.\nAdditionally, many users desire the ability to have a greater level of control\nand fix perceived flaws in systems they rely on. However, how the ability to\nprovide feedback to autonomous systems influences user trust is a largely\nunexplored area of research. Our research investigates how the act of providing\nfeedback can affect user understanding of an intelligent system and its\naccuracy. We present a controlled experiment using a simulated object detection\nsystem with image data to study the effects of interactive feedback collection\non user impressions. The results show that providing human-in-the-loop feedback\nlowered both participants' trust in the system and their perception of system\naccuracy, regardless of whether the system accuracy improved in response to\ntheir feedback. These results highlight the importance of considering the\neffects of allowing end-user feedback on user trust when designing intelligent\nsystems.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 16:46:41 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Honeycutt", "Donald R.", ""], ["Nourani", "Mahsan", ""], ["Ragan", "Eric D.", ""]]}, {"id": "2008.12736", "submitter": "Shalini Pandey", "authors": "Shalini Pandey, Jaideep Srivastava", "title": "RKT : Relation-Aware Self-Attention for Knowledge Tracing", "comments": null, "journal-ref": null, "doi": "10.1145/3340531.3411994", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world has transitioned into a new phase of online learning in response to\nthe recent Covid19 pandemic. Now more than ever, it has become paramount to\npush the limits of online learning in every manner to keep flourishing the\neducation system. One crucial component of online learning is Knowledge Tracing\n(KT). The aim of KT is to model student's knowledge level based on their\nanswers to a sequence of exercises referred as interactions. Students acquire\ntheir skills while solving exercises and each such interaction has a distinct\nimpact on student ability to solve a future exercise. This \\textit{impact} is\ncharacterized by 1) the relation between exercises involved in the interactions\nand 2) student forget behavior. Traditional studies on knowledge tracing do not\nexplicitly model both the components jointly to estimate the impact of these\ninteractions. In this paper, we propose a novel Relation-aware self-attention\nmodel for Knowledge Tracing (RKT). We introduce a relation-aware self-attention\nlayer that incorporates the contextual information. This contextual information\nintegrates both the exercise relation information through their textual content\nas well as student performance data and the forget behavior information through\nmodeling an exponentially decaying kernel function. Extensive experiments on\nthree real-world datasets, among which two new collections are released to the\npublic, show that our model outperforms state-of-the-art knowledge tracing\nmethods. Furthermore, the interpretable attention weights help visualize the\nrelation between interactions and temporal patterns in the human learning\nprocess.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 16:47:03 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Pandey", "Shalini", ""], ["Srivastava", "Jaideep", ""]]}, {"id": "2008.12750", "submitter": "Dimitris Perdios", "authors": "Dimitris Perdios, Manuel Vonlanthen, Florian Martinez, Marcel Arditi,\n  Jean-Philippe Thiran", "title": "CNN-Based Image Reconstruction Method for Ultrafast Ultrasound Imaging", "comments": "Main: 15 pages (6 figures). Supplement: 9 pages (10 figures). Video\n  provided as ancillary file. This work has been submitted to the IEEE\n  Transactions on Ultrasonics, Ferroelectrics, and Frequency Control for\n  possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrafast ultrasound (US) revolutionized biomedical imaging with its\ncapability of acquiring full-view frames at over 1 kHz, unlocking breakthrough\nmodalities such as shear-wave elastography and functional US neuroimaging. Yet,\nit suffers from strong diffraction artifacts, mainly caused by grating lobes,\nside lobes, or edge waves. Multiple acquisitions are typically required to\nobtain a sufficient image quality, at the cost of a reduced frame rate. To\nanswer the increasing demand for high-quality imaging from single-shot\nacquisitions, we propose a two-step convolutional neural network (CNN)-based\nimage reconstruction method, compatible with real-time imaging. A low-quality\nestimate is obtained by means of a backprojection-based operation, akin to\nconventional delay-and-sum beamforming, from which a high-quality image is\nrestored using a residual CNN with multi-scale and multi-channel filtering\nproperties, trained specifically to remove the diffraction artifacts inherent\nto ultrafast US imaging. To account for both the high dynamic range and the\nradio frequency property of US images, we introduce the mean signed logarithmic\nabsolute error (MSLAE) as training loss function. Experiments were conducted\nwith a linear transducer array, in single plane wave (PW) imaging. Trainings\nwere performed on a simulated dataset, crafted to contain a wide diversity of\nstructures and echogenicities. Extensive numerical evaluations demonstrate that\nthe proposed approach can reconstruct images from single PWs with a quality\nsimilar to that of gold-standard synthetic aperture imaging, on a dynamic range\nin excess of 60 dB. In vitro and in vivo experiments show that trainings\nperformed on simulated data translate well to experimental settings.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 17:15:37 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Perdios", "Dimitris", ""], ["Vonlanthen", "Manuel", ""], ["Martinez", "Florian", ""], ["Arditi", "Marcel", ""], ["Thiran", "Jean-Philippe", ""]]}, {"id": "2008.12760", "submitter": "Roozbeh Mottaghi", "authors": "Luca Weihs, Jordi Salvador, Klemen Kotar, Unnat Jain, Kuo-Hao Zeng,\n  Roozbeh Mottaghi, Aniruddha Kembhavi", "title": "AllenAct: A Framework for Embodied AI Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The domain of Embodied AI, in which agents learn to complete tasks through\ninteraction with their environment from egocentric observations, has\nexperienced substantial growth with the advent of deep reinforcement learning\nand increased interest from the computer vision, NLP, and robotics communities.\nThis growth has been facilitated by the creation of a large number of simulated\nenvironments (such as AI2-THOR, Habitat and CARLA), tasks (like point\nnavigation, instruction following, and embodied question answering), and\nassociated leaderboards. While this diversity has been beneficial and organic,\nit has also fragmented the community: a huge amount of effort is required to do\nsomething as simple as taking a model trained in one environment and testing it\nin another. This discourages good science. We introduce AllenAct, a modular and\nflexible learning framework designed with a focus on the unique requirements of\nEmbodied AI research. AllenAct provides first-class support for a growing\ncollection of embodied environments, tasks and algorithms, provides\nreproductions of state-of-the-art models and includes extensive documentation,\ntutorials, start-up code, and pre-trained models. We hope that our framework\nmakes Embodied AI more accessible and encourages new researchers to join this\nexciting area. The framework can be accessed at: https://allenact.org/\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 17:35:22 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Weihs", "Luca", ""], ["Salvador", "Jordi", ""], ["Kotar", "Klemen", ""], ["Jain", "Unnat", ""], ["Zeng", "Kuo-Hao", ""], ["Mottaghi", "Roozbeh", ""], ["Kembhavi", "Aniruddha", ""]]}, {"id": "2008.12763", "submitter": "Ju Fan", "authors": "Ju Fan, Tongyu Liu, Guoliang Li, Junyou Chen, Yuwei Shen, Xiaoyong Du", "title": "Relational Data Synthesis using Generative Adversarial Networks: A\n  Design Space Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of big data has brought an urgent demand for\nprivacy-preserving data publishing. Traditional solutions to this demand have\nlimitations on effectively balancing the tradeoff between privacy and utility\nof the released data. Thus, the database community and machine learning\ncommunity have recently studied a new problem of relational data synthesis\nusing generative adversarial networks (GAN) and proposed various algorithms.\nHowever, these algorithms are not compared under the same framework and thus it\nis hard for practitioners to understand GAN's benefits and limitations. To\nbridge the gaps, we conduct so far the most comprehensive experimental study\nthat investigates applying GAN to relational data synthesis. We introduce a\nunified GAN-based framework and define a space of design solutions for each\ncomponent in the framework, including neural network architectures and training\nstrategies. We conduct extensive experiments to explore the design space and\ncompare with traditional data synthesis approaches. Through extensive\nexperiments, we find that GAN is very promising for relational data synthesis,\nand provide guidance for selecting appropriate design solutions. We also point\nout limitations of GAN and identify future research directions.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 17:41:11 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Fan", "Ju", ""], ["Liu", "Tongyu", ""], ["Li", "Guoliang", ""], ["Chen", "Junyou", ""], ["Shen", "Yuwei", ""], ["Du", "Xiaoyong", ""]]}, {"id": "2008.12767", "submitter": "Bashir Mohammed", "authors": "Tanwi Mallick, Mariam Kiran, Bashir Mohammed, Prasanna Balaprakash", "title": "Dynamic Graph Neural Network for Traffic Forecasting in Wide Area\n  Networks", "comments": "10 Pages, 11 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wide area networking infrastructures (WANs), particularly science and\nresearch WANs, are the backbone for moving large volumes of scientific data\nbetween experimental facilities and data centers. With demands growing at\nexponential rates, these networks are struggling to cope with large data\nvolumes, real-time responses, and overall network performance. Network\noperators are increasingly looking for innovative ways to manage the limited\nunderlying network resources. Forecasting network traffic is a critical\ncapability for proactive resource management, congestion mitigation, and\ndedicated transfer provisioning. To this end, we propose a nonautoregressive\ngraph-based neural network for multistep network traffic forecasting.\nSpecifically, we develop a dynamic variant of diffusion convolutional recurrent\nneural networks to forecast traffic in research WANs. We evaluate the efficacy\nof our approach on real traffic from ESnet, the U.S. Department of Energy's\ndedicated science network. Our results show that compared to classical\nforecasting methods, our approach explicitly learns the dynamic nature of\nspatiotemporal traffic patterns, showing significant improvements in\nforecasting accuracy. Our technique can surpass existing statistical and deep\nlearning approaches by achieving approximately 20% mean absolute percentage\nerror for multiple hours of forecasts despite dynamic network traffic settings.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 17:47:11 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Mallick", "Tanwi", ""], ["Kiran", "Mariam", ""], ["Mohammed", "Bashir", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "2008.12775", "submitter": "Brandon Amos", "authors": "Brandon Amos, Samuel Stanton, Denis Yarats, Andrew Gordon Wilson", "title": "On the model-based stochastic value gradient for continuous\n  reinforcement learning", "comments": "L4DC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For over a decade, model-based reinforcement learning has been seen as a way\nto leverage control-based domain knowledge to improve the sample-efficiency of\nreinforcement learning agents. While model-based agents are conceptually\nappealing, their policies tend to lag behind those of model-free agents in\nterms of final reward, especially in non-trivial environments. In response,\nresearchers have proposed model-based agents with increasingly complex\ncomponents, from ensembles of probabilistic dynamics models, to heuristics for\nmitigating model error. In a reversal of this trend, we show that simple\nmodel-based agents can be derived from existing ideas that not only match, but\noutperform state-of-the-art model-free agents in terms of both\nsample-efficiency and final reward. We find that a model-free soft value\nestimate for policy evaluation and a model-based stochastic value gradient for\npolicy improvement is an effective combination, achieving state-of-the-art\nresults on a high-dimensional humanoid control task, which most model-based\nagents are unable to solve. Our findings suggest that model-based policy\nevaluation deserves closer attention.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 17:58:29 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 17:28:25 GMT"}, {"version": "v3", "created": "Thu, 27 May 2021 17:59:15 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Amos", "Brandon", ""], ["Stanton", "Samuel", ""], ["Yarats", "Denis", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "2008.12776", "submitter": "Yujia Jin", "authors": "Yujia Jin and Aaron Sidford", "title": "Efficiently Solving MDPs with Stochastic Mirror Descent", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified framework based on primal-dual stochastic mirror descent\nfor approximately solving infinite-horizon Markov decision processes (MDPs)\ngiven a generative model. When applied to an average-reward MDP with $A_{tot}$\ntotal state-action pairs and mixing time bound $t_{mix}$ our method computes an\n$\\epsilon$-optimal policy with an expected $\\widetilde{O}(t_{mix}^2 A_{tot}\n\\epsilon^{-2})$ samples from the state-transition matrix, removing the\nergodicity dependence of prior art. When applied to a $\\gamma$-discounted MDP\nwith $A_{tot}$ total state-action pairs our method computes an\n$\\epsilon$-optimal policy with an expected $\\widetilde{O}((1-\\gamma)^{-4}\nA_{tot} \\epsilon^{-2})$ samples, matching the previous state-of-the-art up to a\n$(1-\\gamma)^{-1}$ factor. Both methods are model-free, update state values and\npolicies simultaneously, and run in time linear in the number of samples taken.\nWe achieve these results through a more general stochastic mirror descent\nframework for solving bilinear saddle-point problems with simplex and box\ndomains and we demonstrate the flexibility of this framework by providing\nfurther applications to constrained MDPs.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 17:58:40 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Jin", "Yujia", ""], ["Sidford", "Aaron", ""]]}, {"id": "2008.12804", "submitter": "Martin Faj\\v{c}\\'ik", "authors": "Martin Fajcik, Josef Jon, Pavel Smrz", "title": "Rethinking the Objectives of Extractive Question Answering", "comments": "final preprint version (added manual analysis, code & results,\n  experiments with MLP similarity, complexity analysis, conditional objective)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work demonstrates that, contrary to a common belief, using the objective\nwith independence assumption for modelling the span probability $P(a_s,a_e) =\nP(a_s)P(a_e)$ of span starting at position $a_s$ and ending at position $a_e$\nhas adverse effects. Therefore we propose multiple approaches to modelling\njoint probability $P(a_s,a_e)$ directly. Among those, we propose a compound\nobjective, composed from the joint probability while still keeping the\nobjective with independence assumption as an auxiliary objective. We find that\nthe compound objective is consistently superior or equal to other assumptions\nin exact match. Additionally, we identified common errors caused by the\nassumption of independence and manually checked the counterpart predictions,\ndemonstrating the impact of the compound objective on the real examples. Our\nfindings are supported via experiments with three extractive QA models (BIDAF,\nBERT, ALBERT) over six datasets and our code, individual results and manual\nanalysis are available online.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 18:22:19 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 15:04:42 GMT"}, {"version": "v3", "created": "Mon, 19 Jul 2021 13:24:01 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Fajcik", "Martin", ""], ["Jon", "Josef", ""], ["Smrz", "Pavel", ""]]}, {"id": "2008.12813", "submitter": "Sanxing Chen", "authors": "Sanxing Chen, Xiaodong Liu, Jianfeng Gao, Jian Jiao, Ruofei Zhang and\n  Yangfeng Ji", "title": "HittER: Hierarchical Transformers for Knowledge Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the challenging problem of learning representations of\nentities and relations in a complex multi-relational knowledge graph. We\npropose HittER, a Hierarchical Transformer model to jointly learn\nEntity-relation composition and Relational contextualization based on a source\nentity's neighborhood. Our proposed model consists of two different Transformer\nblocks: the bottom block extracts features of each entity-relation pair in the\nlocal neighborhood of the source entity and the top block aggregates the\nrelational information from the outputs of the bottom block. We further design\na masked entity prediction task to balance information from the relational\ncontext and the source entity itself. Evaluated on the task of link prediction,\nour approach achieves new state-of-the-art results on two standard benchmark\ndatasets FB15K-237 and WN18RR.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 18:58:15 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Chen", "Sanxing", ""], ["Liu", "Xiaodong", ""], ["Gao", "Jianfeng", ""], ["Jiao", "Jian", ""], ["Zhang", "Ruofei", ""], ["Ji", "Yangfeng", ""]]}, {"id": "2008.12818", "submitter": "Niki Efthymiou", "authors": "Niki Efthymiou, Panagiotis P. Filntisis, Petros Koutras, Antigoni\n  Tsiami, Jack Hadfield, Gerasimos Potamianos, Petros Maragos", "title": "ChildBot: Multi-Robot Perception and Interaction with Children", "comments": "19 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an integrated robotic system capable of\nparticipating in and performing a wide range of educational and entertainment\ntasks, in collaboration with one or more children. The system, called ChildBot,\nfeatures multimodal perception modules and multiple robotic agents that monitor\nthe interaction environment, and can robustly coordinate complex Child-Robot\nInteraction use-cases. In order to validate the effectiveness of the system and\nits integrated modules, we have conducted multiple experiments with a total of\n52 children. Our results show improved perception capabilities in comparison to\nour earlier works that ChildBot was based on. In addition, we have conducted a\npreliminary user experience study, employing some educational/entertainment\ntasks, that yields encouraging results regarding the technical validity of our\nsystem and initial insights on the user experience with it.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 19:07:28 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Efthymiou", "Niki", ""], ["Filntisis", "Panagiotis P.", ""], ["Koutras", "Petros", ""], ["Tsiami", "Antigoni", ""], ["Hadfield", "Jack", ""], ["Potamianos", "Gerasimos", ""], ["Maragos", "Petros", ""]]}, {"id": "2008.12825", "submitter": "Jay Mardia", "authors": "Jay Mardia", "title": "Is the space complexity of planted clique recovery the same as that of\n  detection?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the planted clique problem in which a clique of size k is planted in\nan Erd\\H{o}s-R\\'enyi graph G(n, 1/2), and one is interested in either detecting\nor recovering this planted clique. This problem is interesting because it is\nwidely believed to show a statistical-computational gap at clique size\nk=sqrt{n}, and has emerged as the prototypical problem with such a gap from\nwhich average-case hardness of other statistical problems can be deduced. It\nalso displays a tight computational connection between the detection and\nrecovery variants, unlike other problems of a similar nature. This wide\ninvestigation into the computational complexity of the planted clique problem\nhas, however, mostly focused on its time complexity. In this work, we ask-\n  Do the statistical-computational phenomena that make the planted clique an\ninteresting problem also hold when we use `space efficiency' as our notion of\ncomputational efficiency?\n  It is relatively easy to show that a positive answer to this question depends\non the existence of a O(log n) space algorithm that can recover planted cliques\nof size k = Omega(sqrt{n}). Our main result comes very close to designing such\nan algorithm. We show that for k=Omega(sqrt{n}), the recovery problem can be\nsolved in O((log*{n}-log*{k/sqrt{n}}) log n) bits of space.\n  1. If k = omega(sqrt{n}log^{(l)}n) for any constant integer l > 0, the space\nusage is O(log n) bits.\n  2.If k = Theta(sqrt{n}), the space usage is O(log*{n} log n) bits.\n  Our result suggests that there does exist an O(log n) space algorithm to\nrecover cliques of size k = Omega(sqrt{n}), since we come very close to\nachieving such parameters. This provides evidence that the\nstatistical-computational phenomena that (conjecturally) hold for planted\nclique time complexity also (conjecturally) hold for space complexity.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 19:49:42 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 23:44:57 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Mardia", "Jay", ""]]}, {"id": "2008.12828", "submitter": "Mike Merrill", "authors": "Ge Zhang, Mike A. Merrill, Yang Liu, Jeffrey Heer, Tim Althoff", "title": "CORAL: COde RepresentAtion Learning with Weakly-Supervised Transformers\n  for Analyzing Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale analysis of source code, and in particular scientific source\ncode, holds the promise of better understanding the data science process,\nidentifying analytical best practices, and providing insights to the builders\nof scientific toolkits. However, large corpora have remained unanalyzed in\ndepth, as descriptive labels are absent and require expert domain knowledge to\ngenerate. We propose a novel weakly supervised transformer-based architecture\nfor computing joint representations of code from both abstract syntax trees and\nsurrounding natural language comments. We then evaluate the model on a new\nclassification task for labeling computational notebook cells as stages in the\ndata analysis process from data import to wrangling, exploration, modeling, and\nevaluation. We show that our model, leveraging only easily-available weak\nsupervision, achieves a 38% increase in accuracy over expert-supplied\nheuristics and outperforms a suite of baselines. Our model enables us to\nexamine a set of 118,000 Jupyter Notebooks to uncover common data analysis\npatterns. Focusing on notebooks with relationships to academic articles, we\nconduct the largest ever study of scientific code and find that notebook\ncomposition correlates with the citation count of corresponding papers.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 19:57:49 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Zhang", "Ge", ""], ["Merrill", "Mike A.", ""], ["Liu", "Yang", ""], ["Heer", "Jeffrey", ""], ["Althoff", "Tim", ""]]}, {"id": "2008.12829", "submitter": "Ryan Urbanowicz", "authors": "Ryan J. Urbanowicz and Pranshu Suri and Yuhan Cui and Jason H. Moore\n  and Karen Ruth and Rachael Stolzenberg-Solomon and Shannon M. Lynch", "title": "A Rigorous Machine Learning Analysis Pipeline for Biomedical Binary\n  Classification: Application in Pancreatic Cancer Nested Case-control Studies\n  with Implications for Bias Assessments", "comments": "22 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) offers a collection of powerful approaches for\ndetecting and modeling associations, often applied to data having a large\nnumber of features and/or complex associations. Currently, there are many tools\nto facilitate implementing custom ML analyses (e.g. scikit-learn). Interest is\nalso increasing in automated ML packages, which can make it easier for\nnon-experts to apply ML and have the potential to improve model performance. ML\npermeates most subfields of biomedical research with varying levels of rigor\nand correct usage. Tremendous opportunities offered by ML are frequently offset\nby the challenge of assembling comprehensive analysis pipelines, and the ease\nof ML misuse. In this work we have laid out and assembled a complete, rigorous\nML analysis pipeline focused on binary classification (i.e. case/control\nprediction), and applied this pipeline to both simulated and real world data.\nAt a high level, this 'automated' but customizable pipeline includes a)\nexploratory analysis, b) data cleaning and transformation, c) feature\nselection, d) model training with 9 established ML algorithms, each with\nhyperparameter optimization, and e) thorough evaluation, including appropriate\nmetrics, statistical analyses, and novel visualizations. This pipeline\norganizes the many subtle complexities of ML pipeline assembly to illustrate\nbest practices to avoid bias and ensure reproducibility. Additionally, this\npipeline is the first to compare established ML algorithms to 'ExSTraCS', a\nrule-based ML algorithm with the unique capability of interpretably modeling\nheterogeneous patterns of association. While designed to be widely applicable\nwe apply this pipeline to an epidemiological investigation of established and\nnewly identified risk factors for pancreatic cancer to evaluate how different\nsources of bias might be handled by ML algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 19:58:05 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 20:31:35 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Urbanowicz", "Ryan J.", ""], ["Suri", "Pranshu", ""], ["Cui", "Yuhan", ""], ["Moore", "Jason H.", ""], ["Ruth", "Karen", ""], ["Stolzenberg-Solomon", "Rachael", ""], ["Lynch", "Shannon M.", ""]]}, {"id": "2008.12833", "submitter": "Gabriel Spadon", "authors": "Gabriel Spadon, Shenda Hong, Bruno Brandoli, Stan Matwin, Jose F.\n  Rodrigues-Jr, and Jimeng Sun", "title": "Pay Attention to Evolution: Time Series Forecasting with Deep\n  Graph-Evolution Learning", "comments": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021", "journal-ref": null, "doi": "10.1109/TPAMI.2021.3076155", "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-series forecasting is one of the most active research topics in\nartificial intelligence. Applications in real-world time series should consider\ntwo factors for achieving reliable predictions: modeling dynamic dependencies\namong multiple variables and adjusting the model's intrinsic hyperparameters. A\nstill open gap in that literature is that statistical and ensemble learning\napproaches systematically present lower predictive performance than deep\nlearning methods. They generally disregard the data sequence aspect entangled\nwith multivariate data represented in more than one time series. Conversely,\nthis work presents a novel neural network architecture for time-series\nforecasting that combines the power of graph evolution with deep recurrent\nlearning on distinct data distributions; we named our method Recurrent Graph\nEvolution Neural Network (ReGENN). The idea is to infer multiple multivariate\nrelationships between co-occurring time-series by assuming that the temporal\ndata depends not only on inner variables and intra-temporal relationships\n(i.e., observations from itself) but also on outer variables and inter-temporal\nrelationships (i.e., observations from other-selves). An extensive set of\nexperiments was conducted comparing ReGENN with dozens of ensemble methods and\nclassical statistical ones, showing sound improvement of up to 64.87% over the\ncompeting algorithms. Furthermore, we present an analysis of the intermediate\nweights arising from ReGENN, showing that by looking at inter and\nintra-temporal relationships simultaneously, time-series forecasting is majorly\nimproved if paying attention to how multiple multivariate data synchronously\nevolve.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 20:10:07 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 11:10:35 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 15:46:00 GMT"}, {"version": "v4", "created": "Wed, 26 May 2021 19:58:48 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Spadon", "Gabriel", ""], ["Hong", "Shenda", ""], ["Brandoli", "Bruno", ""], ["Matwin", "Stan", ""], ["Rodrigues-Jr", "Jose F.", ""], ["Sun", "Jimeng", ""]]}, {"id": "2008.12839", "submitter": "Prithvijit Chattopadhyay Chattopadhyay", "authors": "Prithvijit Chattopadhyay, Yogesh Balaji, Judy Hoffman", "title": "Learning to Balance Specificity and Invariance for In and Out of Domain\n  Generalization", "comments": "Published at ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Domain-specific Masks for Generalization, a model for improving\nboth in-domain and out-of-domain generalization performance. For domain\ngeneralization, the goal is to learn from a set of source domains to produce a\nsingle model that will best generalize to an unseen target domain. As such,\nmany prior approaches focus on learning representations which persist across\nall source domains with the assumption that these domain agnostic\nrepresentations will generalize well. However, often individual domains contain\ncharacteristics which are unique and when leveraged can significantly aid\nin-domain recognition performance. To produce a model which best generalizes to\nboth seen and unseen domains, we propose learning domain specific masks. The\nmasks are encouraged to learn a balance of domain-invariant and domain-specific\nfeatures, thus enabling a model which can benefit from the predictive power of\nspecialized features while retaining the universal applicability of\ndomain-invariant features. We demonstrate competitive performance compared to\nnaive baselines and state-of-the-art methods on both PACS and DomainNet.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 20:39:51 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Chattopadhyay", "Prithvijit", ""], ["Balaji", "Yogesh", ""], ["Hoffman", "Judy", ""]]}, {"id": "2008.12842", "submitter": "Rahul Ragesh", "authors": "Rahul Ragesh, Sundararajan Sellamanickam, Arun Iyer, Ram Bairi, Vijay\n  Lingam", "title": "HeteGCN: Heterogeneous Graph Convolutional Networks for Text\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning efficient and inductive graph\nconvolutional networks for text classification with a large number of examples\nand features. Existing state-of-the-art graph embedding based methods such as\npredictive text embedding (PTE) and TextGCN have shortcomings in terms of\npredictive performance, scalability and inductive capability. To address these\nlimitations, we propose a heterogeneous graph convolutional network (HeteGCN)\nmodeling approach that unites the best aspects of PTE and TextGCN together. The\nmain idea is to learn feature embeddings and derive document embeddings using a\nHeteGCN architecture with different graphs used across layers. We simplify\nTextGCN by dissecting into several HeteGCN models which (a) helps to study the\nusefulness of individual models and (b) offers flexibility in fusing learned\nembeddings from different models. In effect, the number of model parameters is\nreduced significantly, enabling faster training and improving performance in\nsmall labeled training set scenario. Our detailed experimental studies\ndemonstrate the efficacy of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 12:24:35 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Ragesh", "Rahul", ""], ["Sellamanickam", "Sundararajan", ""], ["Iyer", "Arun", ""], ["Bairi", "Ram", ""], ["Lingam", "Vijay", ""]]}, {"id": "2008.12854", "submitter": "Anh Nguyen Tuan", "authors": "Anh Tuan Nguyen", "title": "TATL at W-NUT 2020 Task 2: A Transformer-based Baseline System for\n  Identification of Informative COVID-19 English Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the COVID-19 outbreak continues to spread throughout the world, more and\nmore information about the pandemic has been shared publicly on social media.\nFor example, there are a huge number of COVID-19 English Tweets daily on\nTwitter. However, the majority of those Tweets are uninformative, and hence it\nis important to be able to automatically select only the informative ones for\ndownstream applications. In this short paper, we present our participation in\nthe W-NUT 2020 Shared Task 2: Identification of Informative COVID-19 English\nTweets. Inspired by the recent advances in pretrained Transformer language\nmodels, we propose a simple yet effective baseline for the task. Despite its\nsimplicity, our proposed approach shows very competitive results in the\nleaderboard as we ranked 8 over 56 teams participated in total.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 21:27:42 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Nguyen", "Anh Tuan", ""]]}, {"id": "2008.12873", "submitter": "Fait Poms", "authors": "Ravi Teja Mullapudi, Fait Poms, William R. Mark, Deva Ramanan, Kayvon\n  Fatahalian", "title": "Background Splitting: Finding Rare Classes in a Sea of Background", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the real-world problem of training accurate deep models for image\nclassification of a small number of rare categories. In these scenarios, almost\nall images belong to the background category in the dataset (>95% of the\ndataset is background). We demonstrate that both standard fine-tuning\napproaches and state-of-the-art approaches for training on imbalanced datasets\ndo not produce accurate deep models in the presence of this extreme imbalance.\nOur key observation is that the extreme imbalance due to the background\ncategory can be drastically reduced by leveraging visual knowledge from an\nexisting pre-trained model. Specifically, the background category is \"split\"\ninto smaller and more coherent pseudo-categories during training using a\npre-trained model. We incorporate background splitting into an image\nclassification model by adding an auxiliary loss that learns to mimic the\npredictions of the existing, pre-trained image classification model. Note that\nthis process is automatic and requires no additional manual labels. The\nauxiliary loss regularizes the feature representation of the shared network\ntrunk by requiring it to discriminate between previously homogeneous background\ninstances and reduces overfitting to the small number of rare category\npositives. We also show that BG splitting can be combined with other background\nimbalance methods to further improve performance. We evaluate our method on a\nmodified version of the iNaturalist dataset where only a small subset of rare\ncategory labels are available during training (all other images are labeled as\nbackground). By jointly learning to recognize ImageNet categories and selected\niNaturalist categories, our approach yields performance that is 42.3 mAP points\nhigher than a fine-tuning baseline when 99.98% of the data is background, and\n8.3 mAP points higher than SotA baselines when 98.30% of the data is\nbackground.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 23:05:15 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Mullapudi", "Ravi Teja", ""], ["Poms", "Fait", ""], ["Mark", "William R.", ""], ["Ramanan", "Deva", ""], ["Fatahalian", "Kayvon", ""]]}, {"id": "2008.12876", "submitter": "Yu Guan", "authors": "Yu Guan, Shuyu Dong, P.-A. Absil, Fran\\c{c}ois Glineur", "title": "Alternating minimization algorithms for graph regularized tensor\n  completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a low-rank tensor completion (LRTC) problem which aims to recover\na tensor from incomplete observations. LRTC plays an important role in many\napplications such as signal processing, computer vision, machine learning, and\nneuroscience. A widely used approach is to combine the tensor completion data\nfitting term with a regularizer based on a convex relaxation of the multilinear\nranks of the tensor. For the data fitting function, we model the tensor\nvariable by using the Canonical Polyadic (CP) decomposition and for the\nlow-rank promoting regularization function, we consider a graph Laplacian-based\nfunction which exploits correlations between the rows of the matrix unfoldings.\nFor solving our LRTC model, we propose an efficient alternating minimization\nalgorithm. Furthermore, based on the Kurdyka-{\\L}ojasiewicz property, we show\nthat the sequence generated by the proposed algorithm globally converges to a\ncritical point of the objective function. Besides, an alternating direction\nmethod of multipliers algorithm is also developed for the LRTC model. Extensive\nnumerical experiments on synthetic and real data indicate that the proposed\nalgorithms are effective and efficient.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 23:20:49 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Guan", "Yu", ""], ["Dong", "Shuyu", ""], ["Absil", "P. -A.", ""], ["Glineur", "Fran\u00e7ois", ""]]}, {"id": "2008.12884", "submitter": "Josimar Chire Saire", "authors": "Josimar E. Chire-Saire", "title": "New feature for Complex Network based on Ant Colony Optimization for\n  High Level Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low level classification extracts features from the elements, i.e. physical\nto use them to train a model for a later classification. High level\nclassification uses high level features, the existent patterns, relationship\nbetween the data and combines low and high level features for classification.\nHigh Level features can be got from Complex Network created over the data.\nLocal and global features are used to describe the structure of a Complex\nNetwork, i.e. Average Neighbor Degree, Average Clustering. The present work\nproposed a novel feature to describe the architecture of the Network following\na Ant Colony System approach. The experiments shows the advantage of using this\nfeature because the sensibility with data of different classes.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 00:22:43 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Chire-Saire", "Josimar E.", ""]]}, {"id": "2008.12894", "submitter": "Junaid Malik", "authors": "Junaid Malik, Serkan Kiranyaz, Moncef Gabbouj", "title": "Self-Organized Operational Neural Networks for Severe Image Restoration\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Discriminative learning based on convolutional neural networks (CNNs) aims to\nperform image restoration by learning from training examples of noisy-clean\nimage pairs. It has become the go-to methodology for tackling image restoration\nand has outperformed the traditional non-local class of methods. However, the\ntop-performing networks are generally composed of many convolutional layers and\nhundreds of neurons, with trainable parameters in excess of several millions.\nWe claim that this is due to the inherent linear nature of convolution-based\ntransformation, which is inadequate for handling severe restoration problems.\nRecently, a non-linear generalization of CNNs, called the operational neural\nnetworks (ONN), has been shown to outperform CNN on AWGN denoising. However,\nits formulation is burdened by a fixed collection of well-known nonlinear\noperators and an exhaustive search to find the best possible configuration for\na given architecture, whose efficacy is further limited by a fixed output layer\noperator assignment. In this study, we leverage the Taylor series-based\nfunction approximation to propose a self-organizing variant of ONNs, Self-ONNs,\nfor image restoration, which synthesizes novel nodal transformations onthe-fly\nas part of the learning process, thus eliminating the need for redundant\ntraining runs for operator search. In addition, it enables a finer level of\noperator heterogeneity by diversifying individual connections of the receptive\nfields and weights. We perform a series of extensive ablation experiments\nacross three severe image restoration tasks. Even when a strict equivalence of\nlearnable parameters is imposed, Self-ONNs surpass CNNs by a considerable\nmargin across all problems, improving the generalization performance by up to 3\ndB in terms of PSNR.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 02:19:41 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Malik", "Junaid", ""], ["Kiranyaz", "Serkan", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "2008.12912", "submitter": "Abdul Muqeet", "authors": "Abdul Muqeet, Jiwon Hwang, Subin Yang, Jung Heum Kang, Yongwoo Kim,\n  Sung-Ho Bae", "title": "Multi-Attention Based Ultra Lightweight Image Super-Resolution", "comments": "ECCVW AIM2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lightweight image super-resolution (SR) networks have the utmost significance\nfor real-world applications. There are several deep learning based SR methods\nwith remarkable performance, but their memory and computational cost are\nhindrances in practical usage. To tackle this problem, we propose a\nMulti-Attentive Feature Fusion Super-Resolution Network (MAFFSRN). MAFFSRN\nconsists of proposed feature fusion groups (FFGs) that serve as a feature\nextraction block. Each FFG contains a stack of proposed multi-attention blocks\n(MAB) that are combined in a novel feature fusion structure. Further, the MAB\nwith a cost-efficient attention mechanism (CEA) helps us to refine and extract\nthe features using multiple attention mechanisms. The comprehensive experiments\nshow the superiority of our model over the existing state-of-the-art. We\nparticipated in AIM 2020 efficient SR challenge with our MAFFSRN model and won\n1st, 3rd, and 4th places in memory usage, floating-point operations (FLOPs) and\nnumber of parameters, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 05:19:32 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 06:07:14 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Muqeet", "Abdul", ""], ["Hwang", "Jiwon", ""], ["Yang", "Subin", ""], ["Kang", "Jung Heum", ""], ["Kim", "Yongwoo", ""], ["Bae", "Sung-Ho", ""]]}, {"id": "2008.12922", "submitter": "Haitao Liu", "authors": "Haitao Liu, Yew-Soon Ong, Xiaomo Jiang, Xiaofang Wang", "title": "Modulating Scalable Gaussian Processes for Expressive Statistical\n  Learning", "comments": "31 pages, 9 figures, 4 tables, preprint under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a learning task, Gaussian process (GP) is interested in learning the\nstatistical relationship between inputs and outputs, since it offers not only\nthe prediction mean but also the associated variability. The vanilla GP however\nstruggles to learn complicated distribution with the property of, e.g.,\nheteroscedastic noise, multi-modality and non-stationarity, from massive data\ndue to the Gaussian marginal and the cubic complexity. To this end, this\narticle studies new scalable GP paradigms including the non-stationary\nheteroscedastic GP, the mixture of GPs and the latent GP, which introduce\nadditional latent variables to modulate the outputs or inputs in order to learn\nricher, non-Gaussian statistical representation. We further resort to different\nvariational inference strategies to arrive at analytical or tighter evidence\nlower bounds (ELBOs) of the marginal likelihood for efficient and effective\nmodel training. Extensive numerical experiments against state-of-the-art GP and\nneural network (NN) counterparts on various tasks verify the superiority of\nthese scalable modulated GPs, especially the scalable latent GP, for learning\ndiverse data distributions.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 06:41:45 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Liu", "Haitao", ""], ["Ong", "Yew-Soon", ""], ["Jiang", "Xiaomo", ""], ["Wang", "Xiaofang", ""]]}, {"id": "2008.12925", "submitter": "Seok-Ju Hahn", "authors": "Seok-Ju Hahn, Junghye Lee", "title": "GRAFFL: Gradient-free Federated Learning of a Bayesian Generative Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning platforms are gaining popularity. One of the major\nbenefits is to mitigate the privacy risks as the learning of algorithms can be\nachieved without collecting or sharing data. While federated learning (i.e.,\nmany based on stochastic gradient algorithms) has shown great promise, there\nare still many challenging problems in protecting privacy, especially during\nthe process of gradients update and exchange. This paper presents the first\ngradient-free federated learning framework called GRAFFL for learning a\nBayesian generative model based on approximate Bayesian computation. Unlike\nconventional federated learning algorithms based on gradients, our framework\ndoes not require to disassemble a model (i.e., to linear components) or to\nperturb data (or encryption of data for aggregation) to preserve privacy.\nInstead, this framework uses implicit information derived from each\nparticipating institution to learn posterior distributions of parameters. The\nimplicit information is summary statistics derived from SuffiAE that is a\nneural network developed in this study to create compressed and linearly\nseparable representations thereby protecting sensitive information from\nleakage. As a sufficient dimensionality reduction technique, this is proved to\nprovide sufficient summary statistics. We propose the GRAFFL-based Bayesian\nGaussian mixture model to serve as a proof-of-concept of the framework. Using\nseveral datasets, we demonstrated the feasibility and usefulness of our model\nin terms of privacy protection and prediction performance (i.e., close to an\nideal setting). The trained model as a quasi-global model can generate\ninformative samples involving information from other institutions and enhances\ndata analysis of each institution.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 07:19:44 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Hahn", "Seok-Ju", ""], ["Lee", "Junghye", ""]]}, {"id": "2008.12938", "submitter": "Shimin Gong", "authors": "Shimin Gong, Jiaye Lin, Jinbei Zhang, Dusit Niyato, Dong In Kim, and\n  Mohsen Guizani", "title": "Optimization-driven Machine Learning for Intelligent Reflecting Surfaces\n  Assisted Wireless Networks", "comments": "submitted to IEEE Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent reflecting surface (IRS) has been recently employed to reshape\nthe wireless channels by controlling individual scattering elements' phase\nshifts, namely, passive beamforming. Due to the large size of scattering\nelements, the passive beamforming is typically challenged by the high\ncomputational complexity and inexact channel information. In this article, we\nfocus on machine learning (ML) approaches for performance maximization in\nIRS-assisted wireless networks. In general, ML approaches provide enhanced\nflexibility and robustness against uncertain information and imprecise\nmodeling. Practical challenges still remain mainly due to the demand for a\nlarge dataset in offline training and slow convergence in online learning.\nThese observations motivate us to design a novel optimization-driven ML\nframework for IRS-assisted wireless networks, which takes both advantages of\nthe efficiency in model-based optimization and the robustness in model-free ML\napproaches. By splitting the decision variables into two parts, one part is\nobtained by the outer-loop ML approach, while the other part is optimized\nefficiently by solving an approximate problem. Numerical results verify that\nthe optimization-driven ML approach can improve both the convergence and the\nreward performance compared to conventional model-free learning approaches.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 08:39:43 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Gong", "Shimin", ""], ["Lin", "Jiaye", ""], ["Zhang", "Jinbei", ""], ["Niyato", "Dusit", ""], ["Kim", "Dong In", ""], ["Guizani", "Mohsen", ""]]}, {"id": "2008.12949", "submitter": "Kagan Incetan", "authors": "Kagan Incetan, Ibrahim Omer Celik, Abdulhamid Obeid, Guliz Irem\n  Gokceler, Kutsev Bengisu Ozyoruk, Yasin Almalioglu, Richard J. Chen, Faisal\n  Mahmood, Hunter Gilbert, Nicholas J. Durr, Mehmet Turan", "title": "VR-Caps: A Virtual Environment for Capsule Endoscopy", "comments": "18 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current capsule endoscopes and next-generation robotic capsules for diagnosis\nand treatment of gastrointestinal diseases are complex cyber-physical platforms\nthat must orchestrate complex software and hardware functions. The desired\ntasks for these systems include visual localization, depth estimation, 3D\nmapping, disease detection and segmentation, automated navigation, active\ncontrol, path realization and optional therapeutic modules such as targeted\ndrug delivery and biopsy sampling. Data-driven algorithms promise to enable\nmany advanced functionalities for capsule endoscopes, but real-world data is\nchallenging to obtain. Physically-realistic simulations providing synthetic\ndata have emerged as a solution to the development of data-driven algorithms.\nIn this work, we present a comprehensive simulation platform for capsule\nendoscopy operations and introduce VR-Caps, a virtual active capsule\nenvironment that simulates a range of normal and abnormal tissue conditions\n(e.g., inflated, dry, wet etc.) and varied organ types, capsule endoscope\ndesigns (e.g., mono, stereo, dual and 360{\\deg}camera), and the type, number,\nstrength, and placement of internal and external magnetic sources that enable\nactive locomotion. VR-Caps makes it possible to both independently or jointly\ndevelop, optimize, and test medical imaging and analysis software for the\ncurrent and next-generation endoscopic capsule systems. To validate this\napproach, we train state-of-the-art deep neural networks to accomplish various\nmedical image analysis tasks using simulated data from VR-Caps and evaluate the\nperformance of these models on real medical data. Results demonstrate the\nusefulness and effectiveness of the proposed virtual platform in developing\nalgorithms that quantify fractional coverage, camera trajectory, 3D map\nreconstruction, and disease classification.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 09:54:05 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 12:55:11 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Incetan", "Kagan", ""], ["Celik", "Ibrahim Omer", ""], ["Obeid", "Abdulhamid", ""], ["Gokceler", "Guliz Irem", ""], ["Ozyoruk", "Kutsev Bengisu", ""], ["Almalioglu", "Yasin", ""], ["Chen", "Richard J.", ""], ["Mahmood", "Faisal", ""], ["Gilbert", "Hunter", ""], ["Durr", "Nicholas J.", ""], ["Turan", "Mehmet", ""]]}, {"id": "2008.12952", "submitter": "Aleksandar Bojchevski", "authors": "Aleksandar Bojchevski, Johannes Klicpera, Stephan G\\\"unnemann", "title": "Efficient Robustness Certificates for Discrete Data: Sparsity-Aware\n  Randomized Smoothing for Graphs, Images and More", "comments": "Proceedings of the 37th International Conference on Machine Learning\n  (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing techniques for certifying the robustness of models for discrete data\neither work only for a small class of models or are general at the expense of\nefficiency or tightness. Moreover, they do not account for sparsity in the\ninput which, as our findings show, is often essential for obtaining non-trivial\nguarantees. We propose a model-agnostic certificate based on the randomized\nsmoothing framework which subsumes earlier work and is tight, efficient, and\nsparsity-aware. Its computational complexity does not depend on the number of\ndiscrete categories or the dimension of the input (e.g. the graph size), making\nit highly scalable. We show the effectiveness of our approach on a wide variety\nof models, datasets, and tasks -- specifically highlighting its use for Graph\nNeural Networks. So far, obtaining provable guarantees for GNNs has been\ndifficult due to the discrete and non-i.i.d. nature of graph data. Our method\ncan certify any GNN and handles perturbations to both the graph structure and\nthe node attributes.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 10:09:02 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Bojchevski", "Aleksandar", ""], ["Klicpera", "Johannes", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2008.12967", "submitter": "Jong Chul Ye", "authors": "Gyutaek Oh, Byeongsu Sim, Hyungjin Chung, Leonard Sunwoo, and Jong\n  Chul Ye", "title": "Unpaired Deep Learning for Accelerated MRI using Optimal Transport\n  Driven CycleGAN", "comments": "Accepted for IEEE Transactions on Computational Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning approaches for accelerated MRI have been extensively\nstudied thanks to their high performance reconstruction in spite of\nsignificantly reduced runtime complexity. These neural networks are usually\ntrained in a supervised manner, so matched pairs of subsampled and fully\nsampled k-space data are required. Unfortunately, it is often difficult to\nacquire matched fully sampled k-space data, since the acquisition of fully\nsampled k-space data requires long scan time and often leads to the change of\nthe acquisition protocol. Therefore, unpaired deep learning without matched\nlabel data has become a very important research topic. In this paper, we\npropose an unpaired deep learning approach using a optimal transport driven\ncycle-consistent generative adversarial network (OT-cycleGAN) that employs a\nsingle pair of generator and discriminator. The proposed OT-cycleGAN\narchitecture is rigorously derived from a dual formulation of the optimal\ntransport formulation using a specially designed penalized least squares cost.\nThe experimental results show that our method can reconstruct high resolution\nMR images from accelerated k- space data from both single and multiple coil\nacquisition, without requiring matched reference data.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 12:02:49 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Oh", "Gyutaek", ""], ["Sim", "Byeongsu", ""], ["Chung", "Hyungjin", ""], ["Sunwoo", "Leonard", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2008.12969", "submitter": "Andreas B\\\"uhler", "authors": "Andreas B\\\"uhler, Adrien Gaidon, Andrei Cramariuc, Rares Ambrus, Guy\n  Rosman, Wolfram Burgard", "title": "Driving Through Ghosts: Behavioral Cloning with False Positives", "comments": "7 pages, 5 figures, 4 tables, accepted at 2020 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safe autonomous driving requires robust detection of other traffic\nparticipants. However, robust does not mean perfect, and safe systems typically\nminimize missed detections at the expense of a higher false positive rate. This\nresults in conservative and yet potentially dangerous behavior such as avoiding\nimaginary obstacles. In the context of behavioral cloning, perceptual errors at\ntraining time can lead to learning difficulties or wrong policies, as expert\ndemonstrations might be inconsistent with the perceived world state. In this\nwork, we propose a behavioral cloning approach that can safely leverage\nimperfect perception without being conservative. Our core contribution is a\nnovel representation of perceptual uncertainty for learning to plan. We propose\na new probabilistic birds-eye-view semantic grid to encode the noisy output of\nobject perception systems. We then leverage expert demonstrations to learn an\nimitative driving policy using this probabilistic representation. Using the\nCARLA simulator, we show that our approach can safely overcome critical false\npositives that would otherwise lead to catastrophic failures or conservative\nbehavior.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 12:10:23 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["B\u00fchler", "Andreas", ""], ["Gaidon", "Adrien", ""], ["Cramariuc", "Andrei", ""], ["Ambrus", "Rares", ""], ["Rosman", "Guy", ""], ["Burgard", "Wolfram", ""]]}, {"id": "2008.12970", "submitter": "Kuangen Zhang", "authors": "Kuangen Zhang, Jongwoo Lee, Zhimin Hou, Clarence W. de Silva,\n  Chenglong Fu, Neville Hogan", "title": "How does the structure embedded in learning policy affect learning\n  quadruped locomotion?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is a popular data-driven method that has\ndemonstrated great success in robotics. Previous works usually focus on\nlearning an end-to-end (direct) policy to directly output joint torques. While\nthe direct policy seems convenient, the resultant performance may not meet our\nexpectations. To improve its performance, more sophisticated reward functions\nor more structured policies can be utilized. This paper focuses on the latter\nbecause the structured policy is more intuitive and can inherit insights from\nprevious model-based controllers. It is unsurprising that the structure, such\nas a better choice of the action space and constraints of motion trajectory,\nmay benefit the training process and the final performance of the policy at the\ncost of generality, but the quantitative effect is still unclear. To analyze\nthe effect of the structure quantitatively, this paper investigates three\npolicies with different levels of structure in learning quadruped locomotion: a\ndirect policy, a structured policy, and a highly structured policy. The\nstructured policy is trained to learn a task-space impedance controller and the\nhighly structured policy learns a controller tailored for trot running, which\nwe adopt from previous work. To evaluate trained policies, we design a\nsimulation experiment to track different desired velocities under force\ndisturbances. Simulation results show that structured policy and highly\nstructured policy require 1/3 and 3/4 fewer training steps than the direct\npolicy to achieve a similar level of cumulative reward, and seem more robust\nand efficient than the direct policy. We highlight that the structure embedded\nin the policies significantly affects the overall performance of learning a\ncomplicated task when complex dynamics are involved, such as legged locomotion.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 12:11:19 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Zhang", "Kuangen", ""], ["Lee", "Jongwoo", ""], ["Hou", "Zhimin", ""], ["de Silva", "Clarence W.", ""], ["Fu", "Chenglong", ""], ["Hogan", "Neville", ""]]}, {"id": "2008.12987", "submitter": "Mohammadhossein Ghahramani", "authors": "Mohammadhossein Ghahramani, Yan Qiao, MengChu Zhou, Adrian OHagan, and\n  James Sweeney", "title": "AI-based Modeling and Data-driven Evaluation for Smart Manufacturing\n  Processes", "comments": "13 pages, 7 figures. To appear in IEEE/CAA JAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smart Manufacturing refers to optimization techniques that are implemented in\nproduction operations by utilizing advanced analytics approaches. With the\nwidespread increase in deploying Industrial Internet of Things (IIoT) sensors\nin manufacturing processes, there is a progressive need for optimal and\neffective approaches to data management. Embracing Machine Learning and\nArtificial Intelligence to take advantage of manufacturing data can lead to\nefficient and intelligent automation. In this paper, we conduct a comprehensive\nanalysis based on Evolutionary Computing and Deep Learning algorithms toward\nmaking semiconductor manufacturing smart. We propose a dynamic algorithm for\ngaining useful insights about semiconductor manufacturing processes and to\naddress various challenges. We elaborate on the utilization of a Genetic\nAlgorithm and Neural Network to propose an intelligent feature selection\nalgorithm. Our objective is to provide an advanced solution for controlling\nmanufacturing processes and to gain perspective on various dimensions that\nenable manufacturers to access effective predictive technologies.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 14:57:53 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Ghahramani", "Mohammadhossein", ""], ["Qiao", "Yan", ""], ["Zhou", "MengChu", ""], ["OHagan", "Adrian", ""], ["Sweeney", "James", ""]]}, {"id": "2008.12992", "submitter": "Mohammadhossein Ghahramani", "authors": "Mohammadhossein Ghahramani, MengChu Zhou, and Gang Wang", "title": "Urban Sensing based on Mobile Phone Data: Approaches, Applications and\n  Challenges", "comments": "11 pages, To appear in IEEE/CAA JAC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data volume grows explosively with the proliferation of powerful smartphones\nand innovative mobile applications. The ability to accurately and extensively\nmonitor and analyze these data is necessary. Much concern in mobile data\nanalysis is related to human beings and their behaviours. Due to the potential\nvalue that lies behind these massive data, there have been different proposed\napproaches for understanding corresponding patterns. To that end, monitoring\npeople's interactions, whether counting them at fixed locations or tracking\nthem by generating origin-destination matrices is crucial. The former can be\nused to determine the utilization of assets like roads and city attractions.\nThe latter is valuable when planning transport infrastructure. Such insights\nallow a government to predict the adoption of new roads, new public transport\nroutes, modification of existing infrastructure, and detection of congestion\nzones, resulting in more efficient designs and improvement. Smartphone data\nexploration can help research in various fields, e.g., urban planning,\ntransportation, health care, and business marketing. It can also help\norganizations in decision making, policy implementation, monitoring and\nevaluation at all levels. This work aims to review the methods and techniques\nthat have been implemented to discover knowledge from mobile phone data. We\nclassify these existing methods and present a taxonomy of the related work by\ndiscussing their pros and cons.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 15:14:03 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Ghahramani", "Mohammadhossein", ""], ["Zhou", "MengChu", ""], ["Wang", "Gang", ""]]}, {"id": "2008.12997", "submitter": "Pengfei Xia", "authors": "Pengfei Xia and Bin Li", "title": "Improving Resistance to Adversarial Deformations by Regularizing\n  Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving the resistance of deep neural networks against adversarial attacks\nis important for deploying models to realistic applications. However, most\ndefense methods are designed to defend against intensity perturbations and\nignore location perturbations, which should be equally important for deep model\nsecurity. In this paper, we focus on adversarial deformations, a typical class\nof location perturbations, and propose a flow gradient regularization to\nimprove the resistance of models. Theoretically, we prove that, compared with\ninput gradient regularization, regularizing flow gradients is able to get a\ntighter bound. Over multiple datasets, architectures, and adversarial\ndeformations, our empirical results indicate that models trained with flow\ngradients can acquire a better resistance than trained with input gradients\nwith a large margin, and also better than adversarial training. Moreover,\ncompared with directly training with adversarial deformations, our method can\nachieve better results in unseen attacks, and combining these two methods can\nimprove the resistance further.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 15:28:23 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 05:58:16 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Xia", "Pengfei", ""], ["Li", "Bin", ""]]}, {"id": "2008.13020", "submitter": "Saeed-Ul Hassan", "authors": "Sehrish Iqbal, Saeed-Ul Hassan, Naif Radi Aljohani, Salem Alelyani,\n  Raheel Nawaz and Lutz Bornmann", "title": "A Decade of In-text Citation Analysis based on Natural Language\n  Processing and Machine Learning Techniques: An overview of empirical studies", "comments": "59 pages, 4 figures, 8 tables (submitted to Scientometrics)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citation analysis is one of the most frequently used methods in research\nevaluation. We are seeing significant growth in citation analysis through\nbibliometric metadata, primarily due to the availability of citation databases\nsuch as the Web of Science, Scopus, Google Scholar, Microsoft Academic, and\nDimensions. Due to better access to full-text publication corpora in recent\nyears, information scientists have gone far beyond traditional bibliometrics by\ntapping into advancements in full-text data processing techniques to measure\nthe impact of scientific publications in contextual terms. This has led to\ntechnical developments in citation context and content analysis, citation\nclassifications, citation sentiment analysis, citation summarisation, and\ncitation-based recommendation. This article aims to narratively review the\nstudies on these developments. Its primary focus is on publications that have\nused natural language processing and machine learning techniques to analyse\ncitations.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 17:27:08 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Iqbal", "Sehrish", ""], ["Hassan", "Saeed-Ul", ""], ["Aljohani", "Naif Radi", ""], ["Alelyani", "Salem", ""], ["Nawaz", "Raheel", ""], ["Bornmann", "Lutz", ""]]}, {"id": "2008.13024", "submitter": "Hao Tang", "authors": "Hao Tang, Song Bai, Nicu Sebe", "title": "Dual Attention GANs for Semantic Image Synthesis", "comments": "Accepted to ACM MM 2020, camera ready (9 pages) + supplementary (10\n  pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the semantic image synthesis task that aims at\ntransferring semantic label maps to photo-realistic images. Existing methods\nlack effective semantic constraints to preserve the semantic information and\nignore the structural correlations in both spatial and channel dimensions,\nleading to unsatisfactory blurry and artifact-prone results. To address these\nlimitations, we propose a novel Dual Attention GAN (DAGAN) to synthesize\nphoto-realistic and semantically-consistent images with fine details from the\ninput layouts without imposing extra training overhead or modifying the network\narchitectures of existing methods. We also propose two novel modules, i.e.,\nposition-wise Spatial Attention Module (SAM) and scale-wise Channel Attention\nModule (CAM), to capture semantic structure attention in spatial and channel\ndimensions, respectively. Specifically, SAM selectively correlates the pixels\nat each position by a spatial attention map, leading to pixels with the same\nsemantic label being related to each other regardless of their spatial\ndistances. Meanwhile, CAM selectively emphasizes the scale-wise features at\neach channel by a channel attention map, which integrates associated features\namong all channel maps regardless of their scales. We finally sum the outputs\nof SAM and CAM to further improve feature representation. Extensive experiments\non four challenging datasets show that DAGAN achieves remarkably better results\nthan state-of-the-art methods, while using fewer model parameters. The source\ncode and trained models are available at https://github.com/Ha0Tang/DAGAN.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 17:49:01 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Tang", "Hao", ""], ["Bai", "Song", ""], ["Sebe", "Nicu", ""]]}, {"id": "2008.13038", "submitter": "F. Trevor Rogers", "authors": "F. Trevor Rogers", "title": "Loss convergence in a causal Bayesian neural network of retail firm\n  performance", "comments": "7 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the empirical results from the structural equation model (SEM)\npublished in the paper Assortment Planning for Retail Buying, Retail Store\nOperations, and Firm Performance [1] by implementing the directed acyclic graph\nas a causal Bayesian neural network. Neural network convergence is shown to\nimprove with the removal of the node with the weakest SEM path when variational\ninference is provided by perturbing weights with Flipout layers, while results\nfrom perturbing weights at the output with the Vadam optimizer are\ninconclusive.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 19:16:43 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Rogers", "F. Trevor", ""]]}, {"id": "2008.13044", "submitter": "Stephen Chung", "authors": "Stephen Chung, Robert Kozma", "title": "Reinforcement Learning with Feedback-modulated TD-STDP", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neuron networks have been used successfully to solve simple\nreinforcement learning tasks with continuous action set applying learning rules\nbased on spike-timing-dependent plasticity (STDP). However, most of these\nmodels cannot be applied to reinforcement learning tasks with discrete action\nset since they assume that the selected action is a deterministic function of\nfiring rate of neurons, which is continuous. In this paper, we propose a new\nSTDP-based learning rule for spiking neuron networks which contains feedback\nmodulation. We show that the STDP-based learning rule can be used to solve\nreinforcement learning tasks with discrete action set at a speed similar to\nstandard reinforcement learning algorithms when applied to the CartPole and\nLunarLander tasks. Moreover, we demonstrate that the agent is unable to solve\nthese tasks if feedback modulation is omitted from the learning rule. We\nconclude that feedback modulation allows better credit assignment when only the\nunits contributing to the executed action and TD error participate in learning.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 20:08:59 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Chung", "Stephen", ""], ["Kozma", "Robert", ""]]}, {"id": "2008.13064", "submitter": "Md Rafiqul Islam Rabin", "authors": "Md Rafiqul Islam Rabin, Arjun Mukherjee, Omprakash Gnawali, Mohammad\n  Amin Alipour", "title": "Towards Demystifying Dimensions of Source Code Embeddings", "comments": "1st ACM SIGSOFT International Workshop on Representation Learning for\n  Software Engineering and Program Languages, Co-located with ESEC/FSE\n  (RL+SE&PL'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Source code representations are key in applying machine learning techniques\nfor processing and analyzing programs. A popular approach in representing\nsource code is neural source code embeddings that represents programs with\nhigh-dimensional vectors computed by training deep neural networks on a large\nvolume of programs. Although successful, there is little known about the\ncontents of these vectors and their characteristics. In this paper, we present\nour preliminary results towards better understanding the contents of code2vec\nneural source code embeddings. In particular, in a small case study, we use the\ncode2vec embeddings to create binary SVM classifiers and compare their\nperformance with the handcrafted features. Our results suggest that the\nhandcrafted features can perform very close to the highly-dimensional code2vec\nembeddings, and the information gains are more evenly distributed in the\ncode2vec embeddings compared to the handcrafted features. We also find that the\ncode2vec embeddings are more resilient to the removal of dimensions with low\ninformation gains than the handcrafted features. We hope our results serve a\nstepping stone toward principled analysis and evaluation of these code\nrepresentations.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 21:59:11 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 03:53:21 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2020 00:19:28 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Rabin", "Md Rafiqul Islam", ""], ["Mukherjee", "Arjun", ""], ["Gnawali", "Omprakash", ""], ["Alipour", "Mohammad Amin", ""]]}, {"id": "2008.13065", "submitter": "Elizabeth Cole", "authors": "Elizabeth K. Cole, John M. Pauly, Shreyas S. Vasanawala, Frank Ong", "title": "Unsupervised MRI Reconstruction with Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning-based image reconstruction methods have achieved promising\nresults across multiple MRI applications. However, most approaches require\nlarge-scale fully-sampled ground truth data for supervised training. Acquiring\nfully-sampled data is often either difficult or impossible, particularly for\ndynamic contrast enhancement (DCE), 3D cardiac cine, and 4D flow. We present a\ndeep learning framework for MRI reconstruction without any fully-sampled data\nusing generative adversarial networks. We test the proposed method in two\nscenarios: retrospectively undersampled fast spin echo knee exams and\nprospectively undersampled abdominal DCE. The method recovers more anatomical\nstructure compared to conventional methods.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 22:00:49 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Cole", "Elizabeth K.", ""], ["Pauly", "John M.", ""], ["Vasanawala", "Shreyas S.", ""], ["Ong", "Frank", ""]]}, {"id": "2008.13066", "submitter": "Won Chang", "authors": "Saumya Bhatnagar, Won Chang, Seonjin Kim Jiali Wang", "title": "Computer Model Calibration with Time Series Data using Deep Learning and\n  Quantile Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer models play a key role in many scientific and engineering problems.\nOne major source of uncertainty in computer model experiment is input parameter\nuncertainty. Computer model calibration is a formal statistical procedure to\ninfer input parameters by combining information from model runs and\nobservational data. The existing standard calibration framework suffers from\ninferential issues when the model output and observational data are\nhigh-dimensional dependent data such as large time series due to the difficulty\nin building an emulator and the non-identifiability between effects from input\nparameters and data-model discrepancy. To overcome these challenges we propose\na new calibration framework based on a deep neural network (DNN) with\nlong-short term memory layers that directly emulates the inverse relationship\nbetween the model output and input parameters. Adopting the 'learning with\nnoise' idea we train our DNN model to filter out the effects from data model\ndiscrepancy on input parameter inference. We also formulate a new way to\nconstruct interval predictions for DNN using quantile regression to quantify\nthe uncertainty in input parameter estimates. Through a simulation study and\nreal data application with WRF-hydro model we show that our approach can yield\naccurate point estimates and well calibrated interval estimates for input\nparameters.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 22:18:41 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 06:10:09 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Bhatnagar", "Saumya", ""], ["Chang", "Won", ""], ["Wang", "Seonjin Kim Jiali", ""]]}, {"id": "2008.13072", "submitter": "Kaiyang Li", "authors": "Kaiyang Li, Guangchun Luo, Yang Ye, Wei Li, Shihao Ji, Zhipeng Cai", "title": "Adversarial Privacy Preserving Graph Embedding against Inference Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the surge in popularity of Internet of Things (IoT), mobile\ndevices, social media, etc. has opened up a large source for graph data. Graph\nembedding has been proved extremely useful to learn low-dimensional feature\nrepresentations from graph structured data. These feature representations can\nbe used for a variety of prediction tasks from node classification to link\nprediction. However, existing graph embedding methods do not consider users'\nprivacy to prevent inference attacks. That is, adversaries can infer users'\nsensitive information by analyzing node representations learned from graph\nembedding algorithms. In this paper, we propose Adversarial Privacy Graph\nEmbedding (APGE), a graph adversarial training framework that integrates the\ndisentangling and purging mechanisms to remove users' private information from\nlearned node representations. The proposed method preserves the structural\ninformation and utility attributes of a graph while concealing users' private\nattributes from inference attacks. Extensive experiments on real-world graph\ndatasets demonstrate the superior performance of APGE compared to the\nstate-of-the-arts. Our source code can be found at\nhttps://github.com/uJ62JHD/Privacy-Preserving-Social-Network-Embedding.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 00:06:49 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Li", "Kaiyang", ""], ["Luo", "Guangchun", ""], ["Ye", "Yang", ""], ["Li", "Wei", ""], ["Ji", "Shihao", ""], ["Cai", "Zhipeng", ""]]}, {"id": "2008.13095", "submitter": "Michael Michelashvili", "authors": "Michael Michelashvili and Lior Wolf", "title": "Hierarchical Timbre-Painting and Articulation Generation", "comments": "accepted in Proc. of the 21st International Society for Music\n  Information Retrieval (ISMIR2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a fast and high-fidelity method for music generation, based on\nspecified f0 and loudness, such that the synthesized audio mimics the timbre\nand articulation of a target instrument. The generation process consists of\nlearned source-filtering networks, which reconstruct the signal at increasing\nresolutions. The model optimizes a multi-resolution spectral loss as the\nreconstruction loss, an adversarial loss to make the audio sound more\nrealistic, and a perceptual f0 loss to align the output to the desired input\npitch contour. The proposed architecture enables high-quality fitting of an\ninstrument, given a sample that can be as short as a few minutes, and the\nmethod demonstrates state-of-the-art timbre transfer capabilities. Code and\naudio samples are shared at https://github.com/mosheman5/timbre_painting.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 05:27:39 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 14:49:37 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Michelashvili", "Michael", ""], ["Wolf", "Lior", ""]]}, {"id": "2008.13099", "submitter": "Qingyun Sun", "authors": "Qingyun Sun, Hao Peng, Jianxin Li, Senzhang Wang, Xiangyu Dong,\n  Liangxuan Zhao, Philip S. Yu and Lifang He", "title": "Pairwise Learning for Name Disambiguation in Large-Scale Heterogeneous\n  Academic Networks", "comments": "accepted by ICDM 2020 as regular paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Name disambiguation aims to identify unique authors with the same name.\nExisting name disambiguation methods always exploit author attributes to\nenhance disambiguation results. However, some discriminative author attributes\n(e.g., email and affiliation) may change because of graduation or job-hopping,\nwhich will result in the separation of the same author's papers in digital\nlibraries. Although these attributes may change, an author's co-authors and\nresearch topics do not change frequently with time, which means that papers\nwithin a period have similar text and relation information in the academic\nnetwork. Inspired by this idea, we introduce Multi-view Attention-based\nPairwise Recurrent Neural Network (MA-PairRNN) to solve the name disambiguation\nproblem. We divided papers into small blocks based on discriminative author\nattributes and blocks of the same author will be merged according to pairwise\nclassification results of MA-PairRNN. MA-PairRNN combines heterogeneous graph\nembedding learning and pairwise similarity learning into a framework. In\naddition to attribute and structure information, MA-PairRNN also exploits\nsemantic information by meta-path and generates node representation in an\ninductive way, which is scalable to large graphs. Furthermore, a semantic-level\nattention mechanism is adopted to fuse multiple meta-path based\nrepresentations. A Pseudo-Siamese network consisting of two RNNs takes two\npaper sequences in publication time order as input and outputs their\nsimilarity. Results on two real-world datasets demonstrate that our framework\nhas a significant and consistent improvement of performance on the name\ndisambiguation task. It was also demonstrated that MA-PairRNN can perform well\nwith a small amount of training data and have better generalization ability\nacross different research areas.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 06:08:20 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 03:50:21 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2020 14:22:45 GMT"}, {"version": "v4", "created": "Wed, 20 Jan 2021 12:31:45 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Sun", "Qingyun", ""], ["Peng", "Hao", ""], ["Li", "Jianxin", ""], ["Wang", "Senzhang", ""], ["Dong", "Xiangyu", ""], ["Zhao", "Liangxuan", ""], ["Yu", "Philip S.", ""], ["He", "Lifang", ""]]}, {"id": "2008.13109", "submitter": "Shuqiang Wang", "authors": "Shuqiang Wang, Zhuo Chen, Wen Yu, Baiying Lei", "title": "Brain Stroke Lesion Segmentation Using Consistent Perception Generative\n  Adversarial Network", "comments": "11 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the state-of-the-art deep learning methods have demonstrated\nimpressive performance in segmentation tasks. However, the success of these\nmethods depends on a large amount of manually labeled masks, which are\nexpensive and time-consuming to be collected. To reduce the dependence on full\nlabeled samples, we propose a novel Consistent Perception Generative\nAdversarial Network (CPGAN) for semi-supervised stroke lesion segmentation.\nSpecifically, we design a non-local operation named similarity connection\nmodule (SCM) to capture the information of multi-scale features. This module\ncan selectively aggregate the features at each position by a weighted sum.\nFurthermore, an assistant network is constructed to encourage the discriminator\nto learn meaningful feature representations which are forgotten during\ntraining. The assistant network and the discriminator are used to jointly\ndecide whether the segmentation results are real or fake. With the\nsemi-supervised stroke lesion segmentation, we adopt a consistent perception\nstrategy to enhance the effect of brain stroke lesion prediction for the\nunlabeled data. The CPGAN was evaluated on the Anatomical Tracings of Lesions\nAfter Stroke (ATLAS). The experimental results demonstrate that the proposed\nnetwork achieves superior segmentation performance. In semi-supervised\nsegmentation task, our method using only two-fifths of labeled samples\noutperforms some approaches using full labeled samples.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 07:42:47 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Wang", "Shuqiang", ""], ["Chen", "Zhuo", ""], ["Yu", "Wen", ""], ["Lei", "Baiying", ""]]}, {"id": "2008.13114", "submitter": "Ali Nawaz", "authors": "Ali Nawaz, Attique Ur Rehman, Muhammad Abbas", "title": "A Novel Multiple Ensemble Learning Models Based on Different Datasets\n  for Software Defect Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software testing is one of the important ways to ensure the quality of\nsoftware. It is found that testing cost more than 50% of overall project cost.\nEffective and efficient software testing utilizes the minimum resources of\nsoftware. Therefore, it is important to construct the procedure which is not\nonly able to perform the efficient testing but also minimizes the utilization\nof project resources. The goal of software testing is to find maximum defects\nin the software system. More the defects found in the software ensure more\nefficiency is the software testing Different techniques have been proposed to\ndetect the defects in software and to utilize the resources and achieve good\nresults. As world is continuously moving toward data driven approach for making\nimportant decision. Therefore, in this research paper we performed the machine\nlearning analysis on the publicly available datasets and tried to achieve the\nmaximum accuracy. The major focus of the paper is to apply different machine\nlearning techniques on the datasets and find out which technique produce\nefficient result. Particularly, we proposed an ensemble learning models and\nperform comparative analysis among KNN, Decision tree, SVM and Na\\\"ive Bayes on\ndifferent datasets and it is demonstrated that performance of Ensemble method\nis more than other methods in term of accuracy, precision, recall and F1-score.\nThe classification accuracy of ensemble model trained on CM1 is 98.56%,\nclassification accuracy of ensemble model trained on KM2 is 98.18% similarly,\nthe classification accuracy of ensemble learning model trained on PC1 is\n99.27%. This reveals that Ensemble is more efficient method for making the\ndefect prediction as compared other techniques.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 08:01:39 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Nawaz", "Ali", ""], ["Rehman", "Attique Ur", ""], ["Abbas", "Muhammad", ""]]}, {"id": "2008.13117", "submitter": "Ali Nawaz", "authors": "Ali Nawaz, Attique Ur Rehman", "title": "Vehicle Route Prediction through Multiple Sensors Data Fusion", "comments": null, "journal-ref": "iKSP Journal of Computer Science and Engineering. 1, 2 (Feb.\n  2021), 01-08 (2021)", "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle route prediction is one of the significant tasks in vehicles\nmobility. It is one of the means to reduce the accidents and increase comfort\nin human life. The task of route prediction becomes simpler with the\ndevelopment of certain machine learning and deep learning libraries. Meanwhile,\nthe security and privacy issues are always lying in the vehicle communication\nas well as in route prediction. Therefore, we proposed a framework which will\nreduce these issues in vehicle communication and predict the route of vehicles\nin crossroads. Specifically, our proposed framework consists of two modules and\nboth are working in sequence. The first module of our framework using a deep\nlearning for recognizing the vehicle license plate number. Then, the second\nmodule using supervised learning algorithm of machine learning for predicting\nthe route of the vehicle by using velocity difference and previous mobility\npatterns as the features of machine learning algorithm. Experiment results\nshows that accuracy of our framework.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 08:14:11 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Nawaz", "Ali", ""], ["Rehman", "Attique Ur", ""]]}, {"id": "2008.13118", "submitter": "Islem Rekik", "authors": "Mert Lostar and Islem Rekik", "title": "Deep Hypergraph U-Net for Brain Graph Embedding and Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  -Background. Network neuroscience examines the brain as a complex system\nrepresented by a network (or connectome), providing deeper insights into the\nbrain morphology and function, allowing the identification of atypical brain\nconnectivity alterations, which can be used as diagnostic markers of\nneurological disorders. -Existing Methods. Graph embedding methods which map\ndata samples (e.g., brain networks) into a low dimensional space have been\nwidely used to explore the relationship between samples for classification or\nprediction tasks. However, the majority of these works are based on modeling\nthe pair-wise relationships between samples, failing to capture their\nhigher-order relationships. -New Method. In this paper, inspired by the nascent\nfield of geometric deep learning, we propose Hypergraph U-Net (HUNet), a novel\ndata embedding framework leveraging the hypergraph structure to learn\nlow-dimensional embeddings of data samples while capturing their high-order\nrelationships. Specifically, we generalize the U-Net architecture, naturally\noperating on graphs, to hypergraphs by improving local feature aggregation and\npreserving the high-order relationships present in the data. -Results. We\ntested our method on small-scale and large-scale heterogeneous brain\nconnectomic datasets including morphological and functional brain networks of\nautistic and demented patients, respectively. -Conclusion. Our HUNet\noutperformed state-of-the-art geometric graph and hypergraph data embedding\ntechniques with a gain of 4-14% in classification accuracy, demonstrating both\nscalability and generalizability. HUNet code is available at\nhttps://github.com/basiralab/HUNet.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 08:15:18 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Lostar", "Mert", ""], ["Rekik", "Islem", ""]]}, {"id": "2008.13122", "submitter": "Vincent Grari", "authors": "Vincent Grari, Sylvain Lamprier, Marcin Detyniecki", "title": "Adversarial Learning for Counterfactual Fairness", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, fairness has become an important topic in the machine\nlearning research community. In particular, counterfactual fairness aims at\nbuilding prediction models which ensure fairness at the most individual level.\nRather than globally considering equity over the entire population, the idea is\nto imagine what any individual would look like with a variation of a given\nattribute of interest, such as a different gender or race for instance.\nExisting approaches rely on Variational Auto-encoding of individuals, using\nMaximum Mean Discrepancy (MMD) penalization to limit the statistical dependence\nof inferred representations with their corresponding sensitive attributes. This\nenables the simulation of counterfactual samples used for training the target\nfair model, the goal being to produce similar outcomes for every alternate\nversion of any individual. In this work, we propose to rely on an adversarial\nneural learning approach, that enables more powerful inference than with MMD\npenalties, and is particularly better fitted for the continuous setting, where\nvalues of sensitive attributes cannot be exhaustively enumerated. Experiments\nshow significant improvements in term of counterfactual fairness for both the\ndiscrete and the continuous settings.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 09:06:03 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Grari", "Vincent", ""], ["Lamprier", "Sylvain", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2008.13128", "submitter": "Dachao Lin", "authors": "Dachao Lin, Peiqin Sun, Guangzeng Xie, Shuchang Zhou, Zhihua Zhang", "title": "Optimal Quantization for Batch Normalization in Neural Network\n  Deployments and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantized Neural Networks (QNNs) use low bit-width fixed-point numbers for\nrepresenting weight parameters and activations, and are often used in\nreal-world applications due to their saving of computation resources and\nreproducibility of results.\n  Batch Normalization (BN) poses a challenge for QNNs for requiring floating\npoints in reciprocal operations, and previous QNNs either require computing BN\nat high precision or revise BN to some variants in heuristic ways.\n  In this work, we propose a novel method to quantize BN by converting an\naffine transformation of two floating points to a fixed-point operation with\nshared quantized scale, which is friendly for hardware acceleration and model\ndeployment.\n  We confirm that our method maintains same outputs through rigorous\ntheoretical analysis and numerical analysis. Accuracy and efficiency of our\nquantization method are verified by experiments at layer level on CIFAR and\nImageNet datasets.\n  We also believe that our method is potentially useful in other problems\ninvolving quantization.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 09:33:29 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Lin", "Dachao", ""], ["Sun", "Peiqin", ""], ["Xie", "Guangzeng", ""], ["Zhou", "Shuchang", ""], ["Zhang", "Zhihua", ""]]}, {"id": "2008.13145", "submitter": "John Lawson", "authors": "John Lawson", "title": "Performance portability through machine learning guided kernel selection\n  in SYCL libraries", "comments": "13 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically tuning parallel compute kernels allows libraries and frameworks\nto achieve performance on a wide range of hardware, however these techniques\nare typically focused on finding optimal kernel parameters for particular input\nsizes and parameters. General purpose compute libraries must be able to cater\nto all inputs and parameters provided by a user, and so these techniques are of\nlimited use. Additionally, parallel programming frameworks such as SYCL require\nthat the kernels be deployed in a binary format embedded within the library. As\nsuch it is impractical to deploy a large number of possible kernel\nconfigurations without inflating the library size.\n  Machine learning methods can be used to mitigate against both of these\nproblems and provide performance for general purpose routines with a limited\nnumber of kernel configurations. We show that unsupervised clustering methods\ncan be used to select a subset of the possible kernels that should be deployed\nand that simple classification methods can be trained to select from these\nkernels at runtime to give good performance. As these techniques are fully\nautomated, relying only on benchmark data, the tuning process for new hardware\nor problems does not require any developer effort or expertise.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 11:44:37 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Lawson", "John", ""]]}, {"id": "2008.13160", "submitter": "Rabab Alkhalifa", "authors": "Rabab Alkhalifa, Theodore Yoong, Elena Kochkina, Arkaitz Zubiaga and\n  Maria Liakata", "title": "QMUL-SDS at CheckThat! 2020: Determining COVID-19 Tweet Check-Worthiness\n  Using an Enhanced CT-BERT with Numeric Expressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the participation of the QMUL-SDS team for Task 1 of the\nCLEF 2020 CheckThat! shared task. The purpose of this task is to determine the\ncheck-worthiness of tweets about COVID-19 to identify and prioritise tweets\nthat need fact-checking. The overarching aim is to further support ongoing\nefforts to protect the public from fake news and help people find reliable\ninformation. We describe and analyse the results of our submissions. We show\nthat a CNN using COVID-Twitter-BERT (CT-BERT) enhanced with numeric expressions\ncan effectively boost performance from baseline results. We also show results\nof training data augmentation with rumours on other topics. Our best system\nranked fourth in the task with encouraging outcomes showing potential for\nimproved results in the future.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 13:03:53 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Alkhalifa", "Rabab", ""], ["Yoong", "Theodore", ""], ["Kochkina", "Elena", ""], ["Zubiaga", "Arkaitz", ""], ["Liakata", "Maria", ""]]}, {"id": "2008.13162", "submitter": "Przemyslaw Biecek", "authors": "Wojciech Kretowicz, Przemys{\\l}aw Biecek", "title": "MementoML: Performance of selected machine learning algorithm\n  configurations on OpenML100 datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding optimal hyperparameters for the machine learning algorithm can often\nsignificantly improve its performance. But how to choose them in a\ntime-efficient way? In this paper we present the protocol of generating\nbenchmark data describing the performance of different ML algorithms with\ndifferent hyperparameter configurations. Data collected in this way is used to\nstudy the factors influencing the algorithm's performance.\n  This collection was prepared for the purposes of the study presented in the\nEPP study. We tested algorithms performance on dense grid of hyperparameters.\nTested datasets and hyperparameters were chosen before any algorithm has run\nand were not changed. This is a different approach than the one usually used in\nhyperparameter tuning, where the selection of candidate hyperparameters depends\non the results obtained previously. However, such selection allows for\nsystematic analysis of performance sensitivity from individual hyperparameters.\n  This resulted in a comprehensive dataset of such benchmarks that we would\nlike to share. We hope, that computed and collected result may be helpful for\nother researchers. This paper describes the way data was collected. Here you\ncan find benchmarks of 7 popular machine learning algorithms on 39 OpenML\ndatasets.\n  The detailed data forming this benchmark are available at:\nhttps://www.kaggle.com/mi2datalab/mementoml.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 13:13:52 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Kretowicz", "Wojciech", ""], ["Biecek", "Przemys\u0142aw", ""]]}, {"id": "2008.13176", "submitter": "Vipul Nair", "authors": "Vipul Nair, Paul Hemeren, Alessia Vignolo, Nicoletta Noceti, Elena\n  Nicora, Alessandra Sciutti, Francesco Rea, Erik Billing, Francesca Odone and\n  Giulio Sandini", "title": "Action similarity judgment based on kinematic primitives", "comments": "8 pages, 5 figures, 1 table, to be published in the Proceedings of\n  the 10th Joint IEEE International Conference on Development and Learning and\n  Epigenetic Robotics (ICDL-EpiRob 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding which features humans rely on -- in visually recognizing action\nsimilarity is a crucial step towards a clearer picture of human action\nperception from a learning and developmental perspective. In the present work,\nwe investigate to which extent a computational model based on kinematics can\ndetermine action similarity and how its performance relates to human similarity\njudgments of the same actions. To this aim, twelve participants perform an\naction similarity task, and their performances are compared to that of a\ncomputational model solving the same task. The chosen model has its roots in\ndevelopmental robotics and performs action classification based on learned\nkinematic primitives. The comparative experiment results show that both the\nmodel and human participants can reliably identify whether two actions are the\nsame or not. However, the model produces more false hits and has a greater\nselection bias than human participants. A possible reason for this is the\nparticular sensitivity of the model towards kinematic primitives of the\npresented actions. In a second experiment, human participants' performance on\nan action identification task indicated that they relied solely on kinematic\ninformation rather than on action semantics. The results show that both the\nmodel and human performance are highly accurate in an action similarity task\nbased on kinematic-level features, which can provide an essential basis for\nclassifying human actions.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 13:58:47 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Nair", "Vipul", ""], ["Hemeren", "Paul", ""], ["Vignolo", "Alessia", ""], ["Noceti", "Nicoletta", ""], ["Nicora", "Elena", ""], ["Sciutti", "Alessandra", ""], ["Rea", "Francesco", ""], ["Billing", "Erik", ""], ["Odone", "Francesca", ""], ["Sandini", "Giulio", ""]]}, {"id": "2008.13187", "submitter": "Yanan Sun", "authors": "Yanan Sun and Xian Sun and Yuhan Fang and Gary Yen", "title": "A Novel Training Protocol for Performance Predictors of Evolutionary\n  Neural Architecture Search Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary Neural Architecture Search (ENAS) can automatically design the\narchitectures of Deep Neural Networks (DNNs) using evolutionary computation\nalgorithms. However, most ENAS algorithms require intensive computational\nresource, which is not necessarily available to the users interested.\nPerformance predictors are a type of regression models which can assist to\naccomplish the search, while without exerting much computational resource.\nDespite various performance predictors have been designed, they employ the same\ntraining protocol to build the regression models: 1) sampling a set of DNNs\nwith performance as the training dataset, 2) training the model with the mean\nsquare error criterion, and 3) predicting the performance of DNNs newly\ngenerated during the ENAS. In this paper, we point out that the three steps\nconstituting the training protocol are not well though-out through intuitive\nand illustrative examples. Furthermore, we propose a new training protocol to\naddress these issues, consisting of designing a pairwise ranking indicator to\nconstruct the training target, proposing to use the logistic regression to fit\nthe training samples, and developing a differential method to building the\ntraining instances. To verify the effectiveness of the proposed training\nprotocol, four widely used regression models in the field of machine learning\nhave been chosen to perform the comparisons on two benchmark datasets. The\nexperimental results of all the comparisons demonstrate that the proposed\ntraining protocol can significantly improve the performance prediction accuracy\nagainst the traditional training protocols.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 14:39:28 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 06:22:28 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Sun", "Yanan", ""], ["Sun", "Xian", ""], ["Fang", "Yuhan", ""], ["Yen", "Gary", ""]]}, {"id": "2008.13210", "submitter": "Dimosthenis Pasadakis", "authors": "Dimosthenis Pasadakis, Christie Louis Alappat, Olaf Schenk, Gerhard\n  Wellein", "title": "$K$-way $p$-spectral clustering on Grassmann manifolds", "comments": "36 pages, 12 figures, 4 Tables. Submitted to the \"Journal of Machine\n  Learning Research\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral methods have gained a lot of recent attention due to the simplicity\nof their implementation and their solid mathematical background. We revisit\nspectral graph clustering, and reformulate in the $p$-norm the continuous\nproblem of minimizing the graph Laplacian Rayleigh quotient. The value of $p\n\\in (1,2]$ is reduced, promoting sparser solution vectors that correspond to\noptimal clusters as $p$ approaches one. The computation of multiple\n$p$-eigenvectors of the graph $p$-Laplacian, a nonlinear generalization of the\nstandard graph Laplacian, is achieved by the minimization of our objective\nfunction on the Grassmann manifold, hence ensuring the enforcement of the\northogonality constraint between them. Our approach attempts to bridge the\nfields of graph clustering and nonlinear numerical optimization, and employs a\nrobust algorithm to obtain clusters of high quality. The benefits of the\nsuggested method are demonstrated in a plethora of artificial and real-world\ngraphs. Our results are compared against standard spectral clustering methods\nand the current state-of-the-art algorithm for clustering using the graph\n$p$-Laplacian variant.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 16:25:04 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Pasadakis", "Dimosthenis", ""], ["Alappat", "Christie Louis", ""], ["Schenk", "Olaf", ""], ["Wellein", "Gerhard", ""]]}, {"id": "2008.13221", "submitter": "Vinicius G. Goecks", "authors": "Vinicius G. Goecks", "title": "Human-in-the-Loop Methods for Data-Driven and Reinforcement Learning\n  Systems", "comments": "PhD thesis, Aerospace Engineering, Texas A&M (2020). For more\n  information, see https://vggoecks.com/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent successes combine reinforcement learning algorithms and deep neural\nnetworks, despite reinforcement learning not being widely applied to robotics\nand real world scenarios. This can be attributed to the fact that current\nstate-of-the-art, end-to-end reinforcement learning approaches still require\nthousands or millions of data samples to converge to a satisfactory policy and\nare subject to catastrophic failures during training. Conversely, in real world\nscenarios and after just a few data samples, humans are able to either provide\ndemonstrations of the task, intervene to prevent catastrophic actions, or\nsimply evaluate if the policy is performing correctly. This research\ninvestigates how to integrate these human interaction modalities to the\nreinforcement learning loop, increasing sample efficiency and enabling\nreal-time reinforcement learning in robotics and real world scenarios. This\nnovel theoretical foundation is called Cycle-of-Learning, a reference to how\ndifferent human interaction modalities, namely, task demonstration,\nintervention, and evaluation, are cycled and combined to reinforcement learning\nalgorithms. Results presented in this work show that the reward signal that is\nlearned based upon human interaction accelerates the rate of learning of\nreinforcement learning algorithms and that learning from a combination of human\ndemonstrations and interventions is faster and more sample efficient when\ncompared to traditional supervised learning algorithms. Finally,\nCycle-of-Learning develops an effective transition between policies learned\nusing human demonstrations and interventions to reinforcement learning. The\ntheoretical foundation developed by this research opens new research paths to\nhuman-agent teaming scenarios where autonomous agents are able to learn from\nhuman teammates and adapt to mission performance metrics in real-time and in\nreal world scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 17:28:18 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Goecks", "Vinicius G.", ""]]}, {"id": "2008.13222", "submitter": "Shang-Yi Chuang", "authors": "Shang-Yi Chuang, Hsin-Min Wang and Yu Tsao", "title": "Improved Lite Audio-Visual Speech Enhancement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous studies have investigated the effectiveness of audio-visual\nmultimodal learning for speech enhancement (AVSE) tasks, seeking a solution\nthat uses visual data as auxiliary and complementary input to reduce the noise\nof noisy speech signals. Recently, we proposed a lite audio-visual speech\nenhancement (LAVSE) algorithm. Compared to conventional AVSE systems, LAVSE\nrequires less online computation and moderately solves the user privacy problem\non facial data. In this study, we extend LAVSE to improve its ability to\naddress three practical issues often encountered in implementing AVSE systems,\nnamely, the requirement for additional visual data, audio-visual\nasynchronization, and low-quality visual data. The proposed system is termed\nimproved LAVSE (iLAVSE), which uses a convolutional recurrent neural network\narchitecture as the core AVSE model. We evaluate iLAVSE on the Taiwan Mandarin\nspeech with video dataset. Experimental results confirm that compared to\nconventional AVSE systems, iLAVSE can effectively overcome the aforementioned\nthree practical issues and can improve enhancement performance. The results\nalso confirm that iLAVSE is suitable for real-world scenarios, where\nhigh-quality audio-visual sensors may not always be available.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 17:29:19 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 08:19:43 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Chuang", "Shang-Yi", ""], ["Wang", "Hsin-Min", ""], ["Tsao", "Yu", ""]]}, {"id": "2008.13223", "submitter": "Miriam Zacksenhouse Assoc. Prof.", "authors": "Oren Spector and Miriam Zacksenhouse", "title": "Deep Reinforcement Learning for Contact-Rich Skills Using Compliant\n  Movement Primitives", "comments": "27 pages, 10 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, industrial robots have been installed in various industries\nto handle advanced manufacturing and high precision tasks. However, further\nintegration of industrial robots is hampered by their limited flexibility,\nadaptability and decision making skills compared to human operators. Assembly\ntasks are especially challenging for robots since they are contact-rich and\nsensitive to even small uncertainties. While reinforcement learning (RL) offers\na promising framework to learn contact-rich control policies from scratch, its\napplicability to high-dimensional continuous state-action spaces remains rather\nlimited due to high brittleness and sample complexity. To address those issues,\nwe propose different pruning methods that facilitate convergence and\ngeneralization. In particular, we divide the task into free and contact-rich\nsub-tasks, perform the control in Cartesian rather than joint space, and\nparameterize the control policy. Those pruning methods are naturally\nimplemented within the framework of dynamic movement primitives (DMP). To\nhandle contact-rich tasks, we extend the DMP framework by introducing a\ncoupling term that acts like the human wrist and provides active compliance\nunder contact with the environment. We demonstrate that the proposed method can\nlearn insertion skills that are invariant to space, size, shape, and closely\nrelated scenarios, while handling large uncertainties. Finally we demonstrate\nthat the learned policy can be easily transferred from simulations to real\nworld and achieve similar performance on UR5e robot.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 17:29:43 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 17:47:42 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Spector", "Oren", ""], ["Zacksenhouse", "Miriam", ""]]}, {"id": "2008.13225", "submitter": "Tharun Kumar Reddy Medini", "authors": "Tharun Medini, Beidi Chen, Anshumali Shrivastava", "title": "SOLAR: Sparse Orthogonal Learned and Random Embeddings", "comments": "Under review at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense embedding models are commonly deployed in commercial search engines,\nwherein all the document vectors are pre-computed, and near-neighbor search\n(NNS) is performed with the query vector to find relevant documents. However,\nthe bottleneck of indexing a large number of dense vectors and performing an\nNNS hurts the query time and accuracy of these models. In this paper, we argue\nthat high-dimensional and ultra-sparse embedding is a significantly superior\nalternative to dense low-dimensional embedding for both query efficiency and\naccuracy. Extreme sparsity eliminates the need for NNS by replacing them with\nsimple lookups, while its high dimensionality ensures that the embeddings are\ninformative even when sparse. However, learning extremely high dimensional\nembeddings leads to blow up in the model size. To make the training feasible,\nwe propose a partitioning algorithm that learns such high dimensional\nembeddings across multiple GPUs without any communication. This is facilitated\nby our novel asymmetric mixture of Sparse, Orthogonal, Learned and Random\n(SOLAR) Embeddings. The label vectors are random, sparse, and near-orthogonal\nby design, while the query vectors are learned and sparse. We theoretically\nprove that our way of one-sided learning is equivalent to learning both query\nand label embeddings. With these unique properties, we can successfully train\n500K dimensional SOLAR embeddings for the tasks of searching through 1.6M books\nand multi-label classification on the three largest public datasets. We achieve\nsuperior precision and recall compared to the respective state-of-the-art\nbaselines for each of the tasks with up to 10 times faster speed.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 17:35:35 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Medini", "Tharun", ""], ["Chen", "Beidi", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "2008.13235", "submitter": "Yuyan Wang", "authors": "Benjamin Moseley, Yuyan Wang", "title": "An Objective for Hierarchical Clustering in Euclidean Space and its\n  Connection to Bisecting K-means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores hierarchical clustering in the case where pairs of points\nhave dissimilarity scores (e.g. distances) as a part of the input. The recently\nintroduced objective for points with dissimilarity scores results in every tree\nbeing a 1/2 approximation if the distances form a metric. This shows the\nobjective does not make a significant distinction between a good and poor\nhierarchical clustering in metric spaces. Motivated by this, the paper develops\na new global objective for hierarchical clustering in Euclidean space. The\nobjective captures the criterion that has motivated the use of divisive\nclustering algorithms: that when a split happens, points in the same cluster\nshould be more similar than points in different clusters. Moreover, this\nobjective gives reasonable results on ground-truth inputs for hierarchical\nclustering. The paper builds a theoretical connection between this objective\nand the bisecting k-means algorithm. This paper proves that the optimal 2-means\nsolution results in a constant approximation for the objective. This is the\nfirst paper to show the bisecting k-means algorithm optimizes a natural global\nobjective over the entire tree.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 18:17:46 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Moseley", "Benjamin", ""], ["Wang", "Yuyan", ""]]}, {"id": "2008.13261", "submitter": "Shoaib Ahmed Siddiqui", "authors": "Shoaib Ahmed Siddiqui, Andreas Dengel, Sheraz Ahmed", "title": "Benchmarking adversarial attacks and defenses for time-series data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The adversarial vulnerability of deep networks has spurred the interest of\nresearchers worldwide. Unsurprisingly, like images, adversarial examples also\ntranslate to time-series data as they are an inherent weakness of the model\nitself rather than the modality. Several attempts have been made to defend\nagainst these adversarial attacks, particularly for the visual modality. In\nthis paper, we perform detailed benchmarking of well-proven adversarial defense\nmethodologies on time-series data. We restrict ourselves to the $L_{\\infty}$\nthreat model. We also explore the trade-off between smoothness and clean\naccuracy for regularization-based defenses to better understand the trade-offs\nthat they offer. Our analysis shows that the explored adversarial defenses\noffer robustness against both strong white-box as well as black-box attacks.\nThis paves the way for future research in the direction of adversarial attacks\nand defenses, particularly for time-series data.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 20:03:35 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Siddiqui", "Shoaib Ahmed", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "2008.13265", "submitter": "Deepan Muthirayan", "authors": "Deepan Muthirayan and Pramod Khargonekar", "title": "A Meta-Learning Control Algorithm with Provable Finite-Time Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we provide provable regret guarantees for an online\nmeta-learning control algorithm in an iterative control setting, where in each\niteration the system to be controlled is a linear deterministic system that is\ndifferent and unknown, the cost for the controller in an iteration is a general\nadditive cost function and the control input is required to be constrained,\nwhich if violated incurs an additional cost. We prove (i) that the algorithm\nachieves a regret for the controller cost and constraint violation that are\n$O(T^{3/4})$ for an episode of duration $T$ with respect to the best policy\nthat satisfies the control input control constraints and (ii) that the average\nof the regret for the controller cost and constraint violation with respect to\nthe same policy vary as $O((1+\\log(N)/N)T^{3/4})$ with the number of iterations\n$N$, showing that the worst regret for the learning within an iteration\ncontinuously improves with experience of more iterations.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 20:30:40 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 21:04:18 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 01:32:32 GMT"}, {"version": "v4", "created": "Thu, 10 Sep 2020 22:18:33 GMT"}, {"version": "v5", "created": "Thu, 8 Oct 2020 20:47:57 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Muthirayan", "Deepan", ""], ["Khargonekar", "Pramod", ""]]}, {"id": "2008.13293", "submitter": "Akshay Balsubramani", "authors": "Akshay Balsubramani", "title": "Sharp finite-sample concentration of independent variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show an extension of Sanov's theorem on large deviations, controlling the\ntail probabilities of i.i.d. random variables with matching concentration and\nanti-concentration bounds. This result has a general scope, applies to samples\nof any size, and has a short information-theoretic proof using elementary\ntechniques.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 23:05:55 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 07:22:14 GMT"}, {"version": "v3", "created": "Sat, 17 Oct 2020 02:17:20 GMT"}, {"version": "v4", "created": "Fri, 20 Nov 2020 23:29:52 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Balsubramani", "Akshay", ""]]}, {"id": "2008.13294", "submitter": "Luiz Fernando Guedes Dos Santos", "authors": "Luiz F. G. dos Santos, Ayris Narock, Teresa Nieves-Chinchilla, Marlon\n  Nu\\~nez, Michael Kirk", "title": "Identifying Flux Rope Signatures Using a Deep Neural Network", "comments": "32 pages, 12 figures. This is a pre-print of an article published in\n  Solar Physics Journal", "journal-ref": null, "doi": "10.1007/s11207-020-01697-x", "report-no": null, "categories": "astro-ph.SR astro-ph.IM cs.LG physics.data-an physics.space-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the current challenges in Space Weather, one of the main ones is to\nforecast the internal magnetic configuration within Interplanetary Coronal Mass\nEjections (ICMEs). Currently, a monotonic and coherent magnetic configuration\nobserved is associated with the result of a spacecraft crossing a large flux\nrope with helical magnetic field lines topology. The classification of such an\narrangement is essential to predict geomagnetic disturbance. Thus, the\nclassification relies on the assumption that the ICME's internal structure is a\nwell organized magnetic flux rope. This paper applies machine learning and a\ncurrent physical flux rope analytical model to identify and further understand\nthe internal structures of ICMEs. We trained an image recognition artificial\nneural network with analytical flux rope data, generated from the range of many\npossible trajectories within a cylindrical (circular and elliptical\ncross-section) model. The trained network was then evaluated against the\nobserved ICMEs from WIND during 1995-2015.\n  The methodology developed in this paper can classify 84% of simple real cases\ncorrectly and has a 76% success rate when extended to a broader set with 5%\nnoise applied, although it does exhibit a bias in favor of positive flux rope\nclassification. As a first step towards a generalizable classification and\nparameterization tool, these results show promise. With further tuning and\nrefinement, our model presents a strong potential to evolve into a robust tool\nfor identifying flux rope configurations from in situ data.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 23:23:57 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Santos", "Luiz F. G. dos", ""], ["Narock", "Ayris", ""], ["Nieves-Chinchilla", "Teresa", ""], ["Nu\u00f1ez", "Marlon", ""], ["Kirk", "Michael", ""]]}, {"id": "2008.13298", "submitter": "Nirmit Desai", "authors": "Shalisha Witherspoon, Dean Steuer, Graham Bent, Nirmit Desai", "title": "SEEC: Semantic Vector Federation across Edge Computing Environments", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic vector embedding techniques have proven useful in learning semantic\nrepresentations of data across multiple domains. A key application enabled by\nsuch techniques is the ability to measure semantic similarity between given\ndata samples and find data most similar to a given sample. State-of-the-art\nembedding approaches assume all data is available on a single site. However, in\nmany business settings, data is distributed across multiple edge locations and\ncannot be aggregated due to a variety of constraints. Hence, the applicability\nof state-of-the-art embedding approaches is limited to freely shared datasets,\nleaving out applications with sensitive or mission-critical data. This paper\naddresses this gap by proposing novel unsupervised algorithms called\n\\emph{SEEC} for learning and applying semantic vector embedding in a variety of\ndistributed settings. Specifically, for scenarios where multiple edge locations\ncan engage in joint learning, we adapt the recently proposed federated learning\ntechniques for semantic vector embedding. Where joint learning is not possible,\nwe propose novel semantic vector translation algorithms to enable semantic\nquery across multiple edge locations, each with its own semantic vector-space.\nExperimental results on natural language as well as graph datasets show that\nthis may be a promising new direction.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 23:51:41 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Witherspoon", "Shalisha", ""], ["Steuer", "Dean", ""], ["Bent", "Graham", ""], ["Desai", "Nirmit", ""]]}, {"id": "2008.13306", "submitter": "Subhashis Hazarika", "authors": "Subhashis Hazarika, Ayan Biswas, Phillip J. Wolfram, Earl Lawrence,\n  Nathan Urban", "title": "Relationship-aware Multivariate Sampling Strategy for Scientific\n  Simulation Data", "comments": "To appear as IEEE Vis 2020 Shortpaper", "journal-ref": null, "doi": "10.1109/VIS47514.2020.00015", "report-no": "2020 IEEE Visualization Conference (VIS)", "categories": "cs.LG cs.GR cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing computational power of current supercomputers, the size\nof data produced by scientific simulations is rapidly growing. To reduce the\nstorage footprint and facilitate scalable post-hoc analyses of such scientific\ndata sets, various data reduction/summarization methods have been proposed over\nthe years. Different flavors of sampling algorithms exist to sample the\nhigh-resolution scientific data, while preserving important data properties\nrequired for subsequent analyses. However, most of these sampling algorithms\nare designed for univariate data and cater to post-hoc analyses of single\nvariables. In this work, we propose a multivariate sampling strategy which\npreserves the original variable relationships and enables different\nmultivariate analyses directly on the sampled data. Our proposed strategy\nutilizes principal component analysis to capture the variance of multivariate\ndata and can be built on top of any existing state-of-the-art sampling\nalgorithms for single variables. In addition, we also propose variants of\ndifferent data partitioning schemes (regular and irregular) to efficiently\nmodel the local multivariate relationships. Using two real-world multivariate\ndata sets, we demonstrate the efficacy of our proposed multivariate sampling\nstrategy with respect to its data reduction capabilities as well as the ease of\nperforming efficient post-hoc multivariate analyses.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 00:52:17 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Hazarika", "Subhashis", ""], ["Biswas", "Ayan", ""], ["Wolfram", "Phillip J.", ""], ["Lawrence", "Earl", ""], ["Urban", "Nathan", ""]]}, {"id": "2008.13319", "submitter": "Xiaoyu Chen", "authors": "Xiaoyu Chen, Jiachen Hu, Lihong Li, Liwei Wang", "title": "Efficient Reinforcement Learning in Factored MDPs with Application to\n  Constrained RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) in episodic, factored Markov decision processes\n(FMDPs) is studied. We propose an algorithm called FMDP-BF, which leverages the\nfactorization structure of FMDP. The regret of FMDP-BF is shown to be\nexponentially smaller than that of optimal algorithms designed for non-factored\nMDPs, and improves on the best previous result for FMDPs~\\citep{osband2014near}\nby a factored of $\\sqrt{H|\\mathcal{S}_i|}$, where $|\\mathcal{S}_i|$ is the\ncardinality of the factored state subspace and $H$ is the planning horizon. To\nshow the optimality of our bounds, we also provide a lower bound for FMDP,\nwhich indicates that our algorithm is near-optimal w.r.t. timestep $T$, horizon\n$H$ and factored state-action subspace cardinality. Finally, as an application,\nwe study a new formulation of constrained RL, known as RL with knapsack\nconstraints (RLwK), and provides the first sample-efficient algorithm based on\nFMDP-BF.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 02:20:41 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 07:09:43 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 01:58:03 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Chen", "Xiaoyu", ""], ["Hu", "Jiachen", ""], ["Li", "Lihong", ""], ["Wang", "Liwei", ""]]}, {"id": "2008.13336", "submitter": "Ali Borji", "authors": "Ali Borji", "title": "Shape Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans rely heavily on shape information to recognize objects. Conversely,\nconvolutional neural networks (CNNs) are biased more towards texture. This is\nperhaps the main reason why CNNs are vulnerable to adversarial examples. Here,\nwe explore how shape bias can be incorporated into CNNs to improve their\nrobustness. Two algorithms are proposed, based on the observation that edges\nare invariant to moderate imperceptible perturbations. In the first one, a\nclassifier is adversarially trained on images with the edge map as an\nadditional channel. At inference time, the edge map is recomputed and\nconcatenated to the image. In the second algorithm, a conditional GAN is\ntrained to translate the edge maps, from clean and/or perturbed images, into\nclean images. Inference is done over the generated image corresponding to the\ninput's edge map. Extensive experiments over 10 datasets demonstrate the\neffectiveness of the proposed algorithms against FGSM and $\\ell_\\infty$ PGD-40\nattacks. Further, we show that a) edge information can also benefit other\nadversarial training methods, and b) CNNs trained on edge-augmented inputs are\nmore robust against natural image corruptions such as motion blur, impulse\nnoise and JPEG compression, than CNNs trained solely on RGB images. From a\nbroader perspective, our study suggests that CNNs do not adequately account for\nimage structures that are crucial for robustness. Code is available\nat:~\\url{https://github.com/aliborji/Shapedefence.git}.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 03:23:59 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Borji", "Ali", ""]]}, {"id": "2008.13347", "submitter": "Ashiqur KhudaBukhsh Ashiqur Rahman KhudaBukhsh", "authors": "Ashiqur R. KhudaBukhsh, Shriphani Palakodety, Tom M. Mitchell", "title": "Discovering Bilingual Lexicons in Polyglot Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilingual lexicons and phrase tables are critical resources for modern\nMachine Translation systems. Although recent results show that without any seed\nlexicon or parallel data, highly accurate bilingual lexicons can be learned\nusing unsupervised methods, such methods rely on the existence of large, clean\nmonolingual corpora. In this work, we utilize a single Skip-gram model trained\non a multilingual corpus yielding polyglot word embeddings, and present a novel\nfinding that a surprisingly simple constrained nearest-neighbor sampling\ntechnique in this embedding space can retrieve bilingual lexicons, even in\nharsh social media data sets predominantly written in English and Romanized\nHindi and often exhibiting code switching. Our method does not require\nmonolingual corpora, seed lexicons, or any other such resources. Additionally,\nacross three European language pairs, we observe that polyglot word embeddings\nindeed learn a rich semantic representation of words and substantial bilingual\nlexicons can be retrieved using our constrained nearest neighbor sampling. We\ninvestigate potential reasons and downstream applications in settings spanning\nboth clean texts and noisy social media data sets, and in both resource-rich\nand under-resourced language pairs.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 03:57:50 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["KhudaBukhsh", "Ashiqur R.", ""], ["Palakodety", "Shriphani", ""], ["Mitchell", "Tom M.", ""]]}, {"id": "2008.13351", "submitter": "Yang Yang", "authors": "Yang Yang, Zhen-Qiang Sun, HengShu Zhu, Yanjie Fu, Hui Xiong, Jian\n  Yang", "title": "Learning Adaptive Embedding Considering Incremental Class", "comments": "15 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class-Incremental Learning (CIL) aims to train a reliable model with the\nstreaming data, which emerges unknown classes sequentially. Different from\ntraditional closed set learning, CIL has two main challenges: 1) Novel class\ndetection. The initial training data only contains incomplete classes, and\nstreaming test data will accept unknown classes. Therefore, the model needs to\nnot only accurately classify known classes, but also effectively detect unknown\nclasses; 2) Model expansion. After the novel classes are detected, the model\nneeds to be updated without re-training using entire previous data. However,\ntraditional CIL methods have not fully considered these two challenges, first,\nthey are always restricted to single novel class detection each phase and\nembedding confusion caused by unknown classes. Besides, they also ignore the\ncatastrophic forgetting of known categories in model update. To this end, we\npropose a Class-Incremental Learning without Forgetting (CILF) framework, which\naims to learn adaptive embedding for processing novel class detection and model\nupdate in a unified framework. In detail, CILF designs to regularize\nclassification with decoupled prototype based loss, which can improve the\nintra-class and inter-class structure significantly, and acquire a compact\nembedding representation for novel class detection in result. Then, CILF\nemploys a learnable curriculum clustering operator to estimate the number of\nsemantic clusters via fine-tuning the learned network, in which curriculum\noperator can adaptively learn the embedding in self-taught form. Therefore,\nCILF can detect multiple novel classes and mitigate the embedding confusion\nproblem. Last, with the labeled streaming test data, CILF can update the\nnetwork with robust regularization to mitigate the catastrophic forgetting.\nConsequently, CILF is able to iteratively perform novel class detection and\nmodel update.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 04:11:24 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Yang", "Yang", ""], ["Sun", "Zhen-Qiang", ""], ["Zhu", "HengShu", ""], ["Fu", "Yanjie", ""], ["Xiong", "Hui", ""], ["Yang", "Jian", ""]]}, {"id": "2008.13361", "submitter": "Zhiwei Wang", "authors": "Zhiwei Wang, Zhengzhang Chen, Jingchao Ni, Hui Liu, Haifeng Chen,\n  Jiliang Tang", "title": "Multi-Scale One-Class Recurrent Neural Networks for Discrete Event\n  Sequence Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete event sequences are ubiquitous, such as an ordered event series of\nprocess interactions in Information and Communication Technology systems.\nRecent years have witnessed increasing efforts in detecting anomalies with\ndiscrete-event sequences. However, it still remains an extremely difficult task\ndue to several intrinsic challenges including data imbalance issues, the\ndiscrete property of the events, and sequential nature of the data. To address\nthese challenges, in this paper, we propose OC4Seq, a multi-scale one-class\nrecurrent neural network for detecting anomalies in discrete event sequences.\nSpecifically, OC4Seq integrates the anomaly detection objective with recurrent\nneural networks (RNNs) to embed the discrete event sequences into latent\nspaces, where anomalies can be easily detected. In addition, given that an\nanomalous sequence could be caused by either individual events, subsequences of\nevents, or the whole sequence, we design a multi-scale RNN framework to capture\ndifferent levels of sequential patterns simultaneously. Experimental results on\nthree benchmark datasets show that OC4Seq consistently outperforms various\nrepresentative baselines by a large margin. Moreover, through both quantitative\nand qualitative analysis, the importance of capturing multi-scale sequential\npatterns for event anomaly detection is verified.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 04:48:22 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Wang", "Zhiwei", ""], ["Chen", "Zhengzhang", ""], ["Ni", "Jingchao", ""], ["Liu", "Hui", ""], ["Chen", "Haifeng", ""], ["Tang", "Jiliang", ""]]}, {"id": "2008.13363", "submitter": "Harsh Mehta", "authors": "Harsh Mehta, Ashok Cutkosky, Behnam Neyshabur", "title": "Extreme Memorization via Scale of Initialization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct an experimental setup in which changing the scale of\ninitialization strongly impacts the implicit regularization induced by SGD,\ninterpolating from good generalization performance to completely memorizing the\ntraining set while making little progress on the test set. Moreover, we find\nthat the extent and manner in which generalization ability is affected depends\non the activation and loss function used, with $\\sin$ activation demonstrating\nextreme memorization. In the case of the homogeneous ReLU activation, we show\nthat this behavior can be attributed to the loss function. Our empirical\ninvestigation reveals that increasing the scale of initialization correlates\nwith misalignment of representations and gradients across examples in the same\nclass. This insight allows us to devise an alignment measure over gradients and\nrepresentations which can capture this phenomenon. We demonstrate that our\nalignment measure correlates with generalization of deep models trained on\nimage classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 04:53:11 GMT"}, {"version": "v2", "created": "Sat, 1 May 2021 22:09:15 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Mehta", "Harsh", ""], ["Cutkosky", "Ashok", ""], ["Neyshabur", "Behnam", ""]]}, {"id": "2008.13369", "submitter": "Leena Mathur", "authors": "Leena Mathur and Maja J Matari\\'c", "title": "Introducing Representations of Facial Affect in Automated Multimodal\n  Deception Detection", "comments": "10 pages, Accepted at ACM International Conference on Multimodal\n  Interaction (ICMI), October 2020", "journal-ref": "Proceedings of the 2020 International Conference on Multimodal\n  Interaction (ICMI)", "doi": "10.1145/3382507.3418864", "report-no": null, "categories": "cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated deception detection systems can enhance health, justice, and\nsecurity in society by helping humans detect deceivers in high-stakes\nsituations across medical and legal domains, among others. This paper presents\na novel analysis of the discriminative power of dimensional representations of\nfacial affect for automated deception detection, along with interpretable\nfeatures from visual, vocal, and verbal modalities. We used a video dataset of\npeople communicating truthfully or deceptively in real-world, high-stakes\ncourtroom situations. We leveraged recent advances in automated emotion\nrecognition in-the-wild by implementing a state-of-the-art deep neural network\ntrained on the Aff-Wild database to extract continuous representations of\nfacial valence and facial arousal from speakers. We experimented with unimodal\nSupport Vector Machines (SVM) and SVM-based multimodal fusion methods to\nidentify effective features, modalities, and modeling approaches for detecting\ndeception. Unimodal models trained on facial affect achieved an AUC of 80%, and\nfacial affect contributed towards the highest-performing multimodal approach\n(adaptive boosting) that achieved an AUC of 91% when tested on speakers who\nwere not part of training sets. This approach achieved a higher AUC than\nexisting automated machine learning approaches that used interpretable visual,\nvocal, and verbal features to detect deception in this dataset, but did not use\nfacial affect. Across all videos, deceptive and truthful speakers exhibited\nsignificant differences in facial valence and facial arousal, contributing\ncomputational support to existing psychological theories on affect and\ndeception. The demonstrated importance of facial affect in our models informs\nand motivates the future development of automated, affect-aware machine\nlearning approaches for modeling and detecting deception and other social\nbehaviors in-the-wild.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 05:12:57 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Mathur", "Leena", ""], ["Matari\u0107", "Maja J", ""]]}, {"id": "2008.13374", "submitter": "Neha Gupta", "authors": "Arturs Backurs, Avrim Blum, Neha Gupta", "title": "Active Local Learning", "comments": "Published at COLT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider active local learning: given a query point $x$, and\nactive access to an unlabeled training set $S$, output the prediction $h(x)$ of\na near-optimal $h \\in H$ using significantly fewer labels than would be needed\nto actually learn $h$ fully. In particular, the number of label queries should\nbe independent of the complexity of $H$, and the function $h$ should be\nwell-defined, independent of $x$. This immediately also implies an algorithm\nfor distance estimation: estimating the value $opt(H)$ from many fewer labels\nthan needed to actually learn a near-optimal $h \\in H$, by running local\nlearning on a few random query points and computing the average error.\n  For the hypothesis class consisting of functions supported on the interval\n$[0,1]$ with Lipschitz constant bounded by $L$, we present an algorithm that\nmakes $O(({1 / \\epsilon^6}) \\log(1/\\epsilon))$ label queries from an unlabeled\npool of $O(({L / \\epsilon^4})\\log(1/\\epsilon))$ samples. It estimates the\ndistance to the best hypothesis in the class to an additive error of $\\epsilon$\nfor an arbitrary underlying distribution. We further generalize our algorithm\nto more than one dimensions. We emphasize that the number of labels used is\nindependent of the complexity of the hypothesis class which depends on $L$.\nFurthermore, we give an algorithm to locally estimate the values of a\nnear-optimal function at a few query points of interest with number of labels\nindependent of $L$.\n  We also consider the related problem of approximating the minimum error that\ncan be achieved by the Nadaraya-Watson estimator under a linear diagonal\ntransformation with eigenvalues coming from a small range. For a\n$d$-dimensional pointset of size $N$, our algorithm achieves an additive\napproximation of $\\epsilon$, makes $\\tilde{O}({d}/{\\epsilon^2})$ queries and\nruns in $\\tilde{O}({d^2}/{\\epsilon^{d+4}}+{dN}/{\\epsilon^2})$ time.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 05:39:35 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 02:58:39 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Backurs", "Arturs", ""], ["Blum", "Avrim", ""], ["Gupta", "Neha", ""]]}, {"id": "2008.13412", "submitter": "Patrick Schwab", "authors": "Patrick Schwab, Arash Mehrjou, Sonali Parbhoo, Leo Anthony Celi,\n  J\\\"urgen Hetzel, Markus Hofer, Bernhard Sch\\\"olkopf, Stefan Bauer", "title": "Real-time Prediction of COVID-19 related Mortality using Electronic\n  Health Records", "comments": null, "journal-ref": null, "doi": "10.1038/s41467-020-20816-7", "report-no": null, "categories": "stat.AP cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coronavirus Disease 2019 (COVID-19) is an emerging respiratory disease caused\nby the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) with rapid\nhuman-to-human transmission and a high case fatality rate particularly in older\npatients. Due to the exponential growth of infections, many healthcare systems\nacross the world are under pressure to care for increasing amounts of at-risk\npatients. Given the high number of infected patients, identifying patients with\nthe highest mortality risk early is critical to enable effective intervention\nand optimal prioritisation of care. Here, we present the COVID-19 Early Warning\nSystem (CovEWS), a clinical risk scoring system for assessing COVID-19 related\nmortality risk. CovEWS provides continuous real-time risk scores for individual\npatients with clinically meaningful predictive performance up to 192 hours (8\ndays) in advance, and is automatically derived from patients' electronic health\nrecords (EHRs) using machine learning. We trained and evaluated CovEWS using\nde-identified data from a cohort of 66430 COVID-19 positive patients seen at\nover 69 healthcare institutions in the United States (US), Australia, Malaysia\nand India amounting to an aggregated total of over 2863 years of patient\nobservation time. On an external test cohort of 5005 patients, CovEWS predicts\nCOVID-19 related mortality from $78.8\\%$ ($95\\%$ confidence interval [CI]:\n$76.0$, $84.7\\%$) to $69.4\\%$ ($95\\%$ CI: $57.6, 75.2\\%$) specificity at a\nsensitivity greater than $95\\%$ between respectively 1 and 192 hours prior to\nobserved mortality events - significantly outperforming existing generic and\nCOVID-19 specific clinical risk scores. CovEWS could enable clinicians to\nintervene at an earlier stage, and may therefore help in preventing or\nmitigating COVID-19 related mortality.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 08:07:27 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Schwab", "Patrick", ""], ["Mehrjou", "Arash", ""], ["Parbhoo", "Sonali", ""], ["Celi", "Leo Anthony", ""], ["Hetzel", "J\u00fcrgen", ""], ["Hofer", "Markus", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Bauer", "Stefan", ""]]}, {"id": "2008.13429", "submitter": "Zhao Kang", "authors": "Zhao Kang and Chong Peng and Qiang Cheng and Xinwang Liu and Xi Peng\n  and Zenglin Xu and Ling Tian", "title": "Structured Graph Learning for Clustering and Semi-supervised\n  Classification", "comments": "Appear in Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs have become increasingly popular in modeling structures and\ninteractions in a wide variety of problems during the last decade. Graph-based\nclustering and semi-supervised classification techniques have shown impressive\nperformance. This paper proposes a graph learning framework to preserve both\nthe local and global structure of data. Specifically, our method uses the\nself-expressiveness of samples to capture the global structure and adaptive\nneighbor approach to respect the local structure. Furthermore, most existing\ngraph-based methods conduct clustering and semi-supervised classification on\nthe graph learned from the original data matrix, which doesn't have explicit\ncluster structure, thus they might not achieve the optimal performance. By\nconsidering rank constraint, the achieved graph will have exactly $c$ connected\ncomponents if there are $c$ clusters or classes. As a byproduct of this, graph\nlearning and label inference are jointly and iteratively implemented in a\nprincipled way. Theoretically, we show that our model is equivalent to a\ncombination of kernel k-means and k-means methods under certain condition.\nExtensive experiments on clustering and semi-supervised classification\ndemonstrate that the proposed method outperforms other state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 08:41:20 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Kang", "Zhao", ""], ["Peng", "Chong", ""], ["Cheng", "Qiang", ""], ["Liu", "Xinwang", ""], ["Peng", "Xi", ""], ["Xu", "Zenglin", ""], ["Tian", "Ling", ""]]}, {"id": "2008.13443", "submitter": "Inon Peled", "authors": "Inon Peled, Kelvin Lee, Yu Jiang, Justin Dauwels, Francisco C. Pereira", "title": "Curb Your Normality: On the Quality Requirements of Demand Prediction\n  for Dynamic Public Transport", "comments": "10 pages, 9 tables, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Public Transport (PT) becomes more dynamic and demand-responsive, it\nincreasingly depends on predictions of transport demand. But how accurate need\nsuch predictions be for effective PT operation? We address this question\nthrough an experimental case study of PT trips in Metropolitan Copenhagen,\nDenmark, which we conduct independently of any specific prediction models.\nFirst, we simulate errors in demand prediction through unbiased noise\ndistributions that vary considerably in shape. Using the noisy predictions, we\nthen simulate and optimize demand-responsive PT fleets via a commonly used\nlinear programming formulation and measure their performance. Our results\nsuggest that the optimized performance is mainly affected by the skew of the\nnoise distribution and the presence of infrequently large prediction errors. In\nparticular, the optimized performance can improve under non-Gaussian vs.\nGaussian noise. We also obtain that dynamic routing can reduce trip time by at\nleast 23% vs. static routing. This reduction is estimated at 809,000 EUR per\nyear in terms of Value of Travel Time Savings for the case study.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 09:05:05 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 09:16:06 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Peled", "Inon", ""], ["Lee", "Kelvin", ""], ["Jiang", "Yu", ""], ["Dauwels", "Justin", ""], ["Pereira", "Francisco C.", ""]]}, {"id": "2008.13454", "submitter": "Maximilian M\\\"unch", "authors": "Maximilian M\\\"unch and Michiel Straat and Michael Biehl and\n  Frank-Michael Schleif", "title": "Complex-valued embeddings of generic proximity data", "comments": "Proximity learning, embedding, complex values, complex-valued\n  embedding, learning vector quantization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proximities are at the heart of almost all machine learning methods. If the\ninput data are given as numerical vectors of equal lengths, euclidean distance,\nor a Hilbertian inner product is frequently used in modeling algorithms. In a\nmore generic view, objects are compared by a (symmetric) similarity or\ndissimilarity measure, which may not obey particular mathematical properties.\nThis renders many machine learning methods invalid, leading to convergence\nproblems and the loss of guarantees, like generalization bounds. In many cases,\nthe preferred dissimilarity measure is not metric, like the earth mover\ndistance, or the similarity measure may not be a simple inner product in a\nHilbert space but in its generalization a Krein space. If the input data are\nnon-vectorial, like text sequences, proximity-based learning is used or ngram\nembedding techniques can be applied. Standard embeddings lead to the desired\nfixed-length vector encoding, but are costly and have substantial limitations\nin preserving the original data's full information. As an information\npreserving alternative, we propose a complex-valued vector embedding of\nproximity data. This allows suitable machine learning algorithms to use these\nfixed-length, complex-valued vectors for further processing. The complex-valued\ndata can serve as an input to complex-valued machine learning algorithms. In\nparticular, we address supervised learning and use extensions of\nprototype-based learning. The proposed approach is evaluated on a variety of\nstandard benchmarks and shows strong performance compared to traditional\ntechniques in processing non-metric or non-psd proximity data.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 09:40:30 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["M\u00fcnch", "Maximilian", ""], ["Straat", "Michiel", ""], ["Biehl", "Michael", ""], ["Schleif", "Frank-Michael", ""]]}, {"id": "2008.13485", "submitter": "Andrea Valenti", "authors": "Andrea Valenti, Michele Barsotti, Raffaello Brondi, Davide Bacciu,\n  Luca Ascari", "title": "ROS-Neuro Integration of Deep Convolutional Autoencoders for EEG Signal\n  Compression in Real-time BCIs", "comments": "Accepted at the IEEE International Conference on Systems, Man, and\n  Cybernetics (SMC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical EEG-based BCI applications require the computation of complex\nfunctions over the noisy EEG channels to be carried out in an efficient way.\nDeep learning algorithms are capable of learning flexible nonlinear functions\ndirectly from data, and their constant processing latency is perfect for their\ndeployment into online BCI systems. However, it is crucial for the jitter of\nthe processing system to be as low as possible, in order to avoid unpredictable\nbehaviour that can ruin the system's overall usability. In this paper, we\npresent a novel encoding method, based on on deep convolutional autoencoders,\nthat is able to perform efficient compression of the raw EEG inputs. We deploy\nour model in a ROS-Neuro node, thus making it suitable for the integration in\nROS-based BCI and robotic systems in real world scenarios. The experimental\nresults show that our system is capable to generate meaningful compressed\nencoding preserving to original information contained in the raw input. They\nalso show that the ROS-Neuro node is able to produce such encodings at a steady\nrate, with minimal jitter. We believe that our system can represent an\nimportant step towards the development of an effective BCI processing pipeline\nfully standardized in ROS-Neuro framework.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 10:58:45 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Valenti", "Andrea", ""], ["Barsotti", "Michele", ""], ["Brondi", "Raffaello", ""], ["Bacciu", "Davide", ""], ["Ascari", "Luca", ""]]}, {"id": "2008.13492", "submitter": "Henrik Hellstr\\\"om", "authors": "Henrik Hellstr\\\"om, Jos\\'e Mairton B. da Silva Jr, Viktoria Fodor and\n  Carlo Fischione", "title": "Wireless for Machine Learning", "comments": "Corrected typo in author name. From the incorrect Maitron to the\n  correct Mairton", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As data generation increasingly takes place on devices without a wired\nconnection, Machine Learning over wireless networks becomes critical. Many\nstudies have shown that traditional wireless protocols are highly inefficient\nor unsustainable to support Distributed Machine Learning. This is creating the\nneed for new wireless communication methods. In this survey, we give an\nexhaustive review of the state of the art wireless methods that are\nspecifically designed to support Machine Learning services. Namely,\nover-the-air computation and radio resource allocation optimized for Machine\nLearning. In the over-the-air approach, multiple devices communicate\nsimultaneously over the same time slot and frequency band to exploit the\nsuperposition property of wireless channels for gradient averaging\nover-the-air. In radio resource allocation optimized for Machine Learning,\nActive Learning metrics allow for data evaluation to greatly optimize the\nassignment of radio resources. This paper gives a comprehensive introduction to\nthese methods, reviews the most important works, and highlights crucial open\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 11:09:49 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 11:22:32 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Hellstr\u00f6m", "Henrik", ""], ["Silva", "Jos\u00e9 Mairton B. da", "Jr"], ["Fodor", "Viktoria", ""], ["Fischione", "Carlo", ""]]}, {"id": "2008.13516", "submitter": "Dilruk Perera", "authors": "Dilruk Perera and Roger Zimmermann", "title": "Towards Comprehensive Recommender Systems: Time-Aware\n  UnifiedcRecommendations Based on Listwise Ranking of Implicit Cross-Network\n  Data", "comments": null, "journal-ref": "Association for the Advancement of Artificial Intelligence, 2020\n  (AAAI'20)", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The abundance of information in web applications make recommendation\nessential for users as well as applications. Despite the effectiveness of\nexisting recommender systems, we find two major limitations that reduce their\noverall performance: (1) inability to provide timely recommendations for both\nnew and existing users by considering the dynamic nature of user preferences,\nand (2) not fully optimized for the ranking task when using implicit feedback.\nTherefore, we propose a novel deep learning based unified cross-network\nsolution to mitigate cold-start and data sparsity issues and provide timely\nrecommendations for new and existing users.Furthermore, we consider the ranking\nproblem under implicit feedback as a classification task, and propose a generic\npersonalized listwise optimization criterion for implicit data to effectively\nrank a list of items. We illustrate our cross-network model using Twitter\nauxiliary information for recommendations on YouTube target network. Extensive\ncomparisons against multiple time aware and cross-network base-lines show that\nthe proposed solution is superior in terms of accuracy, novelty and diversity.\nFurthermore, experiments conducted on the popular MovieLens dataset suggest\nthat the proposed listwise ranking method outperforms existing state-of-the-art\nranking techniques.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 08:08:03 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Perera", "Dilruk", ""], ["Zimmermann", "Roger", ""]]}, {"id": "2008.13517", "submitter": "Yishi Xu", "authors": "Yishi Xu, Yingxue Zhang, Wei Guo, Huifeng Guo, Ruiming Tang, Mark\n  Coates", "title": "GraphSAIL: Graph Structure Aware Incremental Learning for Recommender\n  Systems", "comments": "Accepted by CIKM2020 Applied Research Track", "journal-ref": null, "doi": "10.1145/3340531.3412754", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the convenience of collecting information through online services,\nrecommender systems now consume large scale data and play a more important role\nin improving user experience. With the recent emergence of Graph Neural\nNetworks (GNNs), GNN-based recommender models have shown the advantage of\nmodeling the recommender system as a user-item bipartite graph to learn\nrepresentations of users and items. However, such models are expensive to train\nand difficult to perform frequent updates to provide the most up-to-date\nrecommendations. In this work, we propose to update GNN-based recommender\nmodels incrementally so that the computation time can be greatly reduced and\nmodels can be updated more frequently. We develop a Graph Structure Aware\nIncremental Learning framework, GraphSAIL, to address the commonly experienced\ncatastrophic forgetting problem that occurs when training a model in an\nincremental fashion. Our approach preserves a user's long-term preference (or\nan item's long-term property) during incremental model updating. GraphSAIL\nimplements a graph structure preservation strategy which explicitly preserves\neach node's local structure, global structure, and self-information,\nrespectively. We argue that our incremental training framework is the first\nattempt tailored for GNN based recommender systems and demonstrate its\nimprovement compared to other incremental learning techniques on two public\ndatasets. We further verify the effectiveness of our framework on a large-scale\nindustrial dataset.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 04:33:59 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 02:56:15 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Xu", "Yishi", ""], ["Zhang", "Yingxue", ""], ["Guo", "Wei", ""], ["Guo", "Huifeng", ""], ["Tang", "Ruiming", ""], ["Coates", "Mark", ""]]}, {"id": "2008.13526", "submitter": "Sami Khenissi", "authors": "Sami Khenissi and Mariem Boujelbene and Olfa Nasraoui", "title": "Theoretical Modeling of the Iterative Properties of User Discovery in a\n  Collaborative Filtering Recommender System", "comments": "Accepted in Recsys2020. Code available at:\n  https://github.com/samikhenissi/TheoretUserModeling", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The closed feedback loop in recommender systems is a common setting that can\nlead to different types of biases. Several studies have dealt with these biases\nby designing methods to mitigate their effect on the recommendations. However,\nmost existing studies do not consider the iterative behavior of the system\nwhere the closed feedback loop plays a crucial role in incorporating different\nbiases into several parts of the recommendation steps.\n  We present a theoretical framework to model the asymptotic evolution of the\ndifferent components of a recommender system operating within a feedback loop\nsetting, and derive theoretical bounds and convergence properties on\nquantifiable measures of the user discovery and blind spots. We also validate\nour theoretical findings empirically using a real-life dataset and empirically\ntest the efficiency of a basic exploration strategy within our theoretical\nframework.\n  Our findings lay the theoretical basis for quantifying the effect of feedback\nloops and for designing Artificial Intelligence and machine learning algorithms\nthat explicitly incorporate the iterative nature of feedback loops in the\nmachine learning and recommendation process.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 20:30:39 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Khenissi", "Sami", ""], ["Boujelbene", "Mariem", ""], ["Nasraoui", "Olfa", ""]]}, {"id": "2008.13527", "submitter": "Zhimeng Pan", "authors": "Zhimeng Pan, Wenzheng Tao, Qingyao Ai", "title": "Review Regularized Neural Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, text-aware collaborative filtering methods have been\nproposed to address essential challenges in recommendations such as data\nsparsity, cold start problem, and long-tail distribution. However, many of\nthese text-oriented methods rely heavily on the availability of text\ninformation for every user and item, which obviously does not hold in\nreal-world scenarios. Furthermore, specially designed network structures for\ntext processing are highly inefficient for on-line serving and are hard to\nintegrate into current systems. In this paper, we propose a flexible neural\nrecommendation framework, named Review Regularized Recommendation, short as R3.\nIt consists of a neural collaborative filtering part that focuses on prediction\noutput, and a text processing part that serves as a regularizer. This modular\ndesign incorporates text information as richer data sources in the training\nphase while being highly friendly for on-line serving as it needs no on-the-fly\ntext processing in serving time. Our preliminary results show that by using a\nsimple text processing approach, it could achieve better prediction performance\nthan state-of-the-art text-aware methods.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 18:54:27 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Pan", "Zhimeng", ""], ["Tao", "Wenzheng", ""], ["Ai", "Qingyao", ""]]}, {"id": "2008.13528", "submitter": "Scott Graham", "authors": "Scott Graham, Jun-Ki Min and Tao Wu", "title": "Microsoft Recommenders: Tools to Accelerate Developing Recommender\n  Systems", "comments": "pages: 2; submitted to: RecSys '19", "journal-ref": "Proceedings of the 13th ACM Conference on Recommender Systems\n  (2019)", "doi": "10.1145/3298689.3346967", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this work is to highlight the content of the Microsoft\nRecommenders repository and show how it can be used to reduce the time involved\nin developing recommender systems. The open source repository provides python\nutilities to simplify common recommender-related data science work as well as\nexample Jupyter notebooks that demonstrate use of the algorithms and tools\nunder various environments.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 00:25:19 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Graham", "Scott", ""], ["Min", "Jun-Ki", ""], ["Wu", "Tao", ""]]}, {"id": "2008.13532", "submitter": "Rohan Anand", "authors": "Rohan Anand and Joeran Beel", "title": "Auto-Surprise: An Automated Recommender-System (AutoRecSys) Library with\n  Tree of Parzens Estimator (TPE) Optimization", "comments": "To be presented at RecSys '20 Fourteenth ACM Conference on\n  Recommender Systems, September 21-26, 2020, Virtual Event", "journal-ref": null, "doi": "10.1145/3383313.3411467", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Auto-Surprise, an Automated Recommender System library.\nAuto-Surprise is an extension of the Surprise recommender system library and\neases the algorithm selection and configuration process. Compared to\nout-of-the-box Surprise library, Auto-Surprise performs better when evaluated\nwith MovieLens, Book Crossing and Jester Datasets. It may also result in the\nselection of an algorithm with significantly lower runtime. Compared to\nSurprise's grid search, Auto-Surprise performs equally well or slightly better\nin terms of RMSE, and is notably faster in finding the optimum hyperparameters.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 08:29:27 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Anand", "Rohan", ""], ["Beel", "Joeran", ""]]}, {"id": "2008.13533", "submitter": "Dara Bahri", "authors": "Dara Bahri, Yi Tay, Che Zheng, Donald Metzler, Cliff Brunk, Andrew\n  Tomkins", "title": "Generative Models are Unsupervised Predictors of Page Quality: A\n  Colossal-Scale Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large generative language models such as GPT-2 are well-known for their\nability to generate text as well as their utility in supervised downstream\ntasks via fine-tuning. Our work is twofold: firstly we demonstrate via human\nevaluation that classifiers trained to discriminate between human and\nmachine-generated text emerge as unsupervised predictors of \"page quality\",\nable to detect low quality content without any training. This enables fast\nbootstrapping of quality indicators in a low-resource setting. Secondly,\ncurious to understand the prevalence and nature of low quality pages in the\nwild, we conduct extensive qualitative and quantitative analysis over 500\nmillion web articles, making this the largest-scale study ever conducted on the\ntopic.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 07:13:24 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Bahri", "Dara", ""], ["Tay", "Yi", ""], ["Zheng", "Che", ""], ["Metzler", "Donald", ""], ["Brunk", "Cliff", ""], ["Tomkins", "Andrew", ""]]}, {"id": "2008.13535", "submitter": "Ruoxi Wang", "authors": "Ruoxi Wang, Rakesh Shivanna, Derek Z. Cheng, Sagar Jain, Dong Lin,\n  Lichan Hong, Ed H. Chi", "title": "DCN V2: Improved Deep & Cross Network and Practical Lessons for\n  Web-scale Learning to Rank Systems", "comments": null, "journal-ref": "In Proceedings of the Web Conference 2021 (WWW '21)", "doi": "10.1145/3442381.3450078", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning effective feature crosses is the key behind building recommender\nsystems. However, the sparse and large feature space requires exhaustive search\nto identify effective crosses. Deep & Cross Network (DCN) was proposed to\nautomatically and efficiently learn bounded-degree predictive feature\ninteractions. Unfortunately, in models that serve web-scale traffic with\nbillions of training examples, DCN showed limited expressiveness in its cross\nnetwork at learning more predictive feature interactions. Despite significant\nresearch progress made, many deep learning models in production still rely on\ntraditional feed-forward neural networks to learn feature crosses\ninefficiently.\n  In light of the pros/cons of DCN and existing feature interaction learning\napproaches, we propose an improved framework DCN-V2 to make DCN more practical\nin large-scale industrial settings. In a comprehensive experimental study with\nextensive hyper-parameter search and model tuning, we observed that DCN-V2\napproaches outperform all the state-of-the-art algorithms on popular benchmark\ndatasets. The improved DCN-V2 is more expressive yet remains cost efficient at\nfeature interaction learning, especially when coupled with a mixture of\nlow-rank architecture. DCN-V2 is simple, can be easily adopted as building\nblocks, and has delivered significant offline accuracy and online business\nmetrics gains across many web-scale learning to rank systems at Google.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 20:33:02 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 21:01:21 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Wang", "Ruoxi", ""], ["Shivanna", "Rakesh", ""], ["Cheng", "Derek Z.", ""], ["Jain", "Sagar", ""], ["Lin", "Dong", ""], ["Hong", "Lichan", ""], ["Chi", "Ed H.", ""]]}, {"id": "2008.13537", "submitter": "He Zhao", "authors": "He Zhao, Dinh Phung, Viet Huynh, Trung Le, Wray Buntine", "title": "Neural Topic Model via Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recently, Neural Topic Models (NTMs) inspired by variational autoencoders\nhave obtained increasingly research interest due to their promising results on\ntext analysis. However, it is usually hard for existing NTMs to achieve good\ndocument representation and coherent/diverse topics at the same time. Moreover,\nthey often degrade their performance severely on short documents. The\nrequirement of reparameterisation could also comprise their training quality\nand model flexibility. To address these shortcomings, we present a new neural\ntopic model via the theory of optimal transport (OT). Specifically, we propose\nto learn the topic distribution of a document by directly minimising its OT\ndistance to the document's word distributions. Importantly, the cost matrix of\nthe OT distance models the weights between topics and words, which is\nconstructed by the distances between topics and words in an embedding space.\nOur proposed model can be trained efficiently with a differentiable loss.\nExtensive experiments show that our framework significantly outperforms the\nstate-of-the-art NTMs on discovering more coherent and diverse topics and\nderiving better document representations for both regular and short texts.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 06:37:09 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 01:49:09 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Zhao", "He", ""], ["Phung", "Dinh", ""], ["Huynh", "Viet", ""], ["Le", "Trung", ""], ["Buntine", "Wray", ""]]}, {"id": "2008.13539", "submitter": "Weixuan Liang", "authors": "Weixuan Liang and Sihang Zhou and Jian Xiong and Xinwang Liu and Siwei\n  Wang and En Zhu and Zhiping Cai and Xin Xu", "title": "Multi-View Spectral Clustering with High-Order Optimal Neighborhood\n  Laplacian Matrix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view spectral clustering can effectively reveal the intrinsic cluster\nstructure among data by performing clustering on the learned optimal embedding\nacross views. Though demonstrating promising performance in various\napplications, most of existing methods usually linearly combine a group of\npre-specified first-order Laplacian matrices to construct the optimal Laplacian\nmatrix, which may result in limited representation capability and insufficient\ninformation exploitation. Also, storing and implementing complex operations on\nthe $n\\times n$ Laplacian matrices incurs intensive storage and computation\ncomplexity. To address these issues, this paper first proposes a multi-view\nspectral clustering algorithm that learns a high-order optimal neighborhood\nLaplacian matrix, and then extends it to the late fusion version for accurate\nand efficient multi-view clustering. Specifically, our proposed algorithm\ngenerates the optimal Laplacian matrix by searching the neighborhood of the\nlinear combination of both the first-order and high-order base Laplacian\nmatrices simultaneously. By this way, the representative capacity of the\nlearned optimal Laplacian matrix is enhanced, which is helpful to better\nutilize the hidden high-order connection information among data, leading to\nimproved clustering performance. We design an efficient algorithm with proved\nconvergence to solve the resultant optimization problem. Extensive experimental\nresults on nine datasets demonstrate the superiority of our algorithm against\nstate-of-the-art methods, which verifies the effectiveness and advantages of\nthe proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 12:28:40 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Liang", "Weixuan", ""], ["Zhou", "Sihang", ""], ["Xiong", "Jian", ""], ["Liu", "Xinwang", ""], ["Wang", "Siwei", ""], ["Zhu", "En", ""], ["Cai", "Zhiping", ""], ["Xu", "Xin", ""]]}, {"id": "2008.13542", "submitter": "Maksim Eren", "authors": "Maksim Ekin Eren, Nick Solovyev, Edward Raff, Charles Nicholas, Ben\n  Johnson", "title": "COVID-19 Kaggle Literature Organization", "comments": "Maksim Ekin Eren, Nick Solovyev, Edward Raff, Charles Nicholas, and\n  Ben Johnson. 2020. COVID-19 Kaggle Literature Organization. In ACM Sym-posium\n  on Document Engineering 2020 (DocEng 20), September 29-October2, 2020,\n  Virtual Event, CA, USA.ACM, New York, NY, USA, 4 pages.\n  https://doi.org/10.1145/3395027.3419591", "journal-ref": null, "doi": "10.1145/3395027.3419591", "report-no": null, "categories": "cs.IR cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world has faced the devastating outbreak of Severe Acute Respiratory\nSyndrome Coronavirus-2 (SARS-CoV-2), or COVID-19, in 2020. Research in the\nsubject matter was fast-tracked to such a point that scientists were struggling\nto keep up with new findings. With this increase in the scientific literature,\nthere arose a need for organizing those documents. We describe an approach to\norganize and visualize the scientific literature on or related to COVID-19\nusing machine learning techniques so that papers on similar topics are grouped\ntogether. By doing so, the navigation of topics and related papers is\nsimplified. We implemented this approach using the widely recognized CORD-19\ndataset to present a publicly available proof of concept.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 21:02:32 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 14:09:43 GMT"}, {"version": "v3", "created": "Wed, 2 Sep 2020 03:54:34 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Eren", "Maksim Ekin", ""], ["Solovyev", "Nick", ""], ["Raff", "Edward", ""], ["Nicholas", "Charles", ""], ["Johnson", "Ben", ""]]}, {"id": "2008.13544", "submitter": "Hamada Zahera", "authors": "Hamada M. Zahera, Rricha Jalota, Mohamed A. Sherif, Axel N. Ngomo", "title": "I-AID: Identifying Actionable Information from Disaster-related Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Social media plays a significant role in disaster management by providing\nvaluable data about affected people, donations and help requests. Recent\nstudies highlight the need to filter information on social media into\nfine-grained content labels. However, identifying useful information from\nmassive amounts of social media posts during a crisis is a challenging task. In\nthis paper, we propose I-AID, a multimodel approach to automatically categorize\ntweets into multi-label information types and filter critical information from\nthe enormous volume of social media data. I-AID incorporates three main\ncomponents: i) a BERT-based encoder to capture the semantics of a tweet and\nrepresent as a low-dimensional vector, ii) a graph attention network (GAT) to\napprehend correlations between tweets' words/entities and the corresponding\ninformation types, and iii) a Relation Network as a learnable distance metric\nto compute the similarity between tweets and their corresponding information\ntypes in a supervised way. We conducted several experiments on two real\npublicly-available datasets. Our results indicate that I-AID outperforms\nstate-of-the-art approaches in terms of weighted average F1 score by +6% and\n+4% on the TREC-IS dataset and COVID-19 Tweets, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 19:07:50 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 02:32:43 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Zahera", "Hamada M.", ""], ["Jalota", "Rricha", ""], ["Sherif", "Mohamed A.", ""], ["Ngomo", "Axel N.", ""]]}, {"id": "2008.13546", "submitter": "Xavier Amatriain", "authors": "Clara H. McCreery, Namit Katariya, Anitha Kannan, Manish Chablani,\n  Xavier Amatriain", "title": "Effective Transfer Learning for Identifying Similar Questions: Matching\n  User Questions to COVID-19 FAQs", "comments": "arXiv admin note: substantial text overlap with arXiv:1910.04192", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People increasingly search online for answers to their medical questions but\nthe rate at which medical questions are asked online significantly exceeds the\ncapacity of qualified people to answer them. This leaves many questions\nunanswered or inadequately answered. Many of these questions are not unique,\nand reliable identification of similar questions would enable more efficient\nand effective question answering schema. COVID-19 has only exacerbated this\nproblem. Almost every government agency and healthcare organization has tried\nto meet the informational need of users by building online FAQs, but there is\nno way for people to ask their question and know if it is answered on one of\nthese pages. While many research efforts have focused on the problem of general\nquestion similarity, these approaches do not generalize well to domains that\nrequire expert knowledge to determine semantic similarity, such as the medical\ndomain. In this paper, we show how a double fine-tuning approach of pretraining\na neural network on medical question-answer pairs followed by fine-tuning on\nmedical question-question pairs is a particularly useful intermediate task for\nthe ultimate goal of determining medical question similarity. While other\npretraining tasks yield an accuracy below 78.7% on this task, our model\nachieves an accuracy of 82.6% with the same number of training examples, an\naccuracy of 80.0% with a much smaller training set, and an accuracy of 84.5%\nwhen the full corpus of medical question-answer data is used. We also describe\na currently live system that uses the trained model to match user questions to\nCOVID-related FAQs.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 18:20:04 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["McCreery", "Clara H.", ""], ["Katariya", "Namit", ""], ["Kannan", "Anitha", ""], ["Chablani", "Manish", ""], ["Amatriain", "Xavier", ""]]}, {"id": "2008.13547", "submitter": "Qiming Zhu", "authors": "Qiming Zhu, Zeliang Liu, Jinhui Yan", "title": "Machine learning for metal additive manufacturing: Predicting\n  temperature and melt pool fluid dynamics using physics-informed neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG physics.app-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent explosion of machine learning (ML) and artificial intelligence\n(AI) shows great potential in the breakthrough of metal additive manufacturing\n(AM) process modeling. However, the success of conventional machine learning\ntools in data science is primarily attributed to the unprecedented large amount\nof labeled data-sets (big data), which can be either obtained by experiments or\nfirst-principle simulations. Unfortunately, these labeled data-sets are\nexpensive to obtain in AM due to the high expense of the AM experiments and\nprohibitive computational cost of high-fidelity simulations.\n  We propose a physics-informed neural network (PINN) framework that fuses both\ndata and first physical principles, including conservation laws of momentum,\nmass, and energy, into the neural network to inform the learning processes. To\nthe best knowledge of the authors, this is the first application of PINN to\nthree dimensional AM processes modeling. Besides, we propose a hard-type\napproach for Dirichlet boundary conditions (BCs) based on a Heaviside function,\nwhich can not only enforce the BCs but also accelerate the learning process.\nThe PINN framework is applied to two representative metal manufacturing\nproblems, including the 2018 NIST AM-Benchmark test series. We carefully assess\nthe performance of the PINN model by comparing the predictions with available\nexperimental data and high-fidelity simulation results. The investigations show\nthat the PINN, owed to the additional physical knowledge, can accurately\npredict the temperature and melt pool dynamics during metal AM processes with\nonly a moderate amount of labeled data-sets. The foray of PINN to metal AM\nshows the great potential of physics-informed deep learning for broader\napplications to advanced manufacturing.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 20:34:38 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 17:29:15 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Zhu", "Qiming", ""], ["Liu", "Zeliang", ""], ["Yan", "Jinhui", ""]]}, {"id": "2008.13548", "submitter": "Anurag Sarkar", "authors": "Anurag Sarkar, Seth Cooper", "title": "Towards Game Design via Creative Machine Learning (GDCML)", "comments": "6 pages, 4 figures, IEEE Conference on Games (CoG) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, machine learning (ML) systems have been increasingly applied\nfor performing creative tasks. Such creative ML approaches have seen wide use\nin the domains of visual art and music for applications such as image and music\ngeneration and style transfer. However, similar creative ML techniques have not\nbeen as widely adopted in the domain of game design despite the emergence of\nML-based methods for generating game content. In this paper, we argue for\nleveraging and repurposing such creative techniques for designing content for\ngames, referring to these as approaches for Game Design via Creative ML\n(GDCML). We highlight existing systems that enable GDCML and illustrate how\ncreative ML can inform new systems via example applications and a proposed\nsystem.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 21:15:55 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Sarkar", "Anurag", ""], ["Cooper", "Seth", ""]]}, {"id": "2008.13549", "submitter": "Laksh Advani", "authors": "Laksh Advani and Clement Lu and Suraj Maharjan", "title": "C1 at SemEval-2020 Task 9: SentiMix: Sentiment Analysis for Code-Mixed\n  Social Media Text using Feature Engineering", "comments": "SemEval-2020 Task 9", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In today's interconnected and multilingual world, code-mixing of languages on\nsocial media is a common occurrence. While many Natural Language Processing\n(NLP) tasks like sentiment analysis are mature and well designed for\nmonolingual text, techniques to apply these tasks to code-mixed text still\nwarrant exploration. This paper describes our feature engineering approach to\nsentiment analysis in code-mixed social media text for SemEval-2020 Task 9:\nSentiMix. We tackle this problem by leveraging a set of hand-engineered\nlexical, sentiment, and metadata features to design a classifier that can\ndisambiguate between \"positive\", \"negative\" and \"neutral\" sentiment. With this\nmodel, we are able to obtain a weighted F1 score of 0.65 for the \"Hinglish\"\ntask and 0.63 for the \"Spanglish\" tasks\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 00:46:26 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Advani", "Laksh", ""], ["Lu", "Clement", ""], ["Maharjan", "Suraj", ""]]}, {"id": "2008.13567", "submitter": "Moo K. Chung", "authors": "Moo K. Chung", "title": "Introduction to logistic regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For random field theory based multiple comparison corrections In brain\nimaging, it is often necessary to compute the distribution of the supremum of a\nrandom field. Unfortunately, computing the distribution of the supremum of the\nrandom field is not easy and requires satisfying many distributional\nassumptions that may not be true in real data. Thus, there is a need to come up\nwith a different framework that does not use the traditional statistical\nhypothesis testing paradigm that requires to compute p-values. With this as a\nmotivation, we can use a different approach called the logistic regression that\ndoes not require computing the p-value and still be able to localize the\nregions of brain network differences. Unlike other discriminant and\nclassification techniques that tried to classify preselected feature vectors,\nthe method here does not require any preselected feature vectors and performs\nthe classification at each edge level.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 05:18:55 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 17:16:47 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Chung", "Moo K.", ""]]}, {"id": "2008.13569", "submitter": "Suman Bhoi", "authors": "Suman Bhoi, Lee Mong Li, Wynne Hsu", "title": "PREMIER: Personalized REcommendation for Medical prescrIptions from\n  Electronic Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The broad adoption of Electronic Health Records (EHR) has led to vast amounts\nof data being accumulated on a patient's history, diagnosis, prescriptions, and\nlab tests. Advances in recommender technologies have the potential to utilize\nthis information to help doctors personalize the prescribed medications. In\nthis work, we design a two-stage attention-based personalized medication\nrecommender system called PREMIER which incorporates information from the EHR\nto suggest a set of medications. Our system takes into account the interactions\namong drugs in order to minimize the adverse effects for the patient. We\nutilize the various attention weights in the system to compute the\ncontributions from the information sources for the recommended medications.\nExperiment results on MIMIC-III and a proprietary outpatient dataset show that\nPREMIER outperforms state-of-the-art medication recommendation systems while\nachieving the best tradeoff between accuracy and drug-drug interaction. Two\ncase studies are also presented demonstrating that the justifications provided\nby PREMIER are appropriate and aligned to clinical practices.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 04:48:32 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Bhoi", "Suman", ""], ["Li", "Lee Mong", ""], ["Hsu", "Wynne", ""]]}, {"id": "2008.13571", "submitter": "Noboru Yamada", "authors": "Daiki Otaki (1), Hirofumi Nonaka (1) and Noboru Yamada (1) ((1)\n  Nagaoka University of Technology, Niigata, Japan)", "title": "Machine learning thermal circuit network model for thermal design\n  optimization of electronic circuit board layout with transient heating chips", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.app-ph cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a method combining Bayesian optimization (BO) and a\nlamped-capacitance thermal circuit network model that is effective for speeding\nup the thermal design optimization of an electronic circuit board layout with\ntransient heating chips. As electronic devices have become smaller and more\ncomplex, the importance of thermal design optimization to ensure heat\ndissipation performance has increased. However, such thermal design\noptimization is difficult because it is necessary to consider various\ntrade-offs associated with packaging and transient temperature changes of\nheat-generating components. This study aims to improve the performance of\nthermal design optimization by artificial intelligence. BO using a Gaussian\nprocess was combined with the lamped-capacitance thermal circuit network model,\nand its performance was verified by case studies. As a result, BO successfully\nfound the ideal circuit board layout as well as particle swarm optimization\n(PSO) and genetic algorithm (GA) could. The CPU time for BO was 1/5 and 1/4 of\nthat for PSO and GA, respectively. In addition, BO found a non-intuitive\noptimal solution in approximately 7 minutes from 10 million layout patterns. It\nwas estimated that this was 1/1000 of the CPU time required for analyzing all\nlayout patterns.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 01:51:37 GMT"}, {"version": "v2", "created": "Sat, 16 Jan 2021 10:29:32 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Otaki", "Daiki", ""], ["Nonaka", "Hirofumi", ""], ["Yamada", "Noboru", ""]]}, {"id": "2008.13578", "submitter": "Yijue Wang", "authors": "Yijue Wang, Chenghong Wang, Zigeng Wang, Shanglin Zhou, Hang Liu,\n  Jinbo Bi, Caiwen Ding, Sanguthevar Rajasekaran", "title": "Against Membership Inference Attack: Pruning is All You Need", "comments": "Machine Learning (cs.LG); Cryptography and Security (cs.CR); Machine\n  Learning (stat.ML)", "journal-ref": "IJCAI, 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large model size, high computational operations, and vulnerability\nagainst membership inference attack (MIA) have impeded deep learning or deep\nneural networks (DNNs) popularity, especially on mobile devices. To address the\nchallenge, we envision that the weight pruning technique will help DNNs against\nMIA while reducing model storage and computational operation. In this work, we\npropose a pruning algorithm, and we show that the proposed algorithm can find a\nsubnetwork that can prevent privacy leakage from MIA and achieves competitive\naccuracy with the original DNNs. We also verify our theoretical insights with\nexperiments. Our experimental results illustrate that the attack accuracy using\nmodel compression is up to 13.6% and 10% lower than that of the baseline and\nMin-Max game, accordingly.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 02:15:44 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 05:48:54 GMT"}, {"version": "v3", "created": "Tue, 29 Jun 2021 14:50:00 GMT"}, {"version": "v4", "created": "Sun, 4 Jul 2021 13:49:31 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Wang", "Yijue", ""], ["Wang", "Chenghong", ""], ["Wang", "Zigeng", ""], ["Zhou", "Shanglin", ""], ["Liu", "Hang", ""], ["Bi", "Jinbo", ""], ["Ding", "Caiwen", ""], ["Rajasekaran", "Sanguthevar", ""]]}, {"id": "2008.13590", "submitter": "Malena Maria Reiners", "authors": "Malena Reiners and Kathrin Klamroth and Michael Stiglmayr", "title": "Efficient and Sparse Neural Networks by Pruning Weights in a\n  Multiobjective Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overparameterization and overfitting are common concerns when designing and\ntraining deep neural networks, that are often counteracted by pruning and\nregularization strategies. However, these strategies remain secondary to most\nlearning approaches and suffer from time and computational intensive\nprocedures. We suggest a multiobjective perspective on the training of neural\nnetworks by treating its prediction accuracy and the network complexity as two\nindividual objective functions in a biobjective optimization problem. As a\nshowcase example, we use the cross entropy as a measure of the prediction\naccuracy while adopting an l1-penalty function to assess the total cost (or\ncomplexity) of the network parameters. The latter is combined with an\nintra-training pruning approach that reinforces complexity reduction and\nrequires only marginal extra computational cost. From the perspective of\nmultiobjective optimization, this is a truly large-scale optimization problem.\nWe compare two different optimization paradigms: On the one hand, we adopt a\nscalarization-based approach that transforms the biobjective problem into a\nseries of weighted-sum scalarizations. On the other hand we implement\nstochastic multi-gradient descent algorithms that generate a single Pareto\noptimal solution without requiring or using preference information. In the\nfirst case, favorable knee solutions are identified by repeated training runs\nwith adaptively selected scalarization parameters. Preliminary numerical\nresults on exemplary convolutional neural networks confirm that large\nreductions in the complexity of neural networks with neglibile loss of accuracy\nare possible.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 13:28:03 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Reiners", "Malena", ""], ["Klamroth", "Kathrin", ""], ["Stiglmayr", "Michael", ""]]}, {"id": "2008.13600", "submitter": "Dionysis Manousakas", "authors": "Dionysis Manousakas and Cecilia Mascolo", "title": "$\\beta$-Cores: Robust Large-Scale Bayesian Data Summarization in the\n  Presence of Outliers", "comments": "25 pages, 5 figures, Accepted at the 14th ACM International\n  Conference on Web Search and Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning applications should be able to address the intrinsic\nchallenges arising over inference on massive real-world datasets, including\nscalability and robustness to outliers. Despite the multiple benefits of\nBayesian methods (such as uncertainty-aware predictions, incorporation of\nexperts knowledge, and hierarchical modeling), the quality of classic Bayesian\ninference depends critically on whether observations conform with the assumed\ndata generating model, which is impossible to guarantee in practice. In this\nwork, we propose a variational inference method that, in a principled way, can\nsimultaneously scale to large datasets, and robustify the inferred posterior\nwith respect to the existence of outliers in the observed data. Reformulating\nBayes theorem via the $\\beta$-divergence, we posit a robustified\npseudo-Bayesian posterior as the target of inference. Moreover, relying on the\nrecent formulations of Riemannian coresets for scalable Bayesian inference, we\npropose a sparse variational approximation of the robustified posterior and an\nefficient stochastic black-box algorithm to construct it. Overall our method\nallows releasing cleansed data summaries that can be applied broadly in\nscenarios including structured data corruption. We illustrate the applicability\nof our approach in diverse simulated and real datasets, and various statistical\nmodels, including Gaussian mean inference, logistic and neural linear\nregression, demonstrating its superiority to existing Bayesian summarization\nmethods in the presence of outliers.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 13:47:12 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 10:25:11 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Manousakas", "Dionysis", ""], ["Mascolo", "Cecilia", ""]]}, {"id": "2008.13607", "submitter": "Hadrien Pouget", "authors": "Hadrien Pouget, Hana Chockler, Youcheng Sun, Daniel Kroening", "title": "Ranking Policy Decisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policies trained via Reinforcement Learning (RL) are often needlessly\ncomplex, making them more difficult to analyse and interpret. In a run with $n$\ntime steps, a policy will decide $n$ times on an action to take, even when only\na tiny subset of these decisions deliver value over selecting a simple default\naction. Given a pre-trained policy, we propose a black-box method based on\nstatistical fault localisation that ranks the states of the environment\naccording to the importance of decisions made in those states. We evaluate our\nranking method by creating new, simpler policies by pruning decisions\nidentified as unimportant, and measure the impact on performance. Our\nexperimental results on a diverse set of standard benchmarks (gridworld,\nCartPole, Atari games) show that in some cases less than half of the decisions\nmade contribute to the expected reward. We furthermore show that the decisions\nmade in the most frequently visited states are not the most important for the\nexpected reward.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 13:54:44 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Pouget", "Hadrien", ""], ["Chockler", "Hana", ""], ["Sun", "Youcheng", ""], ["Kroening", "Daniel", ""]]}, {"id": "2008.13611", "submitter": "Shreyas Kalvankar", "authors": "Shreyas Kalvankar, Hrushikesh Pandit, Pranav Parwate", "title": "Galaxy Morphology Classification using EfficientNet Architectures", "comments": "13 pages, 7 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV astro-ph.GA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the usage of EfficientNets and their applications to Galaxy\nMorphology Classification. We explore the usage of EfficientNets into\npredicting the vote fractions of the 79,975 testing images from the Galaxy Zoo\n2 challenge on Kaggle. We evaluate this model using the standard competition\nmetric i.e. rmse score and rank among the top 3 on the public leaderboard with\na public score of 0.07765. We propose a fine-tuned architecture using\nEfficientNetB5 to classify galaxies into seven classes - completely round\nsmooth, in-between smooth, cigarshaped smooth, lenticular, barred spiral,\nunbarred spiral and irregular. The network along with other popular\nconvolutional networks are used to classify 29,941 galaxy images. Different\nmetrics such as accuracy, recall, precision, F1 score are used to evaluate the\nperformance of the model along with a comparative study of other state of the\nart convolutional models to determine which one performs the best. We obtain an\naccuracy of 93.7% on our classification model with an F1 score of 0.8857.\nEfficientNets can be applied to large scale galaxy classification in future\noptical space surveys which will provide a large amount of data such as the\nLarge Synoptic Space Telescope.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 14:00:42 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 04:53:52 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Kalvankar", "Shreyas", ""], ["Pandit", "Hrushikesh", ""], ["Parwate", "Pranav", ""]]}, {"id": "2008.13625", "submitter": "Milena \\v{C}uki\\'c Radenkovi\\'c Dr", "authors": "Milena Cukic, Slavoljub Radenkovic, Miodrag Stokic, and Danka Savic", "title": "Transfer entropy applied on EEG in depression reveals aberrated dynamics", "comments": "23 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We applied transfer entropy analysis on samples of electroencephalogram\nrecorded from patients diagnosed with major depressive disorder and matched\nhealthy controls. This is the first graphical representation of aberrated\ndynamics in terms of connectivity and the direction of information between\nstandard centers in MDD.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 14:07:20 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Cukic", "Milena", ""], ["Radenkovic", "Slavoljub", ""], ["Stokic", "Miodrag", ""], ["Savic", "Danka", ""]]}, {"id": "2008.13629", "submitter": "Anmol Kagrecha", "authors": "Anmol Kagrecha, Jayakrishnan Nair, and Krishna Jagannathan", "title": "Statistically Robust, Risk-Averse Best Arm Identification in Multi-Armed\n  Bandits", "comments": "29 pages. Preliminary version appeared in NeurIPS 2019. arXiv admin\n  note: text overlap with arXiv:1906.00569", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional multi-armed bandit (MAB) formulations usually make certain\nassumptions about the underlying arms' distributions, such as bounds on the\nsupport or their tail behaviour. Moreover, such parametric information is\nusually 'baked' into the algorithms. In this paper, we show that specialized\nalgorithms that exploit such parametric information are prone to inconsistent\nlearning performance when the parameter is misspecified. Our key contributions\nare twofold: (i) We establish fundamental performance limits of statistically\nrobust MAB algorithms under the fixed-budget pure exploration setting, and (ii)\nWe propose two classes of algorithms that are asymptotically near-optimal.\nAdditionally, we consider a risk-aware criterion for best arm identification,\nwhere the objective associated with each arm is a linear combination of the\nmean and the conditional value at risk (CVaR). Throughout, we make a very mild\n'bounded moment' assumption, which lets us work with both light-tailed and\nheavy-tailed distributions within a unified framework.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 13:43:12 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Kagrecha", "Anmol", ""], ["Nair", "Jayakrishnan", ""], ["Jagannathan", "Krishna", ""]]}, {"id": "2008.13642", "submitter": "Ritu Yadav", "authors": "Ritu Yadav, Axel Vierling, Karsten Berns", "title": "Radar+RGB Attentive Fusion for Robust Object Detection in Autonomous\n  Vehicles", "comments": "This work is submitted to ICIP 2020 in Jan 2020 and the latest\n  version of this paper will be published on IEEE official website in Oct 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents two variations of architecture referred to as RANet and\nBIRANet. The proposed architecture aims to use radar signal data along with RGB\ncamera images to form a robust detection network that works efficiently, even\nin variable lighting and weather conditions such as rain, dust, fog, and\nothers. First, radar information is fused in the feature extractor network.\nSecond, radar points are used to generate guided anchors. Third, a method is\nproposed to improve region proposal network targets. BIRANet yields 72.3/75.3%\naverage AP/AR on the NuScenes dataset, which is better than the performance of\nour base network Faster-RCNN with Feature pyramid network(FFPN). RANet gives\n69.6/71.9% average AP/AR on the same dataset, which is reasonably acceptable\nperformance. Also, both BIRANet and RANet are evaluated to be robust towards\nthe noise.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 14:27:02 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Yadav", "Ritu", ""], ["Vierling", "Axel", ""], ["Berns", "Karsten", ""]]}, {"id": "2008.13646", "submitter": "Jong Chul Ye", "authors": "Shujaat Khan, Jaeyoung Huh and Jong Chul Ye", "title": "Switchable Deep Beamformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent proposals of deep beamformers using deep neural networks have\nattracted significant attention as computational efficient alternatives to\nadaptive and compressive beamformers. Moreover, deep beamformers are versatile\nin that image post-processing algorithms can be combined with the beamforming.\nUnfortunately, in the current technology, a separate beamformer should be\ntrained and stored for each application, demanding significant scanner\nresources. To address this problem, here we propose a {\\em switchable} deep\nbeamformer that can produce various types of output such as DAS, speckle\nremoval, deconvolution, etc., using a single network with a simple switch. In\nparticular, the switch is implemented through Adaptive Instance Normalization\n(AdaIN) layers, so that various output can be generated by merely changing the\nAdaIN code. Experimental results using B-mode focused ultrasound confirm the\nflexibility and efficacy of the proposed methods for various applications.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 14:31:03 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 11:48:41 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Khan", "Shujaat", ""], ["Huh", "Jaeyoung", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2008.13664", "submitter": "Thomas Lange", "authors": "Thomas Lange, Aneesh Balakrishnan, Maximilien Glorieux, Dan\n  Alexandrescu, Luca Sterpone", "title": "Machine Learning Clustering Techniques for Selective Mitigation of\n  Critical Design Features", "comments": null, "journal-ref": null, "doi": "10.1109/IOLTS50870.2020.9159751", "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selective mitigation or selective hardening is an effective technique to\nobtain a good trade-off between the improvements in the overall reliability of\na circuit and the hardware overhead induced by the hardening techniques.\nSelective mitigation relies on preferentially protecting circuit instances\naccording to their susceptibility and criticality. However, ranking circuit\nparts in terms of vulnerability usually requires computationally intensive\nfault-injection simulation campaigns. This paper presents a new methodology\nwhich uses machine learning clustering techniques to group flip-flops with\nsimilar expected contributions to the overall functional failure rate, based on\nthe analysis of a compact set of features combining attributes from static\nelements and dynamic elements. Fault simulation campaigns can then be executed\non a per-group basis, significantly reducing the time and cost of the\nevaluation. The effectiveness of grouping similar sensitive flip-flops by\nmachine learning clustering algorithms is evaluated on a practical\nexample.Different clustering algorithms are applied and the results are\ncompared to an ideal selective mitigation obtained by exhaustive\nfault-injection simulation.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 15:03:16 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 15:48:17 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Lange", "Thomas", ""], ["Balakrishnan", "Aneesh", ""], ["Glorieux", "Maximilien", ""], ["Alexandrescu", "Dan", ""], ["Sterpone", "Luca", ""]]}, {"id": "2008.13690", "submitter": "Jussi Tohka", "authors": "Jussi Tohka and Mark van Gils", "title": "Evaluation of machine learning algorithms for Health and Wellness\n  applications: a tutorial", "comments": "To be published in Computers in Biology and Medicine", "journal-ref": null, "doi": "10.1016/j.compbiomed.2021.104324", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Research on decision support applications in healthcare, such as those\nrelated to diagnosis, prediction, treatment planning, etc., have seen\nenormously increased interest recently. This development is thanks to the\nincrease in data availability as well as advances in artificial intelligence\nand machine learning research. Highly promising research examples are published\ndaily. However, at the same time, there are some unrealistic expectations with\nregards to the requirements for reliable development and objective validation\nthat is needed in healthcare settings. These expectations may lead to unmet\nschedules and disappointments (or non-uptake) at the end-user side. It is the\naim of this tutorial to provide practical guidance on how to assess performance\nreliably and efficiently and avoid common traps. Instead of giving a list of\ndo's and don't s, this tutorial tries to build a better understanding behind\nthese do's and don't s and presents both the most relevant performance\nevaluation criteria as well as how to compute them. Along the way, we will\nindicate common mistakes and provide references discussing various topics more\nin-depth.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 15:50:51 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 16:40:09 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Tohka", "Jussi", ""], ["van Gils", "Mark", ""]]}, {"id": "2008.13697", "submitter": "Mustafa Hajij", "authors": "Mustafa Hajij, Kyle Istvan", "title": "A Topological Framework for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We utilize classical facts from topology to show that the classification\nproblem in machine learning is always solvable under very mild conditions.\nFurthermore, we show that a softmax classification network acts on an input\ntopological space by a finite sequence of topological moves to achieve the\nclassification task. Moreover, given a training dataset, we show how\ntopological formalism can be used to suggest the appropriate architectural\nchoices for neural networks designed to be trained as classifiers on the data.\nFinally, we show how the architecture of a neural network cannot be chosen\nindependently from the shape of the underlying data. To demonstrate these\nresults, we provide example datasets and show how they are acted upon by neural\nnets from this topological perspective.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 15:56:42 GMT"}, {"version": "v10", "created": "Wed, 21 Oct 2020 04:56:07 GMT"}, {"version": "v11", "created": "Sat, 26 Dec 2020 21:50:42 GMT"}, {"version": "v12", "created": "Fri, 15 Jan 2021 20:42:06 GMT"}, {"version": "v13", "created": "Mon, 21 Jun 2021 12:24:50 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 02:53:24 GMT"}, {"version": "v3", "created": "Fri, 4 Sep 2020 00:47:36 GMT"}, {"version": "v4", "created": "Mon, 7 Sep 2020 02:40:42 GMT"}, {"version": "v5", "created": "Wed, 23 Sep 2020 17:12:02 GMT"}, {"version": "v6", "created": "Mon, 5 Oct 2020 08:31:03 GMT"}, {"version": "v7", "created": "Sun, 11 Oct 2020 23:42:57 GMT"}, {"version": "v8", "created": "Wed, 14 Oct 2020 20:33:22 GMT"}, {"version": "v9", "created": "Sun, 18 Oct 2020 19:27:24 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Hajij", "Mustafa", ""], ["Istvan", "Kyle", ""]]}, {"id": "2008.13703", "submitter": "Nadejda Drenska", "authors": "Jeff Calder and Nadejda Drenska", "title": "Asymptotically optimal strategies for online prediction with\n  history-dependent experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.LG math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish sharp asymptotically optimal strategies for the problem of\nonline prediction with history dependent experts. The prediction problem is\nplayed (in part) over a discrete graph called the $d$ dimensional de Bruijn\ngraph, where $d$ is the number of days of history used by the experts. Previous\nwork [11] established $O(\\varepsilon)$ optimal strategies for $n=2$ experts and\n$d\\leq 4$ days of history, while [10] established $O(\\varepsilon^{1/3})$\noptimal strategies for all $n\\geq 2$ and all $d\\geq 1$, where the game is\nplayed for $N$ steps and $\\varepsilon=N^{-1/2}$. In this paper, we show that\nthe optimality conditions over the de Bruijn graph correspond to a graph\nPoisson equation, and we establish $O(\\varepsilon)$ optimal strategies for all\nvalues of $n$ and $d$.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 16:00:42 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Calder", "Jeff", ""], ["Drenska", "Nadejda", ""]]}, {"id": "2008.13707", "submitter": "Xiaoyong Yuan", "authors": "Xiaoyong Yuan, Lei Ding, Malek Ben Salem, Xiaolin Li, Dapeng Wu", "title": "Connecting Web Event Forecasting with Anomaly Detection: A Case Study on\n  Enterprise Web Applications Using Self-Supervised Neural Networks", "comments": "accepted at EAI SecureComm 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently web applications have been widely used in enterprises to assist\nemployees in providing effective and efficient business processes. Forecasting\nupcoming web events in enterprise web applications can be beneficial in many\nways, such as efficient caching and recommendation. In this paper, we present a\nweb event forecasting approach, DeepEvent, in enterprise web applications for\nbetter anomaly detection. DeepEvent includes three key features: web-specific\nneural networks to take into account the characteristics of sequential web\nevents, self-supervised learning techniques to overcome the scarcity of labeled\ndata, and sequence embedding techniques to integrate contextual events and\ncapture dependencies among web events. We evaluate DeepEvent on web events\ncollected from six real-world enterprise web applications. Our experimental\nresults demonstrate that DeepEvent is effective in forecasting sequential web\nevents and detecting web based anomalies. DeepEvent provides a context-based\nsystem for researchers and practitioners to better forecast web events with\nsituational awareness.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 16:09:04 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 13:56:01 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Yuan", "Xiaoyong", ""], ["Ding", "Lei", ""], ["Salem", "Malek Ben", ""], ["Li", "Xiaolin", ""], ["Wu", "Dapeng", ""]]}, {"id": "2008.13715", "submitter": "Hao Sun", "authors": "Lele Luan and Jingwei Zheng and Yongchao Yang and Ming L. Wang and Hao\n  Sun", "title": "Extracting full-field subpixel structural displacements from videos via\n  deep learning", "comments": "22 figures; 24 figures", "journal-ref": null, "doi": "10.1016/j.jsv.2021.116142", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a deep learning framework based on convolutional neural\nnetworks (CNNs) that enable real-time extraction of full-field subpixel\nstructural displacements from videos. In particular, two new CNN architectures\nare designed and trained on a dataset generated by the phase-based motion\nextraction method from a single lab-recorded high-speed video of a dynamic\nstructure. As displacement is only reliable in the regions with sufficient\ntexture contrast, the sparsity of motion field induced by the texture mask is\nconsidered via the network architecture design and loss function definition.\nResults show that, with the supervision of full and sparse motion field, the\ntrained network is capable of identifying the pixels with sufficient texture\ncontrast as well as their subpixel motions. The performance of the trained\nnetworks is tested on various videos of other structures to extract the\nfull-field motion (e.g., displacement time histories), which indicates that the\ntrained networks have generalizability to accurately extract full-field subtle\ndisplacements for pixels with sufficient texture contrast.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 16:30:07 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 21:45:59 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Luan", "Lele", ""], ["Zheng", "Jingwei", ""], ["Yang", "Yongchao", ""], ["Wang", "Ming L.", ""], ["Sun", "Hao", ""]]}, {"id": "2008.13723", "submitter": "Vignesh Srinivasan", "authors": "Vignesh Srinivasan, Klaus-Robert M\\\"uller, Wojciech Samek, Shinichi\n  Nakajima", "title": "Langevin Cooling for Domain Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain translation is the task of finding correspondence between two domains.\nSeveral Deep Neural Network (DNN) models, e.g., CycleGAN and cross-lingual\nlanguage models, have shown remarkable successes on this task under the\nunsupervised setting---the mappings between the domains are learned from two\nindependent sets of training data in both domains (without paired samples).\nHowever, those methods typically do not perform well on a significant\nproportion of test samples. In this paper, we hypothesize that many of such\nunsuccessful samples lie at the fringe---relatively low-density areas---of data\ndistribution, where the DNN was not trained very well, and propose to perform\nLangevin dynamics to bring such fringe samples towards high density areas. We\ndemonstrate qualitatively and quantitatively that our strategy, called Langevin\nCooling (L-Cool), enhances state-of-the-art methods in image translation and\nlanguage translation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 16:43:17 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Srinivasan", "Vignesh", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""], ["Nakajima", "Shinichi", ""]]}, {"id": "2008.13745", "submitter": "Oindrila Saha", "authors": "Sandeep Mishra, Oindrila Saha", "title": "RecSal : Deep Recursive Supervision for Visual Saliency Prediction", "comments": "to appear in BMVC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art saliency prediction methods develop upon model architectures\nor loss functions; while training to generate one target saliency map. However,\npublicly available saliency prediction datasets can be utilized to create more\ninformation for each stimulus than just a final aggregate saliency map. This\ninformation when utilized in a biologically inspired fashion can contribute in\nbetter prediction performance without the use of models with huge number of\nparameters. In this light, we propose to extract and use the statistics of (a)\nregion specific saliency and (b) temporal order of fixations, to provide\nadditional context to our network. We show that extra supervision using\nspatially or temporally sequenced fixations results in achieving better\nperformance in saliency prediction. Further, we also design novel architectures\nfor utilizing this extra information and show that it achieves superior\nperformance over a base model which is devoid of extra supervision. We show\nthat our best method outperforms previous state-of-the-art methods with 50-80%\nfewer parameters. We also show that our models perform consistently well across\nall evaluation metrics unlike prior methods.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 17:08:34 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Mishra", "Sandeep", ""], ["Saha", "Oindrila", ""]]}, {"id": "2008.13763", "submitter": "Jan-Philipp Schulze", "authors": "J.-P. Schulze, P. Sperl, K. B\\\"ottinger", "title": "Anomaly Detection by Recombining Gated Unsupervised Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by mixture-of-experts models and the analysis of the hidden\nactivations of neural networks, we introduce a novel unsupervised anomaly\ndetection method called ARGUE. Current anomaly detection methods struggle when\nthe training data does contain multiple notions of normal. We designed ARGUE as\na combination of multiple expert networks, which specialise on parts of the\ninput data. For its final decision, ARGUE fuses the distributed knowledge\nacross the expert systems using a gated mixture-of-experts architecture. ARGUE\nachieves superior detection performance across several domains in a purely\ndata-driven way and is more robust to noisy data sets than other\nstate-of-the-art anomaly detection methods.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 17:35:57 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 15:58:25 GMT"}, {"version": "v3", "created": "Sun, 4 Apr 2021 16:58:17 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Schulze", "J. -P.", ""], ["Sperl", "P.", ""], ["B\u00f6ttinger", "K.", ""]]}, {"id": "2008.13773", "submitter": "Wesley Chung", "authors": "Wesley Chung, Valentin Thomas, Marlos C. Machado, Nicolas Le Roux", "title": "Beyond variance reduction: Understanding the true impact of baselines on\n  policy optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bandit and reinforcement learning (RL) problems can often be framed as\noptimization problems where the goal is to maximize average performance while\nhaving access only to stochastic estimates of the true gradient. Traditionally,\nstochastic optimization theory predicts that learning dynamics are governed by\nthe curvature of the loss function and the noise of the gradient estimates. In\nthis paper we demonstrate that this is not the case for bandit and RL problems.\nTo allow our analysis to be interpreted in light of multi-step MDPs, we focus\non techniques derived from stochastic optimization principles (e.g., natural\npolicy gradient and EXP3) and we show that some standard assumptions from\noptimization theory are violated in these problems. We present theoretical\nresults showing that, at least for bandit problems, curvature and noise are not\nsufficient to explain the learning dynamics and that seemingly innocuous\nchoices like the baseline can determine whether an algorithm converges. These\ntheoretical findings match our empirical evaluation, which we extend to\nmulti-state MDPs.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 17:52:09 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 18:13:05 GMT"}, {"version": "v3", "created": "Fri, 19 Feb 2021 18:10:59 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Chung", "Wesley", ""], ["Thomas", "Valentin", ""], ["Machado", "Marlos C.", ""], ["Roux", "Nicolas Le", ""]]}, {"id": "2008.13777", "submitter": "Lijun Ding", "authors": "Lijun Ding, Yuqian Zhang, Yudong Chen", "title": "Low-rank matrix recovery with non-quadratic loss: projected gradient\n  method and regularity projection oracle", "comments": "Main text has 13 pages. Reading first seven pages (takes around 10-15\n  minutes) should give a good understanding of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing results for low-rank matrix recovery largely focus on quadratic\nloss, which enjoys favorable properties such as restricted strong\nconvexity/smoothness (RSC/RSM) and well conditioning over all low rank\nmatrices. However, many interesting problems involve non-quadratic loss do not\nsatisfy such properties; examples including one-bit matrix sensing, one-bit\nmatrix completion, and rank aggregation. For these problems, standard nonconvex\napproaches such as projected gradient with rank constraint alone (a.k.a.\niterative hard thresholding) and Burer-Monteiro approach may perform badly in\npractice and have no satisfactory theory in guaranteeing global and efficient\nconvergence.\n  In this paper, we show that the critical component in low-rank recovery with\nnon-quadratic loss is a regularity projection oracle, which restricts iterates\nto low-rank matrix within an appropriate bounded set, over which the loss\nfunction is well behaved and satisfies a set of relaxed RSC/RSM conditions.\nAccordingly, we analyze an (averaged) projected gradient method equipped with\nsuch an oracle, and prove that it converges globally and linearly. Our results\napply to a wide range of non-quadratic problems including rank aggregation, one\nbit matrix sensing/completion, and more broadly generalized linear models with\nrank constraint.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 17:56:04 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Ding", "Lijun", ""], ["Zhang", "Yuqian", ""], ["Chen", "Yudong", ""]]}, {"id": "2008.13781", "submitter": "Alex Aisen", "authors": "Menashe Benjamin, Guy Engelhard, Alex Aisen, Yinon Aradi, Elad\n  Benjamin", "title": "A Multisite, Report-Based, Centralized Infrastructure for Feedback and\n  Monitoring of Radiology AI/ML Development and Clinical Deployment", "comments": "21 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An infrastructure for multisite, geographically-distributed creation and\ncollection of diverse, high-quality, curated and labeled radiology image data\nis crucial for the successful automated development, deployment, monitoring and\ncontinuous improvement of Artificial Intelligence (AI)/Machine Learning (ML)\nsolutions in the real world. An interactive radiology reporting approach that\nintegrates image viewing, dictation, natural language processing (NLP) and\ncreation of hyperlinks between image findings and the report, provides\nlocalized labels during routine interpretation. These images and labels can be\ncaptured and centralized in a cloud-based system. This method provides a\npractical and efficient mechanism with which to monitor algorithm performance.\nIt also supplies feedback for iterative development and quality improvement of\nnew and existing algorithmic models. Both feedback and monitoring are achieved\nwithout burdening the radiologist. The method addresses proposed regulatory\nrequirements for post-marketing surveillance and external data. Comprehensive\nmulti-site data collection assists in reducing bias. Resource requirements are\ngreatly reduced compared to dedicated retrospective expert labeling.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 17:59:04 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Benjamin", "Menashe", ""], ["Engelhard", "Guy", ""], ["Aisen", "Alex", ""], ["Aradi", "Yinon", ""], ["Benjamin", "Elad", ""]]}]