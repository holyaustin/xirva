[{"id": "2005.00010", "submitter": "Gautam Kamath", "authors": "Gautam Kamath, Jonathan Ullman", "title": "A Primer on Private Statistics", "comments": "20 pages. Comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentially private statistical estimation has seen a flurry of\ndevelopments over the last several years. Study has been divided into two\nschools of thought, focusing on empirical statistics versus population\nstatistics. We suggest that these two lines of work are more similar than\ndifferent by giving examples of methods that were initially framed for\nempirical statistics, but can be applied just as well to population statistics.\nWe also provide a thorough coverage of recent work in this area.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 18:00:00 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Kamath", "Gautam", ""], ["Ullman", "Jonathan", ""]]}, {"id": "2005.00048", "submitter": "Sivasurya Santhanam", "authors": "Sivasurya Santhanam", "title": "Context based Text-generation using LSTM networks", "comments": "10 pages, Abstract published in A2IC 2018\n  (https://www.premc.org/doc/A2IC2018/A2IC2018_Book_Of_Abstracts.pdf)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long short-term memory(LSTM) units on sequence-based models are being used in\ntranslation, question-answering systems, classification tasks due to their\ncapability of learning long-term dependencies. In Natural language generation,\nLSTM networks are providing impressive results on text generation models by\nlearning language models with grammatically stable syntaxes. But the downside\nis that the network does not learn about the context. The network only learns\nthe input-output function and generates text given a set of input words\nirrespective of pragmatics. As the model is trained without any such context,\nthere is no semantic consistency among the generated sentences. The proposed\nmodel is trained to generate text for a given set of input words along with a\ncontext vector. A context vector is similar to a paragraph vector that grasps\nthe semantic meaning(context) of the sentence. Several methods of extracting\nthe context vectors are proposed in this work. While training a language model,\nin addition to the input-output sequences, context vectors are also trained\nalong with the inputs. Due to this structure, the model learns the relation\namong the input words, context vector and the target word. Given a set of\ncontext terms, a well trained model will generate text around the provided\ncontext. Based on the nature of computing context vectors, the model has been\ntried out with two variations (word importance and word clustering). In the\nword clustering method, the suitable embeddings among various domains are also\nexplored. The results are evaluated based on the semantic closeness of the\ngenerated text to the given context.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 18:39:25 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Santhanam", "Sivasurya", ""]]}, {"id": "2005.00054", "submitter": "Shuyang Dai", "authors": "Shuyang Dai, Zhe Gan, Yu Cheng, Chenyang Tao, Lawrence Carin, Jingjing\n  Liu", "title": "APo-VAE: Text Generation in Hyperbolic Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language often exhibits inherent hierarchical structure ingrained\nwith complex syntax and semantics. However, most state-of-the-art deep\ngenerative models learn embeddings only in Euclidean vector space, without\naccounting for this structural property of language. In this paper, we\ninvestigate text generation in a hyperbolic latent space to learn continuous\nhierarchical representations. An Adversarial Poincare Variational Autoencoder\n(APo-VAE) is presented, where both the prior and variational posterior of\nlatent variables are defined over a Poincare ball via wrapped normal\ndistributions. By adopting the primal-dual formulation of KL divergence, an\nadversarial learning procedure is introduced to empower robust model training.\nExtensive experiments in language modeling and dialog-response generation tasks\ndemonstrate the winning effectiveness of the proposed APo-VAE model over VAEs\nin Euclidean latent space, thanks to its superb capabilities in capturing\nlatent language hierarchies in hyperbolic space.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 19:05:41 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 03:56:43 GMT"}, {"version": "v3", "created": "Wed, 14 Jul 2021 22:41:30 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Dai", "Shuyang", ""], ["Gan", "Zhe", ""], ["Cheng", "Yu", ""], ["Tao", "Chenyang", ""], ["Carin", "Lawrence", ""], ["Liu", "Jingjing", ""]]}, {"id": "2005.00060", "submitter": "Pu Zhao", "authors": "Pu Zhao, Pin-Yu Chen, Payel Das, Karthikeyan Natesan Ramamurthy, Xue\n  Lin", "title": "Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness", "comments": "accepted by ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mode connectivity provides novel geometric insights on analyzing loss\nlandscapes and enables building high-accuracy pathways between well-trained\nneural networks. In this work, we propose to employ mode connectivity in loss\nlandscapes to study the adversarial robustness of deep neural networks, and\nprovide novel methods for improving this robustness. Our experiments cover\nvarious types of adversarial attacks applied to different network architectures\nand datasets. When network models are tampered with backdoor or error-injection\nattacks, our results demonstrate that the path connection learned using limited\namount of bonafide data can effectively mitigate adversarial effects while\nmaintaining the original accuracy on clean data. Therefore, mode connectivity\nprovides users with the power to repair backdoored or error-injected models. We\nalso use mode connectivity to investigate the loss landscapes of regular and\nrobust models against evasion attacks. Experiments show that there exists a\nbarrier in adversarial robustness loss on the path connecting regular and\nadversarially-trained models. A high correlation is observed between the\nadversarial robustness loss and the largest eigenvalue of the input Hessian\nmatrix, for which theoretical justifications are provided. Our results suggest\nthat mode connectivity offers a holistic tool and practical means for\nevaluating and improving adversarial robustness.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 19:12:50 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 03:49:28 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Zhao", "Pu", ""], ["Chen", "Pin-Yu", ""], ["Das", "Payel", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Lin", "Xue", ""]]}, {"id": "2005.00061", "submitter": "Su Jiang", "authors": "Su Jiang, Louis J. Durlofsky", "title": "Data-Space Inversion Using a Recurrent Autoencoder for Time-Series\n  Parameterization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-space inversion (DSI) and related procedures represent a family of\nmethods applicable for data assimilation in subsurface flow settings. These\nmethods differ from model-based techniques in that they provide only posterior\npredictions for quantities (time series) of interest, not posterior models with\ncalibrated parameters. DSI methods require a large number of flow simulations\nto first be performed on prior geological realizations. Given observed data,\nposterior predictions can then be generated directly. DSI operates in a\nBayesian setting and provides posterior samples of the data vector. In this\nwork we develop and evaluate a new approach for data parameterization in DSI.\nParameterization reduces the number of variables to determine in the inversion,\nand it maintains the physical character of the data variables. The new\nparameterization uses a recurrent autoencoder (RAE) for dimension reduction,\nand a long-short-term memory (LSTM) network to represent flow-rate time series.\nThe RAE-based parameterization is combined with an ensemble smoother with\nmultiple data assimilation (ESMDA) for posterior generation. Results are\npresented for two- and three-phase flow in a 2D channelized system and a 3D\nmulti-Gaussian model. The RAE procedure, along with existing DSI treatments,\nare assessed through comparison to reference rejection sampling (RS) results.\nThe new DSI methodology is shown to consistently outperform existing\napproaches, in terms of statistical agreement with RS results. The method is\nalso shown to accurately capture derived quantities, which are computed from\nvariables considered directly in DSI. This requires correlation and covariance\nbetween variables to be properly captured, and accuracy in these relationships\nis demonstrated. The RAE-based parameterization developed here is clearly\nuseful in DSI, and it may also find application in other subsurface flow\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 19:17:58 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 17:55:27 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Jiang", "Su", ""], ["Durlofsky", "Louis J.", ""]]}, {"id": "2005.00065", "submitter": "Divya Saxena", "authors": "Divya Saxena, Jiannong Cao", "title": "Generative Adversarial Networks (GANs): Challenges, Solutions, and\n  Future Directions", "comments": "61 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) is a novel class of deep generative\nmodels which has recently gained significant attention. GANs learns complex and\nhigh-dimensional distributions implicitly over images, audio, and data.\nHowever, there exists major challenges in training of GANs, i.e., mode\ncollapse, non-convergence and instability, due to inappropriate design of\nnetwork architecture, use of objective function and selection of optimization\nalgorithm. Recently, to address these challenges, several solutions for better\ndesign and optimization of GANs have been investigated based on techniques of\nre-engineered network architectures, new objective functions and alternative\noptimization algorithms. To the best of our knowledge, there is no existing\nsurvey that has particularly focused on broad and systematic developments of\nthese solutions. In this study, we perform a comprehensive survey of the\nadvancements in GANs design and optimization solutions proposed to handle GANs\nchallenges. We first identify key research issues within each design and\noptimization technique and then propose a new taxonomy to structure solutions\nby key research issues. In accordance with the taxonomy, we provide a detailed\ndiscussion on different GANs variants proposed within each solution and their\nrelationships. Finally, based on the insights gained, we present the promising\nresearch directions in this rapidly growing field.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 19:26:46 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 18:06:37 GMT"}, {"version": "v3", "created": "Fri, 9 Oct 2020 09:07:20 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Saxena", "Divya", ""], ["Cao", "Jiannong", ""]]}, {"id": "2005.00069", "submitter": "Ronan Riochet", "authors": "Ronan Riochet, Josef Sivic, Ivan Laptev and Emmanuel Dupoux", "title": "Occlusion resistant learning of intuitive physics from videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reach human performance on complex tasks, a key ability for artificial\nsystems is to understand physical interactions between objects, and predict\nfuture outcomes of a situation. This ability, often referred to as intuitive\nphysics, has recently received attention and several methods were proposed to\nlearn these physical rules from video sequences. Yet, most of these methods are\nrestricted to the case where no, or only limited, occlusions occur. In this\nwork we propose a probabilistic formulation of learning intuitive physics in 3D\nscenes with significant inter-object occlusions. In our formulation, object\npositions are modeled as latent variables enabling the reconstruction of the\nscene. We then propose a series of approximations that make this problem\ntractable. Object proposals are linked across frames using a combination of a\nrecurrent interaction network, modeling the physics in object space, and a\ncompositional renderer, modeling the way in which objects project onto pixel\nspace. We demonstrate significant improvements over state-of-the-art in the\nintuitive physics benchmark of IntPhys. We apply our method to a second dataset\nwith increasing levels of occlusions, showing it realistically predicts\nsegmentation masks up to 30 frames in the future. Finally, we also show results\non predicting motion of objects in real videos.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 19:35:54 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Riochet", "Ronan", ""], ["Sivic", "Josef", ""], ["Laptev", "Ivan", ""], ["Dupoux", "Emmanuel", ""]]}, {"id": "2005.00072", "submitter": "Anish Agarwal", "authors": "Anish Agarwal, Abdullah Alomar, Arnab Sarker, Devavrat Shah, Dennis\n  Shen, Cindy Yang", "title": "Two Burning Questions on COVID-19: Did shutting down the economy help?\n  Can we (partially) reopen the economy without risking the second wave?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As we reach the apex of the COVID-19 pandemic, the most pressing question\nfacing us is: can we even partially reopen the economy without risking a second\nwave? We first need to understand if shutting down the economy helped. And if\nit did, is it possible to achieve similar gains in the war against the pandemic\nwhile partially opening up the economy? To do so, it is critical to understand\nthe effects of the various interventions that can be put into place and their\ncorresponding health and economic implications. Since many interventions exist,\nthe key challenge facing policy makers is understanding the potential\ntrade-offs between them, and choosing the particular set of interventions that\nworks best for their circumstance. In this memo, we provide an overview of\nSynthetic Interventions (a natural generalization of Synthetic Control), a\ndata-driven and statistically principled method to perform what-if scenario\nplanning, i.e., for policy makers to understand the trade-offs between\ndifferent interventions before having to actually enact them. In essence, the\nmethod leverages information from different interventions that have already\nbeen enacted across the world and fits it to a policy maker's setting of\ninterest, e.g., to estimate the effect of mobility-restricting interventions on\nthe U.S., we use daily death data from countries that enforced severe mobility\nrestrictions to create a \"synthetic low mobility U.S.\" and predict the\ncounterfactual trajectory of the U.S. if it had indeed applied a similar\nintervention. Using Synthetic Interventions, we find that lifting severe\nmobility restrictions and only retaining moderate mobility restrictions (at\nretail and transit locations), seems to effectively flatten the curve. We hope\nthis provides guidance on weighing the trade-offs between the safety of the\npopulation, strain on the healthcare system, and impact on the economy.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 19:39:34 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 15:52:22 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Agarwal", "Anish", ""], ["Alomar", "Abdullah", ""], ["Sarker", "Arnab", ""], ["Shah", "Devavrat", ""], ["Shen", "Dennis", ""], ["Yang", "Cindy", ""]]}, {"id": "2005.00095", "submitter": "Austin Clyde", "authors": "Austin Clyde, Tom Brettin, Alexander Partin, Maulik Shaulik, Hyunseung\n  Yoo, Yvonne Evrard, Yitan Zhu, Fangfang Xia, Rick Stevens", "title": "A Systematic Approach to Featurization for Cancer Drug Sensitivity\n  Predictions with Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By combining various cancer cell line (CCL) drug screening panels, the size\nof the data has grown significantly to begin understanding how advances in deep\nlearning can advance drug response predictions. In this paper we train >35,000\nneural network models, sweeping over common featurization techniques. We found\nthe RNA-seq to be highly redundant and informative even with subsets larger\nthan 128 features. We found the inclusion of single nucleotide polymorphisms\n(SNPs) coded as count matrices improved model performance significantly, and no\nsubstantial difference in model performance with respect to molecular\nfeaturization between the common open source MOrdred descriptors and Dragon7\ndescriptors. Alongside this analysis, we outline data integration between CCL\nscreening datasets and present evidence that new metrics and imbalanced data\ntechniques, as well as advances in data standardization, need to be developed.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 20:42:17 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 15:57:05 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Clyde", "Austin", ""], ["Brettin", "Tom", ""], ["Partin", "Alexander", ""], ["Shaulik", "Maulik", ""], ["Yoo", "Hyunseung", ""], ["Evrard", "Yvonne", ""], ["Zhu", "Yitan", ""], ["Xia", "Fangfang", ""], ["Stevens", "Rick", ""]]}, {"id": "2005.00100", "submitter": "Alexander Gutkin", "authors": "Alexander Gutkin, Tatiana Merkulova and Martin Jansche", "title": "Linguistic Typology Features from Text: Inferring the Sparse Features of\n  World Atlas of Language Structures", "comments": "Originally prepared as a conference submission to EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The use of linguistic typological resources in natural language processing\nhas been steadily gaining more popularity. It has been observed that the use of\ntypological information, often combined with distributed language\nrepresentations, leads to significantly more powerful models. While linguistic\ntypology representations from various resources have mostly been used for\nconditioning the models, there has been relatively little attention on\npredicting features from these resources from the input data. In this paper we\ninvestigate whether the various linguistic features from World Atlas of\nLanguage Structures (WALS) can be reliably inferred from multi-lingual text.\nSuch a predictor can be used to infer structural features for a language never\nobserved in training data. We frame this task as a multi-label classification\ninvolving predicting the set of non-mutually exclusive and extremely sparse\nmulti-valued labels (WALS features). We construct a recurrent neural network\npredictor based on byte embeddings and convolutional layers and test its\nperformance on 556 languages, providing analysis for various linguistic types,\nmacro-areas, language families and individual features. We show that some\nfeatures from various linguistic types can be predicted reliably.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 21:00:53 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 20:53:11 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Gutkin", "Alexander", ""], ["Merkulova", "Tatiana", ""], ["Jansche", "Martin", ""]]}, {"id": "2005.00107", "submitter": "Karush Suri", "authors": "Rinki Gupta, Karush Suri", "title": "Activity Detection from Wearable Electromyogram Sensors using Hidden\n  Markov Model", "comments": null, "journal-ref": null, "doi": "10.1109/ICCMC.2018.8488070", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surface electromyography (sEMG) has gained significant importance during\nrecent advancements in consumer electronics for healthcare systems, gesture\nanalysis and recognition and sign language communication. For such a system, it\nis imperative to determine the regions of activity in a continuously recorded\nsEMG signal. The proposed work provides a novel activity detection approach\nbased on Hidden Markov Models (HMM) using sEMG signals recorded when various\nhand gestures are performed. Detection procedure is designed based on a\nprobabilistic outlook by making use of mathematical models. The requirement of\na threshold for activity detection is obviated making it subject and activity\nindependent. Correctness of the predicted outputs is asserted by classifying\nthe signal segments around the detected transition regions as activity or rest.\nClassified outputs are compared with the transition regions in a stimulus given\nto the subject to perform the activity. The activity onsets are detected with\nan average of 96.25% accuracy whereas the activity termination regions with an\naverage of 87.5% accuracy with the considered set of six activities and four\nsubjects.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 01:14:02 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Gupta", "Rinki", ""], ["Suri", "Karush", ""]]}, {"id": "2005.00113", "submitter": "Vinicius Souza", "authors": "Vinicius M. A. Souza, Denis M. dos Reis, Andre G. Maletzke, Gustavo E.\n  A. P. A. Batista", "title": "Challenges in Benchmarking Stream Learning Algorithms with Real-world\n  Data", "comments": "Preprint of article accepted for publication in the journal Data\n  Mining and Knowledge Discovery", "journal-ref": null, "doi": "10.1007/s10618-020-00698-5", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Streaming data are increasingly present in real-world applications such as\nsensor measurements, satellite data feed, stock market, and financial data. The\nmain characteristics of these applications are the online arrival of data\nobservations at high speed and the susceptibility to changes in the data\ndistributions due to the dynamic nature of real environments. The data stream\nmining community still faces some primary challenges and difficulties related\nto the comparison and evaluation of new proposals, mainly due to the lack of\npublicly available non-stationary real-world datasets. The comparison of stream\nalgorithms proposed in the literature is not an easy task, as authors do not\nalways follow the same recommendations, experimental evaluation procedures,\ndatasets, and assumptions. In this paper, we mitigate problems related to the\nchoice of datasets in the experimental evaluation of stream classifiers and\ndrift detectors. To that end, we propose a new public data repository for\nbenchmarking stream algorithms with real-world data. This repository contains\nthe most popular datasets from literature and new datasets related to a highly\nrelevant public health problem that involves the recognition of disease vector\ninsects using optical sensors. The main advantage of these new datasets is the\nprior knowledge of their characteristics and patterns of changes to evaluate\nnew adaptive algorithm proposals adequately. We also present an in-depth\ndiscussion about the characteristics, reasons, and issues that lead to\ndifferent types of changes in data distribution, as well as a critical review\nof common problems concerning the current benchmark datasets available in the\nliterature.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 21:31:34 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 15:41:10 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Souza", "Vinicius M. A.", ""], ["Reis", "Denis M. dos", ""], ["Maletzke", "Andre G.", ""], ["Batista", "Gustavo E. A. P. A.", ""]]}, {"id": "2005.00115", "submitter": "Sarthak Jain", "authors": "Sarthak Jain, Sarah Wiegreffe, Yuval Pinter, Byron C. Wallace", "title": "Learning to Faithfully Rationalize by Construction", "comments": "ACL2020 Camera Ready Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many settings it is important for one to be able to understand why a model\nmade a particular prediction. In NLP this often entails extracting snippets of\nan input text `responsible for' corresponding model output; when such a snippet\ncomprises tokens that indeed informed the model's prediction, it is a faithful\nexplanation. In some settings, faithfulness may be critical to ensure\ntransparency. Lei et al. (2016) proposed a model to produce faithful rationales\nfor neural text classification by defining independent snippet extraction and\nprediction modules. However, the discrete selection over input tokens performed\nby this method complicates training, leading to high variance and requiring\ncareful hyperparameter tuning. We propose a simpler variant of this approach\nthat provides faithful explanations by construction. In our scheme, named\nFRESH, arbitrary feature importance scores (e.g., gradients from a trained\nmodel) are used to induce binary labels over token inputs, which an extractor\ncan be trained to predict. An independent classifier module is then trained\nexclusively on snippets provided by the extractor; these snippets thus\nconstitute faithful explanations, even if the classifier is arbitrarily\ncomplex. In both automatic and manual evaluations we find that variants of this\nsimple framework yield predictive performance superior to `end-to-end'\napproaches, while being more general and easier to train. Code is available at\nhttps://github.com/successar/FRESH\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 21:45:40 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Jain", "Sarthak", ""], ["Wiegreffe", "Sarah", ""], ["Pinter", "Yuval", ""], ["Wallace", "Byron C.", ""]]}, {"id": "2005.00116", "submitter": "Bhuvan Malladihalli Shashidhara", "authors": "Bhuvan Malladihalli Shashidhara, Darshan Mehta, Yash Kale, Dan Morris,\n  Megan Hazen", "title": "Sequence Information Channel Concatenation for Improving Camera Trap\n  Image Burst Classification", "comments": "8 pages, 4 figures, 2 tables. Git repository can be found at:\n  https://github.com/bhuvi3/camera_trap_animal_classification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Camera Traps are extensively used to observe wildlife in their natural\nhabitat without disturbing the ecosystem. This could help in the early\ndetection of natural or human threats to animals, and help towards ecological\nconservation. Currently, a massive number of such camera traps have been\ndeployed at various ecological conservation areas around the world, collecting\ndata for decades, thereby requiring automation to detect images containing\nanimals. Existing systems perform classification to detect if images contain\nanimals by considering a single image. However, due to challenging scenes with\nanimals camouflaged in their natural habitat, it sometimes becomes difficult to\nidentify the presence of animals from merely a single image. We hypothesize\nthat a short burst of images instead of a single image, assuming that the\nanimal moves, makes it much easier for a human as well as a machine to detect\nthe presence of animals. In this work, we explore a variety of approaches, and\nmeasure the impact of using short image sequences (burst of 3 images) on\nimproving the camera trap image classification. We show that concatenating\nmasks containing sequence information and the images from the 3-image-burst\nacross channels, improves the ROC AUC by 20% on a test-set from unseen\ncamera-sites, as compared to an equivalent model that learns from a single\nimage.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 21:47:14 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 02:57:41 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Shashidhara", "Bhuvan Malladihalli", ""], ["Mehta", "Darshan", ""], ["Kale", "Yash", ""], ["Morris", "Dan", ""], ["Hazen", "Megan", ""]]}, {"id": "2005.00119", "submitter": "Raviteja Anantha", "authors": "Raviteja Anantha, Srinivas Chappidi, and William Dawoodi", "title": "Learning to Rank Intents in Voice Assistants", "comments": "11 pages, 7 figures, 2 tables, accepted at IWSDS 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice Assistants aim to fulfill user requests by choosing the best intent\nfrom multiple options generated by its Automated Speech Recognition and Natural\nLanguage Understanding sub-systems. However, voice assistants do not always\nproduce the expected results. This can happen because voice assistants choose\nfrom ambiguous intents - user-specific or domain-specific contextual\ninformation reduces the ambiguity of the user request. Additionally the user\ninformation-state can be leveraged to understand how relevant/executable a\nspecific intent is for a user request. In this work, we propose a novel\nEnergy-based model for the intent ranking task, where we learn an affinity\nmetric and model the trade-off between extracted meaning from speech utterances\nand relevance/executability aspects of the intent. Furthermore we present a\nMultisource Denoising Autoencoder based pretraining that is capable of learning\nfused representations of data from multiple sources. We empirically show our\napproach outperforms existing state of the art methods by reducing the\nerror-rate by 3.8%, which in turn reduces ambiguity and eliminates undesired\ndead-ends leading to better user experience. Finally, we evaluate the\nrobustness of our algorithm on the intent ranking task and show our algorithm\nimproves the robustness by 33.3%.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 21:51:26 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 03:19:07 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Anantha", "Raviteja", ""], ["Chappidi", "Srinivas", ""], ["Dawoodi", "William", ""]]}, {"id": "2005.00123", "submitter": "Dinesh Raghu", "authors": "Dinesh Raghu, Nikhil Gupta, Mausam", "title": "Unsupervised Learning of KB Queries in Task-Oriented Dialogs", "comments": "Presented at ACL 2021", "journal-ref": "Transactions of the Association for Computational Linguistics\n  (2021) 9: 374-390", "doi": "10.1162/tacl_a_00372", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-oriented dialog (TOD) systems often need to formulate knowledge base\n(KB) queries corresponding to the user intent and use the query results to\ngenerate system responses. Existing approaches require dialog datasets to\nexplicitly annotate these KB queries -- these annotations can be time\nconsuming, and expensive. In response, we define the novel problems of\npredicting the KB query and training the dialog agent, without explicit KB\nquery annotation. For query prediction, we propose a reinforcement learning\n(RL) baseline, which rewards the generation of those queries whose KB results\ncover the entities mentioned in subsequent dialog. Further analysis reveals\nthat correlation among query attributes in KB can significantly confuse memory\naugmented policy optimization (MAPO), an existing state of the art RL agent. To\naddress this, we improve the MAPO baseline with simple but important\nmodifications suited to our task. To train the full TOD system for our setting,\nwe propose a pipelined approach: it independently predicts when to make a KB\nquery (query position predictor), then predicts a KB query at the predicted\nposition (query predictor), and uses the results of predicted query in\nsubsequent dialog (next response predictor). Overall, our work proposes first\nsolutions to our novel problem, and our analysis highlights the research\nchallenges in training TOD systems without query annotation.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 22:10:00 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 04:27:47 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Raghu", "Dinesh", ""], ["Gupta", "Nikhil", ""], ["Mausam", "", ""]]}, {"id": "2005.00124", "submitter": "Shigang Li", "authors": "Shigang Li, Tal Ben-Nun, Giorgi Nadiradze, Salvatore Di Girolamo,\n  Nikoli Dryden, Dan Alistarh, Torsten Hoefler", "title": "Breaking (Global) Barriers in Parallel Stochastic Optimization with\n  Wait-Avoiding Group Averaging", "comments": "Published in IEEE Transactions on Parallel and Distributed Systems\n  (IEEE TPDS), vol. 32, no. 7, pp. 1725-1739, 1 July 2021", "journal-ref": "in IEEE Transactions on Parallel and Distributed Systems, vol. 32,\n  no. 7, pp. 1725-1739, 1 July 2021", "doi": "10.1109/TPDS.2020.3040606", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning at scale is dominated by communication time. Distributing\nsamples across nodes usually yields the best performance, but poses scaling\nchallenges due to global information dissemination and load imbalance across\nuneven sample lengths. State-of-the-art decentralized optimizers mitigate the\nproblem, but require more iterations to achieve the same accuracy as their\nglobally-communicating counterparts. We present Wait-Avoiding Group Model\nAveraging (WAGMA) SGD, a wait-avoiding stochastic optimizer that reduces global\ncommunication via subgroup weight exchange. The key insight is a combination of\nalgorithmic changes to the averaging scheme and the use of a group allreduce\noperation. We prove the convergence of WAGMA-SGD, and empirically show that it\nretains convergence rates similar to Allreduce-SGD. For evaluation, we train\nResNet-50 on ImageNet; Transformer for machine translation; and deep\nreinforcement learning for navigation at scale. Compared with state-of-the-art\ndecentralized SGD variants, WAGMA-SGD significantly improves training\nthroughput (e.g., 2.1x on 1,024 GPUs for reinforcement learning), and achieves\nthe fastest time-to-solution (e.g., the highest score using the shortest\ntraining time for Transformer).\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 22:11:53 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 09:26:19 GMT"}, {"version": "v3", "created": "Sat, 20 Feb 2021 15:36:09 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Li", "Shigang", ""], ["Ben-Nun", "Tal", ""], ["Nadiradze", "Giorgi", ""], ["Di Girolamo", "Salvatore", ""], ["Dryden", "Nikoli", ""], ["Alistarh", "Dan", ""], ["Hoefler", "Torsten", ""]]}, {"id": "2005.00129", "submitter": "Gideon Maillette de Buy Wenniger", "authors": "Gideon Maillette de Buy Wenniger, Thomas van Dongen, Eleri Aedmaa,\n  Herbert Teun Kruitbosch, Edwin A. Valentijn, and Lambert Schomaker", "title": "Structure-Tags Improve Text Classification for Scholarly Document\n  Quality Prediction", "comments": "This new version of the paper brings the paper up-to-date with the\n  improved paper, published at the First Workshop on Scholarly Document\n  Processing, at EMNLP 2020. .Additionally, minor corrections were made\n  including addition of color to Figures 1,2. The changes in comparison to the\n  first arXiv version are substantial, including various additional results,\n  and substantial improvements to the text", "journal-ref": "Proceedings of the First Workshop on Scholarly Document\n  Processing. Association for Computational Linguistics. (2020) 158-167.\n  EMNLP|SDP 2020 https://www.aclweb.org/anthology/2020.sdp-1.18", "doi": "10.18653/v1/2020.sdp-1.18", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training recurrent neural networks on long texts, in particular scholarly\ndocuments, causes problems for learning. While hierarchical attention networks\n(HANs) are effective in solving these problems, they still lose important\ninformation about the structure of the text. To tackle these problems, we\npropose the use of HANs combined with structure-tags which mark the role of\nsentences in the document. Adding tags to sentences, marking them as\ncorresponding to title, abstract or main body text, yields improvements over\nthe state-of-the-art for scholarly document quality prediction. The proposed\nsystem is applied to the task of accept/reject prediction on the PeerRead\ndataset and compared against a recent BiLSTM-based model and joint\ntextual+visual model as well as against plain HANs. Compared to plain HANs,\naccuracy increases on all three domains. On the computation and language domain\nour new model works best overall, and increases accuracy 4.7% over the best\nliterature result. We also obtain improvements when introducing the tags for\nprediction of the number of citations for 88k scientific publications that we\ncompiled from the Allen AI S2ORC dataset. For our HAN-system with\nstructure-tags we reach 28.5% explained variance, an improvement of 1.8% over\nour reimplementation of the BiLSTM-based model as well as 1.0% improvement over\nplain HANs.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 22:34:34 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 20:35:14 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Wenniger", "Gideon Maillette de Buy", ""], ["van Dongen", "Thomas", ""], ["Aedmaa", "Eleri", ""], ["Kruitbosch", "Herbert Teun", ""], ["Valentijn", "Edwin A.", ""], ["Schomaker", "Lambert", ""]]}, {"id": "2005.00130", "submitter": "Thanos Tagaris", "authors": "Thanos Tagaris, Andreas Stafylopatis", "title": "Hide-and-Seek: A Template for Explainable AI", "comments": "24 pages, 14 figures. Submitted on a special issue for Explainable\n  AI, on Elsevier's \"Artificial Intelligence\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Lack of transparency has been the Achilles heal of Neural Networks and their\nwider adoption in industry. Despite significant interest this shortcoming has\nnot been adequately addressed. This study proposes a novel framework called\nHide-and-Seek (HnS) for training Interpretable Neural Networks and establishes\na theoretical foundation for exploring and comparing similar ideas. Extensive\nexperimentation indicates that a high degree of interpretability can be imputed\ninto Neural Networks, without sacrificing their predictive power.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 22:34:37 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Tagaris", "Thanos", ""], ["Stafylopatis", "Andreas", ""]]}, {"id": "2005.00136", "submitter": "Yu Cheng", "authors": "Yu Cheng, Zhe Gan, Yizhe Zhang, Oussama Elachqar, Dianqi Li, Jingjing\n  Liu", "title": "Contextual Text Style Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new task, Contextual Text Style Transfer - translating a\nsentence into a desired style with its surrounding context taken into account.\nThis brings two key challenges to existing style transfer approaches: ($i$) how\nto preserve the semantic meaning of target sentence and its consistency with\nsurrounding context during transfer; ($ii$) how to train a robust model with\nlimited labeled data accompanied with context. To realize high-quality style\ntransfer with natural context preservation, we propose a Context-Aware Style\nTransfer (CAST) model, which uses two separate encoders for each input sentence\nand its surrounding context. A classifier is further trained to ensure\ncontextual consistency of the generated sentence. To compensate for the lack of\nparallel data, additional self-reconstruction and back-translation losses are\nintroduced to leverage non-parallel data in a semi-supervised fashion. Two new\nbenchmarks, Enron-Context and Reddit-Context, are introduced for formality and\noffensiveness style transfer. Experimental results on these datasets\ndemonstrate the effectiveness of the proposed CAST model over state-of-the-art\nmethods across style accuracy, content preservation and contextual consistency\nmetrics.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 23:01:12 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Cheng", "Yu", ""], ["Gan", "Zhe", ""], ["Zhang", "Yizhe", ""], ["Elachqar", "Oussama", ""], ["Li", "Dianqi", ""], ["Liu", "Jingjing", ""]]}, {"id": "2005.00145", "submitter": "Alessandro Ilic Mezza", "authors": "Alessandro Ilic Mezza, Emanu\\\"el A. P. Habets, Meinard M\\\"uller and\n  Augusto Sarti", "title": "Unsupervised Domain Adaptation for Acoustic Scene Classification Using\n  Band-Wise Statistics Matching", "comments": "5 pages, 1 figure, 3 tables, submitted to EUSIPCO 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of machine learning algorithms is known to be negatively\naffected by possible mismatches between training (source) and test (target)\ndata distributions. In fact, this problem emerges whenever an acoustic scene\nclassification system which has been trained on data recorded by a given device\nis applied to samples acquired under different acoustic conditions or captured\nby mismatched recording devices. To address this issue, we propose an\nunsupervised domain adaptation method that consists of aligning the first- and\nsecond-order sample statistics of each frequency band of target-domain acoustic\nscenes to the ones of the source-domain training dataset. This model-agnostic\napproach is devised to adapt audio samples from unseen devices before they are\nfed to a pre-trained classifier, thus avoiding any further learning phase.\nUsing the DCASE 2018 Task 1-B development dataset, we show that the proposed\nmethod outperforms the state-of-the-art unsupervised methods found in the\nliterature in terms of both source- and target-domain classification accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 23:56:05 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Mezza", "Alessandro Ilic", ""], ["Habets", "Emanu\u00ebl A. P.", ""], ["M\u00fcller", "Meinard", ""], ["Sarti", "Augusto", ""]]}, {"id": "2005.00146", "submitter": "Pauching Yap", "authors": "Pauching Yap, Hippolyt Ritter and David Barber", "title": "Addressing Catastrophic Forgetting in Few-Shot Problems", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are known to suffer from catastrophic forgetting when trained\non sequential datasets. While there have been numerous attempts to solve this\nproblem in large-scale supervised classification, little has been done to\novercome catastrophic forgetting in few-shot classification problems. We\ndemonstrate that the popular gradient-based model-agnostic meta-learning\nalgorithm (MAML) indeed suffers from catastrophic forgetting and introduce a\nBayesian online meta-learning framework that tackles this problem. Our\nframework utilises Bayesian online learning and meta-learning along with\nLaplace approximation and variational inference to overcome catastrophic\nforgetting in few-shot classification problems. The experimental evaluations\ndemonstrate that our framework can effectively achieve this goal in comparison\nwith various baselines. As an additional utility, we also demonstrate\nempirically that our framework is capable of meta-learning on sequentially\narriving few-shot tasks from a stationary task distribution.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 23:56:18 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 15:05:21 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 10:15:20 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Yap", "Pauching", ""], ["Ritter", "Hippolyt", ""], ["Barber", "David", ""]]}, {"id": "2005.00147", "submitter": "Yasumasa Onoe", "authors": "Yasumasa Onoe and Greg Durrett", "title": "Interpretable Entity Representations through Large-Scale Typing", "comments": "Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In standard methodology for natural language processing, entities in text are\ntypically embedded in dense vector spaces with pre-trained models. The\nembeddings produced this way are effective when fed into downstream models, but\nthey require end-task fine-tuning and are fundamentally difficult to interpret.\nIn this paper, we present an approach to creating entity representations that\nare human readable and achieve high performance on entity-related tasks out of\nthe box. Our representations are vectors whose values correspond to posterior\nprobabilities over fine-grained entity types, indicating the confidence of a\ntyping model's decision that the entity belongs to the corresponding type. We\nobtain these representations using a fine-grained entity typing model, trained\neither on supervised ultra-fine entity typing data (Choi et al. 2018) or\ndistantly-supervised examples from Wikipedia. On entity probing tasks involving\nrecognizing entity identity, our embeddings used in parameter-free downstream\nmodels achieve competitive performance with ELMo- and BERT-based embeddings in\ntrained models. We also show that it is possible to reduce the size of our type\nset in a learning-based way for particular domains. Finally, we show that these\nembeddings can be post-hoc modified through a small number of rules to\nincorporate domain knowledge and improve performance.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 23:58:03 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 01:18:13 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Onoe", "Yasumasa", ""], ["Durrett", "Greg", ""]]}, {"id": "2005.00152", "submitter": "Gong Cheng", "authors": "Junyou Li, Gong Cheng, Qingxia Liu, Wen Zhang, Evgeny Kharlamov, Kalpa\n  Gunaratna, Huajun Chen", "title": "Neural Entity Summarization with Joint Encoding and Weak Supervision", "comments": "7 pages, accepted to IJCAI-PRICAI 2020 The paper is temporarily\n  withdrawn due to company policies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In a large-scale knowledge graph (KG), an entity is often described by a\nlarge number of triple-structured facts. Many applications require abridged\nversions of entity descriptions, called entity summaries. Existing solutions to\nentity summarization are mainly unsupervised. In this paper, we present a\nsupervised approach NEST that is based on our novel neural model to jointly\nencode graph structure and text in KGs and generate high-quality diversified\nsummaries. Since it is costly to obtain manually labeled summaries for\ntraining, our supervision is weak as we train with programmatically labeled\ndata which may contain noise but is free of manual work. Evaluation results\nshow that our approach significantly outperforms the state of the art on two\npublic benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 00:14:08 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 08:30:29 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Li", "Junyou", ""], ["Cheng", "Gong", ""], ["Liu", "Qingxia", ""], ["Zhang", "Wen", ""], ["Kharlamov", "Evgeny", ""], ["Gunaratna", "Kalpa", ""], ["Chen", "Huajun", ""]]}, {"id": "2005.00159", "submitter": "Pratyush Maini", "authors": "Pratyush Maini, Keshav Kolluru, Danish Pruthi, Mausam", "title": "Why and when should you pool? Analyzing Pooling in Recurrent\n  Architectures", "comments": "Accepted to Findings of EMNLP 2020, to be presented at BlackBoxNLP.\n  Updated Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pooling-based recurrent neural architectures consistently outperform their\ncounterparts without pooling. However, the reasons for their enhanced\nperformance are largely unexamined. In this work, we examine three commonly\nused pooling techniques (mean-pooling, max-pooling, and attention), and propose\nmax-attention, a novel variant that effectively captures interactions among\npredictive tokens in a sentence. We find that pooling-based architectures\nsubstantially differ from their non-pooling equivalents in their learning\nability and positional biases--which elucidate their performance benefits. By\nanalyzing the gradient propagation, we discover that pooling facilitates better\ngradient flow compared to BiLSTMs. Further, we expose how BiLSTMs are\npositionally biased towards tokens in the beginning and the end of a sequence.\nPooling alleviates such biases. Consequently, we identify settings where\npooling offers large benefits: (i) in low resource scenarios, and (ii) when\nimportant words lie towards the middle of the sentence. Among the pooling\ntechniques studied, max-attention is the most effective, resulting in\nsignificant performance gains on several text classification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 00:47:37 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 02:11:02 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Maini", "Pratyush", ""], ["Kolluru", "Keshav", ""], ["Pruthi", "Danish", ""], ["Mausam", "", ""]]}, {"id": "2005.00162", "submitter": "Samuel Mensah", "authors": "Kai Sun, Richong Zhang, Samuel Mensah, Yongyi Mao, Xudong Liu", "title": "Recurrent Interaction Network for Jointly Extracting Entities and\n  Classifying Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of using multi-task learning approaches to address the joint\nextraction of entity and relation is motivated by the relatedness between the\nentity recognition task and the relation classification task. Existing methods\nusing multi-task learning techniques to address the problem learn interactions\namong the two tasks through a shared network, where the shared information is\npassed into the task-specific networks for prediction. However, such an\napproach hinders the model from learning explicit interactions between the two\ntasks to improve the performance on the individual tasks. As a solution, we\ndesign a multi-task learning model which we refer to as recurrent interaction\nnetwork which allows the learning of interactions dynamically, to effectively\nmodel task-specific features for classification. Empirical studies on two\nreal-world datasets confirm the superiority of the proposed model.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 01:03:16 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 02:54:49 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Sun", "Kai", ""], ["Zhang", "Richong", ""], ["Mensah", "Samuel", ""], ["Mao", "Yongyi", ""], ["Liu", "Xudong", ""]]}, {"id": "2005.00178", "submitter": "Clare Lyle", "authors": "Clare Lyle, Mark van der Wilk, Marta Kwiatkowska, Yarin Gal, Benjamin\n  Bloem-Reddy", "title": "On the Benefits of Invariance in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world data analysis problems exhibit invariant structure, and\nmodels that take advantage of this structure have shown impressive empirical\nperformance, particularly in deep learning. While the literature contains a\nvariety of methods to incorporate invariance into models, theoretical\nunderstanding is poor and there is no way to assess when one method should be\npreferred over another. In this work, we analyze the benefits and limitations\nof two widely used approaches in deep learning in the presence of invariance:\ndata augmentation and feature averaging. We prove that training with data\naugmentation leads to better estimates of risk and gradients thereof, and we\nprovide a PAC-Bayes generalization bound for models trained with data\naugmentation. We also show that compared to data augmentation, feature\naveraging reduces generalization error when used with convex losses, and\ntightens PAC-Bayes bounds. We provide empirical support of these theoretical\nresults, including a demonstration of why generalization may not improve by\ntraining with data augmentation: the `learned invariance' fails outside of the\ntraining distribution.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 02:08:58 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Lyle", "Clare", ""], ["van der Wilk", "Mark", ""], ["Kwiatkowska", "Marta", ""], ["Gal", "Yarin", ""], ["Bloem-Reddy", "Benjamin", ""]]}, {"id": "2005.00180", "submitter": "Melikasadat Emami", "authors": "Melikasadat Emami, Mojtaba Sahraee-Ardakan, Parthe Pandit, Sundeep\n  Rangan, Alyson K. Fletcher", "title": "Generalization Error of Generalized Linear Models in High Dimensions", "comments": "20 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the heart of machine learning lies the question of generalizability of\nlearned rules over previously unseen data. While over-parameterized models\nbased on neural networks are now ubiquitous in machine learning applications,\nour understanding of their generalization capabilities is incomplete. This task\nis made harder by the non-convexity of the underlying learning problems. We\nprovide a general framework to characterize the asymptotic generalization error\nfor single-layer neural networks (i.e., generalized linear models) with\narbitrary non-linearities, making it applicable to regression as well as\nclassification problems. This framework enables analyzing the effect of (i)\nover-parameterization and non-linearity during modeling; and (ii) choices of\nloss function, initialization, and regularizer during learning. Our model also\ncaptures mismatch between training and test distributions. As examples, we\nanalyze a few special cases, namely linear regression and logistic regression.\nWe are also able to rigorously and analytically explain the \\emph{double\ndescent} phenomenon in generalized linear models.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 02:17:47 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Emami", "Melikasadat", ""], ["Sahraee-Ardakan", "Mojtaba", ""], ["Pandit", "Parthe", ""], ["Rangan", "Sundeep", ""], ["Fletcher", "Alyson K.", ""]]}, {"id": "2005.00191", "submitter": "Hojjat Aghakhani", "authors": "Hojjat Aghakhani, Dongyu Meng, Yu-Xiang Wang, Christopher Kruegel, and\n  Giovanni Vigna", "title": "Bullseye Polytope: A Scalable Clean-Label Poisoning Attack with Improved\n  Transferability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent source of concern for the security of neural networks is the\nemergence of clean-label dataset poisoning attacks, wherein correctly labeled\npoison samples are injected into the training dataset. While these poison\nsamples look legitimate to the human observer, they contain malicious\ncharacteristics that trigger a targeted misclassification during inference. We\npropose a scalable and transferable clean-label poisoning attack against\ntransfer learning, which creates poison images with their center close to the\ntarget image in the feature space. Our attack, Bullseye Polytope, improves the\nattack success rate of the current state-of-the-art by 26.75% in end-to-end\ntransfer learning, while increasing attack speed by a factor of 12. We further\nextend Bullseye Polytope to a more practical attack model by including multiple\nimages of the same object (e.g., from different angles) when crafting the\npoison samples. We demonstrate that this extension improves attack\ntransferability by over 16% to unseen images (of the same object) without using\nextra poison samples.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 03:22:36 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 19:30:08 GMT"}, {"version": "v3", "created": "Sun, 14 Mar 2021 01:33:47 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Aghakhani", "Hojjat", ""], ["Meng", "Dongyu", ""], ["Wang", "Yu-Xiang", ""], ["Kruegel", "Christopher", ""], ["Vigna", "Giovanni", ""]]}, {"id": "2005.00200", "submitter": "Zhe Gan", "authors": "Linjie Li, Yen-Chun Chen, Yu Cheng, Zhe Gan, Licheng Yu, Jingjing Liu", "title": "HERO: Hierarchical Encoder for Video+Language Omni-representation\n  Pre-training", "comments": "Accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present HERO, a novel framework for large-scale video+language\nomni-representation learning. HERO encodes multimodal inputs in a hierarchical\nstructure, where local context of a video frame is captured by a Cross-modal\nTransformer via multimodal fusion, and global video context is captured by a\nTemporal Transformer. In addition to standard Masked Language Modeling (MLM)\nand Masked Frame Modeling (MFM) objectives, we design two new pre-training\ntasks: (i) Video-Subtitle Matching (VSM), where the model predicts both global\nand local temporal alignment; and (ii) Frame Order Modeling (FOM), where the\nmodel predicts the right order of shuffled video frames. HERO is jointly\ntrained on HowTo100M and large-scale TV datasets to gain deep understanding of\ncomplex social dynamics with multi-character interactions. Comprehensive\nexperiments demonstrate that HERO achieves new state of the art on multiple\nbenchmarks over Text-based Video/Video-moment Retrieval, Video Question\nAnswering (QA), Video-and-language Inference and Video Captioning tasks across\ndifferent domains. We also introduce two new challenging benchmarks How2QA and\nHow2R for Video QA and Retrieval, collected from diverse video content over\nmultimodalities.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 03:49:26 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 20:37:17 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Li", "Linjie", ""], ["Chen", "Yen-Chun", ""], ["Cheng", "Yu", ""], ["Gan", "Zhe", ""], ["Yu", "Licheng", ""], ["Liu", "Jingjing", ""]]}, {"id": "2005.00214", "submitter": "Ang Li", "authors": "Ang Li, Meghana Thotakuri, David A. Ross, Jo\\~ao Carreira, Alexander\n  Vostrikov, Andrew Zisserman", "title": "The AVA-Kinetics Localized Human Actions Video Dataset", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the AVA-Kinetics localized human actions video dataset.\nThe dataset is collected by annotating videos from the Kinetics-700 dataset\nusing the AVA annotation protocol, and extending the original AVA dataset with\nthese new AVA annotated Kinetics clips. The dataset contains over 230k clips\nannotated with the 80 AVA action classes for each of the humans in key-frames.\nWe describe the annotation process and provide statistics about the new\ndataset. We also include a baseline evaluation using the Video Action\nTransformer Network on the AVA-Kinetics dataset, demonstrating improved\nperformance for action classification on the AVA test set. The dataset can be\ndownloaded from https://research.google.com/ava/\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 04:17:14 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 17:40:28 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Li", "Ang", ""], ["Thotakuri", "Meghana", ""], ["Ross", "David A.", ""], ["Carreira", "Jo\u00e3o", ""], ["Vostrikov", "Alexander", ""], ["Zisserman", "Andrew", ""]]}, {"id": "2005.00218", "submitter": "Zhicong Liang", "authors": "Zhicong Liang, Bao Wang, Quanquan Gu, Stanley Osher, Yuan Yao", "title": "Exploring Private Federated Learning with Laplacian Smoothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning aims to protect data privacy by collaboratively learning a\nmodel without sharing private data among users. However, an adversary may still\nbe able to infer the private training data by attacking the released model.\nDifferential privacy(DP) provides a statistical guarantee against such attacks,\nat a privacy of possibly degenerating the accuracy or utility of the trained\nmodels. In this paper, we apply a utility enhancement scheme based on Laplacian\nsmoothing for differentially-private federated learning (DP-Fed-LS), where the\nparameter aggregation with injected Gaussian noise is improved in statistical\nprecision. We provide tight closed-form privacy bounds for both uniform and\nPoisson subsampling and derive corresponding DP guarantees for differential\nprivate federated learning, with or without Laplacian smoothing. Experiments\nover MNIST, SVHN and Shakespeare datasets show that the proposed method can\nimprove model accuracy with DP-guarantee under both subsampling mechanisms.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 04:28:38 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Liang", "Zhicong", ""], ["Wang", "Bao", ""], ["Gu", "Quanquan", ""], ["Osher", "Stanley", ""], ["Yao", "Yuan", ""]]}, {"id": "2005.00220", "submitter": "Juan Cabral", "authors": "Juan B. Cabral, Felipe Ramos, Sebasti\\'an Gurovich and Pablo Granitto", "title": "Automatic Catalog of RRLyrae from $\\sim$ 14 million VVV Light Curves:\n  How far can we go with traditional machine-learning?", "comments": null, "journal-ref": "A&A 642, A58 (2020)", "doi": "10.1051/0004-6361/202038314", "report-no": null, "categories": "astro-ph.IM astro-ph.SR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The creation of a 3D map of the bulge using RRLyrae (RRL) is one of the main\ngoals of the VVV(X) surveys. The overwhelming number of sources under analysis\nrequest the use of automatic procedures. In this context, previous works\nintroduced the use of Machine Learning (ML) methods for the variable star\nclassification. Our goal is the development and analysis of an automatic\nprocedure, based on ML, for the identification of RRLs in the VVV Survey. This\nprocedure will be use to generate reliable catalogs integrated over several\ntiles in the survey. After the reconstruction of light-curves, we extract a set\nof period and intensity-based features. We use for the first time a new subset\nof pseudo color features. We discuss all the appropriate steps needed to define\nour automatic pipeline: selection of quality measures; sampling procedures;\nclassifier setup and model selection. As final result, we construct an ensemble\nclassifier with an average Recall of 0.48 and average Precision of 0.86 over 15\ntiles. We also make available our processed datasets and a catalog of candidate\nRRLs. Perhaps most interestingly, from a classification perspective based on\nphotometric broad-band data, is that our results indicate that Color is an\ninformative feature type of the RRL that should be considered for automatic\nclassification methods via ML. We also argue that Recall and Precision in both\ntables and curves are high quality metrics for this highly imbalanced problem.\nFurthermore, we show for our VVV data-set that to have good estimates it is\nimportant to use the original distribution more than reduced samples with an\nartificial balance. Finally, we show that the use of ensemble classifiers helps\nresolve the crucial model selection step, and that most errors in the\nidentification of RRLs are related to low quality observations of some sources\nor to the difficulty to resolve the RRL-C type given the date.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 04:35:57 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 19:29:32 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Cabral", "Juan B.", ""], ["Ramos", "Felipe", ""], ["Gurovich", "Sebasti\u00e1n", ""], ["Granitto", "Pablo", ""]]}, {"id": "2005.00227", "submitter": "You Zhou", "authors": "Jianfeng Gao and You Zhou and Tamim Asfour", "title": "Learning Compliance Adaptation in Contact-Rich Manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compliant robot behavior is crucial for the realization of contact-rich\nmanipulation tasks. In such tasks, it is important to ensure a high stiffness\nand force tracking accuracy during normal task execution as well as rapid\nadaptation and complaint behavior to react to abnormal situations and changes.\nIn this paper, we propose a novel approach for learning predictive models of\nforce profiles required for contact-rich tasks. Such models allow detecting\nunexpected situations and facilitates better adaptive control. The approach\ncombines an anomaly detection based on Bidirectional Gated Recurrent Units\n(Bi-GRU) and an adaptive force/impedance controller. We evaluated the approach\nin simulated and real world experiments on a humanoid robot.The results show\nthat the approach allow simultaneous high tracking accuracy of desired motions\nand force profile as well as the adaptation to force perturbations due to\nphysical human interaction.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 05:23:34 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Gao", "Jianfeng", ""], ["Zhou", "You", ""], ["Asfour", "Tamim", ""]]}, {"id": "2005.00239", "submitter": "Mujeen Sung", "authors": "Mujeen Sung, Hwisang Jeon, Jinhyuk Lee, Jaewoo Kang", "title": "Biomedical Entity Representations with Synonym Marginalization", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomedical named entities often play important roles in many biomedical text\nmining tools. However, due to the incompleteness of provided synonyms and\nnumerous variations in their surface forms, normalization of biomedical\nentities is very challenging. In this paper, we focus on learning\nrepresentations of biomedical entities solely based on the synonyms of\nentities. To learn from the incomplete synonyms, we use a model-based candidate\nselection and maximize the marginal likelihood of the synonyms present in top\ncandidates. Our model-based candidates are iteratively updated to contain more\ndifficult negative samples as our model evolves. In this way, we avoid the\nexplicit pre-selection of negative samples from more than 400K candidates. On\nfour biomedical entity normalization datasets having three different entity\ntypes (disease, chemical, adverse reaction), our model BioSyn consistently\noutperforms previous state-of-the-art models almost reaching the upper bound on\neach dataset.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 06:20:36 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Sung", "Mujeen", ""], ["Jeon", "Hwisang", ""], ["Lee", "Jinhyuk", ""], ["Kang", "Jaewoo", ""]]}, {"id": "2005.00246", "submitter": "Ashish V. Thapliyal", "authors": "Ashish V. Thapliyal and Radu Soricut", "title": "Cross-modal Language Generation using Pivot Stabilization for Web-scale\n  Language Coverage", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-modal language generation tasks such as image captioning are directly\nhurt in their ability to support non-English languages by the trend of\ndata-hungry models combined with the lack of non-English annotations. We\ninvestigate potential solutions for combining existing language-generation\nannotations in English with translation capabilities in order to create\nsolutions at web-scale in both domain and language coverage. We describe an\napproach called Pivot-Language Generation Stabilization (PLuGS), which\nleverages directly at training time both existing English annotations (gold\ndata) as well as their machine-translated versions (silver data); at run-time,\nit generates first an English caption and then a corresponding target-language\ncaption. We show that PLuGS models outperform other candidate solutions in\nevaluations performed over 5 different target languages, under a large-domain\ntestset using images from the Open Images dataset. Furthermore, we find an\ninteresting effect where the English captions generated by the PLuGS models are\nbetter than the captions generated by the original, monolingual English model.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 06:58:18 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Thapliyal", "Ashish V.", ""], ["Soricut", "Radu", ""]]}, {"id": "2005.00259", "submitter": "Shuchu Han", "authors": "Shuchu Han, Alexandru Niculescu-Mizil", "title": "Supervised Feature Subset Selection and Feature Ranking for Multivariate\n  Time Series without Feature Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce supervised feature ranking and feature subset selection\nalgorithms for multivariate time series (MTS) classification. Unlike most\nexisting supervised/unsupervised feature selection algorithms for MTS our\ntechniques do not require a feature extraction step to generate a\none-dimensional feature vector from the time series. Instead it is based on\ndirectly computing similarity between individual time series and assessing how\nwell the resulting cluster structure matches the labels. The techniques are\namenable to heterogeneous MTS data, where the time series measurements may have\ndifferent sampling resolutions, and to multi-modal data.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 07:46:29 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Han", "Shuchu", ""], ["Niculescu-Mizil", "Alexandru", ""]]}, {"id": "2005.00278", "submitter": "Yanpeng Zhao", "authors": "Yanpeng Zhao and Ivan Titov", "title": "Unsupervised Transfer of Semantic Role Models from Verbal to Nominal\n  Domain", "comments": "Our code is available at https://github.com/zhaoyanpeng/srltransfer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Semantic role labeling (SRL) is an NLP task involving the assignment of\npredicate arguments to types, called semantic roles. Though research on SRL has\nprimarily focused on verbal predicates and many resources available for SRL\nprovide annotations only for verbs, semantic relations are often triggered by\nother linguistic constructions, e.g., nominalizations. In this work, we\ninvestigate a transfer scenario where we assume role-annotated data for the\nsource verbal domain but only unlabeled data for the target nominal domain. Our\nkey assumption, enabling the transfer between the two domains, is that\nselectional preferences of a role (i.e., preferences or constraints on the\nadmissible arguments) do not strongly depend on whether the relation is\ntriggered by a verb or a noun. For example, the same set of arguments can fill\nthe Acquirer role for the verbal predicate `acquire' and its nominal form\n`acquisition'. We approach the transfer task from the variational autoencoding\nperspective. The labeler serves as an encoder (predicting role labels given a\nsentence), whereas selectional preferences are captured in the decoder\ncomponent (generating arguments for the predicting roles). Nominal roles are\nnot labeled in the training data, and the learning objective instead pushes the\nlabeler to assign roles predictive of the arguments. Sharing the decoder\nparameters across the domains encourages consistency between labels predicted\nfor both domains and facilitates the transfer. The method substantially\noutperforms baselines, such as unsupervised and `direct transfer' methods, on\nthe English CoNLL-2009 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 09:20:48 GMT"}, {"version": "v2", "created": "Sat, 26 Sep 2020 12:56:08 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Zhao", "Yanpeng", ""], ["Titov", "Ivan", ""]]}, {"id": "2005.00295", "submitter": "Manikandan Ravikiran", "authors": "Manikandan Ravikiran, Amin Ekant Muljibhai, Toshinori Miyoshi, Hiroaki\n  Ozaki, Yuta Koreeda and Sakata Masayuki", "title": "Hitachi at SemEval-2020 Task 12: Offensive Language Identification with\n  Noisy Labels using Statistical Sampling and Post-Processing", "comments": "preprint v1, Under submission for SemEval 2020 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present our participation in SemEval-2020 Task-12 Subtask-A\n(English Language) which focuses on offensive language identification from\nnoisy labels. To this end, we developed a hybrid system with the BERT\nclassifier trained with tweets selected using Statistical Sampling Algorithm\n(SA) and Post-Processed (PP) using an offensive wordlist. Our developed system\nachieved 34 th position with Macro-averaged F1-score (Macro-F1) of 0.90913 over\nboth offensive and non-offensive classes. We further show comprehensive results\nand error analysis to assist future research in offensive language\nidentification with noisy labels.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 10:16:40 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Ravikiran", "Manikandan", ""], ["Muljibhai", "Amin Ekant", ""], ["Miyoshi", "Toshinori", ""], ["Ozaki", "Hiroaki", ""], ["Koreeda", "Yuta", ""], ["Masayuki", "Sakata", ""]]}, {"id": "2005.00311", "submitter": "Ronen Tamari", "authors": "Ronen Tamari, Chen Shani, Tom Hope, Miriam R. L. Petruck, Omri Abend,\n  Dafna Shahaf", "title": "Language (Re)modelling: Towards Embodied Language Understanding", "comments": "Accepted to ACL2020 Theme Track. Extended bibliography version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While natural language understanding (NLU) is advancing rapidly, today's\ntechnology differs from human-like language understanding in fundamental ways,\nnotably in its inferior efficiency, interpretability, and generalization. This\nwork proposes an approach to representation and learning based on the tenets of\nembodied cognitive linguistics (ECL). According to ECL, natural language is\ninherently executable (like programming languages), driven by mental simulation\nand metaphoric mappings over hierarchical compositions of structures and\nschemata learned through embodied interaction. This position paper argues that\nthe use of grounding by metaphoric inference and simulation will greatly\nbenefit NLU systems, and proposes a system architecture along with a roadmap\ntowards realizing this vision.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 10:57:02 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 12:53:34 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Tamari", "Ronen", ""], ["Shani", "Chen", ""], ["Hope", "Tom", ""], ["Petruck", "Miriam R. L.", ""], ["Abend", "Omri", ""], ["Shahaf", "Dafna", ""]]}, {"id": "2005.00316", "submitter": "Pratyay Banerjee", "authors": "Pratyay Banerjee, Chitta Baral", "title": "Self-supervised Knowledge Triplet Learning for Zero-shot Question\n  Answering", "comments": "Accepted to EMNLP 2020 Long Papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of all Question Answering (QA) systems is to be able to generalize to\nunseen questions. Current supervised methods are reliant on expensive data\nannotation. Moreover, such annotations can introduce unintended annotator bias\nwhich makes systems focus more on the bias than the actual task. In this work,\nwe propose Knowledge Triplet Learning (KTL), a self-supervised task over\nknowledge graphs. We propose heuristics to create synthetic graphs for\ncommonsense and scientific knowledge. We propose methods of how to use KTL to\nperform zero-shot QA and our experiments show considerable improvements over\nlarge pre-trained transformer models.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 11:24:18 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 20:49:29 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Banerjee", "Pratyay", ""], ["Baral", "Chitta", ""]]}, {"id": "2005.00318", "submitter": "Djam\\'e Seddah", "authors": "Benjamin Muller and Benoit Sagot and Djam\\'e Seddah", "title": "Can Multilingual Language Models Transfer to an Unseen Dialect? A Case\n  Study on North African Arabizi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Building natural language processing systems for non standardized and low\nresource languages is a difficult challenge. The recent success of large-scale\nmultilingual pretrained language models provides new modeling tools to tackle\nthis. In this work, we study the ability of multilingual language models to\nprocess an unseen dialect. We take user generated North-African Arabic as our\ncase study, a resource-poor dialectal variety of Arabic with frequent\ncode-mixing with French and written in Arabizi, a non-standardized\ntransliteration of Arabic to Latin script. Focusing on two tasks,\npart-of-speech tagging and dependency parsing, we show in zero-shot and\nunsupervised adaptation scenarios that multilingual language models are able to\ntransfer to such an unseen dialect, specifically in two extreme cases: (i)\nacross scripts, using Modern Standard Arabic as a source language, and (ii)\nfrom a distantly related language, unseen during pretraining, namely Maltese.\nOur results constitute the first successful transfer experiments on this\ndialect, paving thus the way for the development of an NLP ecosystem for\nresource-scarce, non-standardized and highly variable vernacular languages.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 11:29:23 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Muller", "Benjamin", ""], ["Sagot", "Benoit", ""], ["Seddah", "Djam\u00e9", ""]]}, {"id": "2005.00326", "submitter": "Mohammad Hekmatnejad", "authors": "Mohammad Hekmatnejad, Bardh Hoxha and Georgios Fainekos", "title": "Search-based Test-Case Generation by Monitoring Responsibility Safety\n  Rules", "comments": "8 pages, 5 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The safety of Automated Vehicles (AV) as Cyber-Physical Systems (CPS) depends\non the safety of their consisting modules (software and hardware) and their\nrigorous integration. Deep Learning is one of the dominant techniques used for\nperception, prediction, and decision making in AVs. The accuracy of predictions\nand decision-making is highly dependant on the tests used for training their\nunderlying deep-learning. In this work, we propose a method for screening and\nclassifying simulation-based driving test data to be used for training and\ntesting controllers. Our method is based on monitoring and falsification\ntechniques, which lead to a systematic automated procedure for generating and\nselecting qualified test data. We used Responsibility Sensitive Safety (RSS)\nrules as our qualifier specifications to filter out the random tests that do\nnot satisfy the RSS assumptions. Therefore, the remaining tests cover driving\nscenarios that the controlled vehicle does not respond safely to its\nenvironment. Our framework is distributed with the publicly available S-TALIRO\nand Sim-ATAV tools.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 10:10:11 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Hekmatnejad", "Mohammad", ""], ["Hoxha", "Bardh", ""], ["Fainekos", "Georgios", ""]]}, {"id": "2005.00329", "submitter": "Lei Shen", "authors": "Lei Shen, Yang Feng", "title": "CDL: Curriculum Dual Learning for Emotion-Controllable Response\n  Generation", "comments": "To appear at ACL 2020 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion-controllable response generation is an attractive and valuable task\nthat aims to make open-domain conversations more empathetic and engaging.\nExisting methods mainly enhance the emotion expression by adding regularization\nterms to standard cross-entropy loss and thus influence the training process.\nHowever, due to the lack of further consideration of content consistency, the\ncommon problem of response generation tasks, safe response, is intensified.\nBesides, query emotions that can help model the relationship between query and\nresponse are simply ignored in previous models, which would further hurt the\ncoherence. To alleviate these problems, we propose a novel framework named\nCurriculum Dual Learning (CDL) which extends the emotion-controllable response\ngeneration to a dual task to generate emotional responses and emotional queries\nalternatively. CDL utilizes two rewards focusing on emotion and content to\nimprove the duality. Additionally, it applies curriculum learning to gradually\ngenerate high-quality responses based on the difficulties of expressing various\nemotions. Experimental results show that CDL significantly outperforms the\nbaselines in terms of coherence, diversity, and relation to emotion factors.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 12:16:44 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 04:31:34 GMT"}, {"version": "v3", "created": "Thu, 28 May 2020 09:39:15 GMT"}, {"version": "v4", "created": "Wed, 3 Jun 2020 11:31:47 GMT"}, {"version": "v5", "created": "Sun, 7 Jun 2020 12:54:28 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Shen", "Lei", ""], ["Feng", "Yang", ""]]}, {"id": "2005.00336", "submitter": "Vidyasagar Sadhu", "authors": "Vidyasagar Sadhu, Saman Zonouz, Dario Pompili", "title": "On-board Deep-learning-based Unmanned Aerial Vehicle Fault Cause\n  Detection and Identification", "comments": "IEEE International Conference on Robotics and Automation (ICRA), May\n  2020, 6+1 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increase in use of Unmanned Aerial Vehicles (UAVs)/drones, it is\nimportant to detect and identify causes of failure in real time for proper\nrecovery from a potential crash-like scenario or post incident forensics\nanalysis. The cause of crash could be either a fault in the sensor/actuator\nsystem, a physical damage/attack, or a cyber attack on the drone's software. In\nthis paper, we propose novel architectures based on deep Convolutional and Long\nShort-Term Memory Neural Networks (CNNs and LSTMs) to detect (via Autoencoder)\nand classify drone mis-operations based on sensor data. The proposed\narchitectures are able to learn high-level features automatically from the raw\nsensor data and learn the spatial and temporal dynamics in the sensor data. We\nvalidate the proposed deep-learning architectures via simulations and\nexperiments on a real drone. Empirical results show that our solution is able\nto detect with over 90% accuracy and classify various types of drone\nmis-operations (with about 99% accuracy (simulation data) and upto 88% accuracy\n(experimental data)).\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 22:46:34 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 18:55:28 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Sadhu", "Vidyasagar", ""], ["Zonouz", "Saman", ""], ["Pompili", "Dario", ""]]}, {"id": "2005.00341", "submitter": "Prafulla Dhariwal", "authors": "Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec\n  Radford, Ilya Sutskever", "title": "Jukebox: A Generative Model for Music", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Jukebox, a model that generates music with singing in the raw\naudio domain. We tackle the long context of raw audio using a multi-scale\nVQ-VAE to compress it to discrete codes, and modeling those using\nautoregressive Transformers. We show that the combined model at scale can\ngenerate high-fidelity and diverse songs with coherence up to multiple minutes.\nWe can condition on artist and genre to steer the musical and vocal style, and\non unaligned lyrics to make the singing more controllable. We are releasing\nthousands of non cherry-picked samples at https://jukebox.openai.com, along\nwith model weights and code at https://github.com/openai/jukebox\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 09:02:45 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Dhariwal", "Prafulla", ""], ["Jun", "Heewoo", ""], ["Payne", "Christine", ""], ["Kim", "Jong Wook", ""], ["Radford", "Alec", ""], ["Sutskever", "Ilya", ""]]}, {"id": "2005.00352", "submitter": "Louis Martin", "authors": "Louis Martin, Angela Fan, \\'Eric de la Clergerie, Antoine Bordes,\n  Beno\\^it Sagot", "title": "MUSS: Multilingual Unsupervised Sentence Simplification by Mining\n  Paraphrases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress in sentence simplification has been hindered by a lack of labeled\nparallel simplification data, particularly in languages other than English. We\nintroduce MUSS, a Multilingual Unsupervised Sentence Simplification system that\ndoes not require labeled simplification data. MUSS uses a novel approach to\nsentence simplification that trains strong models using sentence-level\nparaphrase data instead of proper simplification data. These models leverage\nunsupervised pretraining and controllable generation mechanisms to flexibly\nadjust attributes such as length and lexical complexity at inference time. We\nfurther present a method to mine such paraphrase data in any language from\nCommon Crawl using semantic sentence embeddings, thus removing the need for\nlabeled data. We evaluate our approach on English, French, and Spanish\nsimplification benchmarks and closely match or outperform the previous best\nsupervised results, despite not using any labeled simplification data. We push\nthe state of the art further by incorporating labeled simplification data.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 12:54:30 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 15:08:50 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Martin", "Louis", ""], ["Fan", "Angela", ""], ["de la Clergerie", "\u00c9ric", ""], ["Bordes", "Antoine", ""], ["Sagot", "Beno\u00eet", ""]]}, {"id": "2005.00359", "submitter": "Peter beim Graben", "authors": "Peter beim Graben, Ronald R\\\"omer, Werner Meyer, Markus Huber,\n  Matthias Wolff", "title": "Reinforcement learning of minimalist grammars", "comments": "25 pages, 2 figures, 9 tables. arXiv admin note: text overlap with\n  arXiv:1906.04447", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech-controlled user interfaces facilitate the operation of devices and\nhousehold functions to laymen. State-of-the-art language technology scans the\nacoustically analyzed speech signal for relevant keywords that are subsequently\ninserted into semantic slots to interpret the user's intent. In order to\ndevelop proper cognitive information and communication technologies, simple\nslot-filling should be replaced by utterance meaning transducers (UMT) that are\nbased on semantic parsers and a mental lexicon, comprising syntactic, phonetic\nand semantic features of the language under consideration. This lexicon must be\nacquired by a cognitive agent during interaction with its users. We outline a\nreinforcement learning algorithm for the acquisition of syntax and semantics of\nEnglish utterances, based on minimalist grammar (MG), a recent computational\nimplementation of generative linguistics. English declarative sentences are\npresented to the agent by a teacher in form of utterance meaning pairs (UMP)\nwhere the meanings are encoded as formulas of predicate logic. Since MG\ncodifies universal linguistic competence through inference rules, thereby\nseparating innate linguistic knowledge from the contingently acquired lexicon,\nour approach unifies generative grammar and reinforcement learning, hence\npotentially resolving the still pending Chomsky-Skinner controversy.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 14:25:58 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Graben", "Peter beim", ""], ["R\u00f6mer", "Ronald", ""], ["Meyer", "Werner", ""], ["Huber", "Markus", ""], ["Wolff", "Matthias", ""]]}, {"id": "2005.00372", "submitter": "Navid Rekabsaz", "authors": "Navid Rekabsaz, Markus Schedl", "title": "Do Neural Ranking Models Intensify Gender Bias?", "comments": "In Proceedings of ACM SIGIR 2020", "journal-ref": null, "doi": "10.1145/3397271.3401280", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concerns regarding the footprint of societal biases in information retrieval\n(IR) systems have been raised in several previous studies. In this work, we\nexamine various recent IR models from the perspective of the degree of gender\nbias in their retrieval results. To this end, we first provide a bias\nmeasurement framework which includes two metrics to quantify the degree of the\nunbalanced presence of gender-related concepts in a given IR model's ranking\nlist. To examine IR models by means of the framework, we create a dataset of\nnon-gendered queries, selected by human annotators. Applying these queries to\nthe MS MARCO Passage retrieval collection, we then measure the gender bias of a\nBM25 model and several recent neural ranking models. The results show that\nwhile all models are strongly biased toward male, the neural models, and in\nparticular the ones based on contextualized embedding models, significantly\nintensify gender bias. Our experiments also show an overall increase in the\ngender bias of neural models when they exploit transfer learning, namely when\nthey use (already biased) pre-trained embeddings.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 13:31:11 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 08:10:14 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 13:11:59 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Rekabsaz", "Navid", ""], ["Schedl", "Markus", ""]]}, {"id": "2005.00393", "submitter": "Nicola Landro", "authors": "Nicola Landro and Ignazio Gallo and Riccardo La Grassa", "title": "Can a powerful neural network be a teacher for a weaker neural network?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transfer learning technique is widely used to learning in one context and\napplying it to another, i.e. the capacity to apply acquired knowledge and\nskills to new situations. But is it possible to transfer the learning from a\ndeep neural network to a weaker neural network? Is it possible to improve the\nperformance of a weak neural network using the knowledge acquired by a more\npowerful neural network? In this work, during the training process of a weak\nnetwork, we add a loss function that minimizes the distance between the\nfeatures previously learned from a strong neural network with the features that\nthe weak network must try to learn. To demonstrate the effectiveness and\nrobustness of our approach, we conducted a large number of experiments using\nthree known datasets and demonstrated that a weak neural network can increase\nits performance if its learning process is driven by a more powerful neural\nnetwork.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 14:19:40 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 07:47:00 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Landro", "Nicola", ""], ["Gallo", "Ignazio", ""], ["La Grassa", "Riccardo", ""]]}, {"id": "2005.00397", "submitter": "Brighter Agyemang", "authors": "Brighter Agyemang and Wei-Ping Wu and Michael Yelpengne Kpiebaareh and\n  Zhihua Lei and Ebenezer Nanor and Lei Chen", "title": "Multi-View Self-Attention for Interpretable Drug-Target Interaction\n  Prediction", "comments": null, "journal-ref": null, "doi": "10.1016/j.jbi.2020.103547", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The drug discovery stage is a vital aspect of the drug development process\nand forms part of the initial stages of the development pipeline. In recent\ntimes, machine learning-based methods are actively being used to model\ndrug-target interactions for rational drug discovery due to the successful\napplication of these methods in other domains. In machine learning approaches,\nthe numerical representation of molecules is critical to the performance of the\nmodel. While significant progress has been made in molecular representation\nengineering, this has resulted in several descriptors for both targets and\ncompounds. Also, the interpretability of model predictions is a vital feature\nthat could have several pharmacological applications. In this study, we propose\na self-attention-based multi-view representation learning approach for modeling\ndrug-target interactions. We evaluated our approach using three benchmark\nkinase datasets and compared the proposed method to some baseline models. Our\nexperimental results demonstrate the ability of our method to achieve\ncompetitive prediction performance and offer biologically plausible drug-target\ninteraction interpretations.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 14:28:17 GMT"}, {"version": "v2", "created": "Sun, 23 Aug 2020 14:49:47 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Agyemang", "Brighter", ""], ["Wu", "Wei-Ping", ""], ["Kpiebaareh", "Michael Yelpengne", ""], ["Lei", "Zhihua", ""], ["Nanor", "Ebenezer", ""], ["Chen", "Lei", ""]]}, {"id": "2005.00406", "submitter": "Hanrui Wang", "authors": "Hanrui Wang and Kuan Wang and Jiacheng Yang and Linxiao Shen and Nan\n  Sun and Hae-Seung Lee and Song Han", "title": "GCN-RL Circuit Designer: Transferable Transistor Sizing with Graph\n  Neural Networks and Reinforcement Learning", "comments": "Accepted to the 57th Design Automation Conference (DAC 2020); 6\n  pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic transistor sizing is a challenging problem in circuit design due to\nthe large design space, complex performance trade-offs, and fast technological\nadvancements. Although there has been plenty of work on transistor sizing\ntargeting on one circuit, limited research has been done on transferring the\nknowledge from one circuit to another to reduce the re-design overhead. In this\npaper, we present GCN-RL Circuit Designer, leveraging reinforcement learning\n(RL) to transfer the knowledge between different technology nodes and\ntopologies. Moreover, inspired by the simple fact that circuit is a graph, we\nlearn on the circuit topology representation with graph convolutional neural\nnetworks (GCN). The GCN-RL agent extracts features of the topology graph whose\nvertices are transistors, edges are wires. Our learning-based optimization\nconsistently achieves the highest Figures of Merit (FoM) on four different\ncircuits compared with conventional black-box optimization methods (Bayesian\nOptimization, Evolutionary Algorithms), random search, and human expert\ndesigns. Experiments on transfer learning between five technology nodes and two\ncircuit topologies demonstrate that RL with transfer learning can achieve much\nhigher FoMs than methods without knowledge transfer. Our transferable\noptimization method makes transistor sizing and design porting more effective\nand efficient.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:58:07 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Wang", "Hanrui", ""], ["Wang", "Kuan", ""], ["Yang", "Jiacheng", ""], ["Shen", "Linxiao", ""], ["Sun", "Nan", ""], ["Lee", "Hae-Seung", ""], ["Han", "Song", ""]]}, {"id": "2005.00407", "submitter": "Metin Ozturk", "authors": "Metin Ozturk, Attai Ibrahim Abubakar, Rao Naveed Bin Rais, Mona Jaber,\n  Sajjad Hussain, Muhammad Ali Imran", "title": "Context-Aware Wireless Connectivity and Processing Unit Optimization for\n  IoT Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel approach is presented in this work for context-aware connectivity and\nprocessing optimization of Internet of things (IoT) networks. Different from\nthe state-of-the-art approaches, the proposed approach simultaneously selects\nthe best connectivity and processing unit (e.g., device, fog, and cloud) along\nwith the percentage of data to be offloaded by jointly optimizing energy\nconsumption, response-time, security, and monetary cost. The proposed scheme\nemploys a reinforcement learning algorithm, and manages to achieve significant\ngains compared to deterministic solutions. In particular, the requirements of\nIoT devices in terms of response-time and security are taken as inputs along\nwith the remaining battery level of the devices, and the developed algorithm\nreturns an optimized policy. The results obtained show that only our method is\nable to meet the holistic multi-objective optimisation criteria, albeit, the\nbenchmark approaches may achieve better results on a particular metric at the\ncost of failing to reach the other targets. Thus, the proposed approach is a\ndevice-centric and context-aware solution that accounts for the monetary and\nbattery constraints.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 02:18:35 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Ozturk", "Metin", ""], ["Abubakar", "Attai Ibrahim", ""], ["Rais", "Rao Naveed Bin", ""], ["Jaber", "Mona", ""], ["Hussain", "Sajjad", ""], ["Imran", "Muhammad Ali", ""]]}, {"id": "2005.00409", "submitter": "Karush Suri", "authors": "Karush Suri, Rinki Gupta", "title": "Continuous sign language recognition from wearable IMUs using deep\n  capsule networks and game theory", "comments": null, "journal-ref": null, "doi": "10.1016/j.compeleceng.2019.08.006", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sign Language is used by the deaf community all over world. The work\npresented here proposes a novel one-dimensional deep capsule network (CapsNet)\narchitecture for continuous Indian Sign Language recognition by means of\nsignals obtained from a custom designed wearable IMU system. The performance of\nthe proposed CapsNet architecture is assessed by altering dynamic routing\nbetween capsule layers. The proposed CapsNet yields improved accuracy values of\n94% for 3 routings and 92.50% for 5 routings in comparison with the\nconvolutional neural network (CNN) that yields an accuracy of 87.99%. Improved\nlearning of the proposed architecture is also validated by spatial activations\ndepicting excited units at the predictive layer. Finally, a novel\nnon-cooperative pick-and-predict competition is designed between CapsNet and\nCNN. Higher value of Nash equilibrium for CapsNet as compared to CNN indicates\nthe suitability of the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 01:21:16 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Suri", "Karush", ""], ["Gupta", "Rinki", ""]]}, {"id": "2005.00410", "submitter": "Karush Suri", "authors": "Karush Suri, Rinki Gupta", "title": "Classification of Hand Gestures from Wearable IMUs using Deep Neural\n  Network", "comments": null, "journal-ref": null, "doi": "10.1109/ICICCT.2018.8473301", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IMUs are gaining significant importance in the field of hand gesture\nanalysis, trajectory detection and kinematic functional study. An Inertial\nMeasurement Unit (IMU) consists of tri-axial accelerometers and gyroscopes\nwhich can together be used for formation analysis. The paper presents a novel\nclassification approach using a Deep Neural Network (DNN) for classifying hand\ngestures obtained from wearable IMU sensors. An optimization objective is set\nfor the classifier in order to reduce correlation between the activities and\nfit the signal-set with best performance parameters. Training of the network is\ncarried out by feed-forward computation of the input features followed by the\nback-propagation of errors. The predicted outputs are analyzed in the form of\nclassification accuracies which are then compared to the conventional\nclassification schemes of SVM and kNN. A 3-5% improvement in accuracies is\nobserved in the case of DNN classification. Results are presented for the\nrecorded accelerometer and gyroscope signals and the considered classification\nschemes.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 01:08:33 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Suri", "Karush", ""], ["Gupta", "Rinki", ""]]}, {"id": "2005.00446", "submitter": "Zhaoyang Wang", "authors": "Zhaoyang Wang and Hongtao Wang", "title": "Defense of Word-level Adversarial Attacks via Random Substitution\n  Encoding", "comments": "12 pages, 2 figures, 4 tables. Accepted as a FULL paper at KSEM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adversarial attacks against deep neural networks on computer vision tasks\nhave spawned many new technologies that help protect models from avoiding false\npredictions. Recently, word-level adversarial attacks on deep models of Natural\nLanguage Processing (NLP) tasks have also demonstrated strong power, e.g.,\nfooling a sentiment classification neural network to make wrong decisions.\nUnfortunately, few previous literatures have discussed the defense of such\nword-level synonym substitution based attacks since they are hard to be\nperceived and detected. In this paper, we shed light on this problem and\npropose a novel defense framework called Random Substitution Encoding (RSE),\nwhich introduces a random substitution encoder into the training process of\noriginal neural networks. Extensive experiments on text classification tasks\ndemonstrate the effectiveness of our framework on defense of word-level\nadversarial attacks, under various base and attack models.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 15:28:43 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 05:55:34 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Wang", "Zhaoyang", ""], ["Wang", "Hongtao", ""]]}, {"id": "2005.00447", "submitter": "Snigdha Bhagat Ms", "authors": "Snigdha Bhagat, S. D. Joshi, Brejesh Lall", "title": "Image fusion using symmetric skip autoencodervia an Adversarial\n  Regulariser", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a challenging task to extract the best of both worlds by combining the\nspatial characteristics of a visible image and the spectral content of an\ninfrared image. In this work, we propose a spatially constrained adversarial\nautoencoder that extracts deep features from the infrared and visible images to\nobtain a more exhaustive and global representation. In this paper, we propose a\nresidual autoencoder architecture, regularised by a residual adversarial\nnetwork, to generate a more realistic fused image. The residual module serves\nas primary building for the encoder, decoder and adversarial network, as an add\non the symmetric skip connections perform the functionality of embedding the\nspatial characteristics directly from the initial layers of encoder structure\nto the decoder part of the network. The spectral information in the infrared\nimage is incorporated by adding the feature maps over several layers in the\nencoder part of the fusion structure, which makes inference on both the visual\nand infrared images separately. In order to efficiently optimize the parameters\nof the network, we propose an adversarial regulariser network which would\nperform supervised learning on the fused image and the original visual image.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 15:31:45 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 07:33:25 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Bhagat", "Snigdha", ""], ["Joshi", "S. D.", ""], ["Lall", "Brejesh", ""]]}, {"id": "2005.00455", "submitter": "Carl Yang", "authors": "Carl Yang, Haonan Wang, Ke Zhang, Liang Chen, Lichao Sun", "title": "Secure Deep Graph Generation with Link Differential Privacy", "comments": "Accepted by IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many data mining and analytical tasks rely on the abstraction of networks\n(graphs) to summarize relational structures among individuals (nodes). Since\nrelational data are often sensitive, we aim to seek effective approaches to\ngenerate utility-preserved yet privacy-protected structured data. In this\npaper, we leverage the differential privacy (DP) framework to formulate and\nenforce rigorous privacy constraints on deep graph generation models, with a\nfocus on edge-DP to guarantee individual link privacy. In particular, we\nenforce edge-DP by injecting proper noise to the gradients of a link\nreconstruction-based graph generation model, while ensuring data utility by\nimproving structure learning with structure-oriented graph discrimination.\nExtensive experiments on two real-world network datasets show that our proposed\nDPGGAN model is able to generate graphs with effectively preserved global\nstructure and rigorously protected individual link privacy.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 15:49:17 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 01:53:56 GMT"}, {"version": "v3", "created": "Sat, 1 May 2021 03:50:35 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Yang", "Carl", ""], ["Wang", "Haonan", ""], ["Zhang", "Ke", ""], ["Chen", "Liang", ""], ["Sun", "Lichao", ""]]}, {"id": "2005.00456", "submitter": "Shikib Mehri", "authors": "Shikib Mehri and Maxine Eskenazi", "title": "USR: An Unsupervised and Reference Free Evaluation Metric for Dialog\n  Generation", "comments": "Accepted to ACL 2020 as long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of meaningful automatic evaluation metrics for dialog has impeded\nopen-domain dialog research. Standard language generation metrics have been\nshown to be ineffective for evaluating dialog models. To this end, this paper\npresents USR, an UnSupervised and Reference-free evaluation metric for dialog.\nUSR is a reference-free metric that trains unsupervised models to measure\nseveral desirable qualities of dialog. USR is shown to strongly correlate with\nhuman judgment on both Topical-Chat (turn-level: 0.42, system-level: 1.0) and\nPersonaChat (turn-level: 0.48 and system-level: 1.0). USR additionally produces\ninterpretable measures for several desirable properties of dialog.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 15:50:50 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Mehri", "Shikib", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "2005.00466", "submitter": "Mike Laszkiewicz", "authors": "Mike Laszkiewicz, Asja Fischer, Johannes Lederer", "title": "Thresholded Adaptive Validation: Tuning the Graphical Lasso for Graph\n  Recovery", "comments": "To appear in the proceedings of Artificial Intelligence and\n  Statistics (AISTATS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Machine Learning algorithms are formulated as regularized optimization\nproblems, but their performance hinges on a regularization parameter that needs\nto be calibrated to each application at hand. In this paper, we propose a\ngeneral calibration scheme for regularized optimization problems and apply it\nto the graphical lasso, which is a method for Gaussian graphical modeling. The\nscheme is equipped with theoretical guarantees and motivates a thresholding\npipeline that can improve graph recovery. Moreover, requiring at most one line\nsearch over the regularization path, the calibration scheme is computationally\nmore efficient than competing schemes that are based on resampling. Finally, we\nshow in simulations that our approach can improve on the graph recovery of\nother approaches considerably.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 15:59:47 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 09:35:43 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Laszkiewicz", "Mike", ""], ["Fischer", "Asja", ""], ["Lederer", "Johannes", ""]]}, {"id": "2005.00478", "submitter": "Sayan Putatunda PhD", "authors": "Sayan Putatunda, Dayananda Ubrangala, Kiran Rama, Ravi Kondapalli", "title": "DriveML: An R Package for Driverless Machine Learning", "comments": "9 pages, 6 figures, Paper selected for presentation at the 2nd\n  International Workshop on Data Quality Assessment for Machine Learning @\n  Special Interest Group on Knowledge Discovery and Data Mining (SIGKDD), 14-18\n  August, 2021, Singapore", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, the concept of automated machine learning has become very\npopular. Automated Machine Learning (AutoML) mainly refers to the automated\nmethods for model selection and hyper-parameter optimization of various\nalgorithms such as random forests, gradient boosting, neural networks, etc. In\nthis paper, we introduce a new package i.e. DriveML for automated machine\nlearning. DriveML helps in implementing some of the pillars of an automated\nmachine learning pipeline such as automated data preparation, feature\nengineering, model building and model explanation by running the function\ninstead of writing lengthy R codes. The DriveML package is available in CRAN.\nWe compare the DriveML package with other relevant packages in CRAN/Github and\nfind that DriveML performs the best across different parameters. We also\nprovide an illustration by applying the DriveML package with default\nconfiguration on a real world dataset. Overall, the main benefits of DriveML\nare in development time savings, reduce developer's errors, optimal tuning of\nmachine learning models and reproducibility.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 16:40:25 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 05:45:23 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Putatunda", "Sayan", ""], ["Ubrangala", "Dayananda", ""], ["Rama", "Kiran", ""], ["Kondapalli", "Ravi", ""]]}, {"id": "2005.00480", "submitter": "Vaibhav Adlakha", "authors": "Vaibhav Adlakha, Parth Shah, Srikanta Bedathur, Mausam", "title": "Knowledge Base Inference for Regular Expression Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two common types of tasks on Knowledge Bases have been studied -- single link\nprediction (Knowledge Base Completion) and path query answering. However, our\nanalysis of user queries on a real-world knowledge base reveals that a\nsignificant fraction of queries specify paths using regular expressions(regex).\nSuch regex queries cannot be handled by any of the existing link prediction or\npath query answering models. In response, we present Regex Query Answering, the\nnovel task of answering regex queries on incomplete KBs. We contribute two\ndatasets for the task, including one where test queries are harvested from\nactual user querylogs. We train baseline neural models for our new task and\npropose novel ways to handle disjunction and Kleene plus regex operators.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 16:43:06 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Adlakha", "Vaibhav", ""], ["Shah", "Parth", ""], ["Bedathur", "Srikanta", ""], ["Mausam", "", ""]]}, {"id": "2005.00496", "submitter": "Tao Li", "authors": "Tao Li, Parth Anand Jawale, Martha Palmer, Vivek Srikumar", "title": "Structured Tuning for Semantic Role Labeling", "comments": "Accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural network-driven semantic role labeling (SRL) systems have shown\nimpressive improvements in F1 scores. These improvements are due to expressive\ninput representations, which, at least at the surface, are orthogonal to\nknowledge-rich constrained decoding mechanisms that helped linear SRL models.\nIntroducing the benefits of structure to inform neural models presents a\nmethodological challenge. In this paper, we present a structured tuning\nframework to improve models using softened constraints only at training time.\nOur framework leverages the expressiveness of neural networks and provides\nsupervision with structured loss components. We start with a strong baseline\n(RoBERTa) to validate the impact of our approach, and show that our framework\noutperforms the baseline by learning to comply with declarative constraints.\nAdditionally, our experiments with smaller training sizes show that we can\nachieve consistent improvements under low-resource scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 17:12:20 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 07:39:17 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Li", "Tao", ""], ["Jawale", "Parth Anand", ""], ["Palmer", "Martha", ""], ["Srikumar", "Vivek", ""]]}, {"id": "2005.00497", "submitter": "Hubert Baniecki", "authors": "Hubert Baniecki, Przemyslaw Biecek", "title": "The Grammar of Interactive Explanatory Model Analysis", "comments": "17 pages, 10 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing need for in-depth analysis of predictive models leads to a series\nof new methods for explaining their local and global properties. Which of these\nmethods is the best? It turns out that this is an ill-posed question. One\ncannot sufficiently explain a black-box machine learning model using a single\nmethod that gives only one perspective. Isolated explanations are prone to\nmisunderstanding, which inevitably leads to wrong or simplistic reasoning. This\nproblem is known as the Rashomon effect and refers to diverse, even\ncontradictory interpretations of the same phenomenon. Surprisingly, the\nmajority of methods developed for explainable machine learning focus on a\nsingle aspect of the model behavior. In contrast, we showcase the problem of\nexplainability as an interactive and sequential analysis of a model. This paper\npresents how different Explanatory Model Analysis (EMA) methods complement each\nother and why it is essential to juxtapose them together. The introduced\nprocess of Interactive EMA (IEMA) derives from the algorithmic side of\nexplainable machine learning and aims to embrace ideas developed in cognitive\nsciences. We formalize the grammar of IEMA to describe potential human-model\ndialogues. IEMA is implemented in the human-centered framework that adopts\ninteractivity, customizability and automation as its main traits. Combined,\nthese methods enhance the responsible approach to predictive modeling.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 17:12:22 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 17:55:17 GMT"}, {"version": "v3", "created": "Sun, 28 Mar 2021 16:10:54 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Baniecki", "Hubert", ""], ["Biecek", "Przemyslaw", ""]]}, {"id": "2005.00502", "submitter": "Liyuan Liu", "authors": "Shi Zhi and Liyuan Liu and Yu Zhang and Shiyin Wang and Qi Li and Chao\n  Zhang and Jiawei Han", "title": "Partially-Typed NER Datasets Integration: Connecting Practice to Theory", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While typical named entity recognition (NER) models require the training set\nto be annotated with all target types, each available datasets may only cover a\npart of them. Instead of relying on fully-typed NER datasets, many efforts have\nbeen made to leverage multiple partially-typed ones for training and allow the\nresulting model to cover a full type set. However, there is neither guarantee\non the quality of integrated datasets, nor guidance on the design of training\nalgorithms. Here, we conduct a systematic analysis and comparison between\npartially-typed NER datasets and fully-typed ones, in both theoretical and\nempirical manner. Firstly, we derive a bound to establish that models trained\nwith partially-typed annotations can reach a similar performance with the ones\ntrained with fully-typed annotations, which also provides guidance on the\nalgorithm design. Moreover, we conduct controlled experiments, which shows\npartially-typed datasets leads to similar performance with the model trained\nwith the same amount of fully-typed annotations\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 17:16:18 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Zhi", "Shi", ""], ["Liu", "Liyuan", ""], ["Zhang", "Yu", ""], ["Wang", "Shiyin", ""], ["Li", "Qi", ""], ["Zhang", "Chao", ""], ["Han", "Jiawei", ""]]}, {"id": "2005.00512", "submitter": "Sarthak Jain", "authors": "Sarthak Jain, Madeleine van Zuylen, Hannaneh Hajishirzi, Iz Beltagy", "title": "SciREX: A Challenge Dataset for Document-Level Information Extraction", "comments": "ACL2020 Camera Ready Submission, Work done by first authors while\n  interning at AI2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting information from full documents is an important problem in many\ndomains, but most previous work focus on identifying relationships within a\nsentence or a paragraph. It is challenging to create a large-scale information\nextraction (IE) dataset at the document level since it requires an\nunderstanding of the whole document to annotate entities and their\ndocument-level relationships that usually span beyond sentences or even\nsections. In this paper, we introduce SciREX, a document level IE dataset that\nencompasses multiple IE tasks, including salient entity identification and\ndocument level $N$-ary relation identification from scientific articles. We\nannotate our dataset by integrating automatic and human annotations, leveraging\nexisting scientific knowledge resources. We develop a neural model as a strong\nbaseline that extends previous state-of-the-art IE models to document-level IE.\nAnalyzing the model performance shows a significant gap between human\nperformance and current baselines, inviting the community to use our dataset as\na challenge to develop document-level IE models. Our data and code are publicly\navailable at https://github.com/allenai/SciREX\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 17:30:10 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Jain", "Sarthak", ""], ["van Zuylen", "Madeleine", ""], ["Hajishirzi", "Hannaneh", ""], ["Beltagy", "Iz", ""]]}, {"id": "2005.00524", "submitter": "Mozhi Zhang", "authors": "Mozhi Zhang, Yoshinari Fujinuma, Michael J. Paul, Jordan Boyd-Graber", "title": "Why Overfitting Isn't Always Bad: Retrofitting Cross-Lingual Word\n  Embeddings to Dictionaries", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual word embeddings (CLWE) are often evaluated on bilingual lexicon\ninduction (BLI). Recent CLWE methods use linear projections, which underfit the\ntraining dictionary, to generalize on BLI. However, underfitting can hinder\ngeneralization to other downstream tasks that rely on words from the training\ndictionary. We address this limitation by retrofitting CLWE to the training\ndictionary, which pulls training translation pairs closer in the embedding\nspace and overfits the training dictionary. This simple post-processing step\noften improves accuracy on two downstream tasks, despite lowering BLI test\naccuracy. We also retrofit to both the training dictionary and a synthetic\ndictionary induced from CLWE, which sometimes generalizes even better on\ndownstream tasks. Our results confirm the importance of fully exploiting\ntraining dictionary in downstream tasks and explains why BLI is a flawed CLWE\nevaluation.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 17:56:01 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Zhang", "Mozhi", ""], ["Fujinuma", "Yoshinari", ""], ["Paul", "Michael J.", ""], ["Boyd-Graber", "Jordan", ""]]}, {"id": "2005.00527", "submitter": "Ruosong Wang", "authors": "Ruosong Wang, Simon S. Du, Lin F. Yang, Sham M. Kakade", "title": "Is Long Horizon Reinforcement Learning More Difficult Than Short Horizon\n  Reinforcement Learning?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to plan for long horizons is a central challenge in episodic\nreinforcement learning problems. A fundamental question is to understand how\nthe difficulty of the problem scales as the horizon increases. Here the natural\nmeasure of sample complexity is a normalized one: we are interested in the\nnumber of episodes it takes to provably discover a policy whose value is\n$\\varepsilon$ near to that of the optimal value, where the value is measured by\nthe normalized cumulative reward in each episode. In a COLT 2018 open problem,\nJiang and Agarwal conjectured that, for tabular, episodic reinforcement\nlearning problems, there exists a sample complexity lower bound which exhibits\na polynomial dependence on the horizon -- a conjecture which is consistent with\nall known sample complexity upper bounds. This work refutes this conjecture,\nproving that tabular, episodic reinforcement learning is possible with a sample\ncomplexity that scales only logarithmically with the planning horizon. In other\nwords, when the values are appropriately normalized (to lie in the unit\ninterval), this results shows that long horizon RL is no more difficult than\nshort horizon RL, at least in a minimax sense. Our analysis introduces two\nideas: (i) the construction of an $\\varepsilon$-net for optimal policies whose\nlog-covering number scales only logarithmically with the planning horizon, and\n(ii) the Online Trajectory Synthesis algorithm, which adaptively evaluates all\npolicies in a given policy class using sample complexity that scales with the\nlog-covering number of the given policy class. Both may be of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 17:56:38 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 16:20:06 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Wang", "Ruosong", ""], ["Du", "Simon S.", ""], ["Yang", "Lin F.", ""], ["Kakade", "Sham M.", ""]]}, {"id": "2005.00544", "submitter": "Dmitry Yudin", "authors": "Alexey Uvarov, Jacob Biamonte, Dmitry Yudin", "title": "Variational Quantum Eigensolver for Frustrated Quantum Systems", "comments": "7 pages, 7 figures, REVTeX4.2", "journal-ref": "Phys. Rev. B 102, 075104 (2020)", "doi": "10.1103/PhysRevB.102.075104", "report-no": null, "categories": "quant-ph cond-mat.dis-nn cond-mat.mtrl-sci cond-mat.str-el cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid quantum-classical algorithms have been proposed as a potentially\nviable application of quantum computers. A particular example - the variational\nquantum eigensolver, or VQE - is designed to determine a global minimum in an\nenergy landscape specified by a quantum Hamiltonian, which makes it appealing\nfor the needs of quantum chemistry. Experimental realizations have been\nreported in recent years and theoretical estimates of its efficiency are a\nsubject of intense effort. Here we consider the performance of the VQE\ntechnique for a Hubbard-like model describing a one-dimensional chain of\nfermions with competing nearest- and next-nearest-neighbor interactions. We\nfind that recovering the VQE solution allows one to obtain the correlation\nfunction of the ground state consistent with the exact result. We also study\nthe barren plateau phenomenon for the Hamiltonian in question and find that the\nseverity of this effect depends on the encoding of fermions to qubits. Our\nresults are consistent with the current knowledge about the barren plateaus in\nquantum optimization.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 18:00:01 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 14:52:52 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Uvarov", "Alexey", ""], ["Biamonte", "Jacob", ""], ["Yudin", "Dmitry", ""]]}, {"id": "2005.00545", "submitter": "Ines Chami", "authors": "Ines Chami, Adva Wolf, Da-Cheng Juan, Frederic Sala, Sujith Ravi and\n  Christopher R\\'e", "title": "Low-Dimensional Hyperbolic Knowledge Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph (KG) embeddings learn low-dimensional representations of\nentities and relations to predict missing facts. KGs often exhibit hierarchical\nand logical patterns which must be preserved in the embedding space. For\nhierarchical data, hyperbolic embedding methods have shown promise for\nhigh-fidelity and parsimonious representations. However, existing hyperbolic\nembedding methods do not account for the rich logical patterns in KGs. In this\nwork, we introduce a class of hyperbolic KG embedding models that\nsimultaneously capture hierarchical and logical patterns. Our approach combines\nhyperbolic reflections and rotations with attention to model complex relational\npatterns. Experimental results on standard KG benchmarks show that our method\nimproves over previous Euclidean- and hyperbolic-based efforts by up to 6.1% in\nmean reciprocal rank (MRR) in low dimensions. Furthermore, we observe that\ndifferent geometric transformations capture different types of relations while\nattention-based transformations generalize to multiple relations. In high\ndimensions, our approach yields new state-of-the-art MRRs of 49.6% on WN18RR\nand 57.7% on YAGO3-10.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 18:00:02 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Chami", "Ines", ""], ["Wolf", "Adva", ""], ["Juan", "Da-Cheng", ""], ["Sala", "Frederic", ""], ["Ravi", "Sujith", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2005.00558", "submitter": "Yizhe Zhang", "authors": "Yizhe Zhang, Guoyin Wang, Chunyuan Li, Zhe Gan, Chris Brockett, Bill\n  Dolan", "title": "POINTER: Constrained Progressive Text Generation via Insertion-based\n  Generative Pre-training", "comments": "EMNLP 2020 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale pre-trained language models, such as BERT and GPT-2, have\nachieved excellent performance in language representation learning and\nfree-form text generation. However, these models cannot be directly employed to\ngenerate text under specified lexical constraints. To address this challenge,\nwe present POINTER (PrOgressive INsertion-based TransformER), a simple yet\nnovel insertion-based approach for hard-constrained text generation. The\nproposed method operates by progressively inserting new tokens between existing\ntokens in a parallel manner. This procedure is recursively applied until a\nsequence is completed. The resulting coarse-to-fine hierarchy makes the\ngeneration process intuitive and interpretable. We pre-train our model with the\nproposed progressive insertion-based objective on a 12GB Wikipedia dataset, and\nfine-tune it on downstream hard-constrained generation tasks.\nNon-autoregressive decoding yields an empirically logarithmic time complexity\nduring inference time. Experimental results on both News and Yelp datasets\ndemonstrate that POINTER achieves state-of-the-art performance on constrained\ntext generation. We released the pre-trained models and the source code to\nfacilitate future research (https://github.com/dreasysnail/POINTER).\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 18:11:54 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 00:07:39 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zhang", "Yizhe", ""], ["Wang", "Guoyin", ""], ["Li", "Chunyuan", ""], ["Gan", "Zhe", ""], ["Brockett", "Chris", ""], ["Dolan", "Bill", ""]]}, {"id": "2005.00561", "submitter": "Anna Rogers", "authors": "Sai Prasanna, Anna Rogers, Anna Rumshisky", "title": "When BERT Plays the Lottery, All Tickets Are Winning", "comments": "EMNLP 2020 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large Transformer-based models were shown to be reducible to a smaller number\nof self-attention heads and layers. We consider this phenomenon from the\nperspective of the lottery ticket hypothesis, using both structured and\nmagnitude pruning. For fine-tuned BERT, we show that (a) it is possible to find\nsubnetworks achieving performance that is comparable with that of the full\nmodel, and (b) similarly-sized subnetworks sampled from the rest of the model\nperform worse. Strikingly, with structured pruning even the worst possible\nsubnetworks remain highly trainable, indicating that most pre-trained BERT\nweights are potentially useful. We also study the \"good\" subnetworks to see if\ntheir success can be attributed to superior linguistic knowledge, but find them\nunstable, and not explained by meaningful self-attention patterns.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 18:24:42 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 10:15:27 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Prasanna", "Sai", ""], ["Rogers", "Anna", ""], ["Rumshisky", "Anna", ""]]}, {"id": "2005.00565", "submitter": "Wouter van Heeswijk PhD", "authors": "Wouter van Heeswijk", "title": "Smart Containers With Bidding Capacity: A Policy Gradient Algorithm for\n  Semi-Cooperative Learning", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart modular freight containers -- as propagated in the Physical Internet\nparadigm -- are equipped with sensors, data storage capability and intelligence\nthat enable them to route themselves from origin to destination without manual\nintervention or central governance. In this self-organizing setting, containers\ncan autonomously place bids on transport services in a spot market setting.\nHowever, for individual containers it may be difficult to learn good bidding\npolicies due to limited observations. By sharing information and costs between\none another, smart containers can jointly learn bidding policies, even though\nsimultaneously competing for the same transport capacity. We replicate this\nbehavior by learning stochastic bidding policies in a semi-cooperative multi\nagent setting. To this end, we develop a reinforcement learning algorithm based\non the policy gradient framework. Numerical experiments show that sharing\nsolely bids and acceptance decisions leads to stable bidding policies.\nAdditional system information only marginally improves performance; individual\njob properties suffice to place appropriate bids. Furthermore, we find that\ncarriers may have incentives not to share information with the smart\ncontainers. The experiments give rise to several directions for follow-up\nresearch, in particular the interaction between smart containers and transport\nservices in self-organizing logistics.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 18:37:38 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["van Heeswijk", "Wouter", ""]]}, {"id": "2005.00568", "submitter": "Judith Katzy", "authors": "Jose M. Clavijo and Paul Glaysher and Judith M. Katzy", "title": "Adversarial domain adaptation to reduce sample bias of a high energy\n  physics classifier", "comments": "15 pages, 8 figures, to be submitted to JINST", "journal-ref": null, "doi": null, "report-no": "Report Number: DESY 20-073", "categories": "stat.ML cs.LG hep-ex hep-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We apply adversarial domain adaptation to reduce sample bias in a\nclassification machine learning algorithm. We add a gradient reversal layer to\na neural network to simultaneously classify signal versus background events,\nwhile minimising the difference of the classifier response to a background\nsample using an alternative MC model. We show this on the example of simulated\nevents at the LHC with $t\\bar{t}H$ signal versus $t\\bar{t}b\\bar{b}$ background\nclassification.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 18:46:12 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Clavijo", "Jose M.", ""], ["Glaysher", "Paul", ""], ["Katzy", "Judith M.", ""]]}, {"id": "2005.00570", "submitter": "Boqing Gong", "authors": "Dan Kondratyuk, Mingxing Tan, Matthew Brown, and Boqing Gong", "title": "When Ensembling Smaller Models is More Efficient than Single Large\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembling is a simple and popular technique for boosting evaluation\nperformance by training multiple models (e.g., with different initializations)\nand aggregating their predictions. This approach is commonly reserved for the\nlargest models, as it is commonly held that increasing the model size provides\na more substantial reduction in error than ensembling smaller models. However,\nwe show results from experiments on CIFAR-10 and ImageNet that ensembles can\noutperform single models with both higher accuracy and requiring fewer total\nFLOPs to compute, even when those individual models' weights and\nhyperparameters are highly optimized. Furthermore, this gap in improvement\nwidens as models become large. This presents an interesting observation that\noutput diversity in ensembling can often be more efficient than training larger\nmodels, especially when the models approach the size of what their dataset can\nfoster. Instead of using the common practice of tuning a single large model,\none can use ensembles as a more flexible trade-off between a model's inference\nspeed and accuracy. This also potentially eases hardware design, e.g., an\neasier way to parallelize the model across multiple workers for real-time or\ndistributed inference.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 18:56:18 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Kondratyuk", "Dan", ""], ["Tan", "Mingxing", ""], ["Brown", "Matthew", ""], ["Gong", "Boqing", ""]]}, {"id": "2005.00571", "submitter": "Deren Lei", "authors": "Deren Lei and Gangrong Jiang and Xiaotao Gu and Kexuan Sun and Yuning\n  Mao and Xiang Ren", "title": "Learning Collaborative Agents with Rule Guidance for Knowledge Graph\n  Reasoning", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Walk-based models have shown their advantages in knowledge graph (KG)\nreasoning by achieving decent performance while providing interpretable\ndecisions. However, the sparse reward signals offered by the KG during\ntraversal are often insufficient to guide a sophisticated walk-based\nreinforcement learning (RL) model. An alternate approach is to use traditional\nsymbolic methods (e.g., rule induction), which achieve good performance but can\nbe hard to generalize due to the limitation of symbolic representation. In this\npaper, we propose RuleGuider, which leverages high-quality rules generated by\nsymbolic-based methods to provide reward supervision for walk-based agents.\nExperiments on benchmark datasets show that RuleGuider improves the performance\nof walk-based models without losing interpretability.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 18:57:14 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 10:13:30 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Lei", "Deren", ""], ["Jiang", "Gangrong", ""], ["Gu", "Xiaotao", ""], ["Sun", "Kexuan", ""], ["Mao", "Yuning", ""], ["Ren", "Xiang", ""]]}, {"id": "2005.00581", "submitter": "Sandeep Subramanian", "authors": "Sandeep Subramanian, Ronan Collobert, Marc'Aurelio Ranzato, Y-Lan\n  Boureau", "title": "Multi-scale Transformer Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate multi-scale transformer language models that learn\nrepresentations of text at multiple scales, and present three different\narchitectures that have an inductive bias to handle the hierarchical nature of\nlanguage. Experiments on large-scale language modeling benchmarks empirically\ndemonstrate favorable likelihood vs memory footprint trade-offs, e.g. we show\nthat it is possible to train a hierarchical variant with 30 layers that has 23%\nsmaller memory footprint and better perplexity, compared to a vanilla\ntransformer with less than half the number of layers, on the Toronto\nBookCorpus. We analyze the advantages of learned representations at multiple\nscales in terms of memory footprint, compute time, and perplexity, which are\nparticularly appealing given the quadratic scaling of transformers' run time\nand memory usage with respect to sequence length.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 19:58:56 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Subramanian", "Sandeep", ""], ["Collobert", "Ronan", ""], ["Ranzato", "Marc'Aurelio", ""], ["Boureau", "Y-Lan", ""]]}, {"id": "2005.00582", "submitter": "Bryan Wilder", "authors": "Bryan Wilder, Eric Horvitz, Ece Kamar", "title": "Learning to Complement Humans", "comments": "Accepted at IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rising vision for AI in the open world centers on the development of\nsystems that can complement humans for perceptual, diagnostic, and reasoning\ntasks. To date, systems aimed at complementing the skills of people have\nemployed models trained to be as accurate as possible in isolation. We\ndemonstrate how an end-to-end learning strategy can be harnessed to optimize\nthe combined performance of human-machine teams by considering the distinct\nabilities of people and machines. The goal is to focus machine learning on\nproblem instances that are difficult for humans, while recognizing instances\nthat are difficult for the machine and seeking human input on them. We\ndemonstrate in two real-world domains (scientific discovery and medical\ndiagnosis) that human-machine teams built via these methods outperform the\nindividual performance of machines and people. We then analyze conditions under\nwhich this complementarity is strongest, and which training methods amplify it.\nTaken together, our work provides the first systematic investigation of how\nmachine learning systems can be trained to complement human reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 20:00:23 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wilder", "Bryan", ""], ["Horvitz", "Eric", ""], ["Kamar", "Ece", ""]]}, {"id": "2005.00583", "submitter": "Koustuv Sinha", "authors": "Koustuv Sinha, Prasanna Parthasarathi, Jasmine Wang, Ryan Lowe,\n  William L. Hamilton, Joelle Pineau", "title": "Learning an Unreferenced Metric for Online Dialogue Evaluation", "comments": "Accepted at ACL 2020, 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating the quality of a dialogue interaction between two agents is a\ndifficult task, especially in open-domain chit-chat style dialogue. There have\nbeen recent efforts to develop automatic dialogue evaluation metrics, but most\nof them do not generalize to unseen datasets and/or need a human-generated\nreference response during inference, making it infeasible for online\nevaluation. Here, we propose an unreferenced automated evaluation metric that\nuses large pre-trained language models to extract latent representations of\nutterances, and leverages the temporal transitions that exist between them. We\nshow that our model achieves higher correlation with human annotations in an\nonline setting, while not requiring true responses for comparison during\ninference.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 20:01:39 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Sinha", "Koustuv", ""], ["Parthasarathi", "Prasanna", ""], ["Wang", "Jasmine", ""], ["Lowe", "Ryan", ""], ["Hamilton", "William L.", ""], ["Pineau", "Joelle", ""]]}, {"id": "2005.00585", "submitter": "Rahul Singh", "authors": "Rahul Singh, Qinsheng Zhang, Yongxin Chen", "title": "Improving Robustness via Risk Averse Distributional Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One major obstacle that precludes the success of reinforcement learning in\nreal-world applications is the lack of robustness, either to model\nuncertainties or external disturbances, of the trained policies. Robustness is\ncritical when the policies are trained in simulations instead of real world\nenvironment. In this work, we propose a risk-aware algorithm to learn robust\npolicies in order to bridge the gap between simulation training and real-world\nimplementation. Our algorithm is based on recently discovered distributional RL\nframework. We incorporate CVaR risk measure in sample based distributional\npolicy gradients (SDPG) for learning risk-averse policies to achieve robustness\nagainst a range of system disturbances. We validate the robustness of\nrisk-aware SDPG on multiple environments.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 20:03:10 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Singh", "Rahul", ""], ["Zhang", "Qinsheng", ""], ["Chen", "Yongxin", ""]]}, {"id": "2005.00592", "submitter": "Mogens Graf Plessen", "authors": "Mogens Graf Plessen", "title": "Integrated Time Series Summarization and Prediction Algorithm and its\n  Application to COVID-19 Data Mining", "comments": "10 pages double column, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a simple method to extract from a set of multiple related\ntime series a compressed representation for each time series based on\nstatistics for the entire set of all time series. This is achieved by a\nhierarchical algorithm that first generates an alphabet of shapelets based on\nthe segmentation of centroids for clustered data, before labels of these\nshapelets are assigned to the segmentation of each single time series via\nnearest neighbor search using unconstrained dynamic time warping as distance\nmeasure to deal with non-uniform time series lenghts. Thereby, a sequence of\nlabels is assigned for each time series. Completion of the last label sequence\npermits prediction of individual time series. Proposed method is evaluated on\ntwo global COVID-19 datasets, first, for the number of daily net cases (daily\nnew infections minus daily recoveries), and, second, for the number of daily\ndeaths attributed to COVID-19 as of April 27, 2020. The first dataset involves\n249 time series for different countries, each of length 96. The second dataset\ninvolves 264 time series, each of length 96. Based on detected anomalies in\navailable data a decentralized exit strategy from lockdowns is advocated.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 20:16:39 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Plessen", "Mogens Graf", ""]]}, {"id": "2005.00596", "submitter": "Zhuolin Jiang", "authors": "Zhuolin Jiang, Jan Silovsky, Man-Hung Siu, William Hartmann, Herbert\n  Gish, Sancar Adali", "title": "Learning from Noisy Labels with Noise Modeling Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label image classification has generated significant interest in recent\nyears and the performance of such systems often suffers from the not so\ninfrequent occurrence of incorrect or missing labels in the training data. In\nthis paper, we extend the state-of the-art of training classifiers to jointly\ndeal with both forms of errorful data. We accomplish this by modeling noisy and\nmissing labels in multi-label images with a new Noise Modeling Network (NMN)\nthat follows our convolutional neural network (CNN), integrates with it,\nforming an end-to-end deep learning system, which can jointly learn the noise\ndistribution and CNN parameters. The NMN learns the distribution of noise\npatterns directly from the noisy data without the need for any clean training\ndata. The NMN can model label noise that depends only on the true label or is\nalso dependent on the image features. We show that the integrated NMN/CNN\nlearning system consistently improves the classification performance, for\ndifferent levels of label noise, on the MSR-COCO dataset and MSR-VTT dataset.\nWe also show that noise performance improvements are obtained when multiple\ninstance learning methods are used.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 20:32:22 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Jiang", "Zhuolin", ""], ["Silovsky", "Jan", ""], ["Siu", "Man-Hung", ""], ["Hartmann", "William", ""], ["Gish", "Herbert", ""], ["Adali", "Sancar", ""]]}, {"id": "2005.00610", "submitter": "Joris Mooij", "authors": "Joris M. Mooij and Tom Claassen", "title": "Constraint-Based Causal Discovery using Partial Ancestral Graphs in the\n  presence of Cycles", "comments": "Major revision. To appear in Proceedings of the 36 th Conference on\n  Uncertainty in Artificial Intelligence (UAI), PMLR volume 124, 2020", "journal-ref": "Proceedings of Machine Learning Research 124 (2020) 1159-1168", "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While feedback loops are known to play important roles in many complex\nsystems, their existence is ignored in a large part of the causal discovery\nliterature, as systems are typically assumed to be acyclic from the outset.\nWhen applying causal discovery algorithms designed for the acyclic setting on\ndata generated by a system that involves feedback, one would not expect to\nobtain correct results. In this work, we show that---surprisingly---the output\nof the Fast Causal Inference (FCI) algorithm is correct if it is applied to\nobservational data generated by a system that involves feedback. More\nspecifically, we prove that for observational data generated by a simple and\n$\\sigma$-faithful Structural Causal Model (SCM), FCI is sound and complete, and\ncan be used to consistently estimate (i) the presence and absence of causal\nrelations, (ii) the presence and absence of direct causal relations, (iii) the\nabsence of confounders, and (iv) the absence of specific cycles in the causal\ngraph of the SCM. We extend these results to constraint-based causal discovery\nalgorithms that exploit certain forms of background knowledge, including the\ncausally sufficient setting (e.g., the PC algorithm) and the Joint Causal\nInference setting (e.g., the FCI-JCI algorithm).\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 21:10:31 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 21:28:26 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Mooij", "Joris M.", ""], ["Claassen", "Tom", ""]]}, {"id": "2005.00611", "submitter": "Ya-Chien Chang", "authors": "Ya-Chien Chang, Nima Roohi, Sicun Gao", "title": "Neural Lyapunov Control", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose new methods for learning control policies and neural network\nLyapunov functions for nonlinear control problems, with provable guarantee of\nstability. The framework consists of a learner that attempts to find the\ncontrol and Lyapunov functions, and a falsifier that finds counterexamples to\nquickly guide the learner towards solutions. The procedure terminates when no\ncounterexample is found by the falsifier, in which case the controlled\nnonlinear system is provably stable. The approach significantly simplifies the\nprocess of Lyapunov control design, provides end-to-end correctness guarantee,\nand can obtain much larger regions of attraction than existing methods such as\nLQR and SOS/SDP. We show experiments on how the new methods obtain high-quality\nsolutions for challenging control problems.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 21:18:39 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 20:41:39 GMT"}, {"version": "v3", "created": "Sat, 19 Dec 2020 21:35:49 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Chang", "Ya-Chien", ""], ["Roohi", "Nima", ""], ["Gao", "Sicun", ""]]}, {"id": "2005.00615", "submitter": "Dehao Liu", "authors": "Dehao Liu, Yan Wang", "title": "A Dual-Dimer Method for Training Physics-Constrained Neural Networks\n  with Minimax Architecture", "comments": "34 pages, 5 figures, accepted by neural networks", "journal-ref": null, "doi": "10.1016/j.neunet.2020.12.028", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data sparsity is a common issue to train machine learning tools such as\nneural networks for engineering and scientific applications, where experiments\nand simulations are expensive. Recently physics-constrained neural networks\n(PCNNs) were developed to reduce the required amount of training data. However,\nthe weights of different losses from data and physical constraints are adjusted\nempirically in PCNNs. In this paper, a new physics-constrained neural network\nwith the minimax architecture (PCNN-MM) is proposed so that the weights of\ndifferent losses can be adjusted systematically. The training of the PCNN-MM is\nsearching the high-order saddle points of the objective function. A novel\nsaddle point search algorithm called Dual-Dimer method is developed. It is\ndemonstrated that the Dual-Dimer method is computationally more efficient than\nthe gradient descent ascent method for nonconvex-nonconcave functions and\nprovides additional eigenvalue information to verify search results. A heat\ntransfer example also shows that the convergence of PCNN-MMs is faster than\nthat of traditional PCNNs.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 21:26:04 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 19:25:43 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Liu", "Dehao", ""], ["Wang", "Yan", ""]]}, {"id": "2005.00616", "submitter": "Jacob Seidman", "authors": "Jacob H. Seidman, Mahyar Fazlyab, Victor M. Preciado, George J. Pappas", "title": "Robust Deep Learning as Optimal Control: Insights and Convergence\n  Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fragility of deep neural networks to adversarially-chosen inputs has\nmotivated the need to revisit deep learning algorithms. Including adversarial\nexamples during training is a popular defense mechanism against adversarial\nattacks. This mechanism can be formulated as a min-max optimization problem,\nwhere the adversary seeks to maximize the loss function using an iterative\nfirst-order algorithm while the learner attempts to minimize it. However,\nfinding adversarial examples in this way causes excessive computational\noverhead during training. By interpreting the min-max problem as an optimal\ncontrol problem, it has recently been shown that one can exploit the\ncompositional structure of neural networks in the optimization problem to\nimprove the training time significantly. In this paper, we provide the first\nconvergence analysis of this adversarial training algorithm by combining\ntechniques from robust optimal control and inexact oracle methods in\noptimization. Our analysis sheds light on how the hyperparameters of the\nalgorithm affect the its stability and convergence. We support our insights\nwith experiments on a robust classification problem.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 21:26:38 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Seidman", "Jacob H.", ""], ["Fazlyab", "Mahyar", ""], ["Preciado", "Victor M.", ""], ["Pappas", "George J.", ""]]}, {"id": "2005.00625", "submitter": "Zhiwei Liu", "authors": "Zhiwei Liu, Yingtong Dou, Philip S. Yu, Yutong Deng, Hao Peng", "title": "Alleviating the Inconsistency Problem of Applying Graph Neural Network\n  to Fraud Detection", "comments": "Accepted by SIGIR'20. We also released a GNN-based fraud detection\n  toolbox with implementations of SOTA models. The code is available at\n  https://github.com/safe-graph/DGFraud", "journal-ref": null, "doi": "10.1145/3397271.3401253", "report-no": null, "categories": "cs.SI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graph-based model can help to detect suspicious fraud online. Owing to\nthe development of Graph Neural Networks~(GNNs), prior research work has\nproposed many GNN-based fraud detection frameworks based on either homogeneous\ngraphs or heterogeneous graphs. These work follow the existing GNN framework by\naggregating the neighboring information to learn the node embedding, which lays\non the assumption that the neighbors share similar context, features, and\nrelations. However, the inconsistency problem is hardly investigated, i.e., the\ncontext inconsistency, feature inconsistency, and relation inconsistency. In\nthis paper, we introduce these inconsistencies and design a new GNN framework,\n$\\mathsf{GraphConsis}$, to tackle the inconsistency problem: (1) for the\ncontext inconsistency, we propose to combine the context embeddings with node\nfeatures, (2) for the feature inconsistency, we design a consistency score to\nfilter the inconsistent neighbors and generate corresponding sampling\nprobability, and (3) for the relation inconsistency, we learn a relation\nattention weights associated with the sampled nodes. Empirical analysis on four\ndatasets indicates the inconsistency problem is crucial in a fraud detection\ntask. The extensive experiments prove the effectiveness of\n$\\mathsf{GraphConsis}$. We also released a GNN-based fraud detection toolbox\nwith implementations of SOTA models. The code is available at\nhttps://github.com/safe-graph/DGFraud.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 21:43:58 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 21:05:30 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 03:24:05 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Liu", "Zhiwei", ""], ["Dou", "Yingtong", ""], ["Yu", "Philip S.", ""], ["Deng", "Yutong", ""], ["Peng", "Hao", ""]]}, {"id": "2005.00631", "submitter": "Umang Bhatt", "authors": "Umang Bhatt, Adrian Weller, and Jos\\'e M. F. Moura", "title": "Evaluating and Aggregating Feature-based Model Explanations", "comments": "Accepted at IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A feature-based model explanation denotes how much each input feature\ncontributes to a model's output for a given data point. As the number of\nproposed explanation functions grows, we lack quantitative evaluation criteria\nto help practitioners know when to use which explanation function. This paper\nproposes quantitative evaluation criteria for feature-based explanations: low\nsensitivity, high faithfulness, and low complexity. We devise a framework for\naggregating explanation functions. We develop a procedure for learning an\naggregate explanation function with lower complexity and then derive a new\naggregate Shapley value explanation function that minimizes sensitivity.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 21:56:36 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Bhatt", "Umang", ""], ["Weller", "Adrian", ""], ["Moura", "Jos\u00e9 M. F.", ""]]}, {"id": "2005.00636", "submitter": "Jasmijn Bastings", "authors": "Anders S{\\o}gaard and Sebastian Ebert and Jasmijn Bastings and Katja\n  Filippova", "title": "We Need to Talk About Random Splits", "comments": "Accepted at EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gorman and Bedrick (2019) argued for using random splits rather than standard\nsplits in NLP experiments. We argue that random splits, like standard splits,\nlead to overly optimistic performance estimates. We can also split data in\nbiased or adversarial ways, e.g., training on short sentences and evaluating on\nlong ones. Biased sampling has been used in domain adaptation to simulate\nreal-world drift; this is known as the covariate shift assumption. In NLP,\nhowever, even worst-case splits, maximizing bias, often under-estimate the\nerror observed on new samples of in-domain data, i.e., the data that models\nshould minimally generalize to at test time. This invalidates the covariate\nshift assumption. Instead of using multiple random splits, future benchmarks\nshould ideally include multiple, independent test sets instead; if infeasible,\nwe argue that multiple biased splits leads to more realistic performance\nestimates than multiple random splits.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 22:14:16 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 16:54:55 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 12:05:35 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["S\u00f8gaard", "Anders", ""], ["Ebert", "Sebastian", ""], ["Bastings", "Jasmijn", ""], ["Filippova", "Katja", ""]]}, {"id": "2005.00638", "submitter": "Xinqiang Ding", "authors": "Xinqiang Ding and Bin Zhang", "title": "Computing Absolute Free Energy with Deep Generative Models", "comments": null, "journal-ref": "The Journal of Physical Chemistry B 2020 124 (45), 10166-10172", "doi": "10.1016/j.bpj.2020.11.1342", "report-no": null, "categories": "cond-mat.stat-mech cs.LG physics.chem-ph physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast and accurate evaluation of free energy has broad applications from drug\ndesign to material engineering. Computing the absolute free energy is of\nparticular interest since it allows the assessment of the relative stability\nbetween states without the use of intermediates. In this letter, we introduce a\ngeneral framework for calculating the absolute free energy of a state. A key\nstep of the calculation is the definition of a reference state with tractable\ndeep generative models using locally sampled configurations. The absolute free\nenergy of this reference state is zero by design. The free energy for the state\nof interest can then be determined as the difference from the reference. We\napplied this approach to both discrete and continuous systems and demonstrated\nits effectiveness. It was found that the Bennett acceptance ratio method\nprovides more accurate and efficient free energy estimations than approximate\nexpressions based on work. We anticipate the method presented here to be a\nvaluable strategy for computing free energy differences.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 22:19:31 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 21:48:52 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Ding", "Xinqiang", ""], ["Zhang", "Bin", ""]]}, {"id": "2005.00642", "submitter": "Wonseok Hwang", "authors": "Wonseok Hwang, Jinyeong Yim, Seunghyun Park, Sohee Yang, Minjoon Seo", "title": "Spatial Dependency Parsing for Semi-Structured Document Information\n  Extraction", "comments": "Accepted at Findings of ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information Extraction (IE) for semi-structured document images is often\napproached as a sequence tagging problem by classifying each recognized input\ntoken into one of the IOB (Inside, Outside, and Beginning) categories. However,\nsuch problem setup has two inherent limitations that (1) it cannot easily\nhandle complex spatial relationships and (2) it is not suitable for highly\nstructured information, which are nevertheless frequently observed in\nreal-world document images. To tackle these issues, we first formulate the IE\ntask as spatial dependency parsing problem that focuses on the relationship\namong text tokens in the documents. Under this setup, we then propose SPADE\n(SPAtial DEpendency parser) that models highly complex spatial relationships\nand an arbitrary number of information layers in the documents in an end-to-end\nmanner. We evaluate it on various kinds of documents such as receipts, name\ncards, forms, and invoices, and show that it achieves a similar or better\nperformance compared to strong baselines including BERT-based IOB taggger.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 22:59:56 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 22:00:46 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 08:32:15 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Hwang", "Wonseok", ""], ["Yim", "Jinyeong", ""], ["Park", "Seunghyun", ""], ["Yang", "Sohee", ""], ["Seo", "Minjoon", ""]]}, {"id": "2005.00644", "submitter": "Wonseok Hwang", "authors": "Wonseok Hwang, Jinyeong Yim, Seunghyun Park, Minjoon Seo", "title": "Syntactic Question Abstraction and Retrieval for Data-Scarce Semantic\n  Parsing", "comments": "Accepted to AKBC 2020 (conference paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning approaches to semantic parsing require a large amount of\nlabeled data, but annotating complex logical forms is costly. Here, we propose\nSyntactic Question Abstraction and Retrieval (SQAR), a method to build a neural\nsemantic parser that translates a natural language (NL) query to a SQL logical\nform (LF) with less than 1,000 annotated examples. SQAR first retrieves a\nlogical pattern from the train data by computing the similarity between NL\nqueries and then grounds a lexical information on the retrieved pattern in\norder to generate the final LF. We validate SQAR by training models using\nvarious small subsets of WikiSQL train data achieving up to 4.9% higher LF\naccuracy compared to the previous state-of-the-art models on WikiSQL test set.\nWe also show that by using query-similarity to retrieve logical pattern, SQAR\ncan leverage a paraphrasing dataset achieving up to 5.9% higher LF accuracy\ncompared to the case where SQAR is trained by using only WikiSQL data. In\ncontrast to a simple pattern classification approach, SQAR can generate unseen\nlogical patterns upon the addition of new examples without re-training the\nmodel. We also discuss an ideal way to create cost efficient and robust train\ndatasets when the data distribution can be approximated under a data-hungry\nsetting.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 23:05:55 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Hwang", "Wonseok", ""], ["Yim", "Jinyeong", ""], ["Park", "Seunghyun", ""], ["Seo", "Minjoon", ""]]}, {"id": "2005.00646", "submitter": "Bill Yuchen Lin", "authors": "Yanlin Feng, Xinyue Chen, Bill Yuchen Lin, Peifeng Wang, Jun Yan,\n  Xiang Ren", "title": "Scalable Multi-Hop Relational Reasoning for Knowledge-Aware Question\n  Answering", "comments": "Accepted to EMNLP 2020. Project page:\n  https://github.com/INK-USC/MHGRN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing work on augmenting question answering (QA) models with external\nknowledge (e.g., knowledge graphs) either struggle to model multi-hop relations\nefficiently, or lack transparency into the model's prediction rationale. In\nthis paper, we propose a novel knowledge-aware approach that equips pre-trained\nlanguage models (PTLMs) with a multi-hop relational reasoning module, named\nmulti-hop graph relation network (MHGRN). It performs multi-hop,\nmulti-relational reasoning over subgraphs extracted from external knowledge\ngraphs. The proposed reasoning module unifies path-based reasoning methods and\ngraph neural networks to achieve better interpretability and scalability. We\nalso empirically show its effectiveness and scalability on CommonsenseQA and\nOpenbookQA datasets, and interpret its behaviors with case studies.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 23:10:26 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 07:12:35 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Feng", "Yanlin", ""], ["Chen", "Xinyue", ""], ["Lin", "Bill Yuchen", ""], ["Wang", "Peifeng", ""], ["Yan", "Jun", ""], ["Ren", "Xiang", ""]]}, {"id": "2005.00652", "submitter": "Bhargavi Paranjape", "authors": "Bhargavi Paranjape, Mandar Joshi, John Thickstun, Hannaneh Hajishirzi,\n  Luke Zettlemoyer", "title": "An Information Bottleneck Approach for Controlling Conciseness in\n  Rationale Extraction", "comments": "EMNLP 2020 main track accepted paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decisions of complex language understanding models can be rationalized by\nlimiting their inputs to a relevant subsequence of the original text. A\nrationale should be as concise as possible without significantly degrading task\nperformance, but this balance can be difficult to achieve in practice. In this\npaper, we show that it is possible to better manage this trade-off by\noptimizing a bound on the Information Bottleneck (IB) objective. Our fully\nunsupervised approach jointly learns an explainer that predicts sparse binary\nmasks over sentences, and an end-task predictor that considers only the\nextracted rationale. Using IB, we derive a learning objective that allows\ndirect control of mask sparsity levels through a tunable sparse prior.\nExperiments on ERASER benchmark tasks demonstrate significant gains over\nnorm-minimization techniques for both task performance and agreement with human\nrationales. Furthermore, we find that in the semi-supervised setting, a modest\namount of gold rationales (25% of training examples) closes the gap with a\nmodel that uses the full input.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 23:26:41 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 16:57:54 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 04:38:35 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Paranjape", "Bhargavi", ""], ["Joshi", "Mandar", ""], ["Thickstun", "John", ""], ["Hajishirzi", "Hannaneh", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "2005.00653", "submitter": "Wasi Ahmad", "authors": "Wasi Uddin Ahmad and Saikat Chakraborty and Baishakhi Ray and Kai-Wei\n  Chang", "title": "A Transformer-based Approach for Source Code Summarization", "comments": "This paper is accepted at ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating a readable summary that describes the functionality of a program\nis known as source code summarization. In this task, learning code\nrepresentation by modeling the pairwise relationship between code tokens to\ncapture their long-range dependencies is crucial. To learn code representation\nfor summarization, we explore the Transformer model that uses a self-attention\nmechanism and has shown to be effective in capturing long-range dependencies.\nIn this work, we show that despite the approach is simple, it outperforms the\nstate-of-the-art techniques by a significant margin. We perform extensive\nanalysis and ablation studies that reveal several important findings, e.g., the\nabsolute encoding of source code tokens' position hinders, while relative\nencoding significantly improves the summarization performance. We have made our\ncode publicly available to facilitate future research.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 23:29:36 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Ahmad", "Wasi Uddin", ""], ["Chakraborty", "Saikat", ""], ["Ray", "Baishakhi", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "2005.00656", "submitter": "Nathan Drenkow", "authors": "Neil Fendley, Max Lennon, I-Jeng Wang, Philippe Burlina, Nathan\n  Drenkow", "title": "Jacks of All Trades, Masters Of None: Addressing Distributional Shift\n  and Obtrusiveness via Transparent Patch Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the development of effective adversarial patch attacks and -- for\nthe first time -- jointly address the antagonistic objectives of attack success\nand obtrusiveness via the design of novel semi-transparent patches. This work\nis motivated by our pursuit of a systematic performance analysis of patch\nattack robustness with regard to geometric transformations. Specifically, we\nfirst elucidate a) key factors underpinning patch attack success and b) the\nimpact of distributional shift between training and testing/deployment when\ncast under the Expectation over Transformation (EoT) formalism. By focusing our\nanalysis on three principal classes of transformations (rotation, scale, and\nlocation), our findings provide quantifiable insights into the design of\neffective patch attacks and demonstrate that scale, among all factors,\nsignificantly impacts patch attack success. Working from these findings, we\nthen focus on addressing how to overcome the principal limitations of scale for\nthe deployment of attacks in real physical settings: namely the obtrusiveness\nof large patches. Our strategy is to turn to the novel design of\nirregularly-shaped, semi-transparent partial patches which we construct via a\nnew optimization process that jointly addresses the antagonistic goals of\nmitigating obtrusiveness and maximizing effectiveness. Our study -- we hope --\nwill help encourage more focus in the community on the issues of obtrusiveness,\nscale, and success in patch attacks.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 23:50:37 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Fendley", "Neil", ""], ["Lennon", "Max", ""], ["Wang", "I-Jeng", ""], ["Burlina", "Philippe", ""], ["Drenkow", "Nathan", ""]]}, {"id": "2005.00670", "submitter": "Morihiro Mizutani", "authors": "Morihiro Mizutani, Akifumi Okuno, Geewook Kim, Hidetoshi Shimodaira", "title": "Stochastic Neighbor Embedding of Multimodal Relational Data for\n  Image-Text Simultaneous Visualization", "comments": "20 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal relational data analysis has become of increasing importance in\nrecent years, for exploring across different domains of data, such as images\nand their text tags obtained from social networking services (e.g., Flickr). A\nvariety of data analysis methods have been developed for visualization; to give\nan example, t-Stochastic Neighbor Embedding (t-SNE) computes low-dimensional\nfeature vectors so that their similarities keep those of the observed data\nvectors. However, t-SNE is designed only for a single domain of data but not\nfor multimodal data; this paper aims at visualizing multimodal relational data\nconsisting of data vectors in multiple domains with relations across these\nvectors. By extending t-SNE, we herein propose Multimodal Relational Stochastic\nNeighbor Embedding (MR-SNE), that (1) first computes augmented relations, where\nwe observe the relations across domains and compute those within each of\ndomains via the observed data vectors, and (2) jointly embeds the augmented\nrelations to a low-dimensional space. Through visualization of Flickr and\nAnimal with Attributes 2 datasets, proposed MR-SNE is compared with other graph\nembedding-based approaches; MR-SNE demonstrates the promising performance.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 00:39:29 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Mizutani", "Morihiro", ""], ["Okuno", "Akifumi", ""], ["Kim", "Geewook", ""], ["Shimodaira", "Hidetoshi", ""]]}, {"id": "2005.00673", "submitter": "Zheng Tang", "authors": "Zheng Tang, Milind Naphade, Stan Birchfield, Jonathan Tremblay,\n  William Hodge, Ratnesh Kumar, Shuo Wang, Xiaodong Yang", "title": "PAMTRI: Pose-Aware Multi-Task Learning for Vehicle Re-Identification\n  Using Highly Randomized Synthetic Data", "comments": "Accepted by ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In comparison with person re-identification (ReID), which has been widely\nstudied in the research community, vehicle ReID has received less attention.\nVehicle ReID is challenging due to 1) high intra-class variability (caused by\nthe dependency of shape and appearance on viewpoint), and 2) small inter-class\nvariability (caused by the similarity in shape and appearance between vehicles\nproduced by different manufacturers). To address these challenges, we propose a\nPose-Aware Multi-Task Re-Identification (PAMTRI) framework. This approach\nincludes two innovations compared with previous methods. First, it overcomes\nviewpoint-dependency by explicitly reasoning about vehicle pose and shape via\nkeypoints, heatmaps and segments from pose estimation. Second, it jointly\nclassifies semantic vehicle attributes (colors and types) while performing\nReID, through multi-task learning with the embedded pose representations. Since\nmanually labeling images with detailed pose and attribute information is\nprohibitive, we create a large-scale highly randomized synthetic dataset with\nautomatically annotated vehicle attributes for training. Extensive experiments\nvalidate the effectiveness of each proposed component, showing that PAMTRI\nachieves significant improvement over state-of-the-art on two mainstream\nvehicle ReID benchmarks: VeRi and CityFlow-ReID. Code and models are available\nat https://github.com/NVlabs/PAMTRI.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 01:29:09 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Tang", "Zheng", ""], ["Naphade", "Milind", ""], ["Birchfield", "Stan", ""], ["Tremblay", "Jonathan", ""], ["Hodge", "William", ""], ["Kumar", "Ratnesh", ""], ["Wang", "Shuo", ""], ["Yang", "Xiaodong", ""]]}, {"id": "2005.00678", "submitter": "Haifeng Yang", "authors": "Haifeng Yang, Caixia Qu, Jianghui Cai, Sulan Zhang, Xujun Zhao", "title": "SVM-Lattice: A Recognition & Evaluation Frame for Double-peaked Profiles", "comments": "19 pages,11 figures,IEEE Access accepted", "journal-ref": null, "doi": "10.1109/ACCESS.2020.2990801", "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In big data era, the special data with rare characteristics may be of great\nsignifications. However, it is very difficult to automatically search these\nsamples from the massive and high-dimensional datasets and systematically\nevaluate them. The DoPS, our previous work [2], provided a search method of\nrare spectra with double-peaked profiles from massive and high-dimensional data\nof LAMOST survey. The identification of the results is mainly depended on\nvisually inspection by astronomers. In this paper, as a follow-up study, a new\nlattice structure named SVM-Lattice is designed based on SVM(Support Vector\nMachine) and FCL(Formal Concept Lattice) and particularly applied in the\nrecognition and evaluation of rare spectra with double-peaked profiles. First,\neach node in the SVM-Lattice structure contains two components: the intents are\ndefined by the support vectors trained by the spectral samples with the\nspecific characteristics, and the relevant extents are all the positive samples\nclassified by the support vectors. The hyperplanes can be extracted from every\nlattice node and used as classifiers to search targets by categories. A\ngeneralization and specialization relationship is expressed between the layers,\nand higher layers indicate higher confidence of targets. Then, including a\nSVM-Lattice building algorithm, a pruning algorithm based on association rules,\nand an evaluation algorithm, the supporting algorithms are provided and\nanalysed. Finally, for the recognition and evaluation of spectra with\ndouble-peaked profiles, several data sets from LAMOST survey are used as\nexperimental dataset. The results exhibit good consistency with traditional\nmethods, more detailed and accurate evaluations of classification results, and\nhigher searching efficiency than other similar methods.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 01:56:18 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Yang", "Haifeng", ""], ["Qu", "Caixia", ""], ["Cai", "Jianghui", ""], ["Zhang", "Sulan", ""], ["Zhao", "Xujun", ""]]}, {"id": "2005.00687", "submitter": "Weihua Hu", "authors": "Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren,\n  Bowen Liu, Michele Catasta, Jure Leskovec", "title": "Open Graph Benchmark: Datasets for Machine Learning on Graphs", "comments": "Fix dataset bug in ogbg-code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Open Graph Benchmark (OGB), a diverse set of challenging and\nrealistic benchmark datasets to facilitate scalable, robust, and reproducible\ngraph machine learning (ML) research. OGB datasets are large-scale, encompass\nmultiple important graph ML tasks, and cover a diverse range of domains,\nranging from social and information networks to biological networks, molecular\ngraphs, source code ASTs, and knowledge graphs. For each dataset, we provide a\nunified evaluation protocol using meaningful application-specific data splits\nand evaluation metrics. In addition to building the datasets, we also perform\nextensive benchmark experiments for each dataset. Our experiments suggest that\nOGB datasets present significant challenges of scalability to large-scale\ngraphs and out-of-distribution generalization under realistic data splits,\nindicating fruitful opportunities for future research. Finally, OGB provides an\nautomated end-to-end graph ML pipeline that simplifies and standardizes the\nprocess of graph data loading, experimental setup, and model evaluation. OGB\nwill be regularly updated and welcomes inputs from the community. OGB datasets\nas well as data loaders, evaluation scripts, baseline code, and leaderboards\nare publicly available at https://ogb.stanford.edu .\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 03:09:50 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 05:34:27 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 06:04:02 GMT"}, {"version": "v4", "created": "Wed, 12 Aug 2020 07:32:14 GMT"}, {"version": "v5", "created": "Wed, 21 Oct 2020 22:10:44 GMT"}, {"version": "v6", "created": "Sat, 23 Jan 2021 20:06:50 GMT"}, {"version": "v7", "created": "Thu, 25 Feb 2021 02:06:27 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Hu", "Weihua", ""], ["Fey", "Matthias", ""], ["Zitnik", "Marinka", ""], ["Dong", "Yuxiao", ""], ["Ren", "Hongyu", ""], ["Liu", "Bowen", ""], ["Catasta", "Michele", ""], ["Leskovec", "Jure", ""]]}, {"id": "2005.00694", "submitter": "Nguyen Van Huynh", "authors": "Nguyen Van Huynh, Diep N. Nguyen, Dinh Thai Hoang, and Eryk Dutkiewicz", "title": "Optimal Beam Association for High Mobility mmWave Vehicular Networks:\n  Lightweight Parallel Reinforcement Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In intelligent transportation systems (ITS), vehicles are expected to feature\nwith advanced applications and services which demand ultra-high data rates and\nlow-latency communications. For that, the millimeter wave (mmWave)\ncommunication has been emerging as a very promising solution. However,\nincorporating the mmWave into ITS is particularly challenging due to the high\nmobility of vehicles and the inherent sensitivity of mmWave beams to dynamic\nblockages. This article addresses these problems by developing an optimal beam\nassociation framework for mmWave vehicular networks under high mobility.\nSpecifically, we use the semi-Markov decision process to capture the dynamics\nand uncertainty of the environment. The Q-learning algorithm is then often used\nto find the optimal policy. However, Q-learning is notorious for its\nslow-convergence. Instead of adopting deep reinforcement learning structures\n(like most works in the literature), we leverage the fact that there are\nusually multiple vehicles on the road to speed up the learning process. To that\nend, we develop a lightweight yet very effective parallel Q-learning algorithm\nto quickly obtain the optimal policy by simultaneously learning from various\nvehicles. Extensive simulations demonstrate that our proposed solution can\nincrease the data rate by 47% and reduce the disconnection probability by 29%\ncompared to other solutions.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 04:05:25 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 06:47:25 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Van Huynh", "Nguyen", ""], ["Nguyen", "Diep N.", ""], ["Hoang", "Dinh Thai", ""], ["Dutkiewicz", "Eryk", ""]]}, {"id": "2005.00695", "submitter": "Hongyang Zhang", "authors": "Sen Wu, Hongyang R. Zhang, Gregory Valiant, Christopher R\\'e", "title": "On the Generalization Effects of Linear Transformations in Data\n  Augmentation", "comments": "International Conference on Machine learning (ICML) 2020. Added\n  experimental results on ImageNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is a powerful technique to improve performance in\napplications such as image and text classification tasks. Yet, there is little\nrigorous understanding of why and how various augmentations work. In this work,\nwe consider a family of linear transformations and study their effects on the\nridge estimator in an over-parametrized linear regression setting. First, we\nshow that transformations which preserve the labels of the data can improve\nestimation by enlarging the span of the training data. Second, we show that\ntransformations which mix data can improve estimation by playing a\nregularization effect. Finally, we validate our theoretical insights on MNIST.\nBased on the insights, we propose an augmentation scheme that searches over the\nspace of transformations by how uncertain the model is about the transformed\ndata. We validate our proposed scheme on image and text datasets. For example,\nour method outperforms RandAugment by 1.24% on CIFAR-100 using\nWide-ResNet-28-10. Furthermore, we achieve comparable accuracy to the SoTA\nAdversarial AutoAugment on CIFAR datasets.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 04:10:21 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 06:00:23 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Wu", "Sen", ""], ["Zhang", "Hongyang R.", ""], ["Valiant", "Gregory", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2005.00697", "submitter": "Qingqing Cao", "authors": "Qingqing Cao, Harsh Trivedi, Aruna Balasubramanian, Niranjan\n  Balasubramanian", "title": "DeFormer: Decomposing Pre-trained Transformers for Faster Question\n  Answering", "comments": "ACL 2020 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based QA models use input-wide self-attention -- i.e. across both\nthe question and the input passage -- at all layers, causing them to be slow\nand memory-intensive. It turns out that we can get by without input-wide\nself-attention at all layers, especially in the lower layers. We introduce\nDeFormer, a decomposed transformer, which substitutes the full self-attention\nwith question-wide and passage-wide self-attentions in the lower layers. This\nallows for question-independent processing of the input text representations,\nwhich in turn enables pre-computing passage representations reducing runtime\ncompute drastically. Furthermore, because DeFormer is largely similar to the\noriginal model, we can initialize DeFormer with the pre-training weights of a\nstandard transformer, and directly fine-tune on the target QA dataset. We show\nDeFormer versions of BERT and XLNet can be used to speed up QA by over 4.3x and\nwith simple distillation-based losses they incur only a 1% drop in accuracy. We\nopen source the code at https://github.com/StonyBrookNLP/deformer.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 04:28:22 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Cao", "Qingqing", ""], ["Trivedi", "Harsh", ""], ["Balasubramanian", "Aruna", ""], ["Balasubramanian", "Niranjan", ""]]}, {"id": "2005.00698", "submitter": "Satya P. Singh Ph.D.", "authors": "Satya P. Singh, Aim\\'e Lay-Ekuakille, Deepak Gangwar, Madan Kumar\n  Sharma, Sukrit Gupta", "title": "Deep ConvLSTM with self-attention for human activity decoding using\n  wearables", "comments": "8 pages, 2 figures, 3 tables. IEEE Sensors Journal, 2020", "journal-ref": null, "doi": "10.1109/JSEN.2020.3045135", "report-no": null, "categories": "cs.HC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decoding human activity accurately from wearable sensors can aid in\napplications related to healthcare and context awareness. The present\napproaches in this domain use recurrent and/or convolutional models to capture\nthe spatio-temporal features from time-series data from multiple sensors. We\npropose a deep neural network architecture that not only captures the\nspatio-temporal features of multiple sensor time-series data but also selects,\nlearns important time points by utilizing a self-attention mechanism. We show\nthe validity of the proposed approach across different data sampling strategies\non six public datasets and demonstrate that the self-attention mechanism gave a\nsignificant improvement in performance over deep networks using a combination\nof recurrent and convolution networks. We also show that the proposed approach\ngave a statistically significant performance enhancement over previous\nstate-of-the-art methods for the tested datasets. The proposed methods open\navenues for better decoding of human activity from multiple body sensors over\nextended periods of time. The code implementation for the proposed model is\navailable at https://github.com/isukrit/encodingHumanActivity.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 04:30:31 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 03:08:37 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Singh", "Satya P.", ""], ["Lay-Ekuakille", "Aim\u00e9", ""], ["Gangwar", "Deepak", ""], ["Sharma", "Madan Kumar", ""], ["Gupta", "Sukrit", ""]]}, {"id": "2005.00699", "submitter": "Jieyu Zhao", "authors": "Jieyu Zhao, Subhabrata Mukherjee, Saghar Hosseini, Kai-Wei Chang and\n  Ahmed Hassan Awadallah", "title": "Gender Bias in Multilingual Embeddings and Cross-Lingual Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual representations embed words from many languages into a single\nsemantic space such that words with similar meanings are close to each other\nregardless of the language. These embeddings have been widely used in various\nsettings, such as cross-lingual transfer, where a natural language processing\n(NLP) model trained on one language is deployed to another language. While the\ncross-lingual transfer techniques are powerful, they carry gender bias from the\nsource to target languages. In this paper, we study gender bias in multilingual\nembeddings and how it affects transfer learning for NLP applications. We create\na multilingual dataset for bias analysis and propose several ways for\nquantifying bias in multilingual representations from both the intrinsic and\nextrinsic perspectives. Experimental results show that the magnitude of bias in\nthe multilingual representations changes differently when we align the\nembeddings to different target spaces and that the alignment direction can also\nhave an influence on the bias in transfer learning. We further provide\nrecommendations for using the multilingual word representations for downstream\ntasks.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 04:34:37 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Zhao", "Jieyu", ""], ["Mukherjee", "Subhabrata", ""], ["Hosseini", "Saghar", ""], ["Chang", "Kai-Wei", ""], ["Awadallah", "Ahmed Hassan", ""]]}, {"id": "2005.00702", "submitter": "Asad Mahmood", "authors": "Asad Mahmood, Zubair Shafiq and Padmini Srinivasan", "title": "A Girl Has A Name: Detecting Authorship Obfuscation", "comments": "9 pages, 4 figures, 2 tables, ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authorship attribution aims to identify the author of a text based on the\nstylometric analysis. Authorship obfuscation, on the other hand, aims to\nprotect against authorship attribution by modifying a text's style. In this\npaper, we evaluate the stealthiness of state-of-the-art authorship obfuscation\nmethods under an adversarial threat model. An obfuscator is stealthy to the\nextent an adversary finds it challenging to detect whether or not a text\nmodified by the obfuscator is obfuscated - a decision that is key to the\nadversary interested in authorship attribution. We show that the existing\nauthorship obfuscation methods are not stealthy as their obfuscated texts can\nbe identified with an average F1 score of 0.87. The reason for the lack of\nstealthiness is that these obfuscators degrade text smoothness, as ascertained\nby neural language models, in a detectable manner. Our results highlight the\nneed to develop stealthy authorship obfuscation methods that can better protect\nthe identity of an author seeking anonymity.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 04:52:55 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Mahmood", "Asad", ""], ["Shafiq", "Zubair", ""], ["Srinivasan", "Padmini", ""]]}, {"id": "2005.00705", "submitter": "Thuy Vu", "authors": "Thuy Vu and Alessandro Moschitti", "title": "AVA: an Automatic eValuation Approach to Question Answering Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce AVA, an automatic evaluation approach for Question Answering,\nwhich given a set of questions associated with Gold Standard answers, can\nestimate system Accuracy. AVA uses Transformer-based language models to encode\nquestion, answer, and reference text. This allows for effectively measuring the\nsimilarity between the reference and an automatic answer, biased towards the\nquestion semantics. To design, train and test AVA, we built multiple large\ntraining, development, and test sets on both public and industrial benchmarks.\nOur innovative solutions achieve up to 74.7% in F1 score in predicting human\njudgement for single answers. Additionally, AVA can be used to evaluate the\noverall system Accuracy with an RMSE, ranging from 0.02 to 0.09, depending on\nthe availability of multiple references.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 05:00:16 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Vu", "Thuy", ""], ["Moschitti", "Alessandro", ""]]}, {"id": "2005.00718", "submitter": "Zebang Zhang", "authors": "Zebang Zhang, Kui Zhao, Kai Huang, Quanhui Jia, Yanming Fang, Quan Yu", "title": "Large-scale Uncertainty Estimation and Its Application in Revenue\n  Forecast of SMEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The economic and banking importance of the small and medium enterprise (SME)\nsector is well recognized in contemporary society. Business credit loans are\nvery important for the operation of SMEs, and the revenue is a key indicator of\ncredit limit management. Therefore, it is very beneficial to construct a\nreliable revenue forecasting model. If the uncertainty of an enterprise's\nrevenue forecasting can be estimated, a more proper credit limit can be\ngranted. Natural gradient boosting approach, which estimates the uncertainty of\nprediction by a multi-parameter boosting algorithm based on the natural\ngradient. However, its original implementation is not easy to scale into big\ndata scenarios, and computationally expensive compared to state-of-the-art\ntree-based models (such as XGBoost). In this paper, we propose a Scalable\nNatural Gradient Boosting Machines that is simple to implement, readily\nparallelizable, interpretable and yields high-quality predictive uncertainty\nestimates. According to the characteristics of revenue distribution, we derive\nan uncertainty quantification function. We demonstrate that our method can\ndistinguish between samples that are accurate and inaccurate on revenue\nforecasting of SMEs. What's more, interpretability can be naturally obtained\nfrom the model, satisfying the financial needs.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 06:17:44 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Zhang", "Zebang", ""], ["Zhao", "Kui", ""], ["Huang", "Kai", ""], ["Jia", "Quanhui", ""], ["Fang", "Yanming", ""], ["Yu", "Quan", ""]]}, {"id": "2005.00724", "submitter": "Sanjay Subramanian", "authors": "Sanjay Subramanian, Ben Bogin, Nitish Gupta, Tomer Wolfson, Sameer\n  Singh, Jonathan Berant, Matt Gardner", "title": "Obtaining Faithful Interpretations from Compositional Neural Networks", "comments": "ACL 2020; first three authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural module networks (NMNs) are a popular approach for modeling\ncompositionality: they achieve high accuracy when applied to problems in\nlanguage and vision, while reflecting the compositional structure of the\nproblem in the network architecture. However, prior work implicitly assumed\nthat the structure of the network modules, describing the abstract reasoning\nprocess, provides a faithful explanation of the model's reasoning; that is,\nthat all modules perform their intended behaviour. In this work, we propose and\nconduct a systematic evaluation of the intermediate outputs of NMNs on NLVR2\nand DROP, two datasets which require composing multiple reasoning steps. We\nfind that the intermediate outputs differ from the expected output,\nillustrating that the network structure does not provide a faithful explanation\nof model behaviour. To remedy that, we train the model with auxiliary\nsupervision and propose particular choices for module architecture that yield\nmuch better faithfulness, at a minimal cost to accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 06:50:35 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 15:52:28 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Subramanian", "Sanjay", ""], ["Bogin", "Ben", ""], ["Gupta", "Nitish", ""], ["Wolfson", "Tomer", ""], ["Singh", "Sameer", ""], ["Berant", "Jonathan", ""], ["Gardner", "Matt", ""]]}, {"id": "2005.00728", "submitter": "Jesse Thomason", "authors": "Homero Roman Roman, Yonatan Bisk, Jesse Thomason, Asli Celikyilmaz,\n  Jianfeng Gao", "title": "RMM: A Recursive Mental Model for Dialog Navigation", "comments": "Findings of Empirical Methods in Natural Language Processing (EMNLP\n  Findings), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language-guided robots must be able to both ask humans questions and\nunderstand answers. Much existing work focuses only on the latter. In this\npaper, we go beyond instruction following and introduce a two-agent task where\none agent navigates and asks questions that a second, guiding agent answers.\nInspired by theory of mind, we propose the Recursive Mental Model (RMM). The\nnavigating agent models the guiding agent to simulate answers given candidate\ngenerated questions. The guiding agent in turn models the navigating agent to\nsimulate navigation steps it would take to generate answers. We use the\nprogress agents make towards the goal as a reinforcement learning reward signal\nto directly inform not only navigation actions, but also both question and\nanswer generation. We demonstrate that RMM enables better generalization to\nnovel environments. Interlocutor modelling may be a way forward for human-agent\ndialogue where robots need to both ask and answer questions.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 06:57:14 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 02:16:27 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Roman", "Homero Roman", ""], ["Bisk", "Yonatan", ""], ["Thomason", "Jesse", ""], ["Celikyilmaz", "Asli", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2005.00730", "submitter": "Nazneen Fatema Rajani", "authors": "Nazneen Fatema Rajani, Rui Zhang, Yi Chern Tan, Stephan Zheng, Jeremy\n  Weiss, Aadit Vyas, Abhijit Gupta, Caiming XIong, Richard Socher, Dragomir\n  Radev", "title": "ESPRIT: Explaining Solutions to Physical Reasoning Tasks", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks lack the ability to reason about qualitative physics and so\ncannot generalize to scenarios and tasks unseen during training. We propose\nESPRIT, a framework for commonsense reasoning about qualitative physics in\nnatural language that generates interpretable descriptions of physical events.\nWe use a two-step approach of first identifying the pivotal physical events in\nan environment and then generating natural language descriptions of those\nevents using a data-to-text approach. Our framework learns to generate\nexplanations of how the physical simulation will causally evolve so that an\nagent or a human can easily reason about a solution using those interpretable\ndescriptions. Human evaluations indicate that ESPRIT produces crucial\nfine-grained details and has high coverage of physical concepts compared to\neven human annotations. Dataset, code and documentation are available at\nhttps://github.com/salesforce/esprit.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 07:03:06 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 00:24:13 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Rajani", "Nazneen Fatema", ""], ["Zhang", "Rui", ""], ["Tan", "Yi Chern", ""], ["Zheng", "Stephan", ""], ["Weiss", "Jeremy", ""], ["Vyas", "Aadit", ""], ["Gupta", "Abhijit", ""], ["XIong", "Caiming", ""], ["Socher", "Richard", ""], ["Radev", "Dragomir", ""]]}, {"id": "2005.00743", "submitter": "Yi Tay", "authors": "Yi Tay, Dara Bahri, Donald Metzler, Da-Cheng Juan, Zhe Zhao, Che Zheng", "title": "Synthesizer: Rethinking Self-Attention in Transformer Models", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dot product self-attention is known to be central and indispensable to\nstate-of-the-art Transformer models. But is it really required? This paper\ninvestigates the true importance and contribution of the dot product-based\nself-attention mechanism on the performance of Transformer models. Via\nextensive experiments, we find that (1) random alignment matrices surprisingly\nperform quite competitively and (2) learning attention weights from token-token\n(query-key) interactions is useful but not that important after all. To this\nend, we propose \\textsc{Synthesizer}, a model that learns synthetic attention\nweights without token-token interactions. In our experiments, we first show\nthat simple Synthesizers achieve highly competitive performance when compared\nagainst vanilla Transformer models across a range of tasks, including machine\ntranslation, language modeling, text generation and GLUE/SuperGLUE benchmarks.\nWhen composed with dot product attention, we find that Synthesizers\nconsistently outperform Transformers. Moreover, we conduct additional\ncomparisons of Synthesizers against Dynamic Convolutions, showing that simple\nRandom Synthesizer is not only $60\\%$ faster but also improves perplexity by a\nrelative $3.5\\%$. Finally, we show that simple factorized Synthesizers can\noutperform Linformers on encoding only tasks.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 08:16:19 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 12:16:06 GMT"}, {"version": "v3", "created": "Mon, 24 May 2021 12:19:35 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Tay", "Yi", ""], ["Bahri", "Dara", ""], ["Metzler", "Donald", ""], ["Juan", "Da-Cheng", ""], ["Zhao", "Zhe", ""], ["Zheng", "Che", ""]]}, {"id": "2005.00745", "submitter": "Saud Aldossari", "authors": "Saud Aldossari, Kwang-Cheng Chen", "title": "Predicting the Path Loss of Wireless Channel Models Using Machine\n  Learning Techniques in MmWave Urban Communications", "comments": "5 pages and 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classic wireless communication channel modeling is performed using\nDeterministic and Stochastic channel methodologies. Machine learning (ML)\nemerges to revolutionize system design for 5G and beyond. ML techniques such as\nsupervise leaning methods will be used to predict the wireless channel path\nloss of a variate of environments base on a certain dataset. The propagation\nsignal of communication systems fundamentals is focusing on channel modeling\nparticularly for new frequency bands such as MmWave. Machine learning can\nfacilitate rapid channel modeling for 5G and beyond wireless communication\nsystems due to the availability of partially relevant channel measurement data\nand model. When irregularity of the wireless channels lead to a complex\nmethodology to achieve accurate models, appropriate machine learning\nmethodology explores to reduce the complexity and increase the accuracy. In\nthis paper, we demonstrate alternative procedures beyond traditional channel\nmodeling to enhance the path loss models using machine learning techniques, to\nalleviate the dilemma of channel complexity and time-consuming process that the\nmeasurements were taken. This demonstrated regression uses the measurement data\nof a certain scenario to successfully assist the prediction of path loss model\nof a different operating environment.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 08:19:18 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Aldossari", "Saud", ""], ["Chen", "Kwang-Cheng", ""]]}, {"id": "2005.00777", "submitter": "Shuyue Jia", "authors": "Yimin Hou, Shuyue Jia, Xiangmin Lun, Yan Shi, Yang Li", "title": "Deep Feature Mining via Attention-based BiLSTM-GCN for Human Motor\n  Imagery Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recognition accuracy and response time are both critically essential ahead of\nbuilding practical electroencephalography (EEG) based brain-computer interface\n(BCI). Recent approaches, however, have either compromised in the\nclassification accuracy or responding time. This paper presents a novel deep\nlearning approach designed towards remarkably accurate and responsive motor\nimagery (MI) recognition based on scalp EEG. Bidirectional Long Short-term\nMemory (BiLSTM) with the Attention mechanism manages to derive relevant\nfeatures from raw EEG signals. The connected graph convolutional neural network\n(GCN) promotes the decoding performance by cooperating with the topological\nstructure of features, which are estimated from the overall data. The\n0.4-second detection framework has shown effective and efficient prediction\nbased on individual and group-wise training, with 98.81% and 94.64% accuracy,\nrespectively, which outperformed all the state-of-the-art studies. The\nintroduced deep feature mining approach can precisely recognize human motion\nintents from raw EEG signals, which paves the road to translate the EEG based\nMI recognition to practical BCI systems.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 10:03:40 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 03:29:42 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Hou", "Yimin", ""], ["Jia", "Shuyue", ""], ["Lun", "Xiangmin", ""], ["Shi", "Yan", ""], ["Li", "Yang", ""]]}, {"id": "2005.00783", "submitter": "Justus Tilmann Caspar Schwabedal", "authors": "Justus T. C. Schwabedal and Pascal Michel and Mario S. Riontino", "title": "Differentially Private Generation of Small Images", "comments": "11 pages, 3 figures. Revised criticism of Beaulieu-Jones et al\n  (2017): their results are likely correct", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the training of generative adversarial networks with differential\nprivacy to anonymize image data sets. On MNIST, we numerically measure the\nprivacy-utility trade-off using parameters from $\\epsilon$-$\\delta$\ndifferential privacy and the inception score. Our experiments uncover a\nsaturated training regime where an increasing privacy budget adds little to the\nquality of generated images. We also explain analytically why differentially\nprivate Adam optimization is independent of the gradient clipping parameter.\nFurthermore, we highlight common errors in previous works on differentially\nprivate deep learning, which we uncovered in recent literature. Throughout the\ntreatment of the subject, we hope to prevent erroneous estimates of anonymity\nin the future.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 10:37:46 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 09:38:10 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Schwabedal", "Justus T. C.", ""], ["Michel", "Pascal", ""], ["Riontino", "Mario S.", ""]]}, {"id": "2005.00784", "submitter": "Shuyin Xia", "authors": "Shuyin Xia, Daowan Peng, Deyu Meng, Changqing Zhang, Guoyin Wang,\n  Zizhong Chen, Wei Wei", "title": "Ball k-means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel accelerated exact k-means algorithm called the\nBall k-means algorithm, which uses a ball to describe a cluster, focusing on\nreducing the point-centroid distance computation. The Ball k-means can\naccurately find the neighbor clusters for each cluster resulting distance\ncomputations only between a point and its neighbor clusters' centroids instead\nof all centroids. Moreover, each cluster can be divided into a stable area and\nan active area, and the later one can be further divided into annulus areas.\nThe assigned cluster of the points in the stable area is not changed in the\ncurrent iteration while the points in the annulus area will be adjusted within\na few neighbor clusters in the current iteration. Also, there are no upper or\nlower bounds in the proposed Ball k-means. Furthermore, reducing\ncentroid-centroid distance computation between iterations makes it efficient\nfor large k clustering. The fast speed, no extra parameters and simple design\nof the Ball k-means make it an all-around replacement of the naive k-means\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 10:39:26 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Xia", "Shuyin", ""], ["Peng", "Daowan", ""], ["Meng", "Deyu", ""], ["Zhang", "Changqing", ""], ["Wang", "Guoyin", ""], ["Chen", "Zizhong", ""], ["Wei", "Wei", ""]]}, {"id": "2005.00789", "submitter": "Harsh Trivedi", "authors": "Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, Ashish Sabharwal", "title": "Is Multihop QA in DiRe Condition? Measuring and Reducing Disconnected\n  Reasoning", "comments": "Accepted at EMNLP'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Has there been real progress in multi-hop question-answering? Models often\nexploit dataset artifacts to produce correct answers, without connecting\ninformation across multiple supporting facts. This limits our ability to\nmeasure true progress and defeats the purpose of building multi-hop QA\ndatasets. We make three contributions towards addressing this. First, we\nformalize such undesirable behavior as disconnected reasoning across subsets of\nsupporting facts. This allows developing a model-agnostic probe for measuring\nhow much any model can cheat via disconnected reasoning. Second, using a notion\nof \\emph{contrastive support sufficiency}, we introduce an automatic\ntransformation of existing datasets that reduces the amount of disconnected\nreasoning. Third, our experiments suggest that there hasn't been much progress\nin multi-hop QA in the reading comprehension setting. For a recent large-scale\nmodel (XLNet), we show that only 18 points out of its answer F1 score of 72 on\nHotpotQA are obtained through multifact reasoning, roughly the same as that of\na simpler RNN baseline. Our transformation substantially reduces disconnected\nreasoning (19 points in answer F1). It is complementary to adversarial\napproaches, yielding further reductions in conjunction.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 11:01:07 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 17:54:00 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 04:18:51 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Trivedi", "Harsh", ""], ["Balasubramanian", "Niranjan", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""]]}, {"id": "2005.00792", "submitter": "Woojeong Jin", "authors": "Woojeong Jin, Rahul Khanna, Suji Kim, Dong-Ho Lee, Fred Morstatter,\n  Aram Galstyan, Xiang Ren", "title": "ForecastQA: A Question Answering Challenge for Event Forecasting with\n  Temporal Text Data", "comments": "Accepted to ACL 2021. Project page:\n  https://inklab.usc.edu/ForecastQA/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event forecasting is a challenging, yet important task, as humans seek to\nconstantly plan for the future. Existing automated forecasting studies rely\nmostly on structured data, such as time-series or event-based knowledge graphs,\nto help predict future events. In this work, we aim to formulate a task,\nconstruct a dataset, and provide benchmarks for developing methods for event\nforecasting with large volumes of unstructured text data. To simulate the\nforecasting scenario on temporal news documents, we formulate the problem as a\nrestricted-domain, multiple-choice, question-answering (QA) task. Unlike\nexisting QA tasks, our task limits accessible information, and thus a model has\nto make a forecasting judgement. To showcase the usefulness of this task\nformulation, we introduce ForecastQA, a question-answering dataset consisting\nof 10,392 event forecasting questions, which have been collected and verified\nvia crowdsourcing efforts. We present our experiments on ForecastQA using\nBERT-based models and find that our best model achieves 60.1% accuracy on the\ndataset, which still lags behind human performance by about 19%. We hope\nForecastQA will support future research efforts in bridging this gap.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 11:03:40 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 23:56:35 GMT"}, {"version": "v3", "created": "Sat, 2 Jan 2021 09:16:31 GMT"}, {"version": "v4", "created": "Tue, 8 Jun 2021 02:54:15 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Jin", "Woojeong", ""], ["Khanna", "Rahul", ""], ["Kim", "Suji", ""], ["Lee", "Dong-Ho", ""], ["Morstatter", "Fred", ""], ["Galstyan", "Aram", ""], ["Ren", "Xiang", ""]]}, {"id": "2005.00797", "submitter": "Haishan Ye", "authors": "Haishan Ye, Luo Luo, Ziang Zhou, Tong Zhang", "title": "Multi-consensus Decentralized Accelerated Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the decentralized optimization problem, which has\napplications in large scale machine learning, sensor networks, and control\ntheory. We propose a novel algorithm that can achieve near optimal\ncommunication complexity, matching the known lower bound up to a logarithmic\nfactor of the condition number of the problem. Our theoretical results give\naffirmative answers to the open problem on whether there exists an algorithm\nthat can achieve a communication complexity (nearly) matching the lower bound\ndepending on the global condition number instead of the local one. Moreover,\nthe proposed algorithm achieves the optimal computation complexity matching the\nlower bound up to universal constants. Furthermore, to achieve a linear\nconvergence rate, our algorithm \\emph{doesn't} require the individual functions\nto be (strongly) convex. Our method relies on a novel combination of known\ntechniques including Nesterov's accelerated gradient descent, multi-consensus\nand gradient-tracking. The analysis is new, and may be applied to other related\nproblems. Empirical studies demonstrate the effectiveness of our method for\nmachine learning applications.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 11:10:32 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Ye", "Haishan", ""], ["Luo", "Luo", ""], ["Zhou", "Ziang", ""], ["Zhang", "Tong", ""]]}, {"id": "2005.00803", "submitter": "Byungsoo Kim", "authors": "Byungsoo Kim, Vinicius C. Azevedo, Markus Gross, Barbara Solenthaler", "title": "Lagrangian Neural Style Transfer for Fluids", "comments": "ACM Transaction on Graphics (SIGGRAPH 2020), additional materials:\n  http://www.byungsoo.me/project/lnst/index.html", "journal-ref": "ACM Trans. Graph. 39, 4, Article 1 (July 2020), 10 pages", "doi": "10.1145/3386569.3392473", "report-no": null, "categories": "cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artistically controlling the shape, motion and appearance of fluid\nsimulations pose major challenges in visual effects production. In this paper,\nwe present a neural style transfer approach from images to 3D fluids formulated\nin a Lagrangian viewpoint. Using particles for style transfer has unique\nbenefits compared to grid-based techniques. Attributes are stored on the\nparticles and hence are trivially transported by the particle motion. This\nintrinsically ensures temporal consistency of the optimized stylized structure\nand notably improves the resulting quality. Simultaneously, the expensive,\nrecursive alignment of stylization velocity fields of grid approaches is\nunnecessary, reducing the computation time to less than an hour and rendering\nneural flow stylization practical in production settings. Moreover, the\nLagrangian representation improves artistic control as it allows for\nmulti-fluid stylization and consistent color transfer from images, and the\ngenerality of the method enables stylization of smoke and liquids likewise.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 11:53:05 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Kim", "Byungsoo", ""], ["Azevedo", "Vinicius C.", ""], ["Gross", "Markus", ""], ["Solenthaler", "Barbara", ""]]}, {"id": "2005.00804", "submitter": "Prachi Jain", "authors": "Prachi Jain, Sushant Rathi, Mausam, Soumen Chakrabarti", "title": "Knowledge Base Completion: Baseline strikes back (Again)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Base Completion (KBC) has been a very active area lately. Several\nrecent KBCpapers propose architectural changes, new training methods, or even\nnew formulations. KBC systems are usually evaluated on standard benchmark\ndatasets: FB15k, FB15k-237, WN18, WN18RR, and Yago3-10. Most existing methods\ntrain with a small number of negative samples for each positive instance in\nthese datasets to save computational costs. This paper discusses how recent\ndevelopments allow us to use all available negative samples for training. We\nshow that Complex, when trained using all available negative samples, gives\nnear state-of-the-art performance on all the datasets. We call this approach\nCOMPLEX-V2. We also highlight how various multiplicative KBC methods, recently\nproposed in the literature, benefit from this train-ing regime and become\nindistinguishable in terms of performance on most datasets. Our work calls for\na reassessment of their individual value, in light of these findings.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 11:53:22 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 11:33:11 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Jain", "Prachi", ""], ["Rathi", "Sushant", ""], ["Mausam", "", ""], ["Chakrabarti", "Soumen", ""]]}, {"id": "2005.00806", "submitter": "Qinyuan Ye", "authors": "Qinyuan Ye, Xiao Huang, Elizabeth Boschee, Xiang Ren", "title": "Teaching Machine Comprehension with Compositional Explanations", "comments": "Accepted to EMNLP 2020 Findings. Camera-ready version. Project page:\n  http://inklab.usc.edu/mrc-explanation-project/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in machine reading comprehension (MRC) rely heavily on the\ncollection of large scale human-annotated examples in the form of (question,\nparagraph, answer) triples. In contrast, humans are typically able to\ngeneralize with only a few examples, relying on deeper underlying world\nknowledge, linguistic sophistication, and/or simply superior deductive powers.\nIn this paper, we focus on \"teaching\" machines reading comprehension, using a\nsmall number of semi-structured explanations that explicitly inform machines\nwhy answer spans are correct. We extract structured variables and rules from\nexplanations and compose neural module teachers that annotate instances for\ntraining downstream MRC models. We use learnable neural modules and soft logic\nto handle linguistic variation and overcome sparse coverage; the modules are\njointly optimized with the MRC model to improve final performance. On the SQuAD\ndataset, our proposed method achieves 70.14% F1 score with supervision from 26\nexplanations, comparable to plain supervised learning using 1,100 labeled\ninstances, yielding a 12x speed up.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 11:54:34 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 20:13:10 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 19:28:50 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Ye", "Qinyuan", ""], ["Huang", "Xiao", ""], ["Boschee", "Elizabeth", ""], ["Ren", "Xiang", ""]]}, {"id": "2005.00808", "submitter": "Nina Grgi\\'c-Hla\\v{c}a", "authors": "Nina Grgi\\'c-Hla\\v{c}a, Adrian Weller, Elissa M. Redmiles", "title": "Dimensions of Diversity in Human Perceptions of Algorithmic Fairness", "comments": "Presented at the CSCW 2019 workshop on Team and Group Diversity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms are increasingly involved in making decisions that affect human\nlives. Prior work has explored how people believe algorithmic decisions should\nbe made, but there is little understanding of which individual factors relate\nto variance in these beliefs across people. As an increasing emphasis is put on\noversight boards and regulatory bodies, it is important to understand the\nbiases that may affect human judgements about the fairness of algorithms.\nBuilding on factors found in moral foundations theory and egocentric fairness\nliterature, we explore how people's perceptions of fairness relate to their (i)\ndemographics (age, race, gender, political view), and (ii) personal experiences\nwith the algorithmic task being evaluated. Specifically, we study human beliefs\nabout the fairness of using different features in an algorithm designed to\nassist judges in making decisions about granting bail. Our analysis suggests\nthat political views and certain demographic factors, such as age and gender,\nexhibit a significant relation to people's beliefs about fairness.\nAdditionally, we find that people beliefs about the fairness of using\ndemographic features such as age, gender and race, for making bail decisions\nabout others, vary egocentrically: that is they vary depending on their own\nage, gender and race respectively.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 11:59:39 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Grgi\u0107-Hla\u010da", "Nina", ""], ["Weller", "Adrian", ""], ["Redmiles", "Elissa M.", ""]]}, {"id": "2005.00811", "submitter": "Keerthiram Murugesan", "authors": "Keerthiram Murugesan, Mattia Atzeni, Pushkar Shukla, Mrinmaya Sachan,\n  Pavan Kapanipathi, Kartik Talamadupula", "title": "Enhancing Text-based Reinforcement Learning Agents with Commonsense\n  Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the recent trend of evaluating progress on\nreinforcement learning technology by using text-based environments and games as\nevaluation environments. This reliance on text brings advances in natural\nlanguage processing into the ambit of these agents, with a recurring thread\nbeing the use of external knowledge to mimic and better human-level\nperformance. We present one such instantiation of agents that use commonsense\nknowledge from ConceptNet to show promising performance on two text-based\nenvironments.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 12:07:02 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Murugesan", "Keerthiram", ""], ["Atzeni", "Mattia", ""], ["Shukla", "Pushkar", ""], ["Sachan", "Mrinmaya", ""], ["Kapanipathi", "Pavan", ""], ["Talamadupula", "Kartik", ""]]}, {"id": "2005.00813", "submitter": "Vinodkumar Prabhakaran", "authors": "Ben Hutchinson, Vinodkumar Prabhakaran, Emily Denton, Kellie Webster,\n  Yu Zhong, Stephen Denuyl", "title": "Social Biases in NLP Models as Barriers for Persons with Disabilities", "comments": "ACL 2020 short paper. 5 pages", "journal-ref": "ACL 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building equitable and inclusive NLP technologies demands consideration of\nwhether and how social attitudes are represented in ML models. In particular,\nrepresentations encoded in models often inadvertently perpetuate undesirable\nsocial biases from the data on which they are trained. In this paper, we\npresent evidence of such undesirable biases towards mentions of disability in\ntwo different English language models: toxicity prediction and sentiment\nanalysis. Next, we demonstrate that the neural embeddings that are the critical\nfirst step in most NLP pipelines similarly contain undesirable biases towards\nmentions of disability. We end by highlighting topical biases in the discourse\nabout disability which may contribute to the observed model biases; for\ninstance, gun violence, homelessness, and drug addiction are over-represented\nin texts discussing mental illness.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 12:16:54 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Hutchinson", "Ben", ""], ["Prabhakaran", "Vinodkumar", ""], ["Denton", "Emily", ""], ["Webster", "Kellie", ""], ["Zhong", "Yu", ""], ["Denuyl", "Stephen", ""]]}, {"id": "2005.00817", "submitter": "Andrea Apicella", "authors": "Andrea Apicella, Francesco Donnarumma, Francesco Isgr\\`o and Roberto\n  Prevete", "title": "A survey on modern trainable activation functions", "comments": "Published in \"Neural Networks\" journal (Elsevier)", "journal-ref": "Neural Networks Volume 138, June 2021, Pages 14-32", "doi": "10.1016/j.neunet.2021.01.026", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural networks literature, there is a strong interest in identifying and\ndefining activation functions which can improve neural network performance. In\nrecent years there has been a renovated interest of the scientific community in\ninvestigating activation functions which can be trained during the learning\nprocess, usually referred to as \"trainable\", \"learnable\" or \"adaptable\"\nactivation functions. They appear to lead to better network performance.\nDiverse and heterogeneous models of trainable activation function have been\nproposed in the literature. In this paper, we present a survey of these models.\nStarting from a discussion on the use of the term \"activation function\" in\nliterature, we propose a taxonomy of trainable activation functions, highlight\ncommon and distinctive proprieties of recent and past models, and discuss main\nadvantages and limitations of this type of approach. We show that many of the\nproposed approaches are equivalent to adding neuron layers which use fixed\n(non-trainable) activation functions and some simple local rule that\nconstraints the corresponding weight layers.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 12:38:43 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 22:11:55 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 12:55:51 GMT"}, {"version": "v4", "created": "Thu, 25 Feb 2021 21:34:34 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Apicella", "Andrea", ""], ["Donnarumma", "Francesco", ""], ["Isgr\u00f2", "Francesco", ""], ["Prevete", "Roberto", ""]]}, {"id": "2005.00820", "submitter": "Clara Meister", "authors": "Clara Meister, Elizabeth Salesky, Ryan Cotterell", "title": "Generalized Entropy Regularization or: There's Nothing Special about\n  Label Smoothing", "comments": "Published as long paper at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work has explored directly regularizing the output distributions of\nprobabilistic models to alleviate peaky (i.e. over-confident) predictions, a\ncommon sign of overfitting. This class of techniques, of which label smoothing\nis one, has a connection to entropy regularization. Despite the consistent\nsuccess of label smoothing across architectures and data sets in language\ngeneration tasks, two problems remain open: (1) there is little understanding\nof the underlying effects entropy regularizers have on models, and (2) the full\nspace of entropy regularization techniques is largely unexplored. We introduce\na parametric family of entropy regularizers, which includes label smoothing as\na special case, and use it to gain a better understanding of the relationship\nbetween the entropy of a model and its performance on language generation\ntasks. We also find that variance in model performance can be explained largely\nby the resulting entropy of the model. Lastly, we find that label smoothing\nprovably does not allow for sparsity in an output distribution, an undesirable\nproperty for language generation models, and therefore advise the use of other\nentropy regularization methods in its place.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 12:46:28 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 06:22:06 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Meister", "Clara", ""], ["Salesky", "Elizabeth", ""], ["Cotterell", "Ryan", ""]]}, {"id": "2005.00826", "submitter": "Lukas Brunke", "authors": "Lukas Brunke", "title": "Learning Model Predictive Control for Competitive Autonomous Racing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this thesis is to design a learning model predictive controller\n(LMPC) that allows multiple agents to race competitively on a predefined race\ntrack in real-time. This thesis addresses two major shortcomings in the already\nexisting single-agent formulation. Previously, the agent determines a locally\noptimal trajectory but does not explore the state space, which may be necessary\nfor overtaking maneuvers. Additionally, obstacle avoidance for LMPC has been\nachieved in the past by using a non-convex terminal set, which increases the\ncomplexity for determining a solution to the optimization problem. The proposed\nalgorithm for multi-agent racing explores the state space by executing the LMPC\nfor multiple different initializations, which yields a richer terminal safe\nset. Furthermore, a new method for selecting states in the terminal set is\ndeveloped, which keeps the convexity for the terminal safe set and allows for\ntaking suboptimal states.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 13:05:31 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Brunke", "Lukas", ""]]}, {"id": "2005.00828", "submitter": "Ali Hamdi", "authors": "Ali Hamdi, Flora Salim, Du Yong Kim", "title": "DroTrack: High-speed Drone-based Object Tracking Under Uncertainty", "comments": "10 pages, 12 figures, FUZZ-IEEE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DroTrack, a high-speed visual single-object tracking framework for\ndrone-captured video sequences. Most of the existing object tracking methods\nare designed to tackle well-known challenges, such as occlusion and cluttered\nbackgrounds. The complex motion of drones, i.e., multiple degrees of freedom in\nthree-dimensional space, causes high uncertainty. The uncertainty problem leads\nto inaccurate location predictions and fuzziness in scale estimations. DroTrack\nsolves such issues by discovering the dependency between object representation\nand motion geometry. We implement an effective object segmentation based on\nFuzzy C Means (FCM). We incorporate the spatial information into the membership\nfunction to cluster the most discriminative segments. We then enhance the\nobject segmentation by using a pre-trained Convolution Neural Network (CNN)\nmodel. DroTrack also leverages the geometrical angular motion to estimate a\nreliable object scale. We discuss the experimental results and performance\nevaluation using two datasets of 51,462 drone-captured frames. The combination\nof the FCM segmentation and the angular scaling increased DroTrack precision by\nup to $9\\%$ and decreased the centre location error by $162$ pixels on average.\nDroTrack outperforms all the high-speed trackers and achieves comparable\nresults in comparison to deep learning trackers. DroTrack offers high frame\nrates up to 1000 frame per second (fps) with the best location precision, more\nthan a set of state-of-the-art real-time trackers.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 13:16:16 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Hamdi", "Ali", ""], ["Salim", "Flora", ""], ["Kim", "Du Yong", ""]]}, {"id": "2005.00840", "submitter": "Hendrik Burwinkel", "authors": "Hendrik Burwinkel, Matthias Keicher, David Bani-Harouni, Tobias\n  Zellner, Florian Eyer, Nassir Navab, Seyed-Ahmad Ahmadi", "title": "Decision Support for Intoxication Prediction Using Graph Convolutional\n  Networks", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every day, poison control centers (PCC) are called for immediate\nclassification and treatment recommendations if an acute intoxication is\nsuspected. Due to the time-sensitive nature of these cases, doctors are\nrequired to propose a correct diagnosis and intervention within a minimal time\nframe. Usually the toxin is known and recommendations can be made accordingly.\nHowever, in challenging cases only symptoms are mentioned and doctors have to\nrely on their clinical experience. Medical experts and our analyses of a\nregional dataset of intoxication records provide evidence that this is\nchallenging, since occurring symptoms may not always match the textbook\ndescription due to regional distinctions, inter-rater variance, and\ninstitutional workflow. Computer-aided diagnosis (CADx) can provide decision\nsupport, but approaches so far do not consider additional information of the\nreported cases like age or gender, despite their potential value towards a\ncorrect diagnosis. In this work, we propose a new machine learning based CADx\nmethod which fuses symptoms and meta information of the patients using graph\nconvolutional networks. We further propose a novel symptom matching method that\nallows the effective incorporation of prior knowledge into the learning process\nand evidently stabilizes the poison prediction. We validate our method against\n10 medical doctors with different experience diagnosing intoxication cases for\n10 different toxins from the PCC in Munich and show our method's superiority in\nperformance for poison prediction.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 14:20:32 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Burwinkel", "Hendrik", ""], ["Keicher", "Matthias", ""], ["Bani-Harouni", "David", ""], ["Zellner", "Tobias", ""], ["Eyer", "Florian", ""], ["Navab", "Nassir", ""], ["Ahmadi", "Seyed-Ahmad", ""]]}, {"id": "2005.00845", "submitter": "Pierre G. B. Moutounet-Cartan", "authors": "Pierre G. B. Moutounet-Cartan", "title": "Deep Convolutional Neural Networks to Diagnose COVID-19 and other\n  Pneumonia Diseases from Posteroanterior Chest X-Rays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The article explores different deep convolutional neural network\narchitectures trained and tested on posteroanterior chest X-rays of 327\npatients who are healthy (152 patients), diagnosed with COVID-19 (125), and\nother types of pneumonia (48). In particular, this paper looks at the deep\nconvolutional neural networks VGG16 and VGG19, InceptionResNetV2 and\nInceptionV3, as well as Xception, all followed by a flat multi-layer perceptron\nand a final 30% drop-out. The paper has found that the best performing network\nis VGG16 with a final $30$% drop-out trained over 3 classes (COVID-19, No\nFinding, Other Pneumonia). It has an internal cross-validated accuracy of\n$93.9(\\pm3.4)$%, a COVID-19 sensitivity of $87.7(-1.9,+2)$%, and a No Finding\nsensitivity of $96.8(\\pm0.8)$%. The respective external cross-validated values\nare $84.1(\\pm13.5)$%, $87.7(-1.9,2)$%, and $96.8(\\pm0.8)$%. The model optimizer\nwas Adam with a 1e-4 learning rate, and categorical cross-entropy loss. It is\nhoped that, once this research will be put to practice in hospitals, healthcare\nprofessionals will be able in the medium to long-term to diagnosing through\nmachine learning tools possible pneumonia, and if detected, whether it is\nlinked to a COVID-19 infection, allowing the detection of new possible COVID-19\nfoyers after the end of possible \"stop-and-go\" lockdowns as expected by until a\nvaccine is found and widespread. Furthermore, in the short-term, it is hoped\npractitioners can compare the diagnosis from the deep convolutional neural\nnetworks with possible RT-PCR testing results, and if clashing, a Computed\nTomography could be performed as they are more accurate in showing COVID-19\npneumonia.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 14:42:50 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Moutounet-Cartan", "Pierre G. B.", ""]]}, {"id": "2005.00850", "submitter": "Lifu Tu", "authors": "Lifu Tu, Richard Yuanzhe Pang, Sam Wiseman, Kevin Gimpel", "title": "ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine\n  Translation", "comments": "ACL 2020 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose to train a non-autoregressive machine translation model to\nminimize the energy defined by a pretrained autoregressive model. In\nparticular, we view our non-autoregressive translation system as an inference\nnetwork (Tu and Gimpel, 2018) trained to minimize the autoregressive teacher\nenergy. This contrasts with the popular approach of training a\nnon-autoregressive model on a distilled corpus consisting of the beam-searched\noutputs of such a teacher model. Our approach, which we call ENGINE\n(ENerGy-based Inference NEtworks), achieves state-of-the-art non-autoregressive\nresults on the IWSLT 2014 DE-EN and WMT 2016 RO-EN datasets, approaching the\nperformance of autoregressive models.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 15:06:47 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 20:44:24 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Tu", "Lifu", ""], ["Pang", "Richard Yuanzhe", ""], ["Wiseman", "Sam", ""], ["Gimpel", "Kevin", ""]]}, {"id": "2005.00856", "submitter": "Wentao Xu", "authors": "Wentao Xu, Shun Zheng, Liang He, Bin Shao, Jian Yin, Tie-Yan Liu", "title": "SEEK: Segmented Embedding of Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, knowledge graph embedding becomes a pretty hot research\ntopic of artificial intelligence and plays increasingly vital roles in various\ndownstream applications, such as recommendation and question answering.\nHowever, existing methods for knowledge graph embedding can not make a proper\ntrade-off between the model complexity and the model expressiveness, which\nmakes them still far from satisfactory. To mitigate this problem, we propose a\nlightweight modeling framework that can achieve highly competitive relational\nexpressiveness without increasing the model complexity. Our framework focuses\non the design of scoring functions and highlights two critical characteristics:\n1) facilitating sufficient feature interactions; 2) preserving both symmetry\nand antisymmetry properties of relations. It is noteworthy that owing to the\ngeneral and elegant design of scoring functions, our framework can incorporate\nmany famous existing methods as special cases. Moreover, extensive experiments\non public benchmarks demonstrate the efficiency and effectiveness of our\nframework. Source codes and data can be found at\n\\url{https://github.com/Wentao-Xu/SEEK}.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 15:15:50 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 10:51:55 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 03:27:31 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Xu", "Wentao", ""], ["Zheng", "Shun", ""], ["He", "Liang", ""], ["Shao", "Bin", ""], ["Yin", "Jian", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2005.00865", "submitter": "Teven Le Scao", "authors": "Teven Le Scao", "title": "Neural Differential Equations for Single Image Super-resolution", "comments": "7 pages, 5 figures, ICLR 2020 Workshop on Integration of Deep Neural\n  Models and Differential Equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although Neural Differential Equations have shown promise on toy problems\nsuch as MNIST, they have yet to be successfully applied to more challenging\ntasks. Inspired by variational methods for image restoration relying on partial\ndifferential equations, we choose to benchmark several forms of Neural DEs and\nbackpropagation methods on single image super-resolution. The adjoint method\npreviously proposed for gradient estimation has no theoretical stability\nguarantees; we find a practical case where this makes it unusable, and show\nthat discrete sensitivity analysis has better stability. In our experiments,\ndifferential models match the performance of a state-of-the art\nsuper-resolution model.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 15:46:45 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Scao", "Teven Le", ""]]}, {"id": "2005.00866", "submitter": "Venkata Duvvuri", "authors": "Venkata Duvvuri", "title": "Minerva: A Portable Machine Learning Microservice Framework for\n  Traditional Enterprise SaaS Applications", "comments": null, "journal-ref": "Proceedings of Computer Science & Information Technology (CS &\n  IT), 2020", "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In traditional SaaS enterprise applications, microservices are an essential\ningredient to deploy machine learning (ML) models successfully. In general,\nmicroservices result in efficiencies in software service design, development,\nand delivery. As they become ubiquitous in the redesign of monolithic software,\nwith the addition of machine learning, the traditional applications are also\nbecoming increasingly intelligent. Here, we propose a portable ML microservice\nframework Minerva (microservices container for applied ML) as an efficient way\nto modularize and deploy intelligent microservices in traditional legacy SaaS\napplications suite, especially in the enterprise domain. We identify and\ndiscuss the needs, challenges and architecture to incorporate ML microservices\nin such applications. Minervas design for optimal integration with legacy\napplications using microservices architecture leveraging lightweight\ninfrastructure accelerates deploying ML models in such applications.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 15:53:33 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Duvvuri", "Venkata", ""]]}, {"id": "2005.00872", "submitter": "J\\'anos V\\'egh", "authors": "J\\'anos V\\'egh", "title": "How deep the machine learning can be", "comments": "29 pages, 8 figures; submitted to book 'A closer look at deep\n  learning' by Nova", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Today we live in the age of artificial intelligence and machine learning;\nfrom small startups to HW or SW giants, everyone wants to build machine\nintelligence chips, applications. The task, however, is hard: not only because\nof the size of the problem: the technology one can utilize (and the paradigm it\nis based upon) strongly degrades the chances to succeed efficiently. Today the\nsingle-processor performance practically reached the limits the laws of nature\nenable. The only feasible way to achieve the needed high computing performance\nseems to be parallelizing many sequentially working units. The laws of the\n(massively) parallelized computing, however, are different from those\nexperienced in connection with assembling and utilizing systems comprising\njust-a-few single processors. As machine learning is mostly based on the\nconventional computing (processors), we scrutinize the (known, but somewhat\nfaded) laws of the parallel computing, concerning AI. This paper attempts to\nreview some of the caveats, especially concerning scaling the computing\nperformance of the AI solutions.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 16:06:31 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["V\u00e9gh", "J\u00e1nos", ""]]}, {"id": "2005.00878", "submitter": "Eduardo Fonseca", "authors": "Eduardo Fonseca, Shawn Hershey, Manoj Plakal, Daniel P. W. Ellis, Aren\n  Jansen, R. Channing Moore, Xavier Serra", "title": "Addressing Missing Labels in Large-Scale Sound Event Recognition Using a\n  Teacher-Student Framework With Loss Masking", "comments": "Accepted in IEEE Signal Processing Letters, openly accessible at\n  https://ieeexplore.ieee.org/document/9130823", "journal-ref": "IEEE Signal Processing Letters, Vol. 27, 2020, pages 1235-1239", "doi": "10.1109/LSP.2020.3006378", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The study of label noise in sound event recognition has recently gained\nattention with the advent of larger and noisier datasets. This work addresses\nthe problem of missing labels, one of the big weaknesses of large audio\ndatasets, and one of the most conspicuous issues for AudioSet. We propose a\nsimple and model-agnostic method based on a teacher-student framework with loss\nmasking to first identify the most critical missing label candidates, and then\nignore their contribution during the learning process. We find that a simple\noptimisation of the training label set improves recognition performance without\nadditional computation. We discover that most of the improvement comes from\nignoring a critical tiny portion of the missing labels. We also show that the\ndamage done by missing labels is larger as the training set gets smaller, yet\nit can still be observed even when training with massive amounts of audio. We\nbelieve these insights can generalize to other large-scale datasets.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 16:21:20 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 14:50:11 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Fonseca", "Eduardo", ""], ["Hershey", "Shawn", ""], ["Plakal", "Manoj", ""], ["Ellis", "Daniel P. W.", ""], ["Jansen", "Aren", ""], ["Moore", "R. Channing", ""], ["Serra", "Xavier", ""]]}, {"id": "2005.00879", "submitter": "Ryosuke Kuwabara", "authors": "Ryosuke Kuwabara, Jun Suzuki, Hideki Nakayama", "title": "Single Model Ensemble using Pseudo-Tags and Distinct Vectors", "comments": "Accepted by ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model ensemble techniques often increase task performance in neural networks;\nhowever, they require increased time, memory, and management effort. In this\nstudy, we propose a novel method that replicates the effects of a model\nensemble with a single model. Our approach creates K-virtual models within a\nsingle parameter space using K-distinct pseudo-tags and K-distinct vectors.\nExperiments on text classification and sequence labeling tasks on several\ndatasets demonstrate that our method emulates or outperforms a traditional\nmodel ensemble with 1/K-times fewer parameters.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 16:23:47 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Kuwabara", "Ryosuke", ""], ["Suzuki", "Jun", ""], ["Nakayama", "Hideki", ""]]}, {"id": "2005.00887", "submitter": "Leopoldo Lusquino Filho", "authors": "Aluizio S. Lima Filho and Gabriel P. Guarisa and Leopoldo A. D.\n  Lusquino Filho and Luiz F. R. Oliveira and Felipe M. G. Franca and Priscila\n  M. V. Lima", "title": "wisardpkg -- A library for WiSARD-based models", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In order to facilitate the production of codes using WiSARD-based models,\nLabZero developed an ML library C++/Python called wisardpkg. This library is an\nMIT-licensed open-source package hosted on GitHub under the license.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 17:03:40 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Filho", "Aluizio S. Lima", ""], ["Guarisa", "Gabriel P.", ""], ["Filho", "Leopoldo A. D. Lusquino", ""], ["Oliveira", "Luiz F. R.", ""], ["Franca", "Felipe M. G.", ""], ["Lima", "Priscila M. V.", ""]]}, {"id": "2005.00904", "submitter": "Mark Law", "authors": "Mark Law, Alessandra Russo, Krysia Broda", "title": "The ILASP system for Inductive Learning of Answer Set Programs", "comments": "Submitted to the ALP newsletter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of Inductive Logic Programming (ILP) is to learn a program that\nexplains a set of examples in the context of some pre-existing background\nknowledge. Until recently, most research on ILP targeted learning Prolog\nprograms. Our own ILASP system instead learns Answer Set Programs, including\nnormal rules, choice rules and hard and weak constraints. Learning such\nexpressive programs widens the applicability of ILP considerably; for example,\nenabling preference learning, learning common-sense knowledge, including\ndefaults and exceptions, and learning non-deterministic theories. In this\npaper, we first give a general overview of ILASP's learning framework and its\ncapabilities. This is followed by a comprehensive summary of the evolution of\nthe ILASP system, presenting the strengths and weaknesses of each version, with\na particular emphasis on scalability.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 19:04:12 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Law", "Mark", ""], ["Russo", "Alessandra", ""], ["Broda", "Krysia", ""]]}, {"id": "2005.00923", "submitter": "Hossein Pourmeidani", "authors": "Hossein Pourmeidani, Punyashloka Debashis, Zhihong Chen, Ronald F.\n  DeMara, and Ramtin Zand", "title": "Electrically-Tunable Stochasticity for Spin-based Neuromorphic Circuits:\n  Self-Adjusting to Variation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy-efficient methods are addressed for leveraging low energy barrier\nnanomagnetic devices within neuromorphic architectures. Using a\nMagnetoresistive Random Access Memory (MRAM) probabilistic device (p-bit) as\nthe basis of neuronal structures in Deep Belief Networks (DBNs), the impact of\nreducing the Magnetic Tunnel Junction's (MTJ's) energy barrier is assessed and\noptimized for the resulting stochasticity present in the learning system. This\ncan mitigate the process variation sensitivity of stochastic DBNs which\nencounter a sharp drop-off when energy barriers exceed near-zero kT. As\nevaluated for the MNIST dataset for energy barriers at near-zero kT to 2.0 kT\nin increments of 0.5 kT, it is shown that the stability factor changes by 5\norders of magnitude. The self-compensating circuit developed herein provides a\ncompact, and low complexity approach to mitigating process variation impacts\ntowards practical implementation and fabrication.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 21:26:10 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Pourmeidani", "Hossein", ""], ["Debashis", "Punyashloka", ""], ["Chen", "Zhihong", ""], ["DeMara", "Ronald F.", ""], ["Zand", "Ramtin", ""]]}, {"id": "2005.00928", "submitter": "Samira Abnar", "authors": "Samira Abnar and Willem Zuidema", "title": "Quantifying Attention Flow in Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Transformer model, \"self-attention\" combines information from attended\nembeddings into the representation of the focal embedding in the next layer.\nThus, across layers of the Transformer, information originating from different\ntokens gets increasingly mixed. This makes attention weights unreliable as\nexplanations probes. In this paper, we consider the problem of quantifying this\nflow of information through self-attention. We propose two methods for\napproximating the attention to input tokens given attention weights, attention\nrollout and attention flow, as post hoc methods when we use attention weights\nas the relative relevance of the input tokens. We show that these methods give\ncomplementary views on the flow of information, and compared to raw attention,\nboth yield higher correlations with importance scores of input tokens obtained\nusing an ablation method and input gradients.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 21:45:27 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 16:59:40 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Abnar", "Samira", ""], ["Zuidema", "Willem", ""]]}, {"id": "2005.00932", "submitter": "Jiawei Zhou", "authors": "Jiawei Zhou, Phillip Keung", "title": "Improving Non-autoregressive Neural Machine Translation with Monolingual\n  Data", "comments": "Published in ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-autoregressive (NAR) neural machine translation is usually done via\nknowledge distillation from an autoregressive (AR) model. Under this framework,\nwe leverage large monolingual corpora to improve the NAR model's performance,\nwith the goal of transferring the AR model's generalization ability while\npreventing overfitting. On top of a strong NAR baseline, our experimental\nresults on the WMT14 En-De and WMT16 En-Ro news translation tasks confirm that\nmonolingual data augmentation consistently improves the performance of the NAR\nmodel to approach the teacher AR model's performance, yields comparable or\nbetter results than the best non-iterative NAR methods in the literature and\nhelps reduce overfitting in the training process.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 22:24:52 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 03:50:58 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 21:48:51 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Zhou", "Jiawei", ""], ["Keung", "Phillip", ""]]}, {"id": "2005.00935", "submitter": "Yasin Yilmaz", "authors": "Ammar Haydari, Yasin Yilmaz", "title": "Deep Reinforcement Learning for Intelligent Transportation Systems: A\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.SY eess.SP eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latest technological improvements increased the quality of transportation.\nNew data-driven approaches bring out a new research direction for all\ncontrol-based systems, e.g., in transportation, robotics, IoT and power\nsystems. Combining data-driven applications with transportation systems plays a\nkey role in recent transportation applications. In this paper, the latest deep\nreinforcement learning (RL) based traffic control applications are surveyed.\nSpecifically, traffic signal control (TSC) applications based on (deep) RL,\nwhich have been studied extensively in the literature, are discussed in detail.\nDifferent problem formulations, RL parameters, and simulation environments for\nTSC are discussed comprehensively. In the literature, there are also several\nautonomous driving applications studied with deep RL models. Our survey\nextensively summarizes existing works in this field by categorizing them with\nrespect to application types, control models and studied algorithms. In the\nend, we discuss the challenges and open questions regarding deep RL-based\ntransportation applications.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 22:44:50 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Haydari", "Ammar", ""], ["Yilmaz", "Yasin", ""]]}, {"id": "2005.00944", "submitter": "Hongyang Zhang", "authors": "Sen Wu, Hongyang R. Zhang, Christopher R\\'e", "title": "Understanding and Improving Information Transfer in Multi-Task Learning", "comments": "Appeared in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate multi-task learning approaches that use a shared feature\nrepresentation for all tasks. To better understand the transfer of task\ninformation, we study an architecture with a shared module for all tasks and a\nseparate output module for each task. We study the theory of this setting on\nlinear and ReLU-activated models. Our key observation is that whether or not\ntasks' data are well-aligned can significantly affect the performance of\nmulti-task learning. We show that misalignment between task data can cause\nnegative transfer (or hurt performance) and provide sufficient conditions for\npositive transfer. Inspired by the theoretical insights, we show that aligning\ntasks' embedding layers leads to performance gains for multi-task training and\ntransfer learning on the GLUE benchmark and sentiment analysis tasks; for\nexample, we obtain a 2.35% GLUE score average improvement on 5 GLUE tasks over\nBERT-LARGE using our alignment method. We also design an SVD-based task\nreweighting scheme and show that it improves the robustness of multi-task\ntraining on a multi-label image dataset.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 23:43:52 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wu", "Sen", ""], ["Zhang", "Hongyang R.", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2005.00947", "submitter": "Rui Sun", "authors": "David Simchi-Levi, Rui Sun, Huanan Zhang", "title": "Online Learning and Optimization for Revenue Management Problems with\n  Add-on Discounts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study in this paper a revenue management problem with add-on discounts.\nThe problem is motivated by the practice in the video game industry, where a\nretailer offers discounts on selected supportive products (e.g. video games) to\ncustomers who have also purchased the core products (e.g. video game consoles).\nWe formulate this problem as an optimization problem to determine the prices of\ndifferent products and the selection of products with add-on discounts. To\novercome the computational challenge of this optimization problem, we propose\nan efficient FPTAS algorithm that can solve the problem approximately to any\ndesired accuracy. Moreover, we consider the revenue management problem in the\nsetting where the retailer has no prior knowledge of the demand functions of\ndifferent products. To resolve this problem, we propose a UCB-based learning\nalgorithm that uses the FPTAS optimization algorithm as a subroutine. We show\nthat our learning algorithm can converge to the optimal algorithm that has\naccess to the true demand functions, and we prove that the convergence rate is\ntight up to a certain logarithmic term. In addition, we conduct numerical\nexperiments with the real-world transaction data we collect from a popular\nvideo gaming brand's online store on Tmall.com. The experiment results\nillustrate our learning algorithm's robust performance and fast convergence in\nvarious scenarios. We also compare our algorithm with the optimal policy that\ndoes not use any add-on discount, and the results show the advantages of using\nthe add-on discount strategy in practice.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 23:54:17 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Simchi-Levi", "David", ""], ["Sun", "Rui", ""], ["Zhang", "Huanan", ""]]}, {"id": "2005.00959", "submitter": "Tom Tirer", "authors": "Tom Tirer, Raja Giryes", "title": "On the Convergence Rate of Projected Gradient Descent for a\n  Back-Projection based Objective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ill-posed linear inverse problems appear in many scientific setups, and are\ntypically addressed by solving optimization problems, which are composed of\ndata fidelity and prior terms. Recently, several works have considered a\nback-projection (BP) based fidelity term as an alternative to the common least\nsquares (LS), and demonstrated excellent results for popular inverse problems.\nThese works have also empirically shown that using the BP term, rather than the\nLS term, requires fewer iterations of optimization algorithms. In this paper,\nwe examine the convergence rate of the projected gradient descent (PGD)\nalgorithm for the BP objective. Our analysis allows to identify an inherent\nsource for its faster convergence compared to using the LS objective, while\nmaking only mild assumptions. We also analyze the more general proximal\ngradient method under a relaxed contraction condition on the proximal mapping\nof the prior. This analysis further highlights the advantage of BP when the\nlinear measurement operator is badly conditioned. Numerical experiments with\nboth $\\ell_1$-norm and GAN-based priors corroborate our theoretical results.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 00:58:23 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 18:04:47 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Tirer", "Tom", ""], ["Giryes", "Raja", ""]]}, {"id": "2005.00961", "submitter": "Hiroyuki Kido", "authors": "Hiroyuki Kido", "title": "Bayesian Entailment Hypothesis: How Brains Implement Monotonic and\n  Non-monotonic Reasoning", "comments": "This paper was submitted to IJCAI 2020 and rejected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent success of Bayesian methods in neuroscience and artificial\nintelligence gives rise to the hypothesis that the brain is a Bayesian machine.\nSince logic, as the laws of thought, is a product and practice of the human\nbrain, it leads to another hypothesis that there is a Bayesian algorithm and\ndata-structure for logical reasoning. In this paper, we give a Bayesian account\nof entailment and characterize its abstract inferential properties. The\nBayesian entailment is shown to be a monotonic consequence relation in an\nextreme case. In general, it is a sort of non-monotonic consequence relation\nwithout Cautious monotony or Cut. The preferential entailment, which is a\nrepresentative non-monotonic consequence relation, is shown to be maximum a\nposteriori entailment, which is an approximation of the Bayesian entailment. We\nfinally discuss merits of our proposals in terms of encoding preferences on\ndefaults, handling change and contradiction, and modeling human entailment.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 01:26:02 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 09:04:54 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 18:00:03 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Kido", "Hiroyuki", ""]]}, {"id": "2005.00965", "submitter": "Tianlu Wang", "authors": "Tianlu Wang, Xi Victoria Lin, Nazneen Fatema Rajani, Bryan McCann,\n  Vicente Ordonez, Caiming Xiong", "title": "Double-Hard Debias: Tailoring Word Embeddings for Gender Bias Mitigation", "comments": "Accepted to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings derived from human-generated corpora inherit strong gender\nbias which can be further amplified by downstream models. Some commonly adopted\ndebiasing approaches, including the seminal Hard Debias algorithm, apply\npost-processing procedures that project pre-trained word embeddings into a\nsubspace orthogonal to an inferred gender subspace. We discover that\nsemantic-agnostic corpus regularities such as word frequency captured by the\nword embeddings negatively impact the performance of these algorithms. We\npropose a simple but effective technique, Double Hard Debias, which purifies\nthe word embeddings against such corpus regularities prior to inferring and\nremoving the gender subspace. Experiments on three bias mitigation benchmarks\nshow that our approach preserves the distributional semantics of the\npre-trained word embeddings while reducing gender bias to a significantly\nlarger degree than prior approaches.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 02:33:20 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wang", "Tianlu", ""], ["Lin", "Xi Victoria", ""], ["Rajani", "Nazneen Fatema", ""], ["McCann", "Bryan", ""], ["Ordonez", "Vicente", ""], ["Xiong", "Caiming", ""]]}, {"id": "2005.00976", "submitter": "Xiang Li", "authors": "Xiang Li and Songcan Chen", "title": "A Concise yet Effective model for Non-Aligned Incomplete Multi-view and\n  Missing Multi-label Learning", "comments": "15 pages, 7 figures", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence\n  2021", "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reality, learning from multi-view multi-label data inevitably confronts\nthree challenges: missing labels, incomplete views, and non-aligned views.\nExisting methods mainly concern the first two and commonly need multiple\nassumptions to attack them, making even state-of-the-arts involve at least two\nexplicit hyper-parameters such that model selection is quite difficult. More\nroughly, they will fail in handling the third challenge, let alone addressing\nthe three jointly. In this paper, we aim at meeting these under the least\nassumption by building a concise yet effective model with just one\nhyper-parameter. To ease insufficiency of available labels, we exploit not only\nthe consensus of multiple views but also the global and local structures hidden\namong multiple labels. Specifically, we introduce an indicator matrix to tackle\nthe first two challenges in a regression form while aligning the same\nindividual labels and all labels of different views in a common label space to\nbattle the third challenge. In aligning, we characterize the global and local\nstructures of multiple labels to be high-rank and low-rank, respectively.\nSubsequently, an efficient algorithm with linear time complexity in the number\nof samples is established. Finally, even without view-alignment, our method\nsubstantially outperforms state-of-the-arts with view-alignment on five real\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 03:38:24 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 12:01:24 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Li", "Xiang", ""], ["Chen", "Songcan", ""]]}, {"id": "2005.00979", "submitter": "Xinwei Geng", "authors": "Xinwei Geng, Longyue Wang, Xing Wang, Bing Qin, Ting Liu, Zhaopeng Tu", "title": "How Does Selective Mechanism Improve Self-Attention Networks?", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention networks (SANs) with selective mechanism has produced\nsubstantial improvements in various NLP tasks by concentrating on a subset of\ninput words. However, the underlying reasons for their strong performance have\nnot been well explained. In this paper, we bridge the gap by assessing the\nstrengths of selective SANs (SSANs), which are implemented with a flexible and\nuniversal Gumbel-Softmax. Experimental results on several representative NLP\ntasks, including natural language inference, semantic role labelling, and\nmachine translation, show that SSANs consistently outperform the standard SANs.\nThrough well-designed probing experiments, we empirically validate that the\nimprovement of SSANs can be attributed in part to mitigating two commonly-cited\nweaknesses of SANs: word order encoding and structure modeling. Specifically,\nthe selective mechanism improves SANs by paying more attention to content words\nthat contribute to the meaning of the sentence. The code and data are released\nat https://github.com/xwgeng/SSAN.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 04:18:44 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Geng", "Xinwei", ""], ["Wang", "Longyue", ""], ["Wang", "Xing", ""], ["Qin", "Bing", ""], ["Liu", "Ting", ""], ["Tu", "Zhaopeng", ""]]}, {"id": "2005.00992", "submitter": "Kohei Nakajima", "authors": "Kohei Nakajima", "title": "Physical reservoir computing -- An introductory perspective", "comments": "18 pages, 8 figures", "journal-ref": null, "doi": "10.35848/1347-4065/ab8d4f", "report-no": null, "categories": "nlin.AO cs.LG physics.app-ph quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the fundamental relationships between physics and its\ninformation-processing capability has been an active research topic for many\nyears. Physical reservoir computing is a recently introduced framework that\nallows one to exploit the complex dynamics of physical systems as\ninformation-processing devices. This framework is particularly suited for edge\ncomputing devices, in which information processing is incorporated at the edge\n(e.g., into sensors) in a decentralized manner to reduce the adaptation delay\ncaused by data transmission overhead. This paper aims to illustrate the\npotentials of the framework using examples from soft robotics and to provide a\nconcise overview focusing on the basic motivations for introducing it, which\nstem from a number of fields, including machine learning, nonlinear dynamical\nsystems, biological science, materials science, and physics.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 05:39:06 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Nakajima", "Kohei", ""]]}, {"id": "2005.01004", "submitter": "Giang Nguyen", "authors": "Giang Nguyen, Shuan Chen, Tae Joon Jun, Daeyoung Kim", "title": "Explaining How Deep Neural Networks Forget by Deep Visualization", "comments": "12 pages, 4 figures, 1 table. arXiv admin note: substantial text\n  overlap with arXiv:2001.01578", "journal-ref": "ICPR 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explaining the behaviors of deep neural networks, usually considered as black\nboxes, is critical especially when they are now being adopted over diverse\naspects of human life. Taking the advantages of interpretable machine learning\n(interpretable ML), this paper proposes a novel tool called Catastrophic\nForgetting Dissector (or CFD) to explain catastrophic forgetting in continual\nlearning settings. We also introduce a new method called Critical Freezing\nbased on the observations of our tool. Experiments on ResNet articulate how\ncatastrophic forgetting happens, particularly showing which components of this\nfamous network are forgetting. Our new continual learning algorithm defeats\nvarious recent techniques by a significant margin, proving the capability of\nthe investigation. Critical freezing not only attacks catastrophic forgetting\nbut also exposes explainability.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 06:44:38 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 04:13:58 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Nguyen", "Giang", ""], ["Chen", "Shuan", ""], ["Jun", "Tae Joon", ""], ["Kim", "Daeyoung", ""]]}, {"id": "2005.01006", "submitter": "Jiandong Zhang", "authors": "Wei Bao, Hongshu Che, Jiandong Zhang", "title": "An Accurate Model for Predicting the (Graded) Effect of Context in Word\n  Similarity Based on Bert", "comments": "ACL-SemEval 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Natural Language Processing (NLP) has been widely used in the semantic\nanalysis in recent years. Our paper mainly discusses a methodology to analyze\nthe effect that context has on human perception of similar words, which is the\nthird task of SemEval 2020. We apply several methods in calculating the\ndistance between two embedding vector generated by Bidirectional Encoder\nRepresentation from Transformer (BERT). Our team will_go won the 1st place in\nFinnish language track of subtask1, the second place in English track of\nsubtask1.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 06:48:35 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 16:02:46 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 03:03:51 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Bao", "Wei", ""], ["Che", "Hongshu", ""], ["Zhang", "Jiandong", ""]]}, {"id": "2005.01026", "submitter": "Guodong Long Dr", "authors": "Ming Xie, Guodong Long, Tao Shen, Tianyi Zhou, Xianzhi Wang, Jing\n  Jiang", "title": "Multi-Center Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has received great attention for its capability to train a\nlarge-scale model in a decentralized manner without needing to access user data\ndirectly. It helps protect the users' private data from centralized collecting.\nUnlike distributed machine learning, federated learning aims to tackle non-IID\ndata from heterogeneous sources in various real-world applications, such as\nthose on smartphones. Existing federated learning approaches usually adopt a\nsingle global model to capture the shared knowledge of all users by aggregating\ntheir gradients, regardless of the discrepancy between their data\ndistributions. However, due to the diverse nature of user behaviors, assigning\nusers' gradients to different global models (i.e., centers) can better capture\nthe heterogeneity of data distributions across users. Our paper proposes a\nnovel multi-center aggregation mechanism for federated learning, which learns\nmultiple global models from the non-IID user data and simultaneously derives\nthe optimal matching between users and centers. We formulate the problem as a\njoint optimization that can be efficiently solved by a stochastic expectation\nmaximization (EM) algorithm. Our experimental results on benchmark datasets\nshow that our method outperforms several popular federated learning methods.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 09:14:31 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Xie", "Ming", ""], ["Long", "Guodong", ""], ["Shen", "Tao", ""], ["Zhou", "Tianyi", ""], ["Wang", "Xianzhi", ""], ["Jiang", "Jing", ""]]}, {"id": "2005.01075", "submitter": "Wouter Verbeke", "authors": "Sam Verboven, Jeroen Berrevoets, Chris Wuytens, Bart Baesens, Wouter\n  Verbeke", "title": "Autoencoders for strategic decision support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the majority of executive domains, a notion of normality is involved in\nmost strategic decisions. However, few data-driven tools that support strategic\ndecision-making are available. We introduce and extend the use of autoencoders\nto provide strategically relevant granular feedback. A first experiment\nindicates that experts are inconsistent in their decision making, highlighting\nthe need for strategic decision support. Furthermore, using two large\nindustry-provided human resources datasets, the proposed solution is evaluated\nin terms of ranking accuracy, synergy with human experts, and dimension-level\nfeedback. This three-point scheme is validated using (a) synthetic data, (b)\nthe perspective of data quality, (c) blind expert validation, and (d)\ntransparent expert evaluation. Our study confirms several principal weaknesses\nof human decision-making and stresses the importance of synergy between a model\nand humans. Moreover, unsupervised learning and in particular the autoencoder\nare shown to be valuable tools for strategic decision-making.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 12:54:06 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Verboven", "Sam", ""], ["Berrevoets", "Jeroen", ""], ["Wuytens", "Chris", ""], ["Baesens", "Bart", ""], ["Verbeke", "Wouter", ""]]}, {"id": "2005.01090", "submitter": "Redouane Lguensat", "authors": "Redouane Lguensat, Ronan Fablet, Julien Le Sommer, Sammy Metref,\n  Emmanuel Cosme, Kaouther Ouenniche, Lucas Drumetz, Jonathan Gula", "title": "Filtering Internal Tides From Wide-Swath Altimeter Data Using\n  Convolutional Neural Networks", "comments": "Accepted for publication in IEEE IGARSS 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG eess.IV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The upcoming Surface Water Ocean Topography (SWOT) satellite altimetry\nmission is expected to yield two-dimensional high-resolution measurements of\nSea Surface Height (SSH), thus allowing for a better characterization of the\nmesoscale and submesoscale eddy field. However, to fulfill the promises of this\nmission, filtering the tidal component of the SSH measurements is necessary.\nThis challenging problem is crucial since the posterior studies done by\nphysical oceanographers using SWOT data will depend heavily on the selected\nfiltering schemes. In this paper, we cast this problem into a supervised\nlearning framework and propose the use of convolutional neural networks\n(ConvNets) to estimate fields free of internal tide signals. Numerical\nexperiments based on an advanced North Atlantic simulation of the ocean\ncirculation (eNATL60) show that our ConvNet considerably reduces the imprint of\nthe internal waves in SSH data even in regions unseen by the neural network. We\nalso investigate the relevance of considering additional data from other sea\nsurface variables such as sea surface temperature (SST).\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 14:02:31 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Lguensat", "Redouane", ""], ["Fablet", "Ronan", ""], ["Sommer", "Julien Le", ""], ["Metref", "Sammy", ""], ["Cosme", "Emmanuel", ""], ["Ouenniche", "Kaouther", ""], ["Drumetz", "Lucas", ""], ["Gula", "Jonathan", ""]]}, {"id": "2005.01095", "submitter": "Cheng Zhang", "authors": "Cheng Zhang, Kun Zhang, Yingzhen Li", "title": "A Causal View on Robustness of Neural Networks", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a causal view on the robustness of neural networks against input\nmanipulations, which applies not only to traditional classification tasks but\nalso to general measurement data. Based on this view, we design a deep causal\nmanipulation augmented model (deep CAMA) which explicitly models possible\nmanipulations on certain causes leading to changes in the observed effect. We\nfurther develop data augmentation and test-time fine-tuning methods to improve\ndeep CAMA's robustness. When compared with discriminative deep neural networks,\nour proposed model shows superior robustness against unseen manipulations. As a\nby-product, our model achieves disentangled representation which separates the\nrepresentation of manipulations from those of other latent causes.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 14:20:05 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 21:12:11 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 16:36:42 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Zhang", "Cheng", ""], ["Zhang", "Kun", ""], ["Li", "Yingzhen", ""]]}, {"id": "2005.01096", "submitter": "Ernie Chang", "authors": "Xiaoyu Shen, Ernie Chang, Hui Su, Jie Zhou, Dietrich Klakow", "title": "Neural Data-to-Text Generation via Jointly Learning the Segmentation and\n  Correspondence", "comments": "Accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neural attention model has achieved great success in data-to-text\ngeneration tasks. Though usually excelling at producing fluent text, it suffers\nfrom the problem of information missing, repetition and \"hallucination\". Due to\nthe black-box nature of the neural attention architecture, avoiding these\nproblems in a systematic way is non-trivial. To address this concern, we\npropose to explicitly segment target text into fragment units and align them\nwith their data correspondences. The segmentation and correspondence are\njointly learned as latent variables without any human annotations. We further\nimpose a soft statistical constraint to regularize the segmental granularity.\nThe resulting architecture maintains the same expressive power as neural\nattention models, while being able to generate fully interpretable outputs with\nseveral times less computational cost. On both E2E and WebNLG benchmarks, we\nshow the proposed model consistently outperforms its neural attention\ncounterparts.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 14:28:28 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Shen", "Xiaoyu", ""], ["Chang", "Ernie", ""], ["Su", "Hui", ""], ["Zhou", "Jie", ""], ["Klakow", "Dietrich", ""]]}, {"id": "2005.01097", "submitter": "Motasem Alfarra Alfarra M", "authors": "Motasem Alfarra, Slavomir Hanzely, Alyazeed Albasyoni, Bernard Ghanem\n  and Peter Richtarik", "title": "Adaptive Learning of the Optimal Mini-Batch Size of SGD", "comments": "17 pages, 45 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in the theoretical understandingof SGD (Qian et al., 2019)\nled to a formula for the optimal mini-batch size minimizing the number of\neffective data passes, i.e., the number of iterations times the mini-batch\nsize. However, this formula is of no practical value as it depends on the\nknowledge of the variance of the stochastic gradients evaluated at the optimum.\nIn this paper we design a practical SGD method capable of learning the optimal\nmini-batch size adaptively throughout its iterations. Our method does this\nprovably, and in our experiments with synthetic and real data robustly exhibits\nnearly optimal behaviour; that is, it works as if the optimal mini-batch size\nwas known a-priori. Further, we generalize our method to several new mini-batch\nstrategies not considered in the literature before, including a sampling\nsuitable for distributed implementations.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 14:28:32 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Alfarra", "Motasem", ""], ["Hanzely", "Slavomir", ""], ["Albasyoni", "Alyazeed", ""], ["Ghanem", "Bernard", ""], ["Richtarik", "Peter", ""]]}, {"id": "2005.01117", "submitter": "Kshitija Taywade", "authors": "Kshitija Taywade, Judy Goldsmith, Brent Harrison", "title": "Multi-agent Reinforcement Learning for Decentralized Stable Matching", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the real world, people/entities usually find matches independently and\nautonomously, such as finding jobs, partners, roommates, etc. It is possible\nthat this search for matches starts with no initial knowledge of the\nenvironment. We propose the use of a multi-agent reinforcement learning (MARL)\nparadigm for a spatially formulated decentralized two-sided matching market\nwith independent and autonomous agents. Having autonomous agents acting\nindependently makes our environment very dynamic and uncertain. Moreover,\nagents lack the knowledge of preferences of other agents and have to explore\nthe environment and interact with other agents to discover their own\npreferences through noisy rewards. We think such a setting better approximates\nthe real world and we study the usefulness of our MARL approach for it. Along\nwith conventional stable matching case where agents have strictly ordered\npreferences, we check the applicability of our approach for stable matching\nwith incomplete lists and ties. We investigate our results for stability, level\nof instability (for unstable results), and fairness. Our MARL approach mostly\nyields stable and fair outcomes.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 15:28:41 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 00:21:07 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Taywade", "Kshitija", ""], ["Goldsmith", "Judy", ""], ["Harrison", "Brent", ""]]}, {"id": "2005.01123", "submitter": "Liangjian Wen PhD.", "authors": "Liangjian Wen, Yiji Zhou, Lirong He, Mingyuan Zhou, Zenglin Xu", "title": "Mutual Information Gradient Estimation for Representation Learning", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutual Information (MI) plays an important role in representation learning.\nHowever, MI is unfortunately intractable in continuous and high-dimensional\nsettings. Recent advances establish tractable and scalable MI estimators to\ndiscover useful representation. However, most of the existing methods are not\ncapable of providing an accurate estimation of MI with low-variance when the MI\nis large. We argue that directly estimating the gradients of MI is more\nappealing for representation learning than estimating MI in itself. To this\nend, we propose the Mutual Information Gradient Estimator (MIGE) for\nrepresentation learning based on the score estimation of implicit\ndistributions. MIGE exhibits a tight and smooth gradient estimation of MI in\nthe high-dimensional and large-MI settings. We expand the applications of MIGE\nin both unsupervised learning of deep representations based on InfoMax and the\nInformation Bottleneck method. Experimental results have indicated significant\nperformance improvement in learning useful representation.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 16:05:58 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wen", "Liangjian", ""], ["Zhou", "Yiji", ""], ["He", "Lirong", ""], ["Zhou", "Mingyuan", ""], ["Xu", "Zenglin", ""]]}, {"id": "2005.01138", "submitter": "Samin Yeasar Arnob", "authors": "Samin Yeasar Arnob", "title": "Off-Policy Adversarial Inverse Reinforcement Learning", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial Imitation Learning (AIL) is a class of algorithms in\nReinforcement learning (RL), which tries to imitate an expert without taking\nany reward from the environment and does not provide expert behavior directly\nto the policy training. Rather, an agent learns a policy distribution that\nminimizes the difference from expert behavior in an adversarial setting.\nAdversarial Inverse Reinforcement Learning (AIRL) leverages the idea of AIL,\nintegrates a reward function approximation along with learning the policy, and\nshows the utility of IRL in the transfer learning setting. But the reward\nfunction approximator that enables transfer learning does not perform well in\nimitation tasks. We propose an Off-Policy Adversarial Inverse Reinforcement\nLearning (Off-policy-AIRL) algorithm which is sample efficient as well as gives\ngood imitation performance compared to the state-of-the-art AIL algorithm in\nthe continuous control tasks. For the same reward function approximator, we\nshow the utility of learning our algorithm over AIL by using the learned reward\nfunction to retrain the policy over a task under significant variation where\nexpert demonstrations are absent.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 16:51:40 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Arnob", "Samin Yeasar", ""]]}, {"id": "2005.01151", "submitter": "Amirreza Shirani", "authors": "Amirreza Shirani, Franck Dernoncourt, Jose Echevarria, Paul Asente,\n  Nedim Lipka and Thamar Solorio", "title": "Let Me Choose: From Verbal Context to Font Selection", "comments": "Accepted to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we aim to learn associations between visual attributes of\nfonts and the verbal context of the texts they are typically applied to.\nCompared to related work leveraging the surrounding visual context, we choose\nto focus only on the input text as this can enable new applications for which\nthe text is the only visual element in the document. We introduce a new\ndataset, containing examples of different topics in social media posts and ads,\nlabeled through crowd-sourcing. Due to the subjective nature of the task,\nmultiple fonts might be perceived as acceptable for an input text, which makes\nthis problem challenging. To this end, we investigate different end-to-end\nmodels to learn label distributions on crowd-sourced data and capture\ninter-subjectivity across all annotations.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 17:36:17 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Shirani", "Amirreza", ""], ["Dernoncourt", "Franck", ""], ["Echevarria", "Jose", ""], ["Asente", "Paul", ""], ["Lipka", "Nedim", ""], ["Solorio", "Thamar", ""]]}, {"id": "2005.01157", "submitter": "Matan Orbach", "authors": "Matan Orbach, Yonatan Bilu, Assaf Toledo, Dan Lahav, Michal Jacovi,\n  Ranit Aharonov and Noam Slonim", "title": "Out of the Echo Chamber: Detecting Countering Debate Speeches", "comments": "Accepted to ACL 2020 as Long Paper. For the associated debate\n  speeches corpus, see\n  https://www.research.ibm.com/haifa/dept/vst/debating_data.shtml#Debate%20Speech%20Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An educated and informed consumption of media content has become a challenge\nin modern times. With the shift from traditional news outlets to social media\nand similar venues, a major concern is that readers are becoming encapsulated\nin \"echo chambers\" and may fall prey to fake news and disinformation, lacking\neasy access to dissenting views. We suggest a novel task aiming to alleviate\nsome of these concerns -- that of detecting articles that most effectively\ncounter the arguments -- and not just the stance -- made in a given text. We\nstudy this problem in the context of debate speeches. Given such a speech, we\naim to identify, from among a set of speeches on the same topic and with an\nopposing stance, the ones that directly counter it. We provide a large dataset\nof 3,685 such speeches (in English), annotated for this relation, which\nhopefully would be of general interest to the NLP community. We explore several\nalgorithms addressing this task, and while some are successful, all fall short\nof expert human performance, suggesting room for further research. All data\ncollected during this work is freely available for research.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 18:02:10 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Orbach", "Matan", ""], ["Bilu", "Yonatan", ""], ["Toledo", "Assaf", ""], ["Lahav", "Dan", ""], ["Jacovi", "Michal", ""], ["Aharonov", "Ranit", ""], ["Slonim", "Noam", ""]]}, {"id": "2005.01158", "submitter": "Gerard de Melo", "authors": "Kshitij Shah, Gerard de Melo", "title": "Correcting the Autocorrect: Context-Aware Typographical Error Correction\n  via Training Data Augmentation", "comments": "Accepted for publication at LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the artificial generation of typographical errors\nbased on real-world statistics. We first draw on a small set of annotated data\nto compute spelling error statistics. These are then invoked to introduce\nerrors into substantially larger corpora. The generation methodology allows us\nto generate particularly challenging errors that require context-aware error\ndetection. We use it to create a set of English language error detection and\ncorrection datasets. Finally, we examine the effectiveness of machine learning\nmodels for detecting and correcting errors based on this data. The datasets are\navailable at http://typo.nlproc.org\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 18:08:17 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Shah", "Kshitij", ""], ["de Melo", "Gerard", ""]]}, {"id": "2005.01181", "submitter": "Alireza Koochali", "authors": "Alireza Koochali, Andreas Dengel, Sheraz Ahmed", "title": "If You Like It, GAN It. Probabilistic Multivariate Times Series Forecast\n  With GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The contribution of this paper is two-fold. First, we present ProbCast - a\nnovel probabilistic model for multivariate time-series forecasting. We employ a\nconditional GAN framework to train our model with adversarial training. Second,\nwe propose a framework that lets us transform a deterministic model into a\nprobabilistic one with improved performance. The motivation of the framework is\nto either transform existing highly accurate point forecast models to their\nprobabilistic counterparts or to train GANs stably by selecting the\narchitecture of GAN's component carefully and efficiently. We conduct\nexperiments over two publicly available datasets namely electricity consumption\ndataset and exchange-rate dataset. The results of the experiments demonstrate\nthe remarkable performance of our model as well as the successful application\nof our proposed framework.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 20:33:13 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Koochali", "Alireza", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "2005.01182", "submitter": "Yihe Dong", "authors": "Yihe Dong, Yu Gao, Richard Peng, Ilya Razenshteyn, Saurabh Sawlani", "title": "A Study of Performance of Optimal Transport", "comments": null, "journal-ref": "Optimal Transport & Machine learning Workshop at NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of efficiently computing optimal transport (OT)\ndistances, which is equivalent to the node-capacitated minimum cost maximum\nflow problem in a bipartite graph. We compare runtimes in computing OT\ndistances on data from several domains, such as synthetic data of geometric\nshapes, embeddings of tokens in documents, and pixels in images. We show that\nin practice, combinatorial methods such as network simplex and augmenting path\nbased algorithms can consistently outperform numerical matrix-scaling based\nmethods such as Sinkhorn [Cuturi'13] and Greenkhorn [Altschuler et al'17], even\nin low accuracy regimes, with up to orders of magnitude speedups. Lastly, we\npresent a new combinatorial algorithm that improves upon the classical\nKuhn-Munkres algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 20:37:05 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Dong", "Yihe", ""], ["Gao", "Yu", ""], ["Peng", "Richard", ""], ["Razenshteyn", "Ilya", ""], ["Sawlani", "Saurabh", ""]]}, {"id": "2005.01185", "submitter": "Yida Huang", "authors": "Haoyan Xu, Yida Huang, Ziheng Duan, Xiaoqian Wang, Jie Feng, Pengyu\n  Song", "title": "Multivariate Time Series Forecasting with Transfer Entropy Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series (MTS) forecasting is an important problem in many\nfields. Accurate forecasting results can effectively help decision-making. To\ndate, many MTS forecasting methods have been proposed and widely applied.\nHowever, these methods assume that the predicted value of a single variable is\naffected by all other variables, which ignores the causal relationship among\nvariables. To address the above issue, a novel end-to-end deep learning model,\ntermed graph neural network with transfer entropy (TEGNN) is proposed in this\npaper. To characterize the causal information among variables, the transfer\nentropy (TE) graph is introduced in our model, where each variable is regarded\nas a graph node and each edge represents the casual relationship between\nvariables. In addition, convolutional neural network (CNN) filters with\ndifferent perception scales are used for time series feature extraction, which\nis used to generate the feature of each node. Finally, graph neural network\n(GNN) is adopted to tackle the forecasting problem of graph structure generated\nby MTS. Three benchmark datasets from the real world are used to evaluate the\nproposed TEGNN and the comprehensive experiments show that the proposed method\nachieves state-of-the-art results in MTS forecasting task.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 20:51:00 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 03:24:47 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 16:50:17 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Xu", "Haoyan", ""], ["Huang", "Yida", ""], ["Duan", "Ziheng", ""], ["Wang", "Xiaoqian", ""], ["Feng", "Jie", ""], ["Song", "Pengyu", ""]]}, {"id": "2005.01194", "submitter": "Sven Weinzierl", "authors": "S. Weinzierl, S. Zilker, J. Brunk, K. Revoredo, A. Nguyen, M. Matzner,\n  J. Becker, B. Eskofier", "title": "An empirical comparison of deep-neural-network architectures for next\n  activity prediction using context-enriched process event logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers have proposed a variety of predictive business process monitoring\n(PBPM) techniques aiming to predict future process behaviour during the process\nexecution. Especially, techniques for the next activity prediction anticipate\ngreat potential in improving operational business processes. To gain more\naccurate predictions, a plethora of these techniques rely on deep neural\nnetworks (DNNs) and consider information about the context, in which the\nprocess is running. However, an in-depth comparison of such techniques is\nmissing in the PBPM literature, which prevents researchers and practitioners\nfrom selecting the best solution for a given event log. To remedy this problem,\nwe empirically evaluate the predictive quality of three promising DNN\narchitectures, combined with five proven encoding techniques and based on five\ncontext-enriched real-life event logs. We provide four findings that can\nsupport researchers and practitioners in designing novel PBPM techniques for\npredicting the next activities.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 21:33:01 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Weinzierl", "S.", ""], ["Zilker", "S.", ""], ["Brunk", "J.", ""], ["Revoredo", "K.", ""], ["Nguyen", "A.", ""], ["Matzner", "M.", ""], ["Becker", "J.", ""], ["Eskofier", "B.", ""]]}, {"id": "2005.01206", "submitter": "Yang Zhao", "authors": "Weitao Li, Pengfei Xu, Yang Zhao, Haitong Li, Yuan Xie, Yingyan Lin", "title": "TIMELY: Pushing Data Movements and Interfaces in PIM Accelerators\n  Towards Local and in Time Domain", "comments": "Accepted by 47th International Symposium on Computer Architecture\n  (ISCA'2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.ET eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resistive-random-access-memory (ReRAM) based processing-in-memory (R$^2$PIM)\naccelerators show promise in bridging the gap between Internet of Thing\ndevices' constrained resources and Convolutional/Deep Neural Networks'\n(CNNs/DNNs') prohibitive energy cost. Specifically, R$^2$PIM accelerators\nenhance energy efficiency by eliminating the cost of weight movements and\nimproving the computational density through ReRAM's high density. However, the\nenergy efficiency is still limited by the dominant energy cost of input and\npartial sum (Psum) movements and the cost of digital-to-analog (D/A) and\nanalog-to-digital (A/D) interfaces. In this work, we identify three\nenergy-saving opportunities in R$^2$PIM accelerators: analog data locality,\ntime-domain interfacing, and input access reduction, and propose an innovative\nR$^2$PIM accelerator called TIMELY, with three key contributions: (1) TIMELY\nadopts analog local buffers (ALBs) within ReRAM crossbars to greatly enhance\nthe data locality, minimizing the energy overheads of both input and Psum\nmovements; (2) TIMELY largely reduces the energy of each single D/A (and A/D)\nconversion and the total number of conversions by using time-domain interfaces\n(TDIs) and the employed ALBs, respectively; (3) we develop an only-once input\nread (O$^2$IR) mapping method to further decrease the energy of input accesses\nand the number of D/A conversions. The evaluation with more than 10 CNN/DNN\nmodels and various chip configurations shows that, TIMELY outperforms the\nbaseline R$^2$PIM accelerator, PRIME, by one order of magnitude in energy\nefficiency while maintaining better computational density (up to 31.2$\\times$)\nand throughput (up to 736.6$\\times$). Furthermore, comprehensive studies are\nperformed to evaluate the effectiveness of the proposed ALB, TDI, and O$^2$IR\ninnovations in terms of energy savings and area reduction.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 23:27:51 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Li", "Weitao", ""], ["Xu", "Pengfei", ""], ["Zhao", "Yang", ""], ["Li", "Haitong", ""], ["Xie", "Yuan", ""], ["Lin", "Yingyan", ""]]}, {"id": "2005.01207", "submitter": "Jonatan Gomez", "authors": "Edwin Camilo Cubides and Jonatan Gomez", "title": "Obtaining Basic Algebra Formulas with Genetic Programming and Functional\n  Rewriting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a set of genetic programming operators and an\ninitialization population process based on concepts of functional programming\nrewriting for boosting inductive genetic programming. Such genetic operators\nare used within a hybrid adaptive evolutionary algorithm that evolves operator\nrates at the same time it evolves the solution. Solutions are represented using\nrecursive functions where genome is encoded as an ordered list of trees and\nphenotype is written in a simple functional programming language that uses\nrewriting as operational semantic (computational model). The fitness is the\nnumber of examples successfully deduced over the cardinal of the set of\nexamples. Parents are selected following a tournament selection mechanism and\nthe next population is obtained following a steady-state strategy. The\nevolutionary process can use some previous functions (programs) induced as\nbackground knowledge. We compare the performance of our technique in a set of\nhard problems (for classical genetic programming). In particular, we take as\ntest-bed the problem of obtaining equivalent algebraic expressions of some\nnotable products (such as square of a binomial, and cube of a binomial), and\nthe recursive formulas of sum of the first n and squares of the first n natural\nnumbers.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 23:32:36 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Cubides", "Edwin Camilo", ""], ["Gomez", "Jonatan", ""]]}, {"id": "2005.01208", "submitter": "Josimar Chire Saire", "authors": "Alexander Ylnner Choquenaira Florez, Braulio Valentin Sanchez Vinces,\n  Diana Carolina Roca Arroyo, Josimar Edinson Chire Saire, Patr{\\i}cia Batista\n  Franco", "title": "Machine Learning Pipeline for Pulsar Star Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work brings together some of the most common machine learning (ML)\nalgorithms, and the objective is to make a comparison at the level of obtained\nresults from a set of unbalanced data. This dataset is composed of almost 17\nthousand observations made to astronomical objects to identify pulsars (HTRU2).\nThe methodological proposal based on evaluating the accuracy of these different\nmodels on the same database treated with two different strategies for\nunbalanced data. The results show that in spite of the noise and unbalance of\nclasses present in this type of data, it is possible to apply them on standard\nML algorithms and obtain promising accuracy ratios.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 23:35:44 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Florez", "Alexander Ylnner Choquenaira", ""], ["Vinces", "Braulio Valentin Sanchez", ""], ["Arroyo", "Diana Carolina Roca", ""], ["Saire", "Josimar Edinson Chire", ""], ["Franco", "Patr\u0131cia Batista", ""]]}, {"id": "2005.01209", "submitter": "Shiqian Ma", "authors": "Bokun Wang, Shiqian Ma, Lingzhou Xue", "title": "Riemannian Stochastic Proximal Gradient Methods for Nonsmooth\n  Optimization over the Stiefel Manifold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Riemannian optimization has drawn a lot of attention due to its wide\napplications in practice. Riemannian stochastic first-order algorithms have\nbeen studied in the literature to solve large-scale machine learning problems\nover Riemannian manifolds. However, most of the existing Riemannian stochastic\nalgorithms require the objective function to be differentiable, and they do not\napply to the case where the objective function is nonsmooth. In this paper, we\npresent two Riemannian stochastic proximal gradient methods for minimizing\nnonsmooth function over the Stiefel manifold. The two methods, named R-ProxSGD\nand R-ProxSPB, are generalizations of proximal SGD and proximal SpiderBoost in\nEuclidean setting to the Riemannian setting. Analysis on the incremental\nfirst-order oracle (IFO) complexity of the proposed algorithms is provided.\nSpecifically, the R-ProxSPB algorithm finds an $\\epsilon$-stationary point with\n$\\mathcal{O}(\\epsilon^{-3})$ IFOs in the online case, and\n$\\mathcal{O}(n+\\sqrt{n}\\epsilon^{-3})$ IFOs in the finite-sum case with $n$\nbeing the number of summands in the objective. Experimental results on online\nsparse PCA and robust low-rank matrix completion show that our proposed methods\nsignificantly outperform the existing methods that uses Riemannian subgradient\ninformation.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 23:41:35 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wang", "Bokun", ""], ["Ma", "Shiqian", ""], ["Xue", "Lingzhou", ""]]}, {"id": "2005.01214", "submitter": "Hoang Nt", "authors": "Hoang NT, Takanori Maehara", "title": "Graph Homomorphism Convolution", "comments": "37th International Conference on Machine Learning (ICML 2020)", "journal-ref": "PMLR 119, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.DM math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the graph classification problem from the graph\nhomomorphism perspective. We consider the homomorphisms from $F$ to $G$, where\n$G$ is a graph of interest (e.g. molecules or social networks) and $F$ belongs\nto some family of graphs (e.g. paths or non-isomorphic trees). We show that\ngraph homomorphism numbers provide a natural invariant (isomorphism invariant\nand $\\mathcal{F}$-invariant) embedding maps which can be used for graph\nclassification. Viewing the expressive power of a graph classifier by the\n$\\mathcal{F}$-indistinguishable concept, we prove the universality property of\ngraph homomorphism vectors in approximating $\\mathcal{F}$-invariant functions.\nIn practice, by choosing $\\mathcal{F}$ whose elements have bounded tree-width,\nwe show that the homomorphism method is efficient compared with other methods.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 23:56:20 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 01:10:37 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["NT", "Hoang", ""], ["Maehara", "Takanori", ""]]}, {"id": "2005.01229", "submitter": "Erik Jones", "authors": "Erik Jones, Robin Jia, Aditi Raghunathan, and Percy Liang", "title": "Robust Encodings: A Framework for Combating Adversarial Typos", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite excellent performance on many tasks, NLP systems are easily fooled by\nsmall adversarial perturbations of inputs. Existing procedures to defend\nagainst such perturbations are either (i) heuristic in nature and susceptible\nto stronger attacks or (ii) provide guaranteed robustness to worst-case\nattacks, but are incompatible with state-of-the-art models like BERT. In this\nwork, we introduce robust encodings (RobEn): a simple framework that confers\nguaranteed robustness, without making compromises on model architecture. The\ncore component of RobEn is an encoding function, which maps sentences to a\nsmaller, discrete space of encodings. Systems using these encodings as a\nbottleneck confer guaranteed robustness with standard training, and the same\nencodings can be used across multiple tasks. We identify two desiderata to\nconstruct robust encoding functions: perturbations of a sentence should map to\na small set of encodings (stability), and models using encodings should still\nperform well (fidelity). We instantiate RobEn to defend against a large family\nof adversarial typos. Across six tasks from GLUE, our instantiation of RobEn\npaired with BERT achieves an average robust accuracy of 71.3% against all\nadversarial typos in the family considered, while previous work using a\ntypo-corrector achieves only 35.3% accuracy against a simple greedy attack.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 01:28:18 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Jones", "Erik", ""], ["Jia", "Robin", ""], ["Raghunathan", "Aditi", ""], ["Liang", "Percy", ""]]}, {"id": "2005.01234", "submitter": "Wanqi Xue", "authors": "Wanqi Xue, Wei Wang", "title": "One-Shot Image Classification by Learning to Restore Prototypes", "comments": "Published as a conference paper in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-shot image classification aims to train image classifiers over the\ndataset with only one image per category. It is challenging for modern deep\nneural networks that typically require hundreds or thousands of images per\nclass. In this paper, we adopt metric learning for this problem, which has been\napplied for few- and many-shot image classification by comparing the distance\nbetween the test image and the center of each class in the feature space.\nHowever, for one-shot learning, the existing metric learning approaches would\nsuffer poor performance because the single training image may not be\nrepresentative of the class. For example, if the image is far away from the\nclass center in the feature space, the metric-learning based algorithms are\nunlikely to make correct predictions for the test images because the decision\nboundary is shifted by this noisy image. To address this issue, we propose a\nsimple yet effective regression model, denoted by RestoreNet, which learns a\nclass agnostic transformation on the image feature to move the image closer to\nthe class center in the feature space. Experiments demonstrate that RestoreNet\nobtains superior performance over the state-of-the-art methods on a broad range\nof datasets. Moreover, RestoreNet can be easily combined with other methods to\nachieve further improvement.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 02:11:30 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Xue", "Wanqi", ""], ["Wang", "Wei", ""]]}, {"id": "2005.01239", "submitter": "Violetta Shevchenko", "authors": "Violetta Shevchenko, Damien Teney, Anthony Dick, Anton van den Hengel", "title": "Visual Question Answering with Prior Class Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel mechanism to embed prior knowledge in a model for visual\nquestion answering. The open-set nature of the task is at odds with the\nubiquitous approach of training of a fixed classifier. We show how to exploit\nadditional information pertaining to the semantics of candidate answers. We\nextend the answer prediction process with a regression objective in a semantic\nspace, in which we project candidate answers using prior knowledge derived from\nword embeddings. We perform an extensive study of learned representations with\nthe GQA dataset, revealing that important semantic information is captured in\nthe relations between embeddings in the answer space. Our method brings\nimprovements in consistency and accuracy over a range of question types.\nExperiments with novel answers, unseen during training, indicate the method's\npotential for open-set prediction.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 02:46:31 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Shevchenko", "Violetta", ""], ["Teney", "Damien", ""], ["Dick", "Anthony", ""], ["Hengel", "Anton van den", ""]]}, {"id": "2005.01246", "submitter": "Raviteja Anantha", "authors": "Raviteja Anantha, Stephen Pulman, and Srinivas Chappidi", "title": "Generalized Reinforcement Meta Learning for Few-Shot Optimization", "comments": "10 pages, 4 figures, 4 tables, 2 algorithms, ICML conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generic and flexible Reinforcement Learning (RL) based\nmeta-learning framework for the problem of few-shot learning. During training,\nit learns the best optimization algorithm to produce a learner\n(ranker/classifier, etc) by exploiting stable patterns in loss surfaces. Our\nmethod implicitly estimates the gradients of a scaled loss function while\nretaining the general properties intact for parameter updates. Besides\nproviding improved performance on few-shot tasks, our framework could be easily\nextended to do network architecture search. We further propose a novel dual\nencoder, affinity-score based decoder topology that achieves additional\nimprovements to performance. Experiments on an internal dataset, MQ2007, and\nAwA2 show our approach outperforms existing alternative approaches by 21%, 8%,\nand 4% respectively on accuracy and NDCG metrics. On Mini-ImageNet dataset our\napproach achieves comparable results with Prototypical Networks. Empirical\nevaluations demonstrate that our approach provides a unified and effective\nframework.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 03:21:05 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Anantha", "Raviteja", ""], ["Pulman", "Stephen", ""], ["Chappidi", "Srinivas", ""]]}, {"id": "2005.01259", "submitter": "Liyan Xu", "authors": "Liyan Xu, Julien Hogan, Rachel E. Patzer and Jinho D. Choi", "title": "Noise Pollution in Hospital Readmission Prediction: Long Document\n  Classification with Reinforcement Learning", "comments": "Accepted to the ACL Workshop on Biomedical Natural Language\n  Processing, BioNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a reinforcement learning approach to extract noise in\nlong clinical documents for the task of readmission prediction after kidney\ntransplant. We face the challenges of developing robust models on a small\ndataset where each document may consist of over 10K tokens with full of noise\nincluding tabular text and task-irrelevant sentences. We first experiment four\ntypes of encoders to empirically decide the best document representation, and\nthen apply reinforcement learning to remove noisy text from the long documents,\nwhich models the noise extraction process as a sequential decision problem. Our\nresults show that the old bag-of-words encoder outperforms deep learning-based\nencoders on this task, and reinforcement learning is able to improve upon\nbaseline while pruning out 25% text segments. Our analysis depicts that\nreinforcement learning is able to identify both typical noisy tokens and\ntask-specific noisy text.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 04:06:53 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 04:36:36 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Xu", "Liyan", ""], ["Hogan", "Julien", ""], ["Patzer", "Rachel E.", ""], ["Choi", "Jinho D.", ""]]}, {"id": "2005.01278", "submitter": "Zhiqiang Zhan", "authors": "Zhiqiang Zhan, Zifeng Hou, Yang Zhang", "title": "A New Data Normalization Method to Improve Dialogue Generation by\n  Minimizing Long Tail Effect", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural models have shown significant progress in dialogue generation.\nMost generation models are based on language models. However, due to the Long\nTail Phenomenon in linguistics, the trained models tend to generate words that\nappear frequently in training datasets, leading to a monotonous issue. To\naddress this issue, we analyze a large corpus from Wikipedia and propose three\nfrequency-based data normalization methods. We conduct extensive experiments\nbased on transformers and three datasets respectively collected from social\nmedia, subtitles, and the industrial application. Experimental results\ndemonstrate significant improvements in diversity and informativeness (defined\nas the numbers of nouns and verbs) of generated responses. More specifically,\nthe unigram and bigram diversity are increased by 2.6%-12.6% and 2.2%-18.9% on\nthe three datasets, respectively. Moreover, the informativeness, i.e. the\nnumbers of nouns and verbs, are increased by 4.0%-7.0% and 1.4%-12.1%,\nrespectively. Additionally, the simplicity and effectiveness enable our methods\nto be adapted to different generation models without much extra computational\ncost.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 05:20:19 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Zhan", "Zhiqiang", ""], ["Hou", "Zifeng", ""], ["Zhang", "Yang", ""]]}, {"id": "2005.01279", "submitter": "Ruiyi Zhang", "authors": "Ruiyi Zhang, Changyou Chen, Zhe Gan, Wenlin Wang, Dinghan Shen, Guoyin\n  Wang, Zheng Wen, Lawrence Carin", "title": "Improving Adversarial Text Generation by Modeling the Distant Future", "comments": "ACL 2020. arXiv admin note: substantial text overlap with\n  arXiv:1811.00696", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto-regressive text generation models usually focus on local fluency, and\nmay cause inconsistent semantic meaning in long text generation. Further,\nautomatically generating words with similar semantics is challenging, and\nhand-crafted linguistic rules are difficult to apply. We consider a text\nplanning scheme and present a model-based imitation-learning approach to\nalleviate the aforementioned issues. Specifically, we propose a novel guider\nnetwork to focus on the generative process over a longer horizon, which can\nassist next-word prediction and provide intermediate rewards for generator\noptimization. Extensive experiments demonstrate that the proposed method leads\nto improved performance.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 05:45:13 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Zhang", "Ruiyi", ""], ["Chen", "Changyou", ""], ["Gan", "Zhe", ""], ["Wang", "Wenlin", ""], ["Shen", "Dinghan", ""], ["Wang", "Guoyin", ""], ["Wen", "Zheng", ""], ["Carin", "Lawrence", ""]]}, {"id": "2005.01291", "submitter": "Pedram Daee", "authors": "Fabio Colella, Pedram Daee, Jussi Jokinen, Antti Oulasvirta, Samuel\n  Kaski", "title": "Human Strategic Steering Improves Performance of Interactive\n  Optimization", "comments": "10 pages, 5 figures, The paper is published in the proceedings of\n  UMAP 2020. Codes available at\n  https://github.com/fcole90/interactive_bayesian_optimisation", "journal-ref": null, "doi": "10.1145/3340631.3394883", "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central concern in an interactive intelligent system is optimization of its\nactions, to be maximally helpful to its human user. In recommender systems for\ninstance, the action is to choose what to recommend, and the optimization task\nis to recommend items the user prefers. The optimization is done based on\nearlier user's feedback (e.g. \"likes\" and \"dislikes\"), and the algorithms\nassume the feedback to be faithful. That is, when the user clicks \"like,\" they\nactually prefer the item. We argue that this fundamental assumption can be\nextensively violated by human users, who are not passive feedback sources.\nInstead, they are in control, actively steering the system towards their goal.\nTo verify this hypothesis, that humans steer and are able to improve\nperformance by steering, we designed a function optimization task where a human\nand an optimization algorithm collaborate to find the maximum of a\n1-dimensional function. At each iteration, the optimization algorithm queries\nthe user for the value of a hidden function $f$ at a point $x$, and the user,\nwho sees the hidden function, provides an answer about $f(x)$. Our study on 21\nparticipants shows that users who understand how the optimization works,\nstrategically provide biased answers (answers not equal to $f(x)$), which\nresults in the algorithm finding the optimum significantly faster. Our work\nhighlights that next-generation intelligent systems will need user models\ncapable of helping users who steer systems to pursue their goals.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 06:56:52 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Colella", "Fabio", ""], ["Daee", "Pedram", ""], ["Jokinen", "Jussi", ""], ["Oulasvirta", "Antti", ""], ["Kaski", "Samuel", ""]]}, {"id": "2005.01297", "submitter": "Tomas Pevny", "authors": "Tomas Pevny, Vasek Smidl, Martin Trapp, Ondrej Polacek, Tomas\n  Oberhuber", "title": "Sum-Product-Transform Networks: Exploiting Symmetries using Invertible\n  Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose Sum-Product-Transform Networks (SPTN), an extension\nof sum-product networks that uses invertible transformations as additional\ninternal nodes. The type and placement of transformations determine properties\nof the resulting SPTN with many interesting special cases. Importantly, SPTN\nwith Gaussian leaves and affine transformations pose the same inference task\ntractable that can be computed efficiently in SPNs. We propose to store affine\ntransformations in their SVD decompositions using an efficient parametrization\nof unitary matrices by a set of Givens rotations. Last but not least, we\ndemonstrate that G-SPTNs achieve state-of-the-art results on the density\nestimation task and are competitive with state-of-the-art methods for anomaly\ndetection.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 07:05:51 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Pevny", "Tomas", ""], ["Smidl", "Vasek", ""], ["Trapp", "Martin", ""], ["Polacek", "Ondrej", ""], ["Oberhuber", "Tomas", ""]]}, {"id": "2005.01317", "submitter": "Jicong Fan", "authors": "Jicong Fan, Chengrun Yang, Madeleine Udell", "title": "Robust Non-Linear Matrix Factorization for Dictionary Learning,\n  Denoising, and Clustering", "comments": null, "journal-ref": "IEEE Transactions on Signal Processing 69, 1755-1770 (2021)", "doi": "10.1109/TSP.2021.3062988", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low dimensional nonlinear structure abounds in datasets across computer\nvision and machine learning. Kernelized matrix factorization techniques have\nrecently been proposed to learn these nonlinear structures for denoising,\nclassification, dictionary learning, and missing data imputation, by observing\nthat the image of the matrix in a sufficiently large feature space is low-rank.\nHowever, these nonlinear methods fail in the presence of sparse noise or\noutliers. In this work, we propose a new robust nonlinear factorization method\ncalled Robust Non-Linear Matrix Factorization (RNLMF). RNLMF constructs a\ndictionary for the data space by factoring a kernelized feature space; a noisy\nmatrix can then be decomposed as the sum of a sparse noise matrix and a clean\ndata matrix that lies in a low dimensional nonlinear manifold. RNLMF is robust\nto sparse noise and outliers and scales to matrices with thousands of rows and\ncolumns. Empirically, RNLMF achieves noticeable improvements over baseline\nmethods in denoising and clustering.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 08:32:21 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 08:51:54 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Fan", "Jicong", ""], ["Yang", "Chengrun", ""], ["Udell", "Madeleine", ""]]}, {"id": "2005.01319", "submitter": "Milad Kazemi", "authors": "Milad Kazemi and Sadegh Soudjani", "title": "Formal Policy Synthesis for Continuous-Space Systems via Reinforcement\n  Learning", "comments": "This is the extended version of the paper accepted in the 16th\n  International Conference on integrated Formal Methods (iFM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies satisfaction of temporal properties on unknown stochastic\nprocesses that have continuous state spaces. We show how reinforcement learning\n(RL) can be applied for computing policies that are finite-memory and\ndeterministic using only the paths of the stochastic process. We address\nproperties expressed in linear temporal logic (LTL) and use their automaton\nrepresentation to give a path-dependent reward function maximised via the RL\nalgorithm. We develop the required assumptions and theories for the convergence\nof the learned policy to the optimal policy in the continuous state space. To\nimprove the performance of the learning on the constructed sparse reward\nfunction, we propose a sequential learning procedure based on a sequence of\nlabelling functions obtained from the positive normal form of the LTL\nspecification. We use this procedure to guide the RL algorithm towards a policy\nthat converges to an optimal policy under suitable assumptions on the process.\nWe demonstrate the approach on a 4-dim cart-pole system and 6-dim boat driving\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 08:36:25 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 11:55:30 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Kazemi", "Milad", ""], ["Soudjani", "Sadegh", ""]]}, {"id": "2005.01347", "submitter": "Omar Ibrahim Mr", "authors": "Omar Adel Ibrahim, Savio Sciancalepore, Roberto Di Pietro", "title": "Noise2Weight: On Detecting Payload Weight from Drones Acoustic Emissions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing popularity of autonomous and remotely-piloted drones have\npaved the way for several use-cases, e.g., merchandise delivery and\nsurveillance. In many scenarios, estimating with zero-touch the weight of the\npayload carried by a drone before its physical approach could be attractive,\ne.g., to provide an early tampering detection.\n  In this paper, we investigate the possibility to remotely detect the weight\nof the payload carried by a commercial drone by analyzing its acoustic\nfingerprint. We characterize the difference in the thrust needed by the drone\nto carry different payloads, resulting in significant variations of the related\nacoustic fingerprint. We applied the above findings to different use-cases,\ncharacterized by different computational capabilities of the detection system.\nResults are striking: using the Mel-Frequency Cepstral Coefficients (MFCC)\ncomponents of the audio signal and different Support Vector Machine (SVM)\nclassifiers, we achieved a minimum classification accuracy of 98% in the\ndetection of the specific payload class carried by the drone, using an\nacquisition time of 0.25 s---performances improve when using longer time\nacquisitions.\n  All the data used for our analysis have been released as open-source, to\nenable the community to validate our findings and use such data as a\nready-to-use basis for further investigations.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 09:44:18 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Ibrahim", "Omar Adel", ""], ["Sciancalepore", "Savio", ""], ["Di Pietro", "Roberto", ""]]}, {"id": "2005.01348", "submitter": "Mostafa Abdou", "authors": "Mostafa Abdou, Vinit Ravishankar, Maria Barrett, Yonatan Belinkov,\n  Desmond Elliott, Anders S{\\o}gaard", "title": "The Sensitivity of Language Models and Humans to Winograd Schema\n  Perturbations", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale pretrained language models are the major driving force behind\nrecent improvements in performance on the Winograd Schema Challenge, a widely\nemployed test of common sense reasoning ability. We show, however, with a new\ndiagnostic dataset, that these models are sensitive to linguistic perturbations\nof the Winograd examples that minimally affect human understanding. Our results\nhighlight interesting differences between humans and language models: language\nmodels are more sensitive to number or gender alternations and synonym\nreplacements than humans, and humans are more stable and consistent in their\npredictions, maintain a much higher absolute performance, and perform better on\nnon-associative instances than associative ones. Overall, humans are correct\nmore often than out-of-the-box models, and the models are sometimes right for\nthe wrong reasons. Finally, we show that fine-tuning on a large, task-specific\ndataset can offer a solution to these issues.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 09:44:54 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 06:48:57 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Abdou", "Mostafa", ""], ["Ravishankar", "Vinit", ""], ["Barrett", "Maria", ""], ["Belinkov", "Yonatan", ""], ["Elliott", "Desmond", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "2005.01350", "submitter": "Quanquan Gu", "authors": "Yue Wu and Weitong Zhang and Pan Xu and Quanquan Gu", "title": "A Finite Time Analysis of Two Time-Scale Actor Critic Methods", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Actor-critic (AC) methods have exhibited great empirical success compared\nwith other reinforcement learning algorithms, where the actor uses the policy\ngradient to improve the learning policy and the critic uses temporal difference\nlearning to estimate the policy gradient. Under the two time-scale learning\nrate schedule, the asymptotic convergence of AC has been well studied in the\nliterature. However, the non-asymptotic convergence and finite sample\ncomplexity of actor-critic methods are largely open. In this work, we provide a\nnon-asymptotic analysis for two time-scale actor-critic methods under\nnon-i.i.d. setting. We prove that the actor-critic method is guaranteed to find\na first-order stationary point (i.e., $\\|\\nabla J(\\boldsymbol{\\theta})\\|_2^2\n\\le \\epsilon$) of the non-concave performance function\n$J(\\boldsymbol{\\theta})$, with $\\mathcal{\\tilde{O}}(\\epsilon^{-2.5})$ sample\ncomplexity. To the best of our knowledge, this is the first work providing\nfinite-time analysis and sample complexity bound for two time-scale\nactor-critic methods.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 09:45:18 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 01:18:58 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Wu", "Yue", ""], ["Zhang", "Weitong", ""], ["Xu", "Pan", ""], ["Gu", "Quanquan", ""]]}, {"id": "2005.01365", "submitter": "Micha{\\l} Narajewski", "authors": "Micha{\\l} Narajewski and Florian Ziel", "title": "Ensemble Forecasting for Intraday Electricity Prices: Simulating\n  Trajectories", "comments": "accepted for publication in Applied Energy", "journal-ref": "Applied Energy 2020, 279", "doi": "10.1016/j.apenergy.2020.115801", "report-no": null, "categories": "q-fin.ST cs.LG cs.SY econ.EM eess.SY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies concerning the point electricity price forecasting have shown\nevidence that the hourly German Intraday Continuous Market is weak-form\nefficient. Therefore, we take a novel, advanced approach to the problem. A\nprobabilistic forecasting of the hourly intraday electricity prices is\nperformed by simulating trajectories in every trading window to receive a\nrealistic ensemble to allow for more efficient intraday trading and redispatch.\nA generalized additive model is fitted to the price differences with the\nassumption that they follow a zero-inflated distribution, precisely a mixture\nof the Dirac and the Student's t-distributions. Moreover, the mixing term is\nestimated using a high-dimensional logistic regression with lasso penalty. We\nmodel the expected value and volatility of the series using i.a. autoregressive\nand no-trade effects or load, wind and solar generation forecasts and\naccounting for the non-linearities in e.g. time to maturity. Both the in-sample\ncharacteristics and forecasting performance are analysed using a rolling window\nforecasting study. Multiple versions of the model are compared to several\nbenchmark models and evaluated using probabilistic forecasting measures and\nsignificance tests. The study aims to forecast the price distribution in the\nGerman Intraday Continuous Market in the last 3 hours of trading, but the\napproach allows for application to other continuous markets, especially in\nEurope. The results prove superiority of the mixture model over the benchmarks\ngaining the most from the modelling of the volatility. They also indicate that\nthe introduction of XBID reduced the market volatility.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 10:21:20 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 11:46:30 GMT"}, {"version": "v3", "created": "Sat, 29 Aug 2020 13:12:31 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Narajewski", "Micha\u0142", ""], ["Ziel", "Florian", ""]]}, {"id": "2005.01378", "submitter": "Yu Cheng", "authors": "Yu Cheng, Ilias Diakonikolas, Rong Ge, Mahdi Soltanolkotabi", "title": "High-Dimensional Robust Mean Estimation via Gradient Descent", "comments": "Under submission to ICML'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of high-dimensional robust mean estimation in the\npresence of a constant fraction of adversarial outliers. A recent line of work\nhas provided sophisticated polynomial-time algorithms for this problem with\ndimension-independent error guarantees for a range of natural distribution\nfamilies.\n  In this work, we show that a natural non-convex formulation of the problem\ncan be solved directly by gradient descent. Our approach leverages a novel\nstructural lemma, roughly showing that any approximate stationary point of our\nnon-convex objective gives a near-optimal solution to the underlying robust\nestimation task. Our work establishes an intriguing connection between\nalgorithmic high-dimensional robust statistics and non-convex optimization,\nwhich may have broader applications to other robust estimation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 10:48:04 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Cheng", "Yu", ""], ["Diakonikolas", "Ilias", ""], ["Ge", "Rong", ""], ["Soltanolkotabi", "Mahdi", ""]]}, {"id": "2005.01386", "submitter": "Sukanta Dey", "authors": "Sukanta Dey, Sukumar Nandi, and Gaurav Trivedi", "title": "PowerPlanningDL: Reliability-Aware Framework for On-Chip Power Grid\n  Design using Deep Learning", "comments": "Published in proceedings of IEEE/ACM Design, Automation and Test in\n  Europe Conference (DATE) 2020, 6 pages", "journal-ref": "DATE 2020 Proceedings, 1520-1525, IEEE", "doi": "10.23919/DATE48585.2020.9116536", "report-no": null, "categories": "cs.LG cs.AR eess.SP math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increase in the complexity of chip designs, VLSI physical design has\nbecome a time-consuming task, which is an iterative design process. Power\nplanning is that part of the floorplanning in VLSI physical design where power\ngrid networks are designed in order to provide adequate power to all the\nunderlying functional blocks. Power planning also requires multiple iterative\nsteps to create the power grid network while satisfying the allowed worst-case\nIR drop and Electromigration (EM) margin. For the first time, this paper\nintroduces Deep learning (DL)-based framework to approximately predict the\ninitial design of the power grid network, considering different reliability\nconstraints. The proposed framework reduces many iterative design steps and\nspeeds up the total design cycle. Neural Network-based multi-target regression\ntechnique is used to create the DL model. Feature extraction is done, and the\ntraining dataset is generated from the floorplans of some of the power grid\ndesigns extracted from the IBM processor. The DL model is trained using the\ngenerated dataset. The proposed DL-based framework is validated using a new set\nof power grid specifications (obtained by perturbing the designs used in the\ntraining phase). The results show that the predicted power grid design is\ncloser to the original design with minimal prediction error (~2%). The proposed\nDL-based approach also improves the design cycle time with a speedup of ~6X for\nstandard power grid benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 11:01:17 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 06:12:18 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Dey", "Sukanta", ""], ["Nandi", "Sukumar", ""], ["Trivedi", "Gaurav", ""]]}, {"id": "2005.01399", "submitter": "Adriano Lucieri", "authors": "Adriano Lucieri, Muhammad Naseer Bajwa, Andreas Dengel and Sheraz\n  Ahmed", "title": "Explaining AI-based Decision Support Systems using Concept Localization\n  Maps", "comments": "Submitted to ICANN2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-centric explainability of AI-based Decision Support Systems (DSS) using\nvisual input modalities is directly related to reliability and practicality of\nsuch algorithms. An otherwise accurate and robust DSS might not enjoy trust of\nexperts in critical application areas if it is not able to provide reasonable\njustification of its predictions. This paper introduces Concept Localization\nMaps (CLMs), which is a novel approach towards explainable image classifiers\nemployed as DSS. CLMs extend Concept Activation Vectors (CAVs) by locating\nsignificant regions corresponding to a learned concept in the latent space of a\ntrained image classifier. They provide qualitative and quantitative assurance\nof a classifier's ability to learn and focus on similar concepts important for\nhumans during image recognition. To better understand the effectiveness of the\nproposed method, we generated a new synthetic dataset called Simple Concept\nDataBase (SCDB) that includes annotations for 10 distinguishable concepts, and\nmade it publicly available. We evaluated our proposed method on SCDB as well as\na real-world dataset called CelebA. We achieved localization recall of above\n80% for most relevant concepts and average recall above 60% for all concepts\nusing SE-ResNeXt-50 on SCDB. Our results on both datasets show great promise of\nCLMs for easing acceptance of DSS in practice.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 11:33:00 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Lucieri", "Adriano", ""], ["Bajwa", "Muhammad Naseer", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "2005.01400", "submitter": "Abhinav Shukla", "authors": "Abhinav Shukla, Stavros Petridis, Maja Pantic", "title": "Does Visual Self-Supervision Improve Learning of Speech Representations\n  for Emotion Recognition?", "comments": "Accepted for publication in IEEE Transactions on Affective Computing;\n  v3: Publication-ready version including additional experiments and discussion", "journal-ref": null, "doi": "10.1109/TAFFC.2021.3062406", "report-no": null, "categories": "eess.AS cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning has attracted plenty of recent research interest.\nHowever, most works for self-supervision in speech are typically unimodal and\nthere has been limited work that studies the interaction between audio and\nvisual modalities for cross-modal self-supervision. This work (1) investigates\nvisual self-supervision via face reconstruction to guide the learning of audio\nrepresentations; (2) proposes an audio-only self-supervision approach for\nspeech representation learning; (3) shows that a multi-task combination of the\nproposed visual and audio self-supervision is beneficial for learning richer\nfeatures that are more robust in noisy conditions; (4) shows that\nself-supervised pretraining can outperform fully supervised training and is\nespecially useful to prevent overfitting on smaller sized datasets. We evaluate\nour learned audio representations for discrete emotion recognition, continuous\naffect recognition and automatic speech recognition. We outperform existing\nself-supervised methods for all tested downstream tasks. Our results\ndemonstrate the potential of visual self-supervision for audio feature learning\nand suggest that joint visual and audio self-supervision leads to more\ninformative audio representations for speech and emotion recognition.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 11:33:40 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 16:46:13 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 11:35:38 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Shukla", "Abhinav", ""], ["Petridis", "Stavros", ""], ["Pantic", "Maja", ""]]}, {"id": "2005.01427", "submitter": "Kacper Sokol", "authors": "Kacper Sokol and Peter Flach", "title": "LIMEtree: Interactively Customisable Explanations Based on Local\n  Surrogate Multi-output Regression Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems based on artificial intelligence and machine learning models should\nbe transparent, in the sense of being capable of explaining their decisions to\ngain humans' approval and trust. While there are a number of explainability\ntechniques that can be used to this end, many of them are only capable of\noutputting a single one-size-fits-all explanation that simply cannot address\nall of the explainees' diverse needs. In this work we introduce a\nmodel-agnostic and post-hoc local explainability technique for black-box\npredictions called LIMEtree, which employs surrogate multi-output regression\ntrees. We validate our algorithm on a deep neural network trained for object\ndetection in images and compare it against Local Interpretable Model-agnostic\nExplanations (LIME). Our method comes with local fidelity guarantees and can\nproduce a range of diverse explanation types, including contrastive and\ncounterfactual explanations praised in the literature. Some of these\nexplanations can be interactively personalised to create bespoke, meaningful\nand actionable insights into the model's behaviour. While other methods may\ngive an illusion of customisability by wrapping, otherwise static, explanations\nin an interactive interface, our explanations are truly interactive, in the\nsense of allowing the user to \"interrogate\" a black-box model. LIMEtree can\ntherefore produce consistent explanations on which an interactive exploratory\nprocess can be built.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 12:31:29 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Sokol", "Kacper", ""], ["Flach", "Peter", ""]]}, {"id": "2005.01432", "submitter": "Hany Abdulsamad", "authors": "Hany Abdulsamad and Jan Peters", "title": "Hierarchical Decomposition of Nonlinear Dynamics and Control for System\n  Identification and Policy Distillation", "comments": "2nd Annual Conference on Learning for Dynamics and Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The control of nonlinear dynamical systems remains a major challenge for\nautonomous agents. Current trends in reinforcement learning (RL) focus on\ncomplex representations of dynamics and policies, which have yielded impressive\nresults in solving a variety of hard control tasks. However, this new\nsophistication and extremely over-parameterized models have come with the cost\nof an overall reduction in our ability to interpret the resulting policies. In\nthis paper, we take inspiration from the control community and apply the\nprinciples of hybrid switching systems in order to break down complex dynamics\ninto simpler components. We exploit the rich representational power of\nprobabilistic graphical models and derive an expectation-maximization (EM)\nalgorithm for learning a sequence model to capture the temporal structure of\nthe data and automatically decompose nonlinear dynamics into stochastic\nswitching linear dynamical systems. Moreover, we show how this framework of\nswitching models enables extracting hierarchies of Markovian and\nauto-regressive locally linear controllers from nonlinear experts in an\nimitation learning scenario.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 12:40:59 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 14:54:33 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Abdulsamad", "Hany", ""], ["Peters", "Jan", ""]]}, {"id": "2005.01446", "submitter": "Aly El Gamal", "authors": "Abu Shafin Mohammad Mahdee Jameel, Ahmed P. Mohamed, Xiwen Zhang, Aly\n  El Gamal", "title": "Deep Learning for Frame Error Prediction using a DARPA Spectrum\n  Collaboration Challenge (SC2) Dataset", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate a first example for employing deep learning in predicting\nframe errors for a Collaborative Intelligent Radio Network (CIRN) using a\ndataset collected during participation in the final scrimmages of the DARPA SC2\nchallenge. Four scenarios are considered based on randomizing or fixing the\nstrategy for bandwidth and channel allocation, and either training and testing\nwith different links or using a pilot phase for each link to train the deep\nneural network. We also investigate the effect of latency constraints, and\nuncover interesting characteristics of the predictor over different Signal to\nNoise Ratio (SNR) ranges. The obtained insights open the door for implementing\na deep-learning-based strategy that is scalable to large heterogeneous\nnetworks, generalizable to diverse wireless environments, and suitable for\npredicting frame error instances and rates within a congested shared spectrum.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 04:53:38 GMT"}, {"version": "v2", "created": "Fri, 25 Dec 2020 01:32:56 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Jameel", "Abu Shafin Mohammad Mahdee", ""], ["Mohamed", "Ahmed P.", ""], ["Zhang", "Xiwen", ""], ["Gamal", "Aly El", ""]]}, {"id": "2005.01449", "submitter": "Chun-Guang Li", "authors": "Ying Chen, Chun-Guang Li, and Chong You", "title": "Stochastic Sparse Subspace Clustering", "comments": "16 pages, 9 figures and 8 tables. This work is accepted by IEEE\n  Conference on Computer Vision and Pattern Recognition (CVPR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art subspace clustering methods are based on self-expressive\nmodel, which represents each data point as a linear combination of other data\npoints. By enforcing such representation to be sparse, sparse subspace\nclustering is guaranteed to produce a subspace-preserving data affinity where\ntwo points are connected only if they are from the same subspace. On the other\nhand, however, data points from the same subspace may not be well-connected,\nleading to the issue of over-segmentation. We introduce dropout to address the\nissue of over-segmentation, which is based on randomly dropping out data points\nin self-expressive model. In particular, we show that dropout is equivalent to\nadding a squared $\\ell_2$ norm regularization on the representation\ncoefficients, therefore induces denser solutions. Then, we reformulate the\noptimization problem as a consensus problem over a set of small-scale\nsubproblems. This leads to a scalable and flexible sparse subspace clustering\napproach, termed Stochastic Sparse Subspace Clustering, which can effectively\nhandle large scale datasets. Extensive experiments on synthetic data and real\nworld datasets validate the efficiency and effectiveness of our proposal.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 13:09:17 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Chen", "Ying", ""], ["Li", "Chun-Guang", ""], ["You", "Chong", ""]]}, {"id": "2005.01452", "submitter": "Marco Melis", "authors": "Marco Melis, Michele Scalas, Ambra Demontis, Davide Maiorca, Battista\n  Biggio, Giorgio Giacinto, Fabio Roli", "title": "Do Gradient-based Explanations Tell Anything About Adversarial\n  Robustness to Android Malware?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine-learning algorithms have demonstrated a strong ability in\ndetecting Android malware, they can be evaded by sparse evasion attacks crafted\nby injecting a small set of fake components, e.g., permissions and system\ncalls, without compromising intrusive functionality. Previous work has shown\nthat, to improve robustness against such attacks, learning algorithms should\navoid overemphasizing few discriminant features, providing instead decisions\nthat rely upon a large subset of components. In this work, we investigate\nwhether gradient-based attribution methods, used to explain classifiers'\ndecisions by identifying the most relevant features, can be used to help\nidentify and select more robust algorithms. To this end, we propose to exploit\ntwo different metrics that represent the evenness of explanations, and a new\ncompact security measure called Adversarial Robustness Metric. Our experiments\nconducted on two different datasets and five classification algorithms for\nAndroid malware detection show that a strong connection exists between the\nuniformity of explanations and adversarial robustness. In particular, we found\nthat popular techniques like Gradient*Input and Integrated Gradients are\nstrongly correlated to security when applied to both linear and nonlinear\ndetectors, while more elementary explanation techniques like the simple\nGradient do not provide reliable information about the robustness of such\nclassifiers.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 13:12:31 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 15:58:04 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Melis", "Marco", ""], ["Scalas", "Michele", ""], ["Demontis", "Ambra", ""], ["Maiorca", "Davide", ""], ["Biggio", "Battista", ""], ["Giacinto", "Giorgio", ""], ["Roli", "Fabio", ""]]}, {"id": "2005.01463", "submitter": "Chiyu Jiang", "authors": "Chiyu Max Jiang, Soheil Esmaeilzadeh, Kamyar Azizzadenesheli, Karthik\n  Kashinath, Mustafa Mustafa, Hamdi A. Tchelepi, Philip Marcus, Prabhat, Anima\n  Anandkumar", "title": "MeshfreeFlowNet: A Physics-Constrained Deep Continuous Space-Time\n  Super-Resolution Framework", "comments": "Supplementary Video: https://youtu.be/mjqwPch9gDo. Accepted to SC20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose MeshfreeFlowNet, a novel deep learning-based super-resolution\nframework to generate continuous (grid-free) spatio-temporal solutions from the\nlow-resolution inputs. While being computationally efficient, MeshfreeFlowNet\naccurately recovers the fine-scale quantities of interest. MeshfreeFlowNet\nallows for: (i) the output to be sampled at all spatio-temporal resolutions,\n(ii) a set of Partial Differential Equation (PDE) constraints to be imposed,\nand (iii) training on fixed-size inputs on arbitrarily sized spatio-temporal\ndomains owing to its fully convolutional encoder. We empirically study the\nperformance of MeshfreeFlowNet on the task of super-resolution of turbulent\nflows in the Rayleigh-Benard convection problem. Across a diverse set of\nevaluation metrics, we show that MeshfreeFlowNet significantly outperforms\nexisting baselines. Furthermore, we provide a large scale implementation of\nMeshfreeFlowNet and show that it efficiently scales across large clusters,\nachieving 96.80% scaling efficiency on up to 128 GPUs and a training time of\nless than 4 minutes.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 05:29:25 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 04:08:23 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Jiang", "Chiyu Max", ""], ["Esmaeilzadeh", "Soheil", ""], ["Azizzadenesheli", "Kamyar", ""], ["Kashinath", "Karthik", ""], ["Mustafa", "Mustafa", ""], ["Tchelepi", "Hamdi A.", ""], ["Marcus", "Philip", ""], ["Prabhat", "", ""], ["Anandkumar", "Anima", ""]]}, {"id": "2005.01468", "submitter": "Dailin Lv", "authors": "Dailin Lv, Wuteng Qi, Yunxiang Li, Lingling Sun, Yaqi Wang", "title": "A cascade network for Detecting COVID-19 using chest x-rays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The worldwide spread of pneumonia caused by a novel coronavirus poses an\nunprecedented challenge to the world's medical resources and prevention and\ncontrol measures. Covid-19 attacks not only the lungs, making it difficult to\nbreathe and life-threatening, but also the heart, kidneys, brain and other\nvital organs of the body, with possible sequela. At present, the detection of\nCOVID-19 needs to be realized by the reverse transcription-polymerase Chain\nReaction (RT-PCR). However, many countries are in the outbreak period of the\nepidemic, and the medical resources are very limited. They cannot provide\nsufficient numbers of gene sequence detection, and many patients may not be\nisolated and treated in time. Given this situation, we researched the\nanalytical and diagnostic capabilities of deep learning on chest radiographs\nand proposed Cascade-SEMEnet which is cascaded with SEME-ResNet50 and\nSEME-DenseNet169. The two cascade networks of Cascade - SEMEnet both adopt\nlarge input sizes and SE-Structure and use MoEx and histogram equalization to\nenhance the data. We first used SEME-ResNet50 to screen chest X-ray and\ndiagnosed three classes: normal, bacterial, and viral pneumonia. Then we used\nSEME-DenseNet169 for fine-grained classification of viral pneumonia and\ndetermined if it is caused by COVID-19. To exclude the influence of\nnon-pathological features on the network, we preprocessed the data with U-Net\nduring the training of SEME-DenseNet169. The results showed that our network\nachieved an accuracy of 85.6\\% in determining the type of pneumonia infection\nand 97.1\\% in the fine-grained classification of COVID-19. We used Grad-CAM to\nvisualize the judgment based on the model and help doctors understand the chest\nradiograph while verifying the effectivene.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 09:56:56 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Lv", "Dailin", ""], ["Qi", "Wuteng", ""], ["Li", "Yunxiang", ""], ["Sun", "Lingling", ""], ["Wang", "Yaqi", ""]]}, {"id": "2005.01472", "submitter": "Usama Masood", "authors": "Shruti Bothe, Usama Masood, Hasan Farooq, Ali Imran", "title": "Neuromorphic AI Empowered Root Cause Analysis of Faults in Emerging\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile cellular network operators spend nearly a quarter of their revenue on\nnetwork maintenance and management. A significant portion of that budget is\nspent on resolving faults diagnosed in the system that disrupt or degrade\ncellular services. Historically, the operations to detect, diagnose and resolve\nissues were carried out by human experts. However, with diversifying cell\ntypes, increased complexity and growing cell density, this methodology is\nbecoming less viable, both technically and financially. To cope with this\nproblem, in recent years, research on self-healing solutions has gained\nsignificant momentum. One of the most desirable features of the self-healing\nparadigm is automated fault diagnosis. While several fault detection and\ndiagnosis machine learning models have been proposed recently, these schemes\nhave one common tenancy of relying on human expert contribution for fault\ndiagnosis and prediction in one way or another. In this paper, we propose an\nAI-based fault diagnosis solution that offers a key step towards a completely\nautomated self-healing system without requiring human expert input. The\nproposed solution leverages Random Forests classifier, Convolutional Neural\nNetwork and neuromorphic based deep learning model which uses RSRP map images\nof faults generated. We compare the performance of the proposed solution\nagainst state-of-the-art solution in literature that mostly use Naive Bayes\nmodels, while considering seven different fault types. Results show that\nneuromorphic computing model achieves high classification accuracy as compared\nto the other models even with relatively small training data\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 13:26:56 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Bothe", "Shruti", ""], ["Masood", "Usama", ""], ["Farooq", "Hasan", ""], ["Imran", "Ali", ""]]}, {"id": "2005.01474", "submitter": "Usama Masood", "authors": "Joel Shodamola, Usama Masood, Marvin Manalastas, Ali Imran", "title": "A Machine Learning based Framework for KPI Maximization in Emerging\n  Networks using Mobility Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current LTE network is faced with a plethora of Configuration and\nOptimization Parameters (COPs), both hard and soft, that are adjusted manually\nto manage the network and provide better Quality of Experience (QoE). With 5G\nin view, the number of these COPs are expected to reach 2000 per site, making\ntheir manual tuning for finding the optimal combination of these parameters, an\nimpossible fleet. Alongside these thousands of COPs is the anticipated network\ndensification in emerging networks which exacerbates the burden of the network\noperators in managing and optimizing the network. Hence, we propose a machine\nlearning-based framework combined with a heuristic technique to discover the\noptimal combination of two pertinent COPs used in mobility, Cell Individual\nOffset (CIO) and Handover Margin (HOM), that maximizes a specific Key\nPerformance Indicator (KPI) such as mean Signal to Interference and Noise Ratio\n(SINR) of all the connected users. The first part of the framework leverages\nthe power of machine learning to predict the KPI of interest given several\ndifferent combinations of CIO and HOM. The resulting predictions are then fed\ninto Genetic Algorithm (GA) which searches for the best combination of the two\nmentioned parameters that yield the maximum mean SINR for all users.\nPerformance of the framework is also evaluated using several machine learning\ntechniques, with CatBoost algorithm yielding the best prediction performance.\nMeanwhile, GA is able to reveal the optimal parameter setting combination more\nefficiently and with three orders of magnitude faster convergence time in\ncomparison to brute force approach.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 13:28:04 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Shodamola", "Joel", ""], ["Masood", "Usama", ""], ["Manalastas", "Marvin", ""], ["Imran", "Ali", ""]]}, {"id": "2005.01492", "submitter": "Xiancai Tian", "authors": "Xiancai Tian, Baihua Zheng, Yazhe Wang, Hsiao-Ting Huang, Chih-Chieh\n  Hung", "title": "TRIPDECODER: Study Travel Time Attributes and Route Preferences of Metro\n  Systems from Smart Card Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we target at recovering the exact routes taken by commuters\ninside a metro system that arenot captured by an Automated Fare Collection\n(AFC) system and hence remain unknown. We strategicallypropose two inference\ntasks to handle the recovering, one to infer the travel time of each travel\nlink thatcontributes to the total duration of any trip inside a metro network\nand the other to infer the route preferencesbased on historical trip records\nand the travel time of each travel link inferred in the previous inferencetask.\nAs these two inference tasks have interrelationship, most of existing works\nperform these two taskssimultaneously. However, our solutionTripDecoderadopts a\ntotally different approach. To the best of ourknowledge,TripDecoderis the first\nmodel that points out and fully utilizes the fact that there are some\ntripsinside a metro system with only one practical route available. It\nstrategically decouples these two inferencetasks by only taking those trip\nrecords with only one practical route as the input for the first inference\ntaskof travel time and feeding the inferred travel time to the second inference\ntask as an additional input whichnot only improves the accuracy but also\neffectively reduces the complexity of both inference tasks. Twocase studies\nhave been performed based on the city-scale real trip records captured by the\nAFC systems inSingapore and Taipei to compare the accuracy and efficiency\nofTripDecoderand its competitors. As expected,TripDecoderhas achieved the best\naccuracy in both datasets, and it also demonstrates its superior efficiencyand\nscalability.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 08:39:48 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Tian", "Xiancai", ""], ["Zheng", "Baihua", ""], ["Wang", "Yazhe", ""], ["Huang", "Hsiao-Ting", ""], ["Hung", "Chih-Chieh", ""]]}, {"id": "2005.01494", "submitter": "Dani Korpi", "authors": "Mikko Honkala, Dani Korpi, Janne M.J. Huttunen", "title": "DeepRx: Fully Convolutional Deep Learning Receiver", "comments": "32 pages, this work has been submitted to the IEEE for possible\n  publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has solved many problems that are out of reach of heuristic\nalgorithms. It has also been successfully applied in wireless communications,\neven though the current radio systems are well-understood and optimal\nalgorithms exist for many tasks. While some gains have been obtained by\nlearning individual parts of a receiver, a better approach is to jointly learn\nthe whole receiver. This, however, often results in a challenging nonlinear\nproblem, for which the optimal solution is infeasible to implement. To this\nend, we propose a deep fully convolutional neural network, DeepRx, which\nexecutes the whole receiver pipeline from frequency domain signal stream to\nuncoded bits in a 5G-compliant fashion. We facilitate accurate channel\nestimation by constructing the input of the convolutional neural network in a\nvery specific manner using both the data and pilot symbols. Also, DeepRx\noutputs soft bits that are compatible with the channel coding used in 5G\nsystems. Using 3GPP-defined channel models, we demonstrate that DeepRx\noutperforms traditional methods. We also show that the high performance can\nlikely be attributed to DeepRx learning to utilize the known constellation\npoints of the unknown data symbols, together with the local symbol\ndistribution, for improved detection accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 13:53:47 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 12:40:04 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Honkala", "Mikko", ""], ["Korpi", "Dani", ""], ["Huttunen", "Janne M. J.", ""]]}, {"id": "2005.01499", "submitter": "Nupur Kumari", "authors": "Gunjan Aggarwal, Abhishek Sinha, Nupur Kumari, Mayank Singh", "title": "On the Benefits of Models with Perceptually-Aligned Gradients", "comments": "Accepted at ICLR 2020 Workshop: Towards Trustworthy ML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial robust models have been shown to learn more robust and\ninterpretable features than standard trained models. As shown in\n[\\cite{tsipras2018robustness}], such robust models inherit useful interpretable\nproperties where the gradient aligns perceptually well with images, and adding\na large targeted adversarial perturbation leads to an image resembling the\ntarget class. We perform experiments to show that interpretable and\nperceptually aligned gradients are present even in models that do not show high\nrobustness to adversarial attacks. Specifically, we perform adversarial\ntraining with attack for different max-perturbation bound. Adversarial training\nwith low max-perturbation bound results in models that have interpretable\nfeatures with only slight drop in performance over clean samples. In this\npaper, we leverage models with interpretable perceptually-aligned features and\nshow that adversarial training with low max-perturbation bound can improve the\nperformance of models for zero-shot and weakly supervised localization tasks.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 14:05:38 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Aggarwal", "Gunjan", ""], ["Sinha", "Abhishek", ""], ["Kumari", "Nupur", ""], ["Singh", "Mayank", ""]]}, {"id": "2005.01520", "submitter": "Doris Xin", "authors": "Angela Lee, Doris Xin, Doris Lee, Aditya Parameswaran", "title": "Demystifying a Dark Art: Understanding Real-World Machine Learning Model\n  Development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that the process of developing machine learning (ML)\nworkflows is a dark-art; even experts struggle to find an optimal workflow\nleading to a high accuracy model. Users currently rely on empirical\ntrial-and-error to obtain their own set of battle-tested guidelines to inform\ntheir modeling decisions. In this study, we aim to demystify this dark art by\nunderstanding how people iterate on ML workflows in practice. We analyze over\n475k user-generated workflows on OpenML, an open-source platform for tracking\nand sharing ML workflows. We find that users often adopt a manual, automated,\nor mixed approach when iterating on their workflows. We observe that manual\napproaches result in fewer wasted iterations compared to automated approaches.\nYet, automated approaches often involve more preprocessing and hyperparameter\noptions explored, resulting in higher performance overall--suggesting potential\nbenefits for a human-in-the-loop ML system that appropriately recommends a\nclever combination of the two strategies.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 14:33:39 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Lee", "Angela", ""], ["Xin", "Doris", ""], ["Lee", "Doris", ""], ["Parameswaran", "Aditya", ""]]}, {"id": "2005.01529", "submitter": "Joseph Gaudio", "authors": "Joseph E. Gaudio, Anuradha M. Annaswamy, Jos\\'e M. Moreu, Michael A.\n  Bolender, Travis E. Gibson", "title": "Accelerated Learning with Robustness to Adversarial Regressors", "comments": "L4DC 2021 Full Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High order momentum-based parameter update algorithms have seen widespread\napplications in training machine learning models. Recently, connections with\nvariational approaches have led to the derivation of new learning algorithms\nwith accelerated learning guarantees. Such methods however, have only\nconsidered the case of static regressors. There is a significant need for\nparameter update algorithms which can be proven stable in the presence of\nadversarial time-varying regressors, as is commonplace in control theory. In\nthis paper, we propose a new discrete time algorithm which 1) provides\nstability and asymptotic convergence guarantees in the presence of adversarial\nregressors by leveraging insights from adaptive control theory and 2) provides\nnon-asymptotic accelerated learning guarantees leveraging insights from convex\noptimization. In particular, our algorithm reaches an $\\epsilon$ sub-optimal\npoint in at most $\\tilde{\\mathcal{O}}(1/\\sqrt{\\epsilon})$ iterations when\nregressors are constant - matching lower bounds due to Nesterov of\n$\\Omega(1/\\sqrt{\\epsilon})$, up to a $\\log(1/\\epsilon)$ factor and provides\nguaranteed bounds for stability when regressors are time-varying. We provide\nnumerical experiments for a variant of Nesterov's provably hard convex\noptimization problem with time-varying regressors, as well as the problem of\nrecovering an image with a time-varying blur and noise using streaming data.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 14:42:49 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 15:37:30 GMT"}, {"version": "v3", "created": "Sat, 5 Jun 2021 00:15:51 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Gaudio", "Joseph E.", ""], ["Annaswamy", "Anuradha M.", ""], ["Moreu", "Jos\u00e9 M.", ""], ["Bolender", "Michael A.", ""], ["Gibson", "Travis E.", ""]]}, {"id": "2005.01538", "submitter": "Sandor Szedmak", "authors": "Sandor Szedmak (1), Anna Cichonska (1), Heli Julkunen (1), Tapio\n  Pahikkala (2), Juho Rousu (1), ((1) Aalto University, (2) University of\n  Turku)", "title": "A Solution for Large Scale Nonlinear Regression with High Rank and\n  Degree at Constant Memory Complexity via Latent Tensor Reconstruction", "comments": "14 pages, 8 figures, uses arxiv.sty", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel method for learning highly nonlinear,\nmultivariate functions from examples. Our method takes advantage of the\nproperty that continuous functions can be approximated by polynomials, which in\nturn are representable by tensors. Hence the function learning problem is\ntransformed into a tensor reconstruction problem, an inverse problem of the\ntensor decomposition. Our method incrementally builds up the unknown tensor\nfrom rank-one terms, which lets us control the complexity of the learned model\nand reduce the chance of overfitting. For learning the models, we present an\nefficient gradient-based algorithm that can be implemented in linear time in\nthe sample size, order, rank of the tensor and the dimension of the input. In\naddition to regression, we present extensions to classification, multi-view\nlearning and vector-valued output as well as a multi-layered formulation. The\nmethod can work in an online fashion via processing mini-batches of the data\nwith constant memory complexity. Consequently, it can fit into systems equipped\nonly with limited resources such as embedded systems or mobile phones. Our\nexperiments demonstrate a favorable accuracy and running time compared to\ncompeting methods.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 14:49:14 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Szedmak", "Sandor", ""], ["Cichonska", "Anna", ""], ["Julkunen", "Heli", ""], ["Pahikkala", "Tapio", ""], ["Rousu", "Juho", ""]]}, {"id": "2005.01557", "submitter": "Rama K Vasudevan", "authors": "Rama K. Vasudevan, Maxim Ziatdinov, Lukas Vlcek, Sergei V. Kalinin", "title": "Off-the-shelf deep learning is not enough: parsimony, Bayes and\n  causality", "comments": "3 figures, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cond-mat.dis-nn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (\"deep learning\") have emerged as a technology of choice\nto tackle problems in natural language processing, computer vision, speech\nrecognition and gameplay, and in just a few years has led to superhuman level\nperformance and ushered in a new wave of \"AI.\" Buoyed by these successes,\nresearchers in the physical sciences have made steady progress in incorporating\ndeep learning into their respective domains. However, such adoption brings\nsubstantial challenges that need to be recognized and confronted. Here, we\ndiscuss both opportunities and roadblocks to implementation of deep learning\nwithin materials science, focusing on the relationship between correlative\nnature of machine learning and causal hypothesis driven nature of physical\nsciences. We argue that deep learning and AI are now well positioned to\nrevolutionize fields where causal links are known, as is the case for\napplications in theory. When confounding factors are frozen or change only\nweakly, this leaves open the pathway for effective deep learning solutions in\nexperimental domains. Similarly, these methods offer a pathway towards\nunderstanding the physics of real-world systems, either via deriving reduced\nrepresentations, deducing algorithmic complexity, or recovering generative\nphysical models. However, extending deep learning and \"AI\" for models with\nunclear causal relationship can produce misleading and potentially incorrect\nresults. Here, we argue the broad adoption of Bayesian methods incorporating\nprior knowledge, development of DL solutions with incorporated physical\nconstraints, and ultimately adoption of causal models, offers a path forward\nfor fundamental and applied research. Most notably, while these advances can\nchange the way science is carried out in ways we cannot imagine, machine\nlearning is not going to substitute science any time soon.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 15:16:30 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Vasudevan", "Rama K.", ""], ["Ziatdinov", "Maxim", ""], ["Vlcek", "Lukas", ""], ["Kalinin", "Sergei V.", ""]]}, {"id": "2005.01560", "submitter": "Burak \\c{C}akmak", "authors": "Burak \\c{C}akmak and Manfred Opper", "title": "A Dynamical Mean-Field Theory for Learning in Restricted Boltzmann\n  Machines", "comments": "29 pages, 2 figures", "journal-ref": null, "doi": "10.1088/1742-5468/abb8c9", "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a message-passing algorithm for computing magnetizations in\nRestricted Boltzmann machines, which are Ising models on bipartite graphs\nintroduced as neural network models for probability distributions over spin\nconfigurations. To model nontrivial statistical dependencies between the spins'\ncouplings, we assume that the rectangular coupling matrix is drawn from an\narbitrary bi-rotation invariant random matrix ensemble. Using the dynamical\nfunctional method of statistical mechanics we exactly analyze the dynamics of\nthe algorithm in the large system limit. We prove the global convergence of the\nalgorithm under a stability criterion and compute asymptotic convergence rates\nshowing excellent agreement with numerical simulations.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 15:19:31 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["\u00c7akmak", "Burak", ""], ["Opper", "Manfred", ""]]}, {"id": "2005.01566", "submitter": "Amitabha Bagchi", "authors": "Amitabha Bagchi", "title": "Lecture notes: Efficient approximation of kernel functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These lecture notes endeavour to collect in one place the mathematical\nbackground required to understand the properties of kernels in general and the\nRandom Fourier Features approximation of Rahimi and Recht (NIPS 2007) in\nparticular. We briefly motivate the use of kernels in Machine Learning with the\nexample of the support vector machine. We discuss positive definite and\nconditionally negative definite kernels in some detail. After a brief\ndiscussion of Hilbert spaces, including the Reproducing Kernel Hilbert Space\nconstruction, we present Mercer's theorem. We discuss the Random Fourier\nFeatures technique and then present, with proofs, scalar and matrix\nconcentration results that help us estimate the error incurred by the\ntechnique. These notes are the transcription of 10 lectures given at IIT Delhi\nbetween January and April 2020.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 15:30:06 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Bagchi", "Amitabha", ""]]}, {"id": "2005.01571", "submitter": "Qingyun Wu", "authors": "Qingyun Wu, Chi Wang, Silu Huang", "title": "Frugal Optimization for Cost-related Hyperparameters", "comments": "29 pages (including supplementary appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increasing demand for democratizing machine learning algorithms calls for\nhyperparameter optimization (HPO) solutions at low cost. Many machine learning\nalgorithms have hyperparameters which can cause a large variation in the\ntraining cost. But this effect is largely ignored in existing HPO methods,\nwhich are incapable to properly control cost during the optimization process.\nTo address this problem, we develop a new cost-frugal HPO solution. The core of\nour solution is a simple but new randomized direct-search method, for which we\nprove a convergence rate of $O(\\frac{\\sqrt{d}}{\\sqrt{K}})$ and an\n$O(d\\epsilon^{-2})$-approximation guarantee on the total cost. We provide\nstrong empirical results in comparison with state-of-the-art HPO methods on\nlarge AutoML benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 15:40:44 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 04:47:31 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 20:48:40 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Wu", "Qingyun", ""], ["Wang", "Chi", ""], ["Huang", "Silu", ""]]}, {"id": "2005.01573", "submitter": "Fei Mi", "authors": "Fei Mi, Boi Faltings", "title": "Memory Augmented Neural Model for Incremental Session-based\n  Recommendation", "comments": "Accepted as a full paper at IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing concerns with privacy have stimulated interests in Session-based\nRecommendation (SR) using no personal data other than what is observed in the\ncurrent browser session. Existing methods are evaluated in static settings\nwhich rarely occur in real-world applications. To better address the dynamic\nnature of SR tasks, we study an incremental SR scenario, where new items and\npreferences appear continuously. We show that existing neural recommenders can\nbe used in incremental SR scenarios with small incremental updates to alleviate\ncomputation overhead and catastrophic forgetting. More importantly, we propose\na general framework called Memory Augmented Neural model (MAN). MAN augments a\nbase neural recommender with a continuously queried and updated nonparametric\nmemory, and the predictions from the neural and the memory components are\ncombined through another lightweight gating network. We empirically show that\nMAN is well-suited for the incremental SR task, and it consistently outperforms\nstate-of-the-art neural and nonparametric methods. We analyze the results and\ndemonstrate that it is particularly good at incrementally learning preferences\non new and infrequent items.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 19:07:20 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Mi", "Fei", ""], ["Faltings", "Boi", ""]]}, {"id": "2005.01575", "submitter": "Angelos Chatzimparmpas", "authors": "Angelos Chatzimparmpas, Rafael M. Martins, Kostiantyn Kucher, Andreas\n  Kerren", "title": "StackGenVis: Alignment of Data, Algorithms, and Models for Stacking\n  Ensemble Learning Using Performance Metrics", "comments": "This manuscript is accepted for publication in a special issue of\n  IEEE Transactions on Visualization and Computer Graphics Journal (IEEE TVCG)", "journal-ref": "IEEE TVCG 2021, 27(2), 1547-1557", "doi": "10.1109/TVCG.2020.3030352", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning (ML), ensemble methods such as bagging, boosting, and\nstacking are widely-established approaches that regularly achieve top-notch\npredictive performance. Stacking (also called \"stacked generalization\") is an\nensemble method that combines heterogeneous base models, arranged in at least\none layer, and then employs another metamodel to summarize the predictions of\nthose models. Although it may be a highly-effective approach for increasing the\npredictive performance of ML, generating a stack of models from scratch can be\na cumbersome trial-and-error process. This challenge stems from the enormous\nspace of available solutions, with different sets of data instances and\nfeatures that could be used for training, several algorithms to choose from,\nand instantiations of these algorithms using diverse parameters (i.e., models)\nthat perform differently according to various metrics. In this work, we present\na knowledge generation model, which supports ensemble learning with the use of\nvisualization, and a visual analytics system for stacked generalization. Our\nsystem, StackGenVis, assists users in dynamically adapting performance metrics,\nmanaging data instances, selecting the most important features for a given data\nset, choosing a set of top-performant and diverse algorithms, and measuring the\npredictive performance. In consequence, our proposed tool helps users to decide\nbetween distinct models and to reduce the complexity of the resulting stack by\nremoving overpromising and underperforming models. The applicability and\neffectiveness of StackGenVis are demonstrated with two use cases: a real-world\nhealthcare data set and a collection of data related to sentiment/stance\ndetection in texts. Finally, the tool has been evaluated through interviews\nwith three ML experts.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 15:43:55 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 11:24:33 GMT"}, {"version": "v3", "created": "Fri, 14 Aug 2020 23:11:02 GMT"}, {"version": "v4", "created": "Thu, 20 Aug 2020 13:31:01 GMT"}, {"version": "v5", "created": "Mon, 24 Aug 2020 20:12:29 GMT"}, {"version": "v6", "created": "Fri, 28 Aug 2020 13:25:32 GMT"}, {"version": "v7", "created": "Thu, 17 Sep 2020 05:09:01 GMT"}, {"version": "v8", "created": "Tue, 1 Dec 2020 20:44:22 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Chatzimparmpas", "Angelos", ""], ["Martins", "Rafael M.", ""], ["Kucher", "Kostiantyn", ""], ["Kerren", "Andreas", ""]]}, {"id": "2005.01577", "submitter": "Mingkui Tan", "authors": "Yifan Zhang, Shuaicheng Niu, Zhen Qiu, Ying Wei, Peilin Zhao, Jianhua\n  Yao, Junzhou Huang, Qingyao Wu, and Mingkui Tan", "title": "COVID-DA: Deep Domain Adaptation from Typical Pneumonia to COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The outbreak of novel coronavirus disease 2019 (COVID-19) has already\ninfected millions of people and is still rapidly spreading all over the globe.\nMost COVID-19 patients suffer from lung infection, so one important diagnostic\nmethod is to screen chest radiography images, e.g., X-Ray or CT images.\nHowever, such examinations are time-consuming and labor-intensive, leading to\nlimited diagnostic efficiency. To solve this issue, AI-based technologies, such\nas deep learning, have been used recently as effective computer-aided means to\nimprove diagnostic efficiency. However, one practical and critical difficulty\nis the limited availability of annotated COVID-19 data, due to the prohibitive\nannotation costs and urgent work of doctors to fight against the pandemic. This\nmakes the learning of deep diagnosis models very challenging. To address this,\nmotivated by that typical pneumonia has similar characteristics with COVID-19\nand many pneumonia datasets are publicly available, we propose to conduct\ndomain knowledge adaptation from typical pneumonia to COVID-19. There are two\nmain challenges: 1) the discrepancy of data distributions between domains; 2)\nthe task difference between the diagnosis of typical pneumonia and COVID-19. To\naddress them, we propose a new deep domain adaptation method for COVID-19\ndiagnosis, namely COVID-DA. Specifically, we alleviate the domain discrepancy\nvia feature adversarial adaptation and handle the task difference issue via a\nnovel classifier separation scheme. In this way, COVID-DA is able to diagnose\nCOVID-19 effectively with only a small number of COVID-19 annotations.\nExtensive experiments verify the effectiveness of COVID-DA and its great\npotential for real-world applications.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 03:13:40 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Zhang", "Yifan", ""], ["Niu", "Shuaicheng", ""], ["Qiu", "Zhen", ""], ["Wei", "Ying", ""], ["Zhao", "Peilin", ""], ["Yao", "Jianhua", ""], ["Huang", "Junzhou", ""], ["Wu", "Qingyao", ""], ["Tan", "Mingkui", ""]]}, {"id": "2005.01578", "submitter": "Pedro Ricardo Ariel Salvador Bassi Electrical Engineer", "authors": "Pedro R. A. S. Bassi, Romis Attux", "title": "A Deep Convolutional Neural Network for COVID-19 Detection Using Chest\n  X-Rays", "comments": null, "journal-ref": null, "doi": "10.1007/s42600-021-00132-9", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: We present image classifiers based on Dense Convolutional Networks\nand transfer learning to classify chest X-ray images according to three labels:\nCOVID-19, pneumonia and normal.\n  Methods: We fine-tuned neural networks pretrained on ImageNet and applied a\ntwice transfer learning approach, using NIH ChestX-ray14 dataset as an\nintermediate step. We also suggested a novelty called output neuron keeping,\nwhich changes the twice transfer learning technique. In order to clarify the\nmodus operandi of the models, we used Layer-wise Relevance Propagation (LRP) to\ngenerate heatmaps.\n  Results: We were able to reach test accuracy of 100% on our test dataset.\nTwice transfer learning and output neuron keeping showed promising results\nimproving performances, mainly in the beginning of the training process.\nAlthough LRP revealed that words on the X-rays can influence the networks'\npredictions, we discovered this had only a very small effect on accuracy.\n  Conclusion: Although clinical studies and larger datasets are still needed to\nfurther ensure good generalization, the state-of-the-art performances we\nachieved show that, with the help of artificial intelligence, chest X-rays can\nbecome a cheap and accurate auxiliary method for COVID-19 diagnosis. Heatmaps\ngenerated by LRP improve the interpretability of the deep neural networks and\nindicate an analytical path for future research on diagnosis. Twice transfer\nlearning with output neuron keeping improved performances.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 13:20:42 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 18:15:40 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 06:48:36 GMT"}, {"version": "v4", "created": "Wed, 13 Jan 2021 04:08:10 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Bassi", "Pedro R. A. S.", ""], ["Attux", "Romis", ""]]}, {"id": "2005.01583", "submitter": "Benjamin Lee", "authors": "Benjamin Charles Germain Lee, Jaime Mears, Eileen Jakeway, Meghan\n  Ferriter, Chris Adams, Nathan Yarasavage, Deborah Thomas, Kate Zwaard, Daniel\n  S. Weld", "title": "The Newspaper Navigator Dataset: Extracting And Analyzing Visual Content\n  from 16 Million Historic Newspaper Pages in Chronicling America", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Chronicling America is a product of the National Digital Newspaper Program, a\npartnership between the Library of Congress and the National Endowment for the\nHumanities to digitize historic newspapers. Over 16 million pages of historic\nAmerican newspapers have been digitized for Chronicling America to date,\ncomplete with high-resolution images and machine-readable METS/ALTO OCR. Of\nconsiderable interest to Chronicling America users is a semantified corpus,\ncomplete with extracted visual content and headlines. To accomplish this, we\nintroduce a visual content recognition model trained on bounding box\nannotations of photographs, illustrations, maps, comics, and editorial cartoons\ncollected as part of the Library of Congress's Beyond Words crowdsourcing\ninitiative and augmented with additional annotations including those of\nheadlines and advertisements. We describe our pipeline that utilizes this deep\nlearning model to extract 7 classes of visual content: headlines, photographs,\nillustrations, maps, comics, editorial cartoons, and advertisements, complete\nwith textual content such as captions derived from the METS/ALTO OCR, as well\nas image embeddings for fast image similarity querying. We report the results\nof running the pipeline on 16.3 million pages from the Chronicling America\ncorpus and describe the resulting Newspaper Navigator dataset, the largest\ndataset of extracted visual content from historic newspapers ever produced. The\nNewspaper Navigator dataset, finetuned visual content recognition model, and\nall source code are placed in the public domain for unrestricted re-use.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 15:51:13 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Lee", "Benjamin Charles Germain", ""], ["Mears", "Jaime", ""], ["Jakeway", "Eileen", ""], ["Ferriter", "Meghan", ""], ["Adams", "Chris", ""], ["Yarasavage", "Nathan", ""], ["Thomas", "Deborah", ""], ["Zwaard", "Kate", ""], ["Weld", "Daniel S.", ""]]}, {"id": "2005.01598", "submitter": "Maurizio Pierini", "authors": "Oliver Knapp and Guenther Dissertori and Olmo Cerri and Thong Q.\n  Nguyen and Jean-Roch Vlimant and Maurizio Pierini", "title": "Adversarially Learned Anomaly Detection on CMS Open Data: re-discovering\n  the top quark", "comments": "16 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ex cs.LG hep-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply an Adversarially Learned Anomaly Detection (ALAD) algorithm to the\nproblem of detecting new physics processes in proton-proton collisions at the\nLarge Hadron Collider. Anomaly detection based on ALAD matches performances\nreached by Variational Autoencoders, with a substantial improvement in some\ncases. Training the ALAD algorithm on 4.4 fb-1 of 8 TeV CMS Open Data, we show\nhow a data-driven anomaly detection and characterization would work in real\nlife, re-discovering the top quark by identifying the main features of the\nt-tbar experimental signature at the LHC.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 16:09:48 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 16:06:46 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Knapp", "Oliver", ""], ["Dissertori", "Guenther", ""], ["Cerri", "Olmo", ""], ["Nguyen", "Thong Q.", ""], ["Vlimant", "Jean-Roch", ""], ["Pierini", "Maurizio", ""]]}, {"id": "2005.01607", "submitter": "Tian Xia", "authors": "Tian Xia, Agisilaos Chartsias, Sotirios A. Tsaftaris", "title": "Pseudo-healthy synthesis with pathology disentanglement and adversarial\n  learning", "comments": "This paper has been accepted by Medical Image Analysis", "journal-ref": null, "doi": "10.1016/j.media.2020.101719", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pseudo-healthy synthesis is the task of creating a subject-specific `healthy'\nimage from a pathological one. Such images can be helpful in tasks such as\nanomaly detection and understanding changes induced by pathology and disease.\nIn this paper, we present a model that is encouraged to disentangle the\ninformation of pathology from what seems to be healthy. We disentangle what\nappears to be healthy and where disease is as a segmentation map, which are\nthen recombined by a network to reconstruct the input disease image. We train\nour models adversarially using either paired or unpaired settings, where we\npair disease images and maps when available. We quantitatively and\nsubjectively, with a human study, evaluate the quality of pseudo-healthy images\nusing several criteria. We show in a series of experiments, performed on ISLES,\nBraTS and Cam-CAN datasets, that our method is better than several baselines\nand methods from the literature. We also show that due to better training\nprocesses we could recover deformations, on surrounding tissue, caused by\ndisease. Our implementation is publicly available at\nhttps://github.com/xiat0616/pseudo-healthy-synthesis. This paper has been\naccepted by Medical Image Analysis:\nhttps://doi.org/10.1016/j.media.2020.101719.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 15:38:05 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 12:33:28 GMT"}, {"version": "v3", "created": "Fri, 18 Jun 2021 11:39:10 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Xia", "Tian", ""], ["Chartsias", "Agisilaos", ""], ["Tsaftaris", "Sotirios A.", ""]]}, {"id": "2005.01609", "submitter": "Xingyu Li", "authors": "Xingyu Li, Konstantinos N. Plataniotis", "title": "How Much Off-The-Shelf Knowledge Is Transferable From Natural Images To\n  Pathology Images?", "comments": "Experimentation data correction", "journal-ref": null, "doi": "10.1371/journal.pone.0240530", "report-no": null, "categories": "eess.IV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved a great success in natural image classification.\nTo overcome data-scarcity in computational pathology, recent studies exploit\ntransfer learning to reuse knowledge gained from natural images in pathology\nimage analysis, aiming to build effective pathology image diagnosis models.\nSince transferability of knowledge heavily depends on the similarity of the\noriginal and target tasks, significant differences in image content and\nstatistics between pathology images and natural images raise the questions: how\nmuch knowledge is transferable? Is the transferred information equally\ncontributed by pre-trained layers? To answer these questions, this paper\nproposes a framework to quantify knowledge gain by a particular layer, conducts\nan empirical investigation in pathology image centered transfer learning, and\nreports some interesting observations. Particularly, compared to the\nperformance baseline obtained by random-weight model, though transferability of\noff-the-shelf representations from deep layers heavily depend on specific\npathology image sets, the general representation generated by early layers does\nconvey transferred knowledge in various image classification applications. The\nobservation in this study encourages further investigation of specific metric\nand tools to quantify effectiveness and feasibility of transfer learning in\nfuture.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 21:29:10 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 15:31:03 GMT"}, {"version": "v3", "created": "Sat, 9 May 2020 01:44:42 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Li", "Xingyu", ""], ["Plataniotis", "Konstantinos N.", ""]]}, {"id": "2005.01618", "submitter": "Ruiyi Zhang", "authors": "Ruiyi Zhang, Tong Yu, Yilin Shen, Hongxia Jin, Changyou Chen, Lawrence\n  Carin", "title": "Reward Constrained Interactive Recommendation with Natural Language\n  Feedback", "comments": "Appeared in NeurIPS 2019; Updated version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-based interactive recommendation provides richer user feedback and has\ndemonstrated advantages over traditional interactive recommender systems.\nHowever, recommendations can easily violate preferences of users from their\npast natural-language feedback, since the recommender needs to explore new\nitems for further improvement. To alleviate this issue, we propose a novel\nconstraint-augmented reinforcement learning (RL) framework to efficiently\nincorporate user preferences over time. Specifically, we leverage a\ndiscriminator to detect recommendations violating user historical preference,\nwhich is incorporated into the standard RL objective of maximizing expected\ncumulative future rewards. Our proposed framework is general and is further\nextended to the task of constrained text generation. Empirical results show\nthat the proposed method yields consistent improvement relative to standard RL\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 16:23:34 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Zhang", "Ruiyi", ""], ["Yu", "Tong", ""], ["Shen", "Yilin", ""], ["Jin", "Hongxia", ""], ["Chen", "Changyou", ""], ["Carin", "Lawrence", ""]]}, {"id": "2005.01627", "submitter": "Dimitri Bertsekas", "authors": "Dimitri Bertsekas", "title": "Multiagent Value Iteration Algorithms in Dynamic Programming and\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider infinite horizon dynamic programming problems, where the control\nat each stage consists of several distinct decisions, each one made by one of\nseveral agents. In an earlier work we introduced a policy iteration algorithm,\nwhere the policy improvement is done one-agent-at-a-time in a given order, with\nknowledge of the choices of the preceding agents in the order. As a result, the\namount of computation for each policy improvement grows linearly with the\nnumber of agents, as opposed to exponentially for the standard\nall-agents-at-once method. For the case of a finite-state discounted problem,\nwe showed convergence to an agent-by-agent optimal policy. In this paper, this\nresult is extended to value iteration and optimistic versions of policy\niteration, as well as to more general DP problems where the Bellman operator is\na contraction mapping, such as stochastic shortest path problems with all\npolicies being proper.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 16:34:24 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Bertsekas", "Dimitri", ""]]}, {"id": "2005.01643", "submitter": "Sergey Levine", "authors": "Sergey Levine, Aviral Kumar, George Tucker, Justin Fu", "title": "Offline Reinforcement Learning: Tutorial, Review, and Perspectives on\n  Open Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this tutorial article, we aim to provide the reader with the conceptual\ntools needed to get started on research on offline reinforcement learning\nalgorithms: reinforcement learning algorithms that utilize previously collected\ndata, without additional online data collection. Offline reinforcement learning\nalgorithms hold tremendous promise for making it possible to turn large\ndatasets into powerful decision making engines. Effective offline reinforcement\nlearning methods would be able to extract policies with the maximum possible\nutility out of the available data, thereby allowing automation of a wide range\nof decision-making domains, from healthcare and education to robotics. However,\nthe limitations of current algorithms make this difficult. We will aim to\nprovide the reader with an understanding of these challenges, particularly in\nthe context of modern deep reinforcement learning methods, and describe some\npotential solutions that have been explored in recent work to mitigate these\nchallenges, along with recent applications, and a discussion of perspectives on\nopen problems in the field.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 17:00:15 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 17:37:01 GMT"}, {"version": "v3", "created": "Sun, 1 Nov 2020 23:50:25 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Levine", "Sergey", ""], ["Kumar", "Aviral", ""], ["Tucker", "George", ""], ["Fu", "Justin", ""]]}, {"id": "2005.01646", "submitter": "Kartik Goyal", "authors": "Kartik Goyal, Chris Dyer, Christopher Warren, Max G'Sell, Taylor\n  Berg-Kirkpatrick", "title": "A Probabilistic Generative Model for Typographical Analysis of Early\n  Modern Printing", "comments": "To appear at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep and interpretable probabilistic generative model to analyze\nglyph shapes in printed Early Modern documents. We focus on clustering\nextracted glyph images into underlying templates in the presence of multiple\nconfounding sources of variance. Our approach introduces a neural editor model\nthat first generates well-understood printing phenomena like spatial\nperturbations from template parameters via interpertable latent variables, and\nthen modifies the result by generating a non-interpretable latent vector\nresponsible for inking variations, jitter, noise from the archiving process,\nand other unforeseen phenomena associated with Early Modern printing.\nCritically, by introducing an inference network whose input is restricted to\nthe visual residual between the observation and the interpretably-modified\ntemplate, we are able to control and isolate what the vector-valued latent\nvariable captures. We show that our approach outperforms rigid interpretable\nclustering baselines (Ocular) and overly-flexible deep generative models (VAE)\nalike on the task of completely unsupervised discovery of typefaces in\nmixed-font documents.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 17:01:11 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Goyal", "Kartik", ""], ["Dyer", "Chris", ""], ["Warren", "Christopher", ""], ["G'Sell", "Max", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "2005.01656", "submitter": "Matthieu Jedor", "authors": "Matthieu Jedor, Jonathan Louedec, Vianney Perchet", "title": "Categorized Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new stochastic multi-armed bandit setting where arms are\ngrouped inside ``ordered'' categories. The motivating example comes from\ne-commerce, where a customer typically has a greater appetence for items of a\nspecific well-identified but unknown category than any other one. We introduce\nthree concepts of ordering between categories, inspired by stochastic dominance\nbetween random variables, which are gradually weaker so that more and more\nbandit scenarios satisfy at least one of them. We first prove\ninstance-dependent lower bounds on the cumulative regret for each of these\nmodels, indicating how the complexity of the bandit problems increases with the\ngenerality of the ordering concept considered. We also provide algorithms that\nfully leverage the structure of the model with their associated theoretical\nguarantees. Finally, we have conducted an analysis on real data to highlight\nthat those ordered categories actually exist in practice.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 17:09:22 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Jedor", "Matthieu", ""], ["Louedec", "Jonathan", ""], ["Perchet", "Vianney", ""]]}, {"id": "2005.01669", "submitter": "Nabil Ibtehaz", "authors": "Nabil Ibtehaz, M. Sohel Rahman", "title": "PPG2ABP: Translating Photoplethysmogram (PPG) Signals to Arterial Blood\n  Pressure (ABP) Waveforms using Fully Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardiovascular diseases are one of the most severe causes of mortality,\ntaking a heavy toll of lives annually throughout the world. The continuous\nmonitoring of blood pressure seems to be the most viable option, but this\ndemands an invasive process, bringing about several layers of complexities.\nThis motivates us to develop a method to predict the continuous arterial blood\npressure (ABP) waveform through a non-invasive approach using\nphotoplethysmogram (PPG) signals. In addition we explore the advantage of deep\nlearning as it would free us from sticking to ideally shaped PPG signals only,\nby making handcrafted feature computation irrelevant, which is a shortcoming of\nthe existing approaches. Thus, we present, PPG2ABP, a deep learning based\nmethod, that manages to predict the continuous ABP waveform from the input PPG\nsignal, with a mean absolute error of 4.604 mmHg, preserving the shape,\nmagnitude and phase in unison. However, the more astounding success of PPG2ABP\nturns out to be that the computed values of DBP, MAP and SBP from the predicted\nABP waveform outperforms the existing works under several metrics, despite that\nPPG2ABP is not explicitly trained to do so.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 17:22:44 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Ibtehaz", "Nabil", ""], ["Rahman", "M. Sohel", ""]]}, {"id": "2005.01683", "submitter": "Neel Dey", "authors": "Neel Dey, Antong Chen, Soheil Ghafurian", "title": "Group Equivariant Generative Adversarial Networks", "comments": "Accepted by the International Conference on Learning Representations\n  (ICLR) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent improvements in generative adversarial visual synthesis incorporate\nreal and fake image transformation in a self-supervised setting, leading to\nincreased stability and perceptual fidelity. However, these approaches\ntypically involve image augmentations via additional regularizers in the GAN\nobjective and thus spend valuable network capacity towards approximating\ntransformation equivariance instead of their desired task. In this work, we\nexplicitly incorporate inductive symmetry priors into the network architectures\nvia group-equivariant convolutional networks. Group-convolutions have higher\nexpressive power with fewer samples and lead to better gradient feedback\nbetween generator and discriminator. We show that group-equivariance integrates\nseamlessly with recent techniques for GAN training across regularizers,\narchitectures, and loss functions. We demonstrate the utility of our methods\nfor conditional synthesis by improving generation in the limited data regime\nacross symmetric imaging datasets and even find benefits for natural images\nwith preferred orientation.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 17:38:49 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 18:00:21 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Dey", "Neel", ""], ["Chen", "Antong", ""], ["Ghafurian", "Soheil", ""]]}, {"id": "2005.01686", "submitter": "Andreas Hoepner PhD", "authors": "Alexander Arimond, Damian Borth, Andreas Hoepner, Michael Klawunn and\n  Stefan Weisheit", "title": "Neural Networks and Value at Risk", "comments": "2019 Financial Data Science Association Paper, San Francisco", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Utilizing a generative regime switching framework, we perform Monte-Carlo\nsimulations of asset returns for Value at Risk threshold estimation. Using\nequity markets and long term bonds as test assets in the global, US, Euro area\nand UK setting over an up to 1,250 weeks sample horizon ending in August 2018,\nwe investigate neural networks along three design steps relating (i) to the\ninitialization of the neural network, (ii) its incentive function according to\nwhich it has been trained and (iii) the amount of data we feed. First, we\ncompare neural networks with random seeding with networks that are initialized\nvia estimations from the best-established model (i.e. the Hidden Markov). We\nfind latter to outperform in terms of the frequency of VaR breaches (i.e. the\nrealized return falling short of the estimated VaR threshold). Second, we\nbalance the incentive structure of the loss function of our networks by adding\na second objective to the training instructions so that the neural networks\noptimize for accuracy while also aiming to stay in empirically realistic regime\ndistributions (i.e. bull vs. bear market frequencies). In particular this\ndesign feature enables the balanced incentive recurrent neural network (RNN) to\noutperform the single incentive RNN as well as any other neural network or\nestablished approach by statistically and economically significant levels.\nThird, we half our training data set of 2,000 days. We find our networks when\nfed with substantially less data (i.e. 1,000 days) to perform significantly\nworse which highlights a crucial weakness of neural networks in their\ndependence on very large data sets ...\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 17:41:59 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 10:22:13 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Arimond", "Alexander", ""], ["Borth", "Damian", ""], ["Hoepner", "Andreas", ""], ["Klawunn", "Michael", ""], ["Weisheit", "Stefan", ""]]}, {"id": "2005.01690", "submitter": "Fabio Miranda", "authors": "Zhicheng Liu, Fabio Miranda, Weiting Xiong, Junyan Yang, Qiao Wang,\n  Claudio T. Silva", "title": "Learning Geo-Contextual Embeddings for Commuting Flow Prediction", "comments": "Github: https://github.com/jackmiemie/GMEL", "journal-ref": "Thirty-Fourth AAAI Conference on Artificial Intelligence (2020)", "doi": "10.1609/aaai.v34i01.5425", "report-no": null, "categories": "physics.soc-ph cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting commuting flows based on infrastructure and land-use information\nis critical for urban planning and public policy development. However, it is a\nchallenging task given the complex patterns of commuting flows. Conventional\nmodels, such as gravity model, are mainly derived from physics principles and\nlimited by their predictive power in real-world scenarios where many factors\nneed to be considered. Meanwhile, most existing machine learning-based methods\nignore the spatial correlations and fail to model the influence of nearby\nregions. To address these issues, we propose Geo-contextual Multitask Embedding\nLearner (GMEL), a model that captures the spatial correlations from geographic\ncontextual information for commuting flow prediction. Specifically, we first\nconstruct a geo-adjacency network containing the geographic contextual\ninformation. Then, an attention mechanism is proposed based on the framework of\ngraph attention network (GAT) to capture the spatial correlations and encode\ngeographic contextual information to embedding space. Two separate GATs are\nused to model supply and demand characteristics. A multitask learning framework\nis used to introduce stronger restrictions and enhance the effectiveness of the\nembedding representation. Finally, a gradient boosting machine is trained based\non the learned embeddings to predict commuting flows. We evaluate our model\nusing real-world datasets from New York City and the experimental results\ndemonstrate the effectiveness of our proposal against the state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 17:45:18 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Liu", "Zhicheng", ""], ["Miranda", "Fabio", ""], ["Xiong", "Weiting", ""], ["Yang", "Junyan", ""], ["Wang", "Qiao", ""], ["Silva", "Claudio T.", ""]]}, {"id": "2005.01697", "submitter": "Alexey Melnikov", "authors": "Alexey A. Melnikov, Pavel Sekatski, Nicolas Sangouard", "title": "Setting up experimental Bell test with reinforcement learning", "comments": "12 pages, 9 figures", "journal-ref": "Phys. Rev. Lett. 125, 160401 (2020)", "doi": "10.1103/PhysRevLett.125.160401", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding optical setups producing measurement results with a targeted\nprobability distribution is hard as a priori the number of possible\nexperimental implementations grows exponentially with the number of modes and\nthe number of devices. To tackle this complexity, we introduce a method\ncombining reinforcement learning and simulated annealing enabling the automated\ndesign of optical experiments producing results with the desired probability\ndistributions. We illustrate the relevance of our method by applying it to a\nprobability distribution favouring high violations of the Bell-CHSH inequality.\nAs a result, we propose new unintuitive experiments leading to higher Bell-CHSH\ninequality violations than the best currently known setups. Our method might\npositively impact the usefulness of photonic experiments for device-independent\nquantum information processing.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 17:52:10 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Melnikov", "Alexey A.", ""], ["Sekatski", "Pavel", ""], ["Sangouard", "Nicolas", ""]]}, {"id": "2005.01698", "submitter": "Fredrik K. Gustafsson", "authors": "Fredrik K. Gustafsson, Martin Danelljan, Radu Timofte, Thomas B.\n  Sch\\\"on", "title": "How to Train Your Energy-Based Model for Regression", "comments": "BMVC 2020. Code is available at\n  https://github.com/fregu856/ebms_regression", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy-based models (EBMs) have become increasingly popular within computer\nvision in recent years. While they are commonly employed for generative image\nmodeling, recent work has applied EBMs also for regression tasks, achieving\nstate-of-the-art performance on object detection and visual tracking. Training\nEBMs is however known to be challenging. While a variety of different\ntechniques have been explored for generative modeling, the application of EBMs\nto regression is not a well-studied problem. How EBMs should be trained for\nbest possible regression performance is thus currently unclear. We therefore\naccept the task of providing the first detailed study of this problem. To that\nend, we propose a simple yet highly effective extension of noise contrastive\nestimation, and carefully compare its performance to six popular methods from\nliterature on the tasks of 1D regression and object detection. The results of\nthis comparison suggest that our training method should be considered the go-to\napproach. We also apply our method to the visual tracking task, achieving\nstate-of-the-art performance on five datasets. Notably, our tracker achieves\n63.7% AUC on LaSOT and 78.7% Success on TrackingNet. Code is available at\nhttps://github.com/fregu856/ebms_regression.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 17:55:01 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 10:08:52 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Gustafsson", "Fredrik K.", ""], ["Danelljan", "Martin", ""], ["Timofte", "Radu", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "2005.01699", "submitter": "Anirbit Mukherjee", "authors": "Anirbit Mukherjee and Ramchandran Muthukumar", "title": "Guarantees on learning depth-2 neural networks under a data-poisoning\n  attack", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent times many state-of-the-art machine learning models have been shown\nto be fragile to adversarial attacks. In this work we attempt to build our\ntheoretical understanding of adversarially robust learning with neural nets. We\ndemonstrate a specific class of neural networks of finite size and a\nnon-gradient stochastic algorithm which tries to recover the weights of the net\ngenerating the realizable true labels in the presence of an oracle doing a\nbounded amount of malicious additive distortion to the labels. We prove (nearly\noptimal) trade-offs among the magnitude of the adversarial attack, the accuracy\nand the confidence achieved by the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 17:56:15 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Mukherjee", "Anirbit", ""], ["Muthukumar", "Ramchandran", ""]]}, {"id": "2005.01711", "submitter": "Karush Suri", "authors": "Karush Suri, Rinki Gupta", "title": "Dual Stage Classification of Hand Gestures using Surface Electromyogram", "comments": "arXiv admin note: text overlap with arXiv:2005.00410", "journal-ref": null, "doi": "10.1109/SPIN.2018.8474145", "report-no": null, "categories": "eess.SP cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surface electromyography (sEMG) is becoming exceeding useful in applications\ninvolving analysis of human motion such as in human-machine interface,\nassistive technology, healthcare and prosthetic development. The proposed work\npresents a novel dual stage classification approach for classification of\ngrasping gestures from sEMG signals. A statistical assessment of these\nactivities is presented to determine the similar characteristics between the\nconsidered activities. Similar activities are grouped together. In the first\nstage of classification, an activity is identified as belonging to a group,\nwhich is then further classified as one of the activities within the group in\nthe second stage of classification. The performance of the proposed approach is\ncompared to the conventional single stage classification approach in terms of\nclassification accuracies. The classification accuracies obtained using the\nproposed dual stage classification are significantly higher as compared to that\nfor single stage classification.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 01:11:38 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Suri", "Karush", ""], ["Gupta", "Rinki", ""]]}, {"id": "2005.01752", "submitter": "Jonathan Tuck", "authors": "Jonathan Tuck, Stephen Boyd", "title": "Fitting Laplacian Regularized Stratified Gaussian Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of jointly estimating multiple related zero-mean\nGaussian distributions from data. We propose to jointly estimate these\ncovariance matrices using Laplacian regularized stratified model fitting, which\nincludes loss and regularization terms for each covariance matrix, and also a\nterm that encourages the different covariances matrices to be close. This\nmethod `borrows strength' from the neighboring covariances, to improve its\nestimate. With well chosen hyper-parameters, such models can perform very well,\nespecially in the low data regime. We propose a distributed method that scales\nto large problems, and illustrate the efficacy of the method with examples in\nfinance, radar signal processing, and weather forecasting.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 18:00:59 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 16:22:53 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Tuck", "Jonathan", ""], ["Boyd", "Stephen", ""]]}, {"id": "2005.01757", "submitter": "Lee Cohen", "authors": "Eliran Shabat, Lee Cohen and Yishay Mansour", "title": "Sample Complexity of Uniform Convergence for Multicalibration", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest in societal concerns in machine learning systems,\nespecially in fairness. Multicalibration gives a comprehensive methodology to\naddress group fairness. In this work, we address the multicalibration error and\ndecouple it from the prediction error. The importance of decoupling the\nfairness metric (multicalibration) and the accuracy (prediction error) is due\nto the inherent trade-off between the two, and the societal decision regarding\nthe \"right tradeoff\" (as imposed many times by regulators). Our work gives\nsample complexity bounds for uniform convergence guarantees of multicalibration\nerror, which implies that regardless of the accuracy, we can guarantee that the\nempirical and (true) multicalibration errors are close. We emphasize that our\nresults: (1) are more general than previous bounds, as they apply to both\nagnostic and realizable settings, and do not rely on a specific type of\nalgorithm (such as deferentially private), (2) improve over previous\nmulticalibration sample complexity bounds and (3) implies uniform convergence\nguarantees for the classical calibration error.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 18:01:38 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 15:28:21 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Shabat", "Eliran", ""], ["Cohen", "Lee", ""], ["Mansour", "Yishay", ""]]}, {"id": "2005.01795", "submitter": "Kundan Krishna", "authors": "Kundan Krishna, Sopan Khosla, Jeffrey P. Bigham, Zachary C. Lipton", "title": "Generating SOAP Notes from Doctor-Patient Conversations Using Modular\n  Summarization Techniques", "comments": "Published at ACL 2021 Main Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following each patient visit, physicians draft long semi-structured clinical\nsummaries called SOAP notes. While invaluable to clinicians and researchers,\ncreating digital SOAP notes is burdensome, contributing to physician burnout.\nIn this paper, we introduce the first complete pipelines to leverage deep\nsummarization models to generate these notes based on transcripts of\nconversations between physicians and patients. After exploring a spectrum of\nmethods across the extractive-abstractive spectrum, we propose Cluster2Sent, an\nalgorithm that (i) extracts important utterances relevant to each summary\nsection; (ii) clusters together related utterances; and then (iii) generates\none summary sentence per cluster. Cluster2Sent outperforms its purely\nabstractive counterpart by 8 ROUGE-1 points, and produces significantly more\nfactual and coherent sentences as assessed by expert human evaluators. For\nreproducibility, we demonstrate similar benefits on the publicly available AMI\ndataset. Our results speak to the benefits of structuring summaries into\nsections and annotating supporting evidence when constructing summarization\ncorpora.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 19:10:26 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 04:09:10 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 14:48:09 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Krishna", "Kundan", ""], ["Khosla", "Sopan", ""], ["Bigham", "Jeffrey P.", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2005.01797", "submitter": "Richard Jiang", "authors": "David Lonsdale, Li Zhang and Richard Jiang", "title": "3D Printed Brain-Controlled Robot-Arm Prosthetic via Embedded Deep\n  Learning from sEMG Sensors", "comments": "The 2020 International Conference on Machine Learning and Cybernetics\n  (ICMLC), http://www.icmlc.com/", "journal-ref": "ICMLC 2020", "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our work on developing robot arm prosthetic via\ndeep learning. Our work proposes to use transfer learning techniques applied to\nthe Google Inception model to retrain the final layer for surface\nelectromyography (sEMG) classification. Data have been collected using the\nThalmic Labs Myo Armband and used to generate graph images comprised of 8\nsubplots per image containing sEMG data captured from 40 data points per\nsensor, corresponding to the array of 8 sEMG sensors in the armband. Data\ncaptured were then classified into four categories (Fist, Thumbs Up, Open Hand,\nRest) via using a deep learning model, Inception-v3, with transfer learning to\ntrain the model for accurate prediction of each on real-time input of new data.\nThis trained model was then downloaded to the ARM processor based embedding\nsystem to enable the brain-controlled robot-arm prosthetic manufactured from\nour 3D printer. Testing of the functionality of the method, a robotic arm was\nproduced using a 3D printer and off-the-shelf hardware to control it. SSH\ncommunication protocols are employed to execute python files hosted on an\nembedded Raspberry Pi with ARM processors to trigger movement on the robot arm\nof the predicted gesture.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 19:14:44 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Lonsdale", "David", ""], ["Zhang", "Li", ""], ["Jiang", "Richard", ""]]}, {"id": "2005.01798", "submitter": "Vasundhra Iyengar", "authors": "Vasundhra Iyengar, Azra Bihorac, Parisa Rashidi", "title": "Automated Detection of Rest Disruptions in Critically Ill Patients", "comments": null, "journal-ref": "2020 42nd Annual International Conference of the IEEE Engineering\n  in Medicine & Biology Society (EMBC), Montreal, QC, Canada, 2020, pp.\n  5450-5454", "doi": "10.1109/EMBC44109.2020.9175252", "report-no": null, "categories": "q-bio.QM cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep has been shown to be an indispensable and important component of\npatients recovery process. Nonetheless, sleep quality of patients in the\nIntensive Care Unit (ICU) is often low, due to factors such as noise, pain, and\nfrequent nursing care activities. Frequent sleep disruptions by the medical\nstaff and/or visitors at certain times might lead to disruption of patient\nsleep-wake cycle and can also impact the severity of pain. Examining the\nassociation between sleep quality and frequent visitation has been difficult,\ndue to lack of automated methods for visitation detection. In this study, we\nrecruited 38 patients to automatically assess visitation frequency from\ncaptured video frames. We used the DensePose R-CNN (ResNet-101) model to\ncalculate the number of people in the room in a video frame. We examined when\npatients are interrupted the most, and we examined the association between\nfrequent disruptions and patient outcomes on pain and length of stay.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 20:22:24 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 19:31:02 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Iyengar", "Vasundhra", ""], ["Bihorac", "Azra", ""], ["Rashidi", "Parisa", ""]]}, {"id": "2005.01800", "submitter": "Michael Smith", "authors": "Michael R. Smith, Nicholas T. Johnson, Joe B. Ingram, Armida J.\n  Carbajal, Ramyaa Ramyaa, Evelyn Domschot, Christopher C. Lamb, Stephen J.\n  Verzi, W. Philip Kegelmeyer", "title": "Mind the Gap: On Bridging the Semantic Gap between Machine Learning and\n  Information Security", "comments": "14 pages, 2 Figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the potential of Machine learning (ML) to learn the behavior of\nmalware, detect novel malware samples, and significantly improve information\nsecurity (InfoSec) we see few, if any, high-impact ML techniques in deployed\nsystems, notwithstanding multiple reported successes in open literature. We\nhypothesize that the failure of ML in making high-impacts in InfoSec are rooted\nin a disconnect between the two communities as evidenced by a semantic gap---a\ndifference in how executables are described (e.g. the data and features\nextracted from the data). Specifically, current datasets and representations\nused by ML are not suitable for learning the behaviors of an executable and\ndiffer significantly from those used by the InfoSec community. In this paper,\nwe survey existing datasets used for classifying malware by ML algorithms and\nthe features that are extracted from the data. We observe that: 1) the current\nset of extracted features are primarily syntactic, not behavioral, 2) datasets\ngenerally contain extreme exemplars producing a dataset in which it is easy to\ndiscriminate classes, and 3) the datasets provide significantly different\nrepresentations of the data encountered in real-world systems. For ML to make\nmore of an impact in the InfoSec community requires a change in the data\n(including the features and labels) that is used to bridge the current semantic\ngap. As a first step in enabling more behavioral analyses, we label existing\nmalware datasets with behavioral features using open-source threat reports\nassociated with malware families. This behavioral labeling alters the analysis\nfrom identifying intent (e.g. good vs bad) or malware family membership to an\nanalysis of which behaviors are exhibited by an executable. We offer the\nannotations with the hope of inspiring future improvements in the data that\nwill further bridge the semantic gap between the ML and InfoSec communities.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 19:19:32 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Smith", "Michael R.", ""], ["Johnson", "Nicholas T.", ""], ["Ingram", "Joe B.", ""], ["Carbajal", "Armida J.", ""], ["Ramyaa", "Ramyaa", ""], ["Domschot", "Evelyn", ""], ["Lamb", "Christopher C.", ""], ["Verzi", "Stephen J.", ""], ["Kegelmeyer", "W. Philip", ""]]}, {"id": "2005.01805", "submitter": "Mark Loyman", "authors": "Mark Loyman and Hayit Greenspan", "title": "Semi-supervised lung nodule retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Content based image retrieval (CBIR) provides the clinician with visual\ninformation that can support, and hopefully improve, his or her decision making\nprocess. Given an input query image, a CBIR system provides as its output a set\nof images, ranked by similarity to the query image. Retrieved images may come\nwith relevant information, such as biopsy-based malignancy labeling, or\ncategorization. Ground truth on similarity between dataset elements (e.g.\nbetween nodules) is not readily available, thus greatly challenging machine\nlearning methods. Such annotations are particularly difficult to obtain, due to\nthe subjective nature of the task, with high inter-observer variability\nrequiring multiple expert annotators. Consequently, past approaches have\nfocused on manual feature extraction, while current approaches use auxiliary\ntasks, such as a binary classification task (e.g. malignancy), for which\nground-true is more readily accessible. However, in a previous study, we have\nshown that binary auxiliary tasks are inferior to the usage of a rough\nsimilarity estimate that are derived from data annotations. The current study\nsuggests a semi-supervised approach that involves two steps: 1) Automatic\nannotation of a given partially labeled dataset; 2) Learning a semantic\nsimilarity metric space based on the predicated annotations. The proposed\nsystem is demonstrated in lung nodule retrieval using the LIDC dataset, and\nshows that it is feasible to learn embedding from predicted ratings. The\nsemi-supervised approach has demonstrated a significantly higher discriminative\nability than the fully-unsupervised reference.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 19:26:14 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Loyman", "Mark", ""], ["Greenspan", "Hayit", ""]]}, {"id": "2005.01807", "submitter": "Nitin Rathi", "authors": "Nitin Rathi, Gopalakrishnan Srinivasan, Priyadarshini Panda, Kaushik\n  Roy", "title": "Enabling Deep Spiking Neural Networks with Hybrid Conversion and Spike\n  Timing Dependent Backpropagation", "comments": "International Conference on Learning Representations (ICLR), 2020\n  https://openreview.net/forum?id=B1xSperKvH&noteId=B1xSperKvH", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) operate with asynchronous discrete events (or\nspikes) which can potentially lead to higher energy-efficiency in neuromorphic\nhardware implementations. Many works have shown that an SNN for inference can\nbe formed by copying the weights from a trained Artificial Neural Network (ANN)\nand setting the firing threshold for each layer as the maximum input received\nin that layer. These type of converted SNNs require a large number of time\nsteps to achieve competitive accuracy which diminishes the energy savings. The\nnumber of time steps can be reduced by training SNNs with spike-based\nbackpropagation from scratch, but that is computationally expensive and slow.\nTo address these challenges, we present a computationally-efficient training\ntechnique for deep SNNs. We propose a hybrid training methodology: 1) take a\nconverted SNN and use its weights and thresholds as an initialization step for\nspike-based backpropagation, and 2) perform incremental spike-timing dependent\nbackpropagation (STDB) on this carefully initialized network to obtain an SNN\nthat converges within few epochs and requires fewer time steps for input\nprocessing. STDB is performed with a novel surrogate gradient function defined\nusing neuron's spike time. The proposed training methodology converges in less\nthan 20 epochs of spike-based backpropagation for most standard image\nclassification datasets, thereby greatly reducing the training complexity\ncompared to training SNNs from scratch. We perform experiments on CIFAR-10,\nCIFAR-100, and ImageNet datasets for both VGG and ResNet architectures. We\nachieve top-1 accuracy of 65.19% for ImageNet dataset on SNN with 250 time\nsteps, which is 10X faster compared to converted SNNs with similar accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 19:30:43 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Rathi", "Nitin", ""], ["Srinivasan", "Gopalakrishnan", ""], ["Panda", "Priyadarshini", ""], ["Roy", "Kaushik", ""]]}, {"id": "2005.01818", "submitter": "Deepjyoti Deka", "authors": "Deepjyoti Deka, Harish Doddi, Sidhant Misra, Murti Salapaka", "title": "Tractable learning in under-excited power grids", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the structure of physical flow networks such as power grids is\ncritical to secure delivery of energy. This paper discusses statistical\nstructure estimation in power grids in the \"under-excited\" regime, where a\nsubset of internal nodes do not have external injection. Prior estimation\nalgorithms based on nodal potentials or voltages fail in the under-excited\nregime. We propose a novel topology learning algorithm for learning\nunderexcited general (non-radial) networks based on physics-informed\nconservation laws. We prove the asymptotic correctness of our algorithm for\ngrids with non-adjacent under-excited internal nodes. More importantly, we\ntheoretically analyze our algorithm's efficacy under noisy measurements, and\ndetermine bounds on maximum noise under which asymptotically correct recovery\nis guaranteed. Our approach is validated through simulations with non-linear\nvoltage samples generated on test grids with real injection data\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 19:54:48 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Deka", "Deepjyoti", ""], ["Doddi", "Harish", ""], ["Misra", "Sidhant", ""], ["Salapaka", "Murti", ""]]}, {"id": "2005.01819", "submitter": "Hsueh-Ti Derek Liu", "authors": "Hsueh-Ti Derek Liu, Vladimir G. Kim, Siddhartha Chaudhuri, Noam\n  Aigerman, Alec Jacobson", "title": "Neural Subdivision", "comments": "16 pages", "journal-ref": "ACM Trans. Graph. 39, 4, (July 2020)", "doi": null, "report-no": null, "categories": "cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Neural Subdivision, a novel framework for data-driven\ncoarse-to-fine geometry modeling. During inference, our method takes a coarse\ntriangle mesh as input and recursively subdivides it to a finer geometry by\napplying the fixed topological updates of Loop Subdivision, but predicting\nvertex positions using a neural network conditioned on the local geometry of a\npatch. This approach enables us to learn complex non-linear subdivision\nschemes, beyond simple linear averaging used in classical techniques. One of\nour key contributions is a novel self-supervised training setup that only\nrequires a set of high-resolution meshes for learning network weights. For any\ntraining shape, we stochastically generate diverse low-resolution\ndiscretizations of coarse counterparts, while maintaining a bijective mapping\nthat prescribes the exact target position of every new vertex during the\nsubdivision process. This leads to a very efficient and accurate loss function\nfor conditional mesh generation, and enables us to train a method that\ngeneralizes across discretizations and favors preserving the manifold structure\nof the output. During training we optimize for the same set of network weights\nacross all local mesh patches, thus providing an architecture that is not\nconstrained to a specific input mesh, fixed genus, or category. Our network\nencodes patch geometry in a local frame in a rotation- and\ntranslation-invariant manner. Jointly, these design choices enable our method\nto generalize well, and we demonstrate that even when trained on a single\nhigh-resolution mesh our method generates reasonable subdivisions for novel\nshapes.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 20:03:21 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Liu", "Hsueh-Ti Derek", ""], ["Kim", "Vladimir G.", ""], ["Chaudhuri", "Siddhartha", ""], ["Aigerman", "Noam", ""], ["Jacobson", "Alec", ""]]}, {"id": "2005.01831", "submitter": "Peter Hase", "authors": "Peter Hase, Mohit Bansal", "title": "Evaluating Explainable AI: Which Algorithmic Explanations Help Users\n  Predict Model Behavior?", "comments": "ACL 2020 (13 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic approaches to interpreting machine learning models have\nproliferated in recent years. We carry out human subject tests that are the\nfirst of their kind to isolate the effect of algorithmic explanations on a key\naspect of model interpretability, simulatability, while avoiding important\nconfounding experimental factors. A model is simulatable when a person can\npredict its behavior on new inputs. Through two kinds of simulation tests\ninvolving text and tabular data, we evaluate five explanations methods: (1)\nLIME, (2) Anchor, (3) Decision Boundary, (4) a Prototype model, and (5) a\nComposite approach that combines explanations from each method. Clear evidence\nof method effectiveness is found in very few cases: LIME improves\nsimulatability in tabular classification, and our Prototype method is effective\nin counterfactual simulation tests. We also collect subjective ratings of\nexplanations, but we do not find that ratings are predictive of how helpful\nexplanations are. Our results provide the first reliable and comprehensive\nestimates of how explanations influence simulatability across a variety of\nexplanation methods and data domains. We show that (1) we need to be careful\nabout the metrics we use to evaluate explanation methods, and (2) there is\nsignificant room for improvement in current methods. All our supporting code,\ndata, and models are publicly available at:\nhttps://github.com/peterbhase/InterpretableNLP-ACL2020\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 20:35:17 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Hase", "Peter", ""], ["Bansal", "Mohit", ""]]}, {"id": "2005.01834", "submitter": "Seyed Amir Hossein Aqajari", "authors": "Seyed Amir Hossein Aqajari (1), Emad Kasaeyan Naeini (1), Milad Asgari\n  Mehrabadi (1), Sina Labbaf (1), Amir M. Rahmani (1 and 2), Nikil Dutt (1)\n  ((1) Department of Computer Science, University of California, Irvine, (2)\n  School of Nursing, University of California, Irvine)", "title": "GSR Analysis for Stress: Development and Validation of an Open Source\n  Tool for Noisy Naturalistic GSR Data", "comments": "6 pages and 5 figures. Link to the github of the tool:\n  https://github.com/HealthSciTech/pyEDA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stress detection problem is receiving great attention in related research\ncommunities. This is due to its essential part in behavioral studies for many\nserious health problems and physical illnesses. There are different methods and\nalgorithms for stress detection using different physiological signals. Previous\nstudies have already shown that Galvanic Skin Response (GSR), also known as\nElectrodermal Activity (EDA), is one of the leading indicators for stress.\nHowever, the GSR signal itself is not trivial to analyze. Different features\nare extracted from GSR signals to detect stress in people like the number of\npeaks, max peak amplitude, etc. In this paper, we are proposing an open-source\ntool for GSR analysis, which uses deep learning algorithms alongside\nstatistical algorithms to extract GSR features for stress detection. Then we\nuse different machine learning algorithms and Wearable Stress and Affect\nDetection (WESAD) dataset to evaluate our results. The results show that we are\ncapable of detecting stress with the accuracy of 92 percent using 10-fold\ncross-validation and using the features extracted from our tool.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 20:40:39 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 00:47:23 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 19:06:12 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Aqajari", "Seyed Amir Hossein", "", "1 and 2"], ["Naeini", "Emad Kasaeyan", "", "1 and 2"], ["Mehrabadi", "Milad Asgari", "", "1 and 2"], ["Labbaf", "Sina", "", "1 and 2"], ["Rahmani", "Amir M.", "", "1 and 2"], ["Dutt", "Nikil", ""]]}, {"id": "2005.01854", "submitter": "Thomas Kober", "authors": "Thomas Kober, Julie Weeds, Lorenzo Bertolini, David Weir", "title": "Data Augmentation for Hypernymy Detection", "comments": "to appear at EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic detection of hypernymy relationships represents a challenging\nproblem in NLP. The successful application of state-of-the-art supervised\napproaches using distributed representations has generally been impeded by the\nlimited availability of high quality training data. We have developed two novel\ndata augmentation techniques which generate new training examples from existing\nones. First, we combine the linguistic principles of hypernym transitivity and\nintersective modifier-noun composition to generate additional pairs of vectors,\nsuch as \"small dog - dog\" or \"small dog - animal\", for which a hypernymy\nrelationship can be assumed. Second, we use generative adversarial networks\n(GANs) to generate pairs of vectors for which the hypernymy relation can also\nbe assumed. We furthermore present two complementary strategies for extending\nan existing dataset by leveraging linguistic resources such as WordNet. Using\nan evaluation across 3 different datasets for hypernymy detection and 2\ndifferent vector spaces, we demonstrate that both of the proposed automatic\ndata augmentation and dataset extension strategies substantially improve\nclassifier performance.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 21:32:12 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 21:13:16 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Kober", "Thomas", ""], ["Weeds", "Julie", ""], ["Bertolini", "Lorenzo", ""], ["Weir", "David", ""]]}, {"id": "2005.01856", "submitter": "Maximilian Ilse", "authors": "Maximilian Ilse, Jakub M. Tomczak, Patrick Forr\\'e", "title": "Selecting Data Augmentation for Simulating Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models trained with purely observational data and the\nprinciple of empirical risk minimization \\citep{vapnik_principles_1992} can\nfail to generalize to unseen domains. In this paper, we focus on the case where\nthe problem arises through spurious correlation between the observed domains\nand the actual task labels. We find that many domain generalization methods do\nnot explicitly take this spurious correlation into account. Instead, especially\nin more application-oriented research areas like medical imaging or robotics,\ndata augmentation techniques that are based on heuristics are used to learn\ndomain invariant features. To bridge the gap between theory and practice, we\ndevelop a causal perspective on the problem of domain generalization. We argue\nthat causal concepts can be used to explain the success of data augmentation by\ndescribing how they can weaken the spurious correlation between the observed\ndomains and the task labels. We demonstrate that data augmentation can serve as\na tool for simulating interventional data. We use these theoretical insights to\nderive a simple algorithm that is able to select data augmentation techniques\nthat will lead to better domain generalization.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 21:33:29 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 14:59:40 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 13:16:20 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 10:52:21 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Ilse", "Maximilian", ""], ["Tomczak", "Jakub M.", ""], ["Forr\u00e9", "Patrick", ""]]}, {"id": "2005.01862", "submitter": "Zengyi Li", "authors": "Zengyi Li, Friedrich T. Sommer", "title": "Complex Amplitude-Phase Boltzmann Machines", "comments": "Short Technical Note", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the framework of Boltzmann machines to a network of complex-valued\nneurons with variable amplitudes, referred to as Complex Amplitude-Phase\nBoltzmann machine (CAP-BM). The model is capable of performing unsupervised\nlearning on the amplitude and relative phase distribution in complex data. The\nsampling rule of the Gibbs distribution and the learning rules of the model are\npresented. Learning in a Complex Amplitude-Phase restricted Boltzmann machine\n(CAP-RBM) is demonstrated on synthetic complex-valued images, and handwritten\nMNIST digits transformed by a complex wavelet transform. Specifically, we show\nthe necessity of a new amplitude-amplitude coupling term in our model. The\nproposed model is potentially valuable for machine learning tasks involving\ncomplex-valued data with amplitude variation, and for developing algorithms for\nnovel computation hardware, such as coupled oscillators and neuromorphic\nhardware, on which Boltzmann sampling can be executed in the complex domain.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 21:44:59 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Li", "Zengyi", ""], ["Sommer", "Friedrich T.", ""]]}, {"id": "2005.01886", "submitter": "Vladimir Pestov", "authors": "Vladimir G. Pestov", "title": "A learning problem whose consistency is equivalent to the non-existence\n  of real-valued measurable cardinals", "comments": "16 pp., journal macros", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the $k$-nearest neighbour learning rule is universally\nconsistent in a metric space $X$ if and only if it is universally consistent in\nevery separable subspace of $X$ and the density of $X$ is less than every\nreal-measurable cardinal. In particular, the $k$-NN classifier is universally\nconsistent in every metric space whose separable subspaces are sigma-finite\ndimensional in the sense of Nagata and Preiss if and only if there are no\nreal-valued measurable cardinals. The latter assumption is relatively\nconsistent with ZFC, however the consistency of the existence of such cardinals\ncannot be proved within ZFC. Our results were inspired by an example sketched\nby C\\'erou and Guyader in 2006 at an intuitive level of rigour.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 23:40:28 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Pestov", "Vladimir G.", ""]]}, {"id": "2005.01889", "submitter": "Seonho Park", "authors": "Seonho Park, George Adosoglou, Panos M. Pardalos", "title": "Interpreting Rate-Distortion of Variational Autoencoder and Using Model\n  Uncertainty for Anomaly Detection", "comments": "Corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building a scalable machine learning system for unsupervised anomaly\ndetection via representation learning is highly desirable. One of the prevalent\nmethods is using a reconstruction error from variational autoencoder (VAE) via\nmaximizing the evidence lower bound. We revisit VAE from the perspective of\ninformation theory to provide some theoretical foundations on using the\nreconstruction error, and finally arrive at a simpler and more effective model\nfor anomaly detection. In addition, to enhance the effectiveness of detecting\nanomalies, we incorporate a practical model uncertainty measure into the\nmetric. We show empirically the competitive performance of our approach on\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 00:03:48 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 16:59:36 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Park", "Seonho", ""], ["Adosoglou", "George", ""], ["Pardalos", "Panos M.", ""]]}, {"id": "2005.01898", "submitter": "Hao Cheng", "authors": "Hao Cheng, Ming-Wei Chang, Kenton Lee, Kristina Toutanova", "title": "Probabilistic Assumptions Matter: Improved Models for\n  Distantly-Supervised Document-Level Question Answering", "comments": "ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of extractive question answering using document-level\ndistant super-vision, pairing questions and relevant documents with answer\nstrings. We compare previously used probability space and distant super-vision\nassumptions (assumptions on the correspondence between the weak answer string\nlabels and possible answer mention spans). We show that these assumptions\ninteract, and that different configurations provide complementary benefits. We\ndemonstrate that a multi-objective model can efficiently combine the advantages\nof multiple assumptions and out-perform the best individual formulation. Our\napproach outperforms previous state-of-the-art models by 4.3 points in F1 on\nTriviaQA-Wiki and 1.7 points in Rouge-L on NarrativeQA summaries.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 01:08:36 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Cheng", "Hao", ""], ["Chang", "Ming-Wei", ""], ["Lee", "Kenton", ""], ["Toutanova", "Kristina", ""]]}, {"id": "2005.01906", "submitter": "Jared Quincy Davis", "authors": "Jared Quincy Davis, Krzysztof Choromanski, Jake Varley, Honglak Lee,\n  Jean-Jacques Slotine, Valerii Likhosterov, Adrian Weller, Ameesh Makadia,\n  Vikas Sindhwani", "title": "Time Dependence in Non-Autonomous Neural ODEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Ordinary Differential Equations (ODEs) are elegant reinterpretations\nof deep networks where continuous time can replace the discrete notion of\ndepth, ODE solvers perform forward propagation, and the adjoint method enables\nefficient, constant memory backpropagation. Neural ODEs are universal\napproximators only when they are non-autonomous, that is, the dynamics depends\nexplicitly on time. We propose a novel family of Neural ODEs with time-varying\nweights, where time-dependence is non-parametric, and the smoothness of weight\ntrajectories can be explicitly controlled to allow a tradeoff between\nexpressiveness and efficiency. Using this enhanced expressiveness, we\noutperform previous Neural ODE variants in both speed and representational\ncapacity, ultimately outperforming standard ResNet and CNN models on select\nimage classification and video prediction tasks.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 01:41:46 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 16:40:50 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Davis", "Jared Quincy", ""], ["Choromanski", "Krzysztof", ""], ["Varley", "Jake", ""], ["Lee", "Honglak", ""], ["Slotine", "Jean-Jacques", ""], ["Likhosterov", "Valerii", ""], ["Weller", "Adrian", ""], ["Makadia", "Ameesh", ""], ["Sindhwani", "Vikas", ""]]}, {"id": "2005.01908", "submitter": "Randy Goebel", "authors": "S. Atakishiyev, H. Babiker, N. Farruque, R. Goebel1, M-Y. Kima, M.H.\n  Motallebi, J. Rabelo, T. Syed, O. R. Za\\\"iane", "title": "A multi-component framework for the analysis and design of explainable\n  artificial intelligence", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of research in explainable artificial intelligence (XAI)\nfollows on two substantial developments. First, the enormous application\nsuccess of modern machine learning methods, especially deep and reinforcement\nlearning, which have created high expectations for industrial, commercial and\nsocial value. Second, the emergence of concern for creating trusted AI systems,\nincluding the creation of regulatory principles to ensure transparency and\ntrust of AI systems.These two threads have created a kind of \"perfect storm\" of\nresearch activity, all eager to create and deliver it any set of tools and\ntechniques to address the XAI demand. As some surveys of current XAI suggest,\nthere is yet to appear a principled framework that respects the literature of\nexplainability in the history of science, and which provides a basis for the\ndevelopment of a framework for transparent XAI. Here we intend to provide a\nstrategic inventory of XAI requirements, demonstrate their connection to a\nhistory of XAI ideas, and synthesize those ideas into a simple framework to\ncalibrate five successive levels of XAI.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 01:48:40 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Atakishiyev", "S.", ""], ["Babiker", "H.", ""], ["Farruque", "N.", ""], ["Goebel1", "R.", ""], ["Kima", "M-Y.", ""], ["Motallebi", "M. H.", ""], ["Rabelo", "J.", ""], ["Syed", "T.", ""], ["Za\u00efane", "O. R.", ""]]}, {"id": "2005.01912", "submitter": "Leopoldo Sarra", "authors": "Leopoldo Sarra, Andrea Aiello, Florian Marquardt", "title": "Renormalized Mutual Information for Artificial Scientific Discovery", "comments": "Added a more detailed introduction and link to code repository.\n  Physics-based examples and Feature Extraction section have been updated", "journal-ref": "Phys. Rev. Lett. 126, 200601 (2021)", "doi": "10.1103/PhysRevLett.126.200601", "report-no": null, "categories": "cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a well-defined renormalized version of mutual information that\nallows to estimate the dependence between continuous random variables in the\nimportant case when one is deterministically dependent on the other. This is\nthe situation relevant for feature extraction, where the goal is to produce a\nlow-dimensional effective description of a high-dimensional system. Our\napproach enables the discovery of collective variables in physical systems,\nthus adding to the toolbox of artificial scientific discovery, while also\naiding the analysis of information flow in artificial neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 16:43:49 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 10:54:07 GMT"}, {"version": "v3", "created": "Fri, 5 Mar 2021 11:20:34 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Sarra", "Leopoldo", ""], ["Aiello", "Andrea", ""], ["Marquardt", "Florian", ""]]}, {"id": "2005.01917", "submitter": "Dylan Peifer", "authors": "Dylan Peifer, Michael Stillman, Daniel Halpern-Leistner", "title": "Learning selection strategies in Buchberger's algorithm", "comments": "14 pages, minor typo and format fixes, to appear in Proceedings of\n  the 37th International Conference on Machine Learning (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SC math.AC math.AG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studying the set of exact solutions of a system of polynomial equations\nlargely depends on a single iterative algorithm, known as Buchberger's\nalgorithm. Optimized versions of this algorithm are crucial for many computer\nalgebra systems (e.g., Mathematica, Maple, Sage). We introduce a new approach\nto Buchberger's algorithm that uses reinforcement learning agents to perform\nS-pair selection, a key step in the algorithm. We then study how the difficulty\nof the problem depends on the choices of domain and distribution of\npolynomials, about which little is known. Finally, we train a policy model\nusing proximal policy optimization (PPO) to learn S-pair selection strategies\nfor random systems of binomial equations. In certain domains, the trained model\noutperforms state-of-the-art selection heuristics in total number of polynomial\nadditions performed, which provides a proof-of-concept that recent developments\nin machine learning have the potential to improve performance of algorithms in\nsymbolic computation.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 02:27:00 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 16:43:30 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 22:01:54 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Peifer", "Dylan", ""], ["Stillman", "Michael", ""], ["Halpern-Leistner", "Daniel", ""]]}, {"id": "2005.01923", "submitter": "Muhammad Ali Farooq", "authors": "Muhammad Ali Farooq and Peter Corcoran", "title": "Generating Thermal Image Data Samples using 3D Facial Modelling\n  Techniques and Deep Learning Methodologies", "comments": "Paper accpeted in QOMEX IEEE 2020 Conference copyright submitted to\n  IEEE", "journal-ref": null, "doi": "10.1109/QoMEX48832.2020.9123079", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for generating synthetic data have become of increasing importance to\nbuild large datasets required for Convolution Neural Networks (CNN) based deep\nlearning techniques for a wide range of computer vision applications. In this\nwork, we extend existing methodologies to show how 2D thermal facial data can\nbe mapped to provide 3D facial models. For the proposed research work we have\nused tufts datasets for generating 3D varying face poses by using a single\nfrontal face pose. The system works by refining the existing image quality by\nperforming fusion based image preprocessing operations. The refined outputs\nhave better contrast adjustments, decreased noise level and higher exposedness\nof the dark regions. It makes the facial landmarks and temperature patterns on\nthe human face more discernible and visible when compared to original raw data.\nDifferent image quality metrics are used to compare the refined version of\nimages with original images. In the next phase of the proposed study, the\nrefined version of images is used to create 3D facial geometry structures by\nusing Convolution Neural Networks (CNN). The generated outputs are then\nimported in blender software to finally extract the 3D thermal facial outputs\nof both males and females. The same technique is also used on our thermal face\ndata acquired using prototype thermal camera (developed under Heliaus EU\nproject) in an indoor lab environment which is then used for generating\nsynthetic 3D face data along with varying yaw face angles and lastly facial\ndepth map is generated.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 02:55:14 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 11:02:04 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Farooq", "Muhammad Ali", ""], ["Corcoran", "Peter", ""]]}, {"id": "2005.01932", "submitter": "Pang Wei Koh", "authors": "Shikhar Murty, Pang Wei Koh, and Percy Liang", "title": "ExpBERT: Representation Engineering with Natural Language Explanations", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we want to specify the inductive bias that married couples typically\ngo on honeymoons for the task of extracting pairs of spouses from text. In this\npaper, we allow model developers to specify these types of inductive biases as\nnatural language explanations. We use BERT fine-tuned on MultiNLI to\n``interpret'' these explanations with respect to the input sentence, producing\nexplanation-guided representations of the input. Across three relation\nextraction tasks, our method, ExpBERT, matches a BERT baseline but with 3--20x\nless labeled data and improves on the baseline by 3--10 F1 points with the same\namount of labeled data.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 03:40:23 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Murty", "Shikhar", ""], ["Koh", "Pang Wei", ""], ["Liang", "Percy", ""]]}, {"id": "2005.01935", "submitter": "Peide Cai", "authors": "Peide Cai, Sukai Wang, Yuxiang Sun, Ming Liu", "title": "Probabilistic End-to-End Vehicle Navigation in Complex Dynamic\n  Environments with Multimodal Sensor Fusion", "comments": "8 pages, 6 figures, 3 tables. IEEE Robotics and Automation Letters\n  (RA-L)", "journal-ref": null, "doi": "10.1109/LRA.2020.2994027", "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All-day and all-weather navigation is a critical capability for autonomous\ndriving, which requires proper reaction to varied environmental conditions and\ncomplex agent behaviors. Recently, with the rise of deep learning, end-to-end\ncontrol for autonomous vehicles has been well studied. However, most works are\nsolely based on visual information, which can be degraded by challenging\nillumination conditions such as dim light or total darkness. In addition, they\nusually generate and apply deterministic control commands without considering\nthe uncertainties in the future. In this paper, based on imitation learning, we\npropose a probabilistic driving model with ultiperception capability utilizing\nthe information from the camera, lidar and radar. We further evaluate its\ndriving performance online on our new driving benchmark, which includes various\nenvironmental conditions (e.g., urban and rural areas, traffic densities,\nweather and times of the day) and dynamic obstacles (e.g., vehicles,\npedestrians, motorcyclists and bicyclists). The results suggest that our\nproposed model outperforms baselines and achieves excellent generalization\nperformance in unseen environments with heavy traffic and extreme weather.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 03:48:10 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Cai", "Peide", ""], ["Wang", "Sukai", ""], ["Sun", "Yuxiang", ""], ["Liu", "Ming", ""]]}, {"id": "2005.01936", "submitter": "Sanae Amani", "authors": "Sanae Amani, Mahnoosh Alizadeh, Christos Thrampoulidis", "title": "Regret Bounds for Safe Gaussian Process Bandit Optimization", "comments": "22 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications require a learner to make sequential decisions given\nuncertainty regarding both the system's payoff function and safety constraints.\nIn safety-critical systems, it is paramount that the learner's actions do not\nviolate the safety constraints at any stage of the learning process. In this\npaper, we study a stochastic bandit optimization problem where the unknown\npayoff and constraint functions are sampled from Gaussian Processes (GPs) first\nconsidered in [Srinivas et al., 2010]. We develop a safe variant of GP-UCB\ncalled SGP-UCB, with necessary modifications to respect safety constraints at\nevery round. The algorithm has two distinct phases. The first phase seeks to\nestimate the set of safe actions in the decision set, while the second phase\nfollows the GP-UCB decision rule. Our main contribution is to derive the first\nsub-linear regret bounds for this problem. We numerically compare SGP-UCB\nagainst existing safe Bayesian GP optimization algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 03:54:43 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Amani", "Sanae", ""], ["Alizadeh", "Mahnoosh", ""], ["Thrampoulidis", "Christos", ""]]}, {"id": "2005.01969", "submitter": "Jiancheng Yang", "authors": "Jiancheng Yang, Yi He, Xiaoyang Huang, Jingwei Xu, Xiaodan Ye, Guangyu\n  Tao, Bingbing Ni", "title": "AlignShift: Bridging the Gap of Imaging Thickness in 3D Anisotropic\n  Volumes", "comments": "MICCAI 2020 (early accepted). Camera ready version. Code is available\n  at https://github.com/M3DV/AlignShift", "journal-ref": null, "doi": "10.1007/978-3-030-59719-1_55", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses a fundamental challenge in 3D medical image processing:\nhow to deal with imaging thickness. For anisotropic medical volumes, there is a\nsignificant performance gap between thin-slice (mostly 1mm) and thick-slice\n(mostly 5mm) volumes. Prior arts tend to use 3D approaches for the thin-slice\nand 2D approaches for the thick-slice, respectively. We aim at a unified\napproach for both thin- and thick-slice medical volumes. Inspired by recent\nadvances in video analysis, we propose AlignShift, a novel parameter-free\noperator to convert theoretically any 2D pretrained network into\nthickness-aware 3D network. Remarkably, the converted networks behave like 3D\nfor the thin-slice, nevertheless degenerate to 2D for the thick-slice\nadaptively. The unified thickness-aware representation learning is achieved by\nshifting and fusing aligned \"virtual slices\" as per the input imaging\nthickness. Extensive experiments on public large-scale DeepLesion benchmark,\nconsisting of 32K lesions for universal lesion detection, validate the\neffectiveness of our method, which outperforms previous state of the art by\nconsiderable margins without whistles and bells. More importantly, to our\nknowledge, this is the first method that bridges the performance gap between\nthin- and thick-slice volumes by a unified framework. To improve research\nreproducibility, our code in PyTorch is open source at\nhttps://github.com/M3DV/AlignShift.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 06:54:26 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 10:03:05 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Yang", "Jiancheng", ""], ["He", "Yi", ""], ["Huang", "Xiaoyang", ""], ["Xu", "Jingwei", ""], ["Ye", "Xiaodan", ""], ["Tao", "Guangyu", ""], ["Ni", "Bingbing", ""]]}, {"id": "2005.01979", "submitter": "Joash Lee", "authors": "Joash Lee, Wenbo Wang, Dusit Niyato", "title": "Demand-Side Scheduling Based on Deep Actor-Critic Learning for Smart\n  Grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of demand-side energy management, where each\nhousehold is equipped with a smart meter that is able to schedule home\nappliances online. The goal is to minimise the overall cost under a real-time\npricing scheme. While previous works have introduced centralised approaches, we\nformulate the smart grid environment as a Markov game, where each household is\na decentralised agent, and the grid operator produces a price signal that\nadapts to the energy demand. The main challenge addressed in our approach is\npartial observability and perceived non-stationarity of the environment from\nthe viewpoint of each agent. We propose a multi-agent extension of a deep\nactor-critic algorithm that shows success in learning in this environment. This\nalgorithm learns a centralised critic that coordinates training of all agents.\nOur approach thus uses centralised learning but decentralised execution.\nSimulation results show that our online deep reinforcement learning method can\nreduce both the peak-to-average ratio of total energy consumed and the cost of\nelectricity for all households based purely on instantaneous observations and a\nprice signal.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 07:32:40 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Lee", "Joash", ""], ["Wang", "Wenbo", ""], ["Niyato", "Dusit", ""]]}, {"id": "2005.01988", "submitter": "Zhong Sun", "authors": "Zhong Sun, Giacomo Pedretti, Alessandro Bricalli, Daniele Ielmini", "title": "One-step regression and classification with crosspoint resistive memory\n  arrays", "comments": "24 pages, 4 figures", "journal-ref": "Science Advances: Vol. 6, no. 5, eaay2378 (2020)", "doi": "10.1126/sciadv.aay2378", "report-no": null, "categories": "cs.LG cs.ET stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning has been getting a large attention in the recent years, as a\ntool to process big data generated by ubiquitous sensors in our daily life.\nHigh speed, low energy computing machines are in demand to enable real-time\nartificial intelligence at the edge, i.e., without the support of a remote\nframe server in the cloud. Such requirements challenge the complementary\nmetal-oxide-semiconductor (CMOS) technology, which is limited by the Moore's\nlaw approaching its end and the communication bottleneck in conventional\ncomputing architecture. Novel computing concepts, architectures and devices are\nthus strongly needed to accelerate data-intensive applications. Here we show a\ncrosspoint resistive memory circuit with feedback configuration can execute\nlinear regression and logistic regression in just one step by computing the\npseudoinverse matrix of the data within the memory. The most elementary\nlearning operation, that is the regression of a sequence of data and the\nclassification of a set of data, can thus be executed in one single\ncomputational step by the novel technology. One-step learning is further\nsupported by simulations of the prediction of the cost of a house in Boston and\nthe training of a 2-layer neural network for MNIST digit recognition. The\nresults are all obtained in one computational step, thanks to the physical,\nparallel, and analog computing within the crosspoint array.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 08:00:07 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Sun", "Zhong", ""], ["Pedretti", "Giacomo", ""], ["Bricalli", "Alessandro", ""], ["Ielmini", "Daniele", ""]]}, {"id": "2005.01992", "submitter": "Milad Moradi", "authors": "Milad Moradi, Matthias Samwald", "title": "Post-hoc explanation of black-box classifiers using confident itemsets", "comments": null, "journal-ref": "Expert Systems with Applications, vol. 165, p. 113941, 2021", "doi": "10.1016/j.eswa.2020.113941", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-box Artificial Intelligence (AI) methods, e.g. deep neural networks,\nhave been widely utilized to build predictive models that can extract complex\nrelationships in a dataset and make predictions for new unseen data records.\nHowever, it is difficult to trust decisions made by such methods since their\ninner working and decision logic is hidden from the user. Explainable\nArtificial Intelligence (XAI) refers to systems that try to explain how a\nblack-box AI model produces its outcomes. Post-hoc XAI methods approximate the\nbehavior of a black-box by extracting relationships between feature values and\nthe predictions. Perturbation-based and decision set methods are among commonly\nused post-hoc XAI systems. The former explanators rely on random perturbations\nof data records to build local or global linear models that explain individual\npredictions or the whole model. The latter explanators use those feature values\nthat appear more frequently to construct a set of decision rules that produces\nthe same outcomes as the target black-box. However, these two classes of XAI\nmethods have some limitations. Random perturbations do not take into account\nthe distribution of feature values in different subspaces, leading to\nmisleading approximations. Decision sets only pay attention to frequent feature\nvalues and miss many important correlations between features and class labels\nthat appear less frequently but accurately represent decision boundaries of the\nmodel. In this paper, we address the above challenges by proposing an\nexplanation method named Confident Itemsets Explanation (CIE). We introduce\nconfident itemsets, a set of feature values that are highly correlated to a\nspecific class label. CIE utilizes confident itemsets to discretize the whole\ndecision space of a model to smaller subspaces.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 08:11:24 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 21:24:58 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Moradi", "Milad", ""], ["Samwald", "Matthias", ""]]}, {"id": "2005.01995", "submitter": "Mehdi Ghatee Dr.", "authors": "Mohammad Mahdi Bejani, Mehdi Ghatee", "title": "Adaptive Low-Rank Factorization to regularize shallow and deep neural\n  networks", "comments": "11 pages, 5 figures, 3 Tables,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overfitting is one of the cursing subjects in the deep learning field. To\nsolve this challenge, many approaches were proposed to regularize the learning\nmodels. They add some hyper-parameters to the model to extend the\ngeneralization; however, it is a hard task to determine these hyper-parameters\nand a bad setting diverges the training process. In addition, most of the\nregularization schemes decrease the learning speed. Recently, Tai et al. [1]\nproposed low-rank tensor decomposition as a constrained filter for removing the\nredundancy in the convolution kernels of CNN. With a different viewpoint, we\nuse Low-Rank matrix Factorization (LRF) to drop out some parameters of the\nlearning model along the training process. However, this scheme similar to [1]\nprobably decreases the training accuracy when it tries to decrease the number\nof operations. Instead, we use this regularization scheme adaptively when the\ncomplexity of a layer is high. The complexity of any layer can be evaluated by\nthe nonlinear condition numbers of its learning system. The resulted method\nentitled \"AdaptiveLRF\" neither decreases the training speed nor vanishes the\naccuracy of the layer. The behavior of AdaptiveLRF is visualized on a noisy\ndataset. Then, the improvements are presented on some small-size and\nlarge-scale datasets. The preference of AdaptiveLRF on famous dropout\nregularizers on shallow networks is demonstrated. Also, AdaptiveLRF competes\nwith dropout and adaptive dropout on the various deep networks including\nMobileNet V2, ResNet V2, DenseNet, and Xception. The best results of\nAdaptiveLRF on SVHN and CIFAR-10 datasets are 98%, 94.1% F-measure, and 97.9%,\n94% accuracy. Finally, we state the usage of the LRF-based loss function to\nimprove the quality of the learning model.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 08:13:30 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Bejani", "Mohammad Mahdi", ""], ["Ghatee", "Mehdi", ""]]}, {"id": "2005.02000", "submitter": "Adriano Lucieri", "authors": "Adriano Lucieri, Muhammad Naseer Bajwa, Stephan Alexander Braun,\n  Muhammad Imran Malik, Andreas Dengel and Sheraz Ahmed", "title": "On Interpretability of Deep Learning based Skin Lesion Classifiers using\n  Concept Activation Vectors", "comments": "Accepted for the IEEE International Joint Conference on Neural\n  Networks (IJCNN) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based medical image classifiers have shown remarkable prowess\nin various application areas like ophthalmology, dermatology, pathology, and\nradiology. However, the acceptance of these Computer-Aided Diagnosis (CAD)\nsystems in real clinical setups is severely limited primarily because their\ndecision-making process remains largely obscure. This work aims at elucidating\na deep learning based medical image classifier by verifying that the model\nlearns and utilizes similar disease-related concepts as described and employed\nby dermatologists. We used a well-trained and high performing neural network\ndeveloped by REasoning for COmplex Data (RECOD) Lab for classification of three\nskin tumours, i.e. Melanocytic Naevi, Melanoma and Seborrheic Keratosis and\nperformed a detailed analysis on its latent space. Two well established and\npublicly available skin disease datasets, PH2 and derm7pt, are used for\nexperimentation. Human understandable concepts are mapped to RECOD image\nclassification model with the help of Concept Activation Vectors (CAVs),\nintroducing a novel training and significance testing paradigm for CAVs. Our\nresults on an independent evaluation set clearly shows that the classifier\nlearns and encodes human understandable concepts in its latent representation.\nAdditionally, TCAV scores (Testing with CAVs) suggest that the neural network\nindeed makes use of disease-related concepts in the correct way when making\npredictions. We anticipate that this work can not only increase confidence of\nmedical practitioners on CAD but also serve as a stepping stone for further\ndevelopment of CAV-based neural network interpretation methods.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 08:27:16 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Lucieri", "Adriano", ""], ["Bajwa", "Muhammad Naseer", ""], ["Braun", "Stephan Alexander", ""], ["Malik", "Muhammad Imran", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "2005.02006", "submitter": "Dominique Mercier", "authors": "Dominique Mercier, Andreas Dengel, Sheraz Ahmed", "title": "P2ExNet: Patch-based Prototype Explanation Network", "comments": "12 pages (11 + 1 references), 7 figures. The 27th International\n  Conference on Neural Information Processing (ICONIP2020)", "journal-ref": null, "doi": "10.1007/978-3-030-63836-8_27", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods have shown great success in several domains as they\nprocess a large amount of data efficiently, capable of solving complex\nclassification, forecast, segmentation, and other tasks. However, they come\nwith the inherent drawback of inexplicability limiting their applicability and\ntrustworthiness. Although there exists work addressing this perspective, most\nof the existing approaches are limited to the image modality due to the\nintuitive and prominent concepts. Conversely, the concepts in the time-series\ndomain are more complex and non-comprehensive but these and an explanation for\nthe network decision are pivotal in critical domains like medical, financial,\nor industry. Addressing the need for an explainable approach, we propose a\nnovel interpretable network scheme, designed to inherently use an explainable\nreasoning process inspired by the human cognition without the need of\nadditional post-hoc explainability methods. Therefore, class-specific patches\nare used as they cover local concepts relevant to the classification to reveal\nsimilarities with samples of the same class. In addition, we introduce a novel\nloss concerning interpretability and accuracy that constraints P2ExNet to\nprovide viable explanations of the data including relevant patches, their\nposition, class similarities, and comparison methods without compromising\naccuracy. Analysis of the results on eight publicly available time-series\ndatasets reveals that P2ExNet reaches comparable performance when compared to\nits counterparts while inherently providing understandable and traceable\ndecisions.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 08:45:43 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 13:02:36 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Mercier", "Dominique", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "2005.02049", "submitter": "Chulun Zhou", "authors": "Chulun Zhou, Liangyu Chen, Jiachen Liu, Xinyan Xiao, Jinsong Su, Sheng\n  Guo, Hua Wu", "title": "Exploring Contextual Word-level Style Relevance for Unsupervised Style\n  Transfer", "comments": "Accepted by ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised style transfer aims to change the style of an input sentence\nwhile preserving its original content without using parallel training data. In\ncurrent dominant approaches, owing to the lack of fine-grained control on the\ninfluence from the target style,they are unable to yield desirable output\nsentences. In this paper, we propose a novel attentional sequence-to-sequence\n(Seq2seq) model that dynamically exploits the relevance of each output word to\nthe target style for unsupervised style transfer. Specifically, we first\npretrain a style classifier, where the relevance of each input word to the\noriginal style can be quantified via layer-wise relevance propagation. In a\ndenoising auto-encoding manner, we train an attentional Seq2seq model to\nreconstruct input sentences and repredict word-level previously-quantified\nstyle relevance simultaneously. In this way, this model is endowed with the\nability to automatically predict the style relevance of each output word. Then,\nwe equip the decoder of this model with a neural style component to exploit the\npredicted wordlevel style relevance for better style transfer. Particularly, we\nfine-tune this model using a carefully-designed objective function involving\nstyle transfer, style relevance consistency, content preservation and fluency\nmodeling loss terms. Experimental results show that our proposed model achieves\nstate-of-the-art performance in terms of both transfer accuracy and content\npreservation.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 10:24:28 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Zhou", "Chulun", ""], ["Chen", "Liangyu", ""], ["Liu", "Jiachen", ""], ["Xiao", "Xinyan", ""], ["Su", "Jinsong", ""], ["Guo", "Sheng", ""], ["Wu", "Hua", ""]]}, {"id": "2005.02057", "submitter": "Budi Kurniawan", "authors": "Budi Kurniawan, Peter Vamplew, Michael Papasimeon, Richard Dazeley,\n  Cameron Foale", "title": "Discrete-to-Deep Supervised Policy Learning", "comments": "9 pages, 9 figures. Adaptive and Learning Agents Workshop at AAMAS\n  2020, Auckland, New Zealand", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are effective function approximators, but hard to train in\nthe reinforcement learning (RL) context mainly because samples are correlated.\nFor years, scholars have got around this by employing experience replay or an\nasynchronous parallel-agent system. This paper proposes Discrete-to-Deep\nSupervised Policy Learning (D2D-SPL) for training neural networks in RL.\nD2D-SPL discretises the continuous state space into discrete states and uses\nactor-critic to learn a policy. It then selects from each discrete state an\ninput value and the action with the highest numerical preference as an\ninput/target pair. Finally it uses input/target pairs from all discrete states\nto train a classifier. D2D-SPL uses a single agent, needs no experience replay\nand learns much faster than state-of-the-art methods. We test our method with\ntwo RL environments, the Cartpole and an aircraft manoeuvring simulator.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 10:49:00 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Kurniawan", "Budi", ""], ["Vamplew", "Peter", ""], ["Papasimeon", "Michael", ""], ["Dazeley", "Richard", ""], ["Foale", "Cameron", ""]]}, {"id": "2005.02071", "submitter": "Christoph Leitner", "authors": "Christoph Leitner, Robert Jarolim, Andreas Konrad, Annika Kruse,\n  Markus Tilp, J\\\"org Schr\\\"ottner, Christian Baumgartner", "title": "Automatic Tracking of the Muscle Tendon Junction in Healthy and Impaired\n  Subjects using Deep Learning", "comments": "Accepted version to be published in 2020, 42nd Annual International\n  Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),\n  Montreal, Canada", "journal-ref": null, "doi": "10.1109/EMBC44109.2020.9176145", "report-no": null, "categories": "q-bio.QM cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recording muscle tendon junction displacements during movement, allows\nseparate investigation of the muscle and tendon behaviour, respectively. In\norder to provide a fully-automatic tracking method, we employ a novel deep\nlearning approach to detect the position of the muscle tendon junction in\nultrasound images. We utilize the attention mechanism to enable the network to\nfocus on relevant regions and to obtain a better interpretation of the results.\nOur data set consists of a large cohort of 79 healthy subjects and 28 subjects\nwith movement limitations performing passive full range of motion and maximum\ncontraction movements. Our trained network shows robust detection of the muscle\ntendon junction on a diverse data set of varying quality with a mean absolute\nerror of 2.55$\\pm$1 mm. We show that our approach can be applied for various\nsubjects and can be operated in real-time. The complete software package is\navailable for open-source use via: https://github.com/luuleitner/deepMTJ\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 11:24:40 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Leitner", "Christoph", ""], ["Jarolim", "Robert", ""], ["Konrad", "Andreas", ""], ["Kruse", "Annika", ""], ["Tilp", "Markus", ""], ["Schr\u00f6ttner", "J\u00f6rg", ""], ["Baumgartner", "Christian", ""]]}, {"id": "2005.02074", "submitter": "Siyuan Liu", "authors": "Xiuyi Fan and Siyuan Liu and Thomas C. Henderson", "title": "Explainable AI for Classification using Probabilistic Logic Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overarching goal of Explainable AI is to develop systems that not only\nexhibit intelligent behaviours, but also are able to explain their rationale\nand reveal insights. In explainable machine learning, methods that produce a\nhigh level of prediction accuracy as well as transparent explanations are\nvaluable. In this work, we present an explainable classification method. Our\nmethod works by first constructing a symbolic Knowledge Base from the training\ndata, and then performing probabilistic inferences on such Knowledge Base with\nlinear programming. Our approach achieves a level of learning performance\ncomparable to that of traditional classifiers such as random forests, support\nvector machines and neural networks. It identifies decisive features that are\nresponsible for a classification as explanations and produces results similar\nto the ones found by SHAP, a state of the art Shapley Value based method. Our\nalgorithms perform well on a range of synthetic and non-synthetic data sets.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 11:39:23 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Fan", "Xiuyi", ""], ["Liu", "Siyuan", ""], ["Henderson", "Thomas C.", ""]]}, {"id": "2005.02077", "submitter": "Claudio Angione", "authors": "Claudio Angione, Eric Silverman, Elisabeth Yaneske", "title": "Using Machine Learning to Emulate Agent-Based Simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this proof-of-concept work, we evaluate the performance of multiple\nmachine-learning methods as statistical emulators for use in the analysis of\nagent-based models (ABMs). Analysing ABM outputs can be challenging, as the\nrelationships between input parameters can be non-linear or even chaotic even\nin relatively simple models, and each model run can require significant CPU\ntime. Statistical emulation, in which a statistical model of the ABM is\nconstructed to facilitate detailed model analyses, has been proposed as an\nalternative to computationally costly Monte Carlo methods. Here we compare\nmultiple machine-learning methods for ABM emulation in order to determine the\napproaches best suited to emulating the complex behaviour of ABMs. Our results\nsuggest that, in most scenarios, artificial neural networks (ANNs) and\ngradient-boosted trees outperform Gaussian process emulators, currently the\nmost commonly used method for the emulation of complex computational models.\nANNs produced the most accurate model replications in scenarios with high\nnumbers of model runs, although training times were longer than the other\nmethods. We propose that agent-based modelling would benefit from using\nmachine-learning methods for emulation, as this can facilitate more robust\nsensitivity analyses for the models while also reducing CPU time consumption\nwhen calibrating and analysing the simulation.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 11:48:36 GMT"}, {"version": "v2", "created": "Sat, 24 Jul 2021 16:04:13 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Angione", "Claudio", ""], ["Silverman", "Eric", ""], ["Yaneske", "Elisabeth", ""]]}, {"id": "2005.02104", "submitter": "Dmitry Yudin", "authors": "A Berezutskii, M Beketov, D Yudin, Z Zimbor\\'as and J Biamonte", "title": "Probing Criticality in Quantum Spin Chains with Neural Networks", "comments": "14pp, 9 figures, IoP class", "journal-ref": "J. Phys. Complex. 1 (2020) 03LT01", "doi": "10.1088/2632-072X/abaa2b", "report-no": null, "categories": "cond-mat.dis-nn cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The numerical emulation of quantum systems often requires an exponential\nnumber of degrees of freedom which translates to a computational bottleneck.\nMethods of machine learning have been used in adjacent fields for effective\nfeature extraction and dimensionality reduction of high-dimensional datasets.\nRecent studies have revealed that neural networks are further suitable for the\ndetermination of macroscopic phases of matter and associated phase transitions\nas well as efficient quantum state representation. In this work, we address\nquantum phase transitions in quantum spin chains, namely the transverse field\nIsing chain and the anisotropic XY chain, and show that even neural networks\nwith no hidden layers can be effectively trained to distinguish between\nmagnetically ordered and disordered phases. Our neural network acts to predict\nthe corresponding crossovers finite-size systems undergo. Our results extend to\na wide class of interacting quantum many-body systems and illustrate the wide\napplicability of neural networks to many-body quantum physics.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 12:34:50 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 16:51:35 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Berezutskii", "A", ""], ["Beketov", "M", ""], ["Yudin", "D", ""], ["Zimbor\u00e1s", "Z", ""], ["Biamonte", "J", ""]]}, {"id": "2005.02121", "submitter": "Subhash Nerella", "authors": "Subhash Nerella, Azra Bihorac, Patrick Tighe, Parisa Rashidi", "title": "Facial Action Unit Detection on ICU Data for Pain Assessment", "comments": "4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current day pain assessment methods rely on patient self-report or by an\nobserver like the Intensive Care Unit (ICU) nurses. Patient self-report is\nsubjective to the individual and suffers due to poor recall. Pain assessment by\nmanual observation is limited by the number of administrations per day and\nstaff workload. Previous studies showed the feasibility of automatic pain\nassessment by detecting Facial Action Units (AUs). Pain is observed to be\nassociated with certain facial action units (AUs). This method of pain\nassessment can overcome the pitfalls of present-day pain assessment techniques.\nAll the previous studies are limited to controlled environment data. In this\nstudy, we evaluated the performance of OpenFace an open-source facial behavior\nanalysis tool and AU R-CNN on the real-world ICU data. Presence of assisted\nbreathing devices, variable lighting of ICUs, patient orientation with respect\nto camera significantly affected the performance of the models, although these\nshowed the state-of-the-art results in facial behavior analysis tasks. In this\nstudy, we show the need for automated pain assessment system which is trained\non real-world ICU data for clinically acceptable pain assessment system.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 17:12:56 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Nerella", "Subhash", ""], ["Bihorac", "Azra", ""], ["Tighe", "Patrick", ""], ["Rashidi", "Parisa", ""]]}, {"id": "2005.02123", "submitter": "Yu-Kai Huang", "authors": "Yu-Kai Huang, Yueh-Cheng Liu, Tsung-Han Wu, Hung-Ting Su and Winston\n  H. Hsu", "title": "Expanding Sparse Guidance for Stereo Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of image based stereo estimation suffers from lighting\nvariations, repetitive patterns and homogeneous appearance. Moreover, to\nachieve good performance, stereo supervision requires sufficient\ndensely-labeled data, which are hard to obtain. In this work, we leverage small\namount of data with very sparse but accurate disparity cues from LiDAR to\nbridge the gap. We propose a novel sparsity expansion technique to expand the\nsparse cues concerning RGB images for local feature enhancement. The feature\nenhancement method can be easily applied to any stereo estimation algorithms\nwith cost volume at the test stage. Extensive experiments on stereo datasets\ndemonstrate the effectiveness and robustness across different backbones on\ndomain adaption and self-supervision scenario. Our sparsity expansion method\noutperforms previous methods in terms of disparity by more than 2 pixel error\non KITTI Stereo 2012 and 3 pixel error on KITTI Stereo 2015. Our approach\nsignificantly boosts the existing state-of-the-art stereo algorithms with\nextremely sparse cues.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 06:41:11 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Huang", "Yu-Kai", ""], ["Liu", "Yueh-Cheng", ""], ["Wu", "Tsung-Han", ""], ["Su", "Hung-Ting", ""], ["Hsu", "Winston H.", ""]]}, {"id": "2005.02130", "submitter": "Mahdi Zolnouri", "authors": "Mahdi Zolnouri and Xinlin Li and Vahid Partovi Nia", "title": "Importance of Data Loading Pipeline in Training Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training large-scale deep neural networks is a long, time-consuming\noperation, often requiring many GPUs to accelerate. In large models, the time\nspent loading data takes a significant portion of model training time. As GPU\nservers are typically expensive, tricks that can save training time are\nvaluable.Slow training is observed especially on real-world applications where\nexhaustive data augmentation operations are required. Data augmentation\ntechniques include: padding, rotation, adding noise, down sampling, up\nsampling, etc. These additional operations increase the need to build an\nefficient data loading pipeline, and to explore existing tools to speed up\ntraining time. We focus on the comparison of two main tools designed for this\ntask, namely binary data format to accelerate data reading, and NVIDIA DALI to\naccelerate data augmentation. Our study shows improvement on the order of 20%\nto 40% if such dedicated tools are used.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 14:19:48 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Zolnouri", "Mahdi", ""], ["Li", "Xinlin", ""], ["Nia", "Vahid Partovi", ""]]}, {"id": "2005.02131", "submitter": "XInlei He", "authors": "Xinlei He and Jinyuan Jia and Michael Backes and Neil Zhenqiang Gong\n  and Yang Zhang", "title": "Stealing Links from Graph Neural Networks", "comments": "To appear in the 30th Usenix Security Symposium, August 2021,\n  Vancouver, B.C., Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph data, such as chemical networks and social networks, may be deemed\nconfidential/private because the data owner often spends lots of resources\ncollecting the data or the data contains sensitive information, e.g., social\nrelationships. Recently, neural networks were extended to graph data, which are\nknown as graph neural networks (GNNs). Due to their superior performance, GNNs\nhave many applications, such as healthcare analytics, recommender systems, and\nfraud detection. In this work, we propose the first attacks to steal a graph\nfrom the outputs of a GNN model that is trained on the graph. Specifically,\ngiven a black-box access to a GNN model, our attacks can infer whether there\nexists a link between any pair of nodes in the graph used to train the model.\nWe call our attacks link stealing attacks. We propose a threat model to\nsystematically characterize an adversary's background knowledge along three\ndimensions which in total leads to a comprehensive taxonomy of 8 different link\nstealing attacks. We propose multiple novel methods to realize these 8 attacks.\nExtensive experiments on 8 real-world datasets show that our attacks are\neffective at stealing links, e.g., AUC (area under the ROC curve) is above 0.95\nin multiple cases. Our results indicate that the outputs of a GNN model reveal\nrich information about the structure of the graph used to train the model.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 13:22:35 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 20:38:16 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["He", "Xinlei", ""], ["Jia", "Jinyuan", ""], ["Backes", "Michael", ""], ["Gong", "Neil Zhenqiang", ""], ["Zhang", "Yang", ""]]}, {"id": "2005.02137", "submitter": "Taehyeong Kim", "authors": "Taehyeong Kim, Injune Hwang, Gi-Cheon Kang, Won-Seok Choi, Hyunseo\n  Kim, Byoung-Tak Zhang", "title": "Label Propagation Adaptive Resonance Theory for Semi-supervised\n  Continuous Learning", "comments": "5 pages, 2 figures, 1 table, accepted in ICASSP 2020", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9054655", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning and continuous learning are fundamental paradigms\nfor human-level intelligence. To deal with real-world problems where labels are\nrarely given and the opportunity to access the same data is limited, it is\nnecessary to apply these two paradigms in a joined fashion. In this paper, we\npropose Label Propagation Adaptive Resonance Theory (LPART) for semi-supervised\ncontinuous learning. LPART uses an online label propagation mechanism to\nperform classification and gradually improves its accuracy as the observed data\naccumulates. We evaluated the proposed model on visual (MNIST, SVHN, CIFAR-10)\nand audio (NSynth) datasets by adjusting the ratio of the labeled and unlabeled\ndata. The accuracies are much higher when both labeled and unlabeled data are\nused, demonstrating the significant advantage of LPART in environments where\nthe data labels are scarce.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 09:12:56 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Kim", "Taehyeong", ""], ["Hwang", "Injune", ""], ["Kang", "Gi-Cheon", ""], ["Choi", "Won-Seok", ""], ["Kim", "Hyunseo", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "2005.02138", "submitter": "Nicholas Sharp", "authors": "Nicholas Sharp, Maks Ovsjanikov", "title": "PointTriNet: Learned Triangulation of 3D Point Sets", "comments": "21 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers a new task in geometric deep learning: generating a\ntriangulation among a set of points in 3D space. We present PointTriNet, a\ndifferentiable and scalable approach enabling point set triangulation as a\nlayer in 3D learning pipelines. The method iteratively applies two neural\nnetworks: a classification network predicts whether a candidate triangle should\nappear in the triangulation, while a proposal network suggests additional\ncandidates. Both networks are structured as PointNets over nearby points and\ntriangles, using a novel triangle-relative input encoding. Since these learning\nproblems operate on local geometric data, our method is efficient and scalable,\nand generalizes to unseen shape categories. Our networks are trained in an\nunsupervised manner from a collection of shapes represented as point clouds. We\ndemonstrate the effectiveness of this approach for classical meshing tasks,\nrobustness to outliers, and as a component in end-to-end learning systems.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 01:58:35 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 12:37:01 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Sharp", "Nicholas", ""], ["Ovsjanikov", "Maks", ""]]}, {"id": "2005.02140", "submitter": "Tomislav Ivek", "authors": "Tomislav Ivek, Domagoj Vlah", "title": "BlackBox: Generalizable Reconstruction of Extremal Values from\n  Incomplete Spatio-Temporal Data", "comments": "3 figures; accepted in Extremes; 2nd place entry at the Extreme Value\n  Analysis 2019 Data Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our submission to the Extreme Value Analysis 2019 Data Challenge\nin which teams were asked to predict extremes of sea surface temperature\nanomaly within spatio-temporal regions of missing data. We present a\ncomputational framework which reconstructs missing data using convolutional\ndeep neural networks. Conditioned on incomplete data, we employ\nautoencoder-like models as multivariate conditional distributions from which\npossible reconstructions of the complete dataset are sampled using imputed\nnoise. In order to mitigate bias introduced by any one particular model, a\nprediction ensemble is constructed to create the final distribution of extremal\nvalues. Our method does not rely on expert knowledge in order to accurately\nreproduce dynamic features of a complex oceanographic system with minimal\nassumptions. The obtained results promise reusability and generalization to\nother domains.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 21:33:46 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 18:01:17 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 16:36:22 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Ivek", "Tomislav", ""], ["Vlah", "Domagoj", ""]]}, {"id": "2005.02142", "submitter": "Guillermo Arturo Mart\\'inez-Mascorro Mr.", "authors": "Guillermo A. Mart\\'inez-Mascorro, Jos\\'e R. Abreu-Pederzini, Jos\\'e C.\n  Ortiz-Bayliss, Hugo Terashima-Mar\\'in", "title": "Suspicious Behavior Detection on Shoplifting Cases for Crime Prevention\n  by Using 3D Convolutional Neural Networks", "comments": null, "journal-ref": "Computation 2021, 9(2), 24", "doi": "10.3390/computation9020024", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crime generates significant losses, both human and economic. Every year,\nbillions of dollars are lost due to attacks, crimes, and scams. Surveillance\nvideo camera networks are generating vast amounts of data, and the surveillance\nstaff can not process all the information in real-time. The human sight has its\nlimitations, where the visual focus is among the most critical ones when\ndealing with surveillance. A crime can occur in a different screen segment or\non a distinct monitor, and the staff may not notice it. Our proposal focuses on\nshoplifting crimes by analyzing special situations that an average person will\nconsider as typical conditions, but may lead to a crime. While other approaches\nidentify the crime itself, we instead model suspicious behavior -- the one that\nmay occur before a person commits a crime -- by detecting precise segments of a\nvideo with a high probability to contain a shoplifting crime. By doing so, we\nprovide the staff with more opportunities to act and prevent crime. We\nimplemented a 3DCNN model as a video feature extractor and tested its\nperformance on a dataset composed of daily-action and shoplifting samples. The\nresults are encouraging since it correctly identifies 75% of the cases where a\ncrime is about to happen.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 22:06:16 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Mart\u00ednez-Mascorro", "Guillermo A.", ""], ["Abreu-Pederzini", "Jos\u00e9 R.", ""], ["Ortiz-Bayliss", "Jos\u00e9 C.", ""], ["Terashima-Mar\u00edn", "Hugo", ""]]}, {"id": "2005.02151", "submitter": "Vince Lyzinski", "authors": "Keith Levin, Carey E. Priebe, Vince Lyzinski", "title": "On the role of features in vertex nomination: Content and context\n  together are better (sometimes)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vertex nomination is a lightly-supervised network information retrieval (IR)\ntask in which vertices of interest in one graph are used to query a second\ngraph to discover vertices of interest in the second graph. Similar to other IR\ntasks, the output of a vertex nomination scheme is a ranked list of the\nvertices in the second graph, with the heretofore unknown vertices of interest\nideally concentrating at the top of the list. Vertex nomination schemes provide\na useful suite of tools for efficiently mining complex networks for pertinent\ninformation. In this paper, we explore, both theoretically and practically, the\ndual roles of content (i.e., edge and vertex attributes) and context (i.e.,\nnetwork topology) in vertex nomination. We provide necessary and sufficient\nconditions under which vertex nomination schemes that leverage both content and\ncontext outperform schemes that leverage only content or context separately.\nWhile the joint utility of both content and context has been demonstrated\nempirically in the literature, the framework presented in this paper provides a\nnovel theoretical basis for understanding the potential complementary roles of\nnetwork features and topology.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 15:13:24 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 13:01:43 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Levin", "Keith", ""], ["Priebe", "Carey E.", ""], ["Lyzinski", "Vince", ""]]}, {"id": "2005.02153", "submitter": "Yunlian Lv", "authors": "Yunlian Lv, Ning Xie, Yimin Shi, Zijiao Wang, and Heng Tao Shen", "title": "Improving Target-driven Visual Navigation with Attention on 3D Spatial\n  Relationships", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embodied artificial intelligence (AI) tasks shift from tasks focusing on\ninternet images to active settings involving embodied agents that perceive and\nact within 3D environments. In this paper, we investigate the target-driven\nvisual navigation using deep reinforcement learning (DRL) in 3D indoor scenes,\nwhose navigation task aims to train an agent that can intelligently make a\nseries of decisions to arrive at a pre-specified target location from any\npossible starting positions only based on egocentric views. However, most\nnavigation methods currently struggle against several challenging problems,\nsuch as data efficiency, automatic obstacle avoidance, and generalization.\nGeneralization problem means that agent does not have the ability to transfer\nnavigation skills learned from previous experience to unseen targets and\nscenes. To address these issues, we incorporate two designs into classic DRL\nframework: attention on 3D knowledge graph (KG) and target skill extension\n(TSE) module. On the one hand, our proposed method combines visual features and\n3D spatial representations to learn navigation policy. On the other hand, TSE\nmodule is used to generate sub-targets which allow agent to learn from\nfailures. Specifically, our 3D spatial relationships are encoded through\nrecently popular graph convolutional network (GCN). Considering the real world\nsettings, our work also considers open action and adds actionable targets into\nconventional navigation situations. Those more difficult settings are applied\nto test whether DRL agent really understand its task, navigating environment,\nand can carry out reasoning. Our experiments, performed in the AI2-THOR, show\nthat our model outperforms the baselines in both SR and SPL metrics, and\nimproves generalization ability across targets and scenes.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 08:46:38 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Lv", "Yunlian", ""], ["Xie", "Ning", ""], ["Shi", "Yimin", ""], ["Wang", "Zijiao", ""], ["Shen", "Heng Tao", ""]]}, {"id": "2005.02154", "submitter": "Xiu-Shen Wei", "authors": "Benyi Hu, Ren-Jie Song, Xiu-Shen Wei, Yazhou Yao, Xian-Sheng Hua, and\n  Yuehu Liu", "title": "PyRetri: A PyTorch-based Library for Unsupervised Image Retrieval by\n  Deep Convolutional Neural Networks", "comments": "Accepted by ACM Multimedia Conference 2020. PyRetri is open-source\n  and available at https://github.com/PyRetri/PyRetri", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant progress of applying deep learning methods to the field\nof content-based image retrieval, there has not been a software library that\ncovers these methods in a unified manner. In order to fill this gap, we\nintroduce PyRetri, an open source library for deep learning based unsupervised\nimage retrieval. The library encapsulates the retrieval process in several\nstages and provides functionality that covers various prominent methods for\neach stage. The idea underlying its design is to provide a unified platform for\ndeep learning based image retrieval research, with high usability and\nextensibility. To the best of our knowledge, this is the first open-source\nlibrary for unsupervised image retrieval by deep learning.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 10:17:18 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 13:12:10 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Hu", "Benyi", ""], ["Song", "Ren-Jie", ""], ["Wei", "Xiu-Shen", ""], ["Yao", "Yazhou", ""], ["Hua", "Xian-Sheng", ""], ["Liu", "Yuehu", ""]]}, {"id": "2005.02155", "submitter": "AKM Shahariar Azad Rabby", "authors": "Jannatul Ferdous, Suvrajit Karmaker, A K M Shahariar Azad Rabby, Syed\n  Akhter Hossain", "title": "MatriVasha: A Multipurpose Comprehensive Database for Bangla Handwritten\n  Compound Characters", "comments": "19 fig, 2 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  At present, recognition of the Bangla handwriting compound character has been\nan essential issue for many years. In recent years there have been\napplication-based researches in machine learning, and deep learning, which is\ngained interest, and most notably is handwriting recognition because it has a\ntremendous application such as Bangla OCR. MatrriVasha, the project which can\nrecognize Bangla, handwritten several compound characters. Currently, compound\ncharacter recognition is an important topic due to its variant application, and\nhelps to create old forms, and information digitization with reliability. But\nunfortunately, there is a lack of a comprehensive dataset that can categorize\nall types of Bangla compound characters. MatrriVasha is an attempt to align\ncompound character, and it's challenging because each person has a unique style\nof writing shapes. After all, MatrriVasha has proposed a dataset that intends\nto recognize Bangla 120(one hundred twenty) compound characters that consist of\n2552(two thousand five hundred fifty-two) isolated handwritten characters\nwritten unique writers which were collected from within Bangladesh. This\ndataset faced problems in terms of the district, age, and gender-based written\nrelated research because the samples were collected that includes a verity of\nthe district, age group, and the equal number of males, and females. As of now,\nour proposed dataset is so far the most extensive dataset for Bangla compound\ncharacters. It is intended to frame the acknowledgment technique for\nhandwritten Bangla compound character. In the future, this dataset will be made\npublicly available to help to widen the research.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 06:38:12 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 07:59:45 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Ferdous", "Jannatul", ""], ["Karmaker", "Suvrajit", ""], ["Rabby", "A K M Shahariar Azad", ""], ["Hossain", "Syed Akhter", ""]]}, {"id": "2005.02157", "submitter": "Mohammadhossein Toutiaee", "authors": "Mohammadhossein Toutiaee, Soheyla Amirian, John A. Miller, Sheng Li", "title": "Stereotype-Free Classification of Fictitious Faces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equal Opportunity and Fairness are receiving increasing attention in\nartificial intelligence. Stereotyping is another source of discrimination,\nwhich yet has been unstudied in literature. GAN-made faces would be exposed to\nsuch discrimination, if they are classified by human perception. It is possible\nto eliminate the human impact on fictitious faces classification task by the\nuse of statistical approaches. We present a novel approach through penalized\nregression to label stereotype-free GAN-generated synthetic unlabeled images.\nThe proposed approach aids labeling new data (fictitious output images) by\nminimizing a penalized version of the least squares cost function between\nrealistic pictures and target pictures.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 04:37:54 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Toutiaee", "Mohammadhossein", ""], ["Amirian", "Soheyla", ""], ["Miller", "John A.", ""], ["Li", "Sheng", ""]]}, {"id": "2005.02158", "submitter": "Jie Wang", "authors": "Hao Zhang, Jie Wang", "title": "An Unsupervised Semantic Sentence Ranking Scheme for Text Documents", "comments": "To appear in Integrated Computer-Aided Engineering (ICAE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Semantic SentenceRank (SSR), an unsupervised scheme for\nautomatically ranking sentences in a single document according to their\nrelative importance. In particular, SSR extracts essential words and phrases\nfrom a text document, and uses semantic measures to construct, respectively, a\nsemantic phrase graph over phrases and words, and a semantic sentence graph\nover sentences. It applies two variants of article-structure-biased PageRank to\nscore phrases and words on the first graph and sentences on the second graph.\nIt then combines these scores to generate the final score for each sentence.\nFinally, SSR solves a multi-objective optimization problem for ranking\nsentences based on their final scores and topic diversity through semantic\nsubtopic clustering. An implementation of SSR that runs in quadratic time is\npresented, and it outperforms, on the SummBank benchmarks, each individual\njudge's ranking and compares favorably with the combined ranking of all judges.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 20:17:51 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Zhang", "Hao", ""], ["Wang", "Jie", ""]]}, {"id": "2005.02160", "submitter": "Hailey James", "authors": "Hailey James, Otkrist Gupta, Dan Raviv", "title": "Printing and Scanning Attack for Image Counter Forensics", "comments": "10 pages, 5 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Examining the authenticity of images has become increasingly important as\nmanipulation tools become more accessible and advanced. Recent work has shown\nthat while CNN-based image manipulation detectors can successfully identify\nmanipulations, they are also vulnerable to adversarial attacks, ranging from\nsimple double JPEG compression to advanced pixel-based perturbation. In this\npaper we explore another method of highly plausible attack: printing and\nscanning. We demonstrate the vulnerability of two state-of-the-art models to\nthis type of attack. We also propose a new machine learning model that performs\ncomparably to these state-of-the-art models when trained and validated on\nprinted and scanned images. Of the three models, our proposed model outperforms\nthe others when trained and validated on images from a single printer. To\nfacilitate this exploration, we create a dataset of over 6,000 printed and\nscanned image blocks. Further analysis suggests that variation between images\nproduced from different printers is significant, large enough that good\nvalidation accuracy on images from one printer does not imply similar\nvalidation accuracy on identical images from a different printer.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 00:32:15 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 17:01:59 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["James", "Hailey", ""], ["Gupta", "Otkrist", ""], ["Raviv", "Dan", ""]]}, {"id": "2005.02161", "submitter": "Jiayi Wei", "authors": "Jiayi Wei, Maruth Goyal, Greg Durrett, Isil Dillig", "title": "LambdaNet: Probabilistic Type Inference using Graph Neural Networks", "comments": "Accepted as a poster at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As gradual typing becomes increasingly popular in languages like Python and\nTypeScript, there is a growing need to infer type annotations automatically.\nWhile type annotations help with tasks like code completion and static error\ncatching, these annotations cannot be fully determined by compilers and are\ntedious to annotate by hand. This paper proposes a probabilistic type inference\nscheme for TypeScript based on a graph neural network. Our approach first uses\nlightweight source code analysis to generate a program abstraction called a\ntype dependency graph, which links type variables with logical constraints as\nwell as name and usage information. Given this program abstraction, we then use\na graph neural network to propagate information between related type variables\nand eventually make type predictions. Our neural architecture can predict both\nstandard types, like number or string, as well as user-defined types that have\nnot been encountered during training. Our experimental results show that our\napproach outperforms prior work in this space by $14\\%$ (absolute) on library\ntypes, while having the ability to make type predictions that are out of scope\nfor existing techniques.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 17:48:40 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Wei", "Jiayi", ""], ["Goyal", "Maruth", ""], ["Durrett", "Greg", ""], ["Dillig", "Isil", ""]]}, {"id": "2005.02162", "submitter": "Etienne David", "authors": "E. David, S. Madec, P. Sadeghi-Tehran, H. Aasen, B. Zheng, S. Liu, N.\n  Kirchgessner, G. Ishikawa, K. Nagasawa, M.A. Badhon, C. Pozniak, B. de Solan,\n  A. Hund, S.C. Chapman, F. Baret, I. Stavness, W. Guo", "title": "Global Wheat Head Detection (GWHD) dataset: a large and diverse dataset\n  of high resolution RGB labelled images to develop and benchmark wheat head\n  detection methods", "comments": "16 pages, 7 figures, Dataset paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection of wheat heads is an important task allowing to estimate pertinent\ntraits including head population density and head characteristics such as\nsanitary state, size, maturity stage and the presence of awns. Several studies\ndeveloped methods for wheat head detection from high-resolution RGB imagery.\nThey are based on computer vision and machine learning and are generally\ncalibrated and validated on limited datasets. However, variability in\nobservational conditions, genotypic differences, development stages, head\norientation represents a challenge in computer vision. Further, possible\nblurring due to motion or wind and overlap between heads for dense populations\nmake this task even more complex. Through a joint international collaborative\neffort, we have built a large, diverse and well-labelled dataset, the Global\nWheat Head detection (GWHD) dataset. It contains 4,700 high-resolution RGB\nimages and 190,000 labelled wheat heads collected from several countries around\nthe world at different growth stages with a wide range of genotypes. Guidelines\nfor image acquisition, associating minimum metadata to respect FAIR principles\nand consistent head labelling methods are proposed when developing new head\ndetection datasets. The GWHD is publicly available at\nhttp://www.global-wheat.com/ and aimed at developing and benchmarking methods\nfor wheat head detection.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 14:20:26 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 07:34:36 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["David", "E.", ""], ["Madec", "S.", ""], ["Sadeghi-Tehran", "P.", ""], ["Aasen", "H.", ""], ["Zheng", "B.", ""], ["Liu", "S.", ""], ["Kirchgessner", "N.", ""], ["Ishikawa", "G.", ""], ["Nagasawa", "K.", ""], ["Badhon", "M. A.", ""], ["Pozniak", "C.", ""], ["de Solan", "B.", ""], ["Hund", "A.", ""], ["Chapman", "S. C.", ""], ["Baret", "F.", ""], ["Stavness", "I.", ""], ["Guo", "W.", ""]]}, {"id": "2005.02163", "submitter": "Anthony Bagnall Dr", "authors": "Anthony Bagnall, Paul Southam, James Large and Richard Harvey", "title": "Detecting Electric Devices in 3D Images of Bags", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aviation and transport security industries face the challenge of\nscreening high volumes of baggage for threats and contraband in the minimum\ntime possible. Automation and semi-automation of this procedure offers the\npotential to increase security by detecting more threats and improve the\ncustomer experience by speeding up the process. Traditional 2D x-ray images are\noften extremely difficult to examine due to the fact that they are tightly\npacked and contain a wide variety of cluttered and occluded objects. Because of\nthese limitations, major airports are introducing 3D x-ray Computed Tomography\n(CT) baggage scanning. We investigate whether we can automate the process of\ndetecting electric devices in these 3D images of luggage. Detecting electrical\ndevices is of particular concern as they can be used to conceal explosives.\nGiven the massive volume of luggage that needs to be screened for this threat,\nthe best way to automate the detection is to first filter whether a bag\ncontains an electric device or not, and if it does, to identify the number of\ndevices and their location. We present an algorithm, Unpack, Predict, eXtract,\nRepack (UXPR), which involves unpacking through segmenting the data at a range\nof scales using an algorithm known as the Sieve, predicting whether a segment\nis electrical or not based on the histogram of voxel intensities, then\nrepacking the bag by ensembling the segments and predictions to identify the\ndevices in bags. Through a range of experiments using data provided by ALERT\n(Awareness and Localization of Explosives-Related Threats) we show that this\nsystem can find a high proportion of devices with unsupervised segmentation if\na similar device has been seen before, and shows promising results for\ndetecting devices not seen at all based on the properties of its constituent\nparts.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 11:30:42 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Bagnall", "Anthony", ""], ["Southam", "Paul", ""], ["Large", "James", ""], ["Harvey", "Richard", ""]]}, {"id": "2005.02165", "submitter": "S.H. Shabbeer Basha", "authors": "S.H.Shabbeer Basha, Sravan Kumar Vinakota, Viswanath Pulabaigari,\n  Snehasis Mukherjee, Shiv Ram Dubey", "title": "AutoTune: Automatically Tuning Convolutional Neural Networks for\n  Improved Transfer Learning", "comments": "This paper is published in Neural Networks journal", "journal-ref": null, "doi": "10.1016/j.neunet.2020.10.009", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning enables solving a specific task having limited data by\nusing the pre-trained deep networks trained on large-scale datasets. Typically,\nwhile transferring the learned knowledge from source task to the target task,\nthe last few layers are fine-tuned (re-trained) over the target dataset.\nHowever, these layers are originally designed for the source task that might\nnot be suitable for the target task. In this paper, we introduce a mechanism\nfor automatically tuning the Convolutional Neural Networks (CNN) for improved\ntransfer learning. The pre-trained CNN layers are tuned with the knowledge from\ntarget data using Bayesian Optimization. First, we train the final layer of the\nbase CNN model by replacing the number of neurons in the softmax layer with the\nnumber of classes involved in the target task. Next, the pre-trained CNN is\ntuned automatically by observing the classification performance on the\nvalidation data (greedy criteria). To evaluate the performance of the proposed\nmethod, experiments are conducted on three benchmark datasets, e.g.,\nCalTech-101, CalTech-256, and Stanford Dogs. The classification results\nobtained through the proposed AutoTune method outperforms the standard baseline\ntransfer learning methods over the three datasets by achieving $95.92\\%$,\n$86.54\\%$, and $84.67\\%$ accuracy over CalTech-101, CalTech-256, and Stanford\nDogs, respectively. The experimental results obtained in this study depict that\ntuning of the pre-trained CNN layers with the knowledge from the target dataset\nconfesses better transfer learning ability. The source codes are available at\nhttps://github.com/JekyllAndHyde8999/AutoTune_CNN_TransferLearning.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 10:42:06 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 05:35:23 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Basha", "S. H. Shabbeer", ""], ["Vinakota", "Sravan Kumar", ""], ["Pulabaigari", "Viswanath", ""], ["Mukherjee", "Snehasis", ""], ["Dubey", "Shiv Ram", ""]]}, {"id": "2005.02167", "submitter": "Brian Goodwin", "authors": "Brian D Goodwin, Corey Jaskolski, Can Zhong, Herick Asmani", "title": "Intra-model Variability in COVID-19 Classification Using Chest X-ray\n  Images", "comments": "7 pages, 5 figures; Writing, analysis, and design carried out by\n  authors Brian and Corey; experiments carried out by authors Can and Herick;\n  results and code located at\n  https://github.com/synthetaic/COVID19-IntraModel-Variability and\n  https://covidresearch.ai/datasets/dataset?id=2", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  X-ray and computed tomography (CT) scanning technologies for COVID-19\nscreening have gained significant traction in AI research since the start of\nthe coronavirus pandemic. Despite these continuous advancements for COVID-19\nscreening, many concerns remain about model reliability when used in a clinical\nsetting. Much has been published, but with limited transparency in expected\nmodel performance. We set out to address this limitation through a set of\nexperiments to quantify baseline performance metrics and variability for\nCOVID-19 detection in chest x-ray for 12 common deep learning architectures.\nSpecifically, we adopted an experimental paradigm controlling for\ntrain-validation-test split and model architecture where the source of\nprediction variability originates from model weight initialization, random data\naugmentation transformations, and batch shuffling. Each model architecture was\ntrained 5 separate times on identical train-validation-test splits of a\npublicly available x-ray image dataset provided by Cohen et al. (2020). Results\nindicate that even within model architectures, model behavior varies in a\nmeaningful way between trained models. Best performing models achieve a false\nnegative rate of 3 out of 20 for detecting COVID-19 in a hold-out set. While\nthese results show promise in using AI for COVID-19 screening, they further\nsupport the urgent need for diverse medical imaging datasets for model training\nin a way that yields consistent prediction outcomes. It is our hope that these\nmodeling results accelerate work in building a more robust dataset and a viable\nscreening tool for COVID-19.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 21:20:32 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Goodwin", "Brian D", ""], ["Jaskolski", "Corey", ""], ["Zhong", "Can", ""], ["Asmani", "Herick", ""]]}, {"id": "2005.02175", "submitter": "Weijian Pan", "authors": "Liang Huang (Member, IEEE), You Zhang, Weijian Pan, Jinyin Chen, Li\n  Ping Qian (Senior Member, IEEE) and Yuan Wu (Senior Member, IEEE)", "title": "Visualizing Deep Learning-based Radio Modulation Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has recently been successfully applied in automatic modulation\nclassification by extracting and classifying radio features in an end-to-end\nway. However, deep learning-based radio modulation classifiers are lack of\ninterpretability, and there is little explanation or visibility into what kinds\nof radio features are extracted and chosen for classification. In this paper,\nwe visualize different deep learning-based radio modulation classifiers by\nintroducing a class activation vector. Specifically, both convolutional neural\nnetworks (CNN) based classifier and long short-term memory (LSTM) based\nclassifier are separately studied, and their extracted radio features are\nvisualized. Extensive numerical results show both the CNN-based classifier and\nLSTM-based classifier extract similar radio features relating to modulation\nreference points. In particular, for the LSTM-based classifier, its obtained\nradio features are similar to the knowledge of human experts. Our numerical\nresults indicate the radio features extracted by deep learning-based\nclassifiers greatly depend on the contents carried by radio signals, and a\nshort radio sample may lead to misclassification.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 07:06:18 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 12:25:22 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Huang", "Liang", "", "Member, IEEE"], ["Zhang", "You", "", "Senior Member, IEEE"], ["Pan", "Weijian", "", "Senior Member, IEEE"], ["Chen", "Jinyin", "", "Senior Member, IEEE"], ["Qian", "Li Ping", "", "Senior Member, IEEE"], ["Wu", "Yuan", "", "Senior Member, IEEE"]]}, {"id": "2005.02177", "submitter": "Yuanrui Dong", "authors": "Yuanrui Dong, Peng Zhao, Hanqiao Yu, Cong Zhao and Shusen Yang", "title": "CDC: Classification Driven Compression for Bandwidth Efficient\n  Edge-Cloud Collaborative Deep Learning", "comments": "Accepted by IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging edge-cloud collaborative Deep Learning (DL) paradigm aims at\nimproving the performance of practical DL implementations in terms of cloud\nbandwidth consumption, response latency, and data privacy preservation.\nFocusing on bandwidth efficient edge-cloud collaborative training of DNN-based\nclassifiers, we present CDC, a Classification Driven Compression framework that\nreduces bandwidth consumption while preserving classification accuracy of\nedge-cloud collaborative DL. Specifically, to reduce bandwidth consumption, for\nresource-limited edge servers, we develop a lightweight autoencoder with a\nclassification guidance for compression with classification driven feature\npreservation, which allows edges to only upload the latent code of raw data for\naccurate global training on the Cloud. Additionally, we design an adjustable\nquantization scheme adaptively pursuing the tradeoff between bandwidth\nconsumption and classification accuracy under different network conditions,\nwhere only fine-tuning is required for rapid compression ratio adjustment.\nResults of extensive experiments demonstrate that, compared with DNN training\nwith raw data, CDC consumes 14.9 times less bandwidth with an accuracy loss no\nmore than 1.06%, and compared with DNN training with data compressed by AE\nwithout guidance, CDC introduces at least 100% lower accuracy loss.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 07:40:32 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Dong", "Yuanrui", ""], ["Zhao", "Peng", ""], ["Yu", "Hanqiao", ""], ["Zhao", "Cong", ""], ["Yang", "Shusen", ""]]}, {"id": "2005.02178", "submitter": "Bill Yuchen Lin", "authors": "Wenxuan Zhou, Bill Yuchen Lin, Xiang Ren", "title": "IsoBN: Fine-Tuning BERT with Isotropic Batch Normalization", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning pre-trained language models (PTLMs), such as BERT and its better\nvariant RoBERTa, has been a common practice for advancing performance in\nnatural language understanding (NLU) tasks. Recent advance in representation\nlearning shows that isotropic (i.e., unit-variance and uncorrelated) embeddings\ncan significantly improve performance on downstream tasks with faster\nconvergence and better generalization. The isotropy of the pre-trained\nembeddings in PTLMs, however, is relatively under-explored. In this paper, we\nanalyze the isotropy of the pre-trained [CLS] embeddings of PTLMs with\nstraightforward visualization, and point out two major issues: high variance in\ntheir standard deviation, and high correlation between different dimensions. We\nalso propose a new network regularization method, isotropic batch normalization\n(IsoBN) to address the issues, towards learning more isotropic representations\nin fine-tuning by dynamically penalizing dominating principal components. This\nsimple yet effective fine-tuning method yields about 1.0 absolute increment on\nthe average of seven NLU tasks.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 11:49:09 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 01:40:26 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Zhou", "Wenxuan", ""], ["Lin", "Bill Yuchen", ""], ["Ren", "Xiang", ""]]}, {"id": "2005.02181", "submitter": "Wei Ji Ma", "authors": "Wei Ji Ma and Benjamin Peters", "title": "A neural network walks into a lab: towards using deep nets as models for\n  human behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What might sound like the beginning of a joke has become an attractive\nprospect for many cognitive scientists: the use of deep neural network models\n(DNNs) as models of human behavior in perceptual and cognitive tasks. Although\nDNNs have taken over machine learning, attempts to use them as models of human\nbehavior are still in the early stages. Can they become a versatile model class\nin the cognitive scientist's toolbox? We first argue why DNNs have the\npotential to be interesting models of human behavior. We then discuss how that\npotential can be more fully realized. On the one hand, we argue that the cycle\nof training, testing, and revising DNNs needs to be revisited through the lens\nof the cognitive scientist's goals. Specifically, we argue that methods for\nassessing the goodness of fit between DNN models and human behavior have to\ndate been impoverished. On the other hand, cognitive science might have to\nstart using more complex tasks (including richer stimulus spaces), but doing so\nmight be beneficial for DNN-independent reasons as well. Finally, we highlight\navenues where traditional cognitive process models and DNNs may show productive\nsynergy.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 11:17:36 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Ma", "Wei Ji", ""], ["Peters", "Benjamin", ""]]}, {"id": "2005.02184", "submitter": "Filip Marcinek", "authors": "Filip Marcinek", "title": "Reproduction of Lateral Inhibition-Inspired Convolutional Neural Network\n  for Visual Attention and Saliency Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, neural networks have continued to flourish, achieving high\nefficiency in detecting relevant objects in photos or simply recognizing\n(classifying) these objects - mainly using CNN networks. Current solutions,\nhowever, are far from ideal, because it often turns out that network can be\neffectively confused with even natural images examples. I suspect that the\nclassification of an object is strongly influenced by the background pixels on\nwhich the object is located. In my work, I analyze the above problem using for\nthis purpose saliency maps created by the LICNN network. They are designed to\nsuppress the neurons surrounding the examined object and, consequently, reduce\nthe contribution of background pixels to the classifier predictions. My\nexperiments on the natural and adversarial images datasets show that, indeed,\nthere is a visible correlation between the background and the wrong-classified\nforeground object. This behavior of the network is not supported by human\nexperience, because, for example, we do not confuse the yellow school bus with\nthe snow plow just because it is on the snowy background.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 13:55:47 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Marcinek", "Filip", ""]]}, {"id": "2005.02191", "submitter": "Alexandre Capone", "authors": "Alexandre Capone, Jonas Umlauft, Thomas Beckers, Armin Lederer, Sandra\n  Hirche", "title": "Localized active learning of Gaussian process state space models", "comments": "Submitted to Learning for Dynamics and Control (L4DC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of learning-based control techniques crucially depends on how\neffectively the system is explored. While most exploration techniques aim to\nachieve a globally accurate model, such approaches are generally unsuited for\nsystems with unbounded state spaces. Furthermore, a globally accurate model is\nnot required to achieve good performance in many common control applications,\ne.g., local stabilization tasks. In this paper, we propose an active learning\nstrategy for Gaussian process state space models that aims to obtain an\naccurate model on a bounded subset of the state-action space. Our approach aims\nto maximize the mutual information of the exploration trajectories with respect\nto a discretization of the region of interest. By employing model predictive\ncontrol, the proposed technique integrates information collected during\nexploration and adaptively improves its exploration strategy. To enable\ncomputational tractability, we decouple the choice of most informative data\npoints from the model predictive control optimization step. This yields two\noptimization problems that can be solved in parallel. We apply the proposed\nmethod to explore the state space of various dynamical systems and compare our\napproach to a commonly used entropy-based exploration strategy. In all\nexperiments, our method yields a better model within the region of interest\nthan the entropy-based method.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 05:35:02 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 08:54:09 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 19:57:11 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Capone", "Alexandre", ""], ["Umlauft", "Jonas", ""], ["Beckers", "Thomas", ""], ["Lederer", "Armin", ""], ["Hirche", "Sandra", ""]]}, {"id": "2005.02196", "submitter": "Shujian Yu", "authors": "Shujian Yu, Ammar Shaker, Francesco Alesiani, Jose C. Principe", "title": "Measuring the Discrepancy between Conditional Distributions: Methods,\n  Properties and Applications", "comments": "manuscript accepted at IJCAI 20; added additional notes on\n  computational complexity and auto-differentiable property; code is available\n  at https://github.com/SJYuCNEL/Bregman-Correntropy-Conditional-Divergence", "journal-ref": null, "doi": "10.24963/ijcai.2020/385", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple yet powerful test statistic to quantify the discrepancy\nbetween two conditional distributions. The new statistic avoids the explicit\nestimation of the underlying distributions in highdimensional space and it\noperates on the cone of symmetric positive semidefinite (SPS) matrix using the\nBregman matrix divergence. Moreover, it inherits the merits of the correntropy\nfunction to explicitly incorporate high-order statistics in the data. We\npresent the properties of our new statistic and illustrate its connections to\nprior art. We finally show the applications of our new statistic on three\ndifferent machine learning problems, namely the multi-task learning over\ngraphs, the concept drift detection, and the information-theoretic feature\nselection, to demonstrate its utility and advantage. Code of our statistic is\navailable at https://bit.ly/BregmanCorrentropy.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 14:03:55 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 00:32:02 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Yu", "Shujian", ""], ["Shaker", "Ammar", ""], ["Alesiani", "Francesco", ""], ["Principe", "Jose C.", ""]]}, {"id": "2005.02205", "submitter": "Min Chen", "authors": "Min Chen and Zhikun Zhang and Tianhao Wang and Michael Backes and\n  Mathias Humbert and Yang Zhang", "title": "When Machine Unlearning Jeopardizes Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The right to be forgotten states that a data owner has the right to erase her\ndata from an entity storing it. In the context of machine learning (ML), the\nright to be forgotten requires an ML model owner to remove the data owner's\ndata from the training set used to build the ML model, a process known as\nmachine unlearning. While originally designed to protect the privacy of the\ndata owner, we argue that machine unlearning may leave some imprint of the data\nin the ML model and thus create unintended privacy risks.\n  In this paper, we perform the first study on investigating the unintended\ninformation leakage caused by machine unlearning. We propose a novel membership\ninference attack which leverages the different outputs of an ML model's two\nversions to infer whether the deleted sample is part of the training set. Our\nexperiments over five different datasets demonstrate that the proposed\nmembership inference attack achieves strong performance. More importantly, we\nshow that our attack in multiple cases outperforms the classical membership\ninference attack on the original ML model, which indicates that machine\nunlearning can have counterproductive effects on privacy. We notice that the\nprivacy degradation is especially significant for well-generalized ML models\nwhere classical membership inference does not perform well. We further\ninvestigate two mechanisms to mitigate the newly discovered privacy risks and\nshow that the only effective mechanism is to release the predicted label only.\nWe believe that our results can help improve privacy in practical\nimplementation of machine unlearning.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 14:11:52 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Chen", "Min", ""], ["Zhang", "Zhikun", ""], ["Wang", "Tianhao", ""], ["Backes", "Michael", ""], ["Humbert", "Mathias", ""], ["Zhang", "Yang", ""]]}, {"id": "2005.02209", "submitter": "Djallel Bouneffouf", "authors": "Djallel Bouneffouf and Emmanuelle Claeys", "title": "Hyper-parameter Tuning for the Contextual Bandit", "comments": "arXiv admin note: text overlap with arXiv:1705.03821", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study here the problem of learning the exploration exploitation trade-off\nin the contextual bandit problem with linear reward function setting. In the\ntraditional algorithms that solve the contextual bandit problem, the\nexploration is a parameter that is tuned by the user. However, our proposed\nalgorithm learn to choose the right exploration parameters in an online manner\nbased on the observed context, and the immediate reward received for the chosen\naction. We have presented here two algorithms that uses a bandit to find the\noptimal exploration of the contextual bandit algorithm, which we hope is the\nfirst step toward the automation of the multi-armed bandit algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 17:20:19 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Bouneffouf", "Djallel", ""], ["Claeys", "Emmanuelle", ""]]}, {"id": "2005.02211", "submitter": "Alessandro Salatiello", "authors": "Alessandro Salatiello and Martin A. Giese", "title": "Recurrent Neural Network Learning of Performance and Intrinsic\n  Population Dynamics from Sparse Neural Data", "comments": null, "journal-ref": "Artificial Neural Networks and Machine Learning - ICANN 2020.\n  ICANN 2020. Lecture Notes in Computer Science, vol 12396. Springer,\n  Cham.:874-86", "doi": "10.1007/978-3-030-61609-0_69", "report-no": null, "categories": "q-bio.NC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are popular models of brain function. The\ntypical training strategy is to adjust their input-output behavior so that it\nmatches that of the biological circuit of interest. Even though this strategy\nensures that the biological and artificial networks perform the same\ncomputational task, it does not guarantee that their internal activity dynamics\nmatch. This suggests that the trained RNNs might end up performing the task\nemploying a different internal computational mechanism, which would make them a\nsuboptimal model of the biological circuit. In this work, we introduce a novel\ntraining strategy that allows learning not only the input-output behavior of an\nRNN but also its internal network dynamics, based on sparse neural recordings.\nWe test the proposed method by training an RNN to simultaneously reproduce\ninternal dynamics and output signals of a physiologically-inspired neural\nmodel. Specifically, this model generates the multiphasic muscle-like activity\npatterns typically observed during the execution of reaching movements, based\non the oscillatory activation patterns concurrently observed in the motor\ncortex. Remarkably, we show that the reproduction of the internal dynamics is\nsuccessful even when the training algorithm relies on the activities of a small\nsubset of neurons sampled from the biological network. Furthermore, we show\nthat training the RNNs with this method significantly improves their\ngeneralization performance. Overall, our results suggest that the proposed\nmethod is suitable for building powerful functional RNN models, which\nautomatically capture important computational properties of the biological\ncircuit of interest from sparse neural recordings.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 14:16:54 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Salatiello", "Alessandro", ""], ["Giese", "Martin A.", ""]]}, {"id": "2005.02217", "submitter": "Manuel Nunes", "authors": "Manuel Nunes, Enrico Gerding, Frank McGroarty, Mahesan Niranjan", "title": "Long short-term memory networks and laglasso for bond yield forecasting:\n  Peeping inside the black box", "comments": "27 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern decision-making in fixed income asset management benefits from\nintelligent systems, which involve the use of state-of-the-art machine learning\nmodels and appropriate methodologies. We conduct the first study of bond yield\nforecasting using long short-term memory (LSTM) networks, validating its\npotential and identifying its memory advantage. Specifically, we model the\n10-year bond yield using univariate LSTMs with three input sequences and five\nforecasting horizons. We compare those with multilayer perceptrons (MLP),\nunivariate and with the most relevant features. To demystify the notion of\nblack box associated with LSTMs, we conduct the first internal study of the\nmodel. To this end, we calculate the LSTM signals through time, at selected\nlocations in the memory cell, using sequence-to-sequence architectures, uni and\nmultivariate. We then proceed to explain the states' signals using exogenous\ninformation, for what we develop the LSTM-LagLasso methodology. The results\nshow that the univariate LSTM model with additional memory is capable of\nachieving similar results as the multivariate MLP using macroeconomic and\nmarket information. Furthermore, shorter forecasting horizons require smaller\ninput sequences and vice-versa. The most remarkable property found consistently\nin the LSTM signals, is the activation/deactivation of units through time, and\nthe specialisation of units by yield range or feature. Those signals are\ncomplex but can be explained by exogenous variables. Additionally, some of the\nrelevant features identified via LSTM-LagLasso are not commonly used in\nforecasting models. In conclusion, our work validates the potential of LSTMs\nand methodologies for bonds, providing additional tools for financial\npractitioners.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 14:23:00 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Nunes", "Manuel", ""], ["Gerding", "Enrico", ""], ["McGroarty", "Frank", ""], ["Niranjan", "Mahesan", ""]]}, {"id": "2005.02231", "submitter": "Deepta Rajan", "authors": "Deepta Rajan, Jayaraman J. Thiagarajan, Alexandros Karargyris,\n  Satyananda Kashyap", "title": "Self-Training with Improved Regularization for Sample-Efficient Chest\n  X-Ray Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated diagnostic assistants in healthcare necessitate accurate AI models\nthat can be trained with limited labeled data, can cope with severe class\nimbalances and can support simultaneous prediction of multiple disease\nconditions. To this end, we present a deep learning framework that utilizes a\nnumber of key components to enable robust modeling in such challenging\nscenarios. Using an important use-case in chest X-ray classification, we\nprovide several key insights on the effective use of data augmentation,\nself-training via distillation and confidence tempering for small data learning\nin medical imaging. Our results show that using 85% lesser labeled data, we can\nbuild predictive models that match the performance of classifiers trained in a\nlarge-scale data setting.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 02:36:00 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 18:46:26 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Rajan", "Deepta", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Karargyris", "Alexandros", ""], ["Kashyap", "Satyananda", ""]]}, {"id": "2005.02249", "submitter": "Lev Utkin", "authors": "Maxim S. Kovalev and Lev V. Utkin", "title": "A robust algorithm for explaining unreliable machine learning survival\n  models using the Kolmogorov-Smirnov bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new robust algorithm based of the explanation method SurvLIME called\nSurvLIME-KS is proposed for explaining machine learning survival models. The\nalgorithm is developed to ensure robustness to cases of a small amount of\ntraining data or outliers of survival data. The first idea behind SurvLIME-KS\nis to apply the Cox proportional hazards model to approximate the black-box\nsurvival model at the local area around a test example due to the linear\nrelationship of covariates in the model. The second idea is to incorporate the\nwell-known Kolmogorov-Smirnov bounds for constructing sets of predicted\ncumulative hazard functions. As a result, the robust maximin strategy is used,\nwhich aims to minimize the average distance between cumulative hazard functions\nof the explained black-box model and of the approximating Cox model, and to\nmaximize the distance over all cumulative hazard functions in the interval\nproduced by the Kolmogorov-Smirnov bounds. The maximin optimization problem is\nreduced to the quadratic program. Various numerical experiments with synthetic\nand real datasets demonstrate the SurvLIME-KS efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 14:47:35 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Kovalev", "Maxim S.", ""], ["Utkin", "Lev V.", ""]]}, {"id": "2005.02251", "submitter": "Vladislav Goncharenko", "authors": "V. Goncharenko, R. Grigoryan, A. Samokhina", "title": "Raccoons vs Demons: multiclass labeled P300 dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We publish dataset of visual P300 BCI performed in Virtual Reality (VR) game\nRaccoons versus Demons (RvD). Data contains reach labels incorporating\ninformation about stimulus chosen enabling us to estimate model's confidence at\neach stimulus prediction stage. Data and experiments code are available at\nhttps://gitlab.com/impulse-neiry_public/raccoons-vs-demons\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 20:10:31 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 15:47:38 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Goncharenko", "V.", ""], ["Grigoryan", "R.", ""], ["Samokhina", "A.", ""]]}, {"id": "2005.02259", "submitter": "Andrew Cropper", "authors": "Andrew Cropper and Rolf Morel", "title": "Learning programs by learning from failures", "comments": "Accepted for the machine learning journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an inductive logic programming (ILP) approach called learning\nfrom failures. In this approach, an ILP system (the learner) decomposes the\nlearning problem into three separate stages: generate, test, and constrain. In\nthe generate stage, the learner generates a hypothesis (a logic program) that\nsatisfies a set of hypothesis constraints (constraints on the syntactic form of\nhypotheses). In the test stage, the learner tests the hypothesis against\ntraining examples. A hypothesis fails when it does not entail all the positive\nexamples or entails a negative example. If a hypothesis fails, then, in the\nconstrain stage, the learner learns constraints from the failed hypothesis to\nprune the hypothesis space, i.e. to constrain subsequent hypothesis generation.\nFor instance, if a hypothesis is too general (entails a negative example), the\nconstraints prune generalisations of the hypothesis. If a hypothesis is too\nspecific (does not entail all the positive examples), the constraints prune\nspecialisations of the hypothesis. This loop repeats until either (i) the\nlearner finds a hypothesis that entails all the positive and none of the\nnegative examples, or (ii) there are no more hypotheses to test. We introduce\nPopper, an ILP system that implements this approach by combining answer set\nprogramming and Prolog. Popper supports infinite problem domains, reasoning\nabout lists and numbers, learning textually minimal programs, and learning\nrecursive programs. Our experimental results on three domains (toy game\nproblems, robot strategies, and list transformations) show that (i) constraints\ndrastically improve learning performance, and (ii) Popper can outperform\nexisting ILP systems, both in terms of predictive accuracies and learning\ntimes.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 14:55:07 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 14:09:52 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2020 08:45:50 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Cropper", "Andrew", ""], ["Morel", "Rolf", ""]]}, {"id": "2005.02265", "submitter": "Chiel van Heerwaarden", "authors": "Menno A. Veerman, Robert Pincus, Robin Stoffer, Caspar van Leeuwen,\n  Damian Podareanu, Chiel C. van Heerwaarden", "title": "Predicting atmospheric optical properties for radiative transfer\n  computations using neural networks", "comments": "13 pages,5 figures, submitted to Philosophical Transactions A", "journal-ref": "Phil. Trans. R. Soc. A. 379: 20200095 (2021)", "doi": "10.1098/rsta.2020.0095", "report-no": null, "categories": "physics.ao-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The radiative transfer equations are well-known, but radiation\nparametrizations in atmospheric models are computationally expensive. A\npromising tool for accelerating parametrizations is the use of machine learning\ntechniques. In this study, we develop a machine learning-based parametrization\nfor the gaseous optical properties by training neural networks to emulate a\nmodern radiation parameterization (RRTMGP). To minimize computational costs, we\nreduce the range of atmospheric conditions for which the neural networks are\napplicable and use machine-specific optimised BLAS functions to accelerate\nmatrix computations. To generate training data, we use a set of randomly\nperturbed atmospheric profiles and calculate optical properties using RRTMGP.\nPredicted optical properties are highly accurate and the resulting radiative\nfluxes have average errors within \\SI{0.5}{\\flux} compared to RRTMGP. Our\nneural network-based gas optics parametrization is up to 4 times faster than\nRRTMGP, depending on the size of the neural networks. We further test the\ntrade-off between speed and accuracy by training neural networks for the narrow\nrange of atmospheric conditions of a single large-eddy simulation, so smaller\nand therefore faster networks can achieve a desired accuracy. We conclude that\nour machine learning-based parametrization can speed-up radiative transfer\ncomputations whilst retaining high accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 15:00:58 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 14:06:45 GMT"}, {"version": "v3", "created": "Sun, 16 Aug 2020 08:59:30 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Veerman", "Menno A.", ""], ["Pincus", "Robert", ""], ["Stoffer", "Robin", ""], ["van Leeuwen", "Caspar", ""], ["Podareanu", "Damian", ""], ["van Heerwaarden", "Chiel C.", ""]]}, {"id": "2005.02269", "submitter": "Agnieszka Miko{\\l}ajczyk", "authors": "Agnieszka Miko{\\l}ajczyk, Micha{\\l} Grochowski, Arkadiusz Kwasigroch", "title": "Towards explainable classifiers using the counterfactual approach --\n  global explanations for discovering bias in data", "comments": "Accepted for publication in Journal of Artificial Intelligence and\n  Soft Computing Research; 12 pages, 4 figures, code available, 8-pages\n  appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes summarized attribution-based post-hoc explanations for the\ndetection and identification of bias in data. A global explanation is proposed,\nand a step-by-step framework on how to detect and test bias is introduced.\nSince removing unwanted bias is often a complicated and tremendous task, it is\nautomatically inserted, instead. Then, the bias is evaluated with the proposed\ncounterfactual approach. The obtained results are validated on a sample skin\nlesion dataset. Using the proposed method, a number of possible bias causing\nartifacts are successfully identified and confirmed in dermoscopy images. In\nparticular, it is confirmed that black frames have a strong influence on\nConvolutional Neural Network's prediction: 22% of them changed the prediction\nfrom benign to malignant.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 15:05:33 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 11:47:07 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Miko\u0142ajczyk", "Agnieszka", ""], ["Grochowski", "Micha\u0142", ""], ["Kwasigroch", "Arkadiusz", ""]]}, {"id": "2005.02274", "submitter": "Antoine Lesage-Landry", "authors": "Antoine Lesage-Landry, Joshua A. Taylor, Duncan S. Callaway", "title": "Online Convex Optimization with Binary Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online optimization with binary decision variables and convex\nloss functions. We design a new algorithm, binary online gradient descent\n(bOGD) and bound its expected dynamic regret. We provide a regret bound that\nholds for any time horizon and a specialized bound for finite time horizons.\nFirst, we present the regret as the sum of the relaxed, continuous round\noptimum tracking error and the rounding error of our update in which the former\nasymptomatically decreases with time under certain conditions. Then, we derive\na finite-time bound that is sublinear in time and linear in the cumulative\nvariation of the relaxed, continuous round optima. We apply bOGD to demand\nresponse with thermostatically controlled loads, in which binary constraints\nmodel discrete on/off settings. We also model uncertainty and varying load\navailability, which depend on temperature deadbands, lockout of cooling units\nand manual overrides. We test the performance of bOGD in several simulations\nbased on demand response. The simulations corroborate that the use of\nrandomization in bOGD does not significantly degrade performance while making\nthe problem more tractable.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 15:09:26 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 16:40:46 GMT"}, {"version": "v3", "created": "Fri, 19 Feb 2021 21:00:44 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Lesage-Landry", "Antoine", ""], ["Taylor", "Joshua A.", ""], ["Callaway", "Duncan S.", ""]]}, {"id": "2005.02291", "submitter": "Dario Fuoli", "authors": "Dario Fuoli, Zhiwu Huang, Martin Danelljan, Radu Timofte, Hua Wang,\n  Longcun Jin, Dewei Su, Jing Liu, Jaehoon Lee, Michal Kudelski, Lukasz Bala,\n  Dmitry Hrybov, Marcin Mozejko, Muchen Li, Siyao Li, Bo Pang, Cewu Lu, Chao\n  Li, Dongliang He, Fu Li, Shilei Wen", "title": "NTIRE 2020 Challenge on Video Quality Mapping: Methods and Results", "comments": "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\n  Workshops", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews the NTIRE 2020 challenge on video quality mapping (VQM),\nwhich addresses the issues of quality mapping from source video domain to\ntarget video domain. The challenge includes both a supervised track (track 1)\nand a weakly-supervised track (track 2) for two benchmark datasets. In\nparticular, track 1 offers a new Internet video benchmark, requiring algorithms\nto learn the map from more compressed videos to less compressed videos in a\nsupervised training manner. In track 2, algorithms are required to learn the\nquality mapping from one device to another when their quality varies\nsubstantially and weakly-aligned video pairs are available. For track 1, in\ntotal 7 teams competed in the final test phase, demonstrating novel and\neffective solutions to the problem. For track 2, some existing methods are\nevaluated, showing promising solutions to the weakly-supervised video quality\nmapping problem.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 15:45:16 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 16:50:39 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 22:12:40 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Fuoli", "Dario", ""], ["Huang", "Zhiwu", ""], ["Danelljan", "Martin", ""], ["Timofte", "Radu", ""], ["Wang", "Hua", ""], ["Jin", "Longcun", ""], ["Su", "Dewei", ""], ["Liu", "Jing", ""], ["Lee", "Jaehoon", ""], ["Kudelski", "Michal", ""], ["Bala", "Lukasz", ""], ["Hrybov", "Dmitry", ""], ["Mozejko", "Marcin", ""], ["Li", "Muchen", ""], ["Li", "Siyao", ""], ["Pang", "Bo", ""], ["Lu", "Cewu", ""], ["Li", "Chao", ""], ["He", "Dongliang", ""], ["Li", "Fu", ""], ["Wen", "Shilei", ""]]}, {"id": "2005.02299", "submitter": "Hector Javier Hortua", "authors": "H\\'ector J. Hort\\'ua, Riccardo Volpi, Luigi Malag\\`o", "title": "Parameters Estimation from the 21 cm signal using Variational Inference", "comments": "Presented at ICLR 2020 Workshop on Fundamental Science in the era of\n  AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.CO cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Upcoming experiments such as Hydrogen Epoch of Reionization Array (HERA) and\nSquare Kilometre Array (SKA) are intended to measure the 21cm signal over a\nwide range of redshifts, representing an incredible opportunity in advancing\nour understanding about the nature of cosmic Reionization. At the same time\nthese kind of experiments will present new challenges in processing the\nextensive amount of data generated, calling for the development of automated\nmethods capable of precisely estimating physical parameters and their\nuncertainties. In this paper we employ Variational Inference, and in particular\nBayesian Neural Networks, as an alternative to MCMC in 21 cm observations to\nreport credible estimations for cosmological and astrophysical parameters and\nassess the correlations among them.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 17:06:56 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Hort\u00faa", "H\u00e9ctor J.", ""], ["Volpi", "Riccardo", ""], ["Malag\u00f2", "Luigi", ""]]}, {"id": "2005.02305", "submitter": "Or Rivlin", "authors": "Or Rivlin, Tamir Hazan, Erez Karpas", "title": "Generalized Planning With Deep Reinforcement Learning", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hallmark of intelligence is the ability to deduce general principles from\nexamples, which are correct beyond the range of those observed. Generalized\nPlanning deals with finding such principles for a class of planning problems,\nso that principles discovered using small instances of a domain can be used to\nsolve much larger instances of the same domain. In this work we study the use\nof Deep Reinforcement Learning and Graph Neural Networks to learn such\ngeneralized policies and demonstrate that they can generalize to instances that\nare orders of magnitude larger than those they were trained on.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 16:06:57 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Rivlin", "Or", ""], ["Hazan", "Tamir", ""], ["Karpas", "Erez", ""]]}, {"id": "2005.02313", "submitter": "Sukrut Rao", "authors": "Sukrut Rao, David Stutz, Bernt Schiele", "title": "Adversarial Training against Location-Optimized Adversarial Patches", "comments": "20 pages, 6 tables, 4 figures, 2 algorithms, European Conference on\n  Computer Vision Workshops 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been shown to be susceptible to adversarial\nexamples -- small, imperceptible changes constructed to cause\nmis-classification in otherwise highly accurate image classifiers. As a\npractical alternative, recent work proposed so-called adversarial patches:\nclearly visible, but adversarially crafted rectangular patches in images. These\npatches can easily be printed and applied in the physical world. While defenses\nagainst imperceptible adversarial examples have been studied extensively,\nrobustness against adversarial patches is poorly understood. In this work, we\nfirst devise a practical approach to obtain adversarial patches while actively\noptimizing their location within the image. Then, we apply adversarial training\non these location-optimized adversarial patches and demonstrate significantly\nimproved robustness on CIFAR10 and GTSRB. Additionally, in contrast to\nadversarial training on imperceptible adversarial examples, our adversarial\npatch training does not reduce accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 16:17:00 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 08:00:26 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Rao", "Sukrut", ""], ["Stutz", "David", ""], ["Schiele", "Bernt", ""]]}, {"id": "2005.02328", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Bindya Venkatesh, Rushil Anirudh, Peer-Timo\n  Bremer, Jim Gaffney, Gemma Anderson, Brian Spears", "title": "Designing Accurate Emulators for Scientific Processes using\n  Calibration-Driven Deep Models", "comments": null, "journal-ref": null, "doi": "10.1038/s41467-020-19448-8", "report-no": null, "categories": "stat.ML cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive models that accurately emulate complex scientific processes can\nachieve exponential speed-ups over numerical simulators or experiments, and at\nthe same time provide surrogates for improving the subsequent analysis.\nConsequently, there is a recent surge in utilizing modern machine learning (ML)\nmethods, such as deep neural networks, to build data-driven emulators. While\nthe majority of existing efforts has focused on tailoring off-the-shelf ML\nsolutions to better suit the scientific problem at hand, we study an often\noverlooked, yet important, problem of choosing loss functions to measure the\ndiscrepancy between observed data and the predictions from a model. Due to lack\nof better priors on the expected residual structure, in practice, simple\nchoices such as the mean squared error and the mean absolute error are made.\nHowever, the inherent symmetric noise assumption made by these loss functions\nmakes them inappropriate in cases where the data is heterogeneous or when the\nnoise distribution is asymmetric. We propose Learn-by-Calibrating (LbC), a\nnovel deep learning approach based on interval calibration for designing\nemulators in scientific applications, that are effective even with\nheterogeneous data and are robust to outliers. Using a large suite of\nuse-cases, we show that LbC provides significant improvements in generalization\nerror over widely-adopted loss function choices, achieves high-quality\nemulators even in small data regimes and more importantly, recovers the\ninherent noise structure without any explicit priors.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 16:54:11 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Venkatesh", "Bindya", ""], ["Anirudh", "Rushil", ""], ["Bremer", "Peer-Timo", ""], ["Gaffney", "Jim", ""], ["Anderson", "Gemma", ""], ["Spears", "Brian", ""]]}, {"id": "2005.02335", "submitter": "Mahsan Nourani", "authors": "Mahsan Nourani, Chiradeep Roy, Tahrima Rahman, Eric D. Ragan, Nicholas\n  Ruozzi, Vibhav Gogate", "title": "Don't Explain without Verifying Veracity: An Evaluation of Explainable\n  AI with Video Activity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable machine learning and artificial intelligence models have been\nused to justify a model's decision-making process. This added transparency aims\nto help improve user performance and understanding of the underlying model.\nHowever, in practice, explainable systems face many open questions and\nchallenges. Specifically, designers might reduce the complexity of deep\nlearning models in order to provide interpretability. The explanations\ngenerated by these simplified models, however, might not accurately justify and\nbe truthful to the model. This can further add confusion to the users as they\nmight not find the explanations meaningful with respect to the model\npredictions. Understanding how these explanations affect user behavior is an\nongoing challenge. In this paper, we explore how explanation veracity affects\nuser performance and agreement in intelligent systems. Through a controlled\nuser study with an explainable activity recognition system, we compare\nvariations in explanation veracity for a video review and querying task. The\nresults suggest that low veracity explanations significantly decrease user\nperformance and agreement compared to both accurate explanations and a system\nwithout explanations. These findings demonstrate the importance of accurate and\nunderstandable explanations and caution that poor explanations can sometimes be\nworse than no explanations with respect to their effect on user performance and\nreliance on an AI system.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 17:06:46 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Nourani", "Mahsan", ""], ["Roy", "Chiradeep", ""], ["Rahman", "Tahrima", ""], ["Ragan", "Eric D.", ""], ["Ruozzi", "Nicholas", ""], ["Gogate", "Vibhav", ""]]}, {"id": "2005.02339", "submitter": "Ali Hassan", "authors": "Ali Hassan, Samrat Acharya, Michael Chertkov, Deepjyoti Deka and Yury\n  Dvorkin", "title": "A Hierarchical Approach to Multi-Energy Demand Response: From\n  Electricity to Multi-Energy Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to proliferation of energy efficiency measures and availability of the\nrenewable energy resources, traditional energy infrastructure systems\n(electricity, heat, gas) can no longer be operated in a centralized manner\nunder the assumption that consumer behavior is inflexible, i.e. cannot be\nadjusted in return for an adequate incentive. To allow for a less centralized\noperating paradigm, consumer-end perspective and abilities should be integrated\nin current dispatch practices and accounted for in switching between different\nenergy sources not only at the system but also at the individual consumer\nlevel. Since consumers are confined within different built environments, this\npaper looks into an opportunity to control energy consumption of an aggregation\nof many residential, commercial and industrial consumers, into an ensemble.\nThis ensemble control becomes a modern demand response contributor to the set\nof modeling tools for multi-energy infrastructure systems.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 17:17:51 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Hassan", "Ali", ""], ["Acharya", "Samrat", ""], ["Chertkov", "Michael", ""], ["Deka", "Deepjyoti", ""], ["Dvorkin", "Yury", ""]]}, {"id": "2005.02342", "submitter": "Ryan Steed", "authors": "Ryan Steed, Benjamin Williams", "title": "Heuristic-Based Weak Learning for Automated Decision-Making", "comments": "5 pages, 3 figures. Camera-ready version for Participatory Approaches\n  to Machine Learning @ ICML 2020. Last updated Dec. 2020: fixed bug in Figure\n  3 - \"always intervene\" heuristic should be \"never intervene.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine learning systems impact many stakeholders and groups of users, often\ndisparately. Prior studies have reconciled conflicting user preferences by\naggregating a high volume of manually labeled pairwise comparisons, but this\ntechnique may be costly or impractical. How can we lower the barrier to\nparticipation in algorithm design? Instead of creating a simplified labeling\ntask for a crowd, we suggest collecting ranked decision-making heuristics from\na focused sample of affected users. With empirical data from two use cases, we\nshow that our weak learning approach, which requires little to no manual\nlabeling, agrees with participants' pairwise choices nearly as often as fully\nsupervised approaches.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 17:22:52 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 18:53:24 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 22:55:01 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Steed", "Ryan", ""], ["Williams", "Benjamin", ""]]}, {"id": "2005.02347", "submitter": "Antoine Savine", "authors": "Brian Huge and Antoine Savine", "title": "Differential Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential machine learning combines automatic adjoint differentiation\n(AAD) with modern machine learning (ML) in the context of risk management of\nfinancial Derivatives. We introduce novel algorithms for training fast,\naccurate pricing and risk approximations, online, in real-time, with\nconvergence guarantees. Our machinery is applicable to arbitrary Derivatives\ninstruments or trading books, under arbitrary stochastic models of the\nunderlying market variables. It effectively resolves computational bottlenecks\nof Derivatives risk reports and capital calculations.\n  Differential ML is a general extension of supervised learning, where ML\nmodels are trained on examples of not only inputs and labels but also\ndifferentials of labels wrt inputs. It is also applicable in many situations\noutside finance, where high quality first-order derivatives wrt training inputs\nare available. Applications in Physics, for example, may leverage differentials\nknown from first principles to learn function approximations more effectively.\n  In finance, AAD computes pathwise differentials with remarkable efficacy so\ndifferential ML algorithms provide extremely effective pricing and risk\napproximations. We can produce fast analytics in models too complex for closed\nform solutions, extract the risk factors of complex transactions and trading\nbooks, and effectively compute risk management metrics like reports across a\nlarge number of scenarios, backtesting and simulation of hedge strategies, or\nregulations like XVA, CCR, FRTB or SIMM-MVA.\n  TensorFlow implementation is available on\nhttps://github.com/differential-machine-learning\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 17:32:37 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 09:10:58 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 10:31:09 GMT"}, {"version": "v4", "created": "Wed, 30 Sep 2020 00:31:30 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Huge", "Brian", ""], ["Savine", "Antoine", ""]]}, {"id": "2005.02356", "submitter": "Shiqian Ma", "authors": "Shixiang Chen, Zengde Deng, Shiqian Ma, Anthony Man-Cho So", "title": "Manifold Proximal Point Algorithms for Dual Principal Component Pursuit\n  and Orthogonal Dictionary Learning", "comments": "Accepted in IEEE Transactions on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of maximizing the $\\ell_1$ norm of a linear map over\nthe sphere, which arises in various machine learning applications such as\northogonal dictionary learning (ODL) and robust subspace recovery (RSR). The\nproblem is numerically challenging due to its nonsmooth objective and nonconvex\nconstraint, and its algorithmic aspects have not been well explored. In this\npaper, we show how the manifold structure of the sphere can be exploited to\ndesign fast algorithms for tackling this problem. Specifically, our\ncontribution is threefold. First, we present a manifold proximal point\nalgorithm (ManPPA) for the problem and show that it converges at a sublinear\nrate. Furthermore, we show that ManPPA can achieve a quadratic convergence rate\nwhen applied to the ODL and RSR problems. Second, we propose a stochastic\nvariant of ManPPA called StManPPA, which is well suited for large-scale\ncomputation, and establish its sublinear convergence rate. Both ManPPA and\nStManPPA have provably faster convergence rates than existing subgradient-type\nmethods. Third, using ManPPA as a building block, we propose a new approach to\nsolving a matrix analog of the problem, in which the sphere is replaced by the\nStiefel manifold. The results from our extensive numerical experiments on the\nODL and RSR problems demonstrate the efficiency and efficacy of our proposed\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 17:40:03 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 13:40:06 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chen", "Shixiang", ""], ["Deng", "Zengde", ""], ["Ma", "Shiqian", ""], ["So", "Anthony Man-Cho", ""]]}, {"id": "2005.02357", "submitter": "Niv Cohen", "authors": "Niv Cohen and Yedid Hoshen", "title": "Sub-Image Anomaly Detection with Deep Pyramid Correspondences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearest neighbor (kNN) methods utilizing deep pre-trained features exhibit\nvery strong anomaly detection performance when applied to entire images. A\nlimitation of kNN methods is the lack of segmentation map describing where the\nanomaly lies inside the image. In this work we present a novel anomaly\nsegmentation approach based on alignment between an anomalous image and a\nconstant number of the similar normal images. Our method, Semantic Pyramid\nAnomaly Detection (SPADE) uses correspondences based on a multi-resolution\nfeature pyramid. SPADE is shown to achieve state-of-the-art performance on\nunsupervised anomaly detection and localization while requiring virtually no\ntraining time.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 17:43:35 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 18:52:41 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 16:28:51 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Cohen", "Niv", ""], ["Hoshen", "Yedid", ""]]}, {"id": "2005.02359", "submitter": "Yedid Hoshen", "authors": "Liron Bergman and Yedid Hoshen", "title": "Classification-Based Anomaly Detection for General Data", "comments": "ICLR'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection, finding patterns that substantially deviate from those\nseen previously, is one of the fundamental problems of artificial intelligence.\nRecently, classification-based methods were shown to achieve superior results\non this task. In this work, we present a unifying view and propose an open-set\nmethod, GOAD, to relax current generalization assumptions. Furthermore, we\nextend the applicability of transformation-based methods to non-image data\nusing random affine transformations. Our method is shown to obtain\nstate-of-the-art accuracy and is applicable to broad data types. The strong\nperformance of our method is extensively validated on multiple datasets from\ndifferent domains.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 17:44:40 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Bergman", "Liron", ""], ["Hoshen", "Yedid", ""]]}, {"id": "2005.02372", "submitter": "Deepak Bhaskar Acharya", "authors": "Deepak Bhaskar Acharya, Huaming Zhang", "title": "Community Detection Clustering via Gumbel Softmax", "comments": "9 Pages, previous title was Clustering for Graph Datasets via Gumbel\n  Softmax", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, in many systems such as speech recognition and visual processing,\ndeep learning has been widely implemented. In this research, we are exploring\nthe possibility of using deep learning in community detection among the graph\ndatasets. Graphs have gained growing traction in different fields, including\nsocial networks, information graphs, the recommender system, and also life\nsciences. In this paper, we propose a method of community detection clustering\nthe nodes of various graph datasets. We cluster different category datasets\nthat belong to Affiliation networks, Animal networks, Human contact networks,\nHuman social networks, Miscellaneous networks. The deep learning role in\nmodeling the interaction between nodes in a network allows a revolution in the\nfield of science relevant to graph network analysis. In this paper, we extend\nthe gumbel softmax approach to graph network clustering. The experimental\nfindings on specific graph datasets reveal that the new approach outperforms\ntraditional clustering significantly, which strongly shows the efficacy of deep\nlearning in graph community detection clustering. We do a series of experiments\non our graph clustering algorithm, using various datasets: Zachary karate club,\nHighland Tribe, Train bombing, American Revolution, Dolphins, Zebra,\nWindsurfers, Les Mis\\'erables, Political books.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 17:55:31 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 03:04:35 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Acharya", "Deepak Bhaskar", ""], ["Zhang", "Huaming", ""]]}, {"id": "2005.02387", "submitter": "Lev Utkin", "authors": "Lev V. Utkin, Maxim S. Kovalev and Ernest M. Kasimov", "title": "SurvLIME-Inf: A simplified modification of SurvLIME for explanation of\n  machine learning survival models", "comments": "arXiv admin note: substantial text overlap with arXiv:2003.08371,\n  arXiv:2005.02249", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new modification of the explanation method SurvLIME called SurvLIME-Inf for\nexplaining machine learning survival models is proposed. The basic idea behind\nSurvLIME as well as SurvLIME-Inf is to apply the Cox proportional hazards model\nto approximate the black-box survival model at the local area around a test\nexample. The Cox model is used due to the linear relationship of covariates. In\ncontrast to SurvLIME, the proposed modification uses $L_{\\infty }$-norm for\ndefining distances between approximating and approximated cumulative hazard\nfunctions. This leads to a simple linear programming problem for determining\nimportant features and for explaining the black-box model prediction. Moreover,\nSurvLIME-Inf outperforms SurvLIME when the training set is very small.\nNumerical experiments with synthetic and real datasets demonstrate the\nSurvLIME-Inf efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 14:34:46 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Utkin", "Lev V.", ""], ["Kovalev", "Maxim S.", ""], ["Kasimov", "Ernest M.", ""]]}, {"id": "2005.02388", "submitter": "Endre Cs\\'oka", "authors": "Endre Cs\\'oka", "title": "Application-oriented mathematical algorithms for group testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have a large number of samples and we want to find the infected ones using\nas few number of tests as possible. We can use group testing which tells about\na small group of people whether at least one of them is infected. Group testing\nis particularly efficient if the infection rate is low. The goal of this\narticle is to summarize and extend the mathematical knowledge about the most\nefficient group testing algorithms, focusing on real-life applications instead\nof pure mathematical motivations and approaches.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 14:40:46 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Cs\u00f3ka", "Endre", ""]]}, {"id": "2005.02392", "submitter": "Matteo Tiezzi", "authors": "Matteo Tiezzi, Giuseppe Marra, Stefano Melacci and Marco Maggini", "title": "Deep Constraint-based Propagation in Graph Neural Networks", "comments": "Published in: IEEE Transactions on Pattern Analysis and Machine\n  Intelligence. arXiv admin note: text overlap with arXiv:2002.07684", "journal-ref": null, "doi": "10.1109/TPAMI.2021.3073504", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of deep learning techniques renewed the interest in neural\narchitectures able to process complex structures that can be represented using\ngraphs, inspired by Graph Neural Networks (GNNs). We focus our attention on the\noriginally proposed GNN model of Scarselli et al. 2009, which encodes the state\nof the nodes of the graph by means of an iterative diffusion procedure that,\nduring the learning stage, must be computed at every epoch, until the fixed\npoint of a learnable state transition function is reached, propagating the\ninformation among the neighbouring nodes. We propose a novel approach to\nlearning in GNNs, based on constrained optimization in the Lagrangian\nframework. Learning both the transition function and the node states is the\noutcome of a joint process, in which the state convergence procedure is\nimplicitly expressed by a constraint satisfaction mechanism, avoiding iterative\nepoch-wise procedures and the network unfolding. Our computational structure\nsearches for saddle points of the Lagrangian in the adjoint space composed of\nweights, nodes state variables and Lagrange multipliers. This process is\nfurther enhanced by multiple layers of constraints that accelerate the\ndiffusion process. An experimental analysis shows that the proposed approach\ncompares favourably with popular models on several benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 16:50:59 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 08:35:58 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2020 11:18:14 GMT"}, {"version": "v4", "created": "Mon, 19 Apr 2021 19:21:06 GMT"}, {"version": "v5", "created": "Thu, 22 Apr 2021 13:51:55 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Tiezzi", "Matteo", ""], ["Marra", "Giuseppe", ""], ["Melacci", "Stefano", ""], ["Maggini", "Marco", ""]]}, {"id": "2005.02426", "submitter": "Zhishuai Guo", "authors": "Zhishuai Guo, Mingrui Liu, Zhuoning Yuan, Li Shen, Wei Liu, Tianbao\n  Yang", "title": "Communication-Efficient Distributed Stochastic AUC Maximization with\n  Deep Neural Networks", "comments": null, "journal-ref": "37th International Conference on Machine Learning, 2020", "doi": null, "report-no": null, "categories": "cs.DC cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study distributed algorithms for large-scale AUC\nmaximization with a deep neural network as a predictive model. Although\ndistributed learning techniques have been investigated extensively in deep\nlearning, they are not directly applicable to stochastic AUC maximization with\ndeep neural networks due to its striking differences from standard loss\nminimization problems (e.g., cross-entropy). Towards addressing this challenge,\nwe propose and analyze a communication-efficient distributed optimization\nalgorithm based on a {\\it non-convex concave} reformulation of the AUC\nmaximization, in which the communication of both the primal variable and the\ndual variable between each worker and the parameter server only occurs after\nmultiple steps of gradient-based updates in each worker. Compared with the\nnaive parallel version of an existing algorithm that computes stochastic\ngradients at individual machines and averages them for updating the model\nparameters, our algorithm requires a much less number of communication rounds\nand still achieves a linear speedup in theory. To the best of our knowledge,\nthis is the \\textbf{first} work that solves the {\\it non-convex concave\nmin-max} problem for AUC maximization with deep neural networks in a\ncommunication-efficient distributed manner while still maintaining the linear\nspeedup property in theory. Our experiments on several benchmark datasets show\nthe effectiveness of our algorithm and also confirm our theory.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 18:08:23 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 06:54:36 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Guo", "Zhishuai", ""], ["Liu", "Mingrui", ""], ["Yuan", "Zhuoning", ""], ["Shen", "Li", ""], ["Liu", "Wei", ""], ["Yang", "Tianbao", ""]]}, {"id": "2005.02433", "submitter": "David Demeter", "authors": "David Demeter, Gregory Kimmel and Doug Downey", "title": "Stolen Probability: A Structural Weakness of Neural Language Models", "comments": "Preprint of paper accepted for ACL-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Network Language Models (NNLMs) generate probability distributions by\napplying a softmax function to a distance metric formed by taking the dot\nproduct of a prediction vector with all word vectors in a high-dimensional\nembedding space. The dot-product distance metric forms part of the inductive\nbias of NNLMs. Although NNLMs optimize well with this inductive bias, we show\nthat this results in a sub-optimal ordering of the embedding space that\nstructurally impoverishes some words at the expense of others when assigning\nprobability. We present numerical, theoretical and empirical analyses showing\nthat words on the interior of the convex hull in the embedding space have their\nprobability bounded by the probabilities of the words on the hull.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 18:40:32 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Demeter", "David", ""], ["Kimmel", "Gregory", ""], ["Downey", "Doug", ""]]}, {"id": "2005.02435", "submitter": "Aravind Jayendran", "authors": "Deepak Mishra, Aravind Jayendran, Prathosh A. P", "title": "Effect of The Latent Structure on Clustering with GANs", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2020.2996935", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have shown remarkable success in\ngeneration of data from natural data manifolds such as images. In several\nscenarios, it is desirable that generated data is well-clustered, especially\nwhen there is severe class imbalance. In this paper, we focus on the problem of\nclustering in generated space of GANs and uncover its relationship with the\ncharacteristics of the latent space. We derive from first principles, the\nnecessary and sufficient conditions needed to achieve faithful clustering in\nthe GAN framework: (i) presence of a multimodal latent space with adjustable\npriors, (ii) existence of a latent space inversion mechanism and (iii)\nimposition of the desired cluster priors on the latent space. We also identify\nthe GAN models in the literature that partially satisfy these conditions and\ndemonstrate the importance of all the components required, through ablative\nstudies on multiple real world image datasets. Additionally, we describe a\nprocedure to construct a multimodal latent space which facilitates learning of\ncluster priors with sparse supervision.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 18:52:49 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Mishra", "Deepak", ""], ["Jayendran", "Aravind", ""], ["P", "Prathosh A.", ""]]}, {"id": "2005.02436", "submitter": "Hiroshi Sasaki", "authors": "Hiroshi Sasaki, Chris G. Willcocks, Toby P. Breckon", "title": "Data Augmentation via Mixed Class Interpolation using Cycle-Consistent\n  Generative Adversarial Networks Applied to Cross-Domain Imagery", "comments": "9 pages, 9 figures, accepted at the 25th International Conference on\n  Pattern Recognition (ICPR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning driven object detection and classification within\nnon-visible imagery has an important role in many fields such as night vision,\nall-weather surveillance and aviation security. However, such applications\noften suffer due to the limited quantity and variety of non-visible spectral\ndomain imagery, in contrast to the high data availability of visible-band\nimagery that readily enables contemporary deep learning driven detection and\nclassification approaches. To address this problem, this paper proposes and\nevaluates a novel data augmentation approach that leverages the more readily\navailable visible-band imagery via a generative domain transfer model. The\nmodel can synthesise large volumes of non-visible domain imagery by\nimage-to-image (I2I) translation from the visible image domain. Furthermore, we\nshow that the generation of interpolated mixed class (non-visible domain) image\nexamples via our novel Conditional CycleGAN Mixup Augmentation (C2GMA)\nmethodology can lead to a significant improvement in the quality of non-visible\ndomain classification tasks that otherwise suffer due to limited data\navailability. Focusing on classification within the Synthetic Aperture Radar\n(SAR) domain, our approach is evaluated on a variation of the Statoil/C-CORE\nIceberg Classifier Challenge dataset and achieves 75.4% accuracy, demonstrating\na significant improvement when compared against traditional data augmentation\nstrategies (Rotation, Mixup, and MixCycleGAN).\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 18:53:38 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 22:29:13 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Sasaki", "Hiroshi", ""], ["Willcocks", "Chris G.", ""], ["Breckon", "Toby P.", ""]]}, {"id": "2005.02439", "submitter": "Xisen Jin", "authors": "Brendan Kennedy and Xisen Jin and Aida Mostafazadeh Davani and Morteza\n  Dehghani and Xiang Ren", "title": "Contextualizing Hate Speech Classifiers with Post-hoc Explanation", "comments": "To appear in Proceedings of the 2020 Annual Conference of the\n  Association for Computational Linguistics; Updated references and discussions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hate speech classifiers trained on imbalanced datasets struggle to determine\nif group identifiers like \"gay\" or \"black\" are used in offensive or prejudiced\nways. Such biases manifest in false positives when these identifiers are\npresent, due to models' inability to learn the contexts which constitute a\nhateful usage of identifiers. We extract SOC post-hoc explanations from\nfine-tuned BERT classifiers to efficiently detect bias towards identity terms.\nThen, we propose a novel regularization technique based on these explanations\nthat encourages models to learn from the context of group identifiers in\naddition to the identifiers themselves. Our approach improved over baselines in\nlimiting false positives on out-of-domain data while maintaining or improving\nin-domain performance. Project page:\nhttps://inklab.usc.edu/contextualize-hate-speech/.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 18:56:40 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 20:19:29 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 18:54:09 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Kennedy", "Brendan", ""], ["Jin", "Xisen", ""], ["Davani", "Aida Mostafazadeh", ""], ["Dehghani", "Morteza", ""], ["Ren", "Xiang", ""]]}, {"id": "2005.02456", "submitter": "Najmeddine Dhieb", "authors": "Najmeddine Dhieb, Hakim Ghazzai, Hichem Besbes, and Yehia Massoud", "title": "Scalable and Secure Architecture for Distributed IoT Systems", "comments": "This paper is accepted for publication in IEEE Technology &\n  Engineering Management Conference (TEMSCON'20), Detroit, USA, jun, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet-of-things (IoT) is perpetually revolutionizing our daily life and\nrapidly transforming physical objects into an ubiquitous connected ecosystem.\nDue to their massive deployment and moderate security levels, those devices\nface a lot of security, management, and control challenges. Their classical\ncentralized architecture is still cloaking vulnerabilities and anomalies that\ncan be exploited by hackers for spying, eavesdropping, and taking control of\nthe network. In this paper, we propose to improve the IoT architecture with\nadditional security features using Artificial Intelligence (AI) and blockchain\ntechnology. We propose a novel architecture based on permissioned blockchain\ntechnology in order to build a scalable and decentralized end-to-end secure IoT\nsystem. Furthermore, we enhance the IoT system security with an AI-component at\nthe gateway level to detect and classify suspected activities, malware, and\ncyber-attacks using machine learning techniques. Simulations and practical\nimplementation show that the proposed architecture delivers high performance\nagainst cyber-attacks.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 23:50:43 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Dhieb", "Najmeddine", ""], ["Ghazzai", "Hakim", ""], ["Besbes", "Hichem", ""], ["Massoud", "Yehia", ""]]}, {"id": "2005.02463", "submitter": "Ramy Mounir", "authors": "Ramy Mounir, Roman Gula, J\\\"orn Theuerkauf, Sudeep Sarkar", "title": "Spatio-Temporal Event Segmentation and Localization for Wildlife\n  Extended Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Using offline training schemes, researchers have tackled the event\nsegmentation problem by providing full or weak-supervision through manually\nannotated labels or self-supervised epoch-based training. Most works consider\nvideos that are at most 10's of minutes long. We present a self-supervised\nperceptual prediction framework capable of temporal event segmentation by\nbuilding stable representations of objects over time and demonstrate it on long\nvideos, spanning several days. The approach is deceptively simple but quite\neffective. We rely on predictions of high-level features computed by a standard\ndeep learning backbone. For prediction, we use an LSTM, augmented with an\nattention mechanism, trained in a self-supervised manner using the prediction\nerror. The self-learned attention maps effectively localize and track the\nevent-related objects in each frame. The proposed approach does not require\nlabels. It requires only a single pass through the video, with no separate\ntraining set. Given the lack of datasets of very long videos, we demonstrate\nour method on video from 10 days (254 hours) of continuous wildlife monitoring\ndata that we had collected with required permissions. We find that the approach\nis robust to various environmental conditions such as day/night conditions,\nrain, sharp shadows, and windy conditions. For the task of temporally locating\nevents, we had an 80% recall rate at 20% false-positive rate for frame-level\nsegmentation. At the activity level, we had an 80% activity recall rate for one\nfalse activity detection every 50 minutes. We will make the dataset, which is\nthe first of its kind, and the code available to the research community.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 20:11:48 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 11:28:16 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 17:41:11 GMT"}, {"version": "v4", "created": "Sun, 18 Jul 2021 19:35:14 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Mounir", "Ramy", ""], ["Gula", "Roman", ""], ["Theuerkauf", "J\u00f6rn", ""], ["Sarkar", "Sudeep", ""]]}, {"id": "2005.02470", "submitter": "Zein Shaheen", "authors": "Zein Shaheen, Gerhard Wohlgenannt, Bassel Zaity, Dmitry Mouromtsev,\n  Vadim Pak", "title": "Russian Natural Language Generation: Creation of a Language Modelling\n  Dataset and Evaluation with Modern Neural Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating coherent, grammatically correct, and meaningful text is very\nchallenging, however, it is crucial to many modern NLP systems. So far,\nresearch has mostly focused on English language, for other languages both\nstandardized datasets, as well as experiments with state-of-the-art models, are\nrare. In this work, we i) provide a novel reference dataset for Russian\nlanguage modeling, ii) experiment with popular modern methods for text\ngeneration, namely variational autoencoders, and generative adversarial\nnetworks, which we trained on the new dataset. We evaluate the generated text\nregarding metrics such as perplexity, grammatical correctness and lexical\ndiversity.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 20:20:25 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Shaheen", "Zein", ""], ["Wohlgenannt", "Gerhard", ""], ["Zaity", "Bassel", ""], ["Mouromtsev", "Dmitry", ""], ["Pak", "Vadim", ""]]}, {"id": "2005.02472", "submitter": "Alireza Zareian", "authors": "Manling Li, Alireza Zareian, Qi Zeng, Spencer Whitehead, Di Lu, Heng\n  Ji, Shih-Fu Chang", "title": "Cross-media Structured Common Space for Multimedia Event Extraction", "comments": "Accepted as an oral paper at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new task, MultiMedia Event Extraction (M2E2), which aims to\nextract events and their arguments from multimedia documents. We develop the\nfirst benchmark and collect a dataset of 245 multimedia news articles with\nextensively annotated events and arguments. We propose a novel method, Weakly\nAligned Structured Embedding (WASE), that encodes structured representations of\nsemantic information from textual and visual data into a common embedding\nspace. The structures are aligned across modalities by employing a weakly\nsupervised training strategy, which enables exploiting available resources\nwithout explicit cross-media annotation. Compared to uni-modal state-of-the-art\nmethods, our approach achieves 4.0% and 9.8% absolute F-score gains on text\nevent argument role labeling and visual event extraction. Compared to\nstate-of-the-art multimedia unstructured representations, we achieve 8.3% and\n5.0% absolute F-score gains on multimedia event extraction and argument role\nlabeling, respectively. By utilizing images, we extract 21.4% more event\nmentions than traditional text-only methods.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 20:21:53 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Li", "Manling", ""], ["Zareian", "Alireza", ""], ["Zeng", "Qi", ""], ["Whitehead", "Spencer", ""], ["Lu", "Di", ""], ["Ji", "Heng", ""], ["Chang", "Shih-Fu", ""]]}, {"id": "2005.02480", "submitter": "Maxime Peyrard", "authors": "Maxime Peyrard and Robert West", "title": "A Ladder of Causal Distances", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal discovery, the task of automatically constructing a causal model from\ndata, is of major significance across the sciences. Evaluating the performance\nof causal discovery algorithms should ideally involve comparing the inferred\nmodels to ground-truth models available for benchmark datasets, which in turn\nrequires a notion of distance between causal models. While such distances have\nbeen proposed previously, they are limited by focusing on graphical properties\nof the causal models being compared. Here, we overcome this limitation by\ndefining distances derived from the causal distributions induced by the models,\nrather than exclusively from their graphical structure. Pearl and Mackenzie\n(2018) have arranged the properties of causal models in a hierarchy called the\n\"ladder of causation\" spanning three rungs: observational, interventional, and\ncounterfactual. Following this organization, we introduce a hierarchy of three\ndistances, one for each rung of the ladder. Our definitions are intuitively\nappealing as well as efficient to compute approximately. We put our causal\ndistances to use by benchmarking standard causal discovery systems on both\nsynthetic and real-world datasets for which ground-truth causal models are\navailable. Finally, we highlight the usefulness of our causal distances by\nbriefly discussing further applications beyond the evaluation of causal\ndiscovery techniques.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 20:39:07 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Peyrard", "Maxime", ""], ["West", "Robert", ""]]}, {"id": "2005.02493", "submitter": "Tiago Cinto", "authors": "T. Cinto (1 and 2), A. L. S. Gradvohl (1), G. P. Coelho (1), A. E. A.\n  da Silva (1) ((1) School of Technology - FT, University of Campinas -\n  UNICAMP, Limeira, SP, Brazil, (2) Federal Institute of Education, Science and\n  Technology of Rio Grande do Sul - IFRS, Campus Feliz, RS, Brazil)", "title": "A Framework for Designing and Evaluating Solar Flare Forecasting Systems", "comments": null, "journal-ref": null, "doi": "10.1093/mnras/staa1257", "report-no": null, "categories": "astro-ph.SR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disturbances in space weather can negatively affect several fields, including\naviation and aerospace, satellites, oil and gas industries, and electrical\nsystems, leading to economic and commercial losses. Solar flares are the most\nsignificant events that can affect the Earth's atmosphere, thus leading\nresearchers to drive efforts on their forecasting. The related literature is\ncomprehensive and holds several systems proposed for flare forecasting.\nHowever, most techniques are tailor-made and designed for specific purposes,\nnot allowing researchers to customize them in case of changes in data input or\nin the prediction algorithm. This paper proposes a framework to design, train,\nand evaluate flare prediction systems which present promising results. Our\nproposed framework involves model and feature selection, randomized\nhyper-parameters optimization, data resampling, and evaluation under\noperational settings. Compared to baseline predictions, our framework generated\nsome proof-of-concept models with positive recalls between 0.70 and 0.75 for\nforecasting $\\geq M$ class flares up to 96 hours ahead while keeping the area\nunder the ROC curve score at high levels.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 21:05:10 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Cinto", "T.", "", "1 and 2"], ["Gradvohl", "A. L. S.", ""], ["Coelho", "G. P.", ""], ["da Silva", "A. E. A.", ""]]}, {"id": "2005.02503", "submitter": "Semih Yagli", "authors": "Semih Yagli, Alex Dytso, H. Vincent Poor", "title": "Information-Theoretic Bounds on the Generalization Error and Privacy\n  Leakage in Federated Learning", "comments": "Accepted for publication in Proceedings of 21st IEEE International\n  Workshop on Signal Processing Advances in Wireless Communications (SPAWC),\n  2020. arXiv version is 10pt font, 6 Pages. This is the same document as the\n  SPAWC version, except that the conference version is written with 9pt font to\n  meet the strict page margin requirements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms operating on mobile networks can be characterized\ninto three different categories. First is the classical situation in which the\nend-user devices send their data to a central server where this data is used to\ntrain a model. Second is the distributed setting in which each device trains\nits own model and send its model parameters to a central server where these\nmodel parameters are aggregated to create one final model. Third is the\nfederated learning setting in which, at any given time $t$, a certain number of\nactive end users train with their own local data along with feedback provided\nby the central server and then send their newly estimated model parameters to\nthe central server. The server, then, aggregates these new parameters, updates\nits own model, and feeds the updated parameters back to all the end users,\ncontinuing this process until it converges.\n  The main objective of this work is to provide an information-theoretic\nframework for all of the aforementioned learning paradigms. Moreover, using the\nprovided framework, we develop upper and lower bounds on the generalization\nerror together with bounds on the privacy leakage in the classical, distributed\nand federated learning settings.\n  Keywords: Federated Learning, Distributed Learning, Machine Learning, Model\nAggregation.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 21:23:45 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Yagli", "Semih", ""], ["Dytso", "Alex", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2005.02507", "submitter": "Mandy Guo", "authors": "Mandy Guo, Yinfei Yang, Daniel Cer, Qinlan Shen, Noah Constant", "title": "MultiReQA: A Cross-Domain Evaluation for Retrieval Question Answering\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrieval question answering (ReQA) is the task of retrieving a\nsentence-level answer to a question from an open corpus (Ahmad et\nal.,2019).This paper presents MultiReQA, anew multi-domain ReQA evaluation\nsuite com-posed of eight retrieval QA tasks drawn from publicly available QA\ndatasets. We provide the first systematic retrieval based evaluation over these\ndatasets using two supervised neural models, based on fine-tuning BERT\nandUSE-QA models respectively, as well as a surprisingly strong information\nretrieval baseline,BM25. Five of these tasks contain both train-ing and test\ndata, while three contain test data only. Performance on the five tasks with\ntrain-ing data shows that while a general model covering all domains is\nachievable, the best performance is often obtained by training exclusively on\nin-domain data.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 21:30:16 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Guo", "Mandy", ""], ["Yang", "Yinfei", ""], ["Cer", "Daniel", ""], ["Shen", "Qinlan", ""], ["Constant", "Noah", ""]]}, {"id": "2005.02515", "submitter": "Myrl Marmarelis", "authors": "Myrl G. Marmarelis, Greg Ver Steeg, Aram Galstyan", "title": "Latent Embeddings of Point Process Excitations", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When specific events seem to spur others in their wake, marked Hawkes\nprocesses enable us to reckon with their statistics. The underdetermined\nempirical nature of these event-triggering mechanisms hinders estimation in the\nmultivariate setting. Spatiotemporal applications alleviate this obstacle by\nallowing relationships to depend only on relative distances in real Euclidean\nspace; we employ the framework as a vessel for embedding arbitrary event types\nin a new latent space. By performing synthetic experiments on short records as\nwell as an investigation into options markets and pathogens, we demonstrate\nthat learning the embedding alongside a point process model uncovers the\ncoherent, rather than spurious, interactions.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 21:54:22 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 22:23:37 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 00:45:44 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Marmarelis", "Myrl G.", ""], ["Steeg", "Greg Ver", ""], ["Galstyan", "Aram", ""]]}, {"id": "2005.02521", "submitter": "Vineet Raghu", "authors": "Vineet K Raghu, Xiaoyu Ge, Arun Balajee, Daniel J. Shirer, Isha Das,\n  Panayiotis V. Benos, and Panos K. Chrysanthis", "title": "A Pipeline for Integrated Theory and Data-Driven Modeling of Genomic and\n  Clinical Data", "comments": "16 pages, 8 figures, Presented at the ACM SIGKDD Workshop on Data\n  Mining in Bioinformatics (BioKDD, 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High throughput genome sequencing technologies such as RNA-Seq and Microarray\nhave the potential to transform clinical decision making and biomedical\nresearch by enabling high-throughput measurements of the genome at a granular\nlevel. However, to truly understand causes of disease and the effects of\nmedical interventions, this data must be integrated with phenotypic,\nenvironmental, and behavioral data from individuals. Further, effective\nknowledge discovery methods that can infer relationships between these data\ntypes are required. In this work, we propose a pipeline for knowledge discovery\nfrom integrated genomic and clinical data. The pipeline begins with a novel\nvariable selection method, and uses a probabilistic graphical model to\nunderstand the relationships between features in the data. We demonstrate how\nthis pipeline can improve breast cancer outcome prediction models, and can\nprovide a biologically interpretable view of sequencing data.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 22:23:27 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Raghu", "Vineet K", ""], ["Ge", "Xiaoyu", ""], ["Balajee", "Arun", ""], ["Shirer", "Daniel J.", ""], ["Das", "Isha", ""], ["Benos", "Panayiotis V.", ""], ["Chrysanthis", "Panos K.", ""]]}, {"id": "2005.02525", "submitter": "Henrique Lemos", "authors": "Henrique Lemos and Pedro Avelar and Marcelo Prates and Lu\\'is Lamb and\n  Artur Garcez", "title": "Neural-Symbolic Relational Reasoning on Graph Models: Effective Link\n  Inference and Computation from Knowledge Bases", "comments": "Under review: ICANN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent developments and growing interest in neural-symbolic models has\nshown that hybrid approaches can offer richer models for Artificial\nIntelligence. The integration of effective relational learning and reasoning\nmethods is one of the key challenges in this direction, as neural learning and\nsymbolic reasoning offer complementary characteristics that can benefit the\ndevelopment of AI systems. Relational labelling or link prediction on knowledge\ngraphs has become one of the main problems in deep learning-based natural\nlanguage processing research. Moreover, other fields which make use of\nneural-symbolic techniques may also benefit from such research endeavours.\nThere have been several efforts towards the identification of missing facts\nfrom existing ones in knowledge graphs. Two lines of research try and predict\nknowledge relations between two entities by considering all known facts\nconnecting them or several paths of facts connecting them. We propose a\nneural-symbolic graph neural network which applies learning over all the paths\nby feeding the model with the embedding of the minimal subset of the knowledge\ngraph containing such paths. By learning to produce representations for\nentities and facts corresponding to word embeddings, we show how the model can\nbe trained end-to-end to decode these representations and infer relations\nbetween entities in a multitask approach. Our contribution is two-fold: a\nneural-symbolic methodology leverages the resolution of relational inference in\nlarge graphs, and we also demonstrate that such neural-symbolic model is shown\nmore effective than path-based approaches\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 22:46:39 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Lemos", "Henrique", ""], ["Avelar", "Pedro", ""], ["Prates", "Marcelo", ""], ["Lamb", "Lu\u00eds", ""], ["Garcez", "Artur", ""]]}, {"id": "2005.02527", "submitter": "Tian Guo", "authors": "Tian Guo, Nicolas Jamet, Valentin Betrix, Louis-Alexandre Piquet,\n  Emmanuel Hauptmann", "title": "ESG2Risk: A Deep Learning Framework from ESG News to Stock Volatility\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating environmental, social, and governance (ESG) considerations into\nsystematic investments has drawn numerous attention recently. In this paper, we\nfocus on the ESG events in financial news flow and exploring the predictive\npower of ESG related financial news on stock volatility. In particular, we\ndevelop a pipeline of ESG news extraction, news representations, and Bayesian\ninference of deep learning models. Experimental evaluation on real data and\ndifferent markets demonstrates the superior predicting performance as well as\nthe relation of high volatility prediction to stocks with potential high risk\nand low return. It also shows the prospect of the proposed pipeline as a\nflexible predicting framework for various textual data and target variables.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 23:01:36 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Guo", "Tian", ""], ["Jamet", "Nicolas", ""], ["Betrix", "Valentin", ""], ["Piquet", "Louis-Alexandre", ""], ["Hauptmann", "Emmanuel", ""]]}, {"id": "2005.02540", "submitter": "Hyeongji Kim", "authors": "Hyeongji Kim, Pekka Parviainen, Ketil Malde", "title": "Measuring Adversarial Robustness using a Voronoi-Epsilon Adversary", "comments": "10 pages. Published at ICLR 2021 Workshop on Security and Safety in\n  Machine Learning Systems. Some definitions (names) are changed from the\n  previous versions. Some sections are also removed. This paper supersedes the\n  paper \"Finding a human-like classifier\".\n  (https://openreview.net/forum?id=BJeGFs9FsH)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies on robustness have argued that there is a tradeoff between\naccuracy and adversarial accuracy. The tradeoff can be inevitable even when we\nneglect generalization. We argue that the tradeoff is inherent to the commonly\nused definition of adversarial accuracy, which uses an adversary that can\nconstruct adversarial points constrained by $\\epsilon$-balls around data\npoints. As $\\epsilon$ gets large, the adversary may use real data points from\nother classes as adversarial examples. We propose a Voronoi-epsilon adversary\nwhich is constrained both by Voronoi cells and by $\\epsilon$-balls. This\nadversary balances between two notions of perturbation. As a result,\nadversarial accuracy based on this adversary avoids a tradeoff between accuracy\nand adversarial accuracy on training data even when $\\epsilon$ is large.\nFinally, we show that a nearest neighbor classifier is the maximally robust\nclassifier against the proposed adversary on the training data.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 00:09:28 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 12:07:29 GMT"}, {"version": "v3", "created": "Fri, 14 May 2021 15:20:35 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Kim", "Hyeongji", ""], ["Parviainen", "Pekka", ""], ["Malde", "Ketil", ""]]}, {"id": "2005.02544", "submitter": "Young Geun Kim", "authors": "Young Geun Kim and Carole-Jean Wu", "title": "AutoScale: Optimizing Energy Efficiency of End-to-End Edge Inference\n  under Stochastic Variance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning inference is increasingly run at the edge. As the programming\nand system stack support becomes mature, it enables acceleration opportunities\nwithin a mobile system, where the system performance envelope is scaled up with\na plethora of programmable co-processors. Thus, intelligent services designed\nfor mobile users can choose between running inference on the CPU or any of the\nco-processors on the mobile system, or exploiting connected systems, such as\nthe cloud or a nearby, locally connected system. By doing so, the services can\nscale out the performance and increase the energy efficiency of edge mobile\nsystems. This gives rise to a new challenge - deciding when inference should\nrun where. Such execution scaling decision becomes more complicated with the\nstochastic nature of mobile-cloud execution, where signal strength variations\nof the wireless networks and resource interference can significantly affect\nreal-time inference performance and system energy efficiency. To enable\naccurate, energy-efficient deep learning inference at the edge, this paper\nproposes AutoScale. AutoScale is an adaptive and light-weight execution scaling\nengine built upon the custom-designed reinforcement learning algorithm. It\ncontinuously learns and selects the most energy-efficient inference execution\ntarget by taking into account characteristics of neural networks and available\nsystems in the collaborative cloud-edge execution environment while adapting to\nthe stochastic runtime variance. Real system implementation and evaluation,\nconsidering realistic execution scenarios, demonstrate an average of 9.8 and\n1.6 times energy efficiency improvement for DNN edge inference over the\nbaseline mobile CPU and cloud offloading, while meeting the real-time\nperformance and accuracy requirement.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 00:30:29 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Kim", "Young Geun", ""], ["Wu", "Carole-Jean", ""]]}, {"id": "2005.02552", "submitter": "Shuya Ding", "authors": "Guanlin Li, Shuya Ding, Jun Luo, Chang Liu", "title": "Enhancing Intrinsic Adversarial Robustness via Feature Pyramid Decoder", "comments": null, "journal-ref": "CVPR 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whereas adversarial training is employed as the main defence strategy against\nspecific adversarial samples, it has limited generalization capability and\nincurs excessive time complexity. In this paper, we propose an attack-agnostic\ndefence framework to enhance the intrinsic robustness of neural networks,\nwithout jeopardizing the ability of generalizing clean samples. Our Feature\nPyramid Decoder (FPD) framework applies to all block-based convolutional neural\nnetworks (CNNs). It implants denoising and image restoration modules into a\ntargeted CNN, and it also constraints the Lipschitz constant of the\nclassification layer. Moreover, we propose a two-phase strategy to train the\nFPD-enhanced CNN, utilizing $\\epsilon$-neighbourhood noisy images with\nmulti-task and self-supervised learning. Evaluated against a variety of\nwhite-box and black-box attacks, we demonstrate that FPD-enhanced CNNs gain\nsufficient robustness against general adversarial samples on MNIST, SVHN and\nCALTECH. In addition, if we further conduct adversarial training, the\nFPD-enhanced CNNs perform better than their non-enhanced versions.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 01:40:26 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Li", "Guanlin", ""], ["Ding", "Shuya", ""], ["Luo", "Jun", ""], ["Liu", "Chang", ""]]}, {"id": "2005.02553", "submitter": "Honglei Zhuang", "authors": "Honglei Zhuang, Xuanhui Wang, Michael Bendersky, Alexander Grushetsky,\n  Yonghui Wu, Petr Mitrichev, Ethan Sterling, Nathan Bell, Walker Ravina, Hai\n  Qian", "title": "Interpretable Learning-to-Rank with Generalized Additive Models", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability of learning-to-rank models is a crucial yet relatively\nunder-examined research area. Recent progress on interpretable ranking models\nlargely focuses on generating post-hoc explanations for existing black-box\nranking models, whereas the alternative option of building an intrinsically\ninterpretable ranking model with transparent and self-explainable structure\nremains unexplored. Developing fully-understandable ranking models is necessary\nin some scenarios (e.g., due to legal or policy constraints) where post-hoc\nmethods cannot provide sufficiently accurate explanations. In this paper, we\nlay the groundwork for intrinsically interpretable learning-to-rank by\nintroducing generalized additive models (GAMs) into ranking tasks. Generalized\nadditive models (GAMs) are intrinsically interpretable machine learning models\nand have been extensively studied on regression and classification tasks. We\nstudy how to extend GAMs into ranking models which can handle both item-level\nand list-level features and propose a novel formulation of ranking GAMs. To\ninstantiate ranking GAMs, we employ neural networks instead of traditional\nsplines or regression trees. We also show that our neural ranking GAMs can be\ndistilled into a set of simple and compact piece-wise linear functions that are\nmuch more efficient to evaluate with little accuracy loss. We conduct\nexperiments on three data sets and show that our proposed neural ranking GAMs\ncan achieve significantly better performance than other traditional GAM\nbaselines while maintaining similar interpretability.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 01:51:30 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 18:44:23 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Zhuang", "Honglei", ""], ["Wang", "Xuanhui", ""], ["Bendersky", "Michael", ""], ["Grushetsky", "Alexander", ""], ["Wu", "Yonghui", ""], ["Mitrichev", "Petr", ""], ["Sterling", "Ethan", ""], ["Bell", "Nathan", ""], ["Ravina", "Walker", ""], ["Qian", "Hai", ""]]}, {"id": "2005.02561", "submitter": "Romain Mormont", "authors": "Romain Mormont, Pierre Geurts, Rapha\\\"el Mar\\'ee", "title": "Multi-task pre-training of deep neural networks for digital pathology", "comments": "Accepted for publication in the IEEE Journal of Biomedical and Health\n  Informatics, special issue on Computational Pathology", "journal-ref": null, "doi": "10.1109/JBHI.2020.2992878", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate multi-task learning as a way of pre-training\nmodels for classification tasks in digital pathology. It is motivated by the\nfact that many small and medium-size datasets have been released by the\ncommunity over the years whereas there is no large scale dataset similar to\nImageNet in the domain. We first assemble and transform many digital pathology\ndatasets into a pool of 22 classification tasks and almost 900k images. Then,\nwe propose a simple architecture and training scheme for creating a\ntransferable model and a robust evaluation and selection protocol in order to\nevaluate our method. Depending on the target task, we show that our models used\nas feature extractors either improve significantly over ImageNet pre-trained\nmodels or provide comparable performance. Fine-tuning improves performance over\nfeature extraction and is able to recover the lack of specificity of ImageNet\nfeatures, as both pre-training sources yield comparable performance.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 08:50:17 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 08:16:31 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Mormont", "Romain", ""], ["Geurts", "Pierre", ""], ["Mar\u00e9e", "Rapha\u00ebl", ""]]}, {"id": "2005.02563", "submitter": "Cong Hao", "authors": "Yuhong Li, Cong Hao, Xiaofan Zhang, Xinheng Liu, Yao Chen, Jinjun\n  Xiong, Wen-mei Hwu, Deming Chen", "title": "EDD: Efficient Differentiable DNN Architecture and Implementation\n  Co-search for Embedded AI Solutions", "comments": "Accepted by Design Automation Conference (DAC'2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High quality AI solutions require joint optimization of AI algorithms and\ntheir hardware implementations. In this work, we are the first to propose a\nfully simultaneous, efficient differentiable DNN architecture and\nimplementation co-search (EDD) methodology. We formulate the co-search problem\nby fusing DNN search variables and hardware implementation variables into one\nsolution space, and maximize both algorithm accuracy and hardware\nimplementation quality. The formulation is differentiable with respect to the\nfused variables, so that gradient descent algorithm can be applied to greatly\nreduce the search time. The formulation is also applicable for various devices\nwith different objectives. In the experiments, we demonstrate the effectiveness\nof our EDD methodology by searching for three representative DNNs, targeting\nlow-latency GPU implementation and FPGA implementations with both recursive and\npipelined architectures. Each model produced by EDD achieves similar accuracy\nas the best existing DNN models searched by neural architecture search (NAS)\nmethods on ImageNet, but with superior performance obtained within 12 GPU-hour\nsearches. Our DNN targeting GPU is 1.40x faster than the state-of-the-art\nsolution reported in Proxyless, and our DNN targeting FPGA delivers 1.45x\nhigher throughput than the state-of-the-art solution reported in DNNBuilder.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 02:37:48 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Li", "Yuhong", ""], ["Hao", "Cong", ""], ["Zhang", "Xiaofan", ""], ["Liu", "Xinheng", ""], ["Chen", "Yao", ""], ["Xiong", "Jinjun", ""], ["Hwu", "Wen-mei", ""], ["Chen", "Deming", ""]]}, {"id": "2005.02575", "submitter": "Erdem B{\\i}y{\\i}k", "authors": "Erdem B{\\i}y{\\i}k, Nicolas Huynh, Mykel J. Kochenderfer, Dorsa Sadigh", "title": "Active Preference-Based Gaussian Process Regression for Reward Learning", "comments": "Proceedings of Robotics: Science and Systems (RSS), July 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing reward functions is a challenging problem in AI and robotics.\nHumans usually have a difficult time directly specifying all the desirable\nbehaviors that a robot needs to optimize. One common approach is to learn\nreward functions from collected expert demonstrations. However, learning reward\nfunctions from demonstrations introduces many challenges: some methods require\nhighly structured models, e.g. reward functions that are linear in some\npredefined set of features, while others adopt less structured reward functions\nthat on the other hand require tremendous amount of data. In addition, humans\ntend to have a difficult time providing demonstrations on robots with high\ndegrees of freedom, or even quantifying reward values for given demonstrations.\nTo address these challenges, we present a preference-based learning approach,\nwhere as an alternative, the human feedback is only in the form of comparisons\nbetween trajectories. Furthermore, we do not assume highly constrained\nstructures on the reward function. Instead, we model the reward function using\na Gaussian Process (GP) and propose a mathematical formulation to actively find\na GP using only human preferences. Our approach enables us to tackle both\ninflexibility and data-inefficiency problems within a preference-based learning\nframework. Our results in simulations and a user study suggest that our\napproach can efficiently learn expressive reward functions for robotics tasks.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 03:29:27 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 23:08:00 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["B\u0131y\u0131k", "Erdem", ""], ["Huynh", "Nicolas", ""], ["Kochenderfer", "Mykel J.", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "2005.02578", "submitter": "Shinsaku Sakaue", "authors": "Shinsaku Sakaue", "title": "Differentiable Greedy Submodular Maximization: Guarantees, Gradient\n  Estimators, and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by, e.g., sensitivity analysis and end-to-end learning, the demand\nfor differentiable optimization algorithms has been significantly increasing.\nIn this paper, we establish a theoretically guaranteed versatile framework that\nmakes the greedy algorithm for monotone submodular function maximization\ndifferentiable. We smooth the greedy algorithm via randomization, and prove\nthat it almost recovers original approximation guarantees in expectation for\nthe cases of cardinality and $\\kappa$-extensible system constrains. We also\nshow how to efficiently compute unbiased gradient estimators of any expected\noutput-dependent quantities. We demonstrate the usefulness of our framework by\ninstantiating it for various applications.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 03:33:46 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 10:29:47 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 02:52:24 GMT"}, {"version": "v4", "created": "Fri, 12 Jun 2020 01:07:08 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Sakaue", "Shinsaku", ""]]}, {"id": "2005.02587", "submitter": "Javier E. Santos", "authors": "Javier E. Santos, Mohammed Mehana, Hao Wu, Masa Prodanovic, Michael J.\n  Pyrcz, Qinjun Kang, Nicholas Lubbers, Hari Viswanathan", "title": "Modeling nanoconfinement effects using active learning", "comments": "Full paper", "journal-ref": "J. Phys. Chem. C 2020", "doi": "10.1021/acs.jpcc.0c07427", "report-no": null, "categories": "physics.app-ph cs.LG physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the spatial configuration of gas molecules in nanopores of shale\nformations is crucial for fluid flow forecasting and hydrocarbon reserves\nestimation. The key challenge in these tight formations is that the majority of\nthe pore sizes are less than 50 nm. At this scale, the fluid properties are\naffected by nanoconfinement effects due to the increased fluid-solid\ninteractions. For instance, gas adsorption to the pore walls could account for\nup to 85% of the total hydrocarbon volume in a tight reservoir. Although there\nare analytical solutions that describe this phenomenon for simple geometries,\nthey are not suitable for describing realistic pores, where surface roughness\nand geometric anisotropy play important roles. To describe these, molecular\ndynamics (MD) simulations are used since they consider fluid-solid and\nfluid-fluid interactions at the molecular level. However, MD simulations are\ncomputationally expensive, and are not able to simulate scales larger than a\nfew connected nanopores. We present a method for building and training\nphysics-based deep learning surrogate models to carry out fast and accurate\npredictions of molecular configurations of gas inside nanopores. Since training\ndeep learning models requires extensive databases that are computationally\nexpensive to create, we employ active learning (AL). AL reduces the overhead of\ncreating comprehensive sets of high-fidelity data by determining where the\nmodel uncertainty is greatest, and running simulations on the fly to minimize\nit. The proposed workflow enables nanoconfinement effects to be rigorously\nconsidered at the mesoscale where complex connected sets of nanopores control\nkey applications such as hydrocarbon recovery and CO2 sequestration.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 04:01:53 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 02:12:39 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Santos", "Javier E.", ""], ["Mehana", "Mohammed", ""], ["Wu", "Hao", ""], ["Prodanovic", "Masa", ""], ["Pyrcz", "Michael J.", ""], ["Kang", "Qinjun", ""], ["Lubbers", "Nicholas", ""], ["Viswanathan", "Hari", ""]]}, {"id": "2005.02589", "submitter": "Anirudh Som", "authors": "Anirudh Som, Narayanan Krishnamurthi, Matthew Buman and Pavan Turaga", "title": "Unsupervised Pre-trained Models from Healthy ADLs Improve Parkinson's\n  Disease Classification of Gait Patterns", "comments": "Accepted in the 42nd Annual International Conferences of the IEEE\n  Engineering in Medicine and Biology Society (EMBC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Application and use of deep learning algorithms for different healthcare\napplications is gaining interest at a steady pace. However, use of such\nalgorithms can prove to be challenging as they require large amounts of\ntraining data that capture different possible variations. This makes it\ndifficult to use them in a clinical setting since in most health applications\nresearchers often have to work with limited data. Less data can cause the deep\nlearning model to over-fit. In this paper, we ask how can we use data from a\ndifferent environment, different use-case, with widely differing data\ndistributions. We exemplify this use case by using single-sensor accelerometer\ndata from healthy subjects performing activities of daily living - ADLs (source\ndataset), to extract features relevant to multi-sensor accelerometer gait data\n(target dataset) for Parkinson's disease classification. We train the\npre-trained model using the source dataset and use it as a feature extractor.\nWe show that the features extracted for the target dataset can be used to train\nan effective classification model. Our pre-trained source model consists of a\nconvolutional autoencoder, and the target classification model is a simple\nmulti-layer perceptron model. We explore two different pre-trained source\nmodels, trained using different activity groups, and analyze the influence the\nchoice of pre-trained model has over the task of Parkinson's disease\nclassification.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 04:08:19 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 00:56:01 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Som", "Anirudh", ""], ["Krishnamurthi", "Narayanan", ""], ["Buman", "Matthew", ""], ["Turaga", "Pavan", ""]]}, {"id": "2005.02593", "submitter": "Yinqiao Li", "authors": "Yinqiao Li, Chi Hu, Yuhao Zhang, Nuo Xu, Yufan Jiang, Tong Xiao,\n  Jingbo Zhu, Tongran Liu, Changliang Li", "title": "Learning Architectures from an Extended Search Space for Language\n  Modeling", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) has advanced significantly in recent years\nbut most NAS systems restrict search to learning architectures of a recurrent\nor convolutional cell. In this paper, we extend the search space of NAS. In\nparticular, we present a general approach to learn both intra-cell and\ninter-cell architectures (call it ESS). For a better search result, we design a\njoint learning method to perform intra-cell and inter-cell NAS simultaneously.\nWe implement our model in a differentiable architecture search system. For\nrecurrent neural language modeling, it outperforms a strong baseline\nsignificantly on the PTB and WikiText data, with a new state-of-the-art on PTB.\nMoreover, the learned architectures show good transferability to other systems.\nE.g., they improve state-of-the-art systems on the CoNLL and WNUT named entity\nrecognition (NER) tasks and CoNLL chunking task, indicating a promising line of\nresearch on large-scale pre-learned architectures.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 05:02:33 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 06:23:49 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Li", "Yinqiao", ""], ["Hu", "Chi", ""], ["Zhang", "Yuhao", ""], ["Xu", "Nuo", ""], ["Jiang", "Yufan", ""], ["Xiao", "Tong", ""], ["Zhu", "Jingbo", ""], ["Liu", "Tongran", ""], ["Li", "Changliang", ""]]}, {"id": "2005.02595", "submitter": "Ashish Gupta", "authors": "Ashish Gupta, Hari Prabhat Gupta, Bhaskar Biswas, Tanima Dutta", "title": "Approaches and Applications of Early Classification of Time Series: A\n  Review", "comments": "15 pages, 6 figures, 6 tables", "journal-ref": "IEEE Transactions on Artificial Intelligence (2020)", "doi": "10.1109/TAI.2020.3027279", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Early classification of time series has been extensively studied for\nminimizing class prediction delay in time-sensitive applications such as\nhealthcare and finance. A primary task of an early classification approach is\nto classify an incomplete time series as soon as possible with some desired\nlevel of accuracy. Recent years have witnessed several approaches for early\nclassification of time series. As most of the approaches have solved the early\nclassification problem with different aspects, it becomes very important to\nmake a thorough review of the existing solutions to know the current status of\nthe area. These solutions have demonstrated reasonable performance in a wide\nrange of applications including human activity recognition, gene expression\nbased health diagnostic, industrial monitoring, and so on. In this paper, we\npresent a systematic review of current literature on early classification\napproaches for both univariate and multivariate time series. We divide various\nexisting approaches into four exclusive categories based on their proposed\nsolution strategies. The four categories include prefix based, shapelet based,\nmodel based, and miscellaneous approaches. The authors also discuss the\napplications of early classification in many areas including industrial\nmonitoring, intelligent transportation, and medical. Finally, we provide a\nquick summary of the current literature with future research directions.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 05:12:22 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 18:06:28 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Gupta", "Ashish", ""], ["Gupta", "Hari Prabhat", ""], ["Biswas", "Bhaskar", ""], ["Dutta", "Tanima", ""]]}, {"id": "2005.02607", "submitter": "Casper Gyurik", "authors": "Casper Gyurik, Chris Cade and Vedran Dunjko", "title": "Towards quantum advantage via topological data analysis", "comments": "26 pages, 3 figures. New algorithms and results added, improved\n  exposition", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even after decades of quantum computing development, examples of generally\nuseful quantum algorithms with exponential speedups over classical counterparts\nare scarce. Recent progress in quantum algorithms for linear-algebra positioned\nquantum machine learning (QML) as a potential source of such useful exponential\nimprovements. Yet, in an unexpected development, a recent series of\n\"dequantization\" results has equally rapidly removed the promise of exponential\nspeedups for several QML algorithms. This raises the critical question whether\nexponential speedups of other linear-algebraic QML algorithms persist. In this\npaper, we study the quantum-algorithmic methods behind the algorithm for\ntopological data analysis of Lloyd, Garnerone and Zanardi through this lens. We\nprovide evidence that the problem solved by this algorithm is classically\nintractable by showing that its natural generalization is as hard as simulating\nthe one clean qubit model -- which is widely believed to require\nsuperpolynomial time on a classical computer -- and is thus very likely immune\nto dequantizations. Based on this result, we provide a number of new quantum\nalgorithms for problems such as rank estimation and complex network analysis,\nalong with complexity-theoretic evidence for their classical intractability.\nFurthermore, we analyze the suitability of the proposed quantum algorithms for\nnear-term implementations. Our results provide a number of useful applications\nfor full-blown, and restricted quantum computers with a guaranteed exponential\nspeedup over classical methods, recovering some of the potential for\nlinear-algebraic QML to become a killer application of quantum computers.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 06:31:24 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 15:23:27 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Gyurik", "Casper", ""], ["Cade", "Chris", ""], ["Dunjko", "Vedran", ""]]}, {"id": "2005.02612", "submitter": "Kubra Cilingir", "authors": "Kubra Cilingir, Rachel Manzelli, Brian Kulis", "title": "Deep Divergence Learning", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical linear metric learning methods have recently been extended along\ntwo distinct lines: deep metric learning methods for learning embeddings of the\ndata using neural networks, and Bregman divergence learning approaches for\nextending learning Euclidean distances to more general divergence measures such\nas divergences over distributions. In this paper, we introduce deep Bregman\ndivergences, which are based on learning and parameterizing functional Bregman\ndivergences using neural networks, and which unify and extend these existing\nlines of work. We show in particular how deep metric learning formulations,\nkernel metric learning, Mahalanobis metric learning, and moment-matching\nfunctions for comparing distributions arise as special cases of these\ndivergences in the symmetric setting. We then describe a deep learning\nframework for learning general functional Bregman divergences, and show in\nexperiments that this method yields superior performance on benchmark datasets\nas compared to existing deep metric learning approaches. We also discuss novel\napplications, including a semi-supervised distributional clustering problem,\nand a new loss function for unsupervised data generation.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 06:43:25 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Cilingir", "Kubra", ""], ["Manzelli", "Rachel", ""], ["Kulis", "Brian", ""]]}, {"id": "2005.02637", "submitter": "Durgesh Samariya", "authors": "Durgesh Samariya and Jiangang Ma and Sunil Aryal", "title": "A Comprehensive Survey on Outlying Aspect Mining Methods", "comments": "12 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, researchers have become increasingly interested in outlying\naspect mining. Outlying aspect mining is the task of finding a set of\nfeature(s), where a given data object is different from the rest of the data\nobjects. Remarkably few studies have been designed to address the problem of\noutlying aspect mining; therefore, little is known about outlying aspect mining\napproaches and their strengths and weaknesses among researchers. In this work,\nwe have grouped existing outlying aspect mining approaches in three different\ncategories. For each category, we have provided existing work that falls in\nthat category and then provided their strengths and weaknesses in those\ncategories. We also offer time complexity comparison of the current techniques\nsince it is a crucial issue in the real-world scenario. The motive behind this\npaper is to give a better understanding of the existing outlying aspect mining\ntechniques and how these techniques have been developed.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 07:48:34 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 04:39:51 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Samariya", "Durgesh", ""], ["Ma", "Jiangang", ""], ["Aryal", "Sunil", ""]]}, {"id": "2005.02643", "submitter": "Wonsik Jung", "authors": "Wonsik Jung, Eunji Jun, Heung-Il Suk", "title": "Deep Recurrent Model for Individualized Prediction of Alzheimer's\n  Disease Progression", "comments": "17 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer's disease (AD) is known as one of the major causes of dementia and\nis characterized by slow progression over several years, with no treatments or\navailable medicines. In this regard, there have been efforts to identify the\nrisk of developing AD in its earliest time. While many of the previous works\nconsidered cross-sectional analysis, more recent studies have focused on the\ndiagnosis and prognosis of AD with longitudinal or time series data in a way of\ndisease progression modeling (DPM). Under the same problem settings, in this\nwork, we propose a novel computational framework that can predict the\nphenotypic measurements of MRI biomarkers and trajectories of clinical status\nalong with cognitive scores at multiple future time points. However, in\nhandling time series data, it generally faces with many unexpected missing\nobservations. In regard to such an unfavorable situation, we define a secondary\nproblem of estimating those missing values and tackle it in a systematic way by\ntaking account of temporal and multivariate relations inherent in time series\ndata. Concretely, we propose a deep recurrent network that jointly tackles the\nfour problems of (i) missing value imputation, (ii) phenotypic measurements\nforecasting, (iii) trajectory estimation of the cognitive score, and (iv)\nclinical status prediction of a subject based on his/her longitudinal imaging\nbiomarkers. Notably, the learnable model parameters of our network are trained\nin an end-to-end manner with our circumspectly defined loss function. In our\nexperiments over TADPOLE challenge cohort, we measured performance for various\nmetrics and compared our method to competing methods in the literature.\nExhaustive analyses and ablation studies were also conducted to better confirm\nthe effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 08:08:00 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 11:28:42 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Jung", "Wonsik", ""], ["Jun", "Eunji", ""], ["Suk", "Heung-Il", ""]]}, {"id": "2005.02649", "submitter": "EPTCS", "authors": "Tuomas Halvari, Jukka K. Nurminen, Tommi Mikkonen", "title": "Testing the Robustness of AutoML Systems", "comments": "In Proceedings AREA 2020, arXiv:2007.11260", "journal-ref": "EPTCS 319, 2020, pp. 103-116", "doi": "10.4204/EPTCS.319.8", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated machine learning (AutoML) systems aim at finding the best machine\nlearning (ML) pipeline that automatically matches the task and data at hand. We\ninvestigate the robustness of machine learning pipelines generated with three\nAutoML systems, TPOT, H2O, and AutoKeras. In particular, we study the influence\nof dirty data on accuracy, and consider how using dirty training data may help\ncreate more robust solutions. Furthermore, we also analyze how the structure of\nthe generated pipelines differs in different cases.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 08:20:03 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 01:32:38 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Halvari", "Tuomas", ""], ["Nurminen", "Jukka K.", ""], ["Mikkonen", "Tommi", ""]]}, {"id": "2005.02664", "submitter": "Fan He", "authors": "Fan He, Kexin Lv, Jie Yang, Xiaolin Huang", "title": "One-shot Distibuted Algorithm for PCA with RBF Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter proposes a one-shot algorithm for feature-distributed kernel PCA.\nOur algorithm is inspired by the dual relationship between sample-distributed\nand feature-distributed scenario. This interesting relationship makes it\npossible to establish distributed kernel PCA for feature-distributed cases from\nideas in distributed PCA in sample-distributed scenario. In theoretical part,\nwe analyze the approximation error for both linear and RBF kernels. The result\nsuggests that when eigenvalues decay fast, the proposed algorithm gives high\nquality results with low communication cost. This result is also verified by\nnumerical experiments, showing the effectiveness of our algorithm in practice.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 09:07:50 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 02:17:46 GMT"}, {"version": "v3", "created": "Thu, 29 Apr 2021 07:11:47 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["He", "Fan", ""], ["Lv", "Kexin", ""], ["Yang", "Jie", ""], ["Huang", "Xiaolin", ""]]}, {"id": "2005.02666", "submitter": "Lars Elend", "authors": "Tim Cofala, Lars Elend, Philip Mirbach, Jonas Prellberg, Thomas\n  Teusch, Oliver Kramer", "title": "Evolutionary Multi-Objective Design of SARS-CoV-2 Protease Inhibitor\n  Candidates", "comments": "15 pages, 7 figures, submitted to PPSN 2020", "journal-ref": "LNCS 12270 (2020) 357-371", "doi": "10.1007/978-3-030-58115-2_25", "report-no": null, "categories": "cs.NE cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational drug design based on artificial intelligence is an emerging\nresearch area. At the time of writing this paper, the world suffers from an\noutbreak of the coronavirus SARS-CoV-2. A promising way to stop the virus\nreplication is via protease inhibition. We propose an evolutionary\nmulti-objective algorithm (EMOA) to design potential protease inhibitors for\nSARS-CoV-2's main protease. Based on the SELFIES representation the EMOA\nmaximizes the binding of candidate ligands to the protein using the docking\ntool QuickVina 2, while at the same time taking into account further objectives\nlike drug-likeliness or the fulfillment of filter constraints. The experimental\npart analyzes the evolutionary process and discusses the inhibitor candidates.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 09:15:20 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 13:35:31 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Cofala", "Tim", ""], ["Elend", "Lars", ""], ["Mirbach", "Philip", ""], ["Prellberg", "Jonas", ""], ["Teusch", "Thomas", ""], ["Kramer", "Oliver", ""]]}, {"id": "2005.02671", "submitter": "Marek Kowalski", "authors": "Marek Kowalski, Stephan J. Garbin, Virginia Estellers, Tadas\n  Baltru\\v{s}aitis, Matthew Johnson, Jamie Shotton", "title": "CONFIG: Controllable Neural Face Image Generation", "comments": "includes supplementary materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our ability to sample realistic natural images, particularly faces, has\nadvanced by leaps and bounds in recent years, yet our ability to exert\nfine-tuned control over the generative process has lagged behind. If this new\ntechnology is to find practical uses, we need to achieve a level of control\nover generative networks which, without sacrificing realism, is on par with\nthat seen in computer graphics and character animation. To this end we propose\nConfigNet, a neural face model that allows for controlling individual aspects\nof output images in semantically meaningful ways and that is a significant step\non the path towards finely-controllable neural rendering. ConfigNet is trained\non real face images as well as synthetic face renders. Our novel method uses\nsynthetic data to factorize the latent space into elements that correspond to\nthe inputs of a traditional rendering pipeline, separating aspects such as head\npose, facial expression, hair style, illumination, and many others which are\nvery hard to annotate in real data. The real images, which are presented to the\nnetwork without labels, extend the variety of the generated images and\nencourage realism. Finally, we propose an evaluation criterion using an\nattribute detection network combined with a user study and demonstrate\nstate-of-the-art individual control over attributes in the output images.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 09:19:46 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 15:10:21 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 10:13:56 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Kowalski", "Marek", ""], ["Garbin", "Stephan J.", ""], ["Estellers", "Virginia", ""], ["Baltru\u0161aitis", "Tadas", ""], ["Johnson", "Matthew", ""], ["Shotton", "Jamie", ""]]}, {"id": "2005.02699", "submitter": "Jing Wu", "authors": "Jing Wu, Xiang Zhang, Mingyi Zhou, Ce Zhu", "title": "ProbaNet: Proposal-balanced Network for Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Candidate object proposals generated by object detectors based on\nconvolutional neural network (CNN) encounter easy-hard samples imbalance\nproblem, which can affect overall performance. In this study, we propose a\nProposal-balanced Network (ProbaNet) for alleviating the imbalance problem.\nFirstly, ProbaNet increases the probability of choosing hard samples for\ntraining by discarding easy samples through threshold truncation. Secondly,\nProbaNet emphasizes foreground proposals by increasing their weights. To\nevaluate the effectiveness of ProbaNet, we train models based on different\nbenchmarks. Mean Average Precision (mAP) of the model using ProbaNet achieves\n1.2$\\%$ higher than the baseline on PASCAL VOC 2007. Furthermore, it is\ncompatible with existing two-stage detectors and offers a very small amount of\nadditional computational cost.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 10:07:39 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 10:32:55 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Wu", "Jing", ""], ["Zhang", "Xiang", ""], ["Zhou", "Mingyi", ""], ["Zhu", "Ce", ""]]}, {"id": "2005.02762", "submitter": "Hamidreza Eivazi", "authors": "Hamidreza Eivazi, Luca Guastoni, Philipp Schlatter, Hossein Azizpour,\n  Ricardo Vinuesa", "title": "Recurrent neural networks and Koopman-based frameworks for temporal\n  predictions in a low-order model of turbulence", "comments": "International Journal of Heat and Fluid Flow. arXiv admin note:\n  substantial text overlap with arXiv:2002.01222", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capabilities of recurrent neural networks and Koopman-based frameworks\nare assessed in the prediction of temporal dynamics of the low-order model of\nnear-wall turbulence by Moehlis et al. (New J. Phys. 6, 56, 2004). Our results\nshow that it is possible to obtain excellent reproductions of the long-term\nstatistics and the dynamic behavior of the chaotic system with properly trained\nlong-short-term memory (LSTM) networks, leading to relative errors in the mean\nand the fluctuations below $1\\%$. Besides, a newly developed Koopman-based\nframework, called Koopman with nonlinear forcing (KNF), leads to the same level\nof accuracy in the statistics at a significantly lower computational expense.\nFurthermore, the KNF framework outperforms the LSTM network when it comes to\nshort-term predictions. We also observe that using a loss function based only\non the instantaneous predictions of the chaotic system can lead to suboptimal\nreproductions in terms of long-term statistics. Thus, we propose a\nmodel-selection criterion based on the computed statistics which allows to\nachieve excellent statistical reconstruction even on small datasets, with\nminimal loss of accuracy in the instantaneous predictions.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 11:05:14 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 13:34:32 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Eivazi", "Hamidreza", ""], ["Guastoni", "Luca", ""], ["Schlatter", "Philipp", ""], ["Azizpour", "Hossein", ""], ["Vinuesa", "Ricardo", ""]]}, {"id": "2005.02767", "submitter": "Marcel Menner", "authors": "Marcel Menner, Melanie N. Zeilinger", "title": "Maximum Likelihood Methods for Inverse Learning of Optimal Controllers", "comments": "21st IFAC World Congress", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a framework for inverse learning of objective functions\nfor constrained optimal control problems, which is based on the\nKarush-Kuhn-Tucker (KKT) conditions. We discuss three variants corresponding to\ndifferent model assumptions and computational complexities. The first method\nuses a convex relaxation of the KKT conditions and serves as the benchmark. The\nmain contribution of this paper is the proposition of two learning methods that\ncombine the KKT conditions with maximum likelihood estimation. The key benefit\nof this combination is the systematic treatment of constraints for learning\nfrom noisy data with a branch-and-bound algorithm using likelihood arguments.\nThis paper discusses theoretic properties of the learning methods and presents\nsimulation results that highlight the advantages of using the maximum\nlikelihood formulation for learning objective functions.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 12:27:22 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Menner", "Marcel", ""], ["Zeilinger", "Melanie N.", ""]]}, {"id": "2005.02771", "submitter": "Timur Sokhin", "authors": "Timur Sokhin, Maria Khodorchenko, and Nikolay Butakov", "title": "Unsupervised Neural Aspect Search with Related Terms Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tasks of aspect identification and term extraction remain challenging in\nnatural language processing. While supervised methods achieve high scores, it\nis hard to use them in real-world applications due to the lack of labelled\ndatasets. Unsupervised approaches outperform these methods on several tasks,\nbut it is still a challenge to extract both an aspect and a corresponding term,\nparticularly in the multi-aspect setting. In this work, we present a novel\nunsupervised neural network with convolutional multi-attention mechanism, that\nallows extracting pairs (aspect, term) simultaneously, and demonstrate the\neffectiveness on the real-world dataset. We apply a special loss aimed to\nimprove the quality of multi-aspect extraction. The experimental study\ndemonstrates, what with this loss we increase the precision not only on this\njoint setting but also on aspect prediction only.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 12:39:45 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Sokhin", "Timur", ""], ["Khodorchenko", "Maria", ""], ["Butakov", "Nikolay", ""]]}, {"id": "2005.02790", "submitter": "Naiyan Wang", "authors": "Hao He, Hengchen Dai, Naiyan Wang", "title": "UST: Unifying Spatio-Temporal Context for Trajectory Prediction in\n  Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trajectory prediction has always been a challenging problem for autonomous\ndriving, since it needs to infer the latent intention from the behaviors and\ninteractions from traffic participants. This problem is intrinsically hard,\nbecause each participant may behave differently under different environments\nand interactions. This key is to effectively model the interlaced influence\nfrom both spatial context and temporal context. Existing work usually encodes\nthese two types of context separately, which would lead to inferior modeling of\nthe scenarios. In this paper, we first propose a unified approach to treat time\nand space dimensions equally for modeling spatio-temporal context. The proposed\nmodule is simple and easy to implement within several lines of codes. In\ncontrast to existing methods which heavily rely on recurrent neural network for\ntemporal context and hand-crafted structure for spatial context, our method\ncould automatically partition the spatio-temporal space to adapt the data.\nLastly, we test our proposed framework on two recently proposed trajectory\nprediction dataset ApolloScape and Argoverse. We show that the proposed method\nsubstantially outperforms the previous state-of-the-art methods while\nmaintaining its simplicity. These encouraging results further validate the\nsuperiority of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 13:02:57 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["He", "Hao", ""], ["Dai", "Hengchen", ""], ["Wang", "Naiyan", ""]]}, {"id": "2005.02791", "submitter": "Nathan Kallus", "authors": "Yichun Hu and Nathan Kallus", "title": "DTR Bandit: Learning to Make Response-Adaptive Decisions With Low Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic treatment regimes (DTRs) are personalized, adaptive, multi-stage\ntreatment plans that adapt treatment decisions both to an individual's initial\nfeatures and to intermediate outcomes and features at each subsequent stage,\nwhich are affected by decisions in prior stages. Examples include personalized\nfirst- and second-line treatments of chronic conditions like diabetes, cancer,\nand depression, which adapt to patient response to first-line treatment,\ndisease progression, and individual characteristics. While existing literature\nmostly focuses on estimating the optimal DTR from offline data such as from\nsequentially randomized trials, we study the problem of developing the optimal\nDTR in an online manner, where the interaction with each individual affect both\nour cumulative reward and our data collection for future learning. We term this\nthe DTR bandit problem. We propose a novel algorithm that, by carefully\nbalancing exploration and exploitation, is guaranteed to achieve rate-optimal\nregret when the transition and reward models are linear. We demonstrate our\nalgorithm and its benefits both in synthetic experiments and in a case study of\nadaptive treatment of major depressive disorder using real-world data.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 13:03:42 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 17:34:53 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Hu", "Yichun", ""], ["Kallus", "Nathan", ""]]}, {"id": "2005.02794", "submitter": "Deajin Jo", "authors": "DaeJin Jo", "title": "Token Manipulation Generative Adversarial Network for Text Generation", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MaskGAN opens the query for the conditional language model by filling in the\nblanks between the given tokens. In this paper, we focus on addressing the\nlimitations caused by having to specify blanks to be filled. We decompose\nconditional text generation problem into two tasks, make-a-blank and\nfill-in-the-blank, and extend the former to handle more complex manipulations\non the given tokens. We cast these tasks as a hierarchical multi agent RL\nproblem and introduce a conditional adversarial learning that allows the agents\nto reach a goal, producing realistic texts, in cooperative setting. We show\nthat the proposed model not only addresses the limitations but also provides\ngood results without compromising the performance in terms of quality and\ndiversity.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 13:10:43 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 12:17:28 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Jo", "DaeJin", ""]]}, {"id": "2005.02817", "submitter": "Saswata Sahoo Dr", "authors": "Saswata Sahoo and Souradip Chakraborty", "title": "Graph Spectral Feature Learning for Mixed Data of Categorical and\n  Numerical Type", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature learning in the presence of a mixed type of variables, numerical and\ncategorical types, is an important issue for related modeling problems. For\nsimple neighborhood queries under mixed data space, standard practice is to\nconsider numerical and categorical variables separately and combining them\nbased on some suitable distance functions. Alternatives, such as Kernel\nlearning or Principal Component do not explicitly consider the inter-dependence\nstructure among the mixed type of variables. In this work, we propose a novel\nstrategy to explicitly model the probabilistic dependence structure among the\nmixed type of variables by an undirected graph. Spectral decomposition of the\ngraph Laplacian provides the desired feature transformation. The Eigen spectrum\nof the transformed feature space shows increased separability and more\nprominent clusterability among the observations. The main novelty of our paper\nlies in capturing interactions of the mixed feature type in an unsupervised\nframework using a graphical model. We numerically validate the implications of\nthe feature learning strategy\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 13:36:59 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Sahoo", "Saswata", ""], ["Chakraborty", "Souradip", ""]]}, {"id": "2005.02819", "submitter": "Max Kochurov", "authors": "Max Kochurov, Rasul Karimov, Serge Kozlukov", "title": "Geoopt: Riemannian Optimization in PyTorch", "comments": "Proceedings of the 37th International Conference on Machine Learning,\n  Vienna, Austria, PMLR 108, 2020, GRLB Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geoopt is a research-oriented modular open-source package for Riemannian\nOptimization in PyTorch. The core of Geoopt is a standard Manifold interface\nthat allows for the generic implementation of optimization algorithms. Geoopt\nsupports basic Riemannian SGD as well as adaptive optimization algorithms.\nGeoopt also provides several algorithms and arithmetic methods for supported\nmanifolds, which allow composing geometry-aware neural network layers that can\nbe integrated with existing models.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 13:39:30 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 18:35:09 GMT"}, {"version": "v3", "created": "Sat, 4 Jul 2020 00:19:43 GMT"}, {"version": "v4", "created": "Thu, 9 Jul 2020 06:55:00 GMT"}, {"version": "v5", "created": "Fri, 17 Jul 2020 16:42:53 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Kochurov", "Max", ""], ["Karimov", "Rasul", ""], ["Kozlukov", "Serge", ""]]}, {"id": "2005.02844", "submitter": "Yanqiao Zhu", "authors": "Feng Yu, Yanqiao Zhu, Qiang Liu, Shu Wu, Liang Wang, Tieniu Tan", "title": "TAGNN: Target Attentive Graph Neural Networks for Session-based\n  Recommendation", "comments": "5 pages, accepted to SIGIR 2020, authors' version", "journal-ref": null, "doi": "10.1145/3397271.3401319", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Session-based recommendation nowadays plays a vital role in many websites,\nwhich aims to predict users' actions based on anonymous sessions. There have\nemerged many studies that model a session as a sequence or a graph via\ninvestigating temporal transitions of items in a session. However, these\nmethods compress a session into one fixed representation vector without\nconsidering the target items to be predicted. The fixed vector will restrict\nthe representation ability of the recommender model, considering the diversity\nof target items and users' interests. In this paper, we propose a novel target\nattentive graph neural network (TAGNN) model for session-based recommendation.\nIn TAGNN, target-aware attention adaptively activates different user interests\nwith respect to varied target items. The learned interest representation vector\nvaries with different target items, greatly improving the expressiveness of the\nmodel. Moreover, TAGNN harnesses the power of graph neural networks to capture\nrich item transitions in sessions. Comprehensive experiments conducted on\nreal-world datasets demonstrate its superiority over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 14:17:05 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Yu", "Feng", ""], ["Zhu", "Yanqiao", ""], ["Liu", "Qiang", ""], ["Wu", "Shu", ""], ["Wang", "Liang", ""], ["Tan", "Tieniu", ""]]}, {"id": "2005.02856", "submitter": "Pranab K. Muhuri Dr.", "authors": "Sandeep Kumar and Pranab K. Muhuri", "title": "A Novel GDP Prediction Technique based on Transfer Learning using CO2\n  Emission Dataset", "comments": null, "journal-ref": "Applied Energy 253 (2019): 113476", "doi": "10.1016/j.apenergy.2019.113476", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last 150 years, CO2 concentration in the atmosphere has increased from\n280 parts per million to 400 parts per million. This has caused an increase in\nthe average global temperatures by nearly 0.7 degree centigrade due to the\ngreenhouse effect. However, the most prosperous states are the highest emitters\nof greenhouse gases (specially, CO2). This indicates a strong relationship\nbetween gaseous emissions and the gross domestic product (GDP) of the states.\nSuch a relationship is highly volatile and nonlinear due to its dependence on\nthe technological advancements and constantly changing domestic and\ninternational regulatory policies and relations. To analyse such vastly\nnonlinear relationships, soft computing techniques has been quite effective as\nthey can predict a compact solution for multi-variable parameters without any\nexplicit insight into the internal system functionalities. This paper reports a\nnovel transfer learning based approach for GDP prediction, which we have termed\nas Domain Adapted Transfer Learning for GDP Prediction. In the proposed\napproach per capita GDP of different nations is predicted using their CO2\nemissions via a model trained on the data of any developed or developing\neconomy. Results are comparatively presented considering three well-known\nregression methods such as Generalized Regression Neural Network, Extreme\nLearning Machine and Support Vector Regression. Then the proposed approach is\nused to reliably estimate the missing per capita GDP of some of the war-torn\nand isolated countries.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 15:30:03 GMT"}], "update_date": "2020-06-28", "authors_parsed": [["Kumar", "Sandeep", ""], ["Muhuri", "Pranab K.", ""]]}, {"id": "2005.02862", "submitter": "Azamat Sultanov", "authors": "Azamat Sultanov, Konstantin Kogos", "title": "Insider Threat Detection Based on Stress Recognition Using Keystroke\n  Dynamics", "comments": "27 pages, 6 figures, 5 tables, 2 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insider threat is one of the most pressing threats in the field of\ninformation security as it leads to huge financial losses by the companies.\nMost of the proposed methods for detecting this threat require expensive and\ninvasive equipment, which makes them difficult to use in practice. In this\npaper, we present a non-invasive method for detecting insider threat based on\nstress recognition using keystroke dynamics assuming that intruder experiences\nstress during making illegal actions, which affects the behavioral\ncharacteristics. Proposed method uses both supervised and unsupervised machine\nlearning algorithms. As the results show, stress can provide highly valuable\ninformation for insider threat detection.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 14:43:12 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Sultanov", "Azamat", ""], ["Kogos", "Konstantin", ""]]}, {"id": "2005.02870", "submitter": "Toshiaki Koike-Akino", "authors": "Toshiaki Koike-Akino and Ye Wang", "title": "Stochastic Bottleneck: Rateless Auto-Encoder for Flexible Dimensionality\n  Reduction", "comments": "14 pages, 12 figures, ISIT 2020 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new concept of rateless auto-encoders (RL-AEs) that enable a\nflexible latent dimensionality, which can be seamlessly adjusted for varying\ndistortion and dimensionality requirements. In the proposed RL-AEs, instead of\na deterministic bottleneck architecture, we use an over-complete representation\nthat is stochastically regularized with weighted dropouts, in a manner\nanalogous to sparse AE (SAE). Unlike SAEs, our RL-AEs employ monotonically\nincreasing dropout rates across the latent representation nodes such that the\nlatent variables become sorted by importance like in principal component\nanalysis (PCA). This is motivated by the rateless property of conventional PCA,\nwhere the least important principal components can be discarded to realize\nvariable rate dimensionality reduction that gracefully degrades the distortion.\nIn contrast, since the latent variables of conventional AEs are equally\nimportant for data reconstruction, they cannot be simply discarded to further\nreduce the dimensionality after the AE model is trained. Our proposed\nstochastic bottleneck framework enables seamless rate adaptation with high\nreconstruction performance, without requiring predetermined latent\ndimensionality at training. We experimentally demonstrate that the proposed\nRL-AEs can achieve variable dimensionality reduction while achieving low\ndistortion compared to conventional AEs.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 14:47:42 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Koike-Akino", "Toshiaki", ""], ["Wang", "Ye", ""]]}, {"id": "2005.02914", "submitter": "Xiangyang Li", "authors": "Xiangyang Li, Guo Pu, Keyu Ming, Pu Li, Jie Wang, Yuxuan Wang", "title": "Review of Text Style Transfer Based on Deep Learning", "comments": "There are some nonstandard problems in current papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text style transfer is a hot issue in recent natural language\nprocessing,which mainly studies the text to adapt to different specific\nsituations, audiences and purposes by making some changes. The style of the\ntext usually includes many aspects such as morphology, grammar, emotion,\ncomplexity, fluency, tense, tone and so on. In the traditional text style\ntransfer model, the text style is generally relied on by experts knowledge and\nhand-designed rules, but with the application of deep learning in the field of\nnatural language processing, the text style transfer method based on deep\nlearning Started to be heavily researched. In recent years, text style transfer\nis becoming a hot issue in natural language processing research. This article\nsummarizes the research on the text style transfer model based on deep learning\nin recent years, and summarizes, analyzes and compares the main research\ndirections and progress. In addition, the article also introduces public data\nsets and evaluation indicators commonly used for text style transfer. Finally,\nthe existing characteristics of the text style transfer model are summarized,\nand the future development trend of the text style transfer model based on deep\nlearning is analyzed and forecasted.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 15:35:53 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 02:59:13 GMT"}, {"version": "v3", "created": "Wed, 30 Dec 2020 03:04:59 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Li", "Xiangyang", ""], ["Pu", "Guo", ""], ["Ming", "Keyu", ""], ["Li", "Pu", ""], ["Wang", "Jie", ""], ["Wang", "Yuxuan", ""]]}, {"id": "2005.02921", "submitter": "Tom Michoel", "authors": "Muhammad Ammar Malik and Tom Michoel", "title": "Restricted maximum-likelihood method for learning latent variance\n  components in gene expression data with known and unknown confounders", "comments": "13 pages, 4 figures, plus 16 pages supplementary information", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG q-bio.GN q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear mixed modelling is a popular approach for detecting and correcting\nspurious sample correlations due to hidden confounders in genome-wide gene\nexpression data. In applications where some confounding factors are known,\nestimating simultaneously the contribution of known and latent variance\ncomponents in linear mixed models is a challenge that has so far relied on\nnumerical gradient-based optimizers to maximize the likelihood function. This\nis unsatisfactory because the resulting solution is poorly characterized and\nthe efficiency of the method may be suboptimal. Here we prove analytically that\nmaximum-likelihood latent variables can always be chosen orthogonal to the\nknown confounding factors, in other words, that maximum-likelihood latent\nvariables explain sample covariances not already explained by known factors.\nBased on this result we propose a restricted maximum-likelihood method which\nestimates the latent variables by maximizing the likelihood on the restricted\nsubspace orthogonal to the known confounding factors, and show that this\nreduces to probabilistic PCA on that subspace. The method then estimates the\nvariance-covariance parameters by maximizing the remaining terms in the\nlikelihood function given the latent variables, using a newly derived analytic\nsolution for this problem. Compared to gradient-based optimizers, our method\nattains equal or higher likelihood values, can be computed using standard\nmatrix operations, results in latent factors that don't overlap with any known\nfactors, and has a runtime reduced by several orders of magnitude. We\nanticipate that the restricted maximum-likelihood method will facilitate the\napplication of linear mixed modelling strategies for learning latent variance\ncomponents to much larger gene expression datasets than currently possible.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 15:53:17 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Malik", "Muhammad Ammar", ""], ["Michoel", "Tom", ""]]}, {"id": "2005.02929", "submitter": "Patricia Pauli", "authors": "Patricia Pauli, Anne Koch, Julian Berberich, Paul Kohler, Frank\n  Allg\\\"ower", "title": "Training robust neural networks using Lipschitz bounds", "comments": null, "journal-ref": null, "doi": "10.1109/LCSYS.2021.3050444", "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their susceptibility to adversarial perturbations, neural networks\n(NNs) are hardly used in safety-critical applications. One measure of\nrobustness to such perturbations in the input is the Lipschitz constant of the\ninput-output map defined by an NN. In this work, we propose a framework to\ntrain multi-layer NNs while at the same time encouraging robustness by keeping\ntheir Lipschitz constant small, thus addressing the robustness issue. More\nspecifically, we design an optimization scheme based on the Alternating\nDirection Method of Multipliers that minimizes not only the training loss of an\nNN but also its Lipschitz constant resulting in a semidefinite programming\nbased training procedure that promotes robustness. We design two versions of\nthis training procedure. The first one includes a regularizer that penalizes an\naccurate upper bound on the Lipschitz constant. The second one allows to\nenforce a desired Lipschitz bound on the NN at all times during training.\nFinally, we provide two examples to show that the proposed framework\nsuccessfully increases the robustness of NNs.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 16:07:46 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 09:07:11 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Pauli", "Patricia", ""], ["Koch", "Anne", ""], ["Berberich", "Julian", ""], ["Kohler", "Paul", ""], ["Allg\u00f6wer", "Frank", ""]]}, {"id": "2005.02934", "submitter": "Pierre-Alexandre Kamienny Mr", "authors": "Pierre-Alexandre Kamienny, Matteo Pirotta, Alessandro Lazaric,\n  Thibault Lavril, Nicolas Usunier, Ludovic Denoyer", "title": "Learning Adaptive Exploration Strategies in Dynamic Environments Through\n  Informed Policy Regularization", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning exploration-exploitation strategies that\neffectively adapt to dynamic environments, where the task may change over time.\nWhile RNN-based policies could in principle represent such strategies, in\npractice their training time is prohibitive and the learning process often\nconverges to poor solutions. In this paper, we consider the case where the\nagent has access to a description of the task (e.g., a task id or task\nparameters) at training time, but not at test time. We propose a novel\nalgorithm that regularizes the training of an RNN-based policy using informed\npolicies trained to maximize the reward in each task. This dramatically reduces\nthe sample complexity of training RNN-based policies, without losing their\nrepresentational power. As a result, our method learns exploration strategies\nthat efficiently balance between gathering information about the unknown and\nchanging task and maximizing the reward over time. We test the performance of\nour algorithm in a variety of environments where tasks may vary within each\nepisode.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 16:14:48 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Kamienny", "Pierre-Alexandre", ""], ["Pirotta", "Matteo", ""], ["Lazaric", "Alessandro", ""], ["Lavril", "Thibault", ""], ["Usunier", "Nicolas", ""], ["Denoyer", "Ludovic", ""]]}, {"id": "2005.02935", "submitter": "Semion Rozov", "authors": "Semion Rozov", "title": "Machine Learning and Deep Learning methods for predictive modelling from\n  Raman spectra in bioprocessing", "comments": "The submitted work is a Master Thesis written at the Swiss Federal\n  Institute of Technology in Zurich (ETH Zurich)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In chemical processing and bioprocessing, conventional online sensors are\nlimited to measure only basic process variables like pressure and temperature,\npH, dissolved O and CO$_2$ and viable cell density (VCD). The concentration of\nother chemical species is more difficult to measure, as it usually requires an\nat-line or off-line approach. Such approaches are invasive and slow compared to\non-line sensing. It is known that different molecules can be distinguished by\ntheir interaction with monochromatic light, producing different profiles for\nthe resulting Raman spectrum, depending on the concentration. Given the\navailability of reference measurements for the target variable, regression\nmethods can be used to model the relationship between the profile of the Raman\nspectra and the concentration of the analyte. This work focused on pretreatment\nmethods of Raman spectra for the facilitation of the regression task using\nMachine Learning and Deep Learning methods, as well as the development of new\nregression models based on these methods. In the majority of cases, this\nallowed to outperform conventional Raman models in terms of prediction error\nand prediction robustness.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 16:15:08 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Rozov", "Semion", ""]]}, {"id": "2005.02936", "submitter": "Ankita Shukla", "authors": "Ankita Shukla, Pavan Turaga and Saket Anand", "title": "GraCIAS: Grassmannian of Corrupted Images for Adversarial Security", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Input transformation based defense strategies fall short in defending against\nstrong adversarial attacks. Some successful defenses adopt approaches that\neither increase the randomness within the applied transformations, or make the\ndefense computationally intensive, making it substantially more challenging for\nthe attacker. However, it limits the applicability of such defenses as a\npre-processing step, similar to computationally heavy approaches that use\nretraining and network modifications to achieve robustness to perturbations. In\nthis work, we propose a defense strategy that applies random image corruptions\nto the input image alone, constructs a self-correlation based subspace followed\nby a projection operation to suppress the adversarial perturbation. Due to its\nsimplicity, the proposed defense is computationally efficient as compared to\nthe state-of-the-art, and yet can withstand huge perturbations. Further, we\ndevelop proximity relationships between the projection operator of a clean\nimage and of its adversarially perturbed version, via bounds relating geodesic\ndistance on the Grassmannian to matrix Frobenius norms. We empirically show\nthat our strategy is complementary to other weak defenses like JPEG compression\nand can be seamlessly integrated with them to create a stronger defense. We\npresent extensive experiments on the ImageNet dataset across four different\nmodels namely InceptionV3, ResNet50, VGG16 and MobileNet models with\nperturbation magnitude set to {\\epsilon} = 16. Unlike state-of-the-art\napproaches, even without any retraining, the proposed strategy achieves an\nabsolute improvement of ~ 4.5% in defense accuracy on ImageNet.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 16:17:12 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 15:11:24 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Shukla", "Ankita", ""], ["Turaga", "Pavan", ""], ["Anand", "Saket", ""]]}, {"id": "2005.02960", "submitter": "Colin White", "authors": "Colin White, Sam Nolen, Yash Savani", "title": "Exploring the Loss Landscape in Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) has seen a steep rise in interest over the\nlast few years. Many algorithms for NAS consist of searching through a space of\narchitectures by iteratively choosing an architecture, evaluating its\nperformance by training it, and using all prior evaluations to come up with the\nnext choice. The evaluation step is noisy - the final accuracy varies based on\nthe random initialization of the weights. Prior work has focused on devising\nnew search algorithms to handle this noise, rather than quantifying or\nunderstanding the level of noise in architecture evaluations. In this work, we\nshow that (1) the simplest hill-climbing algorithm is a powerful baseline for\nNAS, and (2), when the noise in popular NAS benchmark datasets is reduced to a\nminimum, hill-climbing to outperforms many popular state-of-the-art algorithms.\nWe further back up this observation by showing that the number of local minima\nis substantially reduced as the noise decreases, and by giving a theoretical\ncharacterization of the performance of local search in NAS. Based on our\nfindings, for NAS research we suggest (1) using local search as a baseline, and\n(2) denoising the training pipeline when possible.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 17:09:16 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 17:41:43 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 17:41:03 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["White", "Colin", ""], ["Nolen", "Sam", ""], ["Savani", "Yash", ""]]}, {"id": "2005.02971", "submitter": "Gianluigi Pillonetto Dr.", "authors": "Mauro Bisiacco and Gianluigi Pillonetto", "title": "Mathematical foundations of stable RKHSs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reproducing kernel Hilbert spaces (RKHSs) are key spaces for machine learning\nthat are becoming popular also for linear system identification. In particular,\nthe so-called stable RKHSs can be used to model absolutely summable impulse\nresponses. In combination e.g. with regularized least squares they can then be\nused to reconstruct dynamic systems from input-output data. In this paper we\nprovide new structural properties of stable RKHSs. The relation between stable\nkernels and other fundamental classes, like those containing absolutely\nsummable or finite-trace kernels, is elucidated. These insights are then\nbrought into the feature space context. First, it is proved that any stable\nkernel admits feature maps induced by a basis of orthogonal eigenvectors in l2.\nThe exact connection with classical system identification approaches that\nexploit such kind of functions to model impulse responses is also provided.\nThen, the necessary and sufficient stability condition for RKHSs designed by\nformulating kernel eigenvectors and eigenvalues is obtained. Overall, our new\nresults provide novel mathematical foundations of stable RKHSs with impact on\nstability tests, impulse responses modeling and computational efficiency of\nregularized schemes for linear system identification.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 17:25:23 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Bisiacco", "Mauro", ""], ["Pillonetto", "Gianluigi", ""]]}, {"id": "2005.02979", "submitter": "Anthony Corso", "authors": "Anthony Corso, Robert J. Moss, Mark Koren, Ritchie Lee, Mykel J.\n  Kochenderfer", "title": "A Survey of Algorithms for Black-Box Safety Validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous and semi-autonomous systems for safety-critical applications\nrequire rigorous testing before deployment. Due to the complexity of these\nsystems, formal verification may be impossible and real-world testing may be\ndangerous during development. Therefore, simulation-based techniques have been\ndeveloped that treat the system under test as a black box during testing.\nSafety validation tasks include finding disturbances to the system that cause\nit to fail (falsification), finding the most-likely failure, and estimating the\nprobability that the system fails. Motivated by the prevalence of\nsafety-critical artificial intelligence, this work provides a survey of\nstate-of-the-art safety validation techniques with a focus on applied\nalgorithms and their modifications for the safety validation problem. We\npresent and discuss algorithms in the domains of optimization, path planning,\nreinforcement learning, and importance sampling. Problem decomposition\ntechniques are presented to help scale algorithms to large state spaces, and a\nbrief overview of safety-critical applications is given, including autonomous\nvehicles and aircraft collision avoidance systems. Finally, we present a survey\nof existing academic and commercially available safety validation tools.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 17:31:51 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 16:18:28 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Corso", "Anthony", ""], ["Moss", "Robert J.", ""], ["Koren", "Mark", ""], ["Lee", "Ritchie", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2005.02987", "submitter": "Florian Jug", "authors": "Tim-Oliver Buchholz, Mangal Prakash, Alexander Krull, Florian Jug", "title": "DenoiSeg: Joint Denoising and Segmentation", "comments": "10 pages, 4 figures, 2 pages supplement (4 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microscopy image analysis often requires the segmentation of objects, but\ntraining data for this task is typically scarce and hard to obtain. Here we\npropose DenoiSeg, a new method that can be trained end-to-end on only a few\nannotated ground truth segmentations. We achieve this by extending Noise2Void,\na self-supervised denoising scheme that can be trained on noisy images alone,\nto also predict dense 3-class segmentations. The reason for the success of our\nmethod is that segmentation can profit from denoising, especially when\nperformed jointly within the same network. The network becomes a denoising\nexpert by seeing all available raw data, while co-learning to segment, even if\nonly a few segmentation labels are available. This hypothesis is additionally\nfueled by our observation that the best segmentation results on high quality\n(very low noise) raw data are obtained when moderate amounts of synthetic noise\nare added. This renders the denoising-task non-trivial and unleashes the\ndesired co-learning effect. We believe that DenoiSeg offers a viable way to\ncircumvent the tremendous hunger for high quality training data and effectively\nenables few-shot learning of dense segmentations.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 17:42:54 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 21:58:18 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Buchholz", "Tim-Oliver", ""], ["Prakash", "Mangal", ""], ["Krull", "Alexander", ""], ["Jug", "Florian", ""]]}, {"id": "2005.02990", "submitter": "Shubham Toshniwal", "authors": "Shubham Toshniwal, Allyson Ettinger, Kevin Gimpel, and Karen Livescu", "title": "PeTra: A Sparsely Supervised Memory Model for People Tracking", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose PeTra, a memory-augmented neural network designed to track\nentities in its memory slots. PeTra is trained using sparse annotation from the\nGAP pronoun resolution dataset and outperforms a prior memory model on the task\nwhile using a simpler architecture. We empirically compare key modeling\nchoices, finding that we can simplify several aspects of the design of the\nmemory module while retaining strong performance. To measure the people\ntracking capability of memory models, we (a) propose a new diagnostic\nevaluation based on counting the number of unique entities in text, and (b)\nconduct a small scale human evaluation to compare evidence of people tracking\nin the memory logs of PeTra relative to a previous approach. PeTra is highly\neffective in both evaluations, demonstrating its ability to track people in its\nmemory despite being trained with limited annotation.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 17:45:35 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Toshniwal", "Shubham", ""], ["Ettinger", "Allyson", ""], ["Gimpel", "Kevin", ""], ["Livescu", "Karen", ""]]}, {"id": "2005.03004", "submitter": "Wengong Jin", "authors": "Wengong Jin, Regina Barzilay, Tommi Jaakkola", "title": "Adaptive Invariance for Molecule Property Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective property prediction methods can help accelerate the search for\nCOVID-19 antivirals either through accurate in-silico screens or by effectively\nguiding on-going at-scale experimental efforts. However, existing prediction\ntools have limited ability to accommodate scarce or fragmented training data\ncurrently available. In this paper, we introduce a novel approach to learn\npredictors that can generalize or extrapolate beyond the heterogeneous data.\nOur method builds on and extends recently proposed invariant risk minimization,\nadaptively forcing the predictor to avoid nuisance variation. We achieve this\nby continually exercising and manipulating latent representations of molecules\nto highlight undesirable variation to the predictor. To test the method we use\na combination of three data sources: SARS-CoV-2 antiviral screening data,\nmolecular fragments that bind to SARS-CoV-2 main protease and large screening\ndata for SARS-CoV-1. Our predictor outperforms state-of-the-art transfer\nlearning methods by significant margin. We also report the top 20 predictions\nof our model on Broad drug repurposing hub.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 19:47:20 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Jin", "Wengong", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "2005.03059", "submitter": "Reza Rawassizadeh", "authors": "Tahereh Javaheri, Morteza Homayounfar, Zohreh Amoozgar, Reza Reiazi,\n  Fatemeh Homayounieh, Engy Abbas, Azadeh Laali, Amir Reza Radmard, Mohammad\n  Hadi Gharib, Seyed Ali Javad Mousavi, Omid Ghaemi, Rosa Babaei, Hadi Karimi\n  Mobin, Mehdi Hosseinzadeh, Rana Jahanban-Esfahlan, Khaled Seidi, Mannudeep K.\n  Kalra, Guanglan Zhang, L.T. Chitkushev, Benjamin Haibe-Kains, Reza\n  Malekzadeh, Reza Rawassizadeh", "title": "CovidCTNet: An Open-Source Deep Learning Approach to Identify Covid-19\n  Using CT Image", "comments": "5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Coronavirus disease 2019 (Covid-19) is highly contagious with limited\ntreatment options. Early and accurate diagnosis of Covid-19 is crucial in\nreducing the spread of the disease and its accompanied mortality. Currently,\ndetection by reverse transcriptase polymerase chain reaction (RT-PCR) is the\ngold standard of outpatient and inpatient detection of Covid-19. RT-PCR is a\nrapid method, however, its accuracy in detection is only ~70-75%. Another\napproved strategy is computed tomography (CT) imaging. CT imaging has a much\nhigher sensitivity of ~80-98%, but similar accuracy of 70%. To enhance the\naccuracy of CT imaging detection, we developed an open-source set of algorithms\ncalled CovidCTNet that successfully differentiates Covid-19 from\ncommunity-acquired pneumonia (CAP) and other lung diseases. CovidCTNet\nincreases the accuracy of CT imaging detection to 90% compared to radiologists\n(70%). The model is designed to work with heterogeneous and small sample sizes\nindependent of the CT imaging hardware. In order to facilitate the detection of\nCovid-19 globally and assist radiologists and physicians in the screening\nprocess, we are releasing all algorithms and parametric details in an\nopen-source format. Open-source sharing of our CovidCTNet enables developers to\nrapidly improve and optimize services, while preserving user privacy and data\nownership.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 18:16:59 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 20:05:09 GMT"}, {"version": "v3", "created": "Sat, 16 May 2020 00:47:50 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Javaheri", "Tahereh", ""], ["Homayounfar", "Morteza", ""], ["Amoozgar", "Zohreh", ""], ["Reiazi", "Reza", ""], ["Homayounieh", "Fatemeh", ""], ["Abbas", "Engy", ""], ["Laali", "Azadeh", ""], ["Radmard", "Amir Reza", ""], ["Gharib", "Mohammad Hadi", ""], ["Mousavi", "Seyed Ali Javad", ""], ["Ghaemi", "Omid", ""], ["Babaei", "Rosa", ""], ["Mobin", "Hadi Karimi", ""], ["Hosseinzadeh", "Mehdi", ""], ["Jahanban-Esfahlan", "Rana", ""], ["Seidi", "Khaled", ""], ["Kalra", "Mannudeep K.", ""], ["Zhang", "Guanglan", ""], ["Chitkushev", "L. T.", ""], ["Haibe-Kains", "Benjamin", ""], ["Malekzadeh", "Reza", ""], ["Rawassizadeh", "Reza", ""]]}, {"id": "2005.03063", "submitter": "Don Dini", "authors": "Don M. Dini", "title": "Learning, transferring, and recommending performance knowledge with\n  Monte Carlo tree search and neural networks", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making changes to a program to optimize its performance is an unscalable task\nthat relies entirely upon human intuition and experience. In addition,\ncompanies operating at large scale are at a stage where no single individual\nunderstands the code controlling its systems, and for this reason, making\nchanges to improve performance can become intractably difficult. In this paper,\na learning system is introduced that provides AI assistance for finding\nrecommended changes to a program. Specifically, it is shown how the evaluative\nfeedback, delayed-reward performance programming domain can be effectively\nformulated via the Monte Carlo tree search (MCTS) framework. It is then shown\nthat established methods from computational games for using learning to\nexpedite tree-search computation can be adapted to speed up computing\nrecommended program alterations. Estimates of expected utility from MCTS trees\nbuilt for previous problems are used to learn a sampling policy that remains\neffective across new problems, thus demonstrating transferability of\noptimization knowledge. This formulation is applied to the Apache Spark\ndistributed computing environment, and a preliminary result is observed that\nthe time required to build a search tree for finding recommendations is reduced\nby up to a factor of 10x.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 18:26:03 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Dini", "Don M.", ""]]}, {"id": "2005.03066", "submitter": "Danushka Bollegala", "authors": "Asir Saeed, Khai Mai, Pham Minh, Nguyen Tuan Duc, Danushka Bollegala", "title": "Weakly-Supervised Neural Response Selection from an Ensemble of\n  Task-Specialised Dialogue Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue engines that incorporate different types of agents to converse with\nhumans are popular.\n  However, conversations are dynamic in the sense that a selected response will\nchange the conversation on-the-fly, influencing the subsequent utterances in\nthe conversation, which makes the response selection a challenging problem.\n  We model the problem of selecting the best response from a set of responses\ngenerated by a heterogeneous set of dialogue agents by taking into account the\nconversational history, and propose a \\emph{Neural Response Selection} method.\n  The proposed method is trained to predict a coherent set of responses within\na single conversation, considering its own predictions via a curriculum\ntraining mechanism.\n  Our experimental results show that the proposed method can accurately select\nthe most appropriate responses, thereby significantly improving the user\nexperience in dialogue systems.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 18:40:26 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Saeed", "Asir", ""], ["Mai", "Khai", ""], ["Minh", "Pham", ""], ["Duc", "Nguyen Tuan", ""], ["Bollegala", "Danushka", ""]]}, {"id": "2005.03077", "submitter": "Shikhar Tuli", "authors": "Shikhar Tuli and Shreshth Tuli", "title": "AVAC: A Machine Learning based Adaptive RRAM Variability-Aware\n  Controller for Edge Devices", "comments": "Accepted at 2020 IEEE International Symposium on Circuits and Systems\n  (ISCAS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, the Edge Computing paradigm has gained significant popularity both\nin industry and academia. Researchers now increasingly target to improve\nperformance and reduce energy consumption of such devices. Some recent efforts\nfocus on using emerging RRAM technologies for improving energy efficiency,\nthanks to their no leakage property and high integration density. As the\ncomplexity and dynamism of applications supported by such devices escalate, it\nhas become difficult to maintain ideal performance by static RRAM controllers.\nMachine Learning provides a promising solution for this, and hence, this work\nfocuses on extending such controllers to allow dynamic parameter updates. In\nthis work we propose an Adaptive RRAM Variability-Aware Controller, AVAC, which\nperiodically updates Wait Buffer and batch sizes using on-the-fly learning\nmodels and gradient ascent. AVAC allows Edge devices to adapt to different\napplications and their stages, to improve computation performance and reduce\nenergy consumption. Simulations demonstrate that the proposed model can provide\nup to 29% increase in performance and 19% decrease in energy, compared to\nstatic controllers, using traces of real-life healthcare applications on a\nRaspberry-Pi based Edge deployment.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 19:06:51 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Tuli", "Shikhar", ""], ["Tuli", "Shreshth", ""]]}, {"id": "2005.03082", "submitter": "Catherine Ordun", "authors": "Catherine Ordun, Sanjay Purushotham, Edward Raff", "title": "Exploratory Analysis of Covid-19 Tweets using Topic Modeling, UMAP, and\n  DiGraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper illustrates five different techniques to assess the\ndistinctiveness of topics, key terms and features, speed of information\ndissemination, and network behaviors for Covid19 tweets. First, we use pattern\nmatching and second, topic modeling through Latent Dirichlet Allocation (LDA)\nto generate twenty different topics that discuss case spread, healthcare\nworkers, and personal protective equipment (PPE). One topic specific to U.S.\ncases would start to uptick immediately after live White House Coronavirus Task\nForce briefings, implying that many Twitter users are paying attention to\ngovernment announcements. We contribute machine learning methods not previously\nreported in the Covid19 Twitter literature. This includes our third method,\nUniform Manifold Approximation and Projection (UMAP), that identifies unique\nclustering-behavior of distinct topics to improve our understanding of\nimportant themes in the corpus and help assess the quality of generated topics.\nFourth, we calculated retweeting times to understand how fast information about\nCovid19 propagates on Twitter. Our analysis indicates that the median\nretweeting time of Covid19 for a sample corpus in March 2020 was 2.87 hours,\napproximately 50 minutes faster than repostings from Chinese social media about\nH7N9 in March 2013. Lastly, we sought to understand retweet cascades, by\nvisualizing the connections of users over time from fast to slow retweeting. As\nthe time to retweet increases, the density of connections also increase where\nin our sample, we found distinct users dominating the attention of Covid19\nretweeters. One of the simplest highlights of this analysis is that early-stage\ndescriptive methods like regular expressions can successfully identify\nhigh-level themes which were consistently verified as important through every\nsubsequent analysis.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 19:16:38 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Ordun", "Catherine", ""], ["Purushotham", "Sanjay", ""], ["Raff", "Edward", ""]]}, {"id": "2005.03117", "submitter": "Anil Ramakrishna", "authors": "Anil Ramakrishna, Rahul Gupta, Shrikanth Narayanan", "title": "Joint Multi-Dimensional Model for Global and Time-Series Annotations", "comments": "17 pages, 11 figures, currently in final rounds of review at IEEE\n  Transactions of Affective Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing is a popular approach to collect annotations for unlabeled data\ninstances. It involves collecting a large number of annotations from several,\noften naive untrained annotators for each data instance which are then combined\nto estimate the ground truth. Further, annotations for constructs such as\naffect are often multi-dimensional with annotators rating multiple dimensions,\nsuch as valence and arousal, for each instance. Most annotation fusion schemes\nhowever ignore this aspect and model each dimension separately. In this work we\naddress this by proposing a generative model for multi-dimensional annotation\nfusion, which models the dimensions jointly leading to more accurate ground\ntruth estimates. The model we propose is applicable to both global and time\nseries annotation fusion problems and treats the ground truth as a latent\nvariable distorted by the annotators. The model parameters are estimated using\nthe Expectation-Maximization algorithm and we evaluate its performance using\nsynthetic data and real emotion corpora as well as on an artificial task with\nhuman annotations\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 20:08:46 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Ramakrishna", "Anil", ""], ["Gupta", "Rahul", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "2005.03126", "submitter": "Imme Ebert-Uphoff", "authors": "Imme Ebert-Uphoff, Kyle A. Hilburn", "title": "Evaluation, Tuning and Interpretation of Neural Networks for\n  Meteorological Applications", "comments": "Submitted to Bulletin of the American Meteorological Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have opened up many new opportunities to utilize remotely\nsensed images in meteorology. Common applications include image classification,\ne.g., to determine whether an image contains a tropical cyclone, and image\ntranslation, e.g., to emulate radar imagery for satellites that only have\npassive channels. However, there are yet many open questions regarding the use\nof neural networks in meteorology, such as best practices for evaluation,\ntuning and interpretation. This article highlights several strategies and\npractical considerations for neural network development that have not yet\nreceived much attention in the meteorological community, such as the concept of\neffective receptive fields, underutilized meteorological performance measures,\nand methods for NN interpretation, such as synthetic experiments and layer-wise\nrelevance propagation. We also consider the process of neural network\ninterpretation as a whole, recognizing it as an iterative scientist-driven\ndiscovery process, and breaking it down into individual steps that researchers\ncan take. Finally, while most work on neural network interpretation in\nmeteorology has so far focused on networks for image classification tasks, we\nexpand the focus to also include networks for image translation.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 20:46:10 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Ebert-Uphoff", "Imme", ""], ["Hilburn", "Kyle A.", ""]]}, {"id": "2005.03135", "submitter": "Sean Peisert", "authors": "Bogdan Copos and Sean Peisert", "title": "Catch Me If You Can: Using Power Analysis to Identify HPC Activity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring users on large computing platforms such as high performance\ncomputing (HPC) and cloud computing systems is non-trivial. Utilities such as\nprocess viewers provide limited insight into what users are running, due to\ngranularity limitation, and other sources of data, such as system call tracing,\ncan impose significant operational overhead. However, despite technical and\nprocedural measures, instances of users abusing valuable HPC resources for\npersonal gains have been documented in the past \\cite{hpcbitmine}, and systems\nthat are open to large numbers of loosely-verified users from around the world\nare at risk of abuse. In this paper, we show how electrical power consumption\ndata from an HPC platform can be used to identify what programs are executed.\nThe intuition is that during execution, programs exhibit various patterns of\nCPU and memory activity. These patterns are reflected in the power consumption\nof the system and can be used to identify programs running. We test our\napproach on an HPC rack at Lawrence Berkeley National Laboratory using a\nvariety of scientific benchmarks. Among other interesting observations, our\nresults show that by monitoring the power consumption of an HPC rack, it is\npossible to identify if particular programs are running with precision up to\nand recall of 95\\% even in noisy scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 20:57:41 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Copos", "Bogdan", ""], ["Peisert", "Sean", ""]]}, {"id": "2005.03141", "submitter": "Zifan Wang", "authors": "Zifan Wang, Yilin Yang, Ankit Shrivastava, Varun Rawal and Zihao Ding", "title": "Towards Frequency-Based Explanation for Robust CNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current explanation techniques towards a transparent Convolutional Neural\nNetwork (CNN) mainly focuses on building connections between the\nhuman-understandable input features with models' prediction, overlooking an\nalternative representation of the input, the frequency components\ndecomposition. In this work, we present an analysis of the connection between\nthe distribution of frequency components in the input dataset and the reasoning\nprocess the model learns from the data. We further provide quantification\nanalysis about the contribution of different frequency components toward the\nmodel's prediction. We show that the vulnerability of the model against tiny\ndistortions is a result of the model is relying on the high-frequency features,\nthe target features of the adversarial (black and white-box) attackers, to make\nthe prediction. We further show that if the model develops stronger association\nbetween the low-frequency component with true labels, the model is more robust,\nwhich is the explanation of why adversarially trained models are more robust\nagainst tiny distortions.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 21:22:35 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Wang", "Zifan", ""], ["Yang", "Yilin", ""], ["Shrivastava", "Ankit", ""], ["Rawal", "Varun", ""], ["Ding", "Zihao", ""]]}, {"id": "2005.03157", "submitter": "Ana Ozaki", "authors": "Cosimo Persia and Ana Ozaki", "title": "On the Learnability of Possibilistic Theories", "comments": "IJCAI 2020 paper number 5540 (with a copyright notice to IJCAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate learnability of possibilistic theories from entailments in\nlight of Angluin's exact learning model. We consider cases in which only\nmembership, only equivalence, and both kinds of queries can be posed by the\nlearner. We then show that, for a large class of problems, polynomial time\nlearnability results for classical logic can be transferred to the respective\npossibilistic extension. In particular, it follows from our results that the\npossibilistic extension of propositional Horn theories is exactly learnable in\npolynomial time. As polynomial time learnability in the exact model is\ntransferable to the classical probably approximately correct model extended\nwith membership queries, our work also establishes such results in this model.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 22:08:32 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Persia", "Cosimo", ""], ["Ozaki", "Ana", ""]]}, {"id": "2005.03161", "submitter": "Sanjay Kariyappa", "authors": "Sanjay Kariyappa, Atul Prakash, Moinuddin Qureshi", "title": "MAZE: Data-Free Model Stealing Attack Using Zeroth-Order Gradient\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model Stealing (MS) attacks allow an adversary with black-box access to a\nMachine Learning model to replicate its functionality, compromising the\nconfidentiality of the model. Such attacks train a clone model by using the\npredictions of the target model for different inputs. The effectiveness of such\nattacks relies heavily on the availability of data necessary to query the\ntarget model. Existing attacks either assume partial access to the dataset of\nthe target model or availability of an alternate dataset with semantic\nsimilarities.\n  This paper proposes MAZE -- a data-free model stealing attack using\nzeroth-order gradient estimation. In contrast to prior works, MAZE does not\nrequire any data and instead creates synthetic data using a generative model.\nInspired by recent works in data-free Knowledge Distillation (KD), we train the\ngenerative model using a disagreement objective to produce inputs that maximize\ndisagreement between the clone and the target model. However, unlike the\nwhite-box setting of KD, where the gradient information is available, training\na generator for model stealing requires performing black-box optimization, as\nit involves accessing the target model under attack. MAZE relies on\nzeroth-order gradient estimation to perform this optimization and enables a\nhighly accurate MS attack.\n  Our evaluation with four datasets shows that MAZE provides a normalized clone\naccuracy in the range of 0.91x to 0.99x, and outperforms even the recent\nattacks that rely on partial data (JBDA, clone accuracy 0.13x to 0.69x) and\nsurrogate data (KnockoffNets, clone accuracy 0.52x to 0.97x). We also study an\nextension of MAZE in the partial-data setting and develop MAZE-PD, which\ngenerates synthetic data closer to the target distribution. MAZE-PD further\nimproves the clone accuracy (0.97x to 1.0x) and reduces the query required for\nthe attack by 2x-24x.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 22:26:18 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Kariyappa", "Sanjay", ""], ["Prakash", "Atul", ""], ["Qureshi", "Moinuddin", ""]]}, {"id": "2005.03174", "submitter": "Ryota Tanaka", "authors": "Ryota Tanaka, Akinobu Lee", "title": "Fact-based Dialogue Generation with Convergent and Divergent Decoding", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fact-based dialogue generation is a task of generating a human-like response\nbased on both dialogue context and factual texts. Various methods were proposed\nto focus on generating informative words that contain facts effectively.\nHowever, previous works implicitly assume a topic to be kept on a dialogue and\nusually converse passively, therefore the systems have a difficulty to generate\ndiverse responses that provide meaningful information proactively. This paper\nproposes an end-to-end fact-based dialogue system augmented with the ability of\nconvergent and divergent thinking over both context and facts, which can\nconverse about the current topic or introduce a new topic. Specifically, our\nmodel incorporates a novel convergent and divergent decoding that can generate\ninformative and diverse responses considering not only given inputs (context\nand facts) but also inputs-related topics. Both automatic and human evaluation\nresults on DSTC7 dataset show that our model significantly outperforms\nstate-of-the-art baselines, indicating that our model can generate more\nappropriate, informative, and diverse responses.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 23:49:35 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 00:43:36 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Tanaka", "Ryota", ""], ["Lee", "Akinobu", ""]]}, {"id": "2005.03180", "submitter": "Nikola Kovachki", "authors": "Kaushik Bhattacharya, Bamdad Hosseini, Nikola B. Kovachki, Andrew M.\n  Stuart", "title": "Model Reduction and Neural Networks for Parametric PDEs", "comments": "39 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a general framework for data-driven approximation of input-output\nmaps between infinite-dimensional spaces. The proposed approach is motivated by\nthe recent successes of neural networks and deep learning, in combination with\nideas from model reduction. This combination results in a neural network\napproximation which, in principle, is defined on infinite-dimensional spaces\nand, in practice, is robust to the dimension of finite-dimensional\napproximations of these spaces required for computation. For a class of\ninput-output maps, and suitably chosen probability measures on the inputs, we\nprove convergence of the proposed approximation methodology. We also include\nnumerical experiments which demonstrate the effectiveness of the method,\nshowing convergence and robustness of the approximation scheme with respect to\nthe size of the discretization, and compare it with existing algorithms from\nthe literature; our examples include the mapping from coefficient to solution\nin a divergence form elliptic partial differential equation (PDE) problem, and\nthe solution operator for viscous Burgers' equation.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 00:09:27 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 18:45:06 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Bhattacharya", "Kaushik", ""], ["Hosseini", "Bamdad", ""], ["Kovachki", "Nikola B.", ""], ["Stuart", "Andrew M.", ""]]}, {"id": "2005.03185", "submitter": "Micha{\\l} Derezi\\'nski", "authors": "Micha{\\l} Derezi\\'nski and Michael W. Mahoney", "title": "Determinantal Point Processes in Randomized Numerical Linear Algebra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized Numerical Linear Algebra (RandNLA) uses randomness to develop\nimproved algorithms for matrix problems that arise in scientific computing,\ndata science, machine learning, etc. Determinantal Point Processes (DPPs), a\nseemingly unrelated topic in pure and applied mathematics, is a class of\nstochastic point processes with probability distribution characterized by\nsub-determinants of a kernel matrix. Recent work has uncovered deep and\nfruitful connections between DPPs and RandNLA which lead to new guarantees and\nimproved algorithms that are of interest to both areas. We provide an overview\nof this exciting new line of research, including brief introductions to RandNLA\nand DPPs, as well as applications of DPPs to classical linear algebra tasks\nsuch as least squares regression, low-rank approximation and the Nystr\\\"om\nmethod. For example, random sampling with a DPP leads to new kinds of unbiased\nestimators for least squares, enabling more refined statistical and inferential\nunderstanding of these algorithms; a DPP is, in some sense, an optimal\nrandomized algorithm for the Nystr\\\"om method; and a RandNLA technique called\nleverage score sampling can be derived as the marginal distribution of a DPP.\nWe also discuss recent algorithmic developments, illustrating that, while not\nquite as efficient as standard RandNLA techniques, DPP-based algorithms are\nonly moderately more expensive.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 00:39:52 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Derezi\u0144ski", "Micha\u0142", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2005.03188", "submitter": "Jeongmin Chae", "authors": "Songnam Hong and Jeongmin Chae", "title": "Active Learning with Multiple Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online multiple kernel learning (OMKL) has provided an attractive performance\nin nonlinear function learning tasks. Leveraging a random feature\napproximation, the major drawback of OMKL, known as the curse of\ndimensionality, has been recently alleviated. In this paper, we introduce a new\nresearch problem, termed (stream-based) active multiple kernel learning (AMKL),\nin which a learner is allowed to label selected data from an oracle according\nto a selection criterion. This is necessary in many real-world applications as\nacquiring true labels is costly or time-consuming. We prove that AMKL achieves\nan optimal sublinear regret, implying that the proposed selection criterion\nindeed avoids unuseful label-requests. Furthermore, we propose AMKL with an\nadaptive kernel selection (AMKL-AKS) in which irrelevant kernels can be\nexcluded from a kernel dictionary 'on the fly'. This approach can improve the\nefficiency of active learning as well as the accuracy of a function\napproximation. Via numerical tests with various real datasets, it is\ndemonstrated that AMKL-AKS yields a similar or better performance than the\nbest-known OMKL, with a smaller number of labeled data.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 00:48:13 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Hong", "Songnam", ""], ["Chae", "Jeongmin", ""]]}, {"id": "2005.03191", "submitter": "Zhengdong Zhang", "authors": "Wei Han, Zhengdong Zhang, Yu Zhang, Jiahui Yu, Chung-Cheng Chiu, James\n  Qin, Anmol Gulati, Ruoming Pang, Yonghui Wu", "title": "ContextNet: Improving Convolutional Neural Networks for Automatic Speech\n  Recognition with Global Context", "comments": "Submitted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNN) have shown promising results for\nend-to-end speech recognition, albeit still behind other state-of-the-art\nmethods in performance. In this paper, we study how to bridge this gap and go\nbeyond with a novel CNN-RNN-transducer architecture, which we call ContextNet.\nContextNet features a fully convolutional encoder that incorporates global\ncontext information into convolution layers by adding squeeze-and-excitation\nmodules. In addition, we propose a simple scaling method that scales the widths\nof ContextNet that achieves good trade-off between computation and accuracy. We\ndemonstrate that on the widely used LibriSpeech benchmark, ContextNet achieves\na word error rate (WER) of 2.1%/4.6% without external language model (LM),\n1.9%/4.1% with LM and 2.9%/7.0% with only 10M parameters on the clean/noisy\nLibriSpeech test sets. This compares to the previous best published system of\n2.0%/4.6% with LM and 3.9%/11.3% with 20M parameters. The superiority of the\nproposed ContextNet model is also verified on a much larger internal dataset.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 01:03:18 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 01:45:13 GMT"}, {"version": "v3", "created": "Sat, 16 May 2020 00:49:21 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Han", "Wei", ""], ["Zhang", "Zhengdong", ""], ["Zhang", "Yu", ""], ["Yu", "Jiahui", ""], ["Chiu", "Chung-Cheng", ""], ["Qin", "James", ""], ["Gulati", "Anmol", ""], ["Pang", "Ruoming", ""], ["Wu", "Yonghui", ""]]}, {"id": "2005.03197", "submitter": "Anshuman Chhabra", "authors": "Anshuman Chhabra, Vidushi Vashishth, Prasant Mohapatra", "title": "Fair Algorithms for Hierarchical Agglomerative Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Agglomerative Clustering (HAC) algorithms are extensively\nutilized in modern data science, and seek to partition the dataset into\nclusters while generating a hierarchical relationship between the data samples.\nHAC algorithms are employed in many applications, such as biology, natural\nlanguage processing, and recommender systems. Thus, it is imperative to ensure\nthat these algorithms are fair -- even if the dataset contains biases against\ncertain protected groups, the cluster outputs generated should not discriminate\nagainst samples from any of these groups. However, recent work in clustering\nfairness has mostly focused on center-based clustering algorithms, such as\nk-median and k-means clustering. In this paper, we propose fair algorithms for\nperforming HAC that enforce fairness constraints 1) irrespective of the\ndistance linkage criteria used, 2) generalize to any natural measures of\nclustering fairness for HAC, 3) work for multiple protected groups, and 4) have\ncompetitive running times to vanilla HAC. Through extensive experiments on\nmultiple real-world UCI datasets, we show that our proposed algorithm finds\nfairer clusterings compared to vanilla HAC as well as other state-of-the-art\nfair clustering approaches.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 01:41:56 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 01:36:37 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 08:49:39 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Chhabra", "Anshuman", ""], ["Vashishth", "Vidushi", ""], ["Mohapatra", "Prasant", ""]]}, {"id": "2005.03213", "submitter": "Kai Zhou", "authors": "Kai Zhou, Jiong Tang", "title": "Efficient Characterization of Dynamic Response Variation Using\n  Multi-Fidelity Data Fusion through Composite Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainties in a structure is inevitable, which generally lead to variation\nin dynamic response predictions. For a complex structure, brute force Monte\nCarlo simulation for response variation analysis is infeasible since one single\nrun may already be computationally costly. Data driven meta-modeling approaches\nhave thus been explored to facilitate efficient emulation and statistical\ninference. The performance of a meta-model hinges upon both the quality and\nquantity of training dataset. In actual practice, however, high-fidelity data\nacquired from high-dimensional finite element simulation or experiment are\ngenerally scarce, which poses significant challenge to meta-model\nestablishment. In this research, we take advantage of the multi-level response\nprediction opportunity in structural dynamic analysis, i.e., acquiring rapidly\na large amount of low-fidelity data from reduced-order modeling, and acquiring\naccurately a small amount of high-fidelity data from full-scale finite element\nanalysis. Specifically, we formulate a composite neural network fusion approach\nthat can fully utilize the multi-level, heterogeneous datasets obtained. It\nimplicitly identifies the correlation of the low- and high-fidelity datasets,\nwhich yields improved accuracy when compared with the state-of-the-art.\nComprehensive investigations using frequency response variation\ncharacterization as case example are carried out to demonstrate the\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 02:44:03 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Zhou", "Kai", ""], ["Tang", "Jiong", ""]]}, {"id": "2005.03215", "submitter": "Shaojin Ding", "authors": "Shaojin Ding, Tianlong Chen, Xinyu Gong, Weiwei Zha, Zhangyang Wang", "title": "AutoSpeech: Neural Architecture Search for Speaker Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker recognition systems based on Convolutional Neural Networks (CNNs) are\noften built with off-the-shelf backbones such as VGG-Net or ResNet. However,\nthese backbones were originally proposed for image classification, and\ntherefore may not be naturally fit for speaker recognition. Due to the\nprohibitive complexity of manually exploring the design space, we propose the\nfirst neural architecture search approach approach for the speaker recognition\ntasks, named as AutoSpeech. Our algorithm first identifies the optimal\noperation combination in a neural cell and then derives a CNN model by stacking\nthe neural cell for multiple times. The final speaker recognition model can be\nobtained by training the derived CNN model through the standard scheme. To\nevaluate the proposed approach, we conduct experiments on both speaker\nidentification and speaker verification tasks using the VoxCeleb1 dataset.\nResults demonstrate that the derived CNN architectures from the proposed\napproach significantly outperform current speaker recognition systems based on\nVGG-M, ResNet-18, and ResNet-34 back-bones, while enjoying lower model\ncomplexity.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 02:53:47 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 15:53:27 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Ding", "Shaojin", ""], ["Chen", "Tianlong", ""], ["Gong", "Xinyu", ""], ["Zha", "Weiwei", ""], ["Wang", "Zhangyang", ""]]}, {"id": "2005.03220", "submitter": "Ariel Rokem", "authors": "Ariel Rokem, Kendrick Kay", "title": "Fractional ridge regression: a fast, interpretable reparameterization of\n  ridge regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ridge regression (RR) is a regularization technique that penalizes the\nL2-norm of the coefficients in linear regression. One of the challenges of\nusing RR is the need to set a hyperparameter ($\\alpha$) that controls the\namount of regularization. Cross-validation is typically used to select the best\n$\\alpha$ from a set of candidates. However, efficient and appropriate selection\nof $\\alpha$ can be challenging, particularly where large amounts of data are\nanalyzed. Because the selected $\\alpha$ depends on the scale of the data and\npredictors, it is not straightforwardly interpretable. Here, we propose to\nreparameterize RR in terms of the ratio $\\gamma$ between the L2-norms of the\nregularized and unregularized coefficients. This approach, called fractional RR\n(FRR), has several benefits: the solutions obtained for different $\\gamma$ are\nguaranteed to vary, guarding against wasted calculations, and automatically\nspan the relevant range of regularization, avoiding the need for arduous manual\nexploration. We provide an algorithm to solve FRR, as well as open-source\nsoftware implementations in Python and MATLAB\n(https://github.com/nrdg/fracridge). We show that the proposed method is fast\nand scalable for large-scale data problems, and delivers results that are\nstraightforward to interpret and compare across models and datasets.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 03:12:23 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Rokem", "Ariel", ""], ["Kay", "Kendrick", ""]]}, {"id": "2005.03225", "submitter": "Ziyuan Zhao", "authors": "Ziyuan Zhao, Xiaoyan Yang, Bharadwaj Veeravalli, Zeng Zeng", "title": "Deeply Supervised Active Learning for Finger Bones Segmentation", "comments": "Accepted version to be published in the 42nd IEEE Annual\n  International Conference of the IEEE Engineering in Medicine and Biology\n  Society, EMBC 2020, Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation is a prerequisite yet challenging task for medical image\nanalysis. In this paper, we introduce a novel deeply supervised active learning\napproach for finger bones segmentation. The proposed architecture is fine-tuned\nin an iterative and incremental learning manner. In each step, the deep\nsupervision mechanism guides the learning process of hidden layers and selects\nsamples to be labeled. Extensive experiments demonstrated that our method\nachieves competitive segmentation results using less labeled samples as\ncompared with full annotation.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 03:27:40 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Zhao", "Ziyuan", ""], ["Yang", "Xiaoyan", ""], ["Veeravalli", "Bharadwaj", ""], ["Zeng", "Zeng", ""]]}, {"id": "2005.03227", "submitter": "Feng Shi", "authors": "Hengyuan Kang, Liming Xia, Fuhua Yan, Zhibin Wan, Feng Shi, Huan Yuan,\n  Huiting Jiang, Dijia Wu, He Sui, Changqing Zhang, and Dinggang Shen", "title": "Diagnosis of Coronavirus Disease 2019 (COVID-19) with Structured Latent\n  Multi-View Representation Learning", "comments": null, "journal-ref": "IEEE Transactions on Medical Imaging (2020)", "doi": "10.1109/TMI.2020.2992546", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the outbreak of Coronavirus Disease 2019 (COVID-19) has spread\nrapidly across the world. Due to the large number of affected patients and\nheavy labor for doctors, computer-aided diagnosis with machine learning\nalgorithm is urgently needed, and could largely reduce the efforts of\nclinicians and accelerate the diagnosis process. Chest computed tomography (CT)\nhas been recognized as an informative tool for diagnosis of the disease. In\nthis study, we propose to conduct the diagnosis of COVID-19 with a series of\nfeatures extracted from CT images. To fully explore multiple features\ndescribing CT images from different views, a unified latent representation is\nlearned which can completely encode information from different aspects of\nfeatures and is endowed with promising class structure for separability.\nSpecifically, the completeness is guaranteed with a group of backward neural\nnetworks (each for one type of features), while by using class labels the\nrepresentation is enforced to be compact within COVID-19/community-acquired\npneumonia (CAP) and also a large margin is guaranteed between different types\nof pneumonia. In this way, our model can well avoid overfitting compared to the\ncase of directly projecting highdimensional features into classes. Extensive\nexperimental results show that the proposed method outperforms all comparison\nmethods, and rather stable performances are observed when varying the numbers\nof training data.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 15:19:15 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Kang", "Hengyuan", ""], ["Xia", "Liming", ""], ["Yan", "Fuhua", ""], ["Wan", "Zhibin", ""], ["Shi", "Feng", ""], ["Yuan", "Huan", ""], ["Jiang", "Huiting", ""], ["Wu", "Dijia", ""], ["Sui", "He", ""], ["Zhang", "Changqing", ""], ["Shen", "Dinggang", ""]]}, {"id": "2005.03228", "submitter": "Chenhao Xie", "authors": "Chenhao Xie, Qiao Cheng, Jiaqing Liang, Lihan Chen, Yanghua Xiao", "title": "Collective Loss Function for Positive and Unlabeled Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People learn to discriminate between classes without explicit exposure to\nnegative examples. On the contrary, traditional machine learning algorithms\noften rely on negative examples, otherwise the model would be prone to collapse\nand always-true predictions. Therefore, it is crucial to design the learning\nobjective which leads the model to converge and to perform predictions\nunbiasedly without explicit negative signals. In this paper, we propose a\nCollectively loss function to learn from only Positive and Unlabeled data\n(cPU). We theoretically elicit the loss function from the setting of PU\nlearning. We perform intensive experiments on the benchmark and real-world\ndatasets. The results show that cPU consistently outperforms the current\nstate-of-the-art PU learning methods.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 03:30:22 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Xie", "Chenhao", ""], ["Cheng", "Qiao", ""], ["Liang", "Jiaqing", ""], ["Chen", "Lihan", ""], ["Xiao", "Yanghua", ""]]}, {"id": "2005.03229", "submitter": "Pengfei Wei Dr.", "authors": "Pengfei Wei, Yiping Ke, Xinghua Qu, Tze-Yun Leong", "title": "Subdomain Adaptation with Manifolds Discrepancy Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing domain divergence is a key step in transfer learning problems.\nExisting works focus on the minimization of global domain divergence. However,\ntwo domains may consist of several shared subdomains, and differ from each\nother in each subdomain. In this paper, we take the local divergence of\nsubdomains into account in transfer. Specifically, we propose to use\nlow-dimensional manifold to represent subdomain, and align the local data\ndistribution discrepancy in each manifold across domains. A Manifold Maximum\nMean Discrepancy (M3D) is developed to measure the local distribution\ndiscrepancy in each manifold. We then propose a general framework, called\nTransfer with Manifolds Discrepancy Alignment (TMDA), to couple the discovery\nof data manifolds with the minimization of M3D. We instantiate TMDA in the\nsubspace learning case considering both the linear and nonlinear mappings. We\nalso instantiate TMDA in the deep learning framework. Extensive experimental\nstudies demonstrate that TMDA is a promising method for various transfer\nlearning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 04:18:47 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Wei", "Pengfei", ""], ["Ke", "Yiping", ""], ["Qu", "Xinghua", ""], ["Leong", "Tze-Yun", ""]]}, {"id": "2005.03230", "submitter": "Matin Hosseini", "authors": "Matin Hosseini, Anthony Maida", "title": "Hierarchical Predictive Coding Models in a Deep-Learning Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian predictive coding is a putative neuromorphic method for acquiring\nhigher-level neural representations to account for sensory input. Although\noriginating in the neuroscience community, there are also efforts in the\nmachine learning community to study these models. This paper reviews some of\nthe more well known models. Our review analyzes module connectivity and\npatterns of information transfer, seeking to find general principles used\nacross the models. We also survey some recent attempts to cast these models\nwithin a deep learning framework. A defining feature of Bayesian predictive\ncoding is that it uses top-down, reconstructive mechanisms to predict incoming\nsensory inputs or their lower-level representations. Discrepancies between the\npredicted and the actual inputs, known as prediction errors, then give rise to\nfuture learning that refines and improves the predictive accuracy of learned\nhigher-level representations. Predictive coding models intended to describe\ncomputations in the neocortex emerged prior to the development of deep learning\nand used a communication structure between modules that we name the Rao-Ballard\nprotocol. This protocol was derived from a Bayesian generative model with some\nrather strong statistical assumptions. The RB protocol provides a rubric to\nassess the fidelity of deep learning models that claim to implement predictive\ncoding.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 03:39:57 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 00:42:39 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Hosseini", "Matin", ""], ["Maida", "Anthony", ""]]}, {"id": "2005.03231", "submitter": "Qiang Yu", "authors": "Qiang Yu, Chenxiang Ma, Shiming Song, Gaoyan Zhang, Jianwu Dang, Kay\n  Chen Tan", "title": "Constructing Accurate and Efficient Deep Spiking Neural Networks with\n  Double-threshold and Augmented Schemes", "comments": "13 pages", "journal-ref": null, "doi": "10.1109/TNNLS.2020.3043415", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) are considered as a potential candidate to\novercome current challenges such as the high-power consumption encountered by\nartificial neural networks (ANNs), however there is still a gap between them\nwith respect to the recognition accuracy on practical tasks. A conversion\nstrategy was thus introduced recently to bridge this gap by mapping a trained\nANN to an SNN. However, it is still unclear that to what extent this obtained\nSNN can benefit both the accuracy advantage from ANN and high efficiency from\nthe spike-based paradigm of computation. In this paper, we propose two new\nconversion methods, namely TerMapping and AugMapping. The TerMapping is a\nstraightforward extension of a typical threshold-balancing method with a\ndouble-threshold scheme, while the AugMapping additionally incorporates a new\nscheme of augmented spike that employs a spike coefficient to carry the number\nof typical all-or-nothing spikes occurring at a time step. We examine the\nperformance of our methods based on MNIST, Fashion-MNIST and CIFAR10 datasets.\nThe results show that the proposed double-threshold scheme can effectively\nimprove accuracies of the converted SNNs. More importantly, the proposed\nAugMapping is more advantageous for constructing accurate, fast and efficient\ndeep SNNs as compared to other state-of-the-art approaches. Our study therefore\nprovides new approaches for further integration of advanced techniques in ANNs\nto improve the performance of SNNs, which could be of great merit to applied\ndevelopments with spike-based neuromorphic computing.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 06:44:05 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Yu", "Qiang", ""], ["Ma", "Chenxiang", ""], ["Song", "Shiming", ""], ["Zhang", "Gaoyan", ""], ["Dang", "Jianwu", ""], ["Tan", "Kay Chen", ""]]}, {"id": "2005.03232", "submitter": "Ziyuan Zhao", "authors": "Peisheng Qian, Ziyuan Zhao, Haobing Liu, Yingcai Wang, Yu Peng, Sheng\n  Hu, Jing Zhang, Yue Deng, Zeng Zeng", "title": "Multi-Target Deep Learning for Algal Detection and Classification", "comments": "Accepted version to be published in the 42nd IEEE Annual\n  International Conference of the IEEE Engineering in Medicine and Biology\n  Society, EMBC 2020, Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Water quality has a direct impact on industry, agriculture, and public\nhealth. Algae species are common indicators of water quality. It is because\nalgal communities are sensitive to changes in their habitats, giving valuable\nknowledge on variations in water quality. However, water quality analysis\nrequires professional inspection of algal detection and classification under\nmicroscopes, which is very time-consuming and tedious. In this paper, we\npropose a novel multi-target deep learning framework for algal detection and\nclassification. Extensive experiments were carried out on a large-scale colored\nmicroscopic algal dataset. Experimental results demonstrate that the proposed\nmethod leads to the promising performance on algal detection, class\nidentification and genus identification.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 03:40:29 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Qian", "Peisheng", ""], ["Zhao", "Ziyuan", ""], ["Liu", "Haobing", ""], ["Wang", "Yingcai", ""], ["Peng", "Yu", ""], ["Hu", "Sheng", ""], ["Zhang", "Jing", ""], ["Deng", "Yue", ""], ["Zeng", "Zeng", ""]]}, {"id": "2005.03233", "submitter": "Sebastian Risi", "authors": "Djordje Grbic and Sebastian Risi", "title": "Safe Reinforcement Learning through Meta-learned Instincts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important goal in reinforcement learning is to create agents that can\nquickly adapt to new goals while avoiding situations that might cause damage to\nthemselves or their environments. One way agents learn is through exploration\nmechanisms, which are needed to discover new policies. However, in deep\nreinforcement learning, exploration is normally done by injecting noise in the\naction space. While performing well in many domains, this setup has the\ninherent risk that the noisy actions performed by the agent lead to unsafe\nstates in the environment. Here we introduce a novel approach called\nMeta-Learned Instinctual Networks (MLIN) that allows agents to safely learn\nduring their lifetime while avoiding potentially hazardous states. At the core\nof the approach is a plastic network trained through reinforcement learning and\nan evolved \"instinctual\" network, which does not change during the agent's\nlifetime but can modulate the noisy output of the plastic network. We test our\nidea on a simple 2D navigation task with no-go zones, in which the agent has to\nlearn to approach new targets during deployment. MLIN outperforms standard\nmeta-trained networks and allows agents to learn to navigate to new targets\nwithout colliding with any of the no-go zones. These results suggest that\nmeta-learning augmented with an instinctual network is a promising new approach\nfor safe AI, which may enable progress in this area on a variety of different\ndomains.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 17:31:53 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Grbic", "Djordje", ""], ["Risi", "Sebastian", ""]]}, {"id": "2005.03240", "submitter": "Bin Liu", "authors": "Bin Liu, Konstantinos Blekas, and Grigorios Tsoumakas", "title": "Multi-Label Sampling based on Local Label Imbalance", "comments": "arXiv admin note: text overlap with arXiv:1905.00609", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class imbalance is an inherent characteristic of multi-label data that\nhinders most multi-label learning methods. One efficient and flexible strategy\nto deal with this problem is to employ sampling techniques before training a\nmulti-label learning model. Although existing multi-label sampling approaches\nalleviate the global imbalance of multi-label datasets, it is actually the\nimbalance level within the local neighbourhood of minority class examples that\nplays a key role in performance degradation. To address this issue, we propose\na novel measure to assess the local label imbalance of multi-label datasets, as\nwell as two multi-label sampling approaches based on the local label imbalance,\nnamely MLSOL and MLUL. By considering all informative labels, MLSOL creates\nmore diverse and better labeled synthetic instances for difficult examples,\nwhile MLUL eliminates instances that are harmful to their local region.\nExperimental results on 13 multi-label datasets demonstrate the effectiveness\nof the proposed measure and sampling approaches for a variety of evaluation\nmetrics, particularly in the case of an ensemble of classifiers trained on\nrepeated samples of the original data.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 04:14:23 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 10:53:43 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Liu", "Bin", ""], ["Blekas", "Konstantinos", ""], ["Tsoumakas", "Grigorios", ""]]}, {"id": "2005.03247", "submitter": "Vivek Dixit", "authors": "Vivek Dixit, Raja Selvarajan, Muhammad A. Alam, Travis S. Humble, and\n  Sabre Kais", "title": "Training and Classification using a Restricted Boltzmann Machine on the\n  D-Wave 2000Q", "comments": "Front. Phys., 29 June 2021", "journal-ref": null, "doi": "10.3389/fphy.2021.589626", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann Machine (RBM) is an energy based, undirected graphical\nmodel. It is commonly used for unsupervised and supervised machine learning.\nTypically, RBM is trained using contrastive divergence (CD). However, training\nwith CD is slow and does not estimate exact gradient of log-likelihood cost\nfunction. In this work, the model expectation of gradient learning for RBM has\nbeen calculated using a quantum annealer (D-Wave 2000Q), which is much faster\nthan Markov chain Monte Carlo (MCMC) used in CD. Training and classification\nresults are compared with CD. The classification accuracy results indicate\nsimilar performance of both methods. Image reconstruction as well as\nlog-likelihood calculations are used to compare the performance of quantum and\nclassical algorithms for RBM training. It is shown that the samples obtained\nfrom quantum annealer can be used to train a RBM on a 64-bit `bars and stripes'\ndata set with classification performance similar to a RBM trained with CD.\nThough training based on CD showed improved learning performance, training\nusing a quantum annealer eliminates computationally expensive MCMC steps of CD.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 04:43:04 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Dixit", "Vivek", ""], ["Selvarajan", "Raja", ""], ["Alam", "Muhammad A.", ""], ["Humble", "Travis S.", ""], ["Kais", "Sabre", ""]]}, {"id": "2005.03253", "submitter": "Illia Horenko Dr.", "authors": "Horenko Illia and Marchenko Ganna and Gagliardini Patrick", "title": "On a computationally-scalable sparse formulation of the multidimensional\n  and non-stationary maximum entropy principle", "comments": null, "journal-ref": "Commun. Appl. Math. Comput. Sci. 15 (2020) 15-32", "doi": "10.2140/camcos.2020.15.15", "report-no": null, "categories": "stat.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven modelling and computational predictions based on maximum entropy\nprinciple (MaxEnt-principle) aim at finding as-simple-as-possible - but not\nsimpler then necessary - models that allow to avoid the data overfitting\nproblem. We derive a multivariate non-parametric and non-stationary formulation\nof the MaxEnt-principle and show that its solution can be approximated through\na numerical maximisation of the sparse constrained optimization problem with\nregularization. Application of the resulting algorithm to popular financial\nbenchmarks reveals memoryless models allowing for simple and qualitative\ndescriptions of the major stock market indexes data. We compare the obtained\nMaxEnt-models to the heteroschedastic models from the computational\neconometrics (GARCH, GARCH-GJR, MS-GARCH, GARCH-PML4) in terms of the model\nfit, complexity and prediction quality. We compare the resulting model\nlog-likelihoods, the values of the Bayesian Information Criterion, posterior\nmodel probabilities, the quality of the data autocorrelation function fits as\nwell as the Value-at-Risk prediction quality. We show that all of the\nconsidered seven major financial benchmark time series (DJI, SPX, FTSE, STOXX,\nSMI, HSI and N225) are better described by conditionally memoryless\nMaxEnt-models with nonstationary regime-switching than by the common\neconometric models with finite memory. This analysis also reveals a sparse\nnetwork of statistically-significant temporal relations for the positive and\nnegative latent variance changes among different markets. The code is provided\nfor open access.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 05:22:46 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Illia", "Horenko", ""], ["Ganna", "Marchenko", ""], ["Patrick", "Gagliardini", ""]]}, {"id": "2005.03264", "submitter": "Liang Sun", "authors": "Liang Sun, Zhanhao Mo, Fuhua Yan, Liming Xia, Fei Shan, Zhongxiang\n  Ding, Wei Shao, Feng Shi, Huan Yuan, Huiting Jiang, Dijia Wu, Ying Wei,\n  Yaozong Gao, Wanchun Gao, He Sui, Daoqiang Zhang, Dinggang Shen", "title": "Adaptive Feature Selection Guided Deep Forest for COVID-19\n  Classification with Chest CT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chest computed tomography (CT) becomes an effective tool to assist the\ndiagnosis of coronavirus disease-19 (COVID-19). Due to the outbreak of COVID-19\nworldwide, using the computed-aided diagnosis technique for COVID-19\nclassification based on CT images could largely alleviate the burden of\nclinicians. In this paper, we propose an Adaptive Feature Selection guided Deep\nForest (AFS-DF) for COVID-19 classification based on chest CT images.\nSpecifically, we first extract location-specific features from CT images. Then,\nin order to capture the high-level representation of these features with the\nrelatively small-scale data, we leverage a deep forest model to learn\nhigh-level representation of the features. Moreover, we propose a feature\nselection method based on the trained deep forest model to reduce the\nredundancy of features, where the feature selection could be adaptively\nincorporated with the COVID-19 classification model. We evaluated our proposed\nAFS-DF on COVID-19 dataset with 1495 patients of COVID-19 and 1027 patients of\ncommunity acquired pneumonia (CAP). The accuracy (ACC), sensitivity (SEN),\nspecificity (SPE) and AUC achieved by our method are 91.79%, 93.05%, 89.95% and\n96.35%, respectively. Experimental results on the COVID-19 dataset suggest that\nthe proposed AFS-DF achieves superior performance in COVID-19 vs. CAP\nclassification, compared with 4 widely used machine learning methods.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 06:00:02 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Sun", "Liang", ""], ["Mo", "Zhanhao", ""], ["Yan", "Fuhua", ""], ["Xia", "Liming", ""], ["Shan", "Fei", ""], ["Ding", "Zhongxiang", ""], ["Shao", "Wei", ""], ["Shi", "Feng", ""], ["Yuan", "Huan", ""], ["Jiang", "Huiting", ""], ["Wu", "Dijia", ""], ["Wei", "Ying", ""], ["Gao", "Yaozong", ""], ["Gao", "Wanchun", ""], ["Sui", "He", ""], ["Zhang", "Daoqiang", ""], ["Shen", "Dinggang", ""]]}, {"id": "2005.03266", "submitter": "Ritajit Majumdar", "authors": "Shovik Ganguly, Atrayee Chatterjee, Debasmita Bhoumik, Ritajit\n  Majumdar", "title": "An Empirical Study of Incremental Learning in Neural Network with Noisy\n  Training Set", "comments": "Oral Presentation delivered at the 7th International Conference on\n  Computers and Devices for Communication (CODEC) 2019. To appear in Lecture\n  Notes in Networks and Systems (LNSS Springer)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of incremental learning is to train an ANN algorithm in stages, as\nand when newer training data arrives. Incremental learning is becoming\nwidespread in recent times with the advent of deep learning. Noise in the\ntraining data reduces the accuracy of the algorithm. In this paper, we make an\nempirical study of the effect of noise in the training phase. We numerically\nshow that the accuracy of the algorithm is dependent more on the location of\nthe error than the percentage of error. Using Perceptron, Feed Forward Neural\nNetwork and Radial Basis Function Neural Network, we show that for the same\npercentage of error, the accuracy of the algorithm significantly varies with\nthe location of error. Furthermore, our results show that the dependence of the\naccuracy with the location of error is independent of the algorithm. However,\nthe slope of the degradation curve decreases with more sophisticated algorithms\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 06:09:31 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Ganguly", "Shovik", ""], ["Chatterjee", "Atrayee", ""], ["Bhoumik", "Debasmita", ""], ["Majumdar", "Ritajit", ""]]}, {"id": "2005.03288", "submitter": "Trista Chen", "authors": "Ying-Sheng Luo (1), Jonathan Hans Soeseno (1), Trista Pei-Chun Chen\n  (1), Wei-Chao Chen (1, 2) ((1) Inventec Corp. (2) Skywatch Innovation Inc.)", "title": "CARL: Controllable Agent with Reinforcement Learning for Quadruped\n  Locomotion", "comments": "Project page available at\n  https://inventec-ai-center.github.io/projects/CARL/index.html", "journal-ref": "ACM Transactions on Graphics (2020), Volume 39, Issue 4, Article\n  38", "doi": "10.1145/3386569.3392433", "report-no": null, "categories": "cs.LG cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion synthesis in a dynamic environment has been a long-standing problem\nfor character animation. Methods using motion capture data tend to scale poorly\nin complex environments because of their larger capturing and labeling\nrequirement. Physics-based controllers are effective in this regard, albeit\nless controllable. In this paper, we present CARL, a quadruped agent that can\nbe controlled with high-level directives and react naturally to dynamic\nenvironments. Starting with an agent that can imitate individual animation\nclips, we use Generative Adversarial Networks to adapt high-level controls,\nsuch as speed and heading, to action distributions that correspond to the\noriginal animations. Further fine-tuning through the deep reinforcement\nlearning enables the agent to recover from unseen external perturbations while\nproducing smooth transitions. It then becomes straightforward to create\nautonomous agents in dynamic environments by adding navigation modules over the\nentire process. We evaluate our approach by measuring the agent's ability to\nfollow user control and provide a visual analysis of the generated motion to\nshow its effectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 07:18:57 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 03:20:42 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2021 05:10:27 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Luo", "Ying-Sheng", "", "Inventec Corp"], ["Soeseno", "Jonathan Hans", "", "Inventec Corp"], ["Chen", "Trista Pei-Chun", "", "Inventec Corp"], ["Chen", "Wei-Chao", "", "Inventec Corp"]]}, {"id": "2005.03295", "submitter": "Seung-Won Park", "authors": "Seung-won Park, Doo-young Kim, Myun-chul Joe", "title": "Cotatron: Transcription-Guided Speech Encoder for Any-to-Many Voice\n  Conversion without Parallel Data", "comments": "To appear in INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Cotatron, a transcription-guided speech encoder for\nspeaker-independent linguistic representation. Cotatron is based on the\nmultispeaker TTS architecture and can be trained with conventional TTS\ndatasets. We train a voice conversion system to reconstruct speech with\nCotatron features, which is similar to the previous methods based on Phonetic\nPosteriorgram (PPG). By training and evaluating our system with 108 speakers\nfrom the VCTK dataset, we outperform the previous method in terms of both\nnaturalness and speaker similarity. Our system can also convert speech from\nspeakers that are unseen during training, and utilize ASR to automate the\ntranscription with minimal reduction of the performance. Audio samples are\navailable at https://mindslab-ai.github.io/cotatron, and the code with a\npre-trained model will be made available soon.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 07:37:31 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 06:01:38 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Park", "Seung-won", ""], ["Kim", "Doo-young", ""], ["Joe", "Myun-chul", ""]]}, {"id": "2005.03300", "submitter": "Aydin Buluc", "authors": "Alok Tripathy, Katherine Yelick, Aydin Buluc", "title": "Reducing Communication in Graph Neural Network Training", "comments": "To appear in International Conference for High Performance Computing,\n  Networking, Storage, and Analysis (SC'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are powerful and flexible neural networks that\nuse the naturally sparse connectivity information of the data. GNNs represent\nthis connectivity as sparse matrices, which have lower arithmetic intensity and\nthus higher communication costs compared to dense matrices, making GNNs harder\nto scale to high concurrencies than convolutional or fully-connected neural\nnetworks.\n  We introduce a family of parallel algorithms for training GNNs and show that\nthey can asymptotically reduce communication compared to previous parallel GNN\ntraining methods. We implement these algorithms, which are based on 1D, 1.5D,\n2D, and 3D sparse-dense matrix multiplication, using torch.distributed on\nGPU-equipped clusters. Our algorithms optimize communication across the full\nGNN training pipeline. We train GNNs on over a hundred GPUs on multiple\ndatasets, including a protein network with over a billion edges.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 07:45:09 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 06:33:01 GMT"}, {"version": "v3", "created": "Wed, 2 Sep 2020 20:35:32 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Tripathy", "Alok", ""], ["Yelick", "Katherine", ""], ["Buluc", "Aydin", ""]]}, {"id": "2005.03329", "submitter": "Seung-Bin Kim", "authors": "Seung-bin Kim, Jee-weon Jung, Hye-jin Shim, Ju-ho Kim and Ha-Jin Yu", "title": "Segment Aggregation for short utterances speaker verification using raw\n  waveforms", "comments": "5 pages, accepted by INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most studies on speaker verification systems focus on long-duration\nutterances, which are composed of sufficient phonetic information. However, the\nperformances of these systems are known to degrade when short-duration\nutterances are inputted due to the lack of phonetic information as compared to\nthe long utterances. In this paper, we propose a method that compensates for\nthe performance degradation of speaker verification for short utterances,\nreferred to as \"segment aggregation\". The proposed method adopts an\nensemble-based design to improve the stability and accuracy of speaker\nverification systems. The proposed method segments an input utterance into\nseveral short utterances and then aggregates the segment embeddings extracted\nfrom the segmented inputs to compose a speaker embedding. Then, this method\nsimultaneously trains the segment embeddings and the aggregated speaker\nembedding. In addition, we also modified the teacher-student learning method\nfor the proposed method. Experimental results on different input duration using\nthe VoxCeleb1 test set demonstrate that the proposed technique improves speaker\nverification performance by about 45.37% relatively compared to the baseline\nsystem with 1-second test utterance condition.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 08:57:22 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 08:00:22 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2020 05:40:15 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Kim", "Seung-bin", ""], ["Jung", "Jee-weon", ""], ["Shim", "Hye-jin", ""], ["Kim", "Ju-ho", ""], ["Yu", "Ha-Jin", ""]]}, {"id": "2005.03343", "submitter": "Kazuha Itabashi", "authors": "Kazuha Itabashi, Quoc Hoan Tran, Yoshihiko Hasegawa", "title": "Evaluating the phase dynamics of coupled oscillators via time-variant\n  topological features", "comments": "13 pages, 8 figures", "journal-ref": "Phys. Rev. E 103, 032207 (2021)", "doi": "10.1103/PhysRevE.103.032207", "report-no": null, "categories": "physics.data-an cs.LG math.AT nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By characterizing the phase dynamics in coupled oscillators, we gain insights\ninto the fundamental phenomena of complex systems. The collective dynamics in\noscillatory systems are often described by order parameters, which are\ninsufficient for identifying more specific behaviors. To improve this\nsituation, we propose a topological approach that constructs the quantitative\nfeatures describing the phase evolution of oscillators. Here, the phase data\nare mapped into a high-dimensional space at each time, and the topological\nfeatures describing the shape of the data are subsequently extracted from the\nmapped points. These features are extended to time-variant topological features\nby adding the evolution time as an extra dimension in the topological feature\nspace. The time-variant features provide crucial insights into the evolution of\nphase dynamics. Combining these features with the kernel method, we\ncharacterize the multi-clustered synchronized dynamics during the early\nevolution stages. Finally, we demonstrate that our method can qualitatively\nexplain chimera states. The experimental results confirmed the superiority of\nour method over those based on order parameters, especially when the available\ndata are limited to the early-stage dynamics.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 09:19:26 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 10:13:39 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 03:19:58 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Itabashi", "Kazuha", ""], ["Tran", "Quoc Hoan", ""], ["Hasegawa", "Yoshihiko", ""]]}, {"id": "2005.03350", "submitter": "Lkhagvadorj Munkhdalai", "authors": "Lkhagvadorj Munkhdalai, Tsendsuren Munkhdalai and Keun Ho Ryu", "title": "A Locally Adaptive Interpretable Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning models with both good predictability and high\ninterpretability are crucial for decision support systems. Linear regression is\none of the most interpretable prediction models. However, the linearity in a\nsimple linear regression worsens its predictability. In this work, we introduce\na locally adaptive interpretable regression (LoAIR). In LoAIR, a metamodel\nparameterized by neural networks predicts percentile of a Gaussian distribution\nfor the regression coefficients for a rapid adaptation. Our experimental\nresults on public benchmark datasets show that our model not only achieves\ncomparable or better predictive performance than the other state-of-the-art\nbaselines but also discovers some interesting relationships between input and\ntarget variables such as a parabolic relationship between CO2 emissions and\nGross National Product (GNP). Therefore, LoAIR is a step towards bridging the\ngap between econometrics, statistics, and machine learning by improving the\npredictive ability of linear regression without depreciating its\ninterpretability.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 09:26:14 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 01:42:57 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Munkhdalai", "Lkhagvadorj", ""], ["Munkhdalai", "Tsendsuren", ""], ["Ryu", "Keun Ho", ""]]}, {"id": "2005.03353", "submitter": "Martin Emil Jakobsen", "authors": "Martin Emil Jakobsen and Jonas Peters", "title": "Distributional Robustness of K-class Estimators and the PULSE", "comments": "85 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, in causal discovery, invariance properties such as the moment\ncriterion which two-stage least square estimator leverage have been exploited\nfor causal structure learning: e.g., in cases, where the causal parameter is\nnot identifiable, some structure of the non-zero components may be identified,\nand coverage guarantees are available. Subsequently, anchor regression has been\nproposed to trade-off invariance and predictability. The resulting estimator is\nshown to have optimal predictive performance under bounded shift interventions.\nIn this paper, we show that the concepts of anchor regression and K-class\nestimators are closely related. Establishing this connection comes with two\nbenefits: (1) It enables us to prove robustness properties for existing K-class\nestimators when considering distributional shifts. And, (2), we propose a novel\nestimator in instrumental variable settings by minimizing the mean squared\nprediction error subject to the constraint that the estimator lies in an\nasymptotically valid confidence region of the causal parameter. We call this\nestimator PULSE (p-uncorrelated least squares estimator) and show that it can\nbe computed efficiently, even though the underlying optimization problem is\nnon-convex. We further prove that it is consistent. We perform simulation\nexperiments illustrating that there are several settings including weak\ninstrument settings, where PULSE outperforms other estimators and suffers from\nless variability.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 09:39:07 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 17:27:21 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Jakobsen", "Martin Emil", ""], ["Peters", "Jonas", ""]]}, {"id": "2005.03354", "submitter": "Shaopeng Guo", "authors": "Shaopeng Guo and Yujie Wang and Quanquan Li and Junjie Yan", "title": "DMCP: Differentiable Markov Channel Pruning for Neural Networks", "comments": "CVPR2020 Oral. Code has been released at https://github.com/zx55/dmcp", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works imply that the channel pruning can be regarded as searching\noptimal sub-structure from unpruned networks. However, existing works based on\nthis observation require training and evaluating a large number of structures,\nwhich limits their application. In this paper, we propose a novel\ndifferentiable method for channel pruning, named Differentiable Markov Channel\nPruning (DMCP), to efficiently search the optimal sub-structure. Our method is\ndifferentiable and can be directly optimized by gradient descent with respect\nto standard task loss and budget regularization (e.g. FLOPs constraint). In\nDMCP, we model the channel pruning as a Markov process, in which each state\nrepresents for retaining the corresponding channel during pruning, and\ntransitions between states denote the pruning process. In the end, our method\nis able to implicitly select the proper number of channels in each layer by the\nMarkov process with optimized transitions. To validate the effectiveness of our\nmethod, we perform extensive experiments on Imagenet with ResNet and\nMobilenetV2. Results show our method can achieve consistent improvement than\nstate-of-the-art pruning methods in various FLOPs settings. The code is\navailable at https://github.com/zx55/dmcp\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 09:39:55 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 03:41:52 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Guo", "Shaopeng", ""], ["Wang", "Yujie", ""], ["Li", "Quanquan", ""], ["Yan", "Junjie", ""]]}, {"id": "2005.03355", "submitter": "Xi He", "authors": "Xi He", "title": "Quantum correlation alignment for unsupervised domain adaptation", "comments": "11 pages, 9 figures", "journal-ref": "Phys. Rev. A 102, 032410 (2020)", "doi": "10.1103/PhysRevA.102.032410", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correlation alignment (CORAL), a representative domain adaptation (DA)\nalgorithm, decorrelates and aligns a labelled source domain dataset to an\nunlabelled target domain dataset to minimize the domain shift such that a\nclassifier can be applied to predict the target domain labels. In this paper,\nwe implement the CORAL on quantum devices by two different methods. One method\nutilizes quantum basic linear algebra subroutines (QBLAS) to implement the\nCORAL with exponential speedup in the number and dimension of the given data\nsamples. The other method is achieved through a variational hybrid\nquantum-classical procedure. In addition, the numerical experiments of the\nCORAL with three different types of data sets, namely the synthetic data, the\nsynthetic-Iris data, the handwritten digit data, are presented to evaluate the\nperformance of our work. The simulation results prove that the variational\nquantum correlation alignment algorithm (VQCORAL) can achieve competitive\nperformance compared with the classical CORAL.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 09:42:36 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 13:09:25 GMT"}, {"version": "v3", "created": "Sun, 15 Nov 2020 14:04:37 GMT"}, {"version": "v4", "created": "Thu, 3 Jun 2021 15:23:11 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["He", "Xi", ""]]}, {"id": "2005.03357", "submitter": "Muhammad E. H. Chowdhury", "authors": "Moajjem Hossain Chowdhury, Md Nazmul Islam Shuzan, Muhammad E.H.\n  Chowdhury, Zaid B Mahbub, M. Monir Uddin, Amith Khandakar, Mamun Bin Ibne\n  Reaz", "title": "Estimating Blood Pressure from Photoplethysmogram Signal and Demographic\n  Features using Machine Learning Techniques", "comments": "Accepted for publication in Sensor, 14 Figures, 14 Tables", "journal-ref": "Sensors 2020, 20(11), 3127", "doi": "10.3390/s20113127", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypertension is a potentially unsafe health ailment, which can be indicated\ndirectly from the Blood pressure (BP). Hypertension always leads to other\nhealth complications. Continuous monitoring of BP is very important; however,\ncuff-based BP measurements are discrete and uncomfortable to the user. To\naddress this need, a cuff-less, continuous and a non-invasive BP measurement\nsystem is proposed using Photoplethysmogram (PPG) signal and demographic\nfeatures using machine learning (ML) algorithms. PPG signals were acquired from\n219 subjects, which undergo pre-processing and feature extraction steps. Time,\nfrequency and time-frequency domain features were extracted from the PPG and\ntheir derivative signals. Feature selection techniques were used to reduce the\ncomputational complexity and to decrease the chance of over-fitting the ML\nalgorithms. The features were then used to train and evaluate ML algorithms.\nThe best regression models were selected for Systolic BP (SBP) and Diastolic BP\n(DBP) estimation individually. Gaussian Process Regression (GPR) along with\nReliefF feature selection algorithm outperforms other algorithms in estimating\nSBP and DBP with a root-mean-square error (RMSE) of 6.74 and 3.59 respectively.\nThis ML model can be implemented in hardware systems to continuously monitor BP\nand avoid any critical health conditions due to sudden changes.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 09:45:02 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Chowdhury", "Moajjem Hossain", ""], ["Shuzan", "Md Nazmul Islam", ""], ["Chowdhury", "Muhammad E. H.", ""], ["Mahbub", "Zaid B", ""], ["Uddin", "M. Monir", ""], ["Khandakar", "Amith", ""], ["Reaz", "Mamun Bin Ibne", ""]]}, {"id": "2005.03374", "submitter": "Anssi Kanervisto", "authors": "Anssi Kanervisto, Janne Karttunen, Ville Hautam\\\"aki", "title": "Playing Minecraft with Behavioural Cloning", "comments": "To appear in Post Proceedings of the Competitions & Demonstrations\n  Track @ NeurIPS2019. Source code available at\n  https://github.com/Miffyli/minecraft-bc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  MineRL 2019 competition challenged participants to train sample-efficient\nagents to play Minecraft, by using a dataset of human gameplay and a limit\nnumber of steps the environment. We approached this task with behavioural\ncloning by predicting what actions human players would take, and reached fifth\nplace in the final ranking. Despite being a simple algorithm, we observed the\nperformance of such an approach can vary significantly, based on when the\ntraining is stopped. In this paper, we detail our submission to the\ncompetition, run further experiments to study how performance varied over\ntraining and study how different engineering decisions affected these results.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 10:48:51 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Kanervisto", "Anssi", ""], ["Karttunen", "Janne", ""], ["Hautam\u00e4ki", "Ville", ""]]}, {"id": "2005.03403", "submitter": "Yang Zhao", "authors": "Yang Zhao, Xiaohan Chen, Yue Wang, Chaojian Li, Haoran You, Yonggan\n  Fu, Yuan Xie, Zhangyang Wang, Yingyan Lin", "title": "SmartExchange: Trading Higher-cost Memory Storage/Access for Lower-cost\n  Computation", "comments": "Accepted by 47th International Symposium on Computer Architecture\n  (ISCA'2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SmartExchange, an algorithm-hardware co-design framework to trade\nhigher-cost memory storage/access for lower-cost computation, for\nenergy-efficient inference of deep neural networks (DNNs). We develop a novel\nalgorithm to enforce a specially favorable DNN weight structure, where each\nlayerwise weight matrix can be stored as the product of a small basis matrix\nand a large sparse coefficient matrix whose non-zero elements are all\npower-of-2. To our best knowledge, this algorithm is the first formulation that\nintegrates three mainstream model compression ideas: sparsification or pruning,\ndecomposition, and quantization, into one unified framework. The resulting\nsparse and readily-quantized DNN thus enjoys greatly reduced energy consumption\nin data movement as well as weight storage. On top of that, we further design a\ndedicated accelerator to fully utilize the SmartExchange-enforced weights to\nimprove both energy efficiency and latency performance. Extensive experiments\nshow that 1) on the algorithm level, SmartExchange outperforms state-of-the-art\ncompression techniques, including merely sparsification or pruning,\ndecomposition, and quantization, in various ablation studies based on nine DNN\nmodels and four datasets; and 2) on the hardware level, the proposed\nSmartExchange based accelerator can improve the energy efficiency by up to\n6.7$\\times$ and the speedup by up to 19.2$\\times$ over four state-of-the-art\nDNN accelerators, when benchmarked on seven DNN models (including four standard\nDNNs, two compact DNN models, and one segmentation model) and three datasets.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 12:12:49 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 07:35:09 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Zhao", "Yang", ""], ["Chen", "Xiaohan", ""], ["Wang", "Yue", ""], ["Li", "Chaojian", ""], ["You", "Haoran", ""], ["Fu", "Yonggan", ""], ["Xie", "Yuan", ""], ["Wang", "Zhangyang", ""], ["Lin", "Yingyan", ""]]}, {"id": "2005.03405", "submitter": "Feng Shi", "authors": "Xiaofeng Zhu, Bin Song, Feng Shi, Yanbo Chen, Rongyao Hu, Jiangzhang\n  Gan, Wenhai Zhang, Man Li, Liye Wang, Yaozong Gao, Fei Shan, Dinggang Shen", "title": "Joint Prediction and Time Estimation of COVID-19 Developing Severe\n  Symptoms using Chest CT Scan", "comments": null, "journal-ref": "Medical Image Analysis (2020)", "doi": "10.1016/j.media.2020.101824", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapidly worldwide spread of Coronavirus disease (COVID-19), it is of\ngreat importance to conduct early diagnosis of COVID-19 and predict the time\nthat patients might convert to the severe stage, for designing effective\ntreatment plan and reducing the clinicians' workloads. In this study, we\npropose a joint classification and regression method to determine whether the\npatient would develop severe symptoms in the later time, and if yes, predict\nthe possible conversion time that the patient would spend to convert to the\nsevere stage. To do this, the proposed method takes into account 1) the weight\nfor each sample to reduce the outliers' influence and explore the problem of\nimbalance classification, and 2) the weight for each feature via a sparsity\nregularization term to remove the redundant features of high-dimensional data\nand learn the shared information across the classification task and the\nregression task. To our knowledge, this study is the first work to predict the\ndisease progression and the conversion time, which could help clinicians to\ndeal with the potential severe cases in time or even save the patients' lives.\nExperimental analysis was conducted on a real data set from two hospitals with\n422 chest computed tomography (CT) scans, where 52 cases were converted to\nsevere on average 5.64 days and 34 cases were severe at admission. Results show\nthat our method achieves the best classification (e.g., 85.91% of accuracy) and\nregression (e.g., 0.462 of the correlation coefficient) performance, compared\nto all comparison methods. Moreover, our proposed method yields 76.97% of\naccuracy for predicting the severe cases, 0.524 of the correlation coefficient,\nand 0.55 days difference for the converted time.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 12:16:37 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Zhu", "Xiaofeng", ""], ["Song", "Bin", ""], ["Shi", "Feng", ""], ["Chen", "Yanbo", ""], ["Hu", "Rongyao", ""], ["Gan", "Jiangzhang", ""], ["Zhang", "Wenhai", ""], ["Li", "Man", ""], ["Wang", "Liye", ""], ["Gao", "Yaozong", ""], ["Shan", "Fei", ""], ["Shen", "Dinggang", ""]]}, {"id": "2005.03409", "submitter": "Jorge Pe\\~na Queralta", "authors": "Jorge Pe\\~na Queralta, Jenni Raitoharju, Tuan Nguyen Gia, Nikolaos\n  Passalis, Tomi Westerlund", "title": "AutoSOS: Towards Multi-UAV Systems Supporting Maritime Search and Rescue\n  with Lightweight AI and Edge Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rescue vessels are the main actors in maritime safety and rescue operations.\nAt the same time, aerial drones bring a significant advantage into this\nscenario. This paper presents the research directions of the AutoSOS project,\nwhere we work in the development of an autonomous multi-robot search and rescue\nassistance platform capable of sensor fusion and object detection in embedded\ndevices using novel lightweight AI models. The platform is meant to perform\nreconnaissance missions for initial assessment of the environment using novel\nadaptive deep learning algorithms that efficiently use the available sensors\nand computational resources on drones and rescue vessel. When drones find\npotential objects, they will send their sensor data to the vessel to verity the\nfindings with increased accuracy. The actual rescue and treatment operation are\nleft as the responsibility of the rescue personnel. The drones will\nautonomously reconfigure their spatial distribution to enable multi-hop\ncommunication, when a direct connection between a drone transmitting\ninformation and the vessel is unavailable.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 12:22:15 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Queralta", "Jorge Pe\u00f1a", ""], ["Raitoharju", "Jenni", ""], ["Gia", "Tuan Nguyen", ""], ["Passalis", "Nikolaos", ""], ["Westerlund", "Tomi", ""]]}, {"id": "2005.03415", "submitter": "Wojciech Dudzik", "authors": "Wojciech Dudzik, Damian Kosowski", "title": "Kunster -- AR Art Video Maker -- Real time video neural style transfer\n  on mobile devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural style transfer is a well-known branch of deep learning research, with\nmany interesting works and two major drawbacks. Most of the works in the field\nare hard to use by non-expert users and substantial hardware resources are\nrequired. In this work, we present a solution to both of these problems. We\nhave applied neural style transfer to real-time video (over 25 frames per\nsecond), which is capable of running on mobile devices. We also investigate the\nworks on achieving temporal coherence and present the idea of fine-tuning,\nalready trained models, to achieve stable video. What is more, we also analyze\nthe impact of the common deep neural network architecture on the performance of\nmobile devices with regard to number of layers and filters present. In the\nexperiment section we present the results of our work with respect to the iOS\ndevices and discuss the problems present in current Android devices as well as\nfuture possibilities. At the end we present the qualitative results of\nstylization and quantitative results of performance tested on the iPhone 11 Pro\nand iPhone 6s. The presented work is incorporated in Kunster - AR Art Video\nMaker application available in the Apple's App Store.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 12:30:48 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Dudzik", "Wojciech", ""], ["Kosowski", "Damian", ""]]}, {"id": "2005.03419", "submitter": "Kazuaki Murayama", "authors": "Kazuaki. Murayama and Shuichi. Kawano", "title": "Relevance Vector Machine with Weakly Informative Hyperprior and Extended\n  Predictive Information Criterion", "comments": "29 pages, 12 captioned figures, 23 files of non-captioned figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the variational relevance vector machine, the gamma distribution is\nrepresentative as a hyperprior over the noise precision of automatic relevance\ndetermination prior. Instead of the gamma hyperprior, we propose to use the\ninverse gamma hyperprior with a shape parameter close to zero and a scale\nparameter not necessary close to zero. This hyperprior is associated with the\nconcept of a weakly informative prior. The effect of this hyperprior is\ninvestigated through regression to non-homogeneous data. Because it is\ndifficult to capture the structure of such data with a single kernel function,\nwe apply the multiple kernel method, in which multiple kernel functions with\ndifferent widths are arranged for input data. We confirm that the degrees of\nfreedom in a model is controlled by adjusting the scale parameter and keeping\nthe shape parameter close to zero. A candidate for selecting the scale\nparameter is the predictive information criterion. However the estimated model\nusing this criterion seems to cause over-fitting. This is because the multiple\nkernel method makes the model a situation where the dimension of the model is\nlarger than the data size. To select an appropriate scale parameter even in\nsuch a situation, we also propose an extended prediction information criterion.\nIt is confirmed that a multiple kernel relevance vector regression model with\ngood predictive accuracy can be obtained by selecting the scale parameter\nminimizing extended prediction information criterion.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 12:37:19 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Murayama", "Kazuaki.", ""], ["Kawano", "Shuichi.", ""]]}, {"id": "2005.03420", "submitter": "Frank R\\\"oder", "authors": "Frank R\\\"oder, Manfred Eppe, Phuong D.H. Nguyen and Stefan Wermter", "title": "Curious Hierarchical Actor-Critic Reinforcement Learning", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical abstraction and curiosity-driven exploration are two common\nparadigms in current reinforcement learning approaches to break down difficult\nproblems into a sequence of simpler ones and to overcome reward sparsity.\nHowever, there is a lack of approaches that combine these paradigms, and it is\ncurrently unknown whether curiosity also helps to perform the hierarchical\nabstraction. As a novelty and scientific contribution, we tackle this issue and\ndevelop a method that combines hierarchical reinforcement learning with\ncuriosity. Herein, we extend a contemporary hierarchical actor-critic approach\nwith a forward model to develop a hierarchical notion of curiosity. We\ndemonstrate in several continuous-space environments that curiosity can more\nthan double the learning performance and success rates for most of the\ninvestigated benchmarking problems. We also provide our source code and a\nsupplementary video.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 12:44:26 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 18:25:33 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 08:45:36 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["R\u00f6der", "Frank", ""], ["Eppe", "Manfred", ""], ["Nguyen", "Phuong D. H.", ""], ["Wermter", "Stefan", ""]]}, {"id": "2005.03442", "submitter": "Dominique Mercier", "authors": "Dominique Mercier, Shoaib Ahmed Siddiqui, Andreas Dengel, Sheraz Ahmed", "title": "Interpreting Deep Models through the Lens of Data", "comments": "8 pages, 11 figures, Accepted for the IEEE International Joint\n  Conference on Neural Networks (IJCNN) 2020", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207704", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification of input data points relevant for the classifier (i.e. serve\nas the support vector) has recently spurred the interest of researchers for\nboth interpretability as well as dataset debugging. This paper presents an\nin-depth analysis of the methods which attempt to identify the influence of\nthese data points on the resulting classifier. To quantify the quality of the\ninfluence, we curated a set of experiments where we debugged and pruned the\ndataset based on the influence information obtained from different methods. To\ndo so, we provided the classifier with mislabeled examples that hampered the\noverall performance. Since the classifier is a combination of both the data and\nthe model, therefore, it is essential to also analyze these influences for the\ninterpretability of deep learning models. Analysis of the results shows that\nsome interpretability methods can detect mislabels better than using a random\napproach, however, contrary to the claim of these methods, the sample selection\nbased on the training loss showed a superior performance.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 07:59:37 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 08:21:43 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Mercier", "Dominique", ""], ["Siddiqui", "Shoaib Ahmed", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "2005.03447", "submitter": "Zhenyu Zhao", "authors": "Zhenyu Zhao, Yumin Zhang, Totte Harinen, Mike Yung", "title": "Feature Selection Methods for Uplift Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uplift modeling is a predictive modeling technique that estimates the\nuser-level incremental effect of a treatment using machine learning models. It\nis often used for targeting promotions and advertisements, as well as for the\npersonalization of product offerings. In these applications, there are often\nhundreds of features available to build such models. Keeping all the features\nin a model can be costly and inefficient. Feature selection is an essential\nstep in the modeling process for multiple reasons: improving the estimation\naccuracy by eliminating irrelevant features, accelerating model training and\nprediction speed, reducing the monitoring and maintenance workload for feature\ndata pipeline, and providing better model interpretation and diagnostics\ncapability. However, feature selection methods for uplift modeling have been\nrarely discussed in the literature. Although there are various feature\nselection methods for standard machine learning models, we will demonstrate\nthat those methods are sub-optimal for solving the feature selection problem\nfor uplift modeling. To address this problem, we introduce a set of feature\nselection methods designed specifically for uplift modeling, including both\nfilter methods and embedded methods. To evaluate the effectiveness of the\nproposed feature selection methods, we use different uplift models and measure\nthe accuracy of each model with a different number of selected features. We use\nboth synthetic and real data to conduct these experiments. We also implemented\nthe proposed filter methods in an open source Python package (CausalML).\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 00:28:18 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Zhao", "Zhenyu", ""], ["Zhang", "Yumin", ""], ["Harinen", "Totte", ""], ["Yung", "Mike", ""]]}, {"id": "2005.03448", "submitter": "Hao Sun", "authors": "Zhao Chen, Yang Liu and Hao Sun", "title": "Physics-informed learning of governing equations from scarce data", "comments": "46 pages; 1 table, 6 figures and 3 extended data figures in main\n  text; 2 tables and 12 figures in supplementary information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Harnessing data to discover the underlying governing laws or equations that\ndescribe the behavior of complex physical systems can significantly advance our\nmodeling, simulation and understanding of such systems in various science and\nengineering disciplines. This work introduces a novel physics-informed deep\nlearning framework to discover governing partial differential equations (PDEs)\nfrom scarce and noisy data for nonlinear spatiotemporal systems. In particular,\nthis approach seamlessly integrates the strengths of deep neural networks for\nrich representation learning, physics embedding, automatic differentiation and\nsparse regression to (1) approximate the solution of system variables, (2)\ncompute essential derivatives, as well as (3) identify the key derivative terms\nand parameters that form the structure and explicit expression of the PDEs. The\nefficacy and robustness of this method are demonstrated, both numerically and\nexperimentally, on discovering a variety of PDE systems with different levels\nof data scarcity and noise accounting for different initial/boundary\nconditions. The resulting computational framework shows the potential for\nclosed-form model discovery in practical applications where large and accurate\ndatasets are intractable to capture.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 22:13:22 GMT"}, {"version": "v2", "created": "Sat, 9 Jan 2021 23:28:48 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2021 21:26:27 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Chen", "Zhao", ""], ["Liu", "Yang", ""], ["Sun", "Hao", ""]]}, {"id": "2005.03451", "submitter": "Behzad Salami", "authors": "Behzad Salami, Erhan Baturay Onural, Ismail Emir Yuksel, Fahrettin\n  Koc, Oguz Ergin, Adrian Cristal Kestelman, Osman S. Unsal, Hamid\n  Sarbazi-Azad, Onur Mutlu", "title": "An Experimental Study of Reduced-Voltage Operation in Modern FPGAs for\n  Neural Network Acceleration", "comments": "To appear at the DSN 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We empirically evaluate an undervolting technique, i.e., underscaling the\ncircuit supply voltage below the nominal level, to improve the power-efficiency\nof Convolutional Neural Network (CNN) accelerators mapped to Field Programmable\nGate Arrays (FPGAs). Undervolting below a safe voltage level can lead to timing\nfaults due to excessive circuit latency increase. We evaluate the\nreliability-power trade-off for such accelerators. Specifically, we\nexperimentally study the reduced-voltage operation of multiple components of\nreal FPGAs, characterize the corresponding reliability behavior of CNN\naccelerators, propose techniques to minimize the drawbacks of reduced-voltage\noperation, and combine undervolting with architectural CNN optimization\ntechniques, i.e., quantization and pruning. We investigate the effect of\nenvironmental temperature on the reliability-power trade-off of such\naccelerators. We perform experiments on three identical samples of modern\nXilinx ZCU102 FPGA platforms with five state-of-the-art image classification\nCNN benchmarks. This approach allows us to study the effects of our\nundervolting technique for both software and hardware variability. We achieve\nmore than 3X power-efficiency (GOPs/W) gain via undervolting. 2.6X of this gain\nis the result of eliminating the voltage guardband region, i.e., the safe\nvoltage region below the nominal level that is set by FPGA vendor to ensure\ncorrect functionality in worst-case environmental and circuit conditions. 43%\nof the power-efficiency gain is due to further undervolting below the\nguardband, which comes at the cost of accuracy loss in the CNN accelerator. We\nevaluate an effective frequency underscaling technique that prevents this\naccuracy loss, and find that it reduces the power-efficiency gain from 43% to\n25%.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 22:59:07 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 22:40:58 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Salami", "Behzad", ""], ["Onural", "Erhan Baturay", ""], ["Yuksel", "Ismail Emir", ""], ["Koc", "Fahrettin", ""], ["Ergin", "Oguz", ""], ["Kestelman", "Adrian Cristal", ""], ["Unsal", "Osman S.", ""], ["Sarbazi-Azad", "Hamid", ""], ["Mutlu", "Onur", ""]]}, {"id": "2005.03452", "submitter": "Christopher Zach", "authors": "Rasmus Kj{\\ae}r H{\\o}ier, Christopher Zach", "title": "Lifted Regression/Reconstruction Networks", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose lifted regression/reconstruction networks (LRRNs),\nwhich combine lifted neural networks with a guaranteed Lipschitz continuity\nproperty for the output layer. Lifted neural networks explicitly optimize an\nenergy model to infer the unit activations and therefore---in contrast to\nstandard feed-forward neural networks---allow bidirectional feedback between\nlayers. So far lifted neural networks have been modelled around standard\nfeed-forward architectures. We propose to take further advantage of the\nfeedback property by letting the layers simultaneously perform regression and\nreconstruction. The resulting lifted network architecture allows to control the\ndesired amount of Lipschitz continuity, which is an important feature to obtain\nadversarially robust regression and classification methods. We analyse and\nnumerically demonstrate applications for unsupervised and supervised learning.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 13:24:46 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["H\u00f8ier", "Rasmus Kj\u00e6r", ""], ["Zach", "Christopher", ""]]}, {"id": "2005.03453", "submitter": "Ofer Strichman", "authors": "Tomer Cohen, Lior Finkelman, Gal Grimberg, Gadi Shenhar, Ofer\n  Strichman, Yonatan Strichman, Stav Yeger", "title": "A combination of 'pooling' with a prediction model can reduce by 73% the\n  number of COVID-19 (Corona-virus) tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that combining a prediction model (based on neural networks), with a\nnew method of test pooling (better than the original Dorfman method, and better\nthan double-pooling) called 'Grid', we can reduce the number of Covid-19 tests\nby 73%.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 17:33:10 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 18:16:01 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 11:48:46 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Cohen", "Tomer", ""], ["Finkelman", "Lior", ""], ["Grimberg", "Gal", ""], ["Shenhar", "Gadi", ""], ["Strichman", "Ofer", ""], ["Strichman", "Yonatan", ""], ["Yeger", "Stav", ""]]}, {"id": "2005.03454", "submitter": "Christopher Brix", "authors": "Christopher Brix, Parnia Bahar, Hermann Ney", "title": "Successfully Applying the Stabilized Lottery Ticket Hypothesis to the\n  Transformer Architecture", "comments": "Accepted at ACL2020; evaluation corrected: magnitude pruning may be\n  useful to find winning lottery tickets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse models require less memory for storage and enable a faster inference\nby reducing the necessary number of FLOPs. This is relevant both for\ntime-critical and on-device computations using neural networks. The stabilized\nlottery ticket hypothesis states that networks can be pruned after none or few\ntraining iterations, using a mask computed based on the unpruned converged\nmodel. On the transformer architecture and the WMT 2014 English-to-German and\nEnglish-to-French tasks, we show that stabilized lottery ticket pruning\nperforms similar to magnitude pruning for sparsity levels of up to 85%, and\npropose a new combination of pruning techniques that outperforms all other\ntechniques for even higher levels of sparsity. Furthermore, we confirm that the\nparameter's initial sign and not its specific value is the primary factor for\nsuccessful training, and show that magnitude pruning could be used to find\nwinning lottery tickets.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 15:17:28 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 15:22:02 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Brix", "Christopher", ""], ["Bahar", "Parnia", ""], ["Ney", "Hermann", ""]]}, {"id": "2005.03460", "submitter": "Karush Suri", "authors": "Karush Suri, Rinki Gupta", "title": "Transfer Learning for sEMG-based Hand Gesture Classification using Deep\n  Learning in a Master-Slave Architecture", "comments": null, "journal-ref": null, "doi": "10.1109/IC3I44769.2018.9007304", "report-no": null, "categories": "eess.SP cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in diagnostic learning and development of gesture-based\nhuman machine interfaces have driven surface electromyography (sEMG) towards\nsignificant importance. Analysis of hand gestures requires an accurate\nassessment of sEMG signals. The proposed work presents a novel sequential\nmaster-slave architecture consisting of deep neural networks (DNNs) for\nclassification of signs from the Indian sign language using signals recorded\nfrom multiple sEMG channels. The performance of the master-slave network is\naugmented by leveraging additional synthetic feature data generated by long\nshort term memory networks. Performance of the proposed network is compared to\nthat of a conventional DNN prior to and after the addition of synthetic data.\nUp to 14% improvement is observed in the conventional DNN and up to 9%\nimprovement in master-slave network on addition of synthetic data with an\naverage accuracy value of 93.5% asserting the suitability of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 01:16:17 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Suri", "Karush", ""], ["Gupta", "Rinki", ""]]}, {"id": "2005.03461", "submitter": "Chi-Hua Chen", "authors": "Chi-Hua Chen", "title": "ExpDNN: Explainable Deep Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep neural networks have been applied to obtain high\nperformance of prediction, classification, and pattern recognition. However,\nthe weights in these deep neural networks are difficult to be explained.\nAlthough a linear regression method can provide explainable results, the method\nis not suitable in the case of input interaction. Therefore, an explainable\ndeep neural network (ExpDNN) with explainable layers is proposed to obtain\nexplainable results in the case of input interaction. Three cases were given to\nevaluate the proposed ExpDNN, and the results showed that the absolute value of\nweight in an explainable layer can be used to explain the weight of\ncorresponding input for feature extraction.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 07:57:24 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Chen", "Chi-Hua", ""]]}, {"id": "2005.03474", "submitter": "Arpita Biswas", "authors": "Arpita Biswas, Suvam Mukherjee", "title": "Ensuring Fairness under Prior Probability Shifts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of fair classification in the presence of\nprior probability shifts, where the training set distribution differs from the\ntest set. This phenomenon can be observed in the yearly records of several\nreal-world datasets, such as recidivism records and medical expenditure\nsurveys. If unaccounted for, such shifts can cause the predictions of a\nclassifier to become unfair towards specific population subgroups. While the\nfairness notion called Proportional Equality (PE) accounts for such shifts, a\nprocedure to ensure PE-fairness was unknown.\n  In this work, we propose a method, called CAPE, which provides a\ncomprehensive solution to the aforementioned problem. CAPE makes novel use of\nprevalence estimation techniques, sampling and an ensemble of classifiers to\nensure fair predictions under prior probability shifts. We introduce a metric,\ncalled prevalence difference (PD), which CAPE attempts to minimize in order to\nensure PE-fairness. We theoretically establish that this metric exhibits\nseveral desirable properties.\n  We evaluate the efficacy of CAPE via a thorough empirical evaluation on\nsynthetic datasets. We also compare the performance of CAPE with several\npopular fair classifiers on real-world datasets like COMPAS (criminal risk\nassessment) and MEPS (medical expenditure panel survey). The results indicate\nthat CAPE ensures PE-fair predictions, while performing well on other\nperformance metrics.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 13:07:05 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Biswas", "Arpita", ""], ["Mukherjee", "Suvam", ""]]}, {"id": "2005.03475", "submitter": "Chen Gao", "authors": "Jianxin Chang, Chen Gao, Xiangnan He, Yong Li, Depeng Jin", "title": "Bundle Recommendation with Graph Convolutional Networks", "comments": "Accepted by SIGIR 2020 (Short)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bundle recommendation aims to recommend a bundle of items for a user to\nconsume as a whole. Existing solutions integrate user-item interaction modeling\ninto bundle recommendation by sharing model parameters or learning in a\nmulti-task manner, which cannot explicitly model the affiliation between items\nand bundles, and fail to explore the decision-making when a user chooses\nbundles. In this work, we propose a graph neural network model named BGCN\n(short for \\textit{\\textBF{B}undle \\textBF{G}raph \\textBF{C}onvolutional\n\\textBF{N}etwork}) for bundle recommendation. BGCN unifies user-item\ninteraction, user-bundle interaction and bundle-item affiliation into a\nheterogeneous graph. With item nodes as the bridge, graph convolutional\npropagation between user and bundle nodes makes the learned representations\ncapture the item level semantics. Through training based on hard-negative\nsampler, the user's fine-grained preferences for similar bundles are further\ndistinguished. Empirical results on two real-world datasets demonstrate the\nstrong performance gains of BGCN, which outperforms the state-of-the-art\nbaselines by 10.77\\% to 23.18\\%.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 13:48:26 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Chang", "Jianxin", ""], ["Gao", "Chen", ""], ["He", "Xiangnan", ""], ["Li", "Yong", ""], ["Jin", "Depeng", ""]]}, {"id": "2005.03476", "submitter": "Naresh Balaji Ravichandran", "authors": "Naresh Balaji Ravichandran, Anders Lansner, Pawel Herman", "title": "Brain-like approaches to unsupervised learning of hidden representations\n  -- a comparative study", "comments": "arXiv admin note: text overlap with arXiv:2003.12415", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Unsupervised learning of hidden representations has been one of the most\nvibrant research directions in machine learning in recent years. In this work\nwe study the brain-like Bayesian Confidence Propagating Neural Network (BCPNN)\nmodel, recently extended to extract sparse distributed high-dimensional\nrepresentations. The usefulness and class-dependent separability of the hidden\nrepresentations when trained on MNIST and Fashion-MNIST datasets is studied\nusing an external linear classifier and compared with other unsupervised\nlearning methods that include restricted Boltzmann machines and autoencoders.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 11:20:21 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 13:22:54 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Ravichandran", "Naresh Balaji", ""], ["Lansner", "Anders", ""], ["Herman", "Pawel", ""]]}, {"id": "2005.03482", "submitter": "Ao Liu", "authors": "Ao Liu, Beibei Li, Tao Li, Pan Zhou, Rui wang", "title": "AN-GCN: An Anonymous Graph Convolutional Network Defense Against\n  Edge-Perturbing Attack", "comments": "15 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have revealed the vulnerability of graph convolutional\nnetworks (GCNs) to edge-perturbing attacks, such as maliciously inserting or\ndeleting graph edges. However, a theoretical proof of such vulnerability\nremains a big challenge, and effective defense schemes are still open issues.\nIn this paper, we first generalize the formulation of edge-perturbing attacks\nand strictly prove the vulnerability of GCNs to such attacks in node\nclassification tasks. Following this, an anonymous graph convolutional network,\nnamed AN-GCN, is proposed to counter against edge-perturbing attacks.\nSpecifically, we present a node localization theorem to demonstrate how the GCN\nlocates nodes during its training phase. In addition, we design a staggered\nGaussian noise based node position generator, and devise a spectral graph\nconvolution based discriminator in detecting the generated node positions.\nFurther, we give the optimization of the above generator and discriminator.\nAN-GCN can classify nodes without taking their position as input. It is\ndemonstrated that the AN-GCN is secure against edge-perturbing attacks in node\nclassification tasks, as AN-GCN classifies nodes without the edge information\nand thus makes it impossible for attackers to perturb edges anymore. Extensive\nevaluations demonstrated the effectiveness of the general edge-perturbing\nattack model in manipulating the classification results of the target nodes.\nMore importantly, the proposed AN-GCN can achieve 82.7% in node classification\naccuracy without the edge-reading permission, which outperforms the\nstate-of-the-art GCN.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 08:15:24 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 11:14:44 GMT"}, {"version": "v3", "created": "Fri, 23 Apr 2021 13:44:19 GMT"}, {"version": "v4", "created": "Fri, 7 May 2021 08:57:07 GMT"}, {"version": "v5", "created": "Tue, 1 Jun 2021 03:17:58 GMT"}, {"version": "v6", "created": "Thu, 17 Jun 2021 01:41:29 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Liu", "Ao", ""], ["Li", "Beibei", ""], ["Li", "Tao", ""], ["Zhou", "Pan", ""], ["wang", "Rui", ""]]}, {"id": "2005.03490", "submitter": "Gehui Shen", "authors": "Gehui Shen, Song Zhang, Xiang Chen and Zhi-Hong Deng", "title": "Generative Feature Replay with Orthogonal Weight Modification for\n  Continual Learning", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of intelligent agents to learn and remember multiple tasks\nsequentially is crucial to achieving artificial general intelligence. Many\ncontinual learning (CL) methods have been proposed to overcome catastrophic\nforgetting which results from non i.i.d data in the sequential learning of\nneural networks. In this paper we focus on class incremental learning, a\nchallenging CL scenario. For this scenario, generative replay is a promising\nstrategy which generates and replays pseudo data for previous tasks to\nalleviate catastrophic forgetting. However, it is hard to train a generative\nmodel continually for relatively complex data. Based on recently proposed\northogonal weight modification (OWM) algorithm which can approximately keep\npreviously learned feature invariant when learning new tasks, we propose to 1)\nreplay penultimate layer feature with a generative model; 2) leverage a\nself-supervised auxiliary task to further enhance the stability of feature.\nEmpirical results on several datasets show our method always achieves\nsubstantial improvement over powerful OWM while conventional generative replay\nalways results in a negative effect. Meanwhile our method beats several strong\nbaselines including one based on real data storage. In addition, we conduct\nexperiments to study why our method is effective.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 13:56:22 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 03:18:23 GMT"}, {"version": "v3", "created": "Sat, 12 Sep 2020 03:35:24 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Shen", "Gehui", ""], ["Zhang", "Song", ""], ["Chen", "Xiang", ""], ["Deng", "Zhi-Hong", ""]]}, {"id": "2005.03510", "submitter": "Dongyub Lee", "authors": "Dongyub Lee, Myeongcheol Shin, Taesun Whang, Seungwoo Cho, Byeongil\n  Ko, Daniel Lee, Eunggyun Kim, Jaechoon Jo", "title": "Reference and Document Aware Semantic Evaluation Methods for Korean\n  Language Summarization", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text summarization refers to the process that generates a shorter form of\ntext from the source document preserving salient information. Many existing\nworks for text summarization are generally evaluated by using recall-oriented\nunderstudy for gisting evaluation (ROUGE) scores. However, as ROUGE scores are\ncomputed based on n-gram overlap, they do not reflect semantic meaning\ncorrespondences between generated and reference summaries. Because Korean is an\nagglutinative language that combines various morphemes into a word that express\nseveral meanings, ROUGE is not suitable for Korean summarization. In this\npaper, we propose evaluation metrics that reflect semantic meanings of a\nreference summary and the original document, Reference and Document Aware\nSemantic Score (RDASS). We then propose a method for improving the correlation\nof the metrics with human judgment. Evaluation results show that the\ncorrelation with human judgment is significantly higher for our evaluation\nmetrics than for ROUGE scores.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 08:26:30 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 02:40:58 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Lee", "Dongyub", ""], ["Shin", "Myeongcheol", ""], ["Whang", "Taesun", ""], ["Cho", "Seungwoo", ""], ["Ko", "Byeongil", ""], ["Lee", "Daniel", ""], ["Kim", "Eunggyun", ""], ["Jo", "Jaechoon", ""]]}, {"id": "2005.03545", "submitter": "Devamanyu Hazarika", "authors": "Devamanyu Hazarika, Roger Zimmermann, Soujanya Poria", "title": "MISA: Modality-Invariant and -Specific Representations for Multimodal\n  Sentiment Analysis", "comments": "Accepted at ACM MM 2020 (Oral Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Multimodal Sentiment Analysis is an active area of research that leverages\nmultimodal signals for affective understanding of user-generated videos. The\npredominant approach, addressing this task, has been to develop sophisticated\nfusion techniques. However, the heterogeneous nature of the signals creates\ndistributional modality gaps that pose significant challenges. In this paper,\nwe aim to learn effective modality representations to aid the process of\nfusion. We propose a novel framework, MISA, which projects each modality to two\ndistinct subspaces. The first subspace is modality-invariant, where the\nrepresentations across modalities learn their commonalities and reduce the\nmodality gap. The second subspace is modality-specific, which is private to\neach modality and captures their characteristic features. These representations\nprovide a holistic view of the multimodal data, which is used for fusion that\nleads to task predictions. Our experiments on popular sentiment analysis\nbenchmarks, MOSI and MOSEI, demonstrate significant gains over state-of-the-art\nmodels. We also consider the task of Multimodal Humor Detection and experiment\non the recently proposed UR_FUNNY dataset. Here too, our model fares better\nthan strong baselines, establishing MISA as a useful multimodal framework.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 15:13:23 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 12:14:37 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 13:41:27 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Hazarika", "Devamanyu", ""], ["Zimmermann", "Roger", ""], ["Poria", "Soujanya", ""]]}, {"id": "2005.03557", "submitter": "Tengyu Xu", "authors": "Tengyu Xu, Zhe Wang, Yingbin Liang", "title": "Non-asymptotic Convergence Analysis of Two Time-scale (Natural)\n  Actor-Critic Algorithms", "comments": "The results of this paper were initially submitted for publication in\n  February 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an important type of reinforcement learning algorithms, actor-critic (AC)\nand natural actor-critic (NAC) algorithms are often executed in two ways for\nfinding optimal policies. In the first nested-loop design, actor's one update\nof policy is followed by an entire loop of critic's updates of the value\nfunction, and the finite-sample analysis of such AC and NAC algorithms have\nbeen recently well established. The second two time-scale design, in which\nactor and critic update simultaneously but with different learning rates, has\nmuch fewer tuning parameters than the nested-loop design and is hence\nsubstantially easier to implement. Although two time-scale AC and NAC have been\nshown to converge in the literature, the finite-sample convergence rate has not\nbeen established. In this paper, we provide the first such non-asymptotic\nconvergence rate for two time-scale AC and NAC under Markovian sampling and\nwith actor having general policy class approximation. We show that two\ntime-scale AC requires the overall sample complexity at the order of\n$\\mathcal{O}(\\epsilon^{-2.5}\\log^3(\\epsilon^{-1}))$ to attain an\n$\\epsilon$-accurate stationary point, and two time-scale NAC requires the\noverall sample complexity at the order of\n$\\mathcal{O}(\\epsilon^{-4}\\log^2(\\epsilon^{-1}))$ to attain an\n$\\epsilon$-accurate global optimal point. We develop novel techniques for\nbounding the bias error of the actor due to dynamically changing Markovian\nsampling and for analyzing the convergence rate of the linear critic with\ndynamically changing base functions and transition kernel.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 15:42:31 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 02:06:12 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Xu", "Tengyu", ""], ["Wang", "Zhe", ""], ["Liang", "Yingbin", ""]]}, {"id": "2005.03566", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu and Bo Zhang and Xudong Li", "title": "Noisy Differentiable Architecture Search", "comments": "Make use of noise to address collapse from excessive skip connections\n  in DARTS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simplicity is the ultimate sophistication. Differentiable Architecture Search\n(DARTS) has now become one of the mainstream paradigms of neural architecture\nsearch. However, it largely suffers from several disturbing factors of\noptimization process whose results are unstable to reproduce. FairDARTS points\nout that skip connections natively have an unfair advantage in exclusive\ncompetition which primarily leads to dramatic performance collapse. While\nFairDARTS turns the unfair competition into a collaborative one, we instead\nimpede such unfair advantage by injecting unbiased random noise into skip\noperations' output. In effect, the optimizer should perceive this difficulty at\neach training step and refrain from overshooting on skip connections, but in a\nlong run it still converges to the right solution area since no bias is added\nto the gradient. We name this novel approach as NoisyDARTS. Our experiments on\nCIFAR-10 and ImageNet attest that it can effectively break the skip\nconnection's unfair advantage and yield better performance. It generates a\nseries of models that achieve state-of-the-art results on both datasets. Code\nwill be made available at https://github.com/xiaomi-automl/NoisyDARTS.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 15:53:52 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 14:42:33 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Zhang", "Bo", ""], ["Li", "Xudong", ""]]}, {"id": "2005.03582", "submitter": "Mar\\'ia N. Moreno Garc\\'ia", "authors": "Fernando S\\'anchez-Hern\\'andez, Juan Carlos Ballesteros-Herr\\'aez,\n  Mohamed S. Kraiem, Mercedes S\\'anchez-Barba and Mar\\'ia N. Moreno-Garc\\'ia", "title": "Predictive Modeling of ICU Healthcare-Associated Infections from\n  Imbalanced Data. Using Ensembles and a Clustering-Based Undersampling\n  Approach", "comments": null, "journal-ref": "Applied Sciences 9(24),5287,2019", "doi": "10.3390/app9245287", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Early detection of patients vulnerable to infections acquired in the hospital\nenvironment is a challenge in current health systems given the impact that such\ninfections have on patient mortality and healthcare costs. This work is focused\non both the identification of risk factors and the prediction of\nhealthcare-associated infections in intensive-care units by means of\nmachine-learning methods. The aim is to support decision making addressed at\nreducing the incidence rate of infections. In this field, it is necessary to\ndeal with the problem of building reliable classifiers from imbalanced\ndatasets. We propose a clustering-based undersampling strategy to be used in\ncombination with ensemble classifiers. A comparative study with data from 4616\npatients was conducted in order to validate our proposal. We applied several\nsingle and ensemble classifiers both to the original dataset and to data\npreprocessed by means of different resampling methods. The results were\nanalyzed by means of classic and recent metrics specifically designed for\nimbalanced data classification. They revealed that the proposal is more\nefficient in comparison with other approaches.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 16:13:12 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["S\u00e1nchez-Hern\u00e1ndez", "Fernando", ""], ["Ballesteros-Herr\u00e1ez", "Juan Carlos", ""], ["Kraiem", "Mohamed S.", ""], ["S\u00e1nchez-Barba", "Mercedes", ""], ["Moreno-Garc\u00eda", "Mar\u00eda N.", ""]]}, {"id": "2005.03585", "submitter": "Ran Ber", "authors": "Ran Ilan Ber and Tom Haramaty", "title": "Domain Adaptation in Highly Imbalanced and Overlapping Datasets", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many machine learning domains, datasets are characterized by highly\nimbalanced and overlapping classes. Particularly in the medical domain, a\nspecific list of symptoms can be labeled as one of various different\nconditions. Some of these conditions may be more prevalent than others by\nseveral orders of magnitude. Here we present a novel unsupervised domain\nadaptation scheme for such datasets. The scheme, based on a specific type of\nQuantification, is designed to work under both label and conditional shifts. It\nis demonstrated on datasets generated from electronic health records and\nprovides high quality results for both Quantification and Domain Adaptation in\nvery challenging scenarios. Potential benefits of using this scheme in the\ncurrent COVID-19 outbreak, for estimation of prevalence and probability of\ninfection are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 16:15:45 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 10:23:16 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Ber", "Ran Ilan", ""], ["Haramaty", "Tom", ""]]}, {"id": "2005.03588", "submitter": "Inkit Padhi", "authors": "Inkit Padhi, Pierre Dognin, Ke Bai, Cicero Nogueira dos Santos, Vijil\n  Chenthamarakshan, Youssef Mroueh, Payel Das", "title": "Learning Implicit Text Generation via Feature Matching", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative feature matching network (GFMN) is an approach for training\nimplicit generative models for images by performing moment matching on features\nfrom pre-trained neural networks. In this paper, we present new GFMN\nformulations that are effective for sequential data. Our experimental results\nshow the effectiveness of the proposed method, SeqGFMN, for three distinct\ngeneration tasks in English: unconditional text generation, class-conditional\ntext generation, and unsupervised text style transfer. SeqGFMN is stable to\ntrain and outperforms various adversarial approaches for text generation and\ntext style transfer.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 16:16:24 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 00:17:49 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Padhi", "Inkit", ""], ["Dognin", "Pierre", ""], ["Bai", "Ke", ""], ["Santos", "Cicero Nogueira dos", ""], ["Chenthamarakshan", "Vijil", ""], ["Mroueh", "Youssef", ""], ["Das", "Payel", ""]]}, {"id": "2005.03596", "submitter": "Khemraj Shukla", "authors": "Khemraj Shukla, Patricio Clark Di Leoni, James Blackshire, Daniel\n  Sparkman and George Em Karniadakis", "title": "Physics-informed neural network for ultrasound nondestructive\n  quantification of surface breaking cracks", "comments": "19 pages, 12 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an optimized physics-informed neural network (PINN) trained to\nsolve the problem of identifying and characterizing a surface breaking crack in\na metal plate. PINNs are neural networks that can combine data and physics in\nthe learning process by adding the residuals of a system of Partial\nDifferential Equations to the loss function. Our PINN is supervised with\nrealistic ultrasonic surface acoustic wave data acquired at a frequency of 5\nMHz. The ultrasonic surface wave data is represented as a surface deformation\non the top surface of a metal plate, measured by using the method of laser\nvibrometry. The PINN is physically informed by the acoustic wave equation and\nits convergence is sped up using adaptive activation functions. The adaptive\nactivation function uses a scalable hyperparameter in the activation function,\nwhich is optimized to achieve best performance of the network as it changes\ndynamically the topology of the loss function involved in the optimization\nprocess. The usage of adaptive activation function significantly improves the\nconvergence, notably observed in the current study. We use PINNs to estimate\nthe speed of sound of the metal plate, which we do with an error of 1\\%, and\nthen, by allowing the speed of sound to be space dependent, we identify and\ncharacterize the crack as the positions where the speed of sound has decreased.\nOur study also shows the effect of sub-sampling of the data on the sensitivity\nof sound speed estimates. More broadly, the resulting model shows a promising\ndeep neural network model for ill-posed inverse problems.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 16:32:11 GMT"}], "update_date": "2020-05-09", "authors_parsed": [["Shukla", "Khemraj", ""], ["Di Leoni", "Patricio Clark", ""], ["Blackshire", "James", ""], ["Sparkman", "Daniel", ""], ["Karniadakis", "George Em", ""]]}, {"id": "2005.03597", "submitter": "Kai Jia", "authors": "Kai Jia, Martin Rinard", "title": "Efficient Exact Verification of Binarized Neural Networks", "comments": "To be published in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.LO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concerned with the reliability of neural networks, researchers have developed\nverification techniques to prove their robustness. Most verifiers work with\nreal-valued networks. Unfortunately, the exact (complete and sound) verifiers\nface scalability challenges and provide no correctness guarantees due to\nfloating point errors. We argue that Binarized Neural Networks (BNNs) provide\ncomparable robustness and allow exact and significantly more efficient\nverification. We present a new system, EEV, for efficient and exact\nverification of BNNs. EEV consists of two parts: (i) a novel SAT solver that\nspeeds up BNN verification by natively handling the reified cardinality\nconstraints arising in BNN encodings; and (ii) strategies to train\nsolver-friendly robust BNNs by inducing balanced layer-wise sparsity and low\ncardinality bounds, and adaptively cancelling the gradients. We demonstrate the\neffectiveness of EEV by presenting the first exact verification results for\nL-inf-bounded adversarial robustness of nontrivial convolutional BNNs on the\nMNIST and CIFAR10 datasets. Compared to exact verification of real-valued\nnetworks of the same architectures on the same tasks, EEV verifies BNNs\nhundreds to thousands of times faster, while delivering comparable verifiable\naccuracy in most cases.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 16:34:30 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 04:00:16 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Jia", "Kai", ""], ["Rinard", "Martin", ""]]}, {"id": "2005.03622", "submitter": "Alex Dytso", "authors": "Wei Cao, Alex Dytso, Michael Fau{\\ss}, H. Vincent Poor, and Gang Feng", "title": "Nonparametric Estimation of the Fisher Information and Its Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of estimation of the Fisher information for\nlocation from a random sample of size $n$. First, an estimator proposed by\nBhattacharya is revisited and improved convergence rates are derived. Second, a\nnew estimator, termed a clipped estimator, is proposed. Superior upper bounds\non the rates of convergence can be shown for the new estimator compared to the\nBhattacharya estimator, albeit with different regularity conditions. Third,\nboth of the estimators are evaluated for the practically relevant case of a\nrandom variable contaminated by Gaussian noise. Moreover, using Brown's\nidentity, which relates the Fisher information and the minimum mean squared\nerror (MMSE) in Gaussian noise, two corresponding consistent estimators for the\nMMSE are proposed. Simulation examples for the Bhattacharya estimator and the\nclipped estimator as well as the MMSE estimators are presented. The examples\ndemonstrate that the clipped estimator can significantly reduce the required\nsample size to guarantee a specific confidence interval compared to the\nBhattacharya estimator.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 17:21:56 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Cao", "Wei", ""], ["Dytso", "Alex", ""], ["Fau\u00df", "Michael", ""], ["Poor", "H. Vincent", ""], ["Feng", "Gang", ""]]}, {"id": "2005.03624", "submitter": "Thanh Nguyen", "authors": "Thanh V. Nguyen, Nikhil Rao and Karthik Subbian", "title": "Learning Robust Models for e-Commerce Product Search", "comments": "This work has been accepted for publication at ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Showing items that do not match search query intent degrades customer\nexperience in e-commerce. These mismatches result from counterfactual biases of\nthe ranking algorithms toward noisy behavioral signals such as clicks and\npurchases in the search logs. Mitigating the problem requires a large labeled\ndataset, which is expensive and time-consuming to obtain. In this paper, we\ndevelop a deep, end-to-end model that learns to effectively classify mismatches\nand to generate hard mismatched examples to improve the classifier. We train\nthe model end-to-end by introducing a latent variable into the cross-entropy\nloss that alternates between using the real and generated samples. This not\nonly makes the classifier more robust but also boosts the overall ranking\nperformance. Our model achieves a relative gain compared to baselines by over\n26% in F-score, and over 17% in Area Under PR curve. On live search traffic,\nour model gains significant improvement in multiple countries.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 17:22:21 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Nguyen", "Thanh V.", ""], ["Rao", "Nikhil", ""], ["Subbian", "Karthik", ""]]}, {"id": "2005.03626", "submitter": "Antonio Busson", "authors": "Antonio Jos\\'e G. Busson, S\\'ergio Colcher, Ruy Luiz Milidi\\'u, Bruno\n  Pereira Dias, and Andr\\'e Bulc\\~ao", "title": "Seismic Shot Gather Noise Localization Using a Multi-Scale\n  Feature-Fusion-Based Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning-based models, such as convolutional neural networks, have\nadvanced various segments of computer vision. However, this technology is\nrarely applied to seismic shot gather noise localization problem. This letter\npresents an investigation on the effectiveness of a multi-scale\nfeature-fusion-based network for seismic shot-gather noise localization.\nHerein, we describe the following: (1) the construction of a real-world dataset\nof seismic noise localization based on 6,500 seismograms; (2) a multi-scale\nfeature-fusion-based detector that uses the MobileNet combined with the Feature\nPyramid Net as the backbone; and (3) the Single Shot multi-box detector for box\nclassification/regression. Additionally, we propose the use of the Focal Loss\nfunction that improves the detector's prediction accuracy. The proposed\ndetector achieves an AP@0.5 of 78.67\\% in our empirical evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 17:23:55 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Busson", "Antonio Jos\u00e9 G.", ""], ["Colcher", "S\u00e9rgio", ""], ["Milidi\u00fa", "Ruy Luiz", ""], ["Dias", "Bruno Pereira", ""], ["Bulc\u00e3o", "Andr\u00e9", ""]]}, {"id": "2005.03632", "submitter": "Sreejita Ghosh", "authors": "Sreejita Ghosh, Peter Tino, Kerstin Bunte", "title": "Visualisation and knowledge discovery from interpretable models", "comments": "Accepted for proceedings of the International Joint Conference on\n  Neural Networks (IJCNN) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing number of sectors which affect human lives, are using Machine\nLearning (ML) tools. Hence the need for understanding their working mechanism\nand evaluating their fairness in decision-making, are becoming paramount,\nushering in the era of Explainable AI (XAI). In this contribution we introduced\na few intrinsically interpretable models which are also capable of dealing with\nmissing values, in addition to extracting knowledge from the dataset and about\nthe problem. These models are also capable of visualisation of the classifier\nand decision boundaries: they are the angle based variants of Learning Vector\nQuantization. We have demonstrated the algorithms on a synthetic dataset and a\nreal-world one (heart disease dataset from the UCI repository). The newly\ndeveloped classifiers helped in investigating the complexities of the UCI\ndataset as a multiclass problem. The performance of the developed classifiers\nwere comparable to those reported in literature for this dataset, with\nadditional value of interpretability, when the dataset was treated as a binary\nclass problem.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 17:37:06 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 08:22:02 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Ghosh", "Sreejita", ""], ["Tino", "Peter", ""], ["Bunte", "Kerstin", ""]]}, {"id": "2005.03633", "submitter": "Haiwei Wu", "authors": "Haiwei Wu, Yan Jia, Yuanfei Nie, Ming Li", "title": "Domain Aware Training for Far-field Small-footprint Keyword Spotting", "comments": "Submitted to INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the task of small-footprint keyword spotting under\nthe far-field scenario. Far-field environments are commonly encountered in\nreal-life speech applications, causing severe degradation of performance due to\nroom reverberation and various kinds of noises. Our baseline system is built on\nthe convolutional neural network trained with pooled data of both far-field and\nclose-talking speech. To cope with the distortions, we develop three domain\naware training systems, including the domain embedding system, the deep CORAL\nsystem, and the multi-task learning system. These methods incorporate domain\nknowledge into network training and improve the performance of the keyword\nclassifier on far-field conditions. Experimental results show that our proposed\nmethods manage to maintain the performance on the close-talking speech and\nachieve significant improvement on the far-field test set.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 17:38:39 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 15:37:47 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 16:19:46 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Wu", "Haiwei", ""], ["Jia", "Yan", ""], ["Nie", "Yuanfei", ""], ["Li", "Ming", ""]]}, {"id": "2005.03645", "submitter": "Kevin Fauvel", "authors": "Kevin Fauvel, \\'Elisa Fromont, V\\'eronique Masson, Philippe Faverdin,\n  Alexandre Termier", "title": "XEM: An Explainable Ensemble Method for Multivariate Time Series\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present XEM, an eXplainable Ensemble method for Multivariate time series\nclassification. XEM relies on a new hybrid ensemble method that combines an\nexplicit boosting-bagging approach to handle the bias-variance trade-off faced\nby machine learning models and an implicit divide-and-conquer approach to\nindividualize classifier errors on different parts of the training data. Our\nevaluation shows that XEM outperforms the state-of-the-art MTS classifiers on\nthe UEA datasets. Furthermore, XEM provides faithful explainability by design\nand manifests robust performance when faced with challenges arising from\ncontinuous data collection (different MTS length, missing data and noise).\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 17:50:18 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 10:09:47 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 09:09:51 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2020 07:55:40 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Fauvel", "Kevin", ""], ["Fromont", "\u00c9lisa", ""], ["Masson", "V\u00e9ronique", ""], ["Faverdin", "Philippe", ""], ["Termier", "Alexandre", ""]]}, {"id": "2005.03648", "submitter": "Ge Yang", "authors": "Ge Yang, Amy Zhang, Ari S. Morcos, Joelle Pineau, Pieter Abbeel,\n  Roberto Calandra", "title": "Plan2Vec: Unsupervised Representation Learning by Latent Plans", "comments": "code available at https://geyang.github.io/plan2vec", "journal-ref": "Proceedings of Machine Learning Research, the 2nd Annual\n  Conference on Learning for Dynamics and Control (2020) Volume 120, 1-12", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce plan2vec, an unsupervised representation learning\napproach that is inspired by reinforcement learning. Plan2vec constructs a\nweighted graph on an image dataset using near-neighbor distances, and then\nextrapolates this local metric to a global embedding by distilling\npath-integral over planned path. When applied to control, plan2vec offers a way\nto learn goal-conditioned value estimates that are accurate over long horizons\nthat is both compute and sample efficient. We demonstrate the effectiveness of\nplan2vec on one simulated and two challenging real-world image datasets.\nExperimental results show that plan2vec successfully amortizes the planning\ncost, enabling reactive planning that is linear in memory and computation\ncomplexity rather than exhaustive over the entire state space.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 17:52:23 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Yang", "Ge", ""], ["Zhang", "Amy", ""], ["Morcos", "Ari S.", ""], ["Pineau", "Joelle", ""], ["Abbeel", "Pieter", ""], ["Calandra", "Roberto", ""]]}, {"id": "2005.03654", "submitter": "Elena Ericheva", "authors": "Ivan Drokin, Elena Ericheva", "title": "Deep Learning on Point Clouds for False Positive Reduction at Nodule\n  Detection in Chest CT Scans", "comments": null, "journal-ref": "In: van der Aalst W.M.P. et al. (eds) Analysis of Images, Social\n  Networks and Texts. AIST 2020. Lecture Notes in Computer Science, vol 12602.\n  Springer, Cham", "doi": "10.1007/978-3-030-72610-2_15", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on a novel approach for false-positive reduction (FPR) of\nnodule candidates in Computer-aided detection (CADe) systems following the\nsuspicious lesions detection stage. Contrary to typical decisions in medical\nimage analysis, the proposed approach considers input data not as a 2D or 3D\nimage, but rather as a point cloud, and uses deep learning models for point\nclouds. We discovered that point cloud models require less memory and are\nfaster both in training and inference compared to traditional CNN 3D, they\nachieve better performance and do not impose restrictions on the size of the\ninput image, i.e. no restrictions on the size of the nodule candidate. We\npropose an algorithm for transforming 3D CT scan data to point cloud. In some\ncases, the volume of the nodule candidate can be much smaller than the\nsurrounding context, for example, in the case of subpleural localization of the\nnodule. Therefore, we developed an algorithm for sampling points from a point\ncloud constructed from a 3D image of the candidate region. The algorithm is\nable to guarantee the capture of both context and candidate information as part\nof the point cloud of the nodule candidate. We designed and set up an\nexperiment in creating a dataset from an open LIDC-IDRI database for a feature\nof the FPR task, and is herein described in detail. Data augmentation was\napplied both to avoid overfitting and as an upsampling method. Experiments were\nconducted with PointNet, PointNet++, and DGCNN. We show that the proposed\napproach outperforms baseline CNN 3D models and resulted in 85.98 FROC versus\n77.26 FROC for baseline models. We compare our algorithm with published SOTA\nand demonstrate that even without significant modifications it works at the\nappropriate performance level on LUNA2016 and shows SOTA on LIDC-IDRI.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 17:59:54 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 08:31:26 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Drokin", "Ivan", ""], ["Ericheva", "Elena", ""]]}, {"id": "2005.03675", "submitter": "Ines Chami", "authors": "Ines Chami, Sami Abu-El-Haija, Bryan Perozzi, Christopher R\\'e, Kevin\n  Murphy", "title": "Machine Learning on Graphs: A Model and Comprehensive Taxonomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a surge of recent interest in learning representations for\ngraph-structured data. Graph representation learning methods have generally\nfallen into three main categories, based on the availability of labeled data.\nThe first, network embedding (such as shallow graph embedding or graph\nauto-encoders), focuses on learning unsupervised representations of relational\nstructure. The second, graph regularized neural networks, leverages graphs to\naugment neural network losses with a regularization objective for\nsemi-supervised learning. The third, graph neural networks, aims to learn\ndifferentiable functions over discrete topologies with arbitrary structure.\nHowever, despite the popularity of these areas there has been surprisingly\nlittle work on unifying the three paradigms. Here, we aim to bridge the gap\nbetween graph neural networks, network embedding and graph regularization\nmodels. We propose a comprehensive taxonomy of representation learning methods\nfor graph-structured data, aiming to unify several disparate bodies of work.\nSpecifically, we propose a Graph Encoder Decoder Model (GRAPHEDM), which\ngeneralizes popular algorithms for semi-supervised learning on graphs (e.g.\nGraphSage, Graph Convolutional Networks, Graph Attention Networks), and\nunsupervised learning of graph representations (e.g. DeepWalk, node2vec, etc)\ninto a single consistent approach. To illustrate the generality of this\napproach, we fit over thirty existing methods into this framework. We believe\nthat this unifying view both provides a solid foundation for understanding the\nintuition behind these methods, and enables future research in the area.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 18:00:02 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 15:41:03 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Chami", "Ines", ""], ["Abu-El-Haija", "Sami", ""], ["Perozzi", "Bryan", ""], ["R\u00e9", "Christopher", ""], ["Murphy", "Kevin", ""]]}, {"id": "2005.03687", "submitter": "Rajiv Ratn Shah", "authors": "Vishaal Udandarao, Abhishek Maiti, Deepak Srivatsav, Suryatej Reddy\n  Vyalla, Yifang Yin, Rajiv Ratn Shah", "title": "COBRA: Contrastive Bi-Modal Representation Algorithm", "comments": "13 Pages, 6 Figures and 10 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are a wide range of applications that involve multi-modal data, such as\ncross-modal retrieval, visual question-answering, and image captioning. Such\napplications are primarily dependent on aligned distributions of the different\nconstituent modalities. Existing approaches generate latent embeddings for each\nmodality in a joint fashion by representing them in a common manifold. However\nthese joint embedding spaces fail to sufficiently reduce the modality gap,\nwhich affects the performance in downstream tasks. We hypothesize that these\nembeddings retain the intra-class relationships but are unable to preserve the\ninter-class dynamics. In this paper, we present a novel framework COBRA that\naims to train two modalities (image and text) in a joint fashion inspired by\nthe Contrastive Predictive Coding (CPC) and Noise Contrastive Estimation (NCE)\nparadigms which preserve both inter and intra-class relationships. We\nempirically show that this framework reduces the modality gap significantly and\ngenerates a robust and task agnostic joint-embedding space. We outperform\nexisting work on four diverse downstream tasks spanning across seven benchmark\ncross-modal datasets.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 18:20:12 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 20:07:52 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Udandarao", "Vishaal", ""], ["Maiti", "Abhishek", ""], ["Srivatsav", "Deepak", ""], ["Vyalla", "Suryatej Reddy", ""], ["Yin", "Yifang", ""], ["Shah", "Rajiv Ratn", ""]]}, {"id": "2005.03709", "submitter": "Takato Otsuzuki", "authors": "Takato Otsuzuki, Hideaki Hayashi, Yuchen Zheng and Seiichi Uchida", "title": "Regularized Pooling", "comments": "12 pages, 10 figures, accepted for ICANN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In convolutional neural networks (CNNs), pooling operations play important\nroles such as dimensionality reduction and deformation compensation. In\ngeneral, max pooling, which is the most widely used operation for local\npooling, is performed independently for each kernel. However, the deformation\nmay be spatially smooth over the neighboring kernels. This means that max\npooling is too flexible to compensate for actual deformations. In other words,\nits excessive flexibility risks canceling the essential spatial differences\nbetween classes. In this paper, we propose regularized pooling, which enables\nthe value selection direction in the pooling operation to be spatially smooth\nacross adjacent kernels so as to compensate only for actual deformations. The\nresults of experiments on handwritten character images and texture images\nshowed that regularized pooling not only improves recognition accuracy but also\naccelerates the convergence of learning compared with conventional pooling\noperations.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 09:02:17 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 07:10:34 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Otsuzuki", "Takato", ""], ["Hayashi", "Hideaki", ""], ["Zheng", "Yuchen", ""], ["Uchida", "Seiichi", ""]]}, {"id": "2005.03718", "submitter": "Sami Khairy", "authors": "Sami Khairy, Prasanna Balaprakash, Lin X. Cai", "title": "A Gradient-Aware Search Algorithm for Constrained Markov Decision\n  Processes", "comments": "Submitted as a brief paper to the IEEE TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The canonical solution methodology for finite constrained Markov decision\nprocesses (CMDPs), where the objective is to maximize the expected\ninfinite-horizon discounted rewards subject to the expected infinite-horizon\ndiscounted costs constraints, is based on convex linear programming. In this\nbrief, we first prove that the optimization objective in the dual linear\nprogram of a finite CMDP is a piece-wise linear convex function (PWLC) with\nrespect to the Lagrange penalty multipliers. Next, we propose a novel two-level\nGradient-Aware Search (GAS) algorithm which exploits the PWLC structure to find\nthe optimal state-value function and Lagrange penalty multipliers of a finite\nCMDP. The proposed algorithm is applied in two stochastic control problems with\nconstraints: robot navigation in a grid world and solar-powered unmanned aerial\nvehicle (UAV)-based wireless network management. We empirically compare the\nconvergence performance of the proposed GAS algorithm with binary search (BS),\nLagrangian primal-dual optimization (PDO), and Linear Programming (LP).\nCompared with benchmark algorithms, it is shown that the proposed GAS algorithm\nconverges to the optimal solution faster, does not require hyper-parameter\ntuning, and is not sensitive to initialization of the Lagrange penalty\nmultiplier.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 19:38:09 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Khairy", "Sami", ""], ["Balaprakash", "Prasanna", ""], ["Cai", "Lin X.", ""]]}, {"id": "2005.03725", "submitter": "Martin Wainwright", "authors": "Max Rabinovich and Michael I. Jordan and Martin J. Wainwright", "title": "Lower bounds in multiple testing: A framework based on derandomized\n  proxies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large bulk of work in multiple testing has focused on specifying\nprocedures that control the false discovery rate (FDR), with relatively less\nattention being paid to the corresponding Type II error known as the false\nnon-discovery rate (FNR). A line of more recent work in multiple testing has\nbegun to investigate the tradeoffs between the FDR and FNR and to provide lower\nbounds on the performance of procedures that depend on the model structure.\nLacking thus far, however, has been a general approach to obtaining lower\nbounds for a broad class of models. This paper introduces an analysis strategy\nbased on derandomization, illustrated by applications to various concrete\nmodels. Our main result is meta-theorem that gives a general recipe for\nobtaining lower bounds on the combination of FDR and FNR. We illustrate this\nmeta-theorem by deriving explicit bounds for several models, including\ninstances with dependence, scale-transformed alternatives, and\nnon-Gaussian-like distributions. We provide numerical simulations of some of\nthese lower bounds, and show a close relation to the actual performance of the\nBenjamini-Hochberg (BH) algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 19:59:51 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Rabinovich", "Max", ""], ["Jordan", "Michael I.", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "2005.03730", "submitter": "Johan Larsson", "authors": "Johan Larsson, Ma{\\l}gorzata Bogdan, Jonas Wallin", "title": "The Strong Screening Rule for SLOPE", "comments": "15 pages, 5 figures", "journal-ref": "Advances in Neural Information Processing Systems 33, 2020, p.\n  14592-14603", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting relevant features from data sets where the number of observations\n($n$) is much smaller then the number of predictors ($p$) is a major challenge\nin modern statistics. Sorted L-One Penalized Estimation (SLOPE), a\ngeneralization of the lasso, is a promising method within this setting. Current\nnumerical procedures for SLOPE, however, lack the efficiency that respective\ntools for the lasso enjoy, particularly in the context of estimating a complete\nregularization path. A key component in the efficiency of the lasso is\npredictor screening rules: rules that allow predictors to be discarded before\nestimating the model. This is the first paper to establish such a rule for\nSLOPE. We develop a screening rule for SLOPE by examining its subdifferential\nand show that this rule is a generalization of the strong rule for the lasso.\nOur rule is heuristic, which means that it may discard predictors erroneously.\nWe present conditions under which this may happen and show that such situations\nare rare and easily safeguarded against by a simple check of the optimality\nconditions. Our numerical experiments show that the rule performs well in\npractice, leading to improvements by orders of magnitude for data in the $p \\gg\nn$ domain, as well as incurring no additional computational overhead when $n\n\\gg p$. We also examine the effect of correlation structures in the design\nmatrix on the rule and discuss algorithmic strategies for employing the rule.\nFinally, we provide an efficient implementation of the rule in our R package\nSLOPE.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 20:14:20 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 18:17:19 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Larsson", "Johan", ""], ["Bogdan", "Ma\u0142gorzata", ""], ["Wallin", "Jonas", ""]]}, {"id": "2005.03750", "submitter": "James P. Crutchfield", "authors": "S. E. Marzen and J. P. Crutchfield", "title": "Inference, Prediction, and Entropy-Rate Estimation of Continuous-time,\n  Discrete-event Processes", "comments": "11 pages, 5 figures;\n  http://csc.ucdavis.edu/~cmg/compmech/pubs/ctbsi.htm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.IT cs.LG math.IT nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring models, predicting the future, and estimating the entropy rate of\ndiscrete-time, discrete-event processes is well-worn ground. However, a much\nbroader class of discrete-event processes operates in continuous-time. Here, we\nprovide new methods for inferring, predicting, and estimating them. The methods\nrely on an extension of Bayesian structural inference that takes advantage of\nneural network's universal approximation power. Based on experiments with\ncomplex synthetic data, the methods are competitive with the state-of-the-art\nfor prediction and entropy-rate estimation.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 20:54:19 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Marzen", "S. E.", ""], ["Crutchfield", "J. P.", ""]]}, {"id": "2005.03759", "submitter": "Arash Rabbani", "authors": "Arash Rabbani, Masoud Babaei, Reza Shams, Ying Da Wang, Traiwit Chung", "title": "DeePore: a deep learning workflow for rapid and comprehensive\n  characterization of porous materials", "comments": null, "journal-ref": "Advances in Water Resources, 2020, 103787", "doi": "10.1016/j.advwatres.2020.103787", "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DeePore is a deep learning workflow for rapid estimation of a wide range of\nporous material properties based on the binarized micro-tomography images. By\ncombining naturally occurring porous textures we generated 17700 semi-real 3-D\nmicro-structures of porous geo-materials with size of 256^3 voxels and 30\nphysical properties of each sample are calculated using physical simulations on\nthe corresponding pore network models. Next, a designed feed-forward\nconvolutional neural network (CNN) is trained based on the dataset to estimate\nseveral morphological, hydraulic, electrical, and mechanical characteristics of\nthe porous material in a fraction of a second. In order to fine-tune the CNN\ndesign, we tested 9 different training scenarios and selected the one with the\nhighest average coefficient of determination (R^2) equal to 0.885 for 1418\ntesting samples. Additionally, 3 independent synthetic images as well as 3\nrealistic tomography images have been tested using the proposed method and\nresults are compared with pore network modelling and experimental data,\nrespectively. Tested absolute permeabilities had around 13 % relative error\ncompared to the experimental data which is noticeable considering the accuracy\nof the direct numerical simulation methods such as Lattice Boltzmann and Finite\nVolume. The workflow is compatible with any physical size of the images due to\nits dimensionless approach and can be used to characterize large-scale 3-D\nimages by averaging the model outputs for a sliding window that scans the whole\ngeometry.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 08:46:09 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 09:06:32 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Rabbani", "Arash", ""], ["Babaei", "Masoud", ""], ["Shams", "Reza", ""], ["Da Wang", "Ying", ""], ["Chung", "Traiwit", ""]]}, {"id": "2005.03767", "submitter": "Han Bao", "authors": "Han Bao, Jinyong Feng, Nam Dinh, Hongbin Zhang", "title": "Deep Learning Interfacial Momentum Closures in Coarse-Mesh CFD Two-Phase\n  Flow Simulation Using Validation Data", "comments": "This paper has been submitted to International Journal of Multi-phase\n  Flow", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiphase flow phenomena have been widely observed in the industrial\napplications, yet it remains a challenging unsolved problem. Three-dimensional\ncomputational fluid dynamics (CFD) approaches resolve of the flow fields on\nfiner spatial and temporal scales, which can complement dedicated experimental\nstudy. However, closures must be introduced to reflect the underlying physics\nin multiphase flow. Among them, the interfacial forces, including drag, lift,\nturbulent-dispersion and wall-lubrication forces, play an important role in\nbubble distribution and migration in liquid-vapor two-phase flows. Development\nof those closures traditionally rely on the experimental data and analytical\nderivation with simplified assumptions that usually cannot deliver a universal\nsolution across a wide range of flow conditions. In this paper, a data-driven\napproach, named as feature-similarity measurement (FSM), is developed and\napplied to improve the simulation capability of two-phase flow with coarse-mesh\nCFD approach. Interfacial momentum transfer in adiabatic bubbly flow serves as\nthe focus of the present study. Both a mature and a simplified set of\ninterfacial closures are taken as the low-fidelity data. Validation data\n(including relevant experimental data and validated fine-mesh CFD simulations\nresults) are adopted as high-fidelity data. Qualitative and quantitative\nanalysis are performed in this paper. These reveal that FSM can substantially\nimprove the prediction of the coarse-mesh CFD model, regardless of the choice\nof interfacial closures, and it provides scalability and consistency across\ndiscontinuous flow regimes. It demonstrates that data-driven methods can aid\nthe multiphase flow modeling by exploring the connections between local\nphysical features and simulation errors.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 21:25:22 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Bao", "Han", ""], ["Feng", "Jinyong", ""], ["Dinh", "Nam", ""], ["Zhang", "Hongbin", ""]]}, {"id": "2005.03769", "submitter": "Yang Li", "authors": "Yang Li and Jinqiao Duan", "title": "A Data-Driven Approach for Discovering Stochastic Dynamical Systems with\n  Non-Gaussian Levy Noise", "comments": "36 pages", "journal-ref": null, "doi": "10.1016/j.physd.2020.132830", "report-no": null, "categories": "stat.ML cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid increase of valuable observational, experimental and\nsimulating data for complex systems, great efforts are being devoted to\ndiscovering governing laws underlying the evolution of these systems. However,\nthe existing techniques are limited to extract governing laws from data as\neither deterministic differential equations or stochastic differential\nequations with Gaussian noise. In the present work, we develop a new\ndata-driven approach to extract stochastic dynamical systems with non-Gaussian\nsymmetric L\\'evy noise, as well as Gaussian noise. First, we establish a\nfeasible theoretical framework, by expressing the drift coefficient, diffusion\ncoefficient and jump measure (i.e., anomalous diffusion) for the underlying\nstochastic dynamical system in terms of sample paths data. We then design a\nnumerical algorithm to compute the drift, diffusion coefficient and jump\nmeasure, and thus extract a governing stochastic differential equation with\nGaussian and non-Gaussian noise. Finally, we demonstrate the efficacy and\naccuracy of our approach by applying to several prototypical one-, two- and\nthree-dimensional systems. This new approach will become a tool in discovering\ngoverning dynamical laws from noisy data sets, from observing or simulating\ncomplex phenomena, such as rare events triggered by random fluctuations with\nheavy as well as light tail statistical features.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 21:29:17 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 02:18:17 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Li", "Yang", ""], ["Duan", "Jinqiao", ""]]}, {"id": "2005.03770", "submitter": "Jan Achterhold", "authors": "Nathanael Bosch, Jan Achterhold, Laura Leal-Taix\\'e, J\\\"org St\\\"uckler", "title": "Planning from Images with Deep Latent Gaussian Process Dynamics", "comments": "Accepted for publication at the 2nd Annual Conference on Learning for\n  Dynamics and Control (L4DC) 2020, with supplementary material. First two\n  authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning is a powerful approach to control problems with known environment\ndynamics. In unknown environments the agent needs to learn a model of the\nsystem dynamics to make planning applicable. This is particularly challenging\nwhen the underlying states are only indirectly observable through images. We\npropose to learn a deep latent Gaussian process dynamics (DLGPD) model that\nlearns low-dimensional system dynamics from environment interactions with\nvisual observations. The method infers latent state representations from\nobservations using neural networks and models the system dynamics in the\nlearned latent space with Gaussian processes. All parts of the model can be\ntrained jointly by optimizing a lower bound on the likelihood of transitions in\nimage space. We evaluate the proposed approach on the pendulum swing-up task\nwhile using the learned dynamics model for planning in latent space in order to\nsolve the control problem. We also demonstrate that our method can quickly\nadapt a trained agent to changes in the system dynamics from just a few\nrollouts. We compare our approach to a state-of-the-art purely deep learning\nbased method and demonstrate the advantages of combining Gaussian processes\nwith deep learning for data efficiency and transfer learning.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 21:29:45 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Bosch", "Nathanael", ""], ["Achterhold", "Jan", ""], ["Leal-Taix\u00e9", "Laura", ""], ["St\u00fcckler", "J\u00f6rg", ""]]}, {"id": "2005.03773", "submitter": "Ramiro Camino", "authors": "Ramiro Camino, Christian Hammerschmidt, Radu State", "title": "Minority Class Oversampling for Tabular Data with Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practice, machine learning experts are often confronted with imbalanced\ndata. Without accounting for the imbalance, common classifiers perform poorly\nand standard evaluation metrics mislead the practitioners on the model's\nperformance. A common method to treat imbalanced datasets is under- and\noversampling. In this process, samples are either removed from the majority\nclass or synthetic samples are added to the minority class. In this paper, we\nfollow up on recent developments in deep learning. We take proposals of deep\ngenerative models, including our own, and study the ability of these approaches\nto provide realistic samples that improve performance on imbalanced\nclassification tasks via oversampling.\n  Across 160K+ experiments, we show that all of the new methods tend to perform\nbetter than simple baseline methods such as SMOTE, but require different under-\nand oversampling ratios to do so. Our experiments show that the way the method\nof sampling does not affect quality, but runtime varies widely. We also observe\nthat the improvements in terms of performance metric, while shown to be\nsignificant when ranking the methods, often are minor in absolute terms,\nespecially compared to the required effort. Furthermore, we notice that a large\npart of the improvement is due to undersampling, not oversampling. We make our\ncode and testing framework available.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 21:35:57 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 13:59:10 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Camino", "Ramiro", ""], ["Hammerschmidt", "Christian", ""], ["State", "Radu", ""]]}, {"id": "2005.03776", "submitter": "Yang Li", "authors": "Yang Li and Jiacong He and Xin Zhou and Yuan Zhang and Jason Baldridge", "title": "Mapping Natural Language Instructions to Mobile UI Action Sequences", "comments": "Annual Conference of the Association for Computational Linguistics\n  (ACL 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new problem: grounding natural language instructions to mobile\nuser interface actions, and create three new datasets for it. For full task\nevaluation, we create PIXELHELP, a corpus that pairs English instructions with\nactions performed by people on a mobile UI emulator. To scale training, we\ndecouple the language and action data by (a) annotating action phrase spans in\nHowTo instructions and (b) synthesizing grounded descriptions of actions for\nmobile user interfaces. We use a Transformer to extract action phrase tuples\nfrom long-range natural language instructions. A grounding Transformer then\ncontextually represents UI objects using both their content and screen position\nand connects them to object descriptions. Given a starting screen and\ninstruction, our model achieves 70.59% accuracy on predicting complete\nground-truth action sequences in PIXELHELP.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 21:41:40 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 02:11:56 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Li", "Yang", ""], ["He", "Jiacong", ""], ["Zhou", "Xin", ""], ["Zhang", "Yuan", ""], ["Baldridge", "Jason", ""]]}, {"id": "2005.03778", "submitter": "Qiang Lu", "authors": "Guodong Rong, Byung Hyun Shin, Hadi Tabatabaee, Qiang Lu, Steve Lemke,\n  M\\=arti\\c{n}\\v{s} Mo\\v{z}eiko, Eric Boise, Geehoon Uhm, Mark Gerow, Shalin\n  Mehta, Eugene Agafonov, Tae Hyung Kim, Eric Sterner, Keunhae Ushiroda,\n  Michael Reyes, Dmitry Zelenkovsky, Seonman Kim", "title": "LGSVL Simulator: A High Fidelity Simulator for Autonomous Driving", "comments": "6 pages, 7 figures, ITSC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing autonomous driving algorithms on real autonomous vehicles is\nextremely costly and many researchers and developers in the field cannot afford\na real car and the corresponding sensors. Although several free and open-source\nautonomous driving stacks, such as Autoware and Apollo are available, choices\nof open-source simulators to use with them are limited. In this paper, we\nintroduce the LGSVL Simulator which is a high fidelity simulator for autonomous\ndriving. The simulator engine provides end-to-end, full-stack simulation which\nis ready to be hooked up to Autoware and Apollo. In addition, simulator tools\nare provided with the core simulation engine which allow users to easily\ncustomize sensors, create new types of controllable objects, replace some\nmodules in the core simulator, and create digital twins of particular\nenvironments.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 21:57:19 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 17:44:06 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 00:47:14 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Rong", "Guodong", ""], ["Shin", "Byung Hyun", ""], ["Tabatabaee", "Hadi", ""], ["Lu", "Qiang", ""], ["Lemke", "Steve", ""], ["Mo\u017eeiko", "M\u0101rti\u0146\u0161", ""], ["Boise", "Eric", ""], ["Uhm", "Geehoon", ""], ["Gerow", "Mark", ""], ["Mehta", "Shalin", ""], ["Agafonov", "Eugene", ""], ["Kim", "Tae Hyung", ""], ["Sterner", "Eric", ""], ["Ushiroda", "Keunhae", ""], ["Reyes", "Michael", ""], ["Zelenkovsky", "Dmitry", ""], ["Kim", "Seonman", ""]]}, {"id": "2005.03780", "submitter": "Steven Reeves", "authors": "Steven I Reeves, Dongwook Lee, Anurag Singh, and Kunal Verma", "title": "A Gaussian Process Upsampling Model for Improvements in Optical\n  Character Recognition", "comments": "12 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical Character Recognition and extraction is a key tool in the automatic\nevaluation of documents in a financial context. However, the image data\nprovided to automated systems can have unreliable quality, and can be\ninherently low-resolution or downsampled and compressed by a transmitting\nprogram. In this paper, we illustrate the efficacy of a Gaussian Process\nupsampling model for the purposes of improving OCR and extraction through\nupsampling low resolution documents.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 22:13:22 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Reeves", "Steven I", ""], ["Lee", "Dongwook", ""], ["Singh", "Anurag", ""], ["Verma", "Kunal", ""]]}, {"id": "2005.03788", "submitter": "Xinshao Wang Dr", "authors": "Xinshao Wang, Yang Hua, Elyor Kodirov, David A. Clifton, Neil M.\n  Robertson", "title": "ProSelfLC: Progressive Self Label Correction for Training Robust Deep\n  Neural Networks", "comments": "ProSelfLC is the first method to trust self knowledge progressively\n  and adaptively. ProSelfLC redirects and promotes entropy minimisation, which\n  is in marked contrast to recent practices of confidence penalty [42, 33, 6]", "journal-ref": "CVPR 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  To train robust deep neural networks (DNNs), we systematically study several\ntarget modification approaches, which include output regularisation, self and\nnon-self label correction (LC). Two key issues are discovered: (1) Self LC is\nthe most appealing as it exploits its own knowledge and requires no extra\nmodels. However, how to automatically decide the trust degree of a learner as\ntraining goes is not well answered in the literature? (2) Some methods penalise\nwhile the others reward low-entropy predictions, prompting us to ask which one\nis better?\n  To resolve the first issue, taking two well-accepted propositions--deep\nneural networks learn meaningful patterns before fitting noise [3] and minimum\nentropy regularisation principle [10]--we propose a novel end-to-end method\nnamed ProSelfLC, which is designed according to learning time and entropy.\nSpecifically, given a data point, we progressively increase trust in its\npredicted label distribution versus its annotated one if a model has been\ntrained for enough time and the prediction is of low entropy (high confidence).\nFor the second issue, according to ProSelfLC, we empirically prove that it is\nbetter to redefine a meaningful low-entropy status and optimise the learner\ntoward it. This serves as a defence of entropy minimisation.\n  We demonstrate the effectiveness of ProSelfLC through extensive experiments\nin both clean and noisy settings. The source code is available at\nhttps://github.com/XinshaoAmosWang/ProSelfLC-CVPR2021.\n  Keywords: entropy minimisation, maximum entropy, confidence penalty, self\nknowledge distillation, label correction, label noise, semi-supervised\nlearning, output regularisation\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 22:35:04 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 22:10:17 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2020 13:36:09 GMT"}, {"version": "v4", "created": "Mon, 29 Jun 2020 11:04:32 GMT"}, {"version": "v5", "created": "Fri, 9 Oct 2020 12:45:28 GMT"}, {"version": "v6", "created": "Wed, 2 Jun 2021 12:27:53 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Wang", "Xinshao", ""], ["Hua", "Yang", ""], ["Kodirov", "Elyor", ""], ["Clifton", "David A.", ""], ["Robertson", "Neil M.", ""]]}, {"id": "2005.03789", "submitter": "Christoph Dann", "authors": "Christoph Dann, Yishay Mansour, Mehryar Mohri, Ayush Sekhari, Karthik\n  Sridharan", "title": "Reinforcement Learning with Feedback Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study episodic reinforcement learning in Markov decision processes when\nthe agent receives additional feedback per step in the form of several\ntransition observations. Such additional observations are available in a range\nof tasks through extended sensors or prior knowledge about the environment\n(e.g., when certain actions yield similar outcome). We formalize this setting\nusing a feedback graph over state-action pairs and show that model-based\nalgorithms can leverage the additional feedback for more sample-efficient\nlearning. We give a regret bound that, ignoring logarithmic factors and\nlower-order terms, depends only on the size of the maximum acyclic subgraph of\nthe feedback graph, in contrast with a polynomial dependency on the number of\nstates and actions in the absence of a feedback graph. Finally, we highlight\nchallenges when leveraging a small dominating set of the feedback graph as\ncompared to the bandit setting and propose a new algorithm that can use\nknowledge of such a dominating set for more sample-efficient learning of a\nnear-optimal policy.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 22:35:37 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Dann", "Christoph", ""], ["Mansour", "Yishay", ""], ["Mohri", "Mehryar", ""], ["Sekhari", "Ayush", ""], ["Sridharan", "Karthik", ""]]}, {"id": "2005.03793", "submitter": "Chenyou Fan", "authors": "Chenyou Fan, Ping Liu", "title": "Federated Generative Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies training generative adversarial networks under the\nfederated learning setting. Generative adversarial networks (GANs) have\nachieved advancement in various real-world applications, such as image editing,\nstyle transfer, scene generations, etc. However, like other deep learning\nmodels, GANs are also suffering from data limitation problems in real cases. To\nboost the performance of GANs in target tasks, collecting images as many as\npossible from different sources becomes not only important but also essential.\nFor example, to build a robust and accurate bio-metric verification system,\nhuge amounts of images might be collected from surveillance cameras, and/or\nuploaded from cellphones by users accepting agreements. In an ideal case,\nutilize all those data uploaded from public and private devices for model\ntraining is straightforward. Unfortunately, in the real scenarios, this is hard\ndue to a few reasons. At first, some data face the serious concern of leakage,\nand therefore it is prohibitive to upload them to a third-party server for\nmodel training; at second, the images collected by different kinds of devices,\nprobably have distinctive biases due to various factors, $\\textit{e.g.}$,\ncollector preferences, geo-location differences, which is also known as \"domain\nshift\". To handle those problems, we propose a novel generative learning scheme\nutilizing a federated learning framework. Following the configuration of\nfederated learning, we conduct model training and aggregation on one center and\na group of clients. Specifically, our method learns the distributed generative\nmodels in clients, while the models trained in each client are fused into one\nunified and versatile model in the center. We perform extensive experiments to\ncompare different federation strategies, and empirically examine the\neffectiveness of federation under different levels of parallelism and data\nskewness.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 23:06:49 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 14:35:27 GMT"}, {"version": "v3", "created": "Sun, 19 Jul 2020 05:02:05 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Fan", "Chenyou", ""], ["Liu", "Ping", ""]]}, {"id": "2005.03795", "submitter": "Anuradha Kar", "authors": "Anuradha Kar", "title": "MLGaze: Machine Learning-Based Analysis of Gaze Error Patterns in\n  Consumer Eye Tracking Systems", "comments": "https://github.com/anuradhakar49/MLGaze", "journal-ref": null, "doi": "10.3390/vision4020025", "report-no": null, "categories": "eess.SP cs.CV cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Analyzing the gaze accuracy characteristics of an eye tracker is a critical\ntask as its gaze data is frequently affected by non-ideal operating conditions\nin various consumer eye tracking applications. In this study, gaze error\npatterns produced by a commercial eye tracking device were studied with the\nhelp of machine learning algorithms, such as classifiers and regression models.\nGaze data were collected from a group of participants under multiple conditions\nthat commonly affect eye trackers operating on desktop and handheld platforms.\nThese conditions (referred here as error sources) include user distance, head\npose, and eye-tracker pose variations, and the collected gaze data were used to\ntrain the classifier and regression models. It was seen that while the impact\nof the different error sources on gaze data characteristics were nearly\nimpossible to distinguish by visual inspection or from data statistics, machine\nlearning models were successful in identifying the impact of the different\nerror sources and predicting the variability in gaze error levels due to these\nconditions. The objective of this study was to investigate the efficacy of\nmachine learning methods towards the detection and prediction of gaze error\npatterns, which would enable an in-depth understanding of the data quality and\nreliability of eye trackers under unconstrained operating conditions. Coding\nresources for all the machine learning methods adopted in this study were\nincluded in an open repository named MLGaze to allow researchers to replicate\nthe principles presented here using data from their own eye trackers.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 23:07:02 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Kar", "Anuradha", ""]]}, {"id": "2005.03807", "submitter": "Daniel Braithwaite", "authors": "D. T. Braithwaite, M. O'Connor, W. B. Kleijn", "title": "Variance Constrained Autoencoding", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent state-of-the-art autoencoder based generative models have an\nencoder-decoder structure and learn a latent representation with a pre-defined\ndistribution that can be sampled from. Implementing the encoder networks of\nthese models in a stochastic manner provides a natural and common approach to\navoid overfitting and enforce a smooth decoder function. However, we show that\nfor stochastic encoders, simultaneously attempting to enforce a distribution\nconstraint and minimising an output distortion leads to a reduction in\ngenerative and reconstruction quality. In addition, attempting to enforce a\nlatent distribution constraint is not reasonable when performing\ndisentanglement. Hence, we propose the variance-constrained autoencoder (VCAE),\nwhich only enforces a variance constraint on the latent distribution. Our\nexperiments show that VCAE improves upon Wasserstein Autoencoder and the\nVariational Autoencoder in both reconstruction and generative quality on MNIST\nand CelebA. Moreover, we show that VCAE equipped with a total correlation\npenalty term performs equivalently to FactorVAE at learning disentangled\nrepresentations on 3D-Shapes while being a more principled approach.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 00:50:50 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Braithwaite", "D. T.", ""], ["O'Connor", "M.", ""], ["Kleijn", "W. B.", ""]]}, {"id": "2005.03810", "submitter": "Govind Ramnarayan", "authors": "Younhun Kim, Elchanan Mossel, Govind Ramnarayan, Paxton Turner", "title": "Efficient Reconstruction of Stochastic Pedigrees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG q-bio.PE q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new algorithm called {\\sc Rec-Gen} for reconstructing the\ngenealogy or \\textit{pedigree} of an extant population purely from its genetic\ndata. We justify our approach by giving a mathematical proof of the\neffectiveness of {\\sc Rec-Gen} when applied to pedigrees from an idealized\ngenerative model that replicates some of the features of real-world pedigrees.\nOur algorithm is iterative and provides an accurate reconstruction of a large\nfraction of the pedigree while having relatively low \\emph{sample complexity},\nmeasured in terms of the length of the genetic sequences of the population. We\npropose our approach as a prototype for further investigation of the pedigree\nreconstruction problem toward the goal of applications to real-world examples.\nAs such, our results have some conceptual bearing on the increasingly important\nissue of genomic privacy.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 01:08:36 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Kim", "Younhun", ""], ["Mossel", "Elchanan", ""], ["Ramnarayan", "Govind", ""], ["Turner", "Paxton", ""]]}, {"id": "2005.03812", "submitter": "Martina Toshevska", "authors": "Martina Toshevska, Frosina Stojanovska and Jovan Kalajdjieski", "title": "Comparative Analysis of Word Embeddings for Capturing Word Similarities", "comments": "Part of the 6th International Conference on Natural Language\n  Processing (NATP 2020)", "journal-ref": "6th International Conference on Natural Language Processing (NATP\n  2020)", "doi": "10.5121/csit.2020.100402", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Distributed language representation has become the most widely used technique\nfor language representation in various natural language processing tasks. Most\nof the natural language processing models that are based on deep learning\ntechniques use already pre-trained distributed word representations, commonly\ncalled word embeddings. Determining the most qualitative word embeddings is of\ncrucial importance for such models. However, selecting the appropriate word\nembeddings is a perplexing task since the projected embedding space is not\nintuitive to humans. In this paper, we explore different approaches for\ncreating distributed word representations. We perform an intrinsic evaluation\nof several state-of-the-art word embedding methods. Their performance on\ncapturing word similarities is analysed with existing benchmark datasets for\nword pairs similarities. The research in this paper conducts a correlation\nanalysis between ground truth word similarities and similarities obtained by\ndifferent word embedding methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 01:16:03 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Toshevska", "Martina", ""], ["Stojanovska", "Frosina", ""], ["Kalajdjieski", "Jovan", ""]]}, {"id": "2005.03823", "submitter": "Eugene Bagdasaryan", "authors": "Eugene Bagdasaryan and Vitaly Shmatikov", "title": "Blind Backdoors in Deep Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a new method for injecting backdoors into machine learning\nmodels, based on compromising the loss-value computation in the model-training\ncode. We use it to demonstrate new classes of backdoors strictly more powerful\nthan those in the prior literature: single-pixel and physical backdoors in\nImageNet models, backdoors that switch the model to a covert, privacy-violating\ntask, and backdoors that do not require inference-time input modifications.\n  Our attack is blind: the attacker cannot modify the training data, nor\nobserve the execution of his code, nor access the resulting model. The attack\ncode creates poisoned training inputs \"on the fly,\" as the model is training,\nand uses multi-objective optimization to achieve high accuracy on both the main\nand backdoor tasks. We show how a blind attack can evade any known defense and\npropose new ones.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 02:15:53 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 22:09:05 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 17:25:32 GMT"}, {"version": "v4", "created": "Fri, 19 Feb 2021 04:45:28 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Bagdasaryan", "Eugene", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "2005.03824", "submitter": "John McManigle Jr", "authors": "John McManigle, Raquel Bartz, Lawrence Carin", "title": "Y-Net for Chest X-Ray Preprocessing: Simultaneous Classification of\n  Geometry and Segmentation of Annotations", "comments": "Accepted EMBC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade, convolutional neural networks (CNNs) have emerged as\nthe leading algorithms in image classification and segmentation. Recent\npublication of large medical imaging databases have accelerated their use in\nthe biomedical arena. While training data for photograph classification\nbenefits from aggressive geometric augmentation, medical diagnosis --\nespecially in chest radiographs -- depends more strongly on feature location.\nDiagnosis classification results may be artificially enhanced by reliance on\nradiographic annotations. This work introduces a general pre-processing step\nfor chest x-ray input into machine learning algorithms. A modified Y-Net\narchitecture based on the VGG11 encoder is used to simultaneously learn\ngeometric orientation (similarity transform parameters) of the chest and\nsegmentation of radiographic annotations. Chest x-rays were obtained from\npublished databases. The algorithm was trained with 1000 manually labeled\nimages with augmentation. Results were evaluated by expert clinicians, with\nacceptable geometry in 95.8% and annotation mask in 96.2% (n=500), compared to\n27.0% and 34.9% respectively in control images (n=241). We hypothesize that\nthis pre-processing step will improve robustness in future diagnostic\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 02:16:17 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["McManigle", "John", ""], ["Bartz", "Raquel", ""], ["Carin", "Lawrence", ""]]}, {"id": "2005.03825", "submitter": "Xikai Yang", "authors": "Xikai Yang, Xuehang Zheng, Yong Long, Saiprasad Ravishankar", "title": "Learned Multi-layer Residual Sparsifying Transform Model for Low-dose CT\n  Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal models based on sparse representation have received considerable\nattention in recent years. Compared to synthesis dictionary learning,\nsparsifying transform learning involves highly efficient sparse coding and\noperator update steps. In this work, we propose a Multi-layer Residual\nSparsifying Transform (MRST) learning model wherein the transform domain\nresiduals are jointly sparsified over layers. In particular, the transforms for\nthe deeper layers exploit the more intricate properties of the residual maps.\nWe investigate the application of the learned MRST model for low-dose CT\nreconstruction using Penalized Weighted Least Squares (PWLS) optimization.\nExperimental results on Mayo Clinic data show that the MRST model outperforms\nconventional methods such as FBP and PWLS methods based on edge-preserving (EP)\nregularizer and single-layer transform (ST) model, especially for maintaining\nsome subtle details.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 02:36:50 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Yang", "Xikai", ""], ["Zheng", "Xuehang", ""], ["Long", "Yong", ""], ["Ravishankar", "Saiprasad", ""]]}, {"id": "2005.03832", "submitter": "Feng Shi", "authors": "Kelei He, Wei Zhao, Xingzhi Xie, Wen Ji, Mingxia Liu, Zhenyu Tang,\n  Feng Shi, Yang Gao, Jun Liu, Junfeng Zhang, and Dinggang Shen", "title": "Synergistic Learning of Lung Lobe Segmentation and Hierarchical\n  Multi-Instance Classification for Automated Severity Assessment of COVID-19\n  in CT Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding chest CT imaging of the coronavirus disease 2019 (COVID-19)\nwill help detect infections early and assess the disease progression.\nEspecially, automated severity assessment of COVID-19 in CT images plays an\nessential role in identifying cases that are in great need of intensive\nclinical care. However, it is often challenging to accurately assess the\nseverity of this disease in CT images, due to variable infection regions in the\nlungs, similar imaging biomarkers, and large inter-case variations. To this\nend, we propose a synergistic learning framework for automated severity\nassessment of COVID-19 in 3D CT images, by jointly performing lung lobe\nsegmentation and multi-instance classification. Considering that only a few\ninfection regions in a CT image are related to the severity assessment, we\nfirst represent each input image by a bag that contains a set of 2D image\npatches (with each cropped from a specific slice). A multi-task multi-instance\ndeep network (called M$^2$UNet) is then developed to assess the severity of\nCOVID-19 patients and also segment the lung lobe simultaneously. Our M$^2$UNet\nconsists of a patch-level encoder, a segmentation sub-network for lung lobe\nsegmentation, and a classification sub-network for severity assessment (with a\nunique hierarchical multi-instance learning strategy). Here, the context\ninformation provided by segmentation can be implicitly employed to improve the\nperformance of severity assessment. Extensive experiments were performed on a\nreal COVID-19 CT image dataset consisting of 666 chest CT images, with results\nsuggesting the effectiveness of our proposed method compared to several\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 03:16:15 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 08:20:04 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["He", "Kelei", ""], ["Zhao", "Wei", ""], ["Xie", "Xingzhi", ""], ["Ji", "Wen", ""], ["Liu", "Mingxia", ""], ["Tang", "Zhenyu", ""], ["Shi", "Feng", ""], ["Gao", "Yang", ""], ["Liu", "Jun", ""], ["Zhang", "Junfeng", ""], ["Shen", "Dinggang", ""]]}, {"id": "2005.03842", "submitter": "Ali Hadi Zadeh", "authors": "Ali Hadi Zadeh, Isak Edo, Omar Mohamed Awad, and Andreas Moshovos", "title": "GOBO: Quantizing Attention-Based NLP Models for Low Latency and Energy\n  Efficient Inference", "comments": "Accepted at the 53rd IEEE/ACM International Symposium on\n  Microarchitecture - MICRO 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based models have demonstrated remarkable success in various\nnatural language understanding tasks. However, efficient execution remains a\nchallenge for these models which are memory-bound due to their massive number\nof parameters. We present GOBO, a model quantization technique that compresses\nthe vast majority (typically 99.9%) of the 32-bit floating-point parameters of\nstate-of-the-art BERT models and their variants to 3 bits while maintaining\ntheir accuracy. Unlike other quantization methods, GOBO does not require\nfine-tuning nor retraining to compensate for the quantization error. We present\ntwo practical hardware applications of GOBO. In the first GOBO reduces memory\nstorage and traffic and as a result inference latency and energy consumption.\nThis GOBO memory compression mechanism is plug-in compatible with many\narchitectures; we demonstrate it with the TPU, Eyeriss, and an architecture\nusing Tensor Cores-like units. Second, we present a co-designed hardware\narchitecture that also reduces computation. Uniquely, the GOBO architecture\nmaintains most of the weights in 3b even during computation, a property that:\n(1) makes the processing elements area efficient, allowing us to pack more\ncompute power per unit area, (2) replaces most multiply-accumulations with\nadditions, and (3) reduces the off-chip traffic by amplifying on-chip memory\ncapacity.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 03:59:53 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 00:09:30 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Zadeh", "Ali Hadi", ""], ["Edo", "Isak", ""], ["Awad", "Omar Mohamed", ""], ["Moshovos", "Andreas", ""]]}, {"id": "2005.03847", "submitter": "Rishi Sonthalia", "authors": "Rishi Sonthalia, Anna C. Gilbert", "title": "Tree! I am no Tree! I am a Low Dimensional Hyperbolic Embedding", "comments": "Code available at https://github.com/rsonthal/TreeRep", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.MG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given data, finding a faithful low-dimensional hyperbolic embedding of the\ndata is a key method by which we can extract hierarchical information or learn\nrepresentative geometric features of the data. In this paper, we explore a new\nmethod for learning hyperbolic representations by taking a metric-first\napproach. Rather than determining the low-dimensional hyperbolic embedding\ndirectly, we learn a tree structure on the data. This tree structure can then\nbe used directly to extract hierarchical information, embedded into a\nhyperbolic manifold using Sarkar's construction \\cite{sarkar}, or used as a\ntree approximation of the original metric. To this end, we present a novel fast\nalgorithm \\textsc{TreeRep} such that, given a $\\delta$-hyperbolic metric (for\nany $\\delta \\geq 0$), the algorithm learns a tree structure that approximates\nthe original metric. In the case when $\\delta = 0$, we show analytically that\n\\textsc{TreeRep} exactly recovers the original tree structure. We show\nempirically that \\textsc{TreeRep} is not only many orders of magnitude faster\nthan previously known algorithms, but also produces metrics with lower average\ndistortion and higher mean average precision than most previous algorithms for\nlearning hyperbolic embeddings, extracting hierarchical information, and\napproximating metrics via tree metrics.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 04:30:21 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 19:24:44 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 13:51:12 GMT"}, {"version": "v4", "created": "Fri, 23 Oct 2020 01:37:28 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Sonthalia", "Rishi", ""], ["Gilbert", "Anna C.", ""]]}, {"id": "2005.03853", "submitter": "Rishi Sonthalia", "authors": "Rishi Sonthalia, Anna C. Gilbert", "title": "Project and Forget: Solving Large-Scale Metric Constrained Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of dissimilarity measurements amongst data points, determining\nwhat metric representation is most \"consistent\" with the input measurements or\nthe metric that best captures the relevant geometric features of the data is a\nkey step in many machine learning algorithms. Existing methods are restricted\nto specific kinds of metrics or small problem sizes because of the large number\nof metric constraints in such problems. In this paper, we provide an active set\nalgorithm, Project and Forget, that uses Bregman projections, to solve metric\nconstrained problems with many (possibly exponentially) inequality constraints.\nWe provide a theoretical analysis of \\textsc{Project and Forget} and prove that\nour algorithm converges to the global optimal solution and that the $L_2$\ndistance of the current iterate to the optimal solution decays asymptotically\nat an exponential rate. We demonstrate that using our method we can solve large\nproblem instances of three types of metric constrained problems: general weight\ncorrelation clustering, metric nearness, and metric learning; in each case,\nout-performing the state of the art methods with respect to CPU times and\nproblem sizes.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 04:50:54 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Sonthalia", "Rishi", ""], ["Gilbert", "Anna C.", ""]]}, {"id": "2005.03857", "submitter": "Jianlei Yang", "authors": "Xiaotao Jia, Jianlei Yang, Runze Liu, Xueyan Wang, Sorin Dan Cotofana,\n  Weisheng Zhao", "title": "Efficient Computation Reduction in Bayesian Neural Networks Through\n  Feature Decomposition and Memorization", "comments": "accepted by IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Bayesian method is capable of capturing real world\nuncertainties/incompleteness and properly addressing the over-fitting issue\nfaced by deep neural networks. In recent years, Bayesian Neural Networks (BNNs)\nhave drawn tremendous attentions of AI researchers and proved to be successful\nin many applications. However, the required high computation complexity makes\nBNNs difficult to be deployed in computing systems with limited power budget.\nIn this paper, an efficient BNN inference flow is proposed to reduce the\ncomputation cost then is evaluated by means of both software and hardware\nimplementations. A feature decomposition and memorization (\\texttt{DM})\nstrategy is utilized to reform the BNN inference flow in a reduced manner.\nAbout half of the computations could be eliminated compared to the traditional\napproach that has been proved by theoretical analysis and software validations.\nSubsequently, in order to resolve the hardware resource limitations, a\nmemory-friendly computing framework is further deployed to reduce the memory\noverhead introduced by \\texttt{DM} strategy. Finally, we implement our approach\nin Verilog and synthesise it with 45 $nm$ FreePDK technology. Hardware\nsimulation results on multi-layer BNNs demonstrate that, when compared with the\ntraditional BNN inference method, it provides an energy consumption reduction\nof 73\\% and a 4$\\times$ speedup at the expense of 14\\% area overhead.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 05:03:04 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Jia", "Xiaotao", ""], ["Yang", "Jianlei", ""], ["Liu", "Runze", ""], ["Wang", "Xueyan", ""], ["Cotofana", "Sorin Dan", ""], ["Zhao", "Weisheng", ""]]}, {"id": "2005.03858", "submitter": "Alexander Lapanowski", "authors": "Alexander F. Lapanowski, Irina Gaynanova", "title": "Compressing Large Sample Data for Discriminant Analysis", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-sample data became prevalent as data acquisition became cheaper and\neasier. While a large sample size has theoretical advantages for many\nstatistical methods, it presents computational challenges. Sketching, or\ncompression, is a well-studied approach to address these issues in regression\nsettings, but considerably less is known about its performance in\nclassification settings. Here we consider the computational issues due to large\nsample size within the discriminant analysis framework. We propose a new\ncompression approach for reducing the number of training samples for linear and\nquadratic discriminant analysis, in contrast to existing compression methods\nwhich focus on reducing the number of features. We support our approach with a\ntheoretical bound on the misclassification error rate compared to the Bayes\nclassifier. Empirical studies confirm the significant computational gains of\nthe proposed method and its superior predictive ability compared to random\nsub-sampling.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 05:09:08 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Lapanowski", "Alexander F.", ""], ["Gaynanova", "Irina", ""]]}, {"id": "2005.03867", "submitter": "Myunghun Jung", "authors": "Myunghun Jung, Youngmoon Jung, Jahyun Goo, and Hoirin Kim", "title": "Multi-Task Network for Noise-Robust Keyword Spotting and Speaker\n  Verification using CTC-based Soft VAD and Global Query Attention", "comments": "Accepted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyword spotting (KWS) and speaker verification (SV) have been studied\nindependently although it is known that acoustic and speaker domains are\ncomplementary. In this paper, we propose a multi-task network that performs KWS\nand SV simultaneously to fully utilize the interrelated domain information. The\nmulti-task network tightly combines sub-networks aiming at performance\nimprovement in challenging conditions such as noisy environments,\nopen-vocabulary KWS, and short-duration SV, by introducing novel techniques of\nconnectionist temporal classification (CTC)-based soft voice activity detection\n(VAD) and global query attention. Frame-level acoustic and speaker information\nis integrated with phonetically originated weights so that forms a word-level\nglobal representation. Then it is used for the aggregation of feature vectors\nto generate discriminative embeddings. Our proposed approach shows 4.06% and\n26.71% relative improvements in equal error rate (EER) compared to the\nbaselines for both tasks. We also present a visualization example and results\nof ablation experiments.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 05:58:46 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 11:16:56 GMT"}, {"version": "v3", "created": "Sat, 16 May 2020 09:56:34 GMT"}, {"version": "v4", "created": "Fri, 7 Aug 2020 07:23:57 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Jung", "Myunghun", ""], ["Jung", "Youngmoon", ""], ["Goo", "Jahyun", ""], ["Kim", "Hoirin", ""]]}, {"id": "2005.03868", "submitter": "Rasoul Sali", "authors": "Rasoul Sali, Sodiq Adewole, Lubaina Ehsan, Lee A. Denson, Paul Kelly,\n  Beatrice C. Amadi, Lori Holtz, Syed Asad Ali, Sean R. Moore, Sana Syed,\n  Donald E. Brown", "title": "Hierarchical Deep Convolutional Neural Networks for Multi-category\n  Diagnosis of Gastrointestinal Disorders on Histopathological Images", "comments": "accepted at IEEE International Conference on Healthcare Informatics\n  (ICHI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks(CNNs) have been successful for a wide\nrange of computer vision tasks, including image classification. A specific area\nof the application lies in digital pathology for pattern recognition in the\ntissue-based diagnosis of gastrointestinal(GI) diseases. This domain can\nutilize CNNs to translate histopathological images into precise diagnostics.\nThis is challenging since these complex biopsies are heterogeneous and require\nmultiple levels of assessment. This is mainly due to structural similarities in\ndifferent parts of the GI tract and shared features among different gut\ndiseases. Addressing this problem with a flat model that assumes all classes\n(parts of the gut and their diseases) are equally difficult to distinguish\nleads to an inadequate assessment of each class. Since the hierarchical model\nrestricts classification error to each sub-class, it leads to a more\ninformative model than a flat model. In this paper, we propose to apply the\nhierarchical classification of biopsy images from different parts of the GI\ntract and the receptive diseases within each. We embedded a class hierarchy\ninto the plain VGGNet to take advantage of its layers' hierarchical structure.\nThe proposed model was evaluated using an independent set of image patches from\n373 whole slide images. The results indicate that the hierarchical model can\nachieve better results than the flat model for multi-category diagnosis of GI\ndisorders using histopathological images.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 06:05:09 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 01:28:59 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Sali", "Rasoul", ""], ["Adewole", "Sodiq", ""], ["Ehsan", "Lubaina", ""], ["Denson", "Lee A.", ""], ["Kelly", "Paul", ""], ["Amadi", "Beatrice C.", ""], ["Holtz", "Lori", ""], ["Ali", "Syed Asad", ""], ["Moore", "Sean R.", ""], ["Syed", "Sana", ""], ["Brown", "Donald E.", ""]]}, {"id": "2005.03876", "submitter": "Cristina Palmero", "authors": "Cristina Palmero, Abhishek Sharma, Karsten Behrendt, Kapil\n  Krishnakumar, Oleg V. Komogortsev, Sachin S. Talathi", "title": "OpenEDS2020: Open Eyes Dataset", "comments": "Description of dataset used in OpenEDS2020 challenge:\n  https://research.fb.com/programs/openeds-2020-challenge/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the second edition of OpenEDS dataset, OpenEDS2020, a novel\ndataset of eye-image sequences captured at a frame rate of 100 Hz under\ncontrolled illumination, using a virtual-reality head-mounted display mounted\nwith two synchronized eye-facing cameras. The dataset, which is anonymized to\nremove any personally identifiable information on participants, consists of 80\nparticipants of varied appearance performing several gaze-elicited tasks, and\nis divided in two subsets: 1) Gaze Prediction Dataset, with up to 66,560\nsequences containing 550,400 eye-images and respective gaze vectors, created to\nfoster research in spatio-temporal gaze estimation and prediction approaches;\nand 2) Eye Segmentation Dataset, consisting of 200 sequences sampled at 5 Hz,\nwith up to 29,500 images, of which 5% contain a semantic segmentation label,\ndevised to encourage the use of temporal information to propagate labels to\ncontiguous frames. Baseline experiments have been evaluated on OpenEDS2020, one\nfor each task, with average angular error of 5.37 degrees when performing gaze\nprediction on 1 to 5 frames into the future, and a mean intersection over union\nscore of 84.1% for semantic segmentation. As its predecessor, OpenEDS dataset,\nwe anticipate that this new dataset will continue creating opportunities to\nresearchers in eye tracking, machine learning and computer vision communities,\nto advance the state of the art for virtual reality applications. The dataset\nis available for download upon request at\nhttp://research.fb.com/programs/openeds-2020-challenge/.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 06:53:05 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Palmero", "Cristina", ""], ["Sharma", "Abhishek", ""], ["Behrendt", "Karsten", ""], ["Krishnakumar", "Kapil", ""], ["Komogortsev", "Oleg V.", ""], ["Talathi", "Sachin S.", ""]]}, {"id": "2005.03888", "submitter": "Chong You", "authors": "Chong You and Chun-Guang Li and Daniel P. Robinson and Rene Vidal", "title": "Is an Affine Constraint Needed for Affine Subspace Clustering?", "comments": "ICCV 2019. Including proofs that are omitted in the conference\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering methods based on expressing each data point as a linear\ncombination of other data points have achieved great success in computer vision\napplications such as motion segmentation, face and digit clustering. In face\nclustering, the subspaces are linear and subspace clustering methods can be\napplied directly. In motion segmentation, the subspaces are affine and an\nadditional affine constraint on the coefficients is often enforced. However,\nsince affine subspaces can always be embedded into linear subspaces of one\nextra dimension, it is unclear if the affine constraint is really necessary.\nThis paper shows, both theoretically and empirically, that when the dimension\nof the ambient space is high relative to the sum of the dimensions of the\naffine subspaces, the affine constraint has a negligible effect on clustering\nperformance. Specifically, our analysis provides conditions that guarantee the\ncorrectness of affine subspace clustering methods both with and without the\naffine constraint, and shows that these conditions are satisfied for\nhigh-dimensional data. Underlying our analysis is the notion of affinely\nindependent subspaces, which not only provides geometrically interpretable\ncorrectness conditions, but also clarifies the relationships between existing\nresults for affine subspace clustering.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 07:52:17 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["You", "Chong", ""], ["Li", "Chun-Guang", ""], ["Robinson", "Daniel P.", ""], ["Vidal", "Rene", ""]]}, {"id": "2005.03899", "submitter": "Stefan Radev T.", "authors": "Stefan T. Radev, Andreas Voss, Eva Marie Wieschen, Paul-Christian\n  B\\\"urkner", "title": "Amortized Bayesian Inference for Models of Cognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As models of cognition grow in complexity and number of parameters, Bayesian\ninference with standard methods can become intractable, especially when the\ndata-generating model is of unknown analytic form. Recent advances in\nsimulation-based inference using specialized neural network architectures\ncircumvent many previous problems of approximate Bayesian computation.\nMoreover, due to the properties of these special neural network estimators, the\neffort of training the networks via simulations amortizes over subsequent\nevaluations which can re-use the same network for multiple datasets and across\nmultiple researchers. However, these methods have been largely underutilized in\ncognitive science and psychology so far, even though they are well suited for\ntackling a wide variety of modeling problems. With this work, we provide a\ngeneral introduction to amortized Bayesian parameter estimation and model\ncomparison and demonstrate the applicability of the proposed methods on a\nwell-known class of intractable response-time models.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 08:12:15 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 10:33:49 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 05:55:02 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Radev", "Stefan T.", ""], ["Voss", "Andreas", ""], ["Wieschen", "Eva Marie", ""], ["B\u00fcrkner", "Paul-Christian", ""]]}, {"id": "2005.03912", "submitter": "Vajira Thambawita", "authors": "Vajira Thambawita, Debesh Jha, Hugo Lewi Hammer, H{\\aa}vard D.\n  Johansen, Dag Johansen, P{\\aa}l Halvorsen, Michael A. Riegler", "title": "An Extensive Study on Cross-Dataset Bias and Evaluation Metrics\n  Interpretation for Machine Learning applied to Gastrointestinal Tract\n  Abnormality Classification", "comments": "30 pages, 12 figures, 8 tables, Accepted for ACM Transactions on\n  Computing for Healthcare", "journal-ref": null, "doi": "10.1145/3386295", "report-no": null, "categories": "cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precise and efficient automated identification of Gastrointestinal (GI) tract\ndiseases can help doctors treat more patients and improve the rate of disease\ndetection and identification. Currently, automatic analysis of diseases in the\nGI tract is a hot topic in both computer science and medical-related journals.\nNevertheless, the evaluation of such an automatic analysis is often incomplete\nor simply wrong. Algorithms are often only tested on small and biased datasets,\nand cross-dataset evaluations are rarely performed. A clear understanding of\nevaluation metrics and machine learning models with cross datasets is crucial\nto bring research in the field to a new quality level. Towards this goal, we\npresent comprehensive evaluations of five distinct machine learning models\nusing Global Features and Deep Neural Networks that can classify 16 different\nkey types of GI tract conditions, including pathological findings, anatomical\nlandmarks, polyp removal conditions, and normal findings from images captured\nby common GI tract examination instruments. In our evaluation, we introduce\nperformance hexagons using six performance metrics such as recall, precision,\nspecificity, accuracy, F1-score, and Matthews Correlation Coefficient to\ndemonstrate how to determine the real capabilities of models rather than\nevaluating them shallowly. Furthermore, we perform cross-dataset evaluations\nusing different datasets for training and testing. With these cross-dataset\nevaluations, we demonstrate the challenge of actually building a generalizable\nmodel that could be used across different hospitals. Our experiments clearly\nshow that more sophisticated performance metrics and evaluation methods need to\nbe applied to get reliable models rather than depending on evaluations of the\nsplits of the same dataset, i.e., the performance metrics should always be\ninterpreted together rather than relying on a single metric.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 08:59:31 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Thambawita", "Vajira", ""], ["Jha", "Debesh", ""], ["Hammer", "Hugo Lewi", ""], ["Johansen", "H\u00e5vard D.", ""], ["Johansen", "Dag", ""], ["Halvorsen", "P\u00e5l", ""], ["Riegler", "Michael A.", ""]]}, {"id": "2005.03915", "submitter": "Ziqi Yang", "authors": "Ziqi Yang, Bin Shao, Bohan Xuan, Ee-Chien Chang, Fan Zhang", "title": "Defending Model Inversion and Membership Inference Attacks via\n  Prediction Purification", "comments": "updated experiments and results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are susceptible to data inference attacks such as the model\ninversion attack and the membership inference attack, where the attacker could\ninfer the reconstruction and the membership of a data sample from the\nconfidence scores predicted by the target classifier. In this paper, we propose\na unified approach, namely purification framework, to defend data inference\nattacks. It purifies the confidence score vectors predicted by the target\nclassifier by reducing their dispersion. The purifier can be further\nspecialized in defending a particular attack via adversarial learning. We\nevaluate our approach on benchmark datasets and classifiers. We show that when\nthe purifier is dedicated to one attack, it naturally defends the other one,\nwhich empirically demonstrates the connection between the two attacks. The\npurifier can effectively defend both attacks. For example, it can reduce the\nmembership inference accuracy by up to 15% and increase the model inversion\nerror by a factor of up to 4. Besides, it incurs less than 0.4% classification\naccuracy drop and less than 5.5% distortion to the confidence scores.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 09:07:38 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 16:27:41 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Yang", "Ziqi", ""], ["Shao", "Bin", ""], ["Xuan", "Bohan", ""], ["Chang", "Ee-Chien", ""], ["Zhang", "Fan", ""]]}, {"id": "2005.03924", "submitter": "Shuchao Pang", "authors": "Shuchao Pang, Anan Du, Mehmet A. Orgun, Yan Wang, Quanzheng Sheng,\n  Shoujin Wang, Xiaoshui Huang, Zhemei Yu", "title": "Beyond CNNs: Exploiting Further Inherent Symmetries in Medical Images\n  for Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic tumor segmentation is a crucial step in medical image analysis for\ncomputer-aided diagnosis. Although the existing methods based on convolutional\nneural networks (CNNs) have achieved the state-of-the-art performance, many\nchallenges still remain in medical tumor segmentation. This is because regular\nCNNs can only exploit translation invariance, ignoring further inherent\nsymmetries existing in medical images such as rotations and reflections. To\nmitigate this shortcoming, we propose a novel group equivariant segmentation\nframework by encoding those inherent symmetries for learning more precise\nrepresentations. First, kernel-based equivariant operations are devised on\nevery orientation, which can effectively address the gaps of learning\nsymmetries in existing approaches. Then, to keep segmentation networks globally\nequivariant, we design distinctive group layers with layerwise symmetry\nconstraints. By exploiting further symmetries, novel segmentation CNNs can\ndramatically reduce the sample complexity and the redundancy of filters (by\nroughly 2/3) over regular CNNs. More importantly, based on our novel framework,\nwe show that a newly built GER-UNet outperforms its regular CNN-based\ncounterpart and the state-of-the-art segmentation methods on real-world\nclinical data. Specifically, the group layers of our segmentation framework can\nbe seamlessly integrated into any popular CNN-based segmentation architectures.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 09:36:50 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Pang", "Shuchao", ""], ["Du", "Anan", ""], ["Orgun", "Mehmet A.", ""], ["Wang", "Yan", ""], ["Sheng", "Quanzheng", ""], ["Wang", "Shoujin", ""], ["Huang", "Xiaoshui", ""], ["Yu", "Zhemei", ""]]}, {"id": "2005.03932", "submitter": "Shuo Sun", "authors": "Shuo Sun, Kevin Duh", "title": "Modeling Document Interactions for Learning to Rank with Regularized\n  Self-Attention", "comments": "5 pages,5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to rank is an important task that has been successfully deployed in\nmany real-world information retrieval systems. Most existing methods compute\nrelevance judgments of documents independently, without holistically\nconsidering the entire set of competing documents. In this paper, we explore\nmodeling documents interactions with self-attention based neural networks.\nAlthough self-attention networks have achieved state-of-the-art results in many\nNLP tasks, we find empirically that self-attention provides little benefit over\nbaseline neural learning to rank architecture. To improve the learning of\nself-attention weights, We propose simple yet effective regularization terms\ndesigned to model interactions between documents. Evaluations on publicly\navailable Learning to Rank (LETOR) datasets show that training self-attention\nnetwork with our proposed regularization terms can significantly outperform\nexisting learning to rank methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 09:53:31 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Sun", "Shuo", ""], ["Duh", "Kevin", ""]]}, {"id": "2005.03945", "submitter": "Jason T. L. Wang", "authors": "Hao Liu, Yan Xu, Jiasheng Wang, Ju Jing, Chang Liu, Jason T. L. Wang,\n  Haimin Wang", "title": "Inferring Vector Magnetic Fields from Stokes Profiles of GST/NIRIS Using\n  a Convolutional Neural Network", "comments": "24 pages, 9 figures", "journal-ref": "The Astrophysical Journal, 894:70, 2020", "doi": "10.3847/1538-4357/ab8818", "report-no": null, "categories": "astro-ph.SR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new machine learning approach to Stokes inversion based on a\nconvolutional neural network (CNN) and the Milne-Eddington (ME) method. The\nStokes measurements used in this study were taken by the Near InfraRed Imaging\nSpectropolarimeter (NIRIS) on the 1.6 m Goode Solar Telescope (GST) at the Big\nBear Solar Observatory. By learning the latent patterns in the training data\nprepared by the physics-based ME tool, the proposed CNN method is able to infer\nvector magnetic fields from the Stokes profiles of GST/NIRIS. Experimental\nresults show that our CNN method produces smoother and cleaner magnetic maps\nthan the widely used ME method. Furthermore, the CNN method is 4~6 times faster\nthan the ME method, and is able to produce vector magnetic fields in near\nreal-time, which is essential to space weather forecasting. Specifically, it\ntakes ~50 seconds for the CNN method to process an image of 720 x 720 pixels\ncomprising Stokes profiles of GST/NIRIS. Finally, the CNN-inferred results are\nhighly correlated to the ME-calculated results and are closer to the ME's\nresults with the Pearson product-moment correlation coefficient (PPMCC) being\ncloser to 1 on average than those from other machine learning algorithms such\nas multiple support vector regression and multilayer perceptrons (MLP). In\nparticular, the CNN method outperforms the current best machine learning method\n(MLP) by 2.6% on average in PPMCC according to our experimental study. Thus,\nthe proposed physics-assisted deep learning-based CNN tool can be considered as\nan alternative, efficient method for Stokes inversion for high resolution\npolarimetric observations obtained by GST/NIRIS.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 10:26:12 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Liu", "Hao", ""], ["Xu", "Yan", ""], ["Wang", "Jiasheng", ""], ["Jing", "Ju", ""], ["Liu", "Chang", ""], ["Wang", "Jason T. L.", ""], ["Wang", "Haimin", ""]]}, {"id": "2005.03961", "submitter": "Ramin Hasibi", "authors": "Ramin Hasibi, Tom Michoel", "title": "A Graph Feature Auto-Encoder for the Prediction of Unobserved Node\n  Features on Biological Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Molecular interaction networks summarize complex biological\nprocesses as graphs, whose structure is informative of biological function at\nmultiple scales. Simultaneously, omics technologies measure the variation or\nactivity of genes, proteins, or metabolites across individuals or experimental\nconditions. Integrating the complementary viewpoints of biological networks and\nomics data is an important task in bioinformatics, but existing methods treat\nnetworks as discrete structures, which are intrinsically difficult to integrate\nwith continuous node features or activity measures. Graph neural networks map\ngraph nodes into a low-dimensional vector space representation, and can be\ntrained to preserve both the local graph structure and the similarity between\nnode features.\n  Results: We studied the representation of transcriptional, protein-protein\nand genetic interaction networks in E. Coli and mouse using graph neural\nnetworks. We found that such representations explain a large proportion of\nvariation in gene expression data, and that using gene expression data as node\nfeatures improves the reconstruction of the graph from the embedding. We\nfurther proposed a new end-to-end graph feature auto-encoder which is trained\non the feature reconstruction task, and showed that it performs better at\npredicting unobserved node features than auto-encoders that are trained on the\ngraph reconstruction task before learning to predict node features. When\napplied to the problem of imputing missing data in single-cell RNAseq data, our\ngraph feature auto-encoder outperformed a state-of-the-art imputation method\nthat does not use protein interaction information, showing the benefit of\nintegrating biological networks and omics data using graph representation\nlearning.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 11:23:04 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 09:18:25 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Hasibi", "Ramin", ""], ["Michoel", "Tom", ""]]}, {"id": "2005.03975", "submitter": "Yan Xu", "authors": "Dan Su, Yan Xu, Tiezheng Yu, Farhad Bin Siddique, Elham J. Barezi,\n  Pascale Fung", "title": "CAiRE-COVID: A Question Answering and Query-focused Multi-Document\n  Summarization System for COVID-19 Scholarly Information Management", "comments": "Accepted EMNLP2020 NLP-COVID Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CAiRE-COVID, a real-time question answering (QA) and\nmulti-document summarization system, which won one of the 10 tasks in the\nKaggle COVID-19 Open Research Dataset Challenge, judged by medical experts. Our\nsystem aims to tackle the recent challenge of mining the numerous scientific\narticles being published on COVID-19 by answering high priority questions from\nthe community and summarizing salient question-related information. It combines\ninformation extraction with state-of-the-art QA and query-focused\nmulti-document summarization techniques, selecting and highlighting evidence\nsnippets from existing literature given a query. We also propose query-focused\nabstractive and extractive multi-document summarization methods, to provide\nmore relevant information related to the question. We further conduct\nquantitative experiments that show consistent improvements on various metrics\nfor each module. We have launched our website CAiRE-COVID for broader use by\nthe medical community, and have open-sourced the code for our system, to\nbootstrap further study by other researches.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 15:07:27 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 02:47:06 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 11:30:49 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Su", "Dan", ""], ["Xu", "Yan", ""], ["Yu", "Tiezheng", ""], ["Siddique", "Farhad Bin", ""], ["Barezi", "Elham J.", ""], ["Fung", "Pascale", ""]]}, {"id": "2005.03990", "submitter": "Mohammad Rahimzadeh", "authors": "Mohammad Rahimzadeh, Abolfazl Attar", "title": "Detecting and Counting Pistachios based on Deep Learning", "comments": "This is a preprint of an article published in the Iran Journal of\n  Computer Science. The final authenticated version is available online at\n  https://doi.org/10.1007/s42044-021-00090-6. The dataset and the code are\n  available at: https://github.com/mr7495/Pesteh-Set\n  https://github.com/mr7495/Pistachio-Counting", "journal-ref": null, "doi": "10.1007/s42044-021-00090-6", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Pistachios are nutritious nuts that are sorted based on the shape of their\nshell into two categories: Open-mouth and Closed-mouth. The open-mouth\npistachios are higher in price, value, and demand than the closed-mouth\npistachios. Because of these differences, it is considerable for production\ncompanies to precisely count the number of each kind. This paper aims to\npropose a new system for counting the different types of pistachios with\ncomputer vision. We have introduced and shared a new dataset of pistachios,\nincluding six videos with a total length of 167 seconds and 3927 labeled\npistachios. Unlike many other works, our model counts pistachios in videos, not\nimages. Counting objects in videos need assigning each object between the video\nframes so that each object be counted once. The main two challenges in our work\nare the existence of pistachios' occlusion and deformation of pistachios in\ndifferent frames because open-mouth pistachios that move and roll on the\ntransportation line may appear as closed-mouth in some frames and open-mouth in\nother frames. Our novel model first is trained on the RetinaNet object detector\nnetwork using our dataset to detect different types of pistachios in video\nframes. After gathering the detections, we apply them to a new counter\nalgorithm based on a new tracker to assign pistachios in consecutive frames\nwith high accuracy. Our model is able to assign pistachios that turn and change\ntheir appearance (e.g., open-mouth pistachios that look closed-mouth) to each\nother so does not count them incorrectly. Our algorithm performs very fast and\nachieves good counting results. The computed accuracy of our algorithm on six\nvideos (9486 frames) is 94.75%.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 15:10:06 GMT"}, {"version": "v2", "created": "Sun, 30 Aug 2020 18:44:38 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 03:34:15 GMT"}, {"version": "v4", "created": "Mon, 3 May 2021 21:26:55 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Rahimzadeh", "Mohammad", ""], ["Attar", "Abolfazl", ""]]}, {"id": "2005.03991", "submitter": "Reinhard Heckel", "authors": "Reinhard Heckel and Mahdi Soltanolkotabi", "title": "Compressive sensing with un-trained neural networks: Gradient descent\n  finds the smoothest approximation", "comments": "arXiv admin note: text overlap with arXiv:1910.14634", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Un-trained convolutional neural networks have emerged as highly successful\ntools for image recovery and restoration. They are capable of solving standard\ninverse problems such as denoising and compressive sensing with excellent\nresults by simply fitting a neural network model to measurements from a single\nimage or signal without the need for any additional training data. For some\napplications, this critically requires additional regularization in the form of\nearly stopping the optimization. For signal recovery from a few measurements,\nhowever, un-trained convolutional networks have an intriguing self-regularizing\nproperty: Even though the network can perfectly fit any image, the network\nrecovers a natural image from few measurements when trained with gradient\ndescent until convergence. In this paper, we provide numerical evidence for\nthis property and study it theoretically. We show that---without any further\nregularization---an un-trained convolutional neural network can approximately\nreconstruct signals and images that are sufficiently structured, from a near\nminimal number of random measurements.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 15:57:25 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Heckel", "Reinhard", ""], ["Soltanolkotabi", "Mahdi", ""]]}, {"id": "2005.03993", "submitter": "Karthik Gopalakrishnan", "authors": "Karthik Gopalakrishnan, Fathi M.Salem", "title": "Sentiment Analysis Using Simplified Long Short-term Memory Recurrent\n  Neural Networks", "comments": "6 pages, 6 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LSTM or Long Short Term Memory Networks is a specific type of Recurrent\nNeural Network (RNN) that is very effective in dealing with long sequence data\nand learning long term dependencies. In this work, we perform sentiment\nanalysis on a GOP Debate Twitter dataset. To speed up training and reduce the\ncomputational cost and time, six different parameter reduced slim versions of\nthe LSTM model (slim LSTM) are proposed. We evaluate two of these models on the\ndataset. The performance of these two LSTM models along with the standard LSTM\nmodel is compared. The effect of Bidirectional LSTM Layers is also studied. The\nwork also consists of a study to choose the best architecture, apart from\nestablishing the best set of hyper parameters for different LSTM Models.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 12:50:10 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Gopalakrishnan", "Karthik", ""], ["Salem", "Fathi M.", ""]]}, {"id": "2005.03994", "submitter": "Xishuang Dong", "authors": "Xishuang Dong, Shanta Chowdhury, Uboho Victor, Xiangfang Li, Lijun\n  Qian", "title": "Cell Type Identification from Single-Cell Transcriptomic Data via\n  Semi-supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cell type identification from single-cell transcriptomic data is a common\ngoal of single-cell RNA sequencing (scRNAseq) data analysis. Neural networks\nhave been employed to identify cell types from scRNAseq data with high\nperformance. However, it requires a large mount of individual cells with\naccurate and unbiased annotated types to build the identification models.\nUnfortunately, labeling the scRNAseq data is cumbersome and time-consuming as\nit involves manual inspection of marker genes. To overcome this challenge, we\npropose a semi-supervised learning model to use unlabeled scRNAseq cells and\nlimited amount of labeled scRNAseq cells to implement cell identification.\nFirstly, we transform the scRNAseq cells to \"gene sentences\", which is inspired\nby similarities between natural language system and gene system. Then genes in\nthese sentences are represented as gene embeddings to reduce data sparsity.\nWith these embeddings, we implement a semi-supervised learning model based on\nrecurrent convolutional neural networks (RCNN), which includes a shared\nnetwork, a supervised network and an unsupervised network. The proposed model\nis evaluated on macosko2015, a large scale single-cell transcriptomic dataset\nwith ground truth of individual cell types. It is observed that the proposed\nmodel is able to achieve encouraging performance by learning on very limited\namount of labeled scRNAseq cells together with a large number of unlabeled\nscRNAseq cells.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 19:15:43 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Dong", "Xishuang", ""], ["Chowdhury", "Shanta", ""], ["Victor", "Uboho", ""], ["Li", "Xiangfang", ""], ["Qian", "Lijun", ""]]}, {"id": "2005.04014", "submitter": "Mehmet Yamac", "authors": "Mehmet Yamac, Mete Ahishali, Aysen Degerli, Serkan Kiranyaz, Muhammad\n  E. H. Chowdhury, Moncef Gabbouj", "title": "Convolutional Sparse Support Estimator Based Covid-19 Recognition from\n  X-ray Images", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Coronavirus disease (Covid-19) has been the main agenda of the whole world\nsince it came in sight in December 2019. It has already caused thousands of\ncausalities and infected several millions worldwide. Any technological tool\nthat can be provided to healthcare practitioners to save time, effort, and\npossibly lives has crucial importance. The main tools practitioners currently\nuse to diagnose Covid-19 are Reverse Transcription-Polymerase Chain reaction\n(RT-PCR) and Computed Tomography (CT), which require significant time,\nresources and acknowledged experts. X-ray imaging is a common and easily\naccessible tool that has great potential for Covid-19 diagnosis. In this study,\nwe propose a novel approach for Covid-19 recognition from chest X-ray images.\nDespite the importance of the problem, recent studies in this domain produced\nnot so satisfactory results due to the limited datasets available for training.\nRecall that Deep Learning techniques can generally provide state-of-the-art\nperformance in many classification tasks when trained properly over large\ndatasets, such data scarcity can be a crucial obstacle when using them for\nCovid-19 detection. Alternative approaches such as representation-based\nclassification (collaborative or sparse representation) might provide\nsatisfactory performance with limited size datasets, but they generally fall\nshort in performance or speed compared to Machine Learning methods. To address\nthis deficiency, Convolution Support Estimation Network (CSEN) has recently\nbeen proposed as a bridge between model-based and Deep Learning approaches by\nproviding a non-iterative real-time mapping from query sample to ideally sparse\nrepresentation coefficient' support, which is critical information for class\ndecision in representation based techniques.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 13:11:40 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Yamac", "Mehmet", ""], ["Ahishali", "Mete", ""], ["Degerli", "Aysen", ""], ["Kiranyaz", "Serkan", ""], ["Chowdhury", "Muhammad E. H.", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "2005.04035", "submitter": "Siu Lun Chau", "authors": "Siu Lun Chau and Mihai Cucuringu and Dino Sejdinovic", "title": "Spectral Ranking with Covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider approaches to the classical problem of establishing a statistical\nranking on a given set of items from incomplete and noisy pairwise comparisons,\nand propose spectral algorithms able to leverage available covariate\ninformation about the items. We give a comprehensive study of several ways such\nside information can be useful in spectral ranking. We establish connections of\nthe resulting algorithms to reproducing kernel Hilbert spaces and associated\ndependence measures, along with an extension to fair ranking using statistical\nparity. We present an extensive set of numerical experiments showcasing the\ncompetitiveness of the proposed algorithms with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 13:32:45 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 15:41:17 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Chau", "Siu Lun", ""], ["Cucuringu", "Mihai", ""], ["Sejdinovic", "Dino", ""]]}, {"id": "2005.04043", "submitter": "Feng Shi", "authors": "Donglin Di, Feng Shi, Fuhua Yan, Liming Xia, Zhanhao Mo, Zhongxiang\n  Ding, Fei Shan, Shengrui Li, Ying Wei, Ying Shao, Miaofei Han, Yaozong Gao,\n  He Sui, Yue Gao, Dinggang Shen", "title": "Hypergraph Learning for Identification of COVID-19 with CT Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coronavirus disease, named COVID-19, has become the largest global public\nhealth crisis since it started in early 2020. CT imaging has been used as a\ncomplementary tool to assist early screening, especially for the rapid\nidentification of COVID-19 cases from community acquired pneumonia (CAP) cases.\nThe main challenge in early screening is how to model the confusing cases in\nthe COVID-19 and CAP groups, with very similar clinical manifestations and\nimaging features. To tackle this challenge, we propose an Uncertainty\nVertex-weighted Hypergraph Learning (UVHL) method to identify COVID-19 from CAP\nusing CT images. In particular, multiple types of features (including regional\nfeatures and radiomics features) are first extracted from CT image for each\ncase. Then, the relationship among different cases is formulated by a\nhypergraph structure, with each case represented as a vertex in the hypergraph.\nThe uncertainty of each vertex is further computed with an uncertainty score\nmeasurement and used as a weight in the hypergraph. Finally, a learning process\nof the vertex-weighted hypergraph is used to predict whether a new testing case\nbelongs to COVID-19 or not. Experiments on a large multi-center pneumonia\ndataset, consisting of 2,148 COVID-19 cases and 1,182 CAP cases from five\nhospitals, are conducted to evaluate the performance of the proposed method.\nResults demonstrate the effectiveness and robustness of our proposed method on\nthe identification of COVID-19 in comparison to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 11:26:32 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Di", "Donglin", ""], ["Shi", "Feng", ""], ["Yan", "Fuhua", ""], ["Xia", "Liming", ""], ["Mo", "Zhanhao", ""], ["Ding", "Zhongxiang", ""], ["Shan", "Fei", ""], ["Li", "Shengrui", ""], ["Wei", "Ying", ""], ["Shao", "Ying", ""], ["Han", "Miaofei", ""], ["Gao", "Yaozong", ""], ["Sui", "He", ""], ["Gao", "Yue", ""], ["Shen", "Dinggang", ""]]}, {"id": "2005.04048", "submitter": "Lars Hertel", "authors": "Lars Hertel, Julian Collado, Peter Sadowski, Jordan Ott, Pierre Baldi", "title": "Sherpa: Robust Hyperparameter Optimization for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sherpa is a hyperparameter optimization library for machine learning models.\nIt is specifically designed for problems with computationally expensive,\niterative function evaluations, such as the hyperparameter tuning of deep\nneural networks. With Sherpa, scientists can quickly optimize hyperparameters\nusing a variety of powerful and interchangeable algorithms. Sherpa can be run\non either a single machine or in parallel on a cluster. Finally, an interactive\ndashboard enables users to view the progress of models as they are trained,\ncancel trials, and explore which hyperparameter combinations are working best.\nSherpa empowers machine learning practitioners by automating the more tedious\naspects of model tuning. Its source code and documentation are available at\nhttps://github.com/sherpa-ai/sherpa.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 13:52:49 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Hertel", "Lars", ""], ["Collado", "Julian", ""], ["Sadowski", "Peter", ""], ["Ott", "Jordan", ""], ["Baldi", "Pierre", ""]]}, {"id": "2005.04064", "submitter": "Ties Van Rozendaal", "authors": "Ties van Rozendaal, Guillaume Sauti\\`ere, Taco S. Cohen", "title": "Lossy Compression with Distortion Constrained Optimization", "comments": "Accepted as a CVPR 2020 workshop paper: Workshop and Challenge on\n  Learned Image Compression (CLIC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When training end-to-end learned models for lossy compression, one has to\nbalance the rate and distortion losses. This is typically done by manually\nsetting a tradeoff parameter $\\beta$, an approach called $\\beta$-VAE. Using\nthis approach it is difficult to target a specific rate or distortion value,\nbecause the result can be very sensitive to $\\beta$, and the appropriate value\nfor $\\beta$ depends on the model and problem setup. As a result, model\ncomparison requires extensive per-model $\\beta$-tuning, and producing a whole\nrate-distortion curve (by varying $\\beta$) for each model to be compared. We\nargue that the constrained optimization method of Rezende and Viola, 2018 is a\nlot more appropriate for training lossy compression models because it allows us\nto obtain the best possible rate subject to a distortion constraint. This\nenables pointwise model comparisons, by training two models with the same\ndistortion target and comparing their rate. We show that the method does manage\nto satisfy the constraint on a realistic image compression task, outperforms a\nconstrained optimization method based on a hinge-loss, and is more practical to\nuse for model selection than a $\\beta$-VAE.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 14:27:01 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["van Rozendaal", "Ties", ""], ["Sauti\u00e8re", "Guillaume", ""], ["Cohen", "Taco S.", ""]]}, {"id": "2005.04067", "submitter": "Nils Wilde", "authors": "Nils Wilde, Dana Kulic, and Stephen L. Smith", "title": "Active Preference Learning using Maximum Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study active preference learning as a framework for intuitively specifying\nthe behaviour of autonomous robots. In active preference learning, a user\nchooses the preferred behaviour from a set of alternatives, from which the\nrobot learns the user's preferences, modeled as a parameterized cost function.\nPrevious approaches present users with alternatives that minimize the\nuncertainty over the parameters of the cost function. However, different\nparameters might lead to the same optimal behaviour; as a consequence the\nsolution space is more structured than the parameter space. We exploit this by\nproposing a query selection that greedily reduces the maximum error ratio over\nthe solution space. In simulations we demonstrate that the proposed approach\noutperforms other state of the art techniques in both learning efficiency and\nease of queries for the user. Finally, we show that evaluating the learning\nbased on the similarities of solutions instead of the similarities of weights\nallows for better predictions for different scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 14:31:31 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 19:27:27 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Wilde", "Nils", ""], ["Kulic", "Dana", ""], ["Smith", "Stephen L.", ""]]}, {"id": "2005.04073", "submitter": "Ziyuan Zhao", "authors": "Kaixin Xu, Ziyuan Zhao, Jiapan Gu, Zeng Zeng, Chan Wan Ying, Lim Kheng\n  Choon, Thng Choon Hua, Pierce KH Chow", "title": "Multi-Instance Multi-Label Learning for Gene Mutation Prediction in\n  Hepatocellular Carcinoma", "comments": "Accepted version to be published in the 42nd IEEE Annual\n  International Conference of the IEEE Engineering in Medicine and Biology\n  Society, EMBC 2020, Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gene mutation prediction in hepatocellular carcinoma (HCC) is of great\ndiagnostic and prognostic value for personalized treatments and precision\nmedicine. In this paper, we tackle this problem with multi-instance multi-label\nlearning to address the difficulties on label correlations, label\nrepresentations, etc. Furthermore, an effective oversampling strategy is\napplied for data imbalance. Experimental results have shown the superiority of\nthe proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 14:47:25 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Xu", "Kaixin", ""], ["Zhao", "Ziyuan", ""], ["Gu", "Jiapan", ""], ["Zeng", "Zeng", ""], ["Ying", "Chan Wan", ""], ["Choon", "Lim Kheng", ""], ["Hua", "Thng Choon", ""], ["Chow", "Pierce KH", ""]]}, {"id": "2005.04074", "submitter": "Moein Khajehnejad", "authors": "Moein Khajehnejad, Ahmad Asgharian Rezaei, Mahmoudreza Babaei, Jessica\n  Hoffmann, Mahdi Jalili and Adrian Weller", "title": "Adversarial Graph Embeddings for Fair Influence Maximization over Social\n  Networks", "comments": "In Proc. of the 29th International Joint Conference on Artificial\n  Intelligence (IJCAI'20), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influence maximization is a widely studied topic in network science, where\nthe aim is to reach the maximum possible number of nodes, while only targeting\na small initial set of individuals. It has critical applications in many\nfields, including viral marketing, information propagation, news dissemination,\nand vaccinations. However, the objective does not usually take into account\nwhether the final set of influenced nodes is fair with respect to sensitive\nattributes, such as race or gender. Here we address fair influence\nmaximization, aiming to reach minorities more equitably. We introduce\nAdversarial Graph Embeddings: we co-train an auto-encoder for graph embedding\nand a discriminator to discern sensitive attributes. This leads to embeddings\nwhich are similarly distributed across sensitive attributes. We then find a\ngood initial set by clustering the embeddings. We believe we are the first to\nuse embeddings for the task of fair influence maximization. While there are\ntypically trade-offs between fairness and influence maximization objectives,\nour experiments on synthetic and real-world datasets show that our approach\ndramatically reduces disparity while remaining competitive with\nstate-of-the-art influence maximization methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 14:50:12 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 01:01:31 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Khajehnejad", "Moein", ""], ["Rezaei", "Ahmad Asgharian", ""], ["Babaei", "Mahmoudreza", ""], ["Hoffmann", "Jessica", ""], ["Jalili", "Mahdi", ""], ["Weller", "Adrian", ""]]}, {"id": "2005.04076", "submitter": "Mazen Alamir Prof", "authors": "Mazen Alamir", "title": "On the use of Data-Driven Cost Function Identification in Parametrized\n  NMPC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a framework with complete numerical investigation is proposed\nregarding the feasibility of constrained Nonlinear Model Predictive Control\n(NMPC) design using Data-Driven model of the cost function. Although the idea\nis very much in the air, this paper proposes a complete implementation using\npython modules that are made freely available on a GitHub repository. Moreover,\na discussion regarding the different ways of deriving control via data-driven\nmodeling is proposed that can be of interest to practitioners.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 14:53:35 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Alamir", "Mazen", ""]]}, {"id": "2005.04078", "submitter": "Lennart Reiher", "authors": "Lennart Reiher, Bastian Lampe, Lutz Eckstein", "title": "A Sim2Real Deep Learning Approach for the Transformation of Images from\n  Multiple Vehicle-Mounted Cameras to a Semantically Segmented Image in Bird's\n  Eye View", "comments": "Accepted to be published as part of the 23rd IEEE International\n  Conference on Intelligent Transportation Systems (ITSC), Rhodes, Greece,\n  September 20-23, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate environment perception is essential for automated driving. When\nusing monocular cameras, the distance estimation of elements in the environment\nposes a major challenge. Distances can be more easily estimated when the camera\nperspective is transformed to a bird's eye view (BEV). For flat surfaces,\nInverse Perspective Mapping (IPM) can accurately transform images to a BEV.\nThree-dimensional objects such as vehicles and vulnerable road users are\ndistorted by this transformation making it difficult to estimate their position\nrelative to the sensor. This paper describes a methodology to obtain a\ncorrected 360{\\deg} BEV image given images from multiple vehicle-mounted\ncameras. The corrected BEV image is segmented into semantic classes and\nincludes a prediction of occluded areas. The neural network approach does not\nrely on manually labeled data, but is trained on a synthetic dataset in such a\nway that it generalizes well to real-world data. By using semantically\nsegmented images as input, we reduce the reality gap between simulated and\nreal-world data and are able to show that our method can be successfully\napplied in the real world. Extensive experiments conducted on the synthetic\ndata demonstrate the superiority of our approach compared to IPM. Source code\nand datasets are available at https://github.com/ika-rwth-aachen/Cam2BEV\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 14:54:13 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Reiher", "Lennart", ""], ["Lampe", "Bastian", ""], ["Eckstein", "Lutz", ""]]}, {"id": "2005.04081", "submitter": "Yifan Qian", "authors": "Yifan Qian, Paul Expert, Pietro Panzarasa, Mauricio Barahona", "title": "Geometric graphs from data to aid classification tasks with graph\n  convolutional networks", "comments": "Published in Patterns; Date of Publication: 09 April 2021", "journal-ref": "Patterns 2.4 (2021): 100237", "doi": "10.1016/j.patter.2021.100237", "report-no": null, "categories": "cs.LG cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional classification tasks learn to assign samples to given classes\nbased solely on sample features. This paradigm is evolving to include other\nsources of information, such as known relations between samples. Here we show\nthat, even if additional relational information is not available in the data\nset, one can improve classification by constructing geometric graphs from the\nfeatures themselves, and using them within a Graph Convolutional Network. The\nimprovement in classification accuracy is maximized by graphs that capture\nsample similarity with relatively low edge density. We show that such\nfeature-derived graphs increase the alignment of the data to the ground truth\nwhile improving class separation. We also demonstrate that the graphs can be\nmade more efficient using spectral sparsification, which reduces the number of\nedges while still improving classification performance. We illustrate our\nfindings using synthetic and real-world data sets from various scientific\ndomains.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 15:00:45 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 11:28:06 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 18:34:23 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Qian", "Yifan", ""], ["Expert", "Paul", ""], ["Panzarasa", "Pietro", ""], ["Barahona", "Mauricio", ""]]}, {"id": "2005.04088", "submitter": "Xinshun Liu", "authors": "Liu Xinshun, He Xin, Mao Hui, Liu Jing, Lai Weizhong, Ye Qingwen", "title": "Automatic Cross-Domain Transfer Learning for Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning research attempts to make model induction transferable\nacross different domains. This method assumes that specific information\nregarding to which domain each instance belongs is known. This paper helps to\nextend the capability of transfer learning for linear regression problems to\nsituations where the domain information is uncertain or unknown; in fact, the\nframework can be extended to classification problems. For normal datasets, we\nassume that some latent domain information is available for transfer learning.\nThe instances in each domain can be inferred by different parameters. We obtain\nthis domain information from the distribution of the regression coefficients\ncorresponding to the explanatory variable $x$ as well as the response variable\n$y$ based on a Dirichlet process, which is more reasonable. As a result, we\ntransfer not only variable $x$ as usual but also variable $y$, which is\nchallenging since the testing data have no response value. Previous work mainly\novercomes the problem via pseudo-labelling based on transductive learning,\nwhich introduces serious bias. We provide a novel framework for analysing the\nproblem and considering this general situation: the joint distribution of\nvariable $x$ and variable $y$. Furthermore, our method controls the bias well\ncompared with previous work. We perform linear regression on the new feature\nspace that consists of different latent domains and the target domain, which is\nfrom the testing data. The experimental results show that the proposed model\nperforms well on real datasets.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 15:05:37 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Xinshun", "Liu", ""], ["Xin", "He", ""], ["Hui", "Mao", ""], ["Jing", "Liu", ""], ["Weizhong", "Lai", ""], ["Qingwen", "Ye", ""]]}, {"id": "2005.04097", "submitter": "Qiang Fan", "authors": "Qiang Fan, Jianan Bai, Hongxia Zhang, Yang Yi, Lingjia Liu", "title": "Delay-aware Resource Allocation in Fog-assisted IoT Networks Through\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fog nodes in the vicinity of IoT devices are promising to provision low\nlatency services by offloading tasks from IoT devices to them. Mobile IoT is\ncomposed by mobile IoT devices such as vehicles, wearable devices and\nsmartphones. Owing to the time-varying channel conditions, traffic loads and\ncomputing loads, it is challenging to improve the quality of service (QoS) of\nmobile IoT devices. As task delay consists of both the transmission delay and\ncomputing delay, we investigate the resource allocation (i.e., including both\nradio resource and computation resource) in both the wireless channel and fog\nnode to minimize the delay of all tasks while their QoS constraints are\nsatisfied. We formulate the resource allocation problem into an integer\nnon-linear problem, where both the radio resource and computation resource are\ntaken into account. As IoT tasks are dynamic, the resource allocation for\ndifferent tasks are coupled with each other and the future information is\nimpractical to be obtained. Therefore, we design an on-line reinforcement\nlearning algorithm to make the sub-optimal decision in real time based on the\nsystem's experience replay data. The performance of the designed algorithm has\nbeen demonstrated by extensive simulation results.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 05:07:39 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 19:45:24 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Fan", "Qiang", ""], ["Bai", "Jianan", ""], ["Zhang", "Hongxia", ""], ["Yi", "Yang", ""], ["Liu", "Lingjia", ""]]}, {"id": "2005.04107", "submitter": "Yuki Koyama", "authors": "Yuki Koyama, Issei Sato, Masataka Goto", "title": "Sequential Gallery for Interactive Visual Design Optimization", "comments": "To be published at ACM Trans. Graph. (Proc. SIGGRAPH 2020); Project\n  page available at https://koyama.xyz/project/sequential_gallery/", "journal-ref": "ACM Trans. Graph. 39, 4 (July 2020), pp.88:1-88:12", "doi": "10.1145/3386569.3392444", "report-no": null, "categories": "cs.GR cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual design tasks often involve tuning many design parameters. For example,\ncolor grading of a photograph involves many parameters, some of which\nnon-expert users might be unfamiliar with. We propose a novel user-in-the-loop\noptimization method that allows users to efficiently find an appropriate\nparameter set by exploring such a high-dimensional design space through much\neasier two-dimensional search subtasks. This method, called sequential plane\nsearch, is based on Bayesian optimization to keep necessary queries to users as\nfew as possible. To help users respond to plane-search queries, we also propose\nusing a gallery-based interface that provides options in the two-dimensional\nsubspace arranged in an adaptive grid view. We call this interactive framework\nSequential Gallery since users sequentially select the best option from the\noptions provided by the interface. Our experiment with synthetic functions\nshows that our sequential plane search can find satisfactory solutions in fewer\niterations than baselines. We also conducted a preliminary user study, results\nof which suggest that novices can effectively complete search tasks with\nSequential Gallery in a photo-enhancement scenario.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 15:24:35 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Koyama", "Yuki", ""], ["Sato", "Issei", ""], ["Goto", "Masataka", ""]]}, {"id": "2005.04111", "submitter": "Wei Wang", "authors": "Wei Wang, Zhihui Wang, Yuankai Xiang, Jing Sun, Haojie Li, Fuming Sun,\n  Zhengming Ding", "title": "Sparsely-Labeled Source Assisted Domain Adaptation", "comments": "22 pages, 6 figures, submitted to the Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain Adaptation (DA) aims to generalize the classifier learned from the\nsource domain to the target domain. Existing DA methods usually assume that\nrich labels could be available in the source domain. However, there are usually\na large number of unlabeled data but only a few labeled data in the source\ndomain, and how to transfer knowledge from this sparsely-labeled source domain\nto the target domain is still a challenge, which greatly limits their\napplication in the wild. This paper proposes a novel Sparsely-Labeled Source\nAssisted Domain Adaptation (SLSA-DA) algorithm to address the challenge with\nlimited labeled source domain samples. Specifically, due to the label scarcity\nproblem, the projected clustering is conducted on both the source and target\ndomains, so that the discriminative structures of data could be leveraged\nelegantly. Then the label propagation is adopted to propagate the labels from\nthose limited labeled source samples to the whole unlabeled data progressively,\nso that the cluster labels are revealed correctly. Finally, we jointly align\nthe marginal and conditional distributions to mitigate the cross-domain\nmismatch problem, and optimize those three procedures iteratively. However, it\nis nontrivial to incorporate those three procedures into a unified optimization\nframework seamlessly since some variables to be optimized are implicitly\ninvolved in their formulas, thus they could not promote to each other.\nRemarkably, we prove that the projected clustering and conditional distribution\nalignment could be reformulated as different expressions, thus the implicit\nvariables are revealed in different optimization steps. As such, the variables\nrelated to those three quantities could be optimized in a unified optimization\nframework and facilitate to each other, to improve the recognition performance\nobviously.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 15:37:35 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Wang", "Wei", ""], ["Wang", "Zhihui", ""], ["Xiang", "Yuankai", ""], ["Sun", "Jing", ""], ["Li", "Haojie", ""], ["Sun", "Fuming", ""], ["Ding", "Zhengming", ""]]}, {"id": "2005.04112", "submitter": "Arun Venkitaraman", "authors": "Rebecka Winqvist, Arun Venkitaraman, Bo Wahlberg", "title": "On Training and Evaluation of Neural Network Approaches for Model\n  Predictive Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The contribution of this paper is a framework for training and evaluation of\nModel Predictive Control (MPC) implemented using constrained neural networks.\nRecent studies have proposed to use neural networks with differentiable convex\noptimization layers to implement model predictive controllers. The motivation\nis to replace real-time optimization in safety critical feedback control\nsystems with learnt mappings in the form of neural networks with optimization\nlayers. Such mappings take as the input the state vector and predict the\ncontrol law as the output. The learning takes place using training data\ngenerated from off-line MPC simulations. However, a general framework for\ncharacterization of learning approaches in terms of both model validation and\nefficient training data generation is lacking in literature. In this paper, we\ntake the first steps towards developing such a coherent framework. We discuss\nhow the learning problem has similarities with system identification, in\nparticular input design, model structure selection and model validation. We\nconsider the study of neural network architectures in PyTorch with the explicit\nMPC constraints implemented as a differentiable optimization layer using CVXPY.\nWe propose an efficient approach of generating MPC input samples subject to the\nMPC model constraints using a hit-and-run sampler. The corresponding true\noutputs are generated by solving the MPC offline using OSOP. We propose\ndifferent metrics to validate the resulting approaches. Our study further aims\nto explore the advantages of incorporating domain knowledge into the network\nstructure from a training and evaluation perspective. Different model\nstructures are numerically tested using the proposed framework in order to\nobtain more insights in the properties of constrained neural networks based\nMPC.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 15:37:55 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Winqvist", "Rebecka", ""], ["Venkitaraman", "Arun", ""], ["Wahlberg", "Bo", ""]]}, {"id": "2005.04118", "submitter": "Marco Tulio Ribeiro", "authors": "Marco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin, Sameer Singh", "title": "Beyond Accuracy: Behavioral Testing of NLP models with CheckList", "comments": null, "journal-ref": "Association for Computational Linguistics (ACL), 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although measuring held-out accuracy has been the primary approach to\nevaluate generalization, it often overestimates the performance of NLP models,\nwhile alternative approaches for evaluating models either focus on individual\ntasks or on specific behaviors. Inspired by principles of behavioral testing in\nsoftware engineering, we introduce CheckList, a task-agnostic methodology for\ntesting NLP models. CheckList includes a matrix of general linguistic\ncapabilities and test types that facilitate comprehensive test ideation, as\nwell as a software tool to generate a large and diverse number of test cases\nquickly. We illustrate the utility of CheckList with tests for three tasks,\nidentifying critical failures in both commercial and state-of-art models. In a\nuser study, a team responsible for a commercial sentiment analysis model found\nnew and actionable bugs in an extensively tested model. In another user study,\nNLP practitioners with CheckList created twice as many tests, and found almost\nthree times as many bugs as users without it.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 15:48:31 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Ribeiro", "Marco Tulio", ""], ["Wu", "Tongshuang", ""], ["Guestrin", "Carlos", ""], ["Singh", "Sameer", ""]]}, {"id": "2005.04136", "submitter": "Yoojin Choi", "authors": "Yoojin Choi, Jihwan Choi, Mostafa El-Khamy, Jungwon Lee", "title": "Data-Free Network Quantization With Adversarial Knowledge Distillation", "comments": "CVPR 2020 Joint Workshop on Efficient Deep Learning in Computer\n  Vision (EDLCV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network quantization is an essential procedure in deep learning for\ndevelopment of efficient fixed-point inference models on mobile or edge\nplatforms. However, as datasets grow larger and privacy regulations become\nstricter, data sharing for model compression gets more difficult and\nrestricted. In this paper, we consider data-free network quantization with\nsynthetic data. The synthetic data are generated from a generator, while no\ndata are used in training the generator and in quantization. To this end, we\npropose data-free adversarial knowledge distillation, which minimizes the\nmaximum distance between the outputs of the teacher and the (quantized) student\nfor any adversarial samples from a generator. To generate adversarial samples\nsimilar to the original data, we additionally propose matching statistics from\nthe batch normalization layers for generated data and the original data in the\nteacher. Furthermore, we show the gain of producing diverse adversarial samples\nby using multiple generators and multiple students. Our experiments show the\nstate-of-the-art data-free model compression and quantization results for\n(wide) residual networks and MobileNet on SVHN, CIFAR-10, CIFAR-100, and\nTiny-ImageNet datasets. The accuracy losses compared to using the original\ndatasets are shown to be very minimal.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 16:24:55 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Choi", "Yoojin", ""], ["Choi", "Jihwan", ""], ["El-Khamy", "Mostafa", ""], ["Lee", "Jungwon", ""]]}, {"id": "2005.04139", "submitter": "Nanwei Wang", "authors": "Nanwei Wang, Laurent Briollais, Helene Massam", "title": "The scalable Birth-Death MCMC Algorithm for Mixed Graphical Model\n  Learning with Application to Genomic Data Integration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in biological research have seen the emergence of\nhigh-throughput technologies with numerous applications that allow the study of\nbiological mechanisms at an unprecedented depth and scale. A large amount of\ngenomic data is now distributed through consortia like The Cancer Genome Atlas\n(TCGA), where specific types of biological information on specific type of\ntissue or cell are available. In cancer research, the challenge is now to\nperform integrative analyses of high-dimensional multi-omic data with the goal\nto better understand genomic processes that correlate with cancer outcomes,\ne.g. elucidate gene networks that discriminate a specific cancer subgroups\n(cancer sub-typing) or discovering gene networks that overlap across different\ncancer types (pan-cancer studies). In this paper, we propose a novel mixed\ngraphical model approach to analyze multi-omic data of different types\n(continuous, discrete and count) and perform model selection by extending the\nBirth-Death MCMC (BDMCMC) algorithm initially proposed by\n\\citet{stephens2000bayesian} and later developed by\n\\cite{mohammadi2015bayesian}. We compare the performance of our method to the\nLASSO method and the standard BDMCMC method using simulations and find that our\nmethod is superior in terms of both computational efficiency and the accuracy\nof the model selection results. Finally, an application to the TCGA breast\ncancer data shows that integrating genomic information at different levels\n(mutation and expression data) leads to better subtyping of breast cancers.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 16:34:58 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Wang", "Nanwei", ""], ["Briollais", "Laurent", ""], ["Massam", "Helene", ""]]}, {"id": "2005.04149", "submitter": "Mariya Zheleva", "authors": "Wei Xiong, Karyn Doke, Petko Bogdanov, Mariya Zheleva", "title": "LinksIQ: Robust and Efficient Modulation Recognition with Imperfect\n  Spectrum Scans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While critical for the practical progress of spectrum sharing, modulation\nrecognition has so far been investigated under unrealistic assumptions: (i) a\ntransmitter's bandwidth must be scanned alone and in full, (ii) prior knowledge\nof the technology must be available and (iii) a transmitter must be\ntrustworthy. In reality these assumptions cannot be readily met, as a\ntransmitter's bandwidth may only be scanned intermittently, partially, or\nalongside other transmitters, and modulation obfuscation may be introduced by\nshort-lived scans or malicious activity.\n  This paper presents LinksIQ, which bridges the gap between real-world\nspectrum sensing and the growing body of modrec methods designed under\nsimplifying assumptions. Our key insight is that ordered IQ samples form\ndistinctive patterns across modulations, which persist even with scan\ndeficiencies. We mine these patterns through a Fisher Kernel framework and\nemploy lightweight linear support vector machine for modulation classification.\nLinksIQ is robust to noise, scan partiality and data biases without utilizing\nprior knowledge of transmitter technology. Its accuracy consistently\noutperforms baselines in both simulated and real traces. We evaluate LinksIQ\nperformance in a testbed using two popular SDR platforms, RTL-SDR and USRP. We\ndemonstrate high detection accuracy (i.e. 0.74) even with a $20 RTL-SDR\nscanning at 50% transmitter overlap.\n  This constitutes an average of 43% improvement over existing counterparts\nemployed on RTL-SDR scans. We also explore the effects of platform-aware\nclassifier training and discuss implications on real-world modrec system\ndesign. Our results demonstrate the feasibility of low-cost transmitter\nfingerprinting at scale.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 12:16:38 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Xiong", "Wei", ""], ["Doke", "Karyn", ""], ["Bogdanov", "Petko", ""], ["Zheleva", "Mariya", ""]]}, {"id": "2005.04153", "submitter": "Vasco Lopes Ferrinho", "authors": "Vasco Lopes, Paulo Fazendeiro", "title": "A Hybrid Method for Training Convolutional Neural Networks", "comments": "1 figure, 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence algorithms have been steadily increasing in\npopularity and usage. Deep Learning, allows neural networks to be trained using\nhuge datasets and also removes the need for human extracted features, as it\nautomates the feature learning process. In the hearth of training deep neural\nnetworks, such as Convolutional Neural Networks, we find backpropagation, that\nby computing the gradient of the loss function with respect to the weights of\nthe network for a given input, it allows the weights of the network to be\nadjusted to better perform in the given task. In this paper, we propose a\nhybrid method that uses both backpropagation and evolutionary strategies to\ntrain Convolutional Neural Networks, where the evolutionary strategies are used\nto help to avoid local minimas and fine-tune the weights, so that the network\nachieves higher accuracy results. We show that the proposed hybrid method is\ncapable of improving upon regular training in the task of image classification\nin CIFAR-10, where a VGG16 model was used and the final test results increased\n0.61%, in average, when compared to using only backpropagation.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 17:52:48 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Lopes", "Vasco", ""], ["Fazendeiro", "Paulo", ""]]}, {"id": "2005.04154", "submitter": "Setareh Maghsudi", "authors": "Setareh Maghsudi and Mihaela van der Schaar", "title": "A Non-Stationary Bandit-Learning Approach to Energy-Efficient\n  Femto-Caching with Rateless-Coded Transmission", "comments": null, "journal-ref": null, "doi": "10.1109/TWC.2020.2989179", "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-increasing demand for media streaming together with limited backhaul\ncapacity renders developing efficient file-delivery methods imperative. One\nsuch method is femto-caching, which, despite its great potential, imposes\nseveral challenges such as efficient resource management. We study a resource\nallocation problem for joint caching and transmission in small cell networks,\nwhere the system operates in two consecutive phases: (i) cache placement, and\n(ii) joint file- and transmit power selection followed by broadcasting. We\ndefine the utility of every small base station in terms of the number of\nsuccessful reconstructions per unit of transmission power. We then formulate\nthe problem as to select a file from the cache together with a transmission\npower level for every broadcast round so that the accumulated utility over the\nhorizon is maximized. The former problem boils down to a stochastic knapsack\nproblem, and we cast the latter as a multi-armed bandit problem. We develop a\nsolution to each problem and provide theoretical and numerical evaluations. In\ncontrast to the state-of-the-art research, the proposed approach is especially\nsuitable for networks with time-variant statistical properties. Moreover, it is\napplicable and operates well even when no initial information about the\nstatistical characteristics of the random parameters such as file popularity\nand channel quality is available.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 09:07:17 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Maghsudi", "Setareh", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2005.04155", "submitter": "Amir Mosavi Prof", "authors": "Saeed Nosratabadi, Felde Imre, Karoly Szell, Sina Ardabili, Bertalan\n  Beszedes, Amir Mosavi", "title": "Hybrid Machine Learning Models for Crop Yield Prediction", "comments": "5 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prediction of crop yield is essential for food security policymaking,\nplanning, and trade. The objective of the current study is to propose novel\ncrop yield prediction models based on hybrid machine learning methods. In this\nstudy, the performance of the artificial neural networks-imperialist\ncompetitive algorithm (ANN-ICA) and artificial neural networks-gray wolf\noptimizer (ANN-GWO) models for the crop yield prediction are evaluated.\nAccording to the results, ANN-GWO, with R of 0.48, RMSE of 3.19, and MEA of\n26.65, proved a better performance in the crop yield prediction compared to the\nANN-ICA model. The results can be used by either practitioners, researchers or\npolicymakers for food security.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 12:01:27 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Nosratabadi", "Saeed", ""], ["Imre", "Felde", ""], ["Szell", "Karoly", ""], ["Ardabili", "Sina", ""], ["Beszedes", "Bertalan", ""], ["Mosavi", "Amir", ""]]}, {"id": "2005.04156", "submitter": "Daniel Leite", "authors": "Leticia Decker, Daniel Leite, Fabio Viola, Daniele Bonacorsi", "title": "Comparison of Evolving Granular Classifiers applied to Anomaly Detection\n  for Predictive Maintenance in Computing Centers", "comments": "8 pages, 8 figures, IEEE Conference on Evolving and Adaptive\n  Intelligent Systems (EAIS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Log-based predictive maintenance of computing centers is a main concern\nregarding the worldwide computing grid that supports the CERN (European\nOrganization for Nuclear Research) physics experiments. A log, as\nevent-oriented adhoc information, is quite often given as unstructured big\ndata. Log data processing is a time-consuming computational task. The goal is\nto grab essential information from a continuously changeable grid environment\nto construct a classification model. Evolving granular classifiers are suited\nto learn from time-varying log streams and, therefore, perform online\nclassification of the severity of anomalies. We formulated a 4-class online\nanomaly classification problem, and employed time windows between landmarks and\ntwo granular computing methods, namely, Fuzzy-set-Based evolving Modeling\n(FBeM) and evolving Granular Neural Network (eGNN), to model and monitor\nlogging activity rate. The results of classification are of utmost importance\nfor predictive maintenance because priority can be given to specific time\nintervals in which the classifier indicates the existence of high or medium\nseverity anomalies.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 14:08:50 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Decker", "Leticia", ""], ["Leite", "Daniel", ""], ["Viola", "Fabio", ""], ["Bonacorsi", "Daniele", ""]]}, {"id": "2005.04165", "submitter": "Nathan Wycoff", "authors": "Nathan Wycoff, Prasanna Balaprakash, Fangfang Xia", "title": "Towards On-Chip Bayesian Neuromorphic Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If edge devices are to be deployed to critical applications where their\ndecisions could have serious financial, political, or public-health\nconsequences, they will need a way to signal when they are not sure how to\nreact to their environment. For instance, a lost delivery drone could make its\nway back to a distribution center or contact the client if it is confused about\nhow exactly to make its delivery, rather than taking the action which is \"most\nlikely\" correct. This issue is compounded for health care or military\napplications. However, the brain-realistic temporal credit assignment problem\nneuromorphic computing algorithms have to solve is difficult. The double role\nweights play in backpropagation-based-learning, dictating how the network\nreacts to both input and feedback, needs to be decoupled. e-prop 1 is a\npromising learning algorithm that tackles this with Broadcast Alignment (a\ntechnique where network weights are replaced with random weights during\nfeedback) and accumulated local information. We investigate under what\nconditions the Bayesian loss term can be expressed in a similar fashion,\nproposing an algorithm that can be computed with only local information as well\nand which is thus no more difficult to implement on hardware. This algorithm is\nexhibited on a store-recall problem, which suggests that it can learn good\nuncertainty on decisions to be made over time.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 18:45:03 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Wycoff", "Nathan", ""], ["Balaprakash", "Prasanna", ""], ["Xia", "Fangfang", ""]]}, {"id": "2005.04167", "submitter": "Ruthvik Vaila", "authors": "Ruthvik Vaila, John Chiasson, Vishal Saxena", "title": "Continuous Learning in a Single-Incremental-Task Scenario with Spike\n  Features", "comments": "Submitted to ICONS 2020", "journal-ref": "nternational Conference on Neuromorphic Systems 2020", "doi": "10.1145/3407197.3407213", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Deep Neural Networks (DNNs) have two key deficiencies, their dependence on\nhigh precision computing and their inability to perform sequential learning,\nthat is, when a DNN is trained on a first task and the same DNN is trained on\nthe next task it forgets the first task. This phenomenon of forgetting previous\ntasks is also referred to as catastrophic forgetting. On the other hand a\nmammalian brain outperforms DNNs in terms of energy efficiency and the ability\nto learn sequentially without catastrophically forgetting. Here, we use\nbio-inspired Spike Timing Dependent Plasticity (STDP)in the feature extraction\nlayers of the network with instantaneous neurons to extract meaningful\nfeatures. In the classification sections of the network we use a modified\nsynaptic intelligence that we refer to as cost per synapse metric as a\nregularizer to immunize the network against catastrophic forgetting in a\nSingle-Incremental-Task scenario (SIT). In this study, we use MNIST handwritten\ndigits dataset that was divided into five sub-tasks.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 16:18:20 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Vaila", "Ruthvik", ""], ["Chiasson", "John", ""], ["Saxena", "Vishal", ""]]}, {"id": "2005.04168", "submitter": "Maxence Ernoult", "authors": "Maxence Ernoult, Julie Grollier, Damien Querlioz, Yoshua Bengio,\n  Benjamin Scellier", "title": "Equilibrium Propagation with Continual Weight Updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equilibrium Propagation (EP) is a learning algorithm that bridges Machine\nLearning and Neuroscience, by computing gradients closely matching those of\nBackpropagation Through Time (BPTT), but with a learning rule local in space.\nGiven an input $x$ and associated target $y$, EP proceeds in two phases: in the\nfirst phase neurons evolve freely towards a first steady state; in the second\nphase output neurons are nudged towards $y$ until they reach a second steady\nstate. However, in existing implementations of EP, the learning rule is not\nlocal in time: the weight update is performed after the dynamics of the second\nphase have converged and requires information of the first phase that is no\nlonger available physically. In this work, we propose a version of EP named\nContinual Equilibrium Propagation (C-EP) where neuron and synapse dynamics\noccur simultaneously throughout the second phase, so that the weight update\nbecomes local in time. Such a learning rule local both in space and time opens\nthe possibility of an extremely energy efficient hardware implementation of EP.\nWe prove theoretically that, provided the learning rates are sufficiently\nsmall, at each time step of the second phase the dynamics of neurons and\nsynapses follow the gradients of the loss given by BPTT (Theorem 1). We\ndemonstrate training with C-EP on MNIST and generalize C-EP to neural networks\nwhere neurons are connected by asymmetric connections. We show through\nexperiments that the more the network updates follows the gradients of BPTT,\nthe best it performs in terms of training. These results bring EP a step closer\nto biology by better complying with hardware constraints while maintaining its\nintimate link with backpropagation.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 14:54:30 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Ernoult", "Maxence", ""], ["Grollier", "Julie", ""], ["Querlioz", "Damien", ""], ["Bengio", "Yoshua", ""], ["Scellier", "Benjamin", ""]]}, {"id": "2005.04169", "submitter": "Maxence Ernoult", "authors": "Maxence Ernoult, Julie Grollier, Damien Querlioz, Yoshua Bengio,\n  Benjamin Scellier", "title": "Continual Weight Updates and Convolutional Architectures for Equilibrium\n  Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equilibrium Propagation (EP) is a biologically inspired alternative algorithm\nto backpropagation (BP) for training neural networks. It applies to RNNs fed by\na static input x that settle to a steady state, such as Hopfield networks. EP\nis similar to BP in that in the second phase of training, an error signal\npropagates backwards in the layers of the network, but contrary to BP, the\nlearning rule of EP is spatially local. Nonetheless, EP suffers from two major\nlimitations. On the one hand, due to its formulation in terms of real-time\ndynamics, EP entails long simulation times, which limits its applicability to\npractical tasks. On the other hand, the biological plausibility of EP is\nlimited by the fact that its learning rule is not local in time: the synapse\nupdate is performed after the dynamics of the second phase have converged and\nrequires information of the first phase that is no longer available physically.\nOur work addresses these two issues and aims at widening the spectrum of EP\nfrom standard machine learning models to more bio-realistic neural networks.\nFirst, we propose a discrete-time formulation of EP which enables to simplify\nequations, speed up training and extend EP to CNNs. Our CNN model achieves the\nbest performance ever reported on MNIST with EP. Using the same discrete-time\nformulation, we introduce Continual Equilibrium Propagation (C-EP): the weights\nof the network are adjusted continually in the second phase of training using\nlocal information in space and time. We show that in the limit of slow changes\nof synaptic strengths and small nudging, C-EP is equivalent to BPTT (Theorem\n1). We numerically demonstrate Theorem 1 and C-EP training on MNIST and\ngeneralize it to the bio-realistic situation of a neural network with\nasymmetric connections between neurons.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 12:14:06 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Ernoult", "Maxence", ""], ["Grollier", "Julie", ""], ["Querlioz", "Damien", ""], ["Bengio", "Yoshua", ""], ["Scellier", "Benjamin", ""]]}, {"id": "2005.04170", "submitter": "James Smith", "authors": "James E. Smith", "title": "A Neuromorphic Paradigm for Online Unsupervised Clustering", "comments": "Submitted to 53rd IEEE/ACM International Symposium on\n  Microarchitecture", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A computational paradigm based on neuroscientific concepts is proposed and\nshown to be capable of online unsupervised clustering. Because it is an online\nmethod, it is readily amenable to streaming realtime applications and is\ncapable of dynamically adjusting to macro-level input changes. All operations,\nboth training and inference, are localized and efficient. The paradigm is\nimplemented as a cognitive column that incorporates five key elements: 1)\ntemporal coding, 2) an excitatory neuron model for inference, 3)\nwinner-take-all inhibition, 4) a column architecture that combines excitation\nand inhibition, 5) localized training via spike timing de-pendent plasticity\n(STDP). These elements are described and discussed, and a prototype column is\ngiven. The prototype column is simulated with a semi-synthetic benchmark and is\nshown to have performance characteristics on par with classic k-means.\nSimulations reveal the inner operation and capabilities of the column with\nemphasis on excitatory neuron response functions and STDP implementations.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 14:02:34 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Smith", "James E.", ""]]}, {"id": "2005.04171", "submitter": "Maryam Parsa", "authors": "Maryam Parsa, Catherine D. Schuman, Prasanna Date, Derek C. Rose, Bill\n  Kay, J. Parker Mitchell, Steven R. Young, Ryan Dellana, William Severa,\n  Thomas E. Potok, Kaushik Roy", "title": "Hyperparameter Optimization in Binary Communication Networks for\n  Neuromorphic Deployment", "comments": "9 pages, 3 figures, To appear in WCCI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training neural networks for neuromorphic deployment is non-trivial. There\nhave been a variety of approaches proposed to adapt back-propagation or\nback-propagation-like algorithms appropriate for training. Considering that\nthese networks often have very different performance characteristics than\ntraditional neural networks, it is often unclear how to set either the network\ntopology or the hyperparameters to achieve optimal performance. In this work,\nwe introduce a Bayesian approach for optimizing the hyperparameters of an\nalgorithm for training binary communication networks that can be deployed to\nneuromorphic hardware. We show that by optimizing the hyperparameters on this\nalgorithm for each dataset, we can achieve improvements in accuracy over the\nprevious state-of-the-art for this algorithm on each dataset (by up to 15\npercent). This jump in performance continues to emphasize the potential when\nconverting traditional neural networks to binary communication applicable to\nneuromorphic hardware.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 01:15:45 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Parsa", "Maryam", ""], ["Schuman", "Catherine D.", ""], ["Date", "Prasanna", ""], ["Rose", "Derek C.", ""], ["Kay", "Bill", ""], ["Mitchell", "J. Parker", ""], ["Young", "Steven R.", ""], ["Dellana", "Ryan", ""], ["Severa", "William", ""], ["Potok", "Thomas E.", ""], ["Roy", "Kaushik", ""]]}, {"id": "2005.04176", "submitter": "Caroline Wang", "authors": "Caroline Wang, Bin Han, Bhrij Patel, Feroze Mohideen, Cynthia Rudin", "title": "In Pursuit of Interpretable, Fair and Accurate Machine Learning for\n  Criminal Recidivism Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, academics and investigative journalists have criticized\ncertain commercial risk assessments for their black-box nature and failure to\nsatisfy competing notions of fairness. Since then, the field of interpretable\nmachine learning has created simple yet effective algorithms, while the field\nof fair machine learning has proposed various mathematical definitions of\nfairness. However, studies from these fields are largely independent, despite\nthe fact that many applications of machine learning to social issues require\nboth fairness and interpretability. We explore the intersection by revisiting\nthe recidivism prediction problem using state-of-the-art tools from\ninterpretable machine learning, and assessing the models for performance,\ninterpretability, and fairness. Unlike previous works, we compare against two\nexisting risk assessments (COMPAS and the Arnold Public Safety Assessment) and\ntrain models that output probabilities rather than binary predictions. We\npresent multiple models that beat these risk assessments in performance, and\nprovide a fairness analysis of these models. Our results imply that machine\nlearning models should be trained separately for separate locations, and\nupdated over time.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 17:16:31 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Wang", "Caroline", ""], ["Han", "Bin", ""], ["Patel", "Bhrij", ""], ["Mohideen", "Feroze", ""], ["Rudin", "Cynthia", ""]]}, {"id": "2005.04184", "submitter": "Donald Reising", "authors": "Mohamed Fadul, Donald Reising, T. Daniel Loveless, Abdul Ofoli", "title": "Preprint: Using RF-DNA Fingerprints To Classify OFDM Transmitters Under\n  Rayleigh Fading Conditions", "comments": "13 pages, 14 total figures/images, Currently under review by the IEEE\n  Transactions on Information Forensics and Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) is a collection of Internet connected devices\ncapable of interacting with the physical world and computer systems. It is\nestimated that the IoT will consist of approximately fifty billion devices by\nthe year 2020. In addition to the sheer numbers, the need for IoT security is\nexacerbated by the fact that many of the edge devices employ weak to no\nencryption of the communication link. It has been estimated that almost 70% of\nIoT devices use no form of encryption. Previous research has suggested the use\nof Specific Emitter Identification (SEI), a physical layer technique, as a\nmeans of augmenting bit-level security mechanism such as encryption. The work\npresented here integrates a Nelder-Mead based approach for estimating the\nRayleigh fading channel coefficients prior to the SEI approach known as RF-DNA\nfingerprinting. The performance of this estimator is assessed for degrading\nsignal-to-noise ratio and compared with least square and minimum mean squared\nerror channel estimators. Additionally, this work presents classification\nresults using RF-DNA fingerprints that were extracted from received signals\nthat have undergone Rayleigh fading channel correction using Minimum Mean\nSquared Error (MMSE) equalization. This work also performs radio discrimination\nusing RF-DNA fingerprints generated from the normalized magnitude-squared and\nphase response of Gabor coefficients as well as two classifiers. Discrimination\nof four 802.11a Wi-Fi radios achieves an average percent correct classification\nof 90% or better for signal-to-noise ratios of 18 and 21 dB or greater using a\nRayleigh fading channel comprised of two and five paths, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 13:53:25 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Fadul", "Mohamed", ""], ["Reising", "Donald", ""], ["Loveless", "T. Daniel", ""], ["Ofoli", "Abdul", ""]]}, {"id": "2005.04185", "submitter": "Alexandros Papadopoulos", "authors": "Alexandros Papadopoulos, Konstantinos Kyritsis, Lisa Klingelhoefer,\n  Sevasti Bostanjopoulou, K. Ray Chaudhuri, Anastasios Delopoulos", "title": "Detecting Parkinsonian Tremor from IMU Data Collected In-The-Wild using\n  Deep Multiple-Instance Learning", "comments": null, "journal-ref": null, "doi": "10.1109/JBHI.2019.2961748", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parkinson's Disease (PD) is a slowly evolving neuro-logical disease that\naffects about 1% of the population above 60 years old, causing symptoms that\nare subtle at first, but whose intensity increases as the disease progresses.\nAutomated detection of these symptoms could offer clues as to the early onset\nof the disease, thus improving the expected clinical outcomes of the patients\nvia appropriately targeted interventions. This potential has led many\nresearchers to develop methods that use widely available sensors to measure and\nquantify the presence of PD symptoms such as tremor, rigidity and braykinesia.\nHowever, most of these approaches operate under controlled settings, such as in\nlab or at home, thus limiting their applicability under free-living conditions.\nIn this work, we present a method for automatically identifying tremorous\nepisodes related to PD, based on IMU signals captured via a smartphone device.\nWe propose a Multiple-Instance Learning approach, wherein a subject is\nrepresented as an unordered bag of accelerometer signal segments and a single,\nexpert-provided, tremor annotation. Our method combines deep feature learning\nwith a learnable pooling stage that is able to identify key instances within\nthe subject bag, while still being trainable end-to-end. We validate our\nalgorithm on a newly introduced dataset of 45 subjects, containing\naccelerometer signals collected entirely in-the-wild. The good classification\nperformance obtained in the conducted experiments suggests that the proposed\nmethod can efficiently navigate the noisy environment of in-the-wild\nrecordings.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 09:02:30 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Papadopoulos", "Alexandros", ""], ["Kyritsis", "Konstantinos", ""], ["Klingelhoefer", "Lisa", ""], ["Bostanjopoulou", "Sevasti", ""], ["Chaudhuri", "K. Ray", ""], ["Delopoulos", "Anastasios", ""]]}, {"id": "2005.04188", "submitter": "Tongge Huang", "authors": "Tongge Huang, Pranamesh Chakraborty, Anuj Sharma", "title": "Deep convolutional generative adversarial networks for traffic data\n  imputation encoding time series as images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sufficient high-quality traffic data are a crucial component of various\nIntelligent Transportation System (ITS) applications and research related to\ncongestion prediction, speed prediction, incident detection, and other traffic\noperation tasks. Nonetheless, missing traffic data are a common issue in sensor\ndata which is inevitable due to several reasons, such as malfunctioning, poor\nmaintenance or calibration, and intermittent communications. Such missing data\nissues often make data analysis and decision-making complicated and\nchallenging. In this study, we have developed a generative adversarial network\n(GAN) based traffic sensor data imputation framework (TSDIGAN) to efficiently\nreconstruct the missing data by generating realistic synthetic data. In recent\nyears, GANs have shown impressive success in image data generation. However,\ngenerating traffic data by taking advantage of GAN based modeling is a\nchallenging task, since traffic data have strong time dependency. To address\nthis problem, we propose a novel time-dependent encoding method called the\nGramian Angular Summation Field (GASF) that converts the problem of traffic\ntime-series data generation into that of image generation. We have evaluated\nand tested our proposed model using the benchmark dataset provided by Caltrans\nPerformance Management Systems (PeMS). This study shows that the proposed model\ncan significantly improve the traffic data imputation accuracy in terms of Mean\nAbsolute Error (MAE) and Root Mean Squared Error (RMSE) compared to\nstate-of-the-art models on the benchmark dataset. Further, the model achieves\nreasonably high accuracy in imputation tasks even under a very high missing\ndata rate ($>$ 50\\%), which shows the robustness and efficiency of the proposed\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 19:14:02 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Huang", "Tongge", ""], ["Chakraborty", "Pranamesh", ""], ["Sharma", "Anuj", ""]]}, {"id": "2005.04210", "submitter": "Y Cooper", "authors": "Y. Cooper", "title": "The critical locus of overparameterized neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many aspects of the geometry of loss functions in deep learning remain\nmysterious. In this paper, we work toward a better understanding of the\ngeometry of the loss function $L$ of overparameterized feedforward neural\nnetworks. In this setting, we identify several components of the critical locus\nof $L$ and study their geometric properties. For networks of depth $\\ell \\geq\n4$, we identify a locus of critical points we call the star locus $S$. Within\n$S$ we identify a positive-dimensional sublocus $C$ with the property that for\n$p \\in C$, $p$ is a degenerate critical point, and no existing theoretical\nresult guarantees that gradient descent will not converge to $p$. For very wide\nnetworks, we build on earlier work and show that all critical points of $L$ are\ndegenerate, and give lower bounds on the number of zero eigenvalues of the\nHessian at each critical point. For networks that are both deep and very wide,\nwe compare the growth rates of the zero eigenspaces of the Hessian at all the\ndifferent families of critical points that we identify. The results in this\npaper provide a starting point to a more quantitative understanding of the\nproperties of various components of the critical locus of $L$.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 17:59:17 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 01:07:12 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Cooper", "Y.", ""]]}, {"id": "2005.04211", "submitter": "Anirbit Mukherjee", "authors": "Sayar Karmakar and Anirbit Mukherjee", "title": "A Study of Neural Training with Iterative Non-Gradient Methods", "comments": "34 pages. In version 4, we have given experimental demonstration of\n  the 2 main neural training algorithms presented in this paper in sections 3\n  and 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we demonstrate provable guarantees on the training of depth-$2$\nneural networks in new regimes than previously explored. (1) First we give a\nsimple stochastic algorithm that can train a $\\rm ReLU$ gate in the realizable\nsetting in linear time while using significantly milder conditions on the data\ndistribution than previous results. Leveraging some additional distributional\nassumptions we also show approximate recovery of the true label generating\nparameters when training a $\\rm ReLU$ gate while a probabilistic adversary is\nallowed to corrupt the true labels of the training data. Our guarantee on\nrecovering the true weight degrades gracefully with increasing probability of\nattack and it's nearly optimal in the worst case. Additionally, our analysis\nallows for mini-batching and computes how the convergence time scales with the\nmini-batch size. (2) Secondly, we focus on the question of provable\ninterpolation of arbitrary data by finitely large neural nets. We exhibit a\nnon-gradient iterative algorithm \"${\\rm Neuro{-}Tron}$\" which gives a\nfirst-of-its-kind poly-time approximate solving of a neural regression (here in\nthe $\\ell_\\infty$-norm) problem at finite net widths and for non-realizable\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 17:59:23 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 05:57:31 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 18:51:02 GMT"}, {"version": "v4", "created": "Thu, 27 May 2021 04:31:52 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Karmakar", "Sayar", ""], ["Mukherjee", "Anirbit", ""]]}, {"id": "2005.04232", "submitter": "Keyon Vafa", "authors": "Keyon Vafa, Suresh Naidu, David M. Blei", "title": "Text-Based Ideal Points", "comments": "Appeared in Proceedings of the 2020 Conference of the Association for\n  Computational Linguistics (ACL 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ideal point models analyze lawmakers' votes to quantify their political\npositions, or ideal points. But votes are not the only way to express a\npolitical position. Lawmakers also give speeches, release press statements, and\npost tweets. In this paper, we introduce the text-based ideal point model\n(TBIP), an unsupervised probabilistic topic model that analyzes texts to\nquantify the political positions of its authors. We demonstrate the TBIP with\ntwo types of politicized text data: U.S. Senate speeches and senator tweets.\nThough the model does not analyze their votes or political affiliations, the\nTBIP separates lawmakers by party, learns interpretable politicized topics, and\ninfers ideal points close to the classical vote-based ideal points. One benefit\nof analyzing texts, as opposed to votes, is that the TBIP can estimate ideal\npoints of anyone who authors political texts, including non-voting actors. To\nthis end, we use it to study tweets from the 2020 Democratic presidential\ncandidates. Using only the texts of their tweets, it identifies them along an\ninterpretable progressive-to-moderate spectrum.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 21:16:42 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 00:16:52 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Vafa", "Keyon", ""], ["Naidu", "Suresh", ""], ["Blei", "David M.", ""]]}, {"id": "2005.04258", "submitter": "Vivek Singh", "authors": "Walid Bekhtaoui, Ruhan Sa, Brian Teixeira, Vivek Singh, Klaus\n  Kirchberg, Yao-jen Chang, Ankur Kapoor", "title": "View Invariant Human Body Detection and Pose Estimation from Multiple\n  Depth Sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point cloud based methods have produced promising results in areas such as 3D\nobject detection in autonomous driving. However, most of the recent point cloud\nwork focuses on single depth sensor data, whereas less work has been done on\nindoor monitoring applications, such as operation room monitoring in hospitals\nor indoor surveillance. In these scenarios multiple cameras are often used to\ntackle occlusion problems. We propose an end-to-end multi-person 3D pose\nestimation network, Point R-CNN, using multiple point cloud sources. We conduct\nextensive experiments to simulate challenging real world cases, such as\nindividual camera failures, various target appearances, and complex cluttered\nscenes with the CMU panoptic dataset and the MVOR operation room dataset.\nUnlike most of the previous methods that attempt to use multiple sensor\ninformation by building complex fusion models, which often lead to poor\ngeneralization, we take advantage of the efficiency of concatenating point\nclouds to fuse the information at the input level. In the meantime, we show our\nend-to-end network greatly outperforms cascaded state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 19:06:28 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Bekhtaoui", "Walid", ""], ["Sa", "Ruhan", ""], ["Teixeira", "Brian", ""], ["Singh", "Vivek", ""], ["Kirchberg", "Klaus", ""], ["Chang", "Yao-jen", ""], ["Kapoor", "Ankur", ""]]}, {"id": "2005.04259", "submitter": "Jiyang Gao", "authors": "Jiyang Gao, Chen Sun, Hang Zhao, Yi Shen, Dragomir Anguelov, Congcong\n  Li, Cordelia Schmid", "title": "VectorNet: Encoding HD Maps and Agent Dynamics from Vectorized\n  Representation", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavior prediction in dynamic, multi-agent systems is an important problem\nin the context of self-driving cars, due to the complex representations and\ninteractions of road components, including moving agents (e.g. pedestrians and\nvehicles) and road context information (e.g. lanes, traffic lights). This paper\nintroduces VectorNet, a hierarchical graph neural network that first exploits\nthe spatial locality of individual road components represented by vectors and\nthen models the high-order interactions among all components. In contrast to\nmost recent approaches, which render trajectories of moving agents and road\ncontext information as bird-eye images and encode them with convolutional\nneural networks (ConvNets), our approach operates on a vector representation.\nBy operating on the vectorized high definition (HD) maps and agent\ntrajectories, we avoid lossy rendering and computationally intensive ConvNet\nencoding steps. To further boost VectorNet's capability in learning context\nfeatures, we propose a novel auxiliary task to recover the randomly masked out\nmap entities and agent trajectories based on their context. We evaluate\nVectorNet on our in-house behavior prediction benchmark and the recently\nreleased Argoverse forecasting dataset. Our method achieves on par or better\nperformance than the competitive rendering approach on both benchmarks while\nsaving over 70% of the model parameters with an order of magnitude reduction in\nFLOPs. It also outperforms the state of the art on the Argoverse dataset.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 19:07:03 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Gao", "Jiyang", ""], ["Sun", "Chen", ""], ["Zhao", "Hang", ""], ["Shen", "Yi", ""], ["Anguelov", "Dragomir", ""], ["Li", "Congcong", ""], ["Schmid", "Cordelia", ""]]}, {"id": "2005.04269", "submitter": "Pavel Shvechikov", "authors": "Arsenii Kuznetsov, Pavel Shvechikov, Alexander Grishin, Dmitry Vetrov", "title": "Controlling Overestimation Bias with Truncated Mixture of Continuous\n  Distributional Quantile Critics", "comments": "Under review by the International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overestimation bias is one of the major impediments to accurate\noff-policy learning. This paper investigates a novel way to alleviate the\noverestimation bias in a continuous control setting. Our method---Truncated\nQuantile Critics, TQC,---blends three ideas: distributional representation of a\ncritic, truncation of critics prediction, and ensembling of multiple critics.\nDistributional representation and truncation allow for arbitrary granular\noverestimation control, while ensembling provides additional score\nimprovements. TQC outperforms the current state of the art on all environments\nfrom the continuous control benchmark suite, demonstrating 25% improvement on\nthe most challenging Humanoid environment.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 19:52:26 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Kuznetsov", "Arsenii", ""], ["Shvechikov", "Pavel", ""], ["Grishin", "Alexander", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "2005.04272", "submitter": "Liang Tong", "authors": "Liang Tong, Minzhe Guo, Atul Prakash, Yevgeniy Vorobeychik", "title": "Towards Robustness against Unsuspicious Adversarial Examples", "comments": "v2.0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the remarkable success of deep neural networks, significant concerns\nhave emerged about their robustness to adversarial perturbations to inputs.\nWhile most attacks aim to ensure that these are imperceptible, physical\nperturbation attacks typically aim for being unsuspicious, even if perceptible.\nHowever, there is no universal notion of what it means for adversarial examples\nto be unsuspicious. We propose an approach for modeling suspiciousness by\nleveraging cognitive salience. Specifically, we split an image into foreground\n(salient region) and background (the rest), and allow significantly larger\nadversarial perturbations in the background, while ensuring that cognitive\nsalience of background remains low. We describe how to compute the resulting\nnon-salience-preserving dual-perturbation attacks on classifiers. We then\nexperimentally demonstrate that our attacks indeed do not significantly change\nperceptual salience of the background, but are highly effective against\nclassifiers robust to conventional attacks. Furthermore, we show that\nadversarial training with dual-perturbation attacks yields classifiers that are\nmore robust to these than state-of-the-art robust learning approaches, and\ncomparable in terms of robustness to conventional attacks.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 20:06:47 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 16:58:09 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Tong", "Liang", ""], ["Guo", "Minzhe", ""], ["Prakash", "Atul", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "2005.04275", "submitter": "Jiayi Liu", "authors": "Jiayi Liu, Samarth Tripathi, Unmesh Kurup, Mohak Shah", "title": "Pruning Algorithms to Accelerate Convolutional Neural Networks for Edge\n  Applications: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the general trend of increasing Convolutional Neural Network (CNN) model\nsizes, model compression and acceleration techniques have become critical for\nthe deployment of these models on edge devices. In this paper, we provide a\ncomprehensive survey on Pruning, a major compression strategy that removes\nnon-critical or redundant neurons from a CNN model. The survey covers the\noverarching motivation for pruning, different strategies and criteria, their\nadvantages and drawbacks, along with a compilation of major pruning techniques.\nWe conclude the survey with a discussion on alternatives to pruning and current\nchallenges for the model compression community.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 20:12:45 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Liu", "Jiayi", ""], ["Tripathi", "Samarth", ""], ["Kurup", "Unmesh", ""], ["Shah", "Mohak", ""]]}, {"id": "2005.04277", "submitter": "Peng Su", "authors": "Peng Su and K. Vijay-Shanker", "title": "Adversarial Learning for Supervised and Semi-supervised Relation\n  Extraction in Biomedical Literature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is a technique of improving model performance by\ninvolving adversarial examples in the training process. In this paper, we\ninvestigate adversarial training with multiple adversarial examples to benefit\nthe relation extraction task. We also apply adversarial training technique in\nsemi-supervised scenarios to utilize unlabeled data. The evaluation results on\nprotein-protein interaction and protein subcellular localization task\nillustrate adversarial training provides improvement on the supervised model,\nand is also effective on involving unlabeled data in the semi-supervised\ntraining case. In addition, our method achieves state-of-the-art performance on\ntwo benchmarking datasets.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 20:19:26 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 15:21:50 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Su", "Peng", ""], ["Vijay-Shanker", "K.", ""]]}, {"id": "2005.04286", "submitter": "Liyao Gao Mr.", "authors": "Liyao Gao, Yifan Du, Hongshan Li, Guang Lin", "title": "RotEqNet: Rotation-Equivariant Network for Fluid Systems with Symmetric\n  High-Order Tensors", "comments": "Preprint submitted to Journal of Computational Physics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG physics.comp-ph physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent application of scientific modeling, machine learning models are\nlargely applied to facilitate computational simulations of fluid systems.\nRotation symmetry is a general property for most symmetric fluid systems.\nHowever, in general, current machine learning methods have no theoretical way\nto guarantee rotational symmetry. By observing an important property of\ncontraction and rotation operation on high-order symmetric tensors, we prove\nthat the rotation operation is preserved via tensor contraction. Based on this\ntheoretical justification, in this paper, we introduce Rotation-Equivariant\nNetwork (RotEqNet) to guarantee the property of rotation-equivariance for\nhigh-order tensors in fluid systems. We implement RotEqNet and evaluate our\nclaims through four case studies on various fluid systems. The property of\nerror reduction and rotation-equivariance is verified in these case studies.\nResults from the comparative study show that our method outperforms\nconventional methods, which rely on data augmentation.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 22:33:34 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Gao", "Liyao", ""], ["Du", "Yifan", ""], ["Li", "Hongshan", ""], ["Lin", "Guang", ""]]}, {"id": "2005.04288", "submitter": "Li Fu", "authors": "Li Fu, Xiaoxiao Li, Libo Zi", "title": "Incremental Learning for End-to-End Automatic Speech Recognition", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new incremental learning for end-to-end Automatic Speech\nRecognition (ASR) to extend the model's capacity on a new task while retaining\nthe performance on previous ones. The proposed method is effective without\naccessing to the old dataset to address the issues of high retraining cost and\nunavailable old dataset. To achieve this, both attention distillation and\nknowledge distillation are applied to preserve the ability of the old model\nduring the progressive learning. With an ASR model pre-trained on 12,000h\nMandarin speech, we test our proposed method on 300h new scenario task and 1h\nnew named entities task. Experiments show that our method yields 3.25% and\n0.88% absolute Character Error Rate (CER) reduction on the new scenario, when\ncompared with the pre-trained model and the full-data retraining baseline,\nrespectively. It even yields a surprising 0.37% absolute CER reduction on the\nnew scenario than the fine-tuning. For the new named entities task, our method\nsignificantly improves the accuracy compared with the pre-trained model, i.e.\n16.95% absolute CER reduction. For both of the new task adaptions, the new\nmodels still maintain a same accuracy with the retraining baseline on the old\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 08:18:08 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 03:39:18 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Fu", "Li", ""], ["Li", "Xiaoxiao", ""], ["Zi", "Libo", ""]]}, {"id": "2005.04289", "submitter": "Mario Popolin Neto", "authors": "M\\'ario Popolin Neto and Fernando V. Paulovich", "title": "Explainable Matrix -- Visualization for Global and Local\n  Interpretability of Random Forest Classification Ensembles", "comments": "IEEE VIS VAST 2020", "journal-ref": null, "doi": "10.1109/TVCG.2020.3030354", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Over the past decades, classification models have proven to be essential\nmachine learning tools given their potential and applicability in various\ndomains. In these years, the north of the majority of the researchers had been\nto improve quantitative metrics, notwithstanding the lack of information about\nmodels' decisions such metrics convey. This paradigm has recently shifted, and\nstrategies beyond tables and numbers to assist in interpreting models'\ndecisions are increasing in importance. Part of this trend, visualization\ntechniques have been extensively used to support classification models'\ninterpretability, with a significant focus on rule-based models. Despite the\nadvances, the existing approaches present limitations in terms of visual\nscalability, and the visualization of large and complex models, such as the\nones produced by the Random Forest (RF) technique, remains a challenge. In this\npaper, we propose Explainable Matrix (ExMatrix), a novel visualization method\nfor RF interpretability that can handle models with massive quantities of\nrules. It employs a simple yet powerful matrix-like visual metaphor, where rows\nare rules, columns are features, and cells are rules predicates, enabling the\nanalysis of entire models and auditing classification results. ExMatrix\napplicability is confirmed via different examples, showing how it can be used\nin practice to promote RF models interpretability.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 21:03:48 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 13:55:31 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Neto", "M\u00e1rio Popolin", ""], ["Paulovich", "Fernando V.", ""]]}, {"id": "2005.04298", "submitter": "Jinkyu Kim", "authors": "Jinkyu Kim, Mayank Bansal", "title": "Attentional Bottleneck: Towards an Interpretable Deep Driving Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are a key component of behavior prediction and motion\ngeneration for self-driving cars. One of their main drawbacks is a lack of\ntransparency: they should provide easy to interpret rationales for what\ntriggers certain behaviors. We propose an architecture called Attentional\nBottleneck with the goal of improving transparency. Our key idea is to combine\nvisual attention, which identifies what aspects of the input the model is\nusing, with an information bottleneck that enables the model to only use\naspects of the input which are important. This not only provides sparse and\ninterpretable attention maps (e.g. focusing only on specific vehicles in the\nscene), but it adds this transparency at no cost to model accuracy. In fact, we\nfind slight improvements in accuracy when applying Attentional Bottleneck to\nthe ChauffeurNet model, whereas we find that the accuracy deteriorates with a\ntraditional visual attention model.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 21:51:15 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Kim", "Jinkyu", ""], ["Bansal", "Mayank", ""]]}, {"id": "2005.04301", "submitter": "MingYu Lu", "authors": "MingYu Lu and Zachary Shahn and Daby Sow and Finale Doshi-Velez and\n  Li-wei H. Lehman", "title": "Is Deep Reinforcement Learning Ready for Practical Applications in\n  Healthcare? A Sensitivity Analysis of Duel-DDQN for Hemodynamic Management in\n  Sepsis Patients", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential of Reinforcement Learning (RL) has been demonstrated through\nsuccessful applications to games such as Go and Atari. However, while it is\nstraightforward to evaluate the performance of an RL algorithm in a game\nsetting by simply using it to play the game, evaluation is a major challenge in\nclinical settings where it could be unsafe to follow RL policies in practice.\nThus, understanding sensitivity of RL policies to the host of decisions made\nduring implementation is an important step toward building the type of trust in\nRL required for eventual clinical uptake. In this work, we perform a\nsensitivity analysis on a state-of-the-art RL algorithm (Dueling Double Deep\nQ-Networks)applied to hemodynamic stabilization treatment strategies for septic\npatients in the ICU. We consider sensitivity of learned policies to input\nfeatures, embedding model architecture, time discretization, reward function,\nand random seeds. We find that varying these settings can significantly impact\nlearned policies, which suggests a need for caution when interpreting RL agent\noutput.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 22:08:31 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 14:54:03 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Lu", "MingYu", ""], ["Shahn", "Zachary", ""], ["Sow", "Daby", ""], ["Doshi-Velez", "Finale", ""], ["Lehman", "Li-wei H.", ""]]}, {"id": "2005.04305", "submitter": "Danny Hernandez", "authors": "Danny Hernandez, Tom B. Brown", "title": "Measuring the Algorithmic Efficiency of Neural Networks", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three factors drive the advance of AI: algorithmic innovation, data, and the\namount of compute available for training. Algorithmic progress has\ntraditionally been more difficult to quantify than compute and data. In this\nwork, we argue that algorithmic progress has an aspect that is both\nstraightforward to measure and interesting: reductions over time in the compute\nneeded to reach past capabilities. We show that the number of floating-point\noperations required to train a classifier to AlexNet-level performance on\nImageNet has decreased by a factor of 44x between 2012 and 2019. This\ncorresponds to algorithmic efficiency doubling every 16 months over a period of\n7 years. By contrast, Moore's Law would only have yielded an 11x cost\nimprovement. We observe that hardware and algorithmic efficiency gains multiply\nand can be on a similar scale over meaningful horizons, which suggests that a\ngood model of AI progress should integrate measures from both.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 22:26:37 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Hernandez", "Danny", ""], ["Brown", "Tom B.", ""]]}, {"id": "2005.04310", "submitter": "Sara Abdali", "authors": "Sara Abdali, Neil Shah, Evangelos E. Papalexakis", "title": "Semi-Supervised Multi-aspect Detection of Misinformation using\n  Hierarchical Joint Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distinguishing between misinformation and real information is one of the most\nchallenging problems in today's interconnected world. The vast majority of the\nstate-of-the-art in detecting misinformation is fully supervised, requiring a\nlarge number of high-quality human annotations. However, the availability of\nsuch annotations cannot be taken for granted, since it is very costly,\ntime-consuming, and challenging to do so in a way that keeps up with the\nproliferation of misinformation. In this work, we are interested in exploring\nscenarios where the number of annotations is limited. In such scenarios, we\ninvestigate how tapping on a diverse number of resources that characterize a\nnews article, henceforth referred to as \"aspects\" can compensate for the lack\nof labels. In particular, our contributions in this paper are twofold: 1) We\npropose the use of three different aspects: article content, context of social\nsharing behaviors, and host website/domain features, and 2) We introduce a\nprincipled tensor based embedding framework that combines all those aspects\neffectively. We propose HiJoD a 2-level decomposition pipeline which not only\noutperforms state-of-the-art methods with F1-scores of 74% and 81% on Twitter\nand Politifact datasets respectively but also is an order of magnitude faster\nthan similar ensemble approaches.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 22:41:39 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 22:30:14 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Abdali", "Sara", ""], ["Shah", "Neil", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "2005.04316", "submitter": "Siddhant Garg", "authors": "Siddhant Garg and Goutham Ramakrishnan", "title": "Advances in Quantum Deep Learning: An Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The last few decades have seen significant breakthroughs in the fields of\ndeep learning and quantum computing. Research at the junction of the two fields\nhas garnered an increasing amount of interest, which has led to the development\nof quantum deep learning and quantum-inspired deep learning techniques in\nrecent times. In this work, we present an overview of advances in the\nintersection of quantum computing and deep learning by discussing the technical\ncontributions, strengths and similarities of various research works in this\ndomain. To this end, we review and summarise the different schemes proposed to\nmodel quantum neural networks (QNNs) and other variants like quantum\nconvolutional networks (QCNNs). We also briefly describe the recent progress in\nquantum inspired classic deep learning algorithms and their applications to\nnatural language processing.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 23:36:50 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Garg", "Siddhant", ""], ["Ramakrishnan", "Goutham", ""]]}, {"id": "2005.04318", "submitter": "Andrew Lampinen", "authors": "Andrew K. Lampinen and James L. McClelland", "title": "Transforming task representations to perform novel tasks", "comments": "45 pages", "journal-ref": "PNAS December 29, 2020 117 (52) 32970-32981;", "doi": "10.1073/pnas.2008852117", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important aspect of intelligence is the ability to adapt to a novel task\nwithout any direct experience (zero-shot), based on its relationship to\nprevious tasks. Humans can exhibit this cognitive flexibility. By contrast,\nmodels that achieve superhuman performance in specific tasks often fail to\nadapt to even slight task alterations. To address this, we propose a general\ncomputational framework for adapting to novel tasks based on their relationship\nto prior tasks. We begin by learning vector representations of tasks. To adapt\nto new tasks, we propose meta-mappings, higher-order tasks that transform basic\ntask representations. We demonstrate the effectiveness of this framework across\na wide variety of tasks and computational paradigms, ranging from regression to\nimage classification and reinforcement learning. We compare to both human\nadaptability and language-based approaches to zero-shot learning. Across these\ndomains, meta-mapping is successful, often achieving 80-90% performance,\nwithout any data, on a novel task, even when the new task directly contradicts\nprior experience. We further show that meta-mapping can not only generalize to\nnew tasks via learned relationships, but can also generalize using novel\nrelationships unseen during training. Finally, using meta-mapping as a starting\npoint can dramatically accelerate later learning on a new task, and reduce\nlearning time and cumulative error substantially. Our results provide insight\ninto a possible computational basis of intelligent adaptability and offer a\npossible framework for modeling cognitive flexibility and building more\nflexible artificial intelligence systems.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 23:41:57 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 22:26:39 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 18:35:56 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Lampinen", "Andrew K.", ""], ["McClelland", "James L.", ""]]}, {"id": "2005.04320", "submitter": "Paul Kent MSc", "authors": "Paul Kent and Juergen Branke", "title": "BOP-Elites, a Bayesian Optimisation algorithm for Quality-Diversity\n  search", "comments": "Submitted to Parallel Problem Solving from Nature (PPSN) April 22nd -\n  2020 (https://ppsn2020.liacs.leidenuniv.nl/calls/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality Diversity (QD) algorithms such as MAP-Elites are a class of\noptimisation techniques that attempt to find a set of high-performing points\nfrom an objective function while enforcing behavioural diversity of the points\nover one or more interpretable, user chosen, feature functions.\n  In this paper we propose the Bayesian Optimisation of Elites (BOP-Elites)\nalgorithm that uses techniques from Bayesian Optimisation to explicitly model\nboth quality and diversity with Gaussian Processes. By considering user defined\nregions of the feature space as 'niches' our task is to find the optimal\nsolution in each niche. We propose a novel acquisition function to\nintelligently choose new points that provide the highest expected improvement\nto the ensemble problem of identifying the best solution in every niche. In\nthis way each function evaluation enriches our modelling and provides insight\nto the whole problem, naturally balancing exploration and exploitation of the\nsearch space. The resulting algorithm is very effective in identifying the\nparts of the search space that belong to a niche in feature space, and finding\nthe optimal solution in each niche. It is also significantly more sample\nefficient than simpler benchmark approaches. BOP-Elites goes further than\nexisting QD algorithms by quantifying the uncertainty around our predictions\nand offering additional illumination of the search space through surrogate\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 23:49:13 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Kent", "Paul", ""], ["Branke", "Juergen", ""]]}, {"id": "2005.04321", "submitter": "David Charte", "authors": "David Charte, Francisco Charte, Mar\\'ia J. del Jesus, Francisco\n  Herrera", "title": "A Showcase of the Use of Autoencoders in Feature Learning Applications", "comments": "This manuscript was accepted as conference paper in IWINAC 2019. The\n  final authenticated publication is available online at\n  https://doi.org/10.1007/978-3-030-19651-6_40", "journal-ref": "In: From Bioinspired Systems and Biomedical Applications to\n  Machine Learning/IWINAC 2019. LNCS vol 11487. Springer (2019)", "doi": "10.1007/978-3-030-19651-6_40", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoders are techniques for data representation learning based on\nartificial neural networks. Differently to other feature learning methods which\nmay be focused on finding specific transformations of the feature space, they\ncan be adapted to fulfill many purposes, such as data visualization, denoising,\nanomaly detection and semantic hashing. This work presents these applications\nand provides details on how autoencoders can perform them, including code\nsamples making use of an R package with an easy-to-use interface for\nautoencoder design and training, \\texttt{ruta}. Along the way, the explanations\non how each learning task has been achieved are provided with the aim to help\nthe reader design their own autoencoders for these or other objectives.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 23:56:26 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Charte", "David", ""], ["Charte", "Francisco", ""], ["del Jesus", "Mar\u00eda J.", ""], ["Herrera", "Francisco", ""]]}, {"id": "2005.04323", "submitter": "Zhaoming Xie", "authors": "Zhaoming Xie, Hung Yu Ling, Nam Hee Kim, Michiel van de Panne", "title": "ALLSTEPS: Curriculum-driven Learning of Stepping Stone Skills", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are highly adept at walking in environments with foot placement\nconstraints, including stepping-stone scenarios where the footstep locations\nare fully constrained. Finding good solutions to stepping-stone locomotion is a\nlongstanding and fundamental challenge for animation and robotics. We present\nfully learned solutions to this difficult problem using reinforcement learning.\nWe demonstrate the importance of a curriculum for efficient learning and\nevaluate four possible curriculum choices compared to a non-curriculum\nbaseline. Results are presented for a simulated human character, a realistic\nbipedal robot simulation and a monster character, in each case producing\nrobust, plausible motions for challenging stepping stone sequences and\nterrains.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 00:16:38 GMT"}, {"version": "v2", "created": "Sun, 30 Aug 2020 00:45:00 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Xie", "Zhaoming", ""], ["Ling", "Hung Yu", ""], ["Kim", "Nam Hee", ""], ["van de Panne", "Michiel", ""]]}, {"id": "2005.04342", "submitter": "Demetrius DiMucci", "authors": "Demetrius DiMucci", "title": "JigSaw: A tool for discovering explanatory high-order interactions from\n  random forests", "comments": "15 pages 5 figures 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is revolutionizing biology by facilitating the prediction of\noutcomes from complex patterns found in massive data sets. Large biological\ndata sets, like those generated by transcriptome or microbiome studies,measure\nmany relevant components that interact in vivo with one another in modular\nways.Identifying the high-order interactions that machine learning models use\nto make predictions would facilitate the development of hypotheses linking\ncombinations of measured components to outcome. By using the structure of\nrandom forests, a new algorithmic approach, termed JigSaw,was developed to aid\nin the discovery of patterns that could explain predictions made by the forest.\nBy examining the patterns of individual decision trees JigSaw identifies\nhigh-order interactions between measured features that are strongly associated\nwith a particular outcome and identifies the relevant decision thresholds.\nJigSaw's effectiveness was tested in simulation studies where it was able to\nrecover multiple ground truth patterns;even in the presence of significant\nnoise. It was then used to find patterns associated with outcomes in two real\nworld data sets.It was first used to identify patterns clinical measurements\nassociated with heart disease. It was then used to find patterns associated\nwith breast cancer using metabolites measured in the blood. In heart disease,\nJigSaw identified several three-way interactions that combine to explain most\nof the heart disease records (66%) with high precision (93%). In breast cancer,\nthree two-way interactions were recovered that can be combined to explain\nalmost all records (92%) with good precision (79%). JigSaw is an efficient\nmethod for exploring high-dimensional feature spaces for rules that explain\nstatistical associations with a given outcome and can inspire the generation of\ntestable hypotheses.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 01:53:45 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["DiMucci", "Demetrius", ""]]}, {"id": "2005.04343", "submitter": "Elissa M. Redmiles", "authors": "Gabriel Kaptchuk, Daniel G. Goldstein, Eszter Hargittai, Jake Hofman,\n  Elissa M. Redmiles", "title": "How good is good enough for COVID19 apps? The influence of benefits,\n  accuracy, and privacy on willingness to adopt", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing number of contact tracing apps are being developed to complement\nmanual contact tracing. A key question is whether users will be willing to\nadopt these contact tracing apps. In this work, we survey over 4,500 Americans\nto evaluate (1) the effect of both accuracy and privacy concerns on reported\nwillingness to install COVID19 contact tracing apps and (2) how different\ngroups of users weight accuracy vs. privacy. Drawing on our findings from these\nfirst two research questions, we (3) quantitatively model how the amount of\npublic health benefit (reduction in infection rate), amount of individual\nbenefit (true-positive detection of exposures to COVID), and degree of privacy\nrisk in a hypothetical contact tracing app may influence American's willingness\nto install. Our work takes a descriptive ethics approach toward offering\nimplications for the development of policy and app designs related to COVID19.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 01:53:52 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 17:32:30 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 22:56:16 GMT"}, {"version": "v4", "created": "Mon, 18 May 2020 23:13:05 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Kaptchuk", "Gabriel", ""], ["Goldstein", "Daniel G.", ""], ["Hargittai", "Eszter", ""], ["Hofman", "Jake", ""], ["Redmiles", "Elissa M.", ""]]}, {"id": "2005.04345", "submitter": "Shiori Sagawa", "authors": "Shiori Sagawa, Aditi Raghunathan, Pang Wei Koh, Percy Liang", "title": "An Investigation of Why Overparameterization Exacerbates Spurious\n  Correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study why overparameterization -- increasing model size well beyond the\npoint of zero training error -- can hurt test error on minority groups despite\nimproving average test error when there are spurious correlations in the data.\nThrough simulations and experiments on two image datasets, we identify two key\nproperties of the training data that drive this behavior: the proportions of\nmajority versus minority groups, and the signal-to-noise ratio of the spurious\ncorrelations. We then analyze a linear setting and theoretically show how the\ninductive bias of models towards \"memorizing\" fewer examples can cause\noverparameterization to hurt. Our analysis leads to a counterintuitive approach\nof subsampling the majority group, which empirically achieves low minority\nerror in the overparameterized regime, even though the standard approach of\nupweighting the minority fails. Overall, our results suggest a tension between\nusing overparameterized models versus using all the training data for achieving\nlow worst-group error.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 01:59:13 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 22:56:30 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2020 19:32:58 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Sagawa", "Shiori", ""], ["Raghunathan", "Aditi", ""], ["Koh", "Pang Wei", ""], ["Liang", "Percy", ""]]}, {"id": "2005.04347", "submitter": "Aavaas Gajurel", "authors": "Aavaas Gajurel, Sushil J. Louis, Frederick C Harris", "title": "GPU Acceleration of Sparse Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use graphics processing units(GPU) to accelerate sparse and\narbitrary structured neural networks. Sparse networks have nodes in the network\nthat are not fully connected with nodes in preceding and following layers, and\narbitrary structure neural networks have different number of nodes in each\nlayers. Sparse Neural networks with arbitrary structures are generally created\nin the processes like neural network pruning and evolutionary machine learning\nstrategies. We show that we can gain significant speedup for full activation of\nsuch neural networks using graphical processing units. We do a prepossessing\nstep to determine dependency groups for all the nodes in a network, and use\nthat information to guide the progression of activation in the neural network.\nThen we compute activation for each nodes in its own separate thread in the\nGPU, which allows for massive parallelization. We use CUDA framework to\nimplement our approach and compare the results of sequential and GPU\nimplementations. Our results show that the activation of sparse neural networks\nlends very well to GPU acceleration and can help speed up machine learning\nstrategies which generate such networks or other processes that have similar\nstructure.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 02:18:31 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Gajurel", "Aavaas", ""], ["Louis", "Sushil J.", ""], ["Harris", "Frederick C", ""]]}, {"id": "2005.04353", "submitter": "Rong Song", "authors": "Sudi Lyu, Anxiang Zhang, Rong Song", "title": "Dual-track Music Generation using Deep Learning", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music generation is always interesting in a sense that there is no formalized\nrecipe. In this work, we propose a novel dual-track architecture for generating\nclassical piano music, which is able to model the inter-dependency of left-hand\nand right-hand piano music. Particularly, we experimented with a lot of\ndifferent models of neural network as well as different representations of\nmusic, and the results show that our proposed model outperforms all other\ntested methods. Besides, we deployed some special policies for model training\nand generation, which contributed to the model performance remarkably. Finally,\nunder two evaluation methods, we compared our models with the MuseGAN project\nand true music.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 02:34:39 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Lyu", "Sudi", ""], ["Zhang", "Anxiang", ""], ["Song", "Rong", ""]]}, {"id": "2005.04354", "submitter": "Anshoo Tandon", "authors": "Anshoo Tandon and Vincent Y. F. Tan and Shiyao Zhu", "title": "Exact Asymptotics for Learning Tree-Structured Graphical Models with\n  Side Information: Noiseless and Noisy Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given side information that an Ising tree-structured graphical model is\nhomogeneous and has no external field, we derive the exact asymptotics of\nlearning its structure from independently drawn samples. Our results, which\nleverage the use of probabilistic tools from the theory of strong large\ndeviations, refine the large deviation (error exponents) results of Tan,\nAnandkumar, Tong, and Willsky [IEEE Trans. on Inform. Th., 57(3):1714--1735,\n2011] and strictly improve those of Bresler and Karzand [Ann. Statist., 2020].\nIn addition, we extend our results to the scenario in which the samples are\nobserved in random noise. In this case, we show that they strictly improve on\nthe recent results of Nikolakakis, Kalogerias, and Sarwate [Proc. AISTATS,\n1771--1782, 2019]. Our theoretical results demonstrate keen agreement with\nexperimental results for sample sizes as small as that in the hundreds.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 02:42:40 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Tandon", "Anshoo", ""], ["Tan", "Vincent Y. F.", ""], ["Zhu", "Shiyao", ""]]}, {"id": "2005.04355", "submitter": "Xiaotian Hao", "authors": "Xiaotian Hao, Junqi Jin, Jianye Hao, Jin Li, Weixun Wang, Yi Ma,\n  Zhenzhe Zheng, Han Li, Jian Xu and Kun Gai", "title": "Learning to Accelerate Heuristic Searching for Large-Scale Maximum\n  Weighted b-Matching Problems in Online Advertising", "comments": "accepted by IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bipartite b-matching is fundamental in algorithm design, and has been widely\napplied into economic markets, labor markets, etc. These practical problems\nusually exhibit two distinct features: large-scale and dynamic, which requires\nthe matching algorithm to be repeatedly executed at regular intervals. However,\nexisting exact and approximate algorithms usually fail in such settings due to\neither requiring intolerable running time or too much computation resource. To\naddress this issue, we propose \\texttt{NeuSearcher} which leverages the\nknowledge learned from previously instances to solve new problem instances.\nSpecifically, we design a multichannel graph neural network to predict the\nthreshold of the matched edges weights, by which the search region could be\nsignificantly reduced. We further propose a parallel heuristic search algorithm\nto iteratively improve the solution quality until convergence. Experiments on\nboth open and industrial datasets demonstrate that \\texttt{NeuSearcher} can\nspeed up 2 to 3 times while achieving exactly the same matching solution\ncompared with the state-of-the-art approximation approaches.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 02:48:23 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 07:37:56 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Hao", "Xiaotian", ""], ["Jin", "Junqi", ""], ["Hao", "Jianye", ""], ["Li", "Jin", ""], ["Wang", "Weixun", ""], ["Ma", "Yi", ""], ["Zheng", "Zhenzhe", ""], ["Li", "Han", ""], ["Xu", "Jian", ""], ["Gai", "Kun", ""]]}, {"id": "2005.04356", "submitter": "Yunzhong He", "authors": "Yunzhong He, Wenyuan Li, Liang-Wei Chen, Gabriel Forgues, Xunlong Gui,\n  Sui Liang, Bo Hou", "title": "A Social Search Model for Large Scale Social Networks", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of social networks, information on the internet is no longer\nsolely organized by web pages. Rather, content is generated and shared among\nusers and organized around their social relations on social networks. This\npresents new challenges to information retrieval systems. On a social network\nsearch system, the generation of result sets not only needs to consider keyword\nmatches, like a traditional web search engine does, but it also needs to take\ninto account the searcher's social connections and the content's visibility\nsettings. Besides, search ranking should be able to handle both textual\nrelevance and the rich social interaction signals from the social network. In\nthis paper, we present our solution to these two challenges by first\nintroducing a social retrieval mechanism, and then investigate novel deep\nneural networks for the ranking problem. The retrieval system treats social\nconnections as indexing terms, and generates meaningful results sets by biasing\ntowards close social connections in a constrained optimization fashion. The\nresult set is then ranked by a deep neural network that handles textual and\nsocial relevance in a two-tower approach, in which personalization and textual\nrelevance are addressed jointly. The retrieval mechanism is deployed on\nFacebook and is helping billions of users finding postings from their\nconnections efficiently. Based on the postings being retrieved, we evaluate our\ntwo-tower neutral network, and examine the importance of personalization and\ntextual signals in the ranking problem.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 02:59:02 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["He", "Yunzhong", ""], ["Li", "Wenyuan", ""], ["Chen", "Liang-Wei", ""], ["Forgues", "Gabriel", ""], ["Gui", "Xunlong", ""], ["Liang", "Sui", ""], ["Hou", "Bo", ""]]}, {"id": "2005.04361", "submitter": "Qiaoan Chen", "authors": "Qiaoan Chen, Hao Gu, Lingling Yi, Yishi Lin, Peng He, Chuan Chen,\n  Yangqiu Song", "title": "SocialTrans: A Deep Sequential Model with Social Information for\n  Web-Scale Recommendation Systems", "comments": "11 pages,8 figures,4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On social network platforms, a user's behavior is based on his/her personal\ninterests, or influenced by his/her friends. In the literature, it is common to\nmodel either users' personal preference or their socially influenced\npreference. In this paper, we present a novel deep learning model SocialTrans\nfor social recommendations to integrate these two types of preferences.\nSocialTrans is composed of three modules. The first module is based on a\nmulti-layer Transformer to model users' personal preference. The second module\nis a multi-layer graph attention neural network (GAT), which is used to model\nthe social influence strengths between friends in social networks. The last\nmodule merges users' personal preference and socially influenced preference to\nproduce recommendations. Our model can efficiently fit large-scale data and we\ndeployed SocialTrans to a major article recommendation system in China.\nExperiments on three data sets verify the effectiveness of our model and show\nthat it outperforms state-of-the-art social recommendation methods.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 03:39:45 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Chen", "Qiaoan", ""], ["Gu", "Hao", ""], ["Yi", "Lingling", ""], ["Lin", "Yishi", ""], ["He", "Peng", ""], ["Chen", "Chuan", ""], ["Song", "Yangqiu", ""]]}, {"id": "2005.04364", "submitter": "Samson Tan", "authors": "Samson Tan, Shafiq Joty, Min-Yen Kan, Richard Socher", "title": "It's Morphin' Time! Combating Linguistic Discrimination with\n  Inflectional Perturbations", "comments": "To appear in the Proceedings of the 58th Annual Meeting of the\n  Association for Computational Linguistics (ACL 2020)", "journal-ref": null, "doi": "10.18653/v1/2020.acl-main.263", "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training on only perfect Standard English corpora predisposes pre-trained\nneural networks to discriminate against minorities from non-standard linguistic\nbackgrounds (e.g., African American Vernacular English, Colloquial Singapore\nEnglish, etc.). We perturb the inflectional morphology of words to craft\nplausible and semantically similar adversarial examples that expose these\nbiases in popular NLP models, e.g., BERT and Transformer, and show that\nadversarially fine-tuning them for a single epoch significantly improves\nrobustness without sacrificing performance on clean data.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 04:01:43 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Tan", "Samson", ""], ["Joty", "Shafiq", ""], ["Kan", "Min-Yen", ""], ["Socher", "Richard", ""]]}, {"id": "2005.04366", "submitter": "Miao Yin", "authors": "Miao Yin, Siyu Liao, Xiao-Yang Liu, Xiaodong Wang, Bo Yuan", "title": "Compressing Recurrent Neural Networks Using Hierarchical Tucker Tensor\n  Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) have been widely used in sequence analysis\nand modeling. However, when processing high-dimensional data, RNNs typically\nrequire very large model sizes, thereby bringing a series of deployment\nchallenges. Although the state-of-the-art tensor decomposition approaches can\nprovide good model compression performance, these existing methods are still\nsuffering some inherent limitations, such as restricted representation\ncapability and insufficient model complexity reduction. To overcome these\nlimitations, in this paper we propose to develop compact RNN models using\nHierarchical Tucker (HT) decomposition. HT decomposition brings strong\nhierarchical structure to the decomposed RNN models, which is very useful and\nimportant for enhancing the representation capability. Meanwhile, HT\ndecomposition provides higher storage and computational cost reduction than the\nexisting tensor decomposition approaches for RNN compression. Our experimental\nresults show that, compared with the state-of-the-art compressed RNN models,\nsuch as TT-LSTM, TR-LSTM and BT-LSTM, our proposed HT-based LSTM (HT-LSTM),\nconsistently achieves simultaneous and significant increases in both\ncompression ratio and test accuracy on different datasets.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 05:15:20 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Yin", "Miao", ""], ["Liao", "Siyu", ""], ["Liu", "Xiao-Yang", ""], ["Wang", "Xiaodong", ""], ["Yuan", "Bo", ""]]}, {"id": "2005.04369", "submitter": "Di Zhuang", "authors": "Di Zhuang and J. Morris Chang", "title": "Utility-aware Privacy-preserving Data Releasing", "comments": "9 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the big data era, more and more cloud-based data-driven applications are\ndeveloped that leverage individual data to provide certain valuable services\n(the utilities). On the other hand, since the same set of individual data could\nbe utilized to infer the individual's certain sensitive information, it creates\nnew channels to snoop the individual's privacy. Hence it is of great importance\nto develop techniques that enable the data owners to release privatized data,\nthat can still be utilized for certain premised intended purpose. Existing data\nreleasing approaches, however, are either privacy-emphasized (no consideration\non utility) or utility-driven (no guarantees on privacy). In this work, we\npropose a two-step perturbation-based utility-aware privacy-preserving data\nreleasing framework. First, certain predefined privacy and utility problems are\nlearned from the public domain data (background knowledge). Later, our approach\nleverages the learned knowledge to precisely perturb the data owners' data into\nprivatized data that can be successfully utilized for certain intended purpose\n(learning to succeed), without jeopardizing certain predefined privacy\n(training to fail). Extensive experiments have been conducted on Human Activity\nRecognition, Census Income and Bank Marketing datasets to demonstrate the\neffectiveness and practicality of our framework.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 05:32:46 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Zhuang", "Di", ""], ["Chang", "J. Morris", ""]]}, {"id": "2005.04372", "submitter": "Sharu Theresa Jose", "authors": "Sharu Theresa Jose, Osvaldo Simeone", "title": "Information-Theoretic Generalization Bounds for Meta-Learning and\n  Applications", "comments": "Accepted to Entropy", "journal-ref": null, "doi": "10.3390/e23010126", "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning, or \"learning to learn\", refers to techniques that infer an\ninductive bias from data corresponding to multiple related tasks with the goal\nof improving the sample efficiency for new, previously unobserved, tasks. A key\nperformance measure for meta-learning is the meta-generalization gap, that is,\nthe difference between the average loss measured on the meta-training data and\non a new, randomly selected task. This paper presents novel\ninformation-theoretic upper bounds on the meta-generalization gap. Two broad\nclasses of meta-learning algorithms are considered that uses either separate\nwithin-task training and test sets, like MAML, or joint within-task training\nand test sets, like Reptile. Extending the existing work for conventional\nlearning, an upper bound on the meta-generalization gap is derived for the\nformer class that depends on the mutual information (MI) between the output of\nthe meta-learning algorithm and its input meta-training data. For the latter,\nthe derived bound includes an additional MI between the output of the per-task\nlearning procedure and corresponding data set to capture within-task\nuncertainty. Tighter bounds are then developed, under given technical\nconditions, for the two classes via novel Individual Task MI (ITMI) bounds.\nApplications of the derived bounds are finally discussed, including a broad\nclass of noisy iterative algorithms for meta-learning.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 05:48:01 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 16:17:24 GMT"}, {"version": "v3", "created": "Sat, 21 Nov 2020 10:56:09 GMT"}, {"version": "v4", "created": "Fri, 15 Jan 2021 12:00:37 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Jose", "Sharu Theresa", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "2005.04373", "submitter": "Sungbin Lim", "authors": "Woonhyuk Baek and Ildoo Kim and Sungwoong Kim and Sungbin Lim", "title": "AutoCLINT: The Winning Method in AutoCV Challenge 2019", "comments": "9 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NeurIPS 2019 AutoDL challenge is a series of six automated machine learning\ncompetitions. Particularly, AutoCV challenges mainly focused on classification\ntasks on visual domain. In this paper, we introduce the winning method in the\ncompetition, AutoCLINT. The proposed method implements an autonomous training\nstrategy, including efficient code optimization, and applies an automated data\naugmentation to achieve the fast adaptation of pretrained networks. We\nimplement a light version of Fast AutoAugment to search for data augmentation\npolicies efficiently for the arbitrarily given image domains. We also\nempirically analyze the components of the proposed method and provide ablation\nstudies focusing on AutoCV datasets.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 05:50:38 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Baek", "Woonhyuk", ""], ["Kim", "Ildoo", ""], ["Kim", "Sungwoong", ""], ["Lim", "Sungbin", ""]]}, {"id": "2005.04383", "submitter": "Esa Ollila", "authors": "Muhammad Naveed Tabassum and Esa Ollila", "title": "A Compressive Classification Framework for High-Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a compressive classification framework for settings where the data\ndimensionality is significantly higher than the sample size. The proposed\nmethod, referred to as compressive regularized discriminant analysis (CRDA) is\nbased on linear discriminant analysis and has the ability to select significant\nfeatures by using joint-sparsity promoting hard thresholding in the\ndiscriminant rule. Since the number of features is larger than the sample size,\nthe method also uses state-of-the-art regularized sample covariance matrix\nestimators. Several analysis examples on real data sets, including image,\nspeech signal and gene expression data illustrate the promising improvements\noffered by the proposed CRDA classifier in practise. Overall, the proposed\nmethod gives fewer misclassification errors than its competitors, while at the\nsame time achieving accurate feature selection results. The open-source R\npackage and MATLAB toolbox of the proposed method (named compressiveRDA) is\nfreely available.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 06:55:00 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 14:14:02 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Tabassum", "Muhammad Naveed", ""], ["Ollila", "Esa", ""]]}, {"id": "2005.04396", "submitter": "Junheng Huang", "authors": "Junheng Huang, Lu Pan, Kang Xu, Weihua Peng, Fayuan Li", "title": "Generating Pertinent and Diversified Comments with Topic-aware\n  Pointer-Generator Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comment generation, a new and challenging task in Natural Language Generation\n(NLG), attracts a lot of attention in recent years. However, comments generated\nby previous work tend to lack pertinence and diversity. In this paper, we\npropose a novel generation model based on Topic-aware Pointer-Generator\nNetworks (TPGN), which can utilize the topic information hidden in the articles\nto guide the generation of pertinent and diversified comments. Firstly, we\ndesign a keyword-level and topic-level encoder attention mechanism to capture\ntopic information in the articles. Next, we integrate the topic information\ninto pointer-generator networks to guide comment generation. Experiments on a\nlarge scale of comment generation dataset show that our model produces the\nvaluable comments and outperforms competitive baseline models significantly.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 09:04:09 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Huang", "Junheng", ""], ["Pan", "Lu", ""], ["Xu", "Kang", ""], ["Peng", "Weihua", ""], ["Li", "Fayuan", ""]]}, {"id": "2005.04399", "submitter": "Marco Romanelli", "authors": "Marco Romanelli and Konstantinos Chatzikokolakis and Catuscia\n  Palamidessi and Pablo Piantanida", "title": "Estimating g-Leakage via Machine Learning", "comments": "This is the extended version of the paper which will appear in the\n  Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications\n  Security (CCS '20), November 9-13, 2020, Virtual Event, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of estimating the information leakage of a\nsystem in the black-box scenario. It is assumed that the system's internals are\nunknown to the learner, or anyway too complicated to analyze, and the only\navailable information are pairs of input-output data samples, possibly obtained\nby submitting queries to the system or provided by a third party. Previous\nresearch has mainly focused on counting the frequencies to estimate the\ninput-output conditional probabilities (referred to as frequentist approach),\nhowever this method is not accurate when the domain of possible outputs is\nlarge. To overcome this difficulty, the estimation of the Bayes error of the\nideal classifier was recently investigated using Machine Learning (ML) models\nand it has been shown to be more accurate thanks to the ability of those models\nto learn the input-output correspondence. However, the Bayes vulnerability is\nonly suitable to describe one-try attacks. A more general and flexible measure\nof leakage is the g-vulnerability, which encompasses several different types of\nadversaries, with different goals and capabilities. In this paper, we propose a\nnovel approach to perform black-box estimation of the g-vulnerability using ML.\nA feature of our approach is that it does not require to estimate the\nconditional probabilities, and that it is suitable for a large class of ML\nalgorithms. First, we formally show the learnability for all data\ndistributions. Then, we evaluate the performance via various experiments using\nk-Nearest Neighbors and Neural Networks. Our results outperform the frequentist\napproach when the observables domain is large.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 09:26:36 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 16:44:33 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Romanelli", "Marco", ""], ["Chatzikokolakis", "Konstantinos", ""], ["Palamidessi", "Catuscia", ""], ["Piantanida", "Pablo", ""]]}, {"id": "2005.04400", "submitter": "Franz G\\\"otz-Hahn", "authors": "Franz G\\\"otz-Hahn, Vlad Hosu, Dietmar Saupe", "title": "Comment on \"No-Reference Video Quality Assessment Based on the Temporal\n  Pooling of Deep Features\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Neural Processing Letters 50,3 (2019) a machine learning approach to blind\nvideo quality assessment was proposed. It is based on temporal pooling of\nfeatures of video frames, taken from the last pooling layer of deep\nconvolutional neural networks. The method was validated on two established\nbenchmark datasets and gave results far better than the previous\nstate-of-the-art. In this letter we report the results from our careful\nreimplementations. The performance results, claimed in the paper, cannot be\nreached, and are even below the state-of-the-art by a large margin. We show\nthat the originally reported wrong performance results are a consequence of two\ncases of data leakage. Information from outside the training dataset was used\nin the fine-tuning stage and in the model evaluation.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 09:28:01 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["G\u00f6tz-Hahn", "Franz", ""], ["Hosu", "Vlad", ""], ["Saupe", "Dietmar", ""]]}, {"id": "2005.04444", "submitter": "Oleh Lukianykhin", "authors": "Oleh Lukianykhin, Tetiana Bogodorova", "title": "Reinforcement Learning for Thermostatically Controlled Loads Control\n  using Modelica and Python", "comments": "accepted for the Asian Modelica Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of the project is to investigate and assess opportunities for\napplying reinforcement learning (RL) for power system control. As a proof of\nconcept (PoC), voltage control of thermostatically controlled loads (TCLs) for\npower consumption regulation was developed using Modelica-based pipeline. The\nQ-learning RL algorithm has been validated for deterministic and stochastic\ninitialization of TCLs. The latter modelling is closer to real grid behaviour,\nwhich challenges the control development, considering the stochastic nature of\nload switching. In addition, the paper shows the influence of Q-learning\nparameters, including discretization of state-action space, on the controller\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 13:35:49 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Lukianykhin", "Oleh", ""], ["Bogodorova", "Tetiana", ""]]}, {"id": "2005.04447", "submitter": "James Stokes", "authors": "Tianchen Zhao, Giuseppe Carleo, James Stokes, Shravan Veerapaneni", "title": "Natural evolution strategies and variational Monte Carlo", "comments": null, "journal-ref": null, "doi": "10.1088/2632-2153/abcb50", "report-no": null, "categories": "quant-ph cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A notion of quantum natural evolution strategies is introduced, which\nprovides a geometric synthesis of a number of known quantum/classical\nalgorithms for performing classical black-box optimization. Recent work of\nGomes et al. [2019] on heuristic combinatorial optimization using neural\nquantum states is pedagogically reviewed in this context, emphasizing the\nconnection with natural evolution strategies. The algorithmic framework is\nillustrated for approximate combinatorial optimization problems, and a\nsystematic strategy is found for improving the approximation ratios. In\nparticular it is found that natural evolution strategies can achieve\napproximation ratios competitive with widely used heuristic algorithms for\nMax-Cut, at the expense of increased computation time.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 13:48:56 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 16:45:10 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Zhao", "Tianchen", ""], ["Carleo", "Giuseppe", ""], ["Stokes", "James", ""], ["Veerapaneni", "Shravan", ""]]}, {"id": "2005.04454", "submitter": "Hendrik Burwinkel", "authors": "Hendrik Burwinkel, Holger Matz, Stefan Saur, Christoph Hauger, Ayse\n  Mine Evren, Nino Hirnschall, Oliver Findl, Nassir Navab, Seyed-Ahmad Ahmadi", "title": "Domain-specific loss design for unsupervised physical training: A new\n  approach to modeling medical ML solutions", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, cataract surgery is the most frequently performed ophthalmic surgery\nin the world. The cataract, a developing opacity of the human eye lens,\nconstitutes the world's most frequent cause for blindness. During surgery, the\nlens is removed and replaced by an artificial intraocular lens (IOL). To\nprevent patients from needing strong visual aids after surgery, a precise\nprediction of the optical properties of the inserted IOL is crucial. There has\nbeen lots of activity towards developing methods to predict these properties\nfrom biometric eye data obtained by OCT devices, recently also by employing\nmachine learning. They consider either only biometric data or physical models,\nbut rarely both, and often neglect the IOL geometry. In this work, we propose\nOpticNet, a novel optical refraction network, loss function, and training\nscheme which is unsupervised, domain-specific, and physically motivated. We\nderive a precise light propagation eye model using single-ray raytracing and\nformulate a differentiable loss function that back-propagates physical\ngradients into the network. Further, we propose a new transfer learning\nprocedure, which allows unsupervised training on the physical model and\nfine-tuning of the network on a cohort of real IOL patient cases. We show that\nour network is not only superior to systems trained with standard procedures\nbut also that our method outperforms the current state of the art in IOL\ncalculation when compared on two biometric data sets.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 14:39:23 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Burwinkel", "Hendrik", ""], ["Matz", "Holger", ""], ["Saur", "Stefan", ""], ["Hauger", "Christoph", ""], ["Evren", "Ayse Mine", ""], ["Hirnschall", "Nino", ""], ["Findl", "Oliver", ""], ["Navab", "Nassir", ""], ["Ahmadi", "Seyed-Ahmad", ""]]}, {"id": "2005.04473", "submitter": "Fabricio Breve", "authors": "Fabricio Breve, Carlos Norberto Fischer", "title": "Visually Impaired Aid using Convolutional Neural Networks, Transfer\n  Learning, and Particle Competition and Cooperation", "comments": "BREVE, Fabricio Aparecido; FISCHER, Carlos Norberto. Visually\n  Impaired Aid using Convolutional Neural Networks, Transfer Learning, and\n  Particle Competition and Cooperation In: 2020 International Joint Conference\n  on Neural Networks (IJCNN 2020), 2020, Glasgow, UK. Proceedings of 2020\n  International Joint Conference on Neural Networks (IJCNN 2020), 2020.\n  (accepted for publication)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Navigation and mobility are some of the major problems faced by visually\nimpaired people in their daily lives. Advances in computer vision led to the\nproposal of some navigation systems. However, most of them require expensive\nand/or heavy hardware. In this paper we propose the use of convolutional neural\nnetworks (CNN), transfer learning, and semi-supervised learning (SSL) to build\na framework aimed at the visually impaired aid. It has low computational costs\nand, therefore, may be implemented on current smartphones, without relying on\nany additional equipment. The smartphone camera can be used to automatically\ntake pictures of the path ahead. Then, they will be immediately classified,\nproviding almost instantaneous feedback to the user. We also propose a dataset\nto train the classifiers, including indoor and outdoor situations with\ndifferent types of light, floor, and obstacles. Many different CNN\narchitectures are evaluated as feature extractors and classifiers, by\nfine-tuning weights pre-trained on a much larger dataset. The graph-based SSL\nmethod, known as particle competition and cooperation, is also used for\nclassification, allowing feedback from the user to be incorporated without\nretraining the underlying network. 92\\% and 80\\% classification accuracy is\nachieved in the proposed dataset in the best supervised and SSL scenarios,\nrespectively.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 16:11:48 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Breve", "Fabricio", ""], ["Fischer", "Carlos Norberto", ""]]}, {"id": "2005.04485", "submitter": "Octavi Obiols-Sales", "authors": "Octavi Obiols-Sales, Abhinav Vishnu, Nicholas Malaya, Aparna\n  Chandramowlishwaran", "title": "CFDNet: a deep learning-based accelerator for fluid simulations", "comments": "It has been accepted and almost published in the International\n  Conference in Supercomputing (ICS) 2020", "journal-ref": null, "doi": "10.1145/3392717.3392772", "report-no": null, "categories": "physics.flu-dyn cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CFD is widely used in physical system design and optimization, where it is\nused to predict engineering quantities of interest, such as the lift on a plane\nwing or the drag on a motor vehicle. However, many systems of interest are\nprohibitively expensive for design optimization, due to the expense of\nevaluating CFD simulations. To render the computation tractable, reduced-order\nor surrogate models are used to accelerate simulations while respecting the\nconvergence constraints provided by the higher-fidelity solution. This paper\nintroduces CFDNet -- a physical simulation and deep learning coupled framework,\nfor accelerating the convergence of Reynolds Averaged Navier-Stokes\nsimulations. CFDNet is designed to predict the primary physical properties of\nthe fluid including velocity, pressure, and eddy viscosity using a single\nconvolutional neural network at its core. We evaluate CFDNet on a variety of\nuse-cases, both extrapolative and interpolative, where test geometries are\nobserved/not-observed during training. Our results show that CFDNet meets the\nconvergence constraints of the domain-specific physics solver while\noutperforming it by 1.9 - 7.4x on both steady laminar and turbulent flows.\nMoreover, we demonstrate the generalization capacity of CFDNet by testing its\nprediction on new geometries unseen during training. In this case, the approach\nmeets the CFD convergence criterion while still providing significant speedups\nover traditional domain-only models.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 18:06:09 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Obiols-Sales", "Octavi", ""], ["Vishnu", "Abhinav", ""], ["Malaya", "Nicholas", ""], ["Chandramowlishwaran", "Aparna", ""]]}, {"id": "2005.04504", "submitter": "Saeed Saremi", "authors": "Saeed Saremi, Rupesh Srivastava", "title": "Provable Robust Classification via Learned Smoothed Densities", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smoothing classifiers and probability density functions with Gaussian kernels\nappear unrelated, but in this work, they are unified for the problem of robust\nclassification. The key building block is approximating the $\\textit{energy\nfunction}$ of the random variable $Y=X+N(0,\\sigma^2 I_d)$ with a neural network\nwhich we use to formulate the problem of robust classification in terms of\n$\\widehat{x}(Y)$, the $\\textit{Bayes estimator}$ of $X$ given the noisy\nmeasurements $Y$. We introduce $\\textit{empirical Bayes smoothed classifiers}$\nwithin the framework of $\\textit{randomized smoothing}$ and study it\ntheoretically for the two-class linear classifier, where we show one can\nimprove their robustness above $\\textit{the margin}$. We test the theory on\nMNIST and we show that with a learned smoothed energy function and a linear\nclassifier we can achieve provable $\\ell_2$ robust accuracies that are\ncompetitive with empirical defenses. This setup can be significantly improved\nby $\\textit{learning}$ empirical Bayes smoothed classifiers with adversarial\ntraining and on MNIST we show that we can achieve provable robust accuracies\nhigher than the state-of-the-art empirical defenses in a range of radii. We\ndiscuss some fundamental challenges of randomized smoothing based on a\ngeometric interpretation due to concentration of Gaussians in high dimensions,\nand we finish the paper with a proposal for using walk-jump sampling, itself\nbased on learned smoothed densities, for robust classification.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 19:52:32 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Saremi", "Saeed", ""], ["Srivastava", "Rupesh", ""]]}, {"id": "2005.04507", "submitter": "Mahan Tajrobehkar", "authors": "Xin Guo, Jiequn Han, Mahan Tajrobehkar, Wenpin Tang", "title": "PGDOT -- Perturbed Gradient Descent Adapted with Occupation Time", "comments": "15 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops further the idea of perturbed gradient descent (PGD), by\nadapting perturbation with the history of states via the notion of occupation\ntime. The proposed algorithm, perturbed gradient descent adapted with\noccupation time (PGDOT), is shown to converge at least as fast as the PGD\nalgorithm and is guaranteed to avoid getting stuck at saddle points. The\nanalysis is corroborated by empirical studies, in which a mini-batch version of\nPGDOT is shown to outperform alternatives such as mini-batch gradient descent,\nAdam, AMSGrad, and RMSProp in training multilayer perceptrons (MLPs). In\nparticular, the mini-batch PGDOT manages to escape saddle points whereas these\nalternatives fail.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 19:58:23 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 23:42:27 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Guo", "Xin", ""], ["Han", "Jiequn", ""], ["Tajrobehkar", "Mahan", ""], ["Tang", "Wenpin", ""]]}, {"id": "2005.04511", "submitter": "Ethan Chi", "authors": "Ethan A. Chi, John Hewitt, Christopher D. Manning", "title": "Finding Universal Grammatical Relations in Multilingual BERT", "comments": "To appear in ACL 2020; Farsi typo corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has found evidence that Multilingual BERT (mBERT), a\ntransformer-based multilingual masked language model, is capable of zero-shot\ncross-lingual transfer, suggesting that some aspects of its representations are\nshared cross-lingually. To better understand this overlap, we extend recent\nwork on finding syntactic trees in neural networks' internal representations to\nthe multilingual setting. We show that subspaces of mBERT representations\nrecover syntactic tree distances in languages other than English, and that\nthese subspaces are approximately shared across languages. Motivated by these\nresults, we present an unsupervised analysis method that provides evidence\nmBERT learns representations of syntactic dependency labels, in the form of\nclusters which largely agree with the Universal Dependencies taxonomy. This\nevidence suggests that even without explicit supervision, multilingual masked\nlanguage models learn certain linguistic universals.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 20:46:02 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 08:32:18 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Chi", "Ethan A.", ""], ["Hewitt", "John", ""], ["Manning", "Christopher D.", ""]]}, {"id": "2005.04513", "submitter": "Mohammad Sabouri", "authors": "Mohammad Sabouri, Sara Siamak, Maryam Dehghani, Mohsen Mohammadi and\n  Mohammad Hassan Asemani", "title": "Intelligent GPS Spoofing Attack Detection in Power Grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The GPS is vulnerable to GPS spoofing attack (GSA), which leads to disorder\nin time and position results of the GPS receiver. In power grids, phasor\nmeasurement units (PMUs) use GPS to build time-tagged measurements, so they are\nsusceptible to this attack. As a result of this attack, sampling time and phase\nangle of the PMU measurements change. In this paper, a neural network GPS\nspoofing detection (NNGSD) with employing PMU data from the dynamic power\nsystem is presented to detect GSAs. Numerical results in different conditions\nshow the real-time performance of the proposed detection method.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 20:52:18 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Sabouri", "Mohammad", ""], ["Siamak", "Sara", ""], ["Dehghani", "Maryam", ""], ["Mohammadi", "Mohsen", ""], ["Asemani", "Mohammad Hassan", ""]]}, {"id": "2005.04518", "submitter": "Preslav Nakov", "authors": "Ramy Baly, Georgi Karadzhov, Jisun An, Haewoon Kwak, Yoan Dinkov,\n  Ahmed Ali, James Glass, Preslav Nakov", "title": "What Was Written vs. Who Read It: News Media Profiling Using Text\n  Analysis and Social Media Context", "comments": "Factuality of reporting, fact-checking, political ideology, media\n  bias, disinformation, propaganda, social media, news media", "journal-ref": "ACL-2020", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the political bias and the factuality of reporting of entire news\noutlets are critical elements of media profiling, which is an understudied but\nan increasingly important research direction. The present level of\nproliferation of fake, biased, and propagandistic content online, has made it\nimpossible to fact-check every single suspicious claim, either manually or\nautomatically. Alternatively, we can profile entire news outlets and look for\nthose that are likely to publish fake or biased content. This approach makes it\npossible to detect likely \"fake news\" the moment they are published, by simply\nchecking the reliability of their source. From a practical perspective,\npolitical bias and factuality of reporting have a linguistic aspect but also a\nsocial context. Here, we study the impact of both, namely (i) what was written\n(i.e., what was published by the target medium, and how it describes itself on\nTwitter) vs. (ii) who read it (i.e., analyzing the readers of the target medium\non Facebook, Twitter, and YouTube). We further study (iii) what was written\nabout the target medium on Wikipedia. The evaluation results show that what was\nwritten matters most, and that putting all information sources together yields\nhuge improvements over the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 22:00:08 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Baly", "Ramy", ""], ["Karadzhov", "Georgi", ""], ["An", "Jisun", ""], ["Kwak", "Haewoon", ""], ["Dinkov", "Yoan", ""], ["Ali", "Ahmed", ""], ["Glass", "James", ""], ["Nakov", "Preslav", ""]]}, {"id": "2005.04536", "submitter": "Alexis Asseman", "authors": "Alexis Asseman, Nicolas Antoine and Ahmet S. Ozcan", "title": "Accelerating Deep Neuroevolution on Distributed FPGAs for Reinforcement\n  Learning Problems", "comments": "12 pages. Submitted to ACM Journal on Emerging Technologies in\n  Computing Systems: Special Issue on Hardware and Algorithms for Efficient\n  Machine Learning", "journal-ref": null, "doi": "10.1145/3425500", "report-no": null, "categories": "cs.NE cs.AI cs.AR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning augmented by the representational power of deep neural\nnetworks, has shown promising results on high-dimensional problems, such as\ngame playing and robotic control. However, the sequential nature of these\nproblems poses a fundamental challenge for computational efficiency. Recently,\nalternative approaches such as evolutionary strategies and deep neuroevolution\ndemonstrated competitive results with faster training time on distributed CPU\ncores. Here, we report record training times (running at about 1 million frames\nper second) for Atari 2600 games using deep neuroevolution implemented on\ndistributed FPGAs. Combined hardware implementation of the game console, image\npre-processing and the neural network in an optimized pipeline, multiplied with\nthe system level parallelism enabled the acceleration. These results are the\nfirst application demonstration on the IBM Neural Computer, which is a custom\ndesigned system that consists of 432 Xilinx FPGAs interconnected in a 3D mesh\nnetwork topology. In addition to high performance, experiments also showed\nimprovement in accuracy for all games compared to the CPU-implementation of the\nsame algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 00:41:39 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Asseman", "Alexis", ""], ["Antoine", "Nicolas", ""], ["Ozcan", "Ahmet S.", ""]]}, {"id": "2005.04537", "submitter": "Nathan P. Lawrence", "authors": "Nathan P. Lawrence, Gregory E. Stewart, Philip D. Loewen, Michael G.\n  Forbes, Johan U. Backstrom, R. Bhushan Gopaluni", "title": "Reinforcement Learning based Design of Linear Fixed Structure\n  Controllers", "comments": "IFAC World Congress 2020", "journal-ref": null, "doi": "10.1016/j.ifacol.2020.12.127", "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has been successfully applied to the problem of tuning\nPID controllers in several applications. The existing methods often utilize\nfunction approximation, such as neural networks, to update the controller\nparameters at each time-step of the underlying process. In this work, we\npresent a simple finite-difference approach, based on random search, to tuning\nlinear fixed-structure controllers. For clarity and simplicity, we focus on PID\ncontrollers. Our algorithm operates on the entire closed-loop step response of\nthe system and iteratively improves the PID gains towards a desired closed-loop\nresponse. This allows for embedding stability requirements into the reward\nfunction without any modeling procedures.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 00:53:11 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Lawrence", "Nathan P.", ""], ["Stewart", "Gregory E.", ""], ["Loewen", "Philip D.", ""], ["Forbes", "Michael G.", ""], ["Backstrom", "Johan U.", ""], ["Gopaluni", "R. Bhushan", ""]]}, {"id": "2005.04539", "submitter": "Nathan P. Lawrence", "authors": "Nathan P. Lawrence, Gregory E. Stewart, Philip D. Loewen, Michael G.\n  Forbes, Johan U. Backstrom, R. Bhushan Gopaluni", "title": "Optimal PID and Antiwindup Control Design as a Reinforcement Learning\n  Problem", "comments": "IFAC World Congress 2020", "journal-ref": null, "doi": "10.1016/j.ifacol.2020.12.129", "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has seen several successful applications to\nprocess control. Common methods rely on a deep neural network structure to\nmodel the controller or process. With increasingly complicated control\nstructures, the closed-loop stability of such methods becomes less clear. In\nthis work, we focus on the interpretability of DRL control methods. In\nparticular, we view linear fixed-structure controllers as shallow neural\nnetworks embedded in the actor-critic framework. PID controllers guide our\ndevelopment due to their simplicity and acceptance in industrial practice. We\nthen consider input saturation, leading to a simple nonlinear control\nstructure. In order to effectively operate within the actuator limits we then\nincorporate a tuning parameter for anti-windup compensation. Finally, the\nsimplicity of the controller allows for straightforward initialization. This\nmakes our method inherently stabilizing, both during and after training, and\namenable to known operational PID gains.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 01:05:26 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Lawrence", "Nathan P.", ""], ["Stewart", "Gregory E.", ""], ["Loewen", "Philip D.", ""], ["Forbes", "Michael G.", ""], ["Backstrom", "Johan U.", ""], ["Gopaluni", "R. Bhushan", ""]]}, {"id": "2005.04544", "submitter": "Baihan Lin", "authors": "Baihan Lin, Guillermo Cecchi, Djallel Bouneffouf, Jenna Reinen, Irina\n  Rish", "title": "An Empirical Study of Human Behavioral Agents in Bandits, Contextual\n  Bandits and Reinforcement Learning", "comments": "This article supersedes and extends our work arXiv:1706.02897 (MAB)\n  and arXiv:1906.11286 (RL) into the Contextual Bandit (CB) framework. It\n  generalized extensively into multi-armed bandits, contextual bandits and RL\n  settings to create a unified framework of human behavioral agents", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial behavioral agents are often evaluated based on their consistent\nbehaviors and performance to take sequential actions in an environment to\nmaximize some notion of cumulative reward. However, human decision making in\nreal life usually involves different strategies and behavioral trajectories\nthat lead to the same empirical outcome. Motivated by clinical literature of a\nwide range of neurological and psychiatric disorders, we propose here a more\ngeneral and flexible parametric framework for sequential decision making that\ninvolves a two-stream reward processing mechanism. We demonstrated that this\nframework is flexible and unified enough to incorporate a family of problems\nspanning multi-armed bandits (MAB), contextual bandits (CB) and reinforcement\nlearning (RL), which decompose the sequential decision making process in\ndifferent levels. Inspired by the known reward processing abnormalities of many\nmental disorders, our clinically-inspired agents demonstrated interesting\nbehavioral trajectories and comparable performance on simulated tasks with\nparticular reward distributions, a real-world dataset capturing human\ndecision-making in gambling tasks, and the PacMan game across different reward\nstationarities in a lifelong learning setting.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 01:43:39 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 01:55:54 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 10:14:12 GMT"}, {"version": "v4", "created": "Mon, 14 Sep 2020 15:23:22 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Lin", "Baihan", ""], ["Cecchi", "Guillermo", ""], ["Bouneffouf", "Djallel", ""], ["Reinen", "Jenna", ""], ["Rish", "Irina", ""]]}, {"id": "2005.04557", "submitter": "Youzhi Liang", "authors": "Xiaoyu Wu, Zeyu Bai, Jianguo Jia, Youzhi Liang", "title": "A Multi-Variate Triple-Regression Forecasting Algorithm for Long-Term\n  Customized Allergy Season Prediction", "comments": "4 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel multi-variate algorithm using a\ntriple-regression methodology to predict the airborne-pollen allergy season\nthat can be customized for each patient in the long term. To improve the\nprediction accuracy, we first perform a pre-processing to integrate the\nhistorical data of pollen concentration and various inferential signals from\nother covariates such as the meteorological data. We then propose a novel\nalgorithm which encompasses three-stage regressions: in Stage 1, a regression\nmodel to predict the start/end date of a airborne-pollen allergy season is\ntrained from a feature matrix extracted from 12 time series of the covariates\nwith a rolling window; in Stage 2, a regression model to predict the\ncorresponding uncertainty is trained based on the feature matrix and the\nprediction result from Stage 1; in Stage 3, a weighted linear regression model\nis built upon prediction results from Stage 1 and 2. It is observed and proved\nthat Stage 3 contributes to the improved forecasting accuracy and the reduced\nuncertainty of the multi-variate triple-regression algorithm. Based on\ndifferent allergy sensitivity level, the triggering concentration of the pollen\n- the definition of the allergy season can be customized individually. In our\nbacktesting, a mean absolute error (MAE) of 4.7 days was achieved using the\nalgorithm. We conclude that this algorithm could be applicable in both generic\nand long-term forecasting problems.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 02:42:12 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 18:58:37 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 01:23:50 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Wu", "Xiaoyu", ""], ["Bai", "Zeyu", ""], ["Jia", "Jianguo", ""], ["Liang", "Youzhi", ""]]}, {"id": "2005.04559", "submitter": "Mahdi Biparva", "authors": "Mahdi Biparva, John Tsotsos", "title": "Compact Neural Representation Using Attentive Network Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have evolved to become power demanding and consequently\ndifficult to apply to small-size mobile platforms. Network parameter reduction\nmethods have been introduced to systematically deal with the computational and\nmemory complexity of deep networks. We propose to examine the ability of\nattentive connection pruning to deal with redundancy reduction in neural\nnetworks as a contribution to the reduction of computational demand. In this\nwork, we describe a Top-Down attention mechanism that is added to a Bottom-Up\nfeedforward network to select important connections and subsequently prune\nredundant ones at all parametric layers. Our method not only introduces a novel\nhierarchical selection mechanism as the basis of pruning but also remains\ncompetitive with previous baseline methods in the experimental evaluation. We\nconduct experiments using different network architectures on popular benchmark\ndatasets to show high compression ratio is achievable with negligible loss of\naccuracy.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 03:20:01 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Biparva", "Mahdi", ""], ["Tsotsos", "John", ""]]}, {"id": "2005.04560", "submitter": "Xiang Lisa Li", "authors": "Xiang Lisa Li and Alexander M. Rush", "title": "Posterior Control of Blackbox Generation", "comments": "Accepted for publication at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text generation often requires high-precision output that obeys task-specific\nrules. This fine-grained control is difficult to enforce with off-the-shelf\ndeep learning models. In this work, we consider augmenting neural generation\nmodels with discrete control states learned through a structured\nlatent-variable approach. Under this formulation, task-specific knowledge can\nbe encoded through a range of rich, posterior constraints that are effectively\ntrained into the model. This approach allows users to ground internal model\ndecisions based on prior knowledge, without sacrificing the representational\npower of neural generative models. Experiments consider applications of this\napproach for text generation. We find that this method improves over standard\nbenchmarks, while also providing fine-grained control.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 03:22:45 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Li", "Xiang Lisa", ""], ["Rush", "Alexander M.", ""]]}, {"id": "2005.04563", "submitter": "Omobayode Fagbohungbe", "authors": "Omobayode Fagbohungbe, Sheikh Rufsan Reza, Xishuang Dong, Lijun Qian", "title": "Efficient Privacy Preserving Edge Computing Framework for Image\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to extract knowledge from the large data collected by edge devices,\ntraditional cloud based approach that requires data upload may not be feasible\ndue to communication bandwidth limitation as well as privacy and security\nconcerns of end users. To address these challenges, a novel privacy preserving\nedge computing framework is proposed in this paper for image classification.\nSpecifically, autoencoder will be trained unsupervised at each edge device\nindividually, then the obtained latent vectors will be transmitted to the edge\nserver for the training of a classifier. This framework would reduce the\ncommunications overhead and protect the data of the end users. Comparing to\nfederated learning, the training of the classifier in the proposed framework\ndoes not subject to the constraints of the edge devices, and the autoencoder\ncan be trained independently at each edge device without any server\ninvolvement. Furthermore, the privacy of the end users' data is protected by\ntransmitting latent vectors without additional cost of encryption. Experimental\nresults provide insights on the image classification performance vs. various\ndesign parameters such as the data compression ratio of the autoencoder and the\nmodel complexity.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 03:36:32 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Fagbohungbe", "Omobayode", ""], ["Reza", "Sheikh Rufsan", ""], ["Dong", "Xishuang", ""], ["Qian", "Lijun", ""]]}, {"id": "2005.04564", "submitter": "Xianxu Hou", "authors": "Xianxu Hou, Jingxin Liu, Bolei Xu, Xiaolong Wang, Bozhi Liu, Guoping\n  Qiu", "title": "Class-Aware Domain Adaptation for Improving Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have demonstrated convolutional neural networks are vulnerable\nto adversarial examples, i.e., inputs to machine learning models that an\nattacker has intentionally designed to cause the models to make a mistake. To\nimprove the adversarial robustness of neural networks, adversarial training has\nbeen proposed to train networks by injecting adversarial examples into the\ntraining data. However, adversarial training could overfit to a specific type\nof adversarial attack and also lead to standard accuracy drop on clean images.\nTo this end, we propose a novel Class-Aware Domain Adaptation (CADA) method for\nadversarial defense without directly applying adversarial training.\nSpecifically, we propose to learn domain-invariant features for adversarial\nexamples and clean images via a domain discriminator. Furthermore, we introduce\na class-aware component into the discriminator to increase the discriminative\npower of the network for adversarial examples. We evaluate our newly proposed\napproach using multiple benchmark datasets. The results demonstrate that our\nmethod can significantly improve the state-of-the-art of adversarial robustness\nfor various attacks and maintain high performances on clean images.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 03:45:19 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Hou", "Xianxu", ""], ["Liu", "Jingxin", ""], ["Xu", "Bolei", ""], ["Wang", "Xiaolong", ""], ["Liu", "Bozhi", ""], ["Qiu", "Guoping", ""]]}, {"id": "2005.04567", "submitter": "Qin Li", "authors": "Qin Li, Huachun Tan, Xizhu Jiang, Yuankai Wu, Linhui Ye", "title": "Non-recurrent Traffic Congestion Detection with a Coupled Scalable\n  Bayesian Robust Tensor Factorization Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-recurrent traffic congestion (NRTC) usually brings unexpected delays to\ncommuters. Hence, it is critical to accurately detect and recognize the NRTC in\na real-time manner. The advancement of road traffic detectors and loop\ndetectors provides researchers with a large-scale multivariable\ntemporal-spatial traffic data, which allows the deep research on NRTC to be\nconducted. However, it remains a challenging task to construct an analytical\nframework through which the natural spatial-temporal structural properties of\nmultivariable traffic information can be effectively represented and exploited\nto better understand and detect NRTC. In this paper, we present a novel\nanalytical training-free framework based on coupled scalable Bayesian robust\ntensor factorization (Coupled SBRTF). The framework can couple multivariable\ntraffic data including traffic flow, road speed, and occupancy through sharing\na similar or the same sparse structure. And, it naturally captures the\nhigh-dimensional spatial-temporal structural properties of traffic data by\ntensor factorization. With its entries revealing the distribution and magnitude\nof NRTC, the shared sparse structure of the framework compasses sufficiently\nabundant information about NRTC. While the low-rank part of the framework,\nexpresses the distribution of general expected traffic condition as an\nauxiliary product. Experimental results on real-world traffic data show that\nthe proposed method outperforms coupled Bayesian robust principal component\nanalysis (coupled BRPCA), the rank sparsity tensor decomposition (RSTD), and\nstandard normal deviates (SND) in detecting NRTC. The proposed method performs\neven better when only traffic data in weekdays are utilized, and hence can\nprovide more precise estimation of NRTC for daily commuters.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 03:58:18 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Li", "Qin", ""], ["Tan", "Huachun", ""], ["Jiang", "Xizhu", ""], ["Wu", "Yuankai", ""], ["Ye", "Linhui", ""]]}, {"id": "2005.04573", "submitter": "Li Zhang", "authors": "Li Zhang and Mingliang Wang and Mingxia Liu and Daoqiang Zhang", "title": "A Survey on Deep Learning for Neuroimaging-based Brain Disorder Analysis", "comments": "30 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been recently used for the analysis of neuroimages, such as\nstructural magnetic resonance imaging (MRI), functional MRI, and positron\nemission tomography (PET), and has achieved significant performance\nimprovements over traditional machine learning in computer-aided diagnosis of\nbrain disorders. This paper reviews the applications of deep learning methods\nfor neuroimaging-based brain disorder analysis. We first provide a\ncomprehensive overview of deep learning techniques and popular network\narchitectures, by introducing various types of deep neural networks and recent\ndevelopments. We then review deep learning methods for computer-aided analysis\nof four typical brain disorders, including Alzheimer's disease, Parkinson's\ndisease, Autism spectrum disorder, and Schizophrenia, where the first two\ndiseases are neurodegenerative disorders and the last two are\nneurodevelopmental and psychiatric disorders, respectively. More importantly,\nwe discuss the limitations of existing studies and present possible future\ndirections.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 04:20:50 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Zhang", "Li", ""], ["Wang", "Mingliang", ""], ["Liu", "Mingxia", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "2005.04586", "submitter": "Aly El Gamal", "authors": "Sharan Ramjee, Shengtai Ju, Diyu Yang, Xiaoyu Liu, Aly El Gamal,\n  Yonina C. Eldar", "title": "Ensemble Wrapper Subsampling for Deep Modulation Classification", "comments": "22 pages, 13 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subsampling of received wireless signals is important for relaxing hardware\nrequirements as well as the computational cost of signal processing algorithms\nthat rely on the output samples. We propose a subsampling technique to\nfacilitate the use of deep learning for automatic modulation classification in\nwireless communication systems. Unlike traditional approaches that rely on\npre-designed strategies that are solely based on expert knowledge, the proposed\ndata-driven subsampling strategy employs deep neural network architectures to\nsimulate the effect of removing candidate combinations of samples from each\ntraining input vector, in a manner inspired by how wrapper feature selection\nmodels work. The subsampled data is then processed by another deep learning\nclassifier that recognizes each of the considered 10 modulation types. We show\nthat the proposed subsampling strategy not only introduces drastic reduction in\nthe classifier training time, but can also improve the classification accuracy\nto higher levels than those reached before for the considered dataset. An\nimportant feature herein is exploiting the transferability property of deep\nneural networks to avoid retraining the wrapper models and obtain superior\nperformance through an ensemble of wrappers over that possible through solely\nrelying on any of them.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 06:11:13 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Ramjee", "Sharan", ""], ["Ju", "Shengtai", ""], ["Yang", "Diyu", ""], ["Liu", "Xiaoyu", ""], ["Gamal", "Aly El", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "2005.04587", "submitter": "Zexin Cai", "authors": "Zexin Cai, Chuxiong Zhang, Ming Li", "title": "From Speaker Verification to Multispeaker Speech Synthesis, Deep\n  Transfer with Feedback Constraint", "comments": "Accepted by INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-fidelity speech can be synthesized by end-to-end text-to-speech models\nin recent years. However, accessing and controlling speech attributes such as\nspeaker identity, prosody, and emotion in a text-to-speech system remains a\nchallenge. This paper presents a system involving feedback constraint for\nmultispeaker speech synthesis. We manage to enhance the knowledge transfer from\nthe speaker verification to the speech synthesis by engaging the speaker\nverification network. The constraint is taken by an added loss related to the\nspeaker identity, which is centralized to improve the speaker similarity\nbetween the synthesized speech and its natural reference audio. The model is\ntrained and evaluated on publicly available datasets. Experimental results,\nincluding visualization on speaker embedding space, show significant\nimprovement in terms of speaker identity cloning in the spectrogram level.\nSynthesized samples are available online for listening.\n(https://caizexin.github.io/mlspk-syn-samples/index.html)\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 06:11:37 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 20:08:34 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2020 13:55:25 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Cai", "Zexin", ""], ["Zhang", "Chuxiong", ""], ["Li", "Ming", ""]]}, {"id": "2005.04593", "submitter": "Ritam Guha Mr.", "authors": "Ritam Guha, Manosij Ghosh, Shyok Mutsuddi, Ram Sarkar, Seyedali\n  Mirjalili", "title": "Embedded Chaotic Whale Survival Algorithm for Filter-Wrapper Feature\n  Selection", "comments": "28 pages, 6 figures, submitted a minor revision to Soft Computing,\n  Springer", "journal-ref": null, "doi": "10.1007/s00500-020-05183-1", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification accuracy provided by a machine learning model depends a lot on\nthe feature set used in the learning process. Feature Selection (FS) is an\nimportant and challenging pre-processing technique which helps to identify only\nthe relevant features from a dataset thereby reducing the feature dimension as\nwell as improving the classification accuracy at the same time. The binary\nversion of Whale Optimization Algorithm (WOA) is a popular FS technique which\nis inspired from the foraging behavior of humpback whales. In this paper, an\nembedded version of WOA called Embedded Chaotic Whale Survival Algorithm\n(ECWSA) has been proposed which uses its wrapper process to achieve high\nclassification accuracy and a filter approach to further refine the selected\nsubset with low computation cost. Chaos has been introduced in the ECWSA to\nguide selection of the type of movement followed by the whales while searching\nfor prey. A fitness-dependent death mechanism has also been introduced in the\nsystem of whales which is inspired from the real-life scenario in which whales\ndie if they are unable to catch their prey. The proposed method has been\nevaluated on 18 well-known UCI datasets and compared with its predecessors as\nwell as some other popular FS methods.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 07:01:18 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Guha", "Ritam", ""], ["Ghosh", "Manosij", ""], ["Mutsuddi", "Shyok", ""], ["Sarkar", "Ram", ""], ["Mirjalili", "Seyedali", ""]]}, {"id": "2005.04596", "submitter": "Ritam Guha Mr.", "authors": "Ritam Guha, Manosij Ghosh, Pawan Kumar Singh, Ram Sarkar, Mita\n  Nasipuri", "title": "A Hybrid Swarm and Gravitation based feature selection algorithm for\n  Handwritten Indic Script Classification problem", "comments": "37 pages, 22 figures, submitted to Multimedia Tools and Applications,\n  Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In any multi-script environment, handwritten script classification is of\nparamount importance before the document images are fed to their respective\nOptical Character Recognition (OCR) engines. Over the years, this complex\npattern classification problem has been solved by researchers proposing various\nfeature vectors mostly having large dimension, thereby increasing the\ncomputation complexity of the whole classification model. Feature Selection\n(FS) can serve as an intermediate step to reduce the size of the feature\nvectors by restricting them only to the essential and relevant features. In our\npaper, we have addressed this issue by introducing a new FS algorithm, called\nHybrid Swarm and Gravitation based FS (HSGFS). This algorithm is made to run on\n3 feature vectors introduced in the literature recently - Distance-Hough\nTransform (DHT), Histogram of Oriented Gradients (HOG) and Modified log-Gabor\n(MLG) filter Transform. Three state-of-the-art classifiers namely, Multi-Layer\nPerceptron (MLP), K-Nearest Neighbour (KNN) and Support Vector Machine (SVM)\nare used for the handwritten script classification. Handwritten datasets,\nprepared at block, text-line and word level, consisting of officially\nrecognized 12 Indic scripts are used for the evaluation of our method. An\naverage improvement in the range of 2-5 % is achieved in the classification\naccuracies by utilizing only about 75-80 % of the original feature vectors on\nall three datasets. The proposed methodology also shows better performance when\ncompared to some popularly used FS models.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 07:27:55 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Guha", "Ritam", ""], ["Ghosh", "Manosij", ""], ["Singh", "Pawan Kumar", ""], ["Sarkar", "Ram", ""], ["Nasipuri", "Mita", ""]]}, {"id": "2005.04602", "submitter": "Anthony Rhodes", "authors": "Anthony D. Rhodes, Bin Jiang", "title": "Regularized L21-Based Semi-NonNegative Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general-purpose data compression algorithm, Regularized L21\nSemi-NonNegative Matrix Factorization (L21 SNF). L21 SNF provides robust,\nparts-based compression applicable to mixed-sign data for which high fidelity,\nindividualdata point reconstruction is paramount. We derive a rigorous proof of\nconvergenceof our algorithm. Through experiments, we show the use-case\nadvantages presentedby L21 SNF, including application to the compression of\nhighly overdeterminedsystems encountered broadly across many general machine\nlearning processes.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 08:19:51 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Rhodes", "Anthony D.", ""], ["Jiang", "Bin", ""]]}, {"id": "2005.04612", "submitter": "Ritajit Majumdar", "authors": "Aditya Vikram Singhania, Saronyo Lal Mukherjee, Ritajit Majumdar,\n  Akash Mehta, Priyanka Banerjee and Debasmita Bhoumik", "title": "A machine learning based heuristic to predict the efficacy of online\n  sale", "comments": "Paper selected for Oral presentation at the 2nd International\n  Conference on Emerging Technologies in Data Mining and Information Security\n  (IEMIS 2020). Will appear in Springer Advances in Intelligent Systems and\n  Computing (AISC) Series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is difficult to decide upon the efficacy of an online sale simply from the\ndiscount offered on commodities. Different features have different influence on\nthe price of a product which must be taken into consideration when determining\nthe significance of a discount. In this paper we have proposed a machine\nlearning based heuristic to quantify the \\textit{\"significance\"} of the\ndiscount offered on any commodity. Our proposed technique can quantify the\nsignificance of the discount based on features and the original price, and\nhence can guide a buyer during a sale season by predicting the efficacy of the\nsale. We have applied this technique on the Flipkart Summer Sale dataset using\nSupport Vector Machine, which predicts the efficacy of the sale with an\naccuracy of 91.11\\%. Our result shows that very few mobile phones have a\nsignificant discount during the Flipkart Summer Sale.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 09:31:54 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Singhania", "Aditya Vikram", ""], ["Mukherjee", "Saronyo Lal", ""], ["Majumdar", "Ritajit", ""], ["Mehta", "Akash", ""], ["Banerjee", "Priyanka", ""], ["Bhoumik", "Debasmita", ""]]}, {"id": "2005.04646", "submitter": "Hiroki Matsutani", "authors": "Hirohisa Watanabe, Mineto Tsukada and Hiroki Matsutani", "title": "An FPGA-Based On-Device Reinforcement Learning Approach using Online\n  Sequential Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DQN (Deep Q-Network) is a method to perform Q-learning for reinforcement\nlearning using deep neural networks. DQNs require a large buffer and batch\nprocessing for an experience replay and rely on a backpropagation based\niterative optimization, making them difficult to be implemented on\nresource-limited edge devices. In this paper, we propose a lightweight\non-device reinforcement learning approach for low-cost FPGA devices. It\nexploits a recently proposed neural-network based on-device learning approach\nthat does not rely on the backpropagation method but uses OS-ELM (Online\nSequential Extreme Learning Machine) based training algorithm. In addition, we\npropose a combination of L2 regularization and spectral normalization for the\non-device reinforcement learning so that output values of the neural network\ncan be fit into a certain range and the reinforcement learning becomes stable.\nThe proposed reinforcement learning approach is designed for PYNQ-Z1 board as a\nlow-cost FPGA platform. The evaluation results using OpenAI Gym demonstrate\nthat the proposed algorithm and its FPGA implementation complete a CartPole-v0\ntask 29.77x and 89.40x faster than a conventional DQN-based approach when the\nnumber of hidden-layer nodes is 64.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 12:37:26 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 08:35:11 GMT"}, {"version": "v3", "created": "Tue, 23 Mar 2021 07:09:38 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Watanabe", "Hirohisa", ""], ["Tsukada", "Mineto", ""], ["Matsutani", "Hiroki", ""]]}, {"id": "2005.04671", "submitter": "Miaohua Zhang", "authors": "Miaohua Zhang, Yongsheng Gao", "title": "A Generalized Kernel Risk Sensitive Loss for Robust Two-Dimensional\n  Singular Value Decomposition", "comments": "Under Consideration by \"Pattern Recognition\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-dimensional singular decomposition (2DSVD) has been widely used for image\nprocessing tasks, such as image reconstruction, classification, and clustering.\nHowever, traditional 2DSVD algorithm is based on the mean square error (MSE)\nloss, which is sensitive to outliers. To overcome this problem, we propose a\nrobust 2DSVD framework based on a generalized kernel risk sensitive loss\n(GKRSL-2DSVD) which is more robust to noise and and outliers. Since the\nproposed objective function is non-convex, a majorization-minimization\nalgorithm is developed to efficiently solve it with guaranteed convergence. The\nproposed framework has inherent properties of processing non-centered data,\nrotational invariant, being easily extended to higher order spaces.\nExperimental results on public databases demonstrate that the performance of\nthe proposed method on different applications significantly outperforms that of\nall the benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 14:02:40 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 04:20:50 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Zhang", "Miaohua", ""], ["Gao", "Yongsheng", ""]]}, {"id": "2005.04679", "submitter": "Erdogan Taskesen", "authors": "Erdogan Taskesen", "title": "HNet: Graphical Hypergeometric Networks", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Real-world data often contain measurements with both continuous\nand discrete values. Despite the availability of many libraries, data sets with\nmixed data types require intensive pre-processing steps, and it remains a\nchallenge to describe the relationships between variables. The data\nunderstanding phase is an important step in the data mining process, however,\nwithout making any assumptions on the data, the search space is\nsuper-exponential in the number of variables. Methods: We propose graphical\nhypergeometric networks (HNet), a method to test associations across variables\nfor significance using statistical inference. The aim is to determine a network\nusing only the significant associations in order to shed light on the complex\nrelationships across variables. HNet processes raw unstructured data sets and\noutputs a network that consists of (partially) directed or undirected edges\nbetween the nodes (i.e., variables). To evaluate the accuracy of HNet, we used\nwell known data sets and in addition generated data sets with known ground\ntruth. The performance of HNet is compared to Bayesian structure learning.\nResults: We demonstrate that HNet showed high accuracy and performance in the\ndetection of node links. In the case of the Alarm data set we can demonstrate\non average an MCC score of 0.33 + 0.0002 (P<1x10-6), whereas Bayesian structure\nlearning resulted in an average MCC score of 0.52 + 0.006 (P<1x10-11), and\nrandomly assigning edges resulted in a MCC score of 0.004 + 0.0003 (P=0.49).\nConclusions: HNet can process raw unstructured data sets, allows analysis of\nmixed data types, it easily scales up in number of variables, and allows\ndetailed examination of the detected associations. Availability:\nhttps://erdogant.github.io/hnet/\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 14:33:52 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Taskesen", "Erdogan", ""]]}, {"id": "2005.04680", "submitter": "Alexander Heinecke", "authors": "Dhiraj Kalamkar, Evangelos Georganas, Sudarshan Srinivasan, Jianping\n  Chen, Mikhail Shiryaev, Alexander Heinecke", "title": "Optimizing Deep Learning Recommender Systems' Training On CPU Cluster\n  Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IR cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last two years, the goal of many researchers has been to squeeze\nthe last bit of performance out of HPC system for AI tasks. Often this\ndiscussion is held in the context of how fast ResNet50 can be trained.\nUnfortunately, ResNet50 is no longer a representative workload in 2020. Thus,\nwe focus on Recommender Systems which account for most of the AI cycles in\ncloud computing centers. More specifically, we focus on Facebook's DLRM\nbenchmark. By enabling it to run on latest CPU hardware and software tailored\nfor HPC, we are able to achieve more than two-orders of magnitude improvement\nin performance (110x) on a single socket compared to the reference CPU\nimplementation, and high scaling efficiency up to 64 sockets, while fitting\nultra-large datasets. This paper discusses the optimization techniques for the\nvarious operators in DLRM and which component of the systems are stressed by\nthese different operators. The presented techniques are applicable to a broader\nset of DL workloads that pose the same scaling challenges/characteristics as\nDLRM.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 14:40:16 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Kalamkar", "Dhiraj", ""], ["Georganas", "Evangelos", ""], ["Srinivasan", "Sudarshan", ""], ["Chen", "Jianping", ""], ["Shiryaev", "Mikhail", ""], ["Heinecke", "Alexander", ""]]}, {"id": "2005.04689", "submitter": "Tien Dung Nguyen", "authors": "Tien-Dung Nguyen", "title": "Improving The Performance Of The K-means Algorithm", "comments": "The graduation thesis submitted to the School of Computer Science and\n  Engineering, International University - Vietnam National University HCMC in\n  partial fulfillment of the requirements for the degree of Master of\n  Information Technology Management", "journal-ref": null, "doi": null, "report-no": "Graduation Thesis (2013)", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Incremental K-means (IKM), an improved version of K-means (KM), was\nintroduced to improve the clustering quality of KM significantly. However, the\nspeed of IKM is slower than KM. My thesis proposes two algorithms to speed up\nIKM while remaining the quality of its clustering result approximately. The\nfirst algorithm, called Divisive K-means, improves the speed of IKM by speeding\nup its splitting process of clusters. Testing with UCI Machine Learning data\nsets, the new algorithm achieves the empirically global optimum as IKM and has\nlower complexity, $O(k*log_{2}k*n)$, than IKM, $O(k^{2}n)$. The second\nalgorithm, called Parallel Two-Phase K-means (Par2PK-means), parallelizes IKM\nby employing the model of Two-Phase K-means. Testing with large data sets, this\nalgorithm attains a good speedup ratio, closing to the linearly speed-up ratio.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 15:09:44 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Nguyen", "Tien-Dung", ""]]}, {"id": "2005.04690", "submitter": "Longteng Guo", "authors": "Longteng Guo, Jing Liu, Xinxin Zhu, Xingjian He, Jie Jiang, Hanqing Lu", "title": "Non-Autoregressive Image Captioning with Counterfactuals-Critical\n  Multi-Agent Learning", "comments": "IJCAI 2020 (copyright held by IJCAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most image captioning models are autoregressive, i.e. they generate each word\nby conditioning on previously generated words, which leads to heavy latency\nduring inference. Recently, non-autoregressive decoding has been proposed in\nmachine translation to speed up the inference time by generating all words in\nparallel. Typically, these models use the word-level cross-entropy loss to\noptimize each word independently. However, such a learning process fails to\nconsider the sentence-level consistency, thus resulting in inferior generation\nquality of these non-autoregressive models. In this paper, we propose a\nNon-Autoregressive Image Captioning (NAIC) model with a novel training\nparadigm: Counterfactuals-critical Multi-Agent Learning (CMAL). CMAL formulates\nNAIC as a multi-agent reinforcement learning system where positions in the\ntarget sequence are viewed as agents that learn to cooperatively maximize a\nsentence-level reward. Besides, we propose to utilize massive unlabeled images\nto boost captioning performance. Extensive experiments on MSCOCO image\ncaptioning benchmark show that our NAIC model achieves a performance comparable\nto state-of-the-art autoregressive models, while brings 13.9x decoding speedup.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 15:09:44 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Guo", "Longteng", ""], ["Liu", "Jing", ""], ["Zhu", "Xinxin", ""], ["He", "Xingjian", ""], ["Jiang", "Jie", ""], ["Lu", "Hanqing", ""]]}, {"id": "2005.04692", "submitter": "Tomaso Aste", "authors": "Tomaso Aste", "title": "Topological regularization with information filtering networks", "comments": "16 pages , 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A methodology to perform topological regularization via information filtering\nnetwork is introduced. This methodology can be directly applied to sparse\nmodeling with the vast family of elliptical probability distributions. It can\nalso be directly implemented for $L_0$ norm regularized multicollinear\nregression. In this paper, I describe in detail an application to sparse\nmodeling with multivariate Student-t. A specific $L_0$ norm regularized\nexpectation-maximization likelihood maximization procedure is proposed for this\nsparse Student-t case. Examples with real data from stock prices log-returns\nand from artificially generated data demonstrate applicability, performances,\nand potentials of this methodology.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 15:15:04 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Aste", "Tomaso", ""]]}, {"id": "2005.04697", "submitter": "Jonathan Frawley", "authors": "Jonathan Frawley, Chris G. Willcocks, Maged Habib, Caspar Geenen,\n  David H. Steel and Boguslaw Obara", "title": "Segmentation of Macular Edema Datasets with Small Residual 3D U-Net\n  Architectures", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the application of deep convolutional neural networks\nwith prohibitively small datasets to the problem of macular edema segmentation.\nIn particular, we investigate several different heavily regularized\narchitectures. We find that, contrary to popular belief, neural architectures\nwithin this application setting are able to achieve close to human-level\nperformance on unseen test images without requiring large numbers of training\nexamples. Annotating these 3D datasets is difficult, with multiple criteria\nrequired. It takes an experienced clinician two days to annotate a single 3D\nimage, whereas our trained model achieves similar performance in less than a\nsecond. We found that an approach which uses targeted dataset augmentation,\nalongside architectural simplification with an emphasis on residual design, has\nacceptable generalization performance - despite relying on fewer than 15\ntraining examples.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 15:34:46 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Frawley", "Jonathan", ""], ["Willcocks", "Chris G.", ""], ["Habib", "Maged", ""], ["Geenen", "Caspar", ""], ["Steel", "David H.", ""], ["Obara", "Boguslaw", ""]]}, {"id": "2005.04703", "submitter": "Yuzhi Zhao", "authors": "Yuzhi Zhao, Lai-Man Po, Qiong Yan, Wei Liu, Tingyu Lin", "title": "Hierarchical Regression Network for Spectral Reconstruction from RGB\n  Images", "comments": "1st Place in CVPRW 2020 NTIRE Spectral Reconstruction Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing visual image with a hyperspectral camera has been successfully\napplied to many areas due to its narrow-band imaging technology. Hyperspectral\nreconstruction from RGB images denotes a reverse process of hyperspectral\nimaging by discovering an inverse response function. Current works mainly map\nRGB images directly to corresponding spectrum but do not consider context\ninformation explicitly. Moreover, the use of encoder-decoder pair in current\nalgorithms leads to loss of information. To address these problems, we propose\na 4-level Hierarchical Regression Network (HRNet) with PixelShuffle layer as\ninter-level interaction. Furthermore, we adopt a residual dense block to remove\nartifacts of real world RGB images and a residual global block to build\nattention mechanism for enlarging perceptive field. We evaluate proposed HRNet\nwith other architectures and techniques by participating in NTIRE 2020\nChallenge on Spectral Reconstruction from RGB Images. The HRNet is the winning\nmethod of track 2 - real world images and ranks 3rd on track 1 - clean images.\nPlease visit the project web page\nhttps://github.com/zhaoyuzhi/Hierarchical-Regression-Network-for-Spectral-Reconstruction-from-RGB-Images\nto try our codes and pre-trained models.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 16:06:11 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Zhao", "Yuzhi", ""], ["Po", "Lai-Man", ""], ["Yan", "Qiong", ""], ["Liu", "Wei", ""], ["Lin", "Tingyu", ""]]}, {"id": "2005.04708", "submitter": "Aya Ahmed", "authors": "Aya Mostafa Ahmed, Alaa Alameer Ahmad, Stefano Fortunati, Aydin\n  Sezgin, Maria S. Greco, Fulvio Gini", "title": "A Reinforcement Learning based approach for Multi-target Detection in\n  Massive MIMO radar", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of multi-target detection for massive\nmultiple input multiple output (MMIMO) cognitive radar (CR). The concept of CR\nis based on the perception-action cycle that senses and intelligently adapts to\nthe dynamic environment in order to optimally satisfy a specific mission.\nHowever, this usually requires a priori knowledge of the environmental model,\nwhich is not available in most cases. We propose a reinforcement learning (RL)\nbased algorithm for cognitive multi-target detection in the presence of unknown\ndisturbance statistics. The radar acts as an agent that continuously senses the\nunknown environment (i.e., targets and disturbance) and consequently optimizes\ntransmitted waveforms in order to maximize the probability of detection\n($P_\\mathsf{D}$) by focusing the energy in specific range-angle cells (i.e.,\nbeamforming). Furthermore, we propose a solution to the beamforming\noptimization problem with less complexity than the existing methods. Numerical\nsimulations are performed to assess the performance of the proposed RL-based\nalgorithm in both stationary and dynamic environments. The RL based beamforming\nis compared to the conventional omnidirectional approach with equal power\nallocation and to adaptive beamforming with no RL. As highlighted by the\nproposed numerical results, our RL-based beamformer outperforms both approaches\nin terms of target detection performance. The performance improvement is even\nparticularly remarkable under environmentally harsh conditions such as low SNR,\nheavy-tailed disturbance and rapidly changing scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 16:29:06 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 09:27:02 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 09:32:49 GMT"}, {"version": "v4", "created": "Tue, 2 Mar 2021 11:35:32 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Ahmed", "Aya Mostafa", ""], ["Ahmad", "Alaa Alameer", ""], ["Fortunati", "Stefano", ""], ["Sezgin", "Aydin", ""], ["Greco", "Maria S.", ""], ["Gini", "Fulvio", ""]]}, {"id": "2005.04712", "submitter": "Hirofumi Inaguma", "authors": "Hirofumi Inaguma, Masato Mimura, Tatsuya Kawahara", "title": "CTC-synchronous Training for Monotonic Attention Model", "comments": "Accepted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monotonic chunkwise attention (MoChA) has been studied for the online\nstreaming automatic speech recognition (ASR) based on a sequence-to-sequence\nframework. In contrast to connectionist temporal classification (CTC), backward\nprobabilities cannot be leveraged in the alignment marginalization process\nduring training due to left-to-right dependency in the decoder. This results in\nthe error propagation of alignments to subsequent token generation. To address\nthis problem, we propose CTC-synchronous training (CTC-ST), in which MoChA uses\nCTC alignments to learn optimal monotonic alignments. Reference CTC alignments\nare extracted from a CTC branch sharing the same encoder with the decoder. The\nentire model is jointly optimized so that the expected boundaries from MoChA\nare synchronized with the alignments. Experimental evaluations of the TEDLIUM\nrelease-2 and Librispeech corpora show that the proposed method significantly\nimproves recognition, especially for long utterances. We also show that CTC-ST\ncan bring out the full potential of SpecAugment for MoChA.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 16:48:23 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 01:53:33 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 10:07:04 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Inaguma", "Hirofumi", ""], ["Mimura", "Masato", ""], ["Kawahara", "Tatsuya", ""]]}, {"id": "2005.04723", "submitter": "Nickolay Shlyankin", "authors": "N.S. Shlyankin, A.V. Gaidel", "title": "Application of the Hidden Markov Model for determining PQRST complexes\n  in electrocardiograms", "comments": "in Russian", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of the hidden Markov model with various parameters in the\nsegmentation task of QRS, ST, T, P, PQ, ISO complexes of electrocardiograms is\nconsidered. Models were trained using the Viterbi algorithm using the QT\nDatabase. For comparison, the Pan-Tompkins algorithm for searching for the\nduration of QRS complexes was modified.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 17:32:25 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Shlyankin", "N. S.", ""], ["Gaidel", "A. V.", ""]]}, {"id": "2005.04725", "submitter": "Xiyuan Chen", "authors": "Xiyuan Chen, Mark Heimann, Fatemeh Vahedian, Danai Koutra", "title": "CONE-Align: Consistent Network Alignment with Proximity-Preserving Node\n  Embedding", "comments": "In Proceedings of the 29th ACM International Conference on\n  Information and Knowledge Management (CIKM), 2020", "journal-ref": null, "doi": "10.1145/3340531.3412136", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network alignment, the process of finding correspondences between nodes in\ndifferent graphs, has many scientific and industrial applications. Existing\nunsupervised network alignment methods find suboptimal alignments that break up\nnode neighborhoods, i.e. do not preserve matched neighborhood consistency. To\nimprove this, we propose CONE-Align, which models intra-network proximity with\nnode embeddings and uses them to match nodes across networks after aligning the\nembedding subspaces. Experiments on diverse, challenging datasets show that\nCONE-Align is robust and obtains 19.25% greater accuracy on average than the\nbest-performing state-of-the-art graph alignment algorithm in highly noisy\nsettings.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 17:37:27 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 22:47:22 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Chen", "Xiyuan", ""], ["Heimann", "Mark", ""], ["Vahedian", "Fatemeh", ""], ["Koutra", "Danai", ""]]}, {"id": "2005.04726", "submitter": "Shreyansh Bhatt", "authors": "Shreyansh Bhatt, Amit Sheth, Valerie Shalin, Jinjin Zhao", "title": "Knowledge Graph semantic enhancement of input data for improving AI", "comments": null, "journal-ref": "IEEE Internet Computing, 24(2), 66-72 (2020)", "doi": "10.1109/MIC.2020.2979620", "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent systems designed using machine learning algorithms require a\nlarge number of labeled data. Background knowledge provides complementary, real\nworld factual information that can augment the limited labeled data to train a\nmachine learning algorithm. The term Knowledge Graph (KG) is in vogue as for\nmany practical applications, it is convenient and useful to organize this\nbackground knowledge in the form of a graph. Recent academic research and\nimplemented industrial intelligent systems have shown promising performance for\nmachine learning algorithms that combine training data with a knowledge graph.\nIn this article, we discuss the use of relevant KGs to enhance input data for\ntwo applications that use machine learning -- recommendation and community\ndetection. The KG improves both accuracy and explainability.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 17:37:38 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Bhatt", "Shreyansh", ""], ["Sheth", "Amit", ""], ["Shalin", "Valerie", ""], ["Zhao", "Jinjin", ""]]}, {"id": "2005.04732", "submitter": "Xiang Zhou", "authors": "Xiang Zhou, Mohit Bansal", "title": "Towards Robustifying NLI Models Against Lexical Dataset Biases", "comments": "ACL 2020 (13 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning models are making fast progress on the task of Natural\nLanguage Inference, recent studies have also shown that these models achieve\nhigh accuracy by exploiting several dataset biases, and without deep\nunderstanding of the language semantics. Using contradiction-word bias and\nword-overlapping bias as our two bias examples, this paper explores both\ndata-level and model-level debiasing methods to robustify models against\nlexical dataset biases. First, we debias the dataset through data augmentation\nand enhancement, but show that the model bias cannot be fully removed via this\nmethod. Next, we also compare two ways of directly debiasing the model without\nknowing what the dataset biases are in advance. The first approach aims to\nremove the label bias at the embedding level. The second approach employs a\nbag-of-words sub-model to capture the features that are likely to exploit the\nbias and prevents the original model from learning these biased features by\nforcing orthogonality between these two sub-models. We performed evaluations on\nnew balanced datasets extracted from the original MNLI dataset as well as the\nNLI stress tests, and show that the orthogonality approach is better at\ndebiasing the model while maintaining competitive overall accuracy. Our code\nand data are available at: https://github.com/owenzx/LexicalDebias-ACL2020\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 17:56:10 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 23:44:17 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Zhou", "Xiang", ""], ["Bansal", "Mohit", ""]]}, {"id": "2005.04755", "submitter": "Achin Jain", "authors": "Achin Jain, Matthew O'Kelly, Pratik Chaudhari, Manfred Morari", "title": "BayesRace: Learning to race autonomously using prior experience", "comments": null, "journal-ref": "4th Conference on Robot Learning (CoRL 2020)", "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous race cars require perception, estimation, planning, and control\nmodules which work together asynchronously while driving at the limit of a\nvehicle's handling capability. A fundamental challenge encountered in designing\nthese software components lies in predicting the vehicle's future state (e.g.\nposition, orientation, and speed) with high accuracy. The root cause is the\ndifficulty in identifying vehicle model parameters that capture the effects of\nlateral tire slip. We present a model-based planning and control framework for\nautonomous racing that significantly reduces the effort required in system\nidentification and control design. Our approach alleviates the gap induced by\nsimulation-based controller design by learning from on-board sensor\nmeasurements. A major focus of this work is empirical, thus, we demonstrate our\ncontributions by experiments on validated 1:43 and 1:10 scale autonomous racing\nsimulations.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 19:15:06 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 22:32:12 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Jain", "Achin", ""], ["O'Kelly", "Matthew", ""], ["Chaudhari", "Pratik", ""], ["Morari", "Manfred", ""]]}, {"id": "2005.04763", "submitter": "Tomer Koren", "authors": "Vitaly Feldman, Tomer Koren, Kunal Talwar", "title": "Private Stochastic Convex Optimization: Optimal Rates in Linear Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study differentially private (DP) algorithms for stochastic convex\noptimization: the problem of minimizing the population loss given i.i.d.\nsamples from a distribution over convex loss functions. A recent work of\nBassily et al. (2019) has established the optimal bound on the excess\npopulation loss achievable given $n$ samples. Unfortunately, their algorithm\nachieving this bound is relatively inefficient: it requires $O(\\min\\{n^{3/2},\nn^{5/2}/d\\})$ gradient computations, where $d$ is the dimension of the\noptimization problem.\n  We describe two new techniques for deriving DP convex optimization algorithms\nboth achieving the optimal bound on excess loss and using $O(\\min\\{n, n^2/d\\})$\ngradient computations. In particular, the algorithms match the running time of\nthe optimal non-private algorithms. The first approach relies on the use of\nvariable batch sizes and is analyzed using the privacy amplification by\niteration technique of Feldman et al. (2018). The second approach is based on a\ngeneral reduction to the problem of localizing an approximately optimal\nsolution with differential privacy. Such localization, in turn, can be achieved\nusing existing (non-private) uniformly stable optimization algorithms. As in\nthe earlier work, our algorithms require a mild smoothness assumption. We also\ngive a linear-time algorithm achieving the optimal bound on the excess loss for\nthe strongly convex case, as well as a faster algorithm for the non-smooth\ncase.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 19:52:03 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Feldman", "Vitaly", ""], ["Koren", "Tomer", ""], ["Talwar", "Kunal", ""]]}, {"id": "2005.04774", "submitter": "Mustafa Hajij", "authors": "Mustafa Hajij, Eyad Said, Robert Todd", "title": "PageRank and The K-Means Clustering Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We utilize the PageRank vector to generalize the $k$-means clustering\nalgorithm to directed and undirected graphs. We demonstrate that PageRank and\nother centrality measures can be used in our setting to robustly compute\ncentrality of nodes in a given graph. Furthermore, we show how our method can\nbe generalized to metric spaces and apply it to other domains such as point\nclouds and triangulated meshes\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 20:30:34 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 18:47:40 GMT"}, {"version": "v3", "created": "Tue, 9 Mar 2021 07:23:43 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Hajij", "Mustafa", ""], ["Said", "Eyad", ""], ["Todd", "Robert", ""]]}, {"id": "2005.04788", "submitter": "Ming-Chang Lee", "authors": "Ming-Chang Lee, Jia-Chun Lin, and Ernst Gunnar Gran", "title": "Distributed Fine-Grained Traffic Speed Prediction for Large-Scale\n  Transportation Networks based on Automatic LSTM Customization and Sharing", "comments": "14 pages, 7 figures, 2 tables, Euro-par 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-term traffic speed prediction has been an important research topic in\nthe past decade, and many approaches have been introduced. However, providing\nfine-grained, accurate, and efficient traffic-speed prediction for large-scale\ntransportation networks where numerous traffic detectors are deployed has not\nbeen well studied. In this paper, we propose DistPre, which is a distributed\nfine-grained traffic speed prediction scheme for large-scale transportation\nnetworks. To achieve fine-grained and accurate traffic-speed prediction,\nDistPre customizes a Long Short-Term Memory (LSTM) model with an appropriate\nhyperparameter configuration for a detector. To make such customization process\nefficient and applicable for large-scale transportation networks, DistPre\nconducts LSTM customization on a cluster of computation nodes and allows any\ntrained LSTM model to be shared between different detectors. If a detector\nobserves a similar traffic pattern to another one, DistPre directly shares the\nexisting LSTM model between the two detectors rather than customizing an LSTM\nmodel per detector. Experiments based on traffic data collected from freeway\nI5-N in California are conducted to evaluate the performance of DistPre. The\nresults demonstrate that DistPre provides time-efficient LSTM customization and\naccurate fine-grained traffic-speed prediction for large-scale transportation\nnetworks.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 21:24:23 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 13:17:42 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Lee", "Ming-Chang", ""], ["Lin", "Jia-Chun", ""], ["Gran", "Ernst Gunnar", ""]]}, {"id": "2005.04806", "submitter": "Lizhen Shi", "authors": "Lizhen Shi, Bo Chen", "title": "Comparison and Benchmark of Graph Clustering Algorithms", "comments": "32 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph clustering is widely used in analysis of biological networks, social\nnetworks and etc. For over a decade many graph clustering algorithms have been\npublished, however a comprehensive and consistent performance comparison is not\navailable. In this paper we benchmarked more than 70 graph clustering programs\nto evaluate their runtime and quality performance for both weighted and\nunweighted graphs. We also analyzed the characteristics of ground truth that\naffects the performance. Our work is capable to not only supply a start point\nfor engineers to select clustering algorithms but also could provide a\nviewpoint for researchers to design new algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 22:54:36 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Shi", "Lizhen", ""], ["Chen", "Bo", ""]]}, {"id": "2005.04809", "submitter": "Novanto Yudistira", "authors": "Novanto Yudistira", "title": "COVID-19 growth prediction using multivariate long short term memory", "comments": null, "journal-ref": "IAENG International Journal of Computer Science, vol. 47, no. 4,\n  pp829-837, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Coronavirus disease (COVID-19) spread forecasting is an important task to\ntrack the growth of the pandemic. Existing predictions are merely based on\nqualitative analyses and mathematical modeling. The use of available big data\nwith machine learning is still limited in COVID-19 growth prediction even\nthough the availability of data is abundance. To make use of big data in the\nprediction using deep learning, we use long short-term memory (LSTM) method to\nlearn the correlation of COVID-19 growth over time. The structure of an LSTM\nlayer is searched heuristically until the best validation score is achieved.\nFirst, we trained training data containing confirmed cases from around the\nglobe. We achieved favorable performance compared with that of the recurrent\nneural network (RNN) method with a comparable low validation error. The\nevaluation is conducted based on graph visualization and root mean squared\nerror (RMSE). We found that it is not easy to achieve the same quantity of\nconfirmed cases over time. However, LSTM provide a similar pattern between the\nactual cases and prediction. In the future, our proposed prediction can be used\nfor anticipating forthcoming pandemics. The code is provided here:\nhttps://github.com/cbasemaster/lstmcorona\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 23:21:19 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 04:07:36 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Yudistira", "Novanto", ""]]}, {"id": "2005.04813", "submitter": "Alessio Del Bue", "authors": "Marco Cristani, Alessio Del Bue, Vittorio Murino, Francesco Setti and\n  Alessandro Vinciarelli", "title": "The Visual Social Distancing Problem", "comments": "9 pages, 5 figures. All the authors equally contributed to this\n  manuscript and they are listed by alphabetical order. Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main and most effective measures to contain the recent viral\noutbreak is the maintenance of the so-called Social Distancing (SD). To comply\nwith this constraint, workplaces, public institutions, transports and schools\nwill likely adopt restrictions over the minimum inter-personal distance between\npeople. Given this actual scenario, it is crucial to massively measure the\ncompliance to such physical constraint in our life, in order to figure out the\nreasons of the possible breaks of such distance limitations, and understand if\nthis implies a possible threat given the scene context. All of this, complying\nwith privacy policies and making the measurement acceptable. To this end, we\nintroduce the Visual Social Distancing (VSD) problem, defined as the automatic\nestimation of the inter-personal distance from an image, and the\ncharacterization of the related people aggregations. VSD is pivotal for a\nnon-invasive analysis to whether people comply with the SD restriction, and to\nprovide statistics about the level of safety of specific areas whenever this\nconstraint is violated. We then discuss how VSD relates with previous\nliterature in Social Signal Processing and indicate which existing Computer\nVision methods can be used to manage such problem. We conclude with future\nchallenges related to the effectiveness of VSD systems, ethical implications\nand future application scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 00:04:34 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Cristani", "Marco", ""], ["Del Bue", "Alessio", ""], ["Murino", "Vittorio", ""], ["Setti", "Francesco", ""], ["Vinciarelli", "Alessandro", ""]]}, {"id": "2005.04816", "submitter": "Aditya Siddhant", "authors": "Aditya Siddhant, Ankur Bapna, Yuan Cao, Orhan Firat, Mia Chen, Sneha\n  Kudugunta, Naveen Arivazhagan and Yonghui Wu", "title": "Leveraging Monolingual Data with Self-Supervision for Multilingual\n  Neural Machine Translation", "comments": null, "journal-ref": "ACL 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few years two promising research directions in low-resource\nneural machine translation (NMT) have emerged. The first focuses on utilizing\nhigh-resource languages to improve the quality of low-resource languages via\nmultilingual NMT. The second direction employs monolingual data with\nself-supervision to pre-train translation models, followed by fine-tuning on\nsmall amounts of supervised data. In this work, we join these two lines of\nresearch and demonstrate the efficacy of monolingual data with self-supervision\nin multilingual NMT. We offer three major results: (i) Using monolingual data\nsignificantly boosts the translation quality of low-resource languages in\nmultilingual models. (ii) Self-supervision improves zero-shot translation\nquality in multilingual models. (iii) Leveraging monolingual data with\nself-supervision provides a viable path towards adding new languages to\nmultilingual models, getting up to 33 BLEU on ro-en translation without any\nparallel data or back-translation.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 00:20:33 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Siddhant", "Aditya", ""], ["Bapna", "Ankur", ""], ["Cao", "Yuan", ""], ["Firat", "Orhan", ""], ["Chen", "Mia", ""], ["Kudugunta", "Sneha", ""], ["Arivazhagan", "Naveen", ""], ["Wu", "Yonghui", ""]]}, {"id": "2005.04828", "submitter": "Joel Stremmel", "authors": "Joel Stremmel and Arjun Singh", "title": "Pretraining Federated Text Models for Next Word Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a decentralized approach for training models on\ndistributed devices, by summarizing local changes and sending aggregate\nparameters from local models to the cloud rather than the data itself. In this\nresearch we employ the idea of transfer learning to federated training for next\nword prediction (NWP) and conduct a number of experiments demonstrating\nenhancements to current baselines for which federated NWP models have been\nsuccessful. Specifically, we compare federated training baselines from randomly\ninitialized models to various combinations of pretraining approaches including\npretrained word embeddings and whole model pretraining followed by federated\nfine tuning for NWP on a dataset of Stack Overflow posts. We realize lift in\nperformance using pretrained embeddings without exacerbating the number of\nrequired training rounds or memory footprint. We also observe notable\ndifferences using centrally pretrained networks, especially depending on the\ndatasets used. Our research offers effective, yet inexpensive, improvements to\nfederated NWP and paves the way for more rigorous experimentation of transfer\nlearning techniques for federated learning.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 01:48:50 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 03:33:13 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 21:51:46 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Stremmel", "Joel", ""], ["Singh", "Arjun", ""]]}, {"id": "2005.04830", "submitter": "Xenofon Vasilakos", "authors": "Xenofon Vasilakos, Navid Nikaein, Dean H Lorenz, Berkay Koksal, Nasim\n  Ferdosian", "title": "Integrated Methodology to Cognitive Network Slice Management in\n  Virtualized 5G Networks", "comments": "22 pages, 4 figures, 5 author bios and photos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fifth Generation (5G) networks are envisioned to be fully autonomous in\naccordance to the ETSI-defined Zero touch network and Service Management (ZSM)\nconcept. To this end, purpose-specific Machine Learning (ML) models can be used\nto manage and control physical as well as virtual network resources in a way\nthat is fully compliant to slice Service Level Agreements (SLAs), while also\nboosting the revenue of the underlying physical network operator(s). This is\nbecause specially designed and trained ML models can be both proactive and very\neffective against slice management issues that can induce significant SLA\npenalties or runtime costs. However, reaching that point is very challenging.\n5G networks will be highly dynamic and complex, offering a large scale of\nheterogeneous, sophisticated and resource-demanding 5G services as network\nslices. This raises a need for a well-defined, generic and step-wise roadmap to\ndesigning, building and deploying efficient ML models as collaborative\ncomponents of what can be defined as Cognitive Network and Slice Management\n(CNSM) 5G systems. To address this need, we take a use case-driven approach to\ndesign and present a novel Integrated Methodology for CNSM in virtualized 5G\nnetworks based on a concrete eHealth use case, and elaborate on it to derive a\ngeneric approach for 5G slice management use cases. The three fundamental\ncomponents that comprise our proposed methodology include (i) a 5G Cognitive\nWorkflow model that conditions everything from the design up to the final\ndeployment of ML models; (ii) a Four-stage approach to Cognitive Slice\nManagement with an emphasis on anomaly detection; and (iii) a Proactive Control\nScheme for the collaboration of different ML models targeting different slice\nlife-cycle management problems.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 01:51:47 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Vasilakos", "Xenofon", ""], ["Nikaein", "Navid", ""], ["Lorenz", "Dean H", ""], ["Koksal", "Berkay", ""], ["Ferdosian", "Nasim", ""]]}, {"id": "2005.04832", "submitter": "Shubhanshu Shekhar", "authors": "Shubhanshu Shekhar, Tara Javidi", "title": "Multi-Scale Zero-Order Optimization of Smooth Functions in an RKHS", "comments": "20 pages, 2 figures. Preliminary version -- feedback welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to optimize a black-box function $f:\\mathcal{X} \\mapsto \\mathbb{R}$\nunder the assumption that $f$ is H\\\"older smooth and has bounded norm in the\nRKHS associated with a given kernel $K$. This problem is known to have an\nagnostic Gaussian Process (GP) bandit interpretation in which an appropriately\nconstructed GP surrogate model with kernel $K$ is used to obtain an upper\nconfidence bound (UCB) algorithm. In this paper, we propose a new algorithm\n(\\texttt{LP-GP-UCB}) where the usual GP surrogate model is augmented with Local\nPolynomial (LP) estimators of the H\\\"older smooth function $f$ to construct a\nmulti-scale UCB guiding the search for the optimizer. We analyze this algorithm\nand derive high probability bounds on its simple and cumulative regret. We then\nprove that the elements of many common RKHS are H\\\"older smooth and obtain the\ncorresponding H\\\"older smoothness parameters, and hence, specialize our regret\nbounds for several commonly used kernels. When specialized to the Squared\nExponential (SE) kernel, \\texttt{LP-GP-UCB} matches the optimal performance,\nwhile for the case of Mat\\'ern kernels $(K_{\\nu})_{\\nu>0}$, it results in\nuniformly tighter regret bounds for all values of the smoothness parameter\n$\\nu>0$. Most notably, for certain ranges of $\\nu$, the algorithm achieves\nnear-optimal bounds on simple and cumulative regrets, matching the\nalgorithm-independent lower bounds up to polylog factors, and thus closing the\nlarge gap between the existing upper and lower bounds for these values of\n$\\nu$. Additionally, our analysis provides the first explicit regret bounds, in\nterms of the budget $n$, for the Rational-Quadratic (RQ) and Gamma-Exponential\n(GE). Finally, experiments with synthetic functions as well as a CNN\nhyperparameter tuning task demonstrate the practical benefits of our\nmulti-scale partitioning approach over some existing algorithms numerically.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 01:55:39 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Shekhar", "Shubhanshu", ""], ["Javidi", "Tara", ""]]}, {"id": "2005.04833", "submitter": "Richard Oentaryo", "authors": "Roy Ka-Wei Lee, Thong Hoang, Richard J. Oentaryo, David Lo", "title": "Keen2Act: Activity Recommendation in Online Social Collaborative\n  Platforms", "comments": "ACM Conference on User Modeling, Adaptation and Personalization", "journal-ref": null, "doi": "10.1145/3340631.3394884", "report-no": null, "categories": "cs.IR cs.LG cs.SE cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social collaborative platforms such as GitHub and Stack Overflow have been\nincreasingly used to improve work productivity via collaborative efforts. To\nimprove user experiences in these platforms, it is desirable to have a\nrecommender system that can suggest not only items (e.g., a GitHub repository)\nto a user, but also activities to be performed on the suggested items (e.g.,\nforking a repository). To this end, we propose a new approach dubbed Keen2Act,\nwhich decomposes the recommendation problem into two stages: the Keen and Act\nsteps. The Keen step identifies, for a given user, a (sub)set of items in which\nhe/she is likely to be interested. The Act step then recommends to the user\nwhich activities to perform on the identified set of items. This decomposition\nprovides a practical approach to tackling complex activity recommendation tasks\nwhile producing higher recommendation quality. We evaluate our proposed\napproach using two real-world datasets and obtain promising results whereby\nKeen2Act outperforms several baseline models.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 02:00:52 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Lee", "Roy Ka-Wei", ""], ["Hoang", "Thong", ""], ["Oentaryo", "Richard J.", ""], ["Lo", "David", ""]]}, {"id": "2005.04834", "submitter": "Jean Feng", "authors": "Jean Feng and Noah Simon", "title": "Ensembled sparse-input hierarchical networks for high-dimensional\n  datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have seen limited use in prediction for high-dimensional data\nwith small sample sizes, because they tend to overfit and require tuning many\nmore hyperparameters than existing off-the-shelf machine learning methods. With\nsmall modifications to the network architecture and training procedure, we show\nthat dense neural networks can be a practical data analysis tool in these\nsettings. The proposed method, Ensemble by Averaging Sparse-Input Hierarchical\nnetworks (EASIER-net), appropriately prunes the network structure by tuning\nonly two L1-penalty parameters, one that controls the input sparsity and\nanother that controls the number of hidden layers and nodes. The method selects\nvariables from the true support if the irrelevant covariates are only weakly\ncorrelated with the response; otherwise, it exhibits a grouping effect, where\nstrongly correlated covariates are selected at similar rates. On a collection\nof real-world datasets with different sizes, EASIER-net selected network\narchitectures in a data-adaptive manner and achieved higher prediction accuracy\nthan off-the-shelf methods on average.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 02:08:53 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Feng", "Jean", ""], ["Simon", "Noah", ""]]}, {"id": "2005.04843", "submitter": "Chaoqi Yang", "authors": "Chaoqi Yang, Ruijie Wang, Shuochao Yao, Tarek Abdelzaher", "title": "Hypergraph Learning with Line Expansion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous hypergraph expansions are solely carried out on either vertex level\nor hyperedge level, thereby missing the symmetric nature of data co-occurrence,\nand resulting in information loss. To address the problem, this paper treats\nvertices and hyperedges equally and proposes a new hypergraph formulation named\nthe \\emph{line expansion (LE)} for hypergraphs learning. The new expansion\nbijectively induces a homogeneous structure from the hypergraph by treating\nvertex-hyperedge pairs as \"line nodes\". By reducing the hypergraph to a simple\ngraph, the proposed \\emph{line expansion} makes existing graph learning\nalgorithms compatible with the higher-order structure and has been proven as a\nunifying framework for various hypergraph expansions. We evaluate the proposed\nline expansion on five hypergraph datasets, the results show that our method\nbeats SOTA baselines by a significant margin.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 03:02:21 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 00:38:09 GMT"}, {"version": "v3", "created": "Sat, 16 May 2020 22:25:51 GMT"}, {"version": "v4", "created": "Sun, 24 May 2020 03:22:05 GMT"}, {"version": "v5", "created": "Tue, 8 Sep 2020 20:45:47 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Yang", "Chaoqi", ""], ["Wang", "Ruijie", ""], ["Yao", "Shuochao", ""], ["Abdelzaher", "Tarek", ""]]}, {"id": "2005.04849", "submitter": "Pipi Hu", "authors": "Pipi Hu, Wuyue Yang, Yi Zhu, Liu Hong", "title": "Revealing hidden dynamics from time-series data by ODENet", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.LG cs.NA math.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To derive the hidden dynamics from observed data is one of the fundamental\nbut also challenging problems in many different fields. In this study, we\npropose a new type of interpretable network called the ordinary differential\nequation network (ODENet), in which the numerical integration of explicit\nordinary differential equations (ODEs) are embedded into the machine learning\nscheme to build a general framework for revealing the hidden dynamics buried in\nmassive time-series data efficiently and reliably. ODENet takes full advantage\nof both machine learning algorithms and ODE modeling. On one hand, the\nembedding of ODEs makes the framework more interpretable benefiting from the\nmature theories of ODEs. On the other hand, the schemes of machine learning\nenable data handling, paralleling, and optimization to be easily and\nefficiently implemented. From classical Lotka-Volterra equations to chaotic\nLorenz equations, the ODENet exhibits its remarkable capability in handling\ntime-series data even in the presence of large noise. We further apply the\nODENet to real actin aggregation data, which shows an impressive performance as\nwell. These results demonstrate the superiority of ODENet in dealing with noisy\ndata, data with either non-equal spacing or large sampling time steps over\nother traditional machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 03:45:22 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 03:59:24 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Hu", "Pipi", ""], ["Yang", "Wuyue", ""], ["Zhu", "Yi", ""], ["Hong", "Liu", ""]]}, {"id": "2005.04871", "submitter": "Lu Wang", "authors": "Lu Wang, Huan Zhang, Jinfeng Yi, Cho-Jui Hsieh, Yuan Jiang", "title": "Spanning Attack: Reinforce Black-box Attacks with Unlabeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial black-box attacks aim to craft adversarial perturbations by\nquerying input-output pairs of machine learning models. They are widely used to\nevaluate the robustness of pre-trained models. However, black-box attacks often\nsuffer from the issue of query inefficiency due to the high dimensionality of\nthe input space, and therefore incur a false sense of model robustness. In this\npaper, we relax the conditions of the black-box threat model, and propose a\nnovel technique called the spanning attack. By constraining adversarial\nperturbations in a low-dimensional subspace via spanning an auxiliary unlabeled\ndataset, the spanning attack significantly improves the query efficiency of a\nwide variety of existing black-box attacks. Extensive experiments show that the\nproposed method works favorably in both soft-label and hard-label black-box\nattacks. Our code is available at https://github.com/wangwllu/spanning_attack.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 05:57:15 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 03:54:26 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Wang", "Lu", ""], ["Zhang", "Huan", ""], ["Yi", "Jinfeng", ""], ["Hsieh", "Cho-Jui", ""], ["Jiang", "Yuan", ""]]}, {"id": "2005.04876", "submitter": "Abhishek Niranjan", "authors": "Abhishek Niranjan, M Ali Basha Shaik, Kushal Verma", "title": "Hierarchical Attention Transformer Architecture For Syntactic Spell\n  Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The attention mechanisms are playing a boosting role in advancements in\nsequence-to-sequence problems. Transformer architecture achieved new state of\nthe art results in machine translation, and it's variants are since being\nintroduced in several other sequence-to-sequence problems. Problems which\ninvolve a shared vocabulary, can benefit from the similar semantic and\nsyntactic structure in the source and target sentences. With the motivation of\nbuilding a reliable and fast post-processing textual module to assist all the\ntext-related use cases in mobile phones, we take on the popular spell\ncorrection problem. In this paper, we propose multi encoder-single decoder\nvariation of conventional transformer. Outputs from the three encoders with\ncharacter level 1-gram, 2-grams and 3-grams inputs are attended in hierarchical\nfashion in the decoder. The context vectors from the encoders clubbed with\nself-attention amplify the n-gram properties at the character level and helps\nin accurate decoding. We demonstrate our model on spell correction dataset from\nSamsung Research, and report significant improvement of 0.11\\%, 0.32\\% and\n0.69\\% in character (CER), word (WER) and sentence (SER) error rates from\nexisting state-of-the-art machine-translation architectures. Our architecture\nis also trains ~7.8 times faster, and is only about 1/3 in size from the next\nmost accurate model.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 06:19:01 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Niranjan", "Abhishek", ""], ["Shaik", "M Ali Basha", ""], ["Verma", "Kushal", ""]]}, {"id": "2005.04879", "submitter": "Ming Bo Cai", "authors": "Ming Bo Cai, Michael Shvartsman, Anqi Wu, Hejia Zhang, Xia Zhu", "title": "Incorporating structured assumptions with probabilistic graphical models\n  in fMRI data analysis", "comments": "update with the version accepted by Neuropsychologia", "journal-ref": "Neuropsychologia, 107500 (2020)", "doi": "10.1016/j.neuropsychologia.2020.107500", "report-no": null, "categories": "stat.AP cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the wide adoption of functional magnetic resonance imaging (fMRI) by\ncognitive neuroscience researchers, large volumes of brain imaging data have\nbeen accumulated in recent years. Aggregating these data to derive scientific\ninsights often faces the challenge that fMRI data are high-dimensional,\nheterogeneous across people, and noisy. These challenges demand the development\nof computational tools that are tailored both for the neuroscience questions\nand for the properties of the data. We review a few recently developed\nalgorithms in various domains of fMRI research: fMRI in naturalistic tasks,\nanalyzing full-brain functional connectivity, pattern classification, inferring\nrepresentational similarity and modeling structured residuals. These algorithms\nall tackle the challenges in fMRI similarly: they start by making clear\nstatements of assumptions about neural data and existing domain knowledge,\nincorporating those assumptions and domain knowledge into probabilistic\ngraphical models, and using those models to estimate properties of interest or\nlatent structures in the data. Such approaches can avoid erroneous findings,\nreduce the impact of noise, better utilize known properties of the data, and\nbetter aggregate data across groups of subjects. With these successful cases,\nwe advocate wider adoption of explicit model construction in cognitive\nneuroscience. Although we focus on fMRI, the principle illustrated here is\ngenerally applicable to brain data of other modalities.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 06:32:54 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 00:44:14 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Cai", "Ming Bo", ""], ["Shvartsman", "Michael", ""], ["Wu", "Anqi", ""], ["Zhang", "Hejia", ""], ["Zhu", "Xia", ""]]}, {"id": "2005.04888", "submitter": "Zixiao Shen", "authors": "Zixiao Shen, Xin Chen, Jonathan M. Garibaldi", "title": "Performance Optimization of a Fuzzy Entropy based Feature Selection and\n  Classification Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, based on a fuzzy entropy feature selection framework,\ndifferent methods have been implemented and compared to improve the key\ncomponents of the framework. Those methods include the combinations of three\nideal vector calculations, three maximal similarity classifiers and three fuzzy\nentropy functions. Different feature removal orders based on the fuzzy entropy\nvalues were also compared. The proposed method was evaluated on three publicly\navailable biomedical datasets. From the experiments, we concluded the optimized\ncombination of the ideal vector, similarity classifier and fuzzy entropy\nfunction for feature selection. The optimized framework was also compared with\nother six classical filter-based feature selection methods. The proposed method\nwas ranked as one of the top performers together with the Correlation and\nReliefF methods. More importantly, the proposed method achieved the most stable\nperformance for all three datasets when the features being gradually removed.\nThis indicates a better feature ranking performance than the other compared\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 07:16:50 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 05:49:24 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Shen", "Zixiao", ""], ["Chen", "Xin", ""], ["Garibaldi", "Jonathan M.", ""]]}, {"id": "2005.04912", "submitter": "Yash Satsangi", "authors": "Yash Satsangi, Sungsu Lim, Shimon Whiteson, Frans Oliehoek, Martha\n  White", "title": "Maximizing Information Gain in Partially Observable Environments via\n  Prediction Reward", "comments": null, "journal-ref": "AAMAS 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information gathering in a partially observable environment can be formulated\nas a reinforcement learning (RL), problem where the reward depends on the\nagent's uncertainty. For example, the reward can be the negative entropy of the\nagent's belief over an unknown (or hidden) variable. Typically, the rewards of\nan RL agent are defined as a function of the state-action pairs and not as a\nfunction of the belief of the agent; this hinders the direct application of\ndeep RL methods for such tasks. This paper tackles the challenge of using\nbelief-based rewards for a deep RL agent, by offering a simple insight that\nmaximizing any convex function of the belief of the agent can be approximated\nby instead maximizing a prediction reward: a reward based on prediction\naccuracy. In particular, we derive the exact error between negative entropy and\nthe expected prediction reward. This insight provides theoretical motivation\nfor several fields using prediction rewards---namely visual attention, question\nanswering systems, and intrinsic motivation---and highlights their connection\nto the usually distinct fields of active perception, active sensing, and sensor\nplacement. Based on this insight we present deep anticipatory networks (DANs),\nwhich enables an agent to take actions to reduce its uncertainty without\nperforming explicit belief inference. We present two applications of DANs:\nbuilding a sensor selection system for tracking people in a shopping mall and\nlearning discrete models of attention on fashion MNIST and MNIST digit\nclassification.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 08:13:49 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Satsangi", "Yash", ""], ["Lim", "Sungsu", ""], ["Whiteson", "Shimon", ""], ["Oliehoek", "Frans", ""], ["White", "Martha", ""]]}, {"id": "2005.04917", "submitter": "Heikki Arponen Dr", "authors": "Heikki Arponen and Tom E. Bishop", "title": "Learning to hash with semantic similarity metrics and empirical KL\n  divergence", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to hash is an efficient paradigm for exact and approximate nearest\nneighbor search from massive databases. Binary hash codes are typically\nextracted from an image by rounding output features from a CNN, which is\ntrained on a supervised binary similar/ dissimilar task. Drawbacks of this\napproach are: (i) resulting codes do not necessarily capture semantic\nsimilarity of the input data (ii) rounding results in information loss,\nmanifesting as decreased retrieval performance and (iii) Using only class-wise\nsimilarity as a target can lead to trivial solutions, simply encoding\nclassifier outputs rather than learning more intricate relations, which is not\ndetected by most performance metrics. We overcome (i) via a novel loss function\nencouraging the relative hash code distances of learned features to match those\nderived from their targets. We address (ii) via a differentiable estimate of\nthe KL divergence between network outputs and a binary target distribution,\nresulting in minimal information loss when the features are rounded to binary.\nFinally, we resolve (iii) by focusing on a hierarchical precision metric.\nEfficiency of the methods is demonstrated with semantic image retrieval on the\nCIFAR-100, ImageNet and Conceptual Captions datasets, using similarities\ninferred from the WordNet label hierarchy or sentence embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 08:20:26 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Arponen", "Heikki", ""], ["Bishop", "Tom E.", ""]]}, {"id": "2005.04938", "submitter": "Tanik Saikh Mr", "authors": "Tanik Saikh, Arkadipta De, Asif Ekbal, Pushpak Bhattacharyya", "title": "A Deep Learning Approach for Automatic Detection of Fake News", "comments": null, "journal-ref": "Proceedings of the 16th International Conference on Natural\n  Language Processing (ICON 2019)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Fake news detection is a very prominent and essential task in the field of\njournalism. This challenging problem is seen so far in the field of politics,\nbut it could be even more challenging when it is to be determined in the\nmulti-domain platform. In this paper, we propose two effective models based on\ndeep learning for solving fake news detection problem in online news contents\nof multiple domains. We evaluate our techniques on the two recently released\ndatasets, namely FakeNews AMT and Celebrity for fake news detection. The\nproposed systems yield encouraging performance, outperforming the current\nhandcrafted feature engineering based state-of-the-art system with a\nsignificant margin of 3.08% and 9.3% by the two models, respectively. In order\nto exploit the datasets, available for the related tasks, we perform\ncross-domain analysis (i.e. model trained on FakeNews AMT and tested on\nCelebrity and vice versa) to explore the applicability of our systems across\nthe domains.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 09:07:46 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Saikh", "Tanik", ""], ["De", "Arkadipta", ""], ["Ekbal", "Asif", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "2005.04949", "submitter": "Evgeni Aizenberg", "authors": "Evgeni Aizenberg and Jeroen van den Hoven", "title": "Designing for Human Rights in AI", "comments": "30 pages, 2 figures, pre-print of the paper accepted for publication\n  in the journal Big Data & Society", "journal-ref": "Big Data & Society 7(2) (2020)", "doi": "10.1177/2053951720949566", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the age of big data, companies and governments are increasingly using\nalgorithms to inform hiring decisions, employee management, policing, credit\nscoring, insurance pricing, and many more aspects of our lives. AI systems can\nhelp us make evidence-driven, efficient decisions, but can also confront us\nwith unjustified, discriminatory decisions wrongly assumed to be accurate\nbecause they are made automatically and quantitatively. It is becoming evident\nthat these technological developments are consequential to people's fundamental\nhuman rights. Despite increasing attention to these urgent challenges in recent\nyears, technical solutions to these complex socio-ethical problems are often\ndeveloped without empirical study of societal context and the critical input of\nsocietal stakeholders who are impacted by the technology. On the other hand,\ncalls for more ethically- and socially-aware AI often fail to provide answers\nfor how to proceed beyond stressing the importance of transparency,\nexplainability, and fairness. Bridging these socio-technical gaps and the deep\ndivide between abstract value language and design requirements is essential to\nfacilitate nuanced, context-dependent design choices that will support moral\nand social values. In this paper, we bridge this divide through the framework\nof Design for Values, drawing on methodologies of Value Sensitive Design and\nParticipatory Design to present a roadmap for proactively engaging societal\nstakeholders to translate fundamental human rights into context-dependent\ndesign requirements through a structured, inclusive, and transparent process.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 09:21:10 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 17:00:46 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Aizenberg", "Evgeni", ""], ["Hoven", "Jeroen van den", ""]]}, {"id": "2005.04954", "submitter": "Tatsuya Hayashi", "authors": "Tatsuya Hayashi and Atsuyoshi Nakamura", "title": "Propagation Graph Estimation by Pairwise Alignment of Time Series\n  Observation Sequences", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various things propagate through the medium of individuals. Some biological\ncells fire right after the firing of their neighbor cells, and such firing\npropagates from cells to cells. In this paper, we study the problem of\nestimating the firing propagation order of cells from the $\\{0,1 \\}$-state\nsequences of all the cells, where '1' at the $i$-th position means the firing\nstate of the cell at time step $i$. We propose a method to estimate the\npropagation direction between cells by the sum of one cell's time delay of the\nmatched positions from the other cell averaged over the minimum cost alignments\nand show how to calculate it efficiently. The propagation order estimated by\nour proposed method is demonstrated to be correct for our synthetic datasets,\nand also to be consistent with visually recognizable firing order for the\ndataset of soil-dwelling amoeba's chemical signal emitting state sequences.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 09:31:44 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Hayashi", "Tatsuya", ""], ["Nakamura", "Atsuyoshi", ""]]}, {"id": "2005.04955", "submitter": "Jiexia Ye", "authors": "Jiexia Ye and Juanjuan Zhao and Kejiang Ye and Chengzhong Xu", "title": "Multi-Graph Convolutional Network for Relationship-Driven Stock Movement\n  Prediction", "comments": "8pages, 4figures", "journal-ref": "2020 25th International Conference on Pattern Recognition (ICPR)", "doi": "10.1109/ICPR48806.2021.9412695", "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stock price movement prediction is commonly accepted as a very challenging\ntask due to the volatile nature of financial markets. Previous works typically\npredict the stock price mainly based on its own information, neglecting the\ncross effect among involved stocks. However, it is well known that an\nindividual stock price is correlated with prices of other stocks in complex\nways. To take the cross effect into consideration, we propose a deep learning\nframework, called Multi-GCGRU, which comprises graph convolutional network\n(GCN) and gated recurrent unit (GRU) to predict stock movement. Specifically,\nwe first encode multiple relationships among stocks into graphs based on\nfinancial domain knowledge and utilize GCN to extract the cross effect based on\nthese pre-defined graphs. To further get rid of prior knowledge, we explore an\nadaptive relationship learned by data automatically. The cross-correlation\nfeatures produced by GCN are concatenated with historical records and then fed\ninto GRU to model the temporal dependency of stock prices. Experiments on two\nstock indexes in China market show that our model outperforms other baselines.\nNote that our model is rather feasible to incorporate more effective stock\nrelationships containing expert knowledge, as well as learn data-driven\nrelationship.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 09:31:44 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 03:45:40 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 07:08:45 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Ye", "Jiexia", ""], ["Zhao", "Juanjuan", ""], ["Ye", "Kejiang", ""], ["Xu", "Chengzhong", ""]]}, {"id": "2005.04966", "submitter": "Junnan Li Dr", "authors": "Junnan Li, Pan Zhou, Caiming Xiong, Steven C.H. Hoi", "title": "Prototypical Contrastive Learning of Unsupervised Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Prototypical Contrastive Learning (PCL), an unsupervised\nrepresentation learning method that addresses the fundamental limitations of\ninstance-wise contrastive learning. PCL not only learns low-level features for\nthe task of instance discrimination, but more importantly, it implicitly\nencodes semantic structures of the data into the learned embedding space.\nSpecifically, we introduce prototypes as latent variables to help find the\nmaximum-likelihood estimation of the network parameters in an\nExpectation-Maximization framework. We iteratively perform E-step as finding\nthe distribution of prototypes via clustering and M-step as optimizing the\nnetwork via contrastive learning. We propose ProtoNCE loss, a generalized\nversion of the InfoNCE loss for contrastive learning, which encourages\nrepresentations to be closer to their assigned prototypes. PCL outperforms\nstate-of-the-art instance-wise contrastive learning methods on multiple\nbenchmarks with substantial improvement in low-resource transfer learning. Code\nand pretrained models are available at https://github.com/salesforce/PCL.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 09:53:36 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 14:33:55 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 02:18:41 GMT"}, {"version": "v4", "created": "Tue, 28 Jul 2020 03:03:28 GMT"}, {"version": "v5", "created": "Tue, 30 Mar 2021 04:07:54 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Li", "Junnan", ""], ["Zhou", "Pan", ""], ["Xiong", "Caiming", ""], ["Hoi", "Steven C. H.", ""]]}, {"id": "2005.04968", "submitter": "John Wilhelm", "authors": "Sebastian M\\\"uksch, Theo Olausson, John Wilhelm, Pavlos Andreadis", "title": "Quantitative Analysis of Image Classification Techniques for\n  Memory-Constrained Devices", "comments": "9 pages, 4 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks, or CNNs, are the state of the art for image\nclassification, but typically come at the cost of a large memory footprint.\nThis limits their usefulness in applications relying on embedded devices, where\nmemory is often a scarce resource. Recently, there has been significant\nprogress in the field of image classification on such memory-constrained\ndevices, with novel contributions like the ProtoNN, Bonsai and FastGRNN\nalgorithms. These have been shown to reach up to 98.2% accuracy on optical\ncharacter recognition using MNIST-10, with a memory footprint as little as 6KB.\nHowever, their potential on more complex multi-class and multi-channel image\nclassification has yet to be determined. In this paper, we compare CNNs with\nProtoNN, Bonsai and FastGRNN when applied to 3-channel image classification\nusing CIFAR-10. For our analysis, we use the existing Direct Convolution\nalgorithm to implement the CNNs memory-optimally and propose new methods of\nadjusting the FastGRNN model to work with multi-channel images. We extend the\nevaluation of each algorithm to a memory size budget of 8KB, 16KB, 32KB, 64KB\nand 128KB to show quantitatively that Direct Convolution CNNs perform best for\nall chosen budgets, with a top performance of 65.7% accuracy at a memory\nfootprint of 58.23KB.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 09:54:54 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 16:47:50 GMT"}, {"version": "v3", "created": "Sat, 19 Sep 2020 19:53:27 GMT"}, {"version": "v4", "created": "Sun, 15 Nov 2020 15:36:42 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["M\u00fcksch", "Sebastian", ""], ["Olausson", "Theo", ""], ["Wilhelm", "John", ""], ["Andreadis", "Pavlos", ""]]}, {"id": "2005.04974", "submitter": "Fernando Navarro", "authors": "Fernando Navarro, Anjany Sekuboyina, Diana Waldmannstetter, Jan C.\n  Peeken, Stephanie E. Combs and Bjoern H. Menze", "title": "Deep Reinforcement Learning for Organ Localization in CT", "comments": "Accepted paper in MIDL 2020", "journal-ref": "https://openreview.net/forum?id=0vDeD2UD0S&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DMIDL.io%2F2020%2FConference%2FAuthors%23your-submissions)", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust localization of organs in computed tomography scans is a constant\npre-processing requirement for organ-specific image retrieval, radiotherapy\nplanning, and interventional image analysis. In contrast to current solutions\nbased on exhaustive search or region proposals, which require large amounts of\nannotated data, we propose a deep reinforcement learning approach for organ\nlocalization in CT. In this work, an artificial agent is actively self-taught\nto localize organs in CT by learning from its asserts and mistakes. Within the\ncontext of reinforcement learning, we propose a novel set of actions tailored\nfor organ localization in CT. Our method can use as a plug-and-play module for\nlocalizing any organ of interest. We evaluate the proposed solution on the\npublic VISCERAL dataset containing CT scans with varying fields of view and\nmultiple organs. We achieved an overall intersection over union of 0.63, an\nabsolute median wall distance of 2.25 mm, and a median distance between\ncentroids of 3.65 mm.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 10:06:13 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Navarro", "Fernando", ""], ["Sekuboyina", "Anjany", ""], ["Waldmannstetter", "Diana", ""], ["Peeken", "Jan C.", ""], ["Combs", "Stephanie E.", ""], ["Menze", "Bjoern H.", ""]]}, {"id": "2005.04975", "submitter": "Xinwang Liu", "authors": "Xinwang Liu, En Zhu, Jiyuan Liu, Timothy Hospedales, Yang Wang, Meng\n  Wang", "title": "SimpleMKKM: Simple Multiple Kernel K-means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple yet effective multiple kernel clustering algorithm,\ntermed simple multiple kernel k-means (SimpleMKKM). It extends the widely used\nsupervised kernel alignment criterion to multi-kernel clustering. Our criterion\nis given by an intractable minimization-maximization problem in the kernel\ncoefficient and clustering partition matrix. To optimize it, we re-formulate\nthe problem as a smooth minimization one, which can be solved efficiently using\na reduced gradient descent algorithm. We theoretically analyze the performance\nof SimpleMKKM in terms of its clustering generalization error. Comprehensive\nexperiments on 11 benchmark datasets demonstrate that SimpleMKKM outperforms\nstate of the art multi-kernel clustering alternatives.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 10:06:40 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 14:05:04 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Liu", "Xinwang", ""], ["Zhu", "En", ""], ["Liu", "Jiyuan", ""], ["Hospedales", "Timothy", ""], ["Wang", "Yang", ""], ["Wang", "Meng", ""]]}, {"id": "2005.04986", "submitter": "Yunjin Tong", "authors": "Yunjin Tong, Shiying Xiong, Xingzhe He, Guanghan Pan, Bo Zhu", "title": "Symplectic Neural Networks in Taylor Series Form for Hamiltonian Systems", "comments": null, "journal-ref": "Journal of Computational Physics, p.110325 (2021)", "doi": "10.1016/j.jcp.2021.110325", "report-no": null, "categories": "cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an effective and lightweight learning algorithm, Symplectic Taylor\nNeural Networks (Taylor-nets), to conduct continuous, long-term predictions of\na complex Hamiltonian dynamic system based on sparse, short-term observations.\nAt the heart of our algorithm is a novel neural network architecture consisting\nof two sub-networks. Both are embedded with terms in the form of Taylor series\nexpansion designed with symmetric structure. The key mechanism underpinning our\ninfrastructure is the strong expressiveness and special symmetric property of\nthe Taylor series expansion, which naturally accommodate the numerical fitting\nprocess of the gradients of the Hamiltonian with respect to the generalized\ncoordinates as well as preserve its symplectic structure. We further\nincorporate a fourth-order symplectic integrator in conjunction with neural\nODEs' framework into our Taylor-net architecture to learn the continuous-time\nevolution of the target systems while simultaneously preserving their\nsymplectic structures. We demonstrated the efficacy of our Taylor-net in\npredicting a broad spectrum of Hamiltonian dynamic systems, including the\npendulum, the Lotka--Volterra, the Kepler, and the H\\'enon--Heiles systems. Our\nmodel exhibits unique computational merits by outperforming previous methods to\na great extent regarding the prediction accuracy, the convergence rate, and the\nrobustness despite using extremely small training data with a short training\nperiod (6000 times shorter than the predicting period), small sample sizes, and\nno intermediate data to train the networks.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 10:32:29 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 05:10:17 GMT"}, {"version": "v3", "created": "Thu, 8 Apr 2021 18:49:23 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Tong", "Yunjin", ""], ["Xiong", "Shiying", ""], ["He", "Xingzhe", ""], ["Pan", "Guanghan", ""], ["Zhu", "Bo", ""]]}, {"id": "2005.04987", "submitter": "Daniele Silvestro", "authors": "Daniele Silvestro and Tobias Andermann", "title": "Prior choice affects ability of Bayesian neural networks to identify\n  unknowns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Bayesian neural networks (BNNs) are a powerful tool, though\ncomputationally demanding, to perform parameter estimation while jointly\nestimating uncertainty around predictions. BNNs are typically implemented using\narbitrary normal-distributed prior distributions on the model parameters. Here,\nwe explore the effects of different prior distributions on classification tasks\nin BNNs and evaluate the evidence supporting the predictions based on posterior\nprobabilities approximated by Markov Chain Monte Carlo sampling and by\ncomputing Bayes factors. We show that the choice of priors has a substantial\nimpact on the ability of the model to confidently assign data to the correct\nclass (true positive rates). Prior choice also affects significantly the\nability of a BNN to identify out-of-distribution instances as unknown (false\npositive rates). When comparing our results against neural networks (NN) with\nMonte Carlo dropout we found that BNNs generally outperform NNs. Finally, in\nour tests we did not find a single best choice as prior distribution. Instead,\neach dataset yielded the best results under a different prior, indicating that\ntesting alternative options can improve the performance of BNNs.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 10:32:47 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Silvestro", "Daniele", ""], ["Andermann", "Tobias", ""]]}, {"id": "2005.04988", "submitter": "Rachel Prudden", "authors": "Rachel Prudden, Samantha Adams, Dmitry Kangin, Niall Robinson, Suman\n  Ravuri, Shakir Mohamed, Alberto Arribas", "title": "A review of radar-based nowcasting of precipitation and applicable\n  machine learning techniques", "comments": "17 pages This work has been submitted to Monthly Weather Review.\n  Copyright in this work may be transferred without further notice", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A 'nowcast' is a type of weather forecast which makes predictions in the very\nshort term, typically less than two hours - a period in which traditional\nnumerical weather prediction can be limited. This type of weather prediction\nhas important applications for commercial aviation; public and outdoor events;\nand the construction industry, power utilities, and ground transportation\nservices that conduct much of their work outdoors. Importantly, one of the key\nneeds for nowcasting systems is in the provision of accurate warnings of\nadverse weather events, such as heavy rain and flooding, for the protection of\nlife and property in such situations. Typical nowcasting approaches are based\non simple extrapolation models applied to observations, primarily rainfall\nradar. In this paper we review existing techniques to radar-based nowcasting\nfrom environmental sciences, as well as the statistical approaches that are\napplicable from the field of machine learning. Nowcasting continues to be an\nimportant component of operational systems and we believe new advances are\npossible with new partnerships between the environmental science and machine\nlearning communities.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 10:34:04 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Prudden", "Rachel", ""], ["Adams", "Samantha", ""], ["Kangin", "Dmitry", ""], ["Robinson", "Niall", ""], ["Ravuri", "Suman", ""], ["Mohamed", "Shakir", ""], ["Arribas", "Alberto", ""]]}, {"id": "2005.05003", "submitter": "Zixiao Shen", "authors": "Zixiao Shen, Xin Chen, Jonathan M. Garibaldi", "title": "A Novel Weighted Combination Method for Feature Selection using Fuzzy\n  Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel weighted combination feature selection\nmethod using bootstrap and fuzzy sets. The proposed method mainly consists of\nthree processes, including fuzzy sets generation using bootstrap, weighted\ncombination of fuzzy sets and feature ranking based on defuzzification. We\nimplemented the proposed method by combining four state-of-the-art feature\nselection methods and evaluated the performance based on three publicly\navailable biomedical datasets using five-fold cross validation. Based on the\nfeature selection results, our proposed method produced comparable (if not\nbetter) classification accuracies to the best of the individual feature\nselection methods for all evaluated datasets. More importantly, we also applied\nstandard deviation and Pearson's correlation to measure the stability of the\nmethods. Remarkably, our combination method achieved significantly higher\nstability than the four individual methods when variations and size reductions\nwere introduced to the datasets.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 11:30:34 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 06:01:29 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Shen", "Zixiao", ""], ["Chen", "Xin", ""], ["Garibaldi", "Jonathan M.", ""]]}, {"id": "2005.05021", "submitter": "Youngnam Lee", "authors": "Youngnam Lee, Byungsoo Kim, Dongmin Shin, JungHoon Kim, Jineon Baek,\n  Jinhwan Lee, Youngduck Choi", "title": "Prescribing Deep Attentive Score Prediction Attracts Improved Student\n  Engagement", "comments": "EDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent Tutoring Systems (ITSs) have been developed to provide students\nwith personalized learning experiences by adaptively generating learning paths\noptimized for each individual. Within the vast scope of ITS, score prediction\nstands out as an area of study that enables students to construct individually\nrealistic goals based on their current position. Via the expected score\nprovided by the ITS, a student can instantaneously compare one's expected score\nto one's actual score, which directly corresponds to the reliability that the\nITS can instill. In other words, refining the precision of predicted scores\nstrictly correlates to the level of confidence that a student may have with an\nITS, which will evidently ensue improved student engagement. However, previous\nstudies have solely concentrated on improving the performance of a prediction\nmodel, largely lacking focus on the benefits generated by its practical\napplication. In this paper, we demonstrate that the accuracy of the score\nprediction model deployed in a real-world setting significantly impacts user\nengagement by providing empirical evidence. To that end, we apply a\nstate-of-the-art deep attentive neural network-based score prediction model to\nSanta, a multi-platform English ITS with approximately 780K users in South\nKorea that exclusively focuses on the TOEIC (Test of English for International\nCommunications) standardized examinations. We run a controlled A/B test on the\nITS with two models, respectively based on collaborative filtering and deep\nattentive neural networks, to verify whether the more accurate model engenders\nany student engagement. The results conclude that the attentive model not only\ninduces high student morale (e.g. higher diagnostic test completion ratio,\nnumber of questions answered, etc.) but also encourages active engagement (e.g.\nhigher purchase rate, improved total profit, etc.) on Santa.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 02:05:40 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 01:06:03 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 06:44:37 GMT"}, {"version": "v4", "created": "Thu, 25 Jun 2020 05:02:29 GMT"}, {"version": "v5", "created": "Wed, 1 Jul 2020 06:51:20 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Lee", "Youngnam", ""], ["Kim", "Byungsoo", ""], ["Shin", "Dongmin", ""], ["Kim", "JungHoon", ""], ["Baek", "Jineon", ""], ["Lee", "Jinhwan", ""], ["Choi", "Youngduck", ""]]}, {"id": "2005.05023", "submitter": "Hatice Gunes Dr", "authors": "Lorcan Reidy, Dennis Chan, Charles Nduka and Hatice Gunes", "title": "Facial Electromyography-based Adaptive Virtual Reality Gaming for\n  Cognitive Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive training has shown promising results for delivering improvements in\nhuman cognition related to attention, problem solving, reading comprehension\nand information retrieval. However, two frequently cited problems in cognitive\ntraining literature are a lack of user engagement with the training programme,\nand a failure of developed skills to generalise to daily life. This paper\nintroduces a new cognitive training (CT) paradigm designed to address these two\nlimitations by combining the benefits of gamification, virtual reality (VR),\nand affective adaptation in the development of an engaging, ecologically valid,\nCT task. Additionally, it incorporates facial electromyography (EMG) as a means\nof determining user affect while engaged in the CT task. This information is\nthen utilised to dynamically adjust the game's difficulty in real-time as users\nplay, with the aim of leading them into a state of flow. Affect recognition\nrates of 64.1% and 76.2%, for valence and arousal respectively, were achieved\nby classifying a DWT-Haar approximation of the input signal using kNN. The\naffect-aware VR cognitive training intervention was then evaluated with a\ncontrol group of older adults. The results obtained substantiate the notion\nthat adaptation techniques can lead to greater feelings of competence and a\nmore appropriate challenge of the user's skills.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 10:01:52 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 12:36:54 GMT"}, {"version": "v3", "created": "Sun, 30 Aug 2020 13:42:12 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Reidy", "Lorcan", ""], ["Chan", "Dennis", ""], ["Nduka", "Charles", ""], ["Gunes", "Hatice", ""]]}, {"id": "2005.05035", "submitter": "Prachi Jain", "authors": "Prachi Jain, Sushant Rathi, Mausam, Soumen Chakrabarti", "title": "Temporal Knowledge Base Completion: New Algorithms and Evaluation\n  Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal knowledge bases associate relational (s,r,o) triples with a set of\ntimes (or a single time instant) when the relation is valid. While\ntime-agnostic KB completion (KBC) has witnessed significant research, temporal\nKB completion (TKBC) is in its early days. In this paper, we consider\npredicting missing entities (link prediction) and missing time intervals (time\nprediction) as joint TKBC tasks where entities, relations, and time are all\nembedded in a uniform, compatible space. We present TIMEPLEX, a novel\ntime-aware KBC method, that also automatically exploits the recurrent nature of\nsome relations and temporal interactions between pairs of relations. TIMEPLEX\nachieves state-of-the-art performance on both prediction tasks.\n  We also find that existing TKBC models heavily overestimate link prediction\nperformance due to imperfect evaluation mechanisms. In response, we propose\nimproved TKBC evaluation protocols for both link and time prediction tasks,\ndealing with subtle issues that arise from the partial overlap of time\nintervals in gold instances and system predictions.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 11:18:47 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 08:13:02 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Jain", "Prachi", ""], ["Rathi", "Sushant", ""], ["Mausam", "", ""], ["Chakrabarti", "Soumen", ""]]}, {"id": "2005.05040", "submitter": "Ali Salamati", "authors": "Ali Salamati, Sadegh Soudjani, and Majid Zamani", "title": "Data-Driven Verification under Signal Temporal Logic Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider systems under uncertainty whose dynamics are partially unknown.\nOur aim is to study satisfaction of temporal logic properties by trajectories\nof such systems. We express these properties as signal temporal logic formulas\nand check if the probability of satisfying the property is at least a given\nthreshold. Since the dynamics are parameterized and partially unknown, we\ncollect data from the system and employ Bayesian inference techniques to\nassociate a confidence value to the satisfaction of the property. The main\nnovelty of our approach is to combine both data-driven and model-based\ntechniques in order to have a two-layer probabilistic reasoning over the\nbehavior of the system: one layer is related to the stochastic noise inside the\nsystem and the next layer is related to the noisy data collected from the\nsystem. We provide approximate algorithms for computing the confidence for\nlinear dynamical systems.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 08:32:30 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Salamati", "Ali", ""], ["Soudjani", "Sadegh", ""], ["Zamani", "Majid", ""]]}, {"id": "2005.05053", "submitter": "Melikasadat Emami", "authors": "Melikasadat Emami, Mojtaba Sahraee-Ardakan, Parthe Pandit, Alyson K.\n  Fletcher, Sundeep Rangan, Michael Trumpis, Brinnae Bent, Chia-Han Chiang,\n  Jonathan Viventi", "title": "Low-Rank Nonlinear Decoding of $\\mu$-ECoG from the Primary Auditory\n  Cortex", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of neural decoding from parallel neural\nmeasurements systems such as micro-electrocorticography ($\\mu$-ECoG). In\nsystems with large numbers of array elements at very high sampling rates, the\ndimension of the raw measurement data may be large. Learning neural decoders\nfor this high-dimensional data can be challenging, particularly when the number\nof training samples is limited. To address this challenge, this work presents a\nnovel neural network decoder with a low-rank structure in the first hidden\nlayer. The low-rank constraints dramatically reduce the number of parameters in\nthe decoder while still enabling a rich class of nonlinear decoder maps. The\nlow-rank decoder is illustrated on $\\mu$-ECoG data from the primary auditory\ncortex (A1) of awake rats. This decoding problem is particularly challenging\ndue to the complexity of neural responses in the auditory cortex and the\npresence of confounding signals in awake animals. It is shown that the proposed\nlow-rank decoder significantly outperforms models using standard dimensionality\nreduction techniques such as principal component analysis (PCA).\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 05:51:08 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Emami", "Melikasadat", ""], ["Sahraee-Ardakan", "Mojtaba", ""], ["Pandit", "Parthe", ""], ["Fletcher", "Alyson K.", ""], ["Rangan", "Sundeep", ""], ["Trumpis", "Michael", ""], ["Bent", "Brinnae", ""], ["Chiang", "Chia-Han", ""], ["Viventi", "Jonathan", ""]]}, {"id": "2005.05057", "submitter": "Anna Guerra", "authors": "Anna Guerra, Francesco Guidi, Davide Dardari, Petar M. Djuric", "title": "Reinforcement Learning for UAV Autonomous Navigation, Mapping and Target\n  Detection", "comments": null, "journal-ref": null, "doi": "10.1109/PLANS46316.2020.9110163", "report-no": null, "categories": "cs.RO cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a joint detection, mapping and navigation problem for\na single unmanned aerial vehicle (UAV) equipped with a low complexity radar and\nflying in an unknown environment. The goal is to optimize its trajectory with\nthe purpose of maximizing the mapping accuracy and, at the same time, to avoid\nareas where measurements might not be sufficiently informative from the\nperspective of a target detection. This problem is formulated as a Markov\ndecision process (MDP) where the UAV is an agent that runs either a state\nestimator for target detection and for environment mapping, and a reinforcement\nlearning (RL) algorithm to infer its own policy of navigation (i.e., the\ncontrol law). Numerical results show the feasibility of the proposed idea,\nhighlighting the UAV's capability of autonomously exploring areas with high\nprobability of target detection while reconstructing the surrounding\nenvironment.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 20:39:18 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Guerra", "Anna", ""], ["Guidi", "Francesco", ""], ["Dardari", "Davide", ""], ["Djuric", "Petar M.", ""]]}, {"id": "2005.05060", "submitter": "Alireza M. Javid", "authors": "Alireza M. Javid, Xinyue Liang, Arun Venkitaraman, Saikat Chatterjee", "title": "Predictive Analysis of COVID-19 Time-series Data from Johns Hopkins\n  University", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a predictive analysis of the spread of COVID-19, also known as\nSARS-CoV-2, using the dataset made publicly available online by the Johns\nHopkins University. Our main objective is to provide predictions of the number\nof infected people for different countries in the next 14 days. The predictive\nanalysis is done using time-series data transformed on a logarithmic scale. We\nuse two well-known methods for prediction: polynomial regression and neural\nnetwork. As the number of training data for each country is limited, we use a\nsingle-layer neural network called the extreme learning machine (ELM) to avoid\nover-fitting. Due to the non-stationary nature of the time-series, a sliding\nwindow approach is used to provide a more accurate prediction.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 12:47:31 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 11:23:51 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 19:08:55 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Javid", "Alireza M.", ""], ["Liang", "Xinyue", ""], ["Venkitaraman", "Arun", ""], ["Chatterjee", "Saikat", ""]]}, {"id": "2005.05067", "submitter": "Remy Priem", "authors": "R\\'emy Priem ((1) and (2)), Nathalie Bartoli (1), Youssef Diouane (2),\n  Alessandro Sgueglia ((1) and (2)) ((1) ONERA, DTIS, Universit\\'ee de\n  Toulouse, Toulouse, France, (2) ISAE-SUPAERO, Universit\\'ee de Toulouse,\n  Toulouse, 31055 Cedex 4, France)", "title": "Upper Trust Bound Feasibility Criterion for Mixed Constrained Bayesian\n  Optimization with Application to Aircraft Design", "comments": "59 pages, 27 figures", "journal-ref": null, "doi": "10.1016/j.ast.2020.105980", "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Bayesian optimization methods have been successfully applied to black box\noptimization problems that are expensive to evaluate. In this paper, we adapt\nthe so-called super effcient global optimization algorithm to solve more\naccurately mixed constrained problems. The proposed approach handles\nconstraints by means of upper trust bound, the latter encourages exploration of\nthe feasible domain by combining the mean prediction and the associated\nuncertainty function given by the Gaussian processes. On top of that, a\nrefinement procedure, based on a learning rate criterion, is introduced to\nenhance the exploitation and exploration trade-off. We show the good potential\nof the approach on a set of numerical experiments. Finally, we present an\napplication to conceptual aircraft configuration upon which we show the\nsuperiority of the proposed approach compared to a set of the state-of-the-art\nblack box optimization solvers. Keywords: Global Optimization, Mixed\nConstrained Optimization, Black box optimization, Bayesian Optimization,\nGaussian Process.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 12:59:09 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 08:59:51 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Priem", "R\u00e9my", ""], ["Bartoli", "Nathalie", ""], ["Diouane", "Youssef", ""], ["Sgueglia", "Alessandro", ""]]}, {"id": "2005.05069", "submitter": "Eric L. Manibardo", "authors": "Eric L. Manibardo, Ibai La\\~na, Javier Del Ser", "title": "Transfer Learning and Online Learning for Traffic Forecasting under\n  Different Data Availability Conditions: Alternatives and Pitfalls", "comments": "Conference paper at ITSC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This work aims at unveiling the potential of Transfer Learning (TL) for\ndeveloping a traffic flow forecasting model in scenarios of absent data.\nKnowledge transfer from high-quality predictive models becomes feasible under\nthe TL paradigm, enabling the generation of new proper models with few data. In\norder to explore this capability, we identify three different levels of data\nabsent scenarios, where TL techniques are applied among Deep Learning (DL)\nmethods for traffic forecasting. Then, traditional batch learning is compared\nagainst TL based models using real traffic flow data, collected by deployed\nloops managed by the City Council of Madrid (Spain). In addition, we apply\nOnline Learning (OL) techniques, where model receives an update after each\nprediction, in order to adapt to traffic flow trend changes and incrementally\nlearn from new incoming traffic data. The obtained experimental results shed\nlight on the advantages of transfer and online learning for traffic flow\nforecasting, and draw practical insights on their interplay with the amount of\navailable training data at the location of interest.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 10:53:49 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Manibardo", "Eric L.", ""], ["La\u00f1a", "Ibai", ""], ["Del Ser", "Javier", ""]]}, {"id": "2005.05074", "submitter": "Said Boumaraf", "authors": "Said Boumaraf, Xiabi Liu, Chokri Ferkous, and Xiaohong Ma", "title": "A New Computer-Aided Diagnosis System with Modified Genetic Feature\n  Selection for BI-RADS Classification of Breast Masses in Mammograms", "comments": null, "journal-ref": null, "doi": "10.1155/2020/7695207", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mammography remains the most prevalent imaging tool for early breast cancer\nscreening. The language used to describe abnormalities in mammographic reports\nis based on the breast Imaging Reporting and Data System (BI-RADS). Assigning a\ncorrect BI-RADS category to each examined mammogram is a strenuous and\nchallenging task for even experts. This paper proposes a new and effective\ncomputer-aided diagnosis (CAD) system to classify mammographic masses into four\nassessment categories in BI-RADS. The mass regions are first enhanced by means\nof histogram equalization and then semiautomatically segmented based on the\nregion growing technique. A total of 130 handcrafted BI-RADS features are then\nextrcated from the shape, margin, and density of each mass, together with the\nmass size and the patient's age, as mentioned in BI-RADS mammography. Then, a\nmodified feature selection method based on the genetic algorithm (GA) is\nproposed to select the most clinically significant BI-RADS features. Finally, a\nback-propagation neural network (BPN) is employed for classification, and its\naccuracy is used as the fitness in GA. A set of 500 mammogram images from the\ndigital database of screening mammography (DDSM) is used for evaluation. Our\nsystem achieves classification accuracy, positive predictive value, negative\npredictive value, and Matthews correlation coefficient of 84.5%, 84.4%, 94.8%,\nand 79.3%, respectively. To our best knowledge, this is the best current result\nfor BI-RADS classification of breast masses in mammography, which makes the\nproposed system promising to support radiologists for deciding proper patient\nmanagement based on the automatically assigned BI-RADS categories.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 13:06:25 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Boumaraf", "Said", ""], ["Liu", "Xiabi", ""], ["Ferkous", "Chokri", ""], ["Ma", "Xiaohong", ""]]}, {"id": "2005.05080", "submitter": "Honglin Li", "authors": "Honglin Li, Payam Barnaghi, Shirin Enshaeifar, Frieder Ganz", "title": "Continual Learning Using Multi-view Task Conditional Neural Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Conventional deep learning models have limited capacity in learning multiple\ntasks sequentially. The issue of forgetting the previously learned tasks in\ncontinual learning is known as catastrophic forgetting or interference. When\nthe input data or the goal of learning change, a continual model will learn and\nadapt to the new status. However, the model will not remember or recognise any\nrevisits to the previous states. This causes performance reduction and\nre-training curves in dealing with periodic or irregularly reoccurring changes\nin the data or goals. The changes in goals or data are referred to as new tasks\nin a continual learning model. Most of the continual learning methods have a\ntask-known setup in which the task identities are known in advance to the\nlearning model. We propose Multi-view Task Conditional Neural Networks\n(Mv-TCNN) that does not require to known the reoccurring tasks in advance. We\nevaluate our model on standard datasets using MNIST, CIFAR10, CIFAR100, and\nalso a real-world dataset that we have collected in a remote healthcare\nmonitoring study (i.e. TIHM dataset). The proposed model outperforms the\nstate-of-the-art solutions in continual learning and adapting to new tasks that\nare not defined in advance.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 01:03:30 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 04:58:37 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 09:19:07 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Li", "Honglin", ""], ["Barnaghi", "Payam", ""], ["Enshaeifar", "Shirin", ""], ["Ganz", "Frieder", ""]]}, {"id": "2005.05083", "submitter": "Binhang Yuan", "authors": "Binhang Yuan and Song Ge and Wenhui Xing", "title": "A Federated Learning Framework for Healthcare IoT devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) revolution has shown potential to give rise to\nmany medical applications with access to large volumes of healthcare data\ncollected by IoT devices. However, the increasing demand for healthcare data\nprivacy and security makes each IoT device an isolated island of data. Further,\nthe limited computation and communication capacity of wearable healthcare\ndevices restrict the application of vanilla federated learning. To this end, we\npropose an advanced federated learning framework to train deep neural networks,\nwhere the network is partitioned and allocated to IoT devices and a centralized\nserver. Then most of the training computation is handled by the powerful\nserver. The sparsification of activations and gradients significantly reduces\nthe communication overhead. Empirical study have suggested that the proposed\nframework guarantees a low accuracy loss, while only requiring 0.2% of the\nsynchronization traffic in vanilla federated learning.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 22:58:43 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Yuan", "Binhang", ""], ["Ge", "Song", ""], ["Xing", "Wenhui", ""]]}, {"id": "2005.05085", "submitter": "Luo Chunjie", "authors": "Chunjie Luo, Xiwen He, Jianfeng Zhan, Lei Wang, Wanling Gao, Jiahui\n  Dai", "title": "Comparison and Benchmarking of AI Models and Frameworks on Mobile\n  Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PF eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to increasing amounts of data and compute resources, deep learning\nachieves many successes in various domains. The application of deep learning on\nthe mobile and embedded devices is taken more and more attentions, benchmarking\nand ranking the AI abilities of mobile and embedded devices becomes an urgent\nproblem to be solved. Considering the model diversity and framework diversity,\nwe propose a benchmark suite, AIoTBench, which focuses on the evaluation of the\ninference abilities of mobile and embedded devices. AIoTBench covers three\ntypical heavy-weight networks: ResNet50, InceptionV3, DenseNet121, as well as\nthree light-weight networks: SqueezeNet, MobileNetV2, MnasNet. Each network is\nimplemented by three frameworks which are designed for mobile and embedded\ndevices: Tensorflow Lite, Caffe2, Pytorch Mobile. To compare and rank the AI\ncapabilities of the devices, we propose two unified metrics as the AI scores:\nValid Images Per Second (VIPS) and Valid FLOPs Per Second (VOPS). Currently, we\nhave compared and ranked 5 mobile devices using our benchmark. This list will\nbe extended and updated soon after.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 15:05:23 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Luo", "Chunjie", ""], ["He", "Xiwen", ""], ["Zhan", "Jianfeng", ""], ["Wang", "Lei", ""], ["Gao", "Wanling", ""], ["Dai", "Jiahui", ""]]}, {"id": "2005.05092", "submitter": "Christopher Arthurs DPhil", "authors": "Christopher J Arthurs and Andrew P King", "title": "Active Training of Physics-Informed Neural Networks to Aggregate and\n  Interpolate Parametric Solutions to the Navier-Stokes Equations", "comments": "16 pages, 9 figures; added missing details from author affiliations", "journal-ref": null, "doi": "10.1016/j.jcp.2021.110364", "report-no": null, "categories": "physics.comp-ph cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this work is to train a neural network which approximates\nsolutions to the Navier-Stokes equations across a region of parameter space, in\nwhich the parameters define physical properties such as domain shape and\nboundary conditions. The contributions of this work are threefold:\n  1) To demonstrate that neural networks can be efficient aggregators of whole\nfamilies of parameteric solutions to physical problems, trained using data\ncreated with traditional, trusted numerical methods such as finite elements.\nAdvantages include extremely fast evaluation of pressure and velocity at any\npoint in physical and parameter space (asymptotically, ~3 $\\mu s$ / query), and\ndata compression (the network requires 99\\% less storage space compared to its\nown training data).\n  2) To demonstrate that the neural networks can accurately interpolate between\nfinite element solutions in parameter space, allowing them to be instantly\nqueried for pressure and velocity field solutions to problems for which\ntraditional simulations have never been performed.\n  3) To introduce an active learning algorithm, so that during training, a\nfinite element solver can automatically be queried to obtain additional\ntraining data in locations where the neural network's predictions are in most\nneed of improvement, thus autonomously acquiring and efficiently distributing\ntraining data throughout parameter space.\n  In addition to the obvious utility of Item 2, above, we demonstrate an\napplication of the network in rapid parameter sweeping, very precisely\npredicting the degree of narrowing in a tube which would result in a 50\\%\nincrease in end-to-end pressure difference at a given flow rate. This\ncapability could have applications in both medical diagnosis of arterial\ndisease, and in computer-aided design.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 21:53:39 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 11:24:36 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Arthurs", "Christopher J", ""], ["King", "Andrew P", ""]]}, {"id": "2005.05097", "submitter": "Daniel Alshamaa", "authors": "Daniel Alshamaa, Farah Chehade, Paul Honeine", "title": "Statistical learning for sensor localization in wireless networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indoor localization has become an important issue for wireless sensor\nnetworks. This paper presents a zoning-based localization technique that uses\nWiFi signals and works efficiently in indoor environments. The targeted area is\ncomposed of several zones, the objective being to determine the zone of the\nsensor using an observation model based on statistical learning.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 13:27:24 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Alshamaa", "Daniel", ""], ["Chehade", "Farah", ""], ["Honeine", "Paul", ""]]}, {"id": "2005.05099", "submitter": "Shonosuke Harada", "authors": "Shonosuke Harada and Hisashi Kashima", "title": "Counterfactual Propagation for Semi-Supervised Individual Treatment\n  Effect Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individual treatment effect (ITE) represents the expected improvement in the\noutcome of taking a particular action to a particular target, and plays\nimportant roles in decision making in various domains. However, its estimation\nproblem is difficult because intervention studies to collect information\nregarding the applied treatments (i.e., actions) and their outcomes are often\nquite expensive in terms of time and monetary costs. In this study, we consider\na semi-supervised ITE estimation problem that exploits more easily-available\nunlabeled instances to improve the performance of ITE estimation using small\nlabeled data. We combine two ideas from causal inference and semi-supervised\nlearning, namely, matching and label propagation, respectively, to propose\ncounterfactual propagation, which is the first semi-supervised ITE estimation\nmethod. Experiments using semi-real datasets demonstrate that the proposed\nmethod can successfully mitigate the data scarcity problem in ITE estimation.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 13:32:38 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Harada", "Shonosuke", ""], ["Kashima", "Hisashi", ""]]}, {"id": "2005.05114", "submitter": "Mohammad Hossein Manshaei", "authors": "Mohammad Amin Samadi, Mohammad Sadegh Akhondzadeh, Sayed Jalal Zahabi,\n  Mohammad Hossein Manshaei, Zeinab Maleki, Payman Adibi", "title": "Evaluating Sparse Interpretable Word Embeddings for Biomedical Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings have found their way into a wide range of natural language\nprocessing tasks including those in the biomedical domain. While these vector\nrepresentations successfully capture semantic and syntactic word relations,\nhidden patterns and trends in the data, they fail to offer interpretability.\nInterpretability is a key means to justification which is an integral part when\nit comes to biomedical applications. We present an inclusive study on\ninterpretability of word embeddings in the medical domain, focusing on the role\nof sparse methods. Qualitative and quantitative measurements and metrics for\ninterpretability of word vector representations are provided. For the\nquantitative evaluation, we introduce an extensive categorized dataset that can\nbe used to quantify interpretability based on category theory. Intrinsic and\nextrinsic evaluation of the studied methods are also presented. As for the\nlatter, we propose datasets which can be utilized for effective extrinsic\nevaluation of word vectors in the biomedical domain. Based on our experiments,\nit is seen that sparse word vectors show far more interpretability while\npreserving the performance of their original vectors in downstream tasks.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 13:56:58 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Samadi", "Mohammad Amin", ""], ["Akhondzadeh", "Mohammad Sadegh", ""], ["Zahabi", "Sayed Jalal", ""], ["Manshaei", "Mohammad Hossein", ""], ["Maleki", "Zeinab", ""], ["Adibi", "Payman", ""]]}, {"id": "2005.05117", "submitter": "Bojan Karla\\v{s}", "authors": "Bojan Karla\\v{s}, Peng Li, Renzhi Wu, Nezihe Merve G\\\"urel, Xu Chu,\n  Wentao Wu, Ce Zhang", "title": "Nearest Neighbor Classifiers over Incomplete Information: From Certain\n  Answers to Certain Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) applications have been thriving recently, largely\nattributed to the increasing availability of data. However, inconsistency and\nincomplete information are ubiquitous in real-world datasets, and their impact\non ML applications remains elusive. In this paper, we present a formal study of\nthis impact by extending the notion of Certain Answers for Codd tables, which\nhas been explored by the database research community for decades, into the\nfield of machine learning. Specifically, we focus on classification problems\nand propose the notion of \"Certain Predictions\" (CP) -- a test data example can\nbe certainly predicted (CP'ed) if all possible classifiers trained on top of\nall possible worlds induced by the incompleteness of data would yield the same\nprediction.\n  We study two fundamental CP queries: (Q1) checking query that determines\nwhether a data example can be CP'ed; and (Q2) counting query that computes the\nnumber of classifiers that support a particular prediction (i.e., label). Given\nthat general solutions to CP queries are, not surprisingly, hard without\nassumption over the type of classifier, we further present a case study in the\ncontext of nearest neighbor (NN) classifiers, where efficient solutions to CP\nqueries can be developed -- we show that it is possible to answer both queries\nin linear or polynomial time over exponentially many possible worlds.\n  We demonstrate one example use case of CP in the important application of\n\"data cleaning for machine learning (DC for ML).\" We show that our proposed\nCPClean approach built based on CP can often significantly outperform existing\ntechniques in terms of classification accuracy with mild manual cleaning\neffort.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 13:58:52 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 10:46:33 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Karla\u0161", "Bojan", ""], ["Li", "Peng", ""], ["Wu", "Renzhi", ""], ["G\u00fcrel", "Nezihe Merve", ""], ["Chu", "Xu", ""], ["Wu", "Wentao", ""], ["Zhang", "Ce", ""]]}, {"id": "2005.05128", "submitter": "Jichen Wang", "authors": "Jichen Wang, Weiguo Zhu, Yongqi Sun, Chunzi Tian", "title": "An Effective Dynamic Spatio-temporal Framework with Multi-Source\n  Information for Traffic Prediction", "comments": "12pages, 12 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traffic prediction is necessary not only for management departments to\ndispatch vehicles but also for drivers to avoid congested roads. Many traffic\nforecasting methods based on deep learning have been proposed in recent years,\nand their main aim is to solve the problem of spatial dependencies and temporal\ndynamics. In this paper, we propose a useful dynamic model to predict the urban\ntraffic volume by combining fully bidirectional LSTM, the more complex\nattention mechanism, and the external features, including weather conditions\nand events. First, we adopt the bidirectional LSTM to obtain temporal\ndependencies of traffic volume dynamically in each layer, which is different\nfrom the hybrid methods combining bidirectional and unidirectional ones;\nsecond, we use a more elaborate attention mechanism to learn short-term and\nlong-term periodic temporal dependencies; and finally, we collect the weather\nconditions and events as the external features to further improve the\nprediction precision. The experimental results show that the proposed model\nimproves the prediction precision by approximately 3-7 percent on the NYC-Taxi\nand NYC-Bike datasets compared to the most recently developed method, being a\nuseful tool for the urban traffic prediction.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 14:23:52 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Wang", "Jichen", ""], ["Zhu", "Weiguo", ""], ["Sun", "Yongqi", ""], ["Tian", "Chunzi", ""]]}, {"id": "2005.05135", "submitter": "Stefano Cerri", "authors": "Stefano Cerri, Oula Puonti, Dominik S. Meier, Jens Wuerfel, Mark\n  M\\\"uhlau, Hartwig R. Siebner, Koen Van Leemput", "title": "A Contrast-Adaptive Method for Simultaneous Whole-Brain and Lesion\n  Segmentation in Multiple Sclerosis", "comments": null, "journal-ref": null, "doi": "10.1016/j.neuroimage.2020.117471", "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we present a method for the simultaneous segmentation of white matter\nlesions and normal-appearing neuroanatomical structures from multi-contrast\nbrain MRI scans of multiple sclerosis patients. The method integrates a novel\nmodel for white matter lesions into a previously validated generative model for\nwhole-brain segmentation. By using separate models for the shape of anatomical\nstructures and their appearance in MRI, the algorithm can adapt to data\nacquired with different scanners and imaging protocols without retraining. We\nvalidate the method using four disparate datasets, showing robust performance\nin white matter lesion segmentation while simultaneously segmenting dozens of\nother brain structures. We further demonstrate that the contrast-adaptive\nmethod can also be safely applied to MRI scans of healthy controls, and\nreplicate previously documented atrophy patterns in deep gray matter structures\nin MS. The algorithm is publicly available as part of the open-source\nneuroimaging package FreeSurfer.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 14:25:35 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 14:57:36 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Cerri", "Stefano", ""], ["Puonti", "Oula", ""], ["Meier", "Dominik S.", ""], ["Wuerfel", "Jens", ""], ["M\u00fchlau", "Mark", ""], ["Siebner", "Hartwig R.", ""], ["Van Leemput", "Koen", ""]]}, {"id": "2005.05144", "submitter": "Edresson Casanova", "authors": "Edresson Casanova, Arnaldo Candido Junior, Christopher Shulby,\n  Frederico Santos de Oliveira, Jo\\~ao Paulo Teixeira, Moacir Antonelli Ponti,\n  Sandra Maria Aluisio", "title": "TTS-Portuguese Corpus: a corpus for speech synthesis in Brazilian\n  Portuguese", "comments": "This paper is under consideration at Language Resources and\n  Evaluation (LREV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech provides a natural way for human-computer interaction. In particular,\nspeech synthesis systems are popular in different applications, such as\npersonal assistants, GPS applications, screen readers and accessibility tools.\nHowever, not all languages are on the same level when in terms of resources and\nsystems for speech synthesis. This work consists of creating publicly available\nresources for Brazilian Portuguese in the form of a novel dataset along with\ndeep learning models for end-to-end speech synthesis. Such dataset has 10.5\nhours from a single speaker, from which a Tacotron 2 model with the RTISI-LA\nvocoder presented the best performance, achieving a 4.03 MOS value. The\nobtained results are comparable to related works covering English language and\nthe state-of-the-art in Portuguese.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 14:36:44 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 12:09:08 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 18:27:46 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Casanova", "Edresson", ""], ["Junior", "Arnaldo Candido", ""], ["Shulby", "Christopher", ""], ["de Oliveira", "Frederico Santos", ""], ["Teixeira", "Jo\u00e3o Paulo", ""], ["Ponti", "Moacir Antonelli", ""], ["Aluisio", "Sandra Maria", ""]]}, {"id": "2005.05151", "submitter": "Louis Annabi", "authors": "Louis Annabi (ETIS), Alexandre Pitti (ETIS), Mathias Quoy (ETIS)", "title": "Autonomous learning and chaining of motor primitives using the Free\n  Energy Principle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we apply the Free-Energy Principle to the question of motor\nprimitives learning. An echo-state network is used to generate motor\ntrajectories. We combine this network with a perception module and a controller\nthat can influence its dynamics. This new compound network permits the\nautonomous learning of a repertoire of motor trajectories. To evaluate the\nrepertoires built with our method, we exploit them in a handwriting task where\nprimitives are chained to produce long-range sequences.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 14:43:55 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Annabi", "Louis", "", "ETIS"], ["Pitti", "Alexandre", "", "ETIS"], ["Quoy", "Mathias", "", "ETIS"]]}, {"id": "2005.05163", "submitter": "Azra Bihorac", "authors": "Yuanfeng Ren (1)(4), Tyler J. Loftus (2)(4), Rahul Sai Kasula (1)(4),\n  Prudhvee Narasimha Sadha (1)(4), Parisa Rashidi (3)(4), Azra Bihorac (1)(4),\n  and Tezcan Ozrazgat-Baslanti (1)(4) ((1) Department of Medicine, College of\n  Medicine, University of Florida, Gainesville, FL, USA, (2) Department of\n  Surgery, College of Medicine, University of Florida, Gainesville, FL, USA,\n  (3) Crayton Pruitt Family Department of Biomedical Engineering, University of\n  Florida, Gainesville, FL, (4) Precision and Intelligent Systems in Medicine\n  (PrismaP), University of Florida, Gainesville, FL, USA)", "title": "Development of Computable Phenotype to Identify and Characterize\n  Transitions in Acuity Status in Intensive Care Unit", "comments": "21 Pages, that include 6 figures, 3 tables and 1 supplemental Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: In the United States, 5.7 million patients are admitted annually\nto intensive care units (ICU), with costs exceeding $82 billion. Although close\nmonitoring and dynamic assessment of patient acuity are key aspects of ICU\ncare, both are limited by the time constraints imposed on healthcare providers.\nMethods: Using the University of Florida Health (UFH) Integrated Data\nRepository as Honest Broker, we created a database with electronic health\nrecords data from a retrospective study cohort of 38,749 adult patients\nadmitted to ICU at UF Health between 06/01/2014 and 08/22/2019. This repository\nincludes demographic information, comorbidities, vital signs, laboratory\nvalues, medications with date and timestamps, and diagnoses and procedure codes\nfor all index admission encounters as well as encounters within 12 months prior\nto index admission and 12 months follow-up. We developed algorithms to identify\nacuity status of the patient every four hours during each ICU stay. Results: We\nhad 383,193 encounters (121,800 unique patients) admitted to the hospital, and\n51,073 encounters (38,749 unique patients) with at least one ICU stay that\nlasted more than four hours. These patients requiring ICU admission had longer\nmedian hospital stay (7 days vs. 1 day) and higher in-hospital mortality (9.6%\nvs. 0.4%) compared with those not admitted to the ICU. Among patients who were\nadmitted to the ICU and expired during hospital admission, more deaths occurred\nin the ICU than on general hospital wards (7.4% vs. 0.8%, respectively).\nConclusions: We developed phenotyping algorithms that determined patient acuity\nstatus every four hours while admitted to the ICU. This approach may be useful\nin developing prognostic and clinical decision-support tools to aid patients,\ncaregivers, and providers in shared decision-making processes regarding\nresource use and escalation of care.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 17:36:17 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Ren", "Yuanfeng", ""], ["Loftus", "Tyler J.", ""], ["Kasula", "Rahul Sai", ""], ["Sadha", "Prudhvee Narasimha", ""], ["Rashidi", "Parisa", ""], ["Bihorac", "Azra", ""], ["Ozrazgat-Baslanti", "Tezcan", ""]]}, {"id": "2005.05178", "submitter": "Trent Weiss", "authors": "Trent Weiss, Madhur Behl", "title": "DeepRacing: Parameterized Trajectories for Autonomous Racing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the challenging problem of high speed autonomous racing in a\nrealistic Formula One environment. DeepRacing is a novel end-to-end framework,\nand a virtual testbed for training and evaluating algorithms for autonomous\nracing. The virtual testbed is implemented using the realistic F1 series of\nvideo games, developed by Codemasters, which many Formula One drivers use for\ntraining. This virtual testbed is released under an open-source license both as\na standalone C++ API and as a binding to the popular Robot Operating System 2\n(ROS2) framework. This open-source API allows anyone to use the high fidelity\nphysics and photo-realistic capabilities of the F1 game as a simulator, and\nwithout hacking any game engine code. We use this framework to evaluate several\nneural network methodologies for autonomous racing. Specifically, we consider\nseveral fully end-to-end models that directly predict steering and acceleration\ncommands for an autonomous race car as well as a model that predicts a list of\nwaypoints to follow in the car's local coordinate system, with the task of\nselecting a steering/throttle angle left to a classical control algorithm. We\nalso present a novel method of autonomous racing by training a deep neural\nnetwork to predict a parameterized representation of a trajectory rather than a\nlist of waypoints. We evaluate these models performance in our open-source\nsimulator and show that trajectory prediction far outperforms end-to-end\ndriving. Additionally, we show that open-loop performance for an end-to-end\nmodel, i.e. root-mean-square error for a model's predicted control values, does\nnot necessarily correlate with increased driving performance in the closed-loop\nsense, i.e. actual ability to race around a track. Finally, we show that our\nproposed model of parameterized trajectory prediction outperforms both\nend-to-end control and waypoint prediction.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 21:35:48 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Weiss", "Trent", ""], ["Behl", "Madhur", ""]]}, {"id": "2005.05195", "submitter": "Ryan Cory-Wright", "authors": "Dimitris Bertsimas, Ryan Cory-Wright, Jean Pauphilet", "title": "Solving Large-Scale Sparse PCA to Certifiable (Near) Optimality", "comments": "Revision submitted to JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse principal component analysis (PCA) is a popular dimensionality\nreduction technique for obtaining principal components which are linear\ncombinations of a small subset of the original features. Existing approaches\ncannot supply certifiably optimal principal components with more than $p=100s$\nof variables. By reformulating sparse PCA as a convex mixed-integer\nsemidefinite optimization problem, we design a cutting-plane method which\nsolves the problem to certifiable optimality at the scale of selecting k=5\ncovariates from p=300 variables, and provides small bound gaps at a larger\nscale. We also propose a convex relaxation and greedy rounding scheme that\nprovides bound gaps of $1-2\\%$ in practice within minutes for $p=100$s or hours\nfor $p=1,000$s and is therefore a viable alternative to the exact method at\nscale. Using real-world financial and medical datasets, we illustrate our\napproach's ability to derive interpretable principal components tractably at\nscale.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 15:39:23 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 21:11:28 GMT"}, {"version": "v3", "created": "Wed, 28 Apr 2021 21:04:39 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Cory-Wright", "Ryan", ""], ["Pauphilet", "Jean", ""]]}, {"id": "2005.05206", "submitter": "Thomas Stahlbuhk", "authors": "Thomas Stahlbuhk, Brooke Shrader and Eytan Modiano", "title": "Learning Algorithms for Minimizing Queue Length Regret", "comments": "28 Pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.IT cs.LG cs.SY eess.SY math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a system consisting of a single transmitter/receiver pair and $N$\nchannels over which they may communicate. Packets randomly arrive to the\ntransmitter's queue and wait to be successfully sent to the receiver. The\ntransmitter may attempt a frame transmission on one channel at a time, where\neach frame includes a packet if one is in the queue. For each channel, an\nattempted transmission is successful with an unknown probability. The\ntransmitter's objective is to quickly identify the best channel to minimize the\nnumber of packets in the queue over $T$ time slots. To analyze system\nperformance, we introduce queue length regret, which is the expected difference\nbetween the total queue length of a learning policy and a controller that knows\nthe rates, a priori. One approach to designing a transmission policy would be\nto apply algorithms from the literature that solve the closely-related\nstochastic multi-armed bandit problem. These policies would focus on maximizing\nthe number of successful frame transmissions over time. However, we show that\nthese methods have $\\Omega(\\log{T})$ queue length regret. On the other hand, we\nshow that there exists a set of queue-length based policies that can obtain\norder optimal $O(1)$ queue length regret. We use our theoretical analysis to\ndevise heuristic methods that are shown to perform well in simulation.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 15:50:56 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 13:26:02 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Stahlbuhk", "Thomas", ""], ["Shrader", "Brooke", ""], ["Modiano", "Eytan", ""]]}, {"id": "2005.05210", "submitter": "Lin Qiu", "authors": "Lin Qiu, Vernon M. Chinchilli, Lin Lin", "title": "Deep Latent Variable Model for Learning Longitudinal Multi-view Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many scientific problems such as video surveillance, modern genomic\nanalysis, and clinical studies, data are often collected from diverse domains\nacross time that exhibit time-dependent heterogeneous properties. It is\nimportant to not only integrate data from multiple sources (called multiview\ndata), but also to incorporate time dependency for deep understanding of the\nunderlying system. Latent factor models are popular tools for exploring\nmulti-view data. However, it is frequently observed that these models do not\nperform well for complex systems and they are not applicable to time-series\ndata. Therefore, we propose a generative model based on variational autoencoder\nand recurrent neural network to infer the latent dynamic factors for\nmultivariate timeseries data. This approach allows us to identify the\ndisentangled latent embeddings across multiple modalities while accounting for\nthe time factor. We invoke our proposed model for analyzing three datasets on\nwhich we demonstrate the effectiveness and the interpretability of the model.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 15:59:06 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 21:23:19 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Qiu", "Lin", ""], ["Chinchilli", "Vernon M.", ""], ["Lin", "Lin", ""]]}, {"id": "2005.05220", "submitter": "Christian Etmann", "authors": "Christian Etmann and Rihuan Ke and Carola-Bibiane Sch\\\"onlieb", "title": "iUNets: Fully invertible U-Nets with Learnable Up- and Downsampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  U-Nets have been established as a standard architecture for image-to-image\nlearning problems such as segmentation and inverse problems in imaging. For\nlarge-scale data, as it for example appears in 3D medical imaging, the U-Net\nhowever has prohibitive memory requirements. Here, we present a new\nfully-invertible U-Net-based architecture called the iUNet, which employs novel\nlearnable and invertible up- and downsampling operations, thereby making the\nuse of memory-efficient backpropagation possible. This allows us to train\ndeeper and larger networks in practice, under the same GPU memory restrictions.\nDue to its invertibility, the iUNet can furthermore be used for constructing\nnormalizing flows.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 16:14:13 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 11:17:53 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 09:32:29 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Etmann", "Christian", ""], ["Ke", "Rihuan", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""]]}, {"id": "2005.05229", "submitter": "Talha Khan", "authors": "Yun Chen, Xingqin Lin, Talha Ahmed Khan, Mohammad Mozaffari", "title": "A Deep Reinforcement Learning Approach to Efficient Drone Mobility\n  Support", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing deployment of drones in a myriad of applications relies on\nseamless and reliable wireless connectivity for safe control and operation of\ndrones. Cellular technology is a key enabler for providing essential wireless\nservices to flying drones in the sky. Existing cellular networks targeting\nterrestrial usage can support the initial deployment of low-altitude drone\nusers, but there are challenges such as mobility support. In this paper, we\npropose a novel handover framework for providing efficient mobility support and\nreliable wireless connectivity to drones served by a terrestrial cellular\nnetwork. Using tools from deep reinforcement learning, we develop a deep\nQ-learning algorithm to dynamically optimize handover decisions to ensure\nrobust connectivity for drone users. Simulation results show that the proposed\nframework significantly reduces the number of handovers at the expense of a\nsmall loss in signal strength relative to the baseline case where a drone\nalways connect to a base station that provides the strongest received signal\nstrength.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 16:21:04 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Chen", "Yun", ""], ["Lin", "Xingqin", ""], ["Khan", "Talha Ahmed", ""], ["Mozaffari", "Mohammad", ""]]}, {"id": "2005.05236", "submitter": "Guillermo Jimenez-Perez", "authors": "Guillermo Jimenez-Perez and Alejandro Alcaine and Oscar Camara", "title": "ECG-DelNet: Delineation of Ambulatory Electrocardiograms with Mixed\n  Quality Labeling Using Neural Networks", "comments": "15 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrocardiogram (ECG) detection and delineation are key steps for numerous\ntasks in clinical practice, as ECG is the most performed non-invasive test for\nassessing cardiac condition. State-of-the-art algorithms employ digital signal\nprocessing (DSP), which require laborious rule adaptation to new morphologies.\nIn contrast, deep learning (DL) algorithms, especially for classification, are\ngaining weight in academic and industrial settings. However, the lack of model\nexplainability and small databases hinder their applicability. We demonstrate\nDL can be successfully applied to low interpretative tasks by embedding ECG\ndetection and delineation onto a segmentation framework. For this purpose, we\nadapted and validated the most used neural network architecture for image\nsegmentation, the U-Net, to one-dimensional data. The model was trained using\nPhysioNet's QT database, comprised of 105 ambulatory ECG recordings, for\nsingle- and multi-lead scenarios. To alleviate data scarcity, data\nregularization techniques such as pre-training with low-quality data labels,\nperforming ECG-based data augmentation and applying strong model regularizers\nto the architecture were attempted. Other variations in the model's capacity\n(U-Net's depth and width), alongside the application of state-of-the-art\nadditions, were evaluated. These variations were exhaustively validated in a\n5-fold cross-validation manner. The best performing configuration reached\nprecisions of 90.12%, 99.14% and 98.25% and recalls of 98.73%, 99.94% and\n99.88% for the P, QRS and T waves, respectively, on par with DSP-based\napproaches. Despite being a data-hungry technique trained on a small dataset,\nDL-based approaches demonstrate to be a viable alternative to traditional\nDSP-based ECG processing techniques.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 16:29:12 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Jimenez-Perez", "Guillermo", ""], ["Alcaine", "Alejandro", ""], ["Camara", "Oscar", ""]]}, {"id": "2005.05238", "submitter": "Reese Pathak", "authors": "Reese Pathak, Martin J. Wainwright", "title": "FedSplit: An algorithmic framework for fast federated optimization", "comments": "27 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Motivated by federated learning, we consider the hub-and-spoke model of\ndistributed optimization in which a central authority coordinates the\ncomputation of a solution among many agents while limiting communication. We\nfirst study some past procedures for federated optimization, and show that\ntheir fixed points need not correspond to stationary points of the original\noptimization problem, even in simple convex settings with deterministic\nupdates. In order to remedy these issues, we introduce FedSplit, a class of\nalgorithms based on operator splitting procedures for solving distributed\nconvex minimization with additive structure. We prove that these procedures\nhave the correct fixed points, corresponding to optima of the original\noptimization problem, and we characterize their convergence rates under\ndifferent settings. Our theory shows that these methods are provably robust to\ninexact computation of intermediate local quantities. We complement our theory\nwith some simple experiments that demonstrate the benefits of our methods in\npractice.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 16:30:09 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Pathak", "Reese", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "2005.05256", "submitter": "Abhilasha Sancheti", "authors": "Abhilasha Sancheti, Kundan Krishna, Balaji Vasan Srinivasan,\n  Anandhavelu Natarajan", "title": "Reinforced Rewards Framework for Text Style Transfer", "comments": "ECIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Style transfer deals with the algorithms to transfer the stylistic properties\nof a piece of text into that of another while ensuring that the core content is\npreserved. There has been a lot of interest in the field of text style transfer\ndue to its wide application to tailored text generation. Existing works\nevaluate the style transfer models based on content preservation and transfer\nstrength. In this work, we propose a reinforcement learning based framework\nthat directly rewards the framework on these target metrics yielding a better\ntransfer of the target style. We show the improved performance of our proposed\nframework based on automatic and human evaluation on three independent tasks:\nwherein we transfer the style of text from formal to informal, high excitement\nto low excitement, modern English to Shakespearean English, and vice-versa in\nall the three cases. Improved performance of the proposed framework over\nexisting state-of-the-art frameworks indicates the viability of the approach.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 16:54:28 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Sancheti", "Abhilasha", ""], ["Krishna", "Kundan", ""], ["Srinivasan", "Balaji Vasan", ""], ["Natarajan", "Anandhavelu", ""]]}, {"id": "2005.05269", "submitter": "Anis Koubaa", "authors": "Adel Ammar, Anis Koubaa", "title": "Deep-Learning-based Automated Palm Tree Counting and Geolocation in\n  Large Farms from Aerial Geotagged Images", "comments": "First version of the paper, 3 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a deep learning framework for the automated\ncounting and geolocation of palm trees from aerial images using convolutional\nneural networks. For this purpose, we collected aerial images in a palm tree\nFarm in the Kharj region, in Riyadh Saudi Arabia, using DJI drones, and we\nbuilt a dataset of around 10,000 instances of palms trees. Then, we developed a\nconvolutional neural network model using the state-of-the-art, Faster R-CNN\nalgorithm. Furthermore, using the geotagged metadata of aerial images, we used\nphotogrammetry concepts and distance corrections to detect the geographical\nlocation of detected palms trees automatically. This geolocation technique was\ntested on two different types of drones (DJI Mavic Pro, and Phantom 4 Pro), and\nwas assessed to provide an average geolocation accuracy of 2.8m. This GPS\ntagging allows us to uniquely identify palm trees and count their number from a\nseries of drone images, while correctly dealing with the issue of image\noverlapping. Moreover, it can be generalized to the geolocation of any other\nobjects in UAV images.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 17:11:49 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Ammar", "Adel", ""], ["Koubaa", "Anis", ""]]}, {"id": "2005.05276", "submitter": "Raoul Heese", "authors": "Raoul Heese, Lukas Morand, Dirk Helm, Michael Bortz", "title": "CupNet -- Pruning a network for geometric data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using data from a simulated cup drawing process, we demonstrate how the\ninherent geometrical structure of cup meshes can be used to effectively prune\nan artificial neural network in a straightforward way.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 17:21:23 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Heese", "Raoul", ""], ["Morand", "Lukas", ""], ["Helm", "Dirk", ""], ["Bortz", "Michael", ""]]}, {"id": "2005.05286", "submitter": "Benjamin Guedj", "authors": "Florent Dewez and Benjamin Guedj and Vincent Vandewalle", "title": "From industry-wide parameters to aircraft-centric on-flight inference:\n  improving aeronautics performance prediction with machine learning", "comments": "Published in Data-Centric Engineering", "journal-ref": "Data-Centric Engineering 2020", "doi": "10.1017/dce.2020.12", "report-no": null, "categories": "stat.AP cs.LG stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Aircraft performance models play a key role in airline operations, especially\nin planning a fuel-efficient flight. In practice, manufacturers provide\nguidelines which are slightly modified throughout the aircraft life cycle via\nthe tuning of a single factor, enabling better fuel predictions. However this\nhas limitations, in particular they do not reflect the evolution of each\nfeature impacting the aircraft performance. Our goal here is to overcome this\nlimitation. The key contribution of the present article is to foster the use of\nmachine learning to leverage the massive amounts of data continuously recorded\nduring flights performed by an aircraft and provide models reflecting its\nactual and individual performance. We illustrate our approach by focusing on\nthe estimation of the drag and lift coefficients from recorded flight data. As\nthese coefficients are not directly recorded, we resort to aerodynamics\napproximations. As a safety check, we provide bounds to assess the accuracy of\nboth the aerodynamics approximation and the statistical performance of our\napproach. We provide numerical results on a collection of machine learning\nalgorithms. We report excellent accuracy on real-life data and exhibit\nempirical evidence to support our modelling, in coherence with aerodynamics\nprinciples.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 17:40:17 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 16:42:36 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2021 10:22:43 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Dewez", "Florent", ""], ["Guedj", "Benjamin", ""], ["Vandewalle", "Vincent", ""]]}, {"id": "2005.05287", "submitter": "Prateek Khandelwal", "authors": "Prateek Khandelwal, Anuj Khandelwal, Snigdha Agarwal, Deep Thomas,\n  Naveen Xavier, Arun Raghuraman (for Group Data and Analytics, Aditya Birla\n  Group)", "title": "Using Computer Vision to enhance Safety of Workforce in Manufacturing in\n  a Post COVID World", "comments": "6 pages, 7 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic forced governments across the world to impose lockdowns\nto prevent virus transmissions. This resulted in the shutdown of all economic\nactivity and accordingly the production at manufacturing plants across most\nsectors was halted. While there is an urgency to resume production, there is an\neven greater need to ensure the safety of the workforce at the plant site.\nReports indicate that maintaining social distancing and wearing face masks\nwhile at work clearly reduces the risk of transmission. We decided to use\ncomputer vision on CCTV feeds to monitor worker activity and detect violations\nwhich trigger real time voice alerts on the shop floor. This paper describes an\nefficient and economic approach of using AI to create a safe environment in a\nmanufacturing setup. We demonstrate our approach to build a robust social\ndistancing measurement algorithm using a mix of modern-day deep learning and\nclassic projective geometry techniques. We have deployed our solution at\nmanufacturing plants across the Aditya Birla Group (ABG). We have also\ndescribed our face mask detection approach which provides a high accuracy\nacross a range of customized masks.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 17:40:58 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 12:16:12 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Khandelwal", "Prateek", "", "for Group Data and Analytics, Aditya Birla\n  Group"], ["Khandelwal", "Anuj", "", "for Group Data and Analytics, Aditya Birla\n  Group"], ["Agarwal", "Snigdha", "", "for Group Data and Analytics, Aditya Birla\n  Group"], ["Thomas", "Deep", "", "for Group Data and Analytics, Aditya Birla\n  Group"], ["Xavier", "Naveen", "", "for Group Data and Analytics, Aditya Birla\n  Group"], ["Raghuraman", "Arun", "", "for Group Data and Analytics, Aditya Birla\n  Group"]]}, {"id": "2005.05294", "submitter": "Claudio Gallicchio", "authors": "Claudio Gallicchio and Alessio Micheli", "title": "Ring Reservoir Neural Networks for Graphs", "comments": "Accepted for IJCNN/WCCI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning for graphs is nowadays a research topic of consolidated\nrelevance. Common approaches in the field typically resort to complex deep\nneural network architectures and demanding training algorithms, highlighting\nthe need for more efficient solutions. The class of Reservoir Computing (RC)\nmodels can play an important role in this context, enabling to develop fruitful\ngraph embeddings through untrained recursive architectures. In this paper, we\nstudy progressive simplifications to the design strategy of RC neural networks\nfor graphs. Our core proposal is based on shaping the organization of the\nhidden neurons to follow a ring topology. Experimental results on graph\nclassification tasks indicate that ring-reservoirs architectures enable\nparticularly effective network configurations, showing consistent advantages in\nterms of predictive performance.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 17:51:40 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Gallicchio", "Claudio", ""], ["Micheli", "Alessio", ""]]}, {"id": "2005.05298", "submitter": "Baolin Peng", "authors": "Baolin Peng and Chunyuan Li and Jinchao Li and Shahin Shayandeh and\n  Lars Liden and Jianfeng Gao", "title": "SOLOIST: Building Task Bots at Scale with Transfer Learning and Machine\n  Teaching", "comments": "18 pages; To appear at TACL; Project Website: https://aka.ms/soloist", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method SOLOIST that uses transfer learning and machine\nteaching to build task bots at scale. We parameterize classical modular\ntask-oriented dialog systems using a Transformer-based auto-regressive language\nmodel, which subsumes different dialog modules into a single neural model. We\npre-train, on heterogeneous dialog corpora, a task-grounded response generation\nmodel, which can generate dialog responses grounded in user goals and\nreal-world knowledge for task completion. The pre-trained model can be\nefficiently adapted to accomplish new tasks with a handful of task-specific\ndialogs via machine teaching, where training samples are generated by human\nteachers interacting with the system. Experiments show that (i) SOLOIST creates\nnew state-of-the-art on well-studied task-oriented dialog benchmarks, including\nCamRest676 and MultiWOZ; (ii) in the few-shot fine-tuning settings, SOLOIST\nsignificantly outperforms existing methods, and (iii) the use of machine\nteaching substantially reduces the labeling cost of fine-tuning. The\npre-trained models and codes are available at https://aka.ms/soloist.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 17:58:34 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 17:42:40 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 03:02:50 GMT"}, {"version": "v4", "created": "Fri, 9 Apr 2021 03:14:57 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Peng", "Baolin", ""], ["Li", "Chunyuan", ""], ["Li", "Jinchao", ""], ["Shayandeh", "Shahin", ""], ["Liden", "Lars", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2005.05304", "submitter": "Zhuo Ma", "authors": "Zhuzhu Wang, Yilong Yang, Yang Liu, Ximeng Liu, Brij B. Gupta,\n  Jianfeng Ma", "title": "Cloud-based Federated Boosting for Mobile Crowdsensing", "comments": "17 pages, 7 figures. arXiv admin note: substantial text overlap with\n  arXiv:1907.10218", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of federated extreme gradient boosting to mobile crowdsensing\napps brings several benefits, in particular high performance on efficiency and\nclassification. However, it also brings a new challenge for data and model\nprivacy protection. Besides it being vulnerable to Generative Adversarial\nNetwork (GAN) based user data reconstruction attack, there is not the existing\narchitecture that considers how to preserve model privacy. In this paper, we\npropose a secret sharing based federated learning architecture FedXGB to\nachieve the privacy-preserving extreme gradient boosting for mobile\ncrowdsensing. Specifically, we first build a secure classification and\nregression tree (CART) of XGBoost using secret sharing. Then, we propose a\nsecure prediction protocol to protect the model privacy of XGBoost in mobile\ncrowdsensing. We conduct a comprehensive theoretical analysis and extensive\nexperiments to evaluate the security, effectiveness, and efficiency of FedXGB.\nThe results indicate that FedXGB is secure against the honest-but-curious\nadversaries and attains less than 1% accuracy loss compared with the original\nXGBoost model.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 08:49:01 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Wang", "Zhuzhu", ""], ["Yang", "Yilong", ""], ["Liu", "Yang", ""], ["Liu", "Ximeng", ""], ["Gupta", "Brij B.", ""], ["Ma", "Jianfeng", ""]]}, {"id": "2005.05321", "submitter": "Brian Kim", "authors": "Brian Kim, Yalin E. Sagduyu, Kemal Davaslioglu, Tugba Erpek, Sennur\n  Ulukus", "title": "Channel-Aware Adversarial Attacks Against Deep Learning-Based Wireless\n  Signal Classifiers", "comments": "Submitted for publication. arXiv admin note: substantial text overlap\n  with arXiv:2002.02400", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents channel-aware adversarial attacks against deep\nlearning-based wireless signal classifiers. There is a transmitter that\ntransmits signals with different modulation types. A deep neural network is\nused at each receiver to classify its over-the-air received signals to\nmodulation types. In the meantime, an adversary transmits an adversarial\nperturbation (subject to a power budget) to fool receivers into making errors\nin classifying signals that are received as superpositions of transmitted\nsignals and adversarial perturbations. First, these evasion attacks are shown\nto fail when channels are not considered in designing adversarial\nperturbations. Then, realistic attacks are presented by considering channel\neffects from the adversary to each receiver. After showing that a channel-aware\nattack is selective (i.e., it affects only the receiver whose channel is\nconsidered in the perturbation design), a broadcast adversarial attack is\npresented by crafting a common adversarial perturbation to simultaneously fool\nclassifiers at different receivers. The major vulnerability of modulation\nclassifiers to over-the-air adversarial attacks is shown by accounting for\ndifferent levels of information available about the channel, the transmitter\ninput, and the classifier model. Finally, a certified defense based on\nrandomized smoothing that augments training data with noise is introduced to\nmake the modulation classifier robust to adversarial perturbations.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 15:42:54 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 20:24:36 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Kim", "Brian", ""], ["Sagduyu", "Yalin E.", ""], ["Davaslioglu", "Kemal", ""], ["Erpek", "Tugba", ""], ["Ulukus", "Sennur", ""]]}, {"id": "2005.05325", "submitter": "Alireza Samadian", "authors": "Mahmoud Abo-Khamis, Sungjin Im, Benjamin Moseley, Kirk Pruhs, Alireza\n  Samadian", "title": "A Relational Gradient Descent Algorithm For Support Vector Machine\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider gradient descent like algorithms for Support Vector Machine (SVM)\ntraining when the data is in relational form. The gradient of the SVM objective\ncan not be efficiently computed by known techniques as it suffers from the\n``subtraction problem''. We first show that the subtraction problem can not be\nsurmounted by showing that computing any constant approximation of the gradient\nof the SVM objective function is $\\#P$-hard, even for acyclic joins. We,\nhowever, circumvent the subtraction problem by restricting our attention to\nstable instances, which intuitively are instances where a nearly optimal\nsolution remains nearly optimal if the points are perturbed slightly. We give\nan efficient algorithm that computes a ``pseudo-gradient'' that guarantees\nconvergence for stable instances at a rate comparable to that achieved by using\nthe actual gradient. We believe that our results suggest that this sort of\nstability the analysis would likely yield useful insight in the context of\ndesigning algorithms on relational data for other learning problems in which\nthe subtraction problem arises.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 17:50:36 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Abo-Khamis", "Mahmoud", ""], ["Im", "Sungjin", ""], ["Moseley", "Benjamin", ""], ["Pruhs", "Kirk", ""], ["Samadian", "Alireza", ""]]}, {"id": "2005.05339", "submitter": "Chris Donahue", "authors": "Chris Donahue, Mina Lee, Percy Liang", "title": "Enabling Language Models to Fill in the Blanks", "comments": "Published as a conference paper at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple approach for text infilling, the task of predicting\nmissing spans of text at any position in a document. While infilling could\nenable rich functionality especially for writing assistance tools, more\nattention has been devoted to language modeling---a special case of infilling\nwhere text is predicted at the end of a document. In this paper, we aim to\nextend the capabilities of language models (LMs) to the more general task of\ninfilling. To this end, we train (or fine-tune) off-the-shelf LMs on sequences\ncontaining the concatenation of artificially-masked text and the text which was\nmasked. We show that this approach, which we call infilling by language\nmodeling, can enable LMs to infill entire sentences effectively on three\ndifferent domains: short stories, scientific abstracts, and lyrics.\nFurthermore, we show that humans have difficulty identifying sentences infilled\nby our approach as machine-generated in the domain of short stories.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 18:00:03 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 18:03:11 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Donahue", "Chris", ""], ["Lee", "Mina", ""], ["Liang", "Percy", ""]]}, {"id": "2005.05385", "submitter": "Murat Yildirim", "authors": "Suleyman Yildirim, Alper Ekrem Murat, Murat Yildirim, Suzan Arslanturk", "title": "Process Knowledge Driven Change Point Detection for Automated\n  Calibration of Discrete Event Simulation Models Using Machine Learning", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Initial development and subsequent calibration of discrete event simulation\nmodels for complex systems require accurate identification of dynamically\nchanging process characteristics. Existing data driven change point methods\n(DD-CPD) assume changes are extraneous to the system, thus cannot utilize\navailable process knowledge. This work proposes a unified framework for\nprocess-driven multi-variate change point detection (PD-CPD) by combining\nchange point detection models with machine learning and process-driven\nsimulation modeling. The PD-CPD, after initializing with DD-CPD's change\npoint(s), uses simulation models to generate system level outputs as\ntime-series data streams which are then used to train neural network models to\npredict system characteristics and change points. The accuracy of the\npredictive models measures the likelihood that the actual process data conforms\nto the simulated change points in system characteristics. PD-CPD iteratively\noptimizes change points by repeating simulation and predictive model building\nsteps until the set of change point(s) with the maximum likelihood is\nidentified. Using an emergency department case study, we show that PD-CPD\nsignificantly improves change point detection accuracy over DD-CPD estimates\nand is able to detect actual change points.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 19:07:26 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 04:24:27 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Yildirim", "Suleyman", ""], ["Murat", "Alper Ekrem", ""], ["Yildirim", "Murat", ""], ["Arslanturk", "Suzan", ""]]}, {"id": "2005.05402", "submitter": "Jie Lei", "authors": "Jie Lei, Liwei Wang, Yelong Shen, Dong Yu, Tamara L. Berg, Mohit\n  Bansal", "title": "MART: Memory-Augmented Recurrent Transformer for Coherent Video\n  Paragraph Captioning", "comments": "ACL 2020 (12 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating multi-sentence descriptions for videos is one of the most\nchallenging captioning tasks due to its high requirements for not only visual\nrelevance but also discourse-based coherence across the sentences in the\nparagraph. Towards this goal, we propose a new approach called Memory-Augmented\nRecurrent Transformer (MART), which uses a memory module to augment the\ntransformer architecture. The memory module generates a highly summarized\nmemory state from the video segments and the sentence history so as to help\nbetter prediction of the next sentence (w.r.t. coreference and repetition\naspects), thus encouraging coherent paragraph generation. Extensive\nexperiments, human evaluations, and qualitative analyses on two popular\ndatasets ActivityNet Captions and YouCookII show that MART generates more\ncoherent and less repetitive paragraph captions than baseline methods, while\nmaintaining relevance to the input video events. All code is available\nopen-source at: https://github.com/jayleicn/recurrent-transformer\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 20:01:41 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Lei", "Jie", ""], ["Wang", "Liwei", ""], ["Shen", "Yelong", ""], ["Yu", "Dong", ""], ["Berg", "Tamara L.", ""], ["Bansal", "Mohit", ""]]}, {"id": "2005.05407", "submitter": "Yuhong Guo", "authors": "Yan Yan, Yuhong Guo", "title": "Multi-Level Generative Models for Partial Label Learning with Non-random\n  Label Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial label (PL) learning tackles the problem where each training instance\nis associated with a set of candidate labels that include both the true label\nand irrelevant noise labels. In this paper, we propose a novel multi-level\ngenerative model for partial label learning (MGPLL), which tackles the problem\nby learning both a label level adversarial generator and a feature level\nadversarial generator under a bi-directional mapping framework between the\nlabel vectors and the data samples. Specifically, MGPLL uses a conditional\nnoise label generation network to model the non-random noise labels and perform\nlabel denoising, and uses a multi-class predictor to map the training instances\nto the denoised label vectors, while a conditional data feature generator is\nused to form an inverse mapping from the denoised label vectors to data\nsamples. Both the noise label generator and the data feature generator are\nlearned in an adversarial manner to match the observed candidate labels and\ndata features respectively. Extensive experiments are conducted on synthesized\nand real-world partial label datasets. The proposed approach demonstrates the\nstate-of-the-art performance for partial label learning.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 20:13:19 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Yan", "Yan", ""], ["Guo", "Yuhong", ""]]}, {"id": "2005.05409", "submitter": "Lorenz Richter", "authors": "Nikolas N\\\"usken, Lorenz Richter", "title": "Solving high-dimensional Hamilton-Jacobi-Bellman PDEs using neural\n  networks: perspectives from the theory of controlled diffusions and measures\n  on path space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal control of diffusion processes is intimately connected to the problem\nof solving certain Hamilton-Jacobi-Bellman equations. Building on recent\nmachine learning inspired approaches towards high-dimensional PDEs, we\ninvestigate the potential of iterative diffusion optimisation techniques, in\nparticular considering applications in importance sampling and rare event\nsimulation. The choice of an appropriate loss function being a central element\nin the algorithmic design, we develop a principled framework based on\ndivergences between path measures, encompassing various existing methods.\nMotivated by connections to forward-backward SDEs, we propose and study the\nnovel log-variance divergence, showing favourable properties of corresponding\nMonte Carlo estimators. The promise of the developed approach is exemplified by\na range of high-dimensional and metastable numerical examples.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 20:14:02 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["N\u00fcsken", "Nikolas", ""], ["Richter", "Lorenz", ""]]}, {"id": "2005.05420", "submitter": "Zhe Liu", "authors": "Binyu Wang and Zhe Liu and Qingbiao Li and Amanda Prorok", "title": "Mobile Robot Path Planning in Dynamic Environments through Globally\n  Guided Reinforcement Learning", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Path planning for mobile robots in large dynamic environments is a\nchallenging problem, as the robots are required to efficiently reach their\ngiven goals while simultaneously avoiding potential conflicts with other robots\nor dynamic objects. In the presence of dynamic obstacles, traditional solutions\nusually employ re-planning strategies, which re-call a planning algorithm to\nsearch for an alternative path whenever the robot encounters a conflict.\nHowever, such re-planning strategies often cause unnecessary detours. To\naddress this issue, we propose a learning-based technique that exploits\nenvironmental spatio-temporal information. Different from existing\nlearning-based methods, we introduce a globally guided reinforcement learning\napproach (G2RL), which incorporates a novel reward structure that generalizes\nto arbitrary environments. We apply G2RL to solve the multi-robot path planning\nproblem in a fully distributed reactive manner. We evaluate our method across\ndifferent map types, obstacle densities, and the number of robots. Experimental\nresults show that G2RL generalizes well, outperforming existing distributed\nmethods, and performing very similarly to fully centralized state-of-the-art\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 20:42:29 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 21:14:15 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Wang", "Binyu", ""], ["Liu", "Zhe", ""], ["Li", "Qingbiao", ""], ["Prorok", "Amanda", ""]]}, {"id": "2005.05431", "submitter": "Neil Getty", "authors": "Neil Getty, Thomas Brettin, Dong Jin, Rick Stevens, Fangfang Xia", "title": "Deep Medical Image Analysis with Representation Learning and\n  Neuromorphic Computing", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore three representative lines of research and demonstrate the utility\nof our methods on a classification benchmark of brain cancer MRI data. First,\nwe present a capsule network that explicitly learns a representation robust to\nrotation and affine transformation. This model requires less training data and\noutperforms both the original convolutional baseline and a previous capsule\nnetwork implementation. Second, we leverage the latest domain adaptation\ntechniques to achieve a new state-of-the-art accuracy. Our experiments show\nthat non-medical images can be used to improve model performance. Finally, we\ndesign a spiking neural network trained on the Intel Loihi neuromorphic chip\n(Fig. 1 shows an inference snapshot). This model consumes much lower power\nwhile achieving reasonable accuracy given model reduction. We posit that more\nresearch in this direction combining hardware and learning advancements will\npower future medical imaging (on-device AI, few-shot prediction, adaptive\nscanning).\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 20:56:37 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Getty", "Neil", ""], ["Brettin", "Thomas", ""], ["Jin", "Dong", ""], ["Stevens", "Rick", ""], ["Xia", "Fangfang", ""]]}, {"id": "2005.05434", "submitter": "Julien Grand-Cl\\'ement", "authors": "Julien Grand-Cl\\'ement, Christian Kroer", "title": "Scalable First-Order Methods for Robust MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust Markov Decision Processes (MDPs) are a powerful framework for modeling\nsequential decision-making problems with model uncertainty. This paper proposes\nthe first first-order framework for solving robust MDPs. Our algorithm\ninterleaves primal-dual first-order updates with approximate Value Iteration\nupdates. By carefully controlling the tradeoff between the accuracy and cost of\nValue Iteration updates, we achieve an ergodic convergence rate of $O \\left(\nA^{2} S^{3}\\log(S)\\log(\\epsilon^{-1}) \\epsilon^{-1} \\right)$ for the best\nchoice of parameters on ellipsoidal and Kullback-Leibler $s$-rectangular\nuncertainty sets, where $S$ and $A$ is the number of states and actions,\nrespectively. Our dependence on the number of states and actions is\nsignificantly better (by a factor of $O(A^{1.5}S^{1.5})$) than that of pure\nValue Iteration algorithms. In numerical experiments on ellipsoidal uncertainty\nsets we show that our algorithm is significantly more scalable than\nstate-of-the-art approaches. Our framework is also the first one to solve\nrobust MDPs with $s$-rectangular KL uncertainty sets.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 21:06:22 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 13:16:12 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 13:35:12 GMT"}, {"version": "v4", "created": "Mon, 14 Sep 2020 23:20:32 GMT"}, {"version": "v5", "created": "Thu, 14 Jan 2021 21:06:53 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Grand-Cl\u00e9ment", "Julien", ""], ["Kroer", "Christian", ""]]}, {"id": "2005.05440", "submitter": "Baiming Chen", "authors": "Baiming Chen, Mengdi Xu, Liang Li, Ding Zhao", "title": "Delay-Aware Model-Based Reinforcement Learning for Continuous Control", "comments": null, "journal-ref": "Neurocomputing Volume 450, 25 August 2021, Pages 119-128", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Action delays degrade the performance of reinforcement learning in many\nreal-world systems. This paper proposes a formal definition of delay-aware\nMarkov Decision Process and proves it can be transformed into standard MDP with\naugmented states using the Markov reward process. We develop a delay-aware\nmodel-based reinforcement learning framework that can incorporate the\nmulti-step delay into the learned system models without learning effort.\nExperiments with the Gym and MuJoCo platforms show that the proposed\ndelay-aware model-based algorithm is more efficient in training and\ntransferable between systems with various durations of delay compared with\noff-policy model-free reinforcement learning methods. Codes available at:\nhttps://github.com/baimingc/dambrl.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 21:13:37 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Chen", "Baiming", ""], ["Xu", "Mengdi", ""], ["Li", "Liang", ""], ["Zhao", "Ding", ""]]}, {"id": "2005.05441", "submitter": "Baiming Chen", "authors": "Baiming Chen, Mengdi Xu, Zuxin Liu, Liang Li, Ding Zhao", "title": "Delay-Aware Multi-Agent Reinforcement Learning for Cooperative and\n  Competitive Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Action and observation delays exist prevalently in the real-world\ncyber-physical systems which may pose challenges in reinforcement learning\ndesign. It is particularly an arduous task when handling multi-agent systems\nwhere the delay of one agent could spread to other agents. To resolve this\nproblem, this paper proposes a novel framework to deal with delays as well as\nthe non-stationary training issue of multi-agent tasks with model-free deep\nreinforcement learning. We formally define the Delay-Aware Markov Game that\nincorporates the delays of all agents in the environment. To solve Delay-Aware\nMarkov Games, we apply centralized training and decentralized execution that\nallows agents to use extra information to ease the non-stationarity issue of\nthe multi-agent systems during training, without the need of a centralized\ncontroller during execution. Experiments are conducted in multi-agent particle\nenvironments including cooperative communication, cooperative navigation, and\ncompetitive experiments. We also test the proposed algorithm in traffic\nscenarios that require coordination of all autonomous vehicles to show the\npractical value of delay-awareness. Results show that the proposed delay-aware\nmulti-agent reinforcement learning algorithm greatly alleviates the performance\ndegradation introduced by delay. Codes and demo videos are available at:\nhttps://github.com/baimingc/delay-aware-MARL.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 21:21:50 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 01:27:43 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Chen", "Baiming", ""], ["Xu", "Mengdi", ""], ["Liu", "Zuxin", ""], ["Li", "Liang", ""], ["Zhao", "Ding", ""]]}, {"id": "2005.05442", "submitter": "Xingyi Yang", "authors": "Wenmian Yang, Guangtao Zeng, Bowen Tan, Zeqian Ju, Subrato\n  Chakravorty, Xuehai He, Shu Chen, Xingyi Yang, Qingyang Wu, Zhou Yu, Eric\n  Xing, Pengtao Xie", "title": "On the Generation of Medical Dialogues for COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under the pandemic of COVID-19, people experiencing COVID19-related symptoms\nor exposed to risk factors have a pressing need to consult doctors. Due to\nhospital closure, a lot of consulting services have been moved online. Because\nof the shortage of medical professionals, many people cannot receive online\nconsultations timely. To address this problem, we aim to develop a medical\ndialogue system that can provide COVID19-related consultations. We collected\ntwo dialogue datasets -- CovidDialog -- (in English and Chinese respectively)\ncontaining conversations between doctors and patients about COVID-19. On these\ntwo datasets, we train several dialogue generation models based on Transformer,\nGPT, and BERT-GPT. Since the two COVID-19 dialogue datasets are small in size,\nwhich bear high risk of overfitting, we leverage transfer learning to mitigate\ndata deficiency. Specifically, we take the pretrained models of Transformer,\nGPT, and BERT-GPT on dialog datasets and other large-scale texts, then finetune\nthem on our CovidDialog tasks. We perform both automatic and human evaluation\nof responses generated by these models. The results show that the generated\nresponses are promising in being doctor-like, relevant to the conversation\nhistory, and clinically informative. The data and code are available at\nhttps://github.com/UCSD-AI4H/COVID-Dialogue.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 21:23:43 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 02:06:58 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Yang", "Wenmian", ""], ["Zeng", "Guangtao", ""], ["Tan", "Bowen", ""], ["Ju", "Zeqian", ""], ["Chakravorty", "Subrato", ""], ["He", "Xuehai", ""], ["Chen", "Shu", ""], ["Yang", "Xingyi", ""], ["Wu", "Qingyang", ""], ["Yu", "Zhou", ""], ["Xing", "Eric", ""], ["Xie", "Pengtao", ""]]}, {"id": "2005.05447", "submitter": "Irene Nandutu", "authors": "Irene Nandutu, Ernest Mwebaze", "title": "Luganda Text-to-Speech Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Uganda, Luganda is the most spoken native language. It is used for\ncommunication in informal as well as formal business transactions. The\ndevelopment of technology startups globally related to TTS has mainly been with\nlanguages like English, French, etc. These are added in TTS engines by Google,\nMicrosoft among others, allowing developers in these regions to innovate TTS\nproducts. Luganda is not supported because the language is not built and\ntrained on these engines. In this study, we analyzed the Luganda language\nstructure and constructions and then proposed and developed a Luganda TTS. The\nsystem was built and trained using locally sourced Luganda language text and\naudio. The engine is now able to capture text and reads it aloud. We tested the\naccuracy using MRT and MOS. MRT and MOS tests results are quite good with MRT\nhaving better results. The results general score was 71%. This study will\nenhance previous solutions to NLP gaps in Uganda, as well as provide raw data\nsuch that other research in this area can take place.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 21:33:33 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Nandutu", "Irene", ""], ["Mwebaze", "Ernest", ""]]}, {"id": "2005.05451", "submitter": "Arjun Gupta", "authors": "Arjun Gupta and Luca Carlone", "title": "Online Monitoring for Neural Network Based Monocular Pedestrian Pose\n  Estimation", "comments": "Accepted to ITSC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Several autonomy pipelines now have core components that rely on deep\nlearning approaches. While these approaches work well in nominal conditions,\nthey tend to have unexpected and severe failure modes that create concerns when\nused in safety-critical applications, including self-driving cars. There are\nseveral works that aim to characterize the robustness of networks offline, but\ncurrently there is a lack of tools to monitor the correctness of network\noutputs online during operation. We investigate the problem of online output\nmonitoring for neural networks that estimate 3D human shapes and poses from\nimages. Our first contribution is to present and evaluate model-based and\nlearning-based monitors for a human-pose-and-shape reconstruction network, and\nassess their ability to predict the output loss for a given test input. As a\nsecond contribution, we introduce an Adversarially-Trained Online Monitor (\nATOM ) that learns how to effectively predict losses from data. ATOM dominates\nmodel-based baselines and can detect bad outputs, leading to substantial\nimprovements in human pose output quality. Our final contribution is an\nextensive experimental evaluation that shows that discarding outputs flagged as\nincorrect by ATOM improves the average error by 12.5%, and the worst-case error\nby 126.5%.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 21:40:41 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Gupta", "Arjun", ""], ["Carlone", "Luca", ""]]}, {"id": "2005.05456", "submitter": "Changkyu Song", "authors": "Changkyu Song and Abdeslam Boularias", "title": "Learning to Slide Unknown Objects with Differentiable Physics\n  Simulations", "comments": "to be published in Robotics: Science and Systems, July 12-16, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new technique for pushing an unknown object from an initial\nconfiguration to a goal configuration with stability constraints. The proposed\nmethod leverages recent progress in differentiable physics models to learn\nunknown mechanical properties of pushed objects, such as their distributions of\nmass and coefficients of friction. The proposed learning technique computes the\ngradient of the distance between predicted poses of objects and their actual\nobserved poses and utilizes that gradient to search for values of the\nmechanical properties that reduce the reality gap. The proposed approach is\nalso utilized to optimize a policy to efficiently push an object toward the\ndesired goal configuration. Experiments with real objects using a real robot to\ngather data show that the proposed approach can identify the mechanical\nproperties of heterogeneous objects from a small number of pushing actions.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 21:53:33 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 01:07:23 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Song", "Changkyu", ""], ["Boularias", "Abdeslam", ""]]}, {"id": "2005.05487", "submitter": "Takashi Morita", "authors": "Takashi Morita and Hiroki Koda", "title": "Exploring TTS without T Using Biologically/Psychologically Motivated\n  Neural Network Modules (ZeroSpeech 2020)", "comments": "Accepted in INTERSPEECH 2020", "journal-ref": null, "doi": "10.21437/Interspeech.2020-3127", "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we reported our exploration of Text-To-Speech without Text\n(TTS without T) in the Zero Resource Speech Challenge 2020, in which\nparticipants proposed an end-to-end, unsupervised system that learned speech\nrecognition and TTS together. We addressed the challenge using\nbiologically/psychologically motivated modules of Artificial Neural Networks\n(ANN), with a particular interest in unsupervised learning of human language as\na biological/psychological problem. The system first processes Mel Frequency\nCepstral Coefficient (MFCC) frames with an Echo-State Network (ESN), and\nsimulates computations in cortical microcircuits. The outcome is discretized by\nour original Variational Autoencoder (VAE) that implements the Dirichlet-based\nBayesian clustering widely accepted in computational linguistics and cognitive\nscience. The discretized signal is then reverted into sound waveform via a\nneural-network implementation of the source-filter model for speech production.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 23:44:37 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 09:18:57 GMT"}, {"version": "v3", "created": "Mon, 10 Aug 2020 09:13:40 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Morita", "Takashi", ""], ["Koda", "Hiroki", ""]]}, {"id": "2005.05490", "submitter": "David Suter", "authors": "David Suter, Ruwan Tennakoon, Erchuan Zhang, Tat-Jun Chin and Alireza\n  Bab-Hadiashar", "title": "Monotone Boolean Functions, Feasibility/Infeasibility, LP-type problems\n  and MaxCon", "comments": "Parts under conference review, work in progress. Keywords: Monotone\n  Boolean Functions, Consensus Maximisation, LP-Type Problem, Computer Vision,\n  Robust Fitting, Matroid, Simplicial Complex, Independence Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper outlines connections between Monotone Boolean Functions, LP-Type\nproblems and the Maximum Consensus Problem. The latter refers to a particular\ntype of robust fitting characterisation, popular in Computer Vision (MaxCon).\nIndeed, this is our main motivation but we believe the results of the study of\nthese connections are more widely applicable to LP-type problems (at least\n'thresholded versions', as we describe), and perhaps even more widely. We\nillustrate, with examples from Computer Vision, how the resulting perspectives\nsuggest new algorithms. Indeed, we focus, in the experimental part, on how the\nInfluence (a property of Boolean Functions that takes on a special form if the\nfunction is Monotone) can guide a search for the MaxCon solution.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 23:51:15 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Suter", "David", ""], ["Tennakoon", "Ruwan", ""], ["Zhang", "Erchuan", ""], ["Chin", "Tat-Jun", ""], ["Bab-Hadiashar", "Alireza", ""]]}, {"id": "2005.05496", "submitter": "Saeid Asgari Taghanaki", "authors": "Saeid Asgari Taghanaki, Mohammad Havaei, Alex Lamb, Aditya Sanghi, Ara\n  Danielyan, Tonya Custis", "title": "Jigsaw-VAE: Towards Balancing Features in Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The latent variables learned by VAEs have seen considerable interest as an\nunsupervised way of extracting features, which can then be used for downstream\ntasks. There is a growing interest in the question of whether features learned\non one environment will generalize across different environments. We\ndemonstrate here that VAE latent variables often focus on some factors of\nvariation at the expense of others - in this case we refer to the features as\n``imbalanced''. Feature imbalance leads to poor generalization when the latent\nvariables are used in an environment where the presence of features changes.\nSimilarly, latent variables trained with imbalanced features induce the VAE to\ngenerate less diverse (i.e. biased towards dominant features) samples. To\naddress this, we propose a regularization scheme for VAEs, which we show\nsubstantially addresses the feature imbalance problem. We also introduce a\nsimple metric to measure the balance of features in generated images.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 00:46:54 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Taghanaki", "Saeid Asgari", ""], ["Havaei", "Mohammad", ""], ["Lamb", "Alex", ""], ["Sanghi", "Aditya", ""], ["Danielyan", "Ara", ""], ["Custis", "Tonya", ""]]}, {"id": "2005.05502", "submitter": "Rui Wang", "authors": "Eliza Huang, Rui Wang, Uma Chandrasekaran, Rose Yu", "title": "Aortic Pressure Forecasting with Deep Sequence Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mean aortic pressure (MAP) is a major determinant of perfusion in all organs\nsystems. The ability to forecast MAP would enhance the ability of physicians to\nestimate prognosis of the patient and assist in early detection of hemodynamic\ninstability. However, forecasting MAP is challenging because the blood pressure\n(BP) time series is noisy and can be highly non-stationary. The aim of this\nstudy was to forecast the mean aortic pressure five minutes in advance, using\nthe 25 Hz time series data of previous five minutes as input. We provide a\nbenchmark study of different deep learning models for BP forecasting. We\ninvestigate a left ventricular dwelling transvalvular micro-axial device, the\nImpella, in patients undergoing high-risk percutaneous intervention. The\nImpella provides hemodynamic support, thus aiding in native heart function\nrecovery. It is also equipped with pressure sensors to capture high frequency\nMAP measurements at origin, instead of peripherally. Our dataset and the\nclinical application is novel in the BP forecasting field. We performed a\ncomprehensive study on time series with increasing, decreasing, and stationary\ntrends. The experiments show that recurrent neural networks with Legendre\nMemory Unit achieve the best performance with an overall forecasting error of\n1.8 mmHg.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 01:07:25 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 21:47:58 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 18:53:02 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Huang", "Eliza", ""], ["Wang", "Rui", ""], ["Chandrasekaran", "Uma", ""], ["Yu", "Rose", ""]]}, {"id": "2005.05509", "submitter": "Mohammad Rami Koujan", "authors": "Mohammad Rami Koujan, Luma Alharbawee, Giorgos Giannakakis, Nicolas\n  Pugeault, Anastasios Roussos", "title": "Real-time Facial Expression Recognition \"In The Wild'' by Disentangling\n  3D Expression from Identity", "comments": "to be published in 15th IEEE International Conference on Automatic\n  Face and Gesture Recognition (FG 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human emotions analysis has been the focus of many studies, especially in the\nfield of Affective Computing, and is important for many applications, e.g.\nhuman-computer intelligent interaction, stress analysis, interactive games,\nanimations, etc. Solutions for automatic emotion analysis have also benefited\nfrom the development of deep learning approaches and the availability of vast\namount of visual facial data on the internet. This paper proposes a novel\nmethod for human emotion recognition from a single RGB image. We construct a\nlarge-scale dataset of facial videos (\\textbf{FaceVid}), rich in facial\ndynamics, identities, expressions, appearance and 3D pose variations. We use\nthis dataset to train a deep Convolutional Neural Network for estimating\nexpression parameters of a 3D Morphable Model and combine it with an effective\nback-end emotion classifier. Our proposed framework runs at 50 frames per\nsecond and is capable of robustly estimating parameters of 3D expression\nvariation and accurately recognizing facial expressions from in-the-wild\nimages. We present extensive experimental evaluation that shows that the\nproposed method outperforms the compared techniques in estimating the 3D\nexpression parameters and achieves state-of-the-art performance in recognising\nthe basic emotions from facial images, as well as recognising stress from\nfacial videos. %compared to the current state of the art in emotion recognition\nfrom facial images.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 01:32:55 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Koujan", "Mohammad Rami", ""], ["Alharbawee", "Luma", ""], ["Giannakakis", "Giorgos", ""], ["Pugeault", "Nicolas", ""], ["Roussos", "Anastasios", ""]]}, {"id": "2005.05510", "submitter": "Jing Pan", "authors": "Jing Pan, Wendao Liu, Jing Zhou", "title": "Benchmark Tests of Convolutional Neural Network and Graph Convolutional\n  Network on HorovodRunner Enabled Spark Clusters", "comments": "AAAI 2020 W8 Deep Learning on Graphs: Methodologies and Applications\n  Accepted Poster Number 23", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The freedom of fast iterations of distributed deep learning tasks is crucial\nfor smaller companies to gain competitive advantages and market shares from big\ntech giants. HorovodRunner brings this process to relatively accessible spark\nclusters. There have been, however, no benchmark tests on HorovodRunner per se,\nnor specifically graph convolutional network (GCN, hereafter), and very limited\nscalability benchmark tests on Horovod, the predecessor requiring custom built\nGPU clusters. For the first time, we show that Databricks' HorovodRunner\nachieves significant lift in scaling efficiency for the convolutional neural\nnetwork (CNN, hereafter) based tasks on both GPU and CPU clusters, but not the\noriginal GCN task. We also implemented the Rectified Adam optimizer for the\nfirst time in HorovodRunner.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 01:36:43 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Pan", "Jing", ""], ["Liu", "Wendao", ""], ["Zhou", "Jing", ""]]}, {"id": "2005.05535", "submitter": "Liu Kunlin", "authors": "Ivan Perov, Daiheng Gao, Nikolay Chervoniy, Kunlin Liu, Sugasa\n  Marangonda, Chris Um\\'e, Mr. Dpfks, Carl Shift Facenheim, Luis RP, Jian\n  Jiang, Sheng Zhang, Pingyu Wu, Bo Zhou, Weiming Zhang", "title": "DeepFaceLab: Integrated, flexible and extensible face-swapping framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deepfake defense not only requires the research of detection but also\nrequires the efforts of generation methods. However, current deepfake methods\nsuffer the effects of obscure workflow and poor performance. To solve this\nproblem, we present DeepFaceLab, the current dominant deepfake framework for\nface-swapping. It provides the necessary tools as well as an easy-to-use way to\nconduct high-quality face-swapping. It also offers a flexible and loose\ncoupling structure for people who need to strengthen their pipeline with other\nfeatures without writing complicated boilerplate code. We detail the principles\nthat drive the implementation of DeepFaceLab and introduce its pipeline,\nthrough which every aspect of the pipeline can be modified painlessly by users\nto achieve their customization purpose. It is noteworthy that DeepFaceLab could\nachieve cinema-quality results with high fidelity. We demonstrate the advantage\nof our system by comparing our approach with other face-swapping methods.For\nmore information, please visit:https://github.com/iperov/DeepFaceLab/.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 03:26:55 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 09:00:36 GMT"}, {"version": "v3", "created": "Thu, 14 May 2020 14:40:07 GMT"}, {"version": "v4", "created": "Wed, 20 May 2020 06:33:52 GMT"}, {"version": "v5", "created": "Tue, 29 Jun 2021 07:07:57 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Perov", "Ivan", ""], ["Gao", "Daiheng", ""], ["Chervoniy", "Nikolay", ""], ["Liu", "Kunlin", ""], ["Marangonda", "Sugasa", ""], ["Um\u00e9", "Chris", ""], ["Dpfks", "Mr.", ""], ["Facenheim", "Carl Shift", ""], ["RP", "Luis", ""], ["Jiang", "Jian", ""], ["Zhang", "Sheng", ""], ["Wu", "Pingyu", ""], ["Zhou", "Bo", ""], ["Zhang", "Weiming", ""]]}, {"id": "2005.05537", "submitter": "Hanchen Wang", "authors": "Hanchen Wang, Defu Lian, Ying Zhang, Lu Qin, Xuemin Lin", "title": "GoGNN: Graph of Graphs Neural Network for Predicting Structured Entity\n  Interactions", "comments": "Accepted by IJCAI 2020", "journal-ref": null, "doi": "10.24963/ijcai.2020/183", "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity interaction prediction is essential in many important applications\nsuch as chemistry, biology, material science, and medical science. The problem\nbecomes quite challenging when each entity is represented by a complex\nstructure, namely structured entity, because two types of graphs are involved:\nlocal graphs for structured entities and a global graph to capture the\ninteractions between structured entities. We observe that existing works on\nstructured entity interaction prediction cannot properly exploit the unique\ngraph of graphs model. In this paper, we propose a Graph of Graphs Neural\nNetwork, namely GoGNN, which extracts the features in both structured entity\ngraphs and the entity interaction graph in a hierarchical way. We also propose\nthe dual-attention mechanism that enables the model to preserve the neighbor\nimportance in both levels of graphs. Extensive experiments on real-world\ndatasets show that GoGNN outperforms the state-of-the-art methods on two\nrepresentative structured entity interaction prediction tasks:\nchemical-chemical interaction prediction and drug-drug interaction prediction.\nOur code is available at Github.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 03:46:15 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Wang", "Hanchen", ""], ["Lian", "Defu", ""], ["Zhang", "Ying", ""], ["Qin", "Lu", ""], ["Lin", "Xuemin", ""]]}, {"id": "2005.05541", "submitter": "Shiyu Duan", "authors": "Shiyu Duan, Shujian Yu, Jose Principe", "title": "Modularizing Deep Learning via Pairwise Learning With Kernels", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By redefining the conventional notions of layers, we present an alternative\nview on finitely wide, fully trainable deep neural networks as stacked linear\nmodels in feature spaces, leading to a kernel machine interpretation. Based on\nthis construction, we then propose a provably optimal modular learning\nframework for classification that does not require between-module\nbackpropagation. This modular approach brings new insights into the label\nrequirement of deep learning: It leverages only implicit pairwise labels (weak\nsupervision) when learning the hidden modules. When training the output module,\non the other hand, it requires full supervision but achieves high label\nefficiency, needing as few as 10 randomly selected labeled examples (one from\neach class) to achieve 94.88% accuracy on CIFAR-10 using a ResNet-18 backbone.\nMoreover, modular training enables fully modularized deep learning workflows,\nwhich then simplify the design and implementation of pipelines and improve the\nmaintainability and reusability of models. To showcase the advantages of such a\nmodularized workflow, we describe a simple yet reliable method for estimating\nreusability of pre-trained modules as well as task transferability in a\ntransfer learning setting. At practically no computation overhead, it precisely\ndescribed the task space structure of 15 binary classification tasks from\nCIFAR-10.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 04:19:37 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 18:09:47 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Duan", "Shiyu", ""], ["Yu", "Shujian", ""], ["Principe", "Jose", ""]]}, {"id": "2005.05546", "submitter": "Yoonkyung Lee", "authors": "Jiae Kim, Yoonkyung Lee and Zhiyu Liang", "title": "The Geometry of Nonlinear Embeddings in Kernel Discriminant Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fisher's linear discriminant analysis is a classical method for\nclassification, yet it is limited to capturing linear features only. Kernel\ndiscriminant analysis as an extension is known to successfully alleviate the\nlimitation through a nonlinear feature mapping. We study the geometry of\nnonlinear embeddings in discriminant analysis with polynomial kernels and\nGaussian kernel by identifying the population-level discriminant function that\ndepends on the data distribution and the kernel. In order to obtain the\ndiscriminant function, we solve a generalized eigenvalue problem with\nbetween-class and within-class covariance operators. The polynomial\ndiscriminants are shown to capture the class difference through the population\nmoments explicitly. For approximation of the Gaussian discriminant, we use a\nparticular representation of the Gaussian kernel by utilizing the exponential\ngenerating function for Hermite polynomials. We also show that the Gaussian\ndiscriminant can be approximated using randomized projections of the data. Our\nresults illuminate how the data distribution and the kernel interact in\ndetermination of the nonlinear embedding for discrimination, and provide a\nguideline for choice of the kernel and its parameters.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 04:46:31 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Kim", "Jiae", ""], ["Lee", "Yoonkyung", ""], ["Liang", "Zhiyu", ""]]}, {"id": "2005.05550", "submitter": "Seyed Amir Hossein Hosseini", "authors": "Seyed Amir Hossein Hosseini, Burhaneddin Yaman, Steen Moeller, and\n  Mehmet Ak\\c{c}akaya", "title": "High-Fidelity Accelerated MRI Reconstruction by Scan-Specific\n  Fine-Tuning of Physics-Based Neural Networks", "comments": null, "journal-ref": "Proceedings of IEEE EMBC, 2020", "doi": "10.1109/EMBC44109.2020.9176241", "report-no": null, "categories": "eess.IV cs.CV cs.LG eess.SP physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long scan duration remains a challenge for high-resolution MRI. Deep learning\nhas emerged as a powerful means for accelerated MRI reconstruction by providing\ndata-driven regularizers that are directly learned from data. These data-driven\npriors typically remain unchanged for future data in the testing phase once\nthey are learned during training. In this study, we propose to use a transfer\nlearning approach to fine-tune these regularizers for new subjects using a\nself-supervision approach. While the proposed approach can compromise the\nextremely fast reconstruction time of deep learning MRI methods, our results on\nknee MRI indicate that such adaptation can substantially reduce the remaining\nartifacts in reconstructed images. In addition, the proposed approach has the\npotential to reduce the risks of generalization to rare pathological\nconditions, which may be unavailable in the training data.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 05:10:10 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Hosseini", "Seyed Amir Hossein", ""], ["Yaman", "Burhaneddin", ""], ["Moeller", "Steen", ""], ["Ak\u00e7akaya", "Mehmet", ""]]}, {"id": "2005.05556", "submitter": "Zhe Liu", "authors": "Zhe Liu, Yun Li, Lina Yao, Xianzhi Wang and Feiping Nie", "title": "Agglomerative Neural Networks for Multi-view Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional multi-view clustering methods seek for a view consensus through\nminimizing the pairwise discrepancy between the consensus and subviews.\nHowever, the pairwise comparison cannot portray the inter-view relationship\nprecisely if some of the subviews can be further agglomerated. To address the\nabove challenge, we propose the agglomerative analysis to approximate the\noptimal consensus view, thereby describing the subview relationship within a\nview structure. We present Agglomerative Neural Network (ANN) based on\nConstrained Laplacian Rank to cluster multi-view data directly while avoiding a\ndedicated postprocessing step (e.g., using K-means). We further extend ANN with\nlearnable data space to handle data of complex scenarios. Our evaluations\nagainst several state-of-the-art multi-view clustering approaches on four\npopular datasets show the promising view-consensus analysis ability of ANN. We\nfurther demonstrate ANN's capability in analyzing complex view structures and\nextensibility in our case study and explain its robustness and effectiveness of\ndata-driven modifications.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 05:39:10 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Liu", "Zhe", ""], ["Li", "Yun", ""], ["Yao", "Lina", ""], ["Wang", "Xianzhi", ""], ["Nie", "Feiping", ""]]}, {"id": "2005.05559", "submitter": "Sumit Raurale", "authors": "Sumit A. Raurale, Geraldine B. Boylan, Gordon Lightbody and John M.\n  O'Toole", "title": "Identifying trace alternant activity in neonatal EEG using an\n  inter-burst detection approach", "comments": "4 pages, to be appearing in upcoming 2020 EMBC Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalography (EEG) is an important clinical tool for reviewing\nsleep-wake cycling in neonates in intensive care. Trace alternant (TA)-a\ncharacteristic pattern of EEG activity during quiet sleep in term neonates-is\ndefined by alternating periods of short-duration, high-voltage activity\n(bursts) separated by lower-voltage activity (inter-bursts). This study\npresents a novel approach for detecting TA activity by first detecting the\ninter-bursts and then processing the temporal map of the bursts and\ninter-bursts. EEG recordings from 72 healthy term neonates were used to develop\nand evaluate performance of 1) an inter-burst detection method which is then\nused for 2) detection of TA activity. First, multiple amplitude and spectral\nfeatures were combined using a support vector machine (SVM) to classify bursts\nfrom inter-bursts within TA activity, resulting in a median area under the\noperating characteristic curve (AUC) of 0.95 (95% confidence interval, CI: 0.93\nto 0.98). Second, post-processing of the continuous SVM output, the confidence\nscore, was used to produce a TA envelope. This envelope was used to detect TA\nactivity within the continuous EEG with a median AUC of 0.84 (95% CI: 0.80 to\n0.88). These results validate how an inter-burst detection approach combined\nwith post processing can be used to classify TA activity. Detecting the\npresence or absence of TA will help quantify disruption of the clinically\nimportant sleep-wake cycle.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 05:50:10 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Raurale", "Sumit A.", ""], ["Boylan", "Geraldine B.", ""], ["Lightbody", "Gordon", ""], ["O'Toole", "John M.", ""]]}, {"id": "2005.05561", "submitter": "Sumit Raurale PhD", "authors": "Sumit A. Raurale, Geraldine B. Boylan, Gordon Lightbody and John M.\n  O'Toole", "title": "Grading the severity of hypoxic-ischemic encephalopathy in newborn EEG\n  using a convolutional neural network", "comments": "4 pages, to be appearing in upcoming 2020 EMBC Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalography (EEG) is a valuable clinical tool for grading injury\ncaused by lack of blood and oxygen to the brain during birth. This study\npresents a novel end-to-end architecture, using a deep convolutional neural\nnetwork, that learns hierarchical representations within raw EEG data. The\nsystem classifies 4 grades of hypoxic-ischemic encephalopathy and is evaluated\non a multi-channel EEG dataset of 63 hours from 54 newborns. The proposed\nmethod achieves a testing accuracy of 79.6% with one-step voting and 81.5% with\ntwo-step voting. These results show how a feature-free approach can be used to\nclassify different grades of injury in newborn EEG with comparable accuracy to\nexisting feature-based systems. Automated grading of newborn background EEG\ncould help with the early identification of those infants in need of\ninterventional therapies such as hypothermia.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 05:58:27 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Raurale", "Sumit A.", ""], ["Boylan", "Geraldine B.", ""], ["Lightbody", "Gordon", ""], ["O'Toole", "John M.", ""]]}, {"id": "2005.05570", "submitter": "Rakesh Chada", "authors": "Rakesh Chada", "title": "Simultaneous paraphrasing and translation by fine-tuning Transformer\n  models", "comments": "Accepted to ACL 2020 4th workshop on Neural Generation and\n  Translation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the third place submission to the shared task on\nsimultaneous translation and paraphrasing for language education at the 4th\nworkshop on Neural Generation and Translation (WNGT) for ACL 2020. The final\nsystem leverages pre-trained translation models and uses a Transformer\narchitecture combined with an oversampling strategy to achieve a competitive\nperformance. This system significantly outperforms the baseline on Hungarian\n(27% absolute improvement in Weighted Macro F1 score) and Portuguese (33%\nabsolute improvement) languages.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 06:34:42 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Chada", "Rakesh", ""]]}, {"id": "2005.05576", "submitter": "Chulhong Kim", "authors": "Sampa Misra, Seungwan Jeon, Seiyon Lee, Ravi Managuli, and Chulhong\n  Kim", "title": "Multi-Channel Transfer Learning of Chest X-ray Images for Screening of\n  COVID-19", "comments": "7 pages, 3 figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 2019 novel coronavirus (COVID-19) has spread rapidly all over the world\nand it is affecting the whole society. The current gold standard test for\nscreening COVID-19 patients is the polymerase chain reaction test. However, the\nCOVID-19 test kits are not widely available and time-consuming. Thus, as an\nalternative, chest X-rays are being considered for quick screening. Since the\npresentation of COVID-19 in chest X-rays is varied in features and\nspecialization in reading COVID-19 chest X-rays are required thus limiting its\nuse for diagnosis. To address this challenge of reading chest X-rays by\nradiologists quickly, we present a multi-channel transfer learning model based\non ResNet architecture to facilitate the diagnosis of COVID-19 chest X-ray.\nThree ResNet-based models (Models a, b, and c) were retrained using Dataset_A\n(1579 normal and 4429 diseased), Dataset_B (4245 pneumonia and 1763\nnon-pneumonia), and Dataset_C (184 COVID-19 and 5824 Non-COVID19),\nrespectively, to classify (a) normal or diseased, (b) pneumonia or\nnon-pneumonia, and (c) COVID-19 or non-COVID19. Finally, these three models\nwere ensembled and fine-tuned using Dataset_D (1579 normal, 4245 pneumonia, and\n184 COVID-19) to classify normal, pneumonia, and COVID-19 cases. Our results\nshow that the ensemble model is more accurate than the single ResNet model,\nwhich is also re-trained using Dataset_D as it extracts more relevant semantic\nfeatures for each class. Our approach provides a precision of 94 % and a recall\nof 100%. Thus, our method could potentially help clinicians in screening\npatients for COVID-19, thus facilitating immediate triaging and treatment for\nbetter outcomes.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 07:03:46 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Misra", "Sampa", ""], ["Jeon", "Seungwan", ""], ["Lee", "Seiyon", ""], ["Managuli", "Ravi", ""], ["Kim", "Chulhong", ""]]}, {"id": "2005.05579", "submitter": "Michal Bou\\v{s}ka", "authors": "Michal Bou\\v{s}ka, Anton\\'in Nov\\'ak, P\\v{r}emysl \\v{S}\\r{u}cha,\n  Istv\\'an M\\'odos, and Zden\\v{e}k Hanz\\'alek", "title": "Data-driven Algorithm for Scheduling with Total Tardiness", "comments": null, "journal-ref": null, "doi": "10.5220/0008915300590068", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the use of deep learning for solving a\nclassical NP-Hard single machine scheduling problem where the criterion is to\nminimize the total tardiness. Instead of designing an end-to-end machine\nlearning model, we utilize well known decomposition of the problem and we\nenhance it with a data-driven approach. We have designed a regressor containing\na deep neural network that learns and predicts the criterion of a given set of\njobs. The network acts as a polynomial-time estimator of the criterion that is\nused in a single-pass scheduling algorithm based on Lawler's decomposition\ntheorem. Essentially, the regressor guides the algorithm to select the best\nposition for each job. The experimental results show that our data-driven\napproach can efficiently generalize information from the training phase to\nsignificantly larger instances (up to 350 jobs) where it achieves an optimality\ngap of about 0.5%, which is four times less than the gap of the\nstate-of-the-art NBR heuristic.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 07:16:43 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Bou\u0161ka", "Michal", ""], ["Nov\u00e1k", "Anton\u00edn", ""], ["\u0160\u016fcha", "P\u0159emysl", ""], ["M\u00f3dos", "Istv\u00e1n", ""], ["Hanz\u00e1lek", "Zden\u011bk", ""]]}, {"id": "2005.05587", "submitter": "Nils Jansen", "authors": "Dennis Gross, Nils Jansen, Guillermo A. P\\'erez, Stephan Raaijmakers", "title": "Robustness Verification for Classifier Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a formal verification procedure that decides whether a classifier\nensemble is robust against arbitrary randomized attacks. Such attacks consist\nof a set of deterministic attacks and a distribution over this set. The\nrobustness-checking problem consists of assessing, given a set of classifiers\nand a labelled data set, whether there exists a randomized attack that induces\na certain expected loss against all classifiers. We show the NP-hardness of the\nproblem and provide an upper bound on the number of attacks that is sufficient\nto form an optimal randomized attack. These results provide an effective way to\nreason about the robustness of a classifier ensemble. We provide SMT and MILP\nencodings to compute optimal randomized attacks or prove that there is no\nattack inducing a certain expected loss. In the latter case, the classifier\nensemble is provably robust. Our prototype implementation verifies multiple\nneural-network ensembles trained for image-classification tasks. The\nexperimental results using the MILP encoding are promising both in terms of\nscalability and the general applicability of our verification procedure.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 07:38:43 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 07:43:16 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Gross", "Dennis", ""], ["Jansen", "Nils", ""], ["P\u00e9rez", "Guillermo A.", ""], ["Raaijmakers", "Stephan", ""]]}, {"id": "2005.05618", "submitter": "Pedro Baptista De Castro", "authors": "Pedro Baptista de Castro, Kensei Terashima, Takafumi D Yamamoto,\n  Zhufeng Hou, Suguru Iwasaki, Ryo Matsumoto, Shintaro Adachi, Yoshito Saito,\n  Peng Song, Hiroyuki Takeya, Yoshihiko Takano", "title": "Machine Learning Guided Discovery of Gigantic Magnetocaloric Effect in\n  HoB$_{2}$ Near Hydrogen Liquefaction Temperature", "comments": "12 pages including 3 figures and 1 table + 11 pages of supplementary\n  information. Published version available at: https://rdcu.be/b36ep", "journal-ref": "NPG Asia Materials 12:35 (2020)", "doi": "10.1038/s41427-020-0214-y", "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic refrigeration exploits the magnetocaloric effect which is the\nentropy change upon application and removal of magnetic fields in materials,\nproviding an alternate path for refrigeration other than the conventional gas\ncycles. While intensive research has uncovered a vast number of magnetic\nmaterials which exhibits large magnetocaloric effect, these properties for a\nlarge number of compounds still remain unknown. To explore new functional\nmaterials in this unknown space, machine learning is used as a guide for\nselecting materials which could exhibit large magnetocaloric effect. By this\napproach, HoB$_{2}$ is singled out, synthesized and its magnetocaloric\nproperties are evaluated, leading to the experimental discovery of gigantic\nmagnetic entropy change 40.1 J kg$^{-1}$ K$^{-1}$ (0.35 J cm$^{-3}$ K$^{-1}$)\nfor a field change of 5 T in the vicinity of a ferromagnetic second-order phase\ntransition with a Curie temperature of 15 K. This is the highest value reported\nso far, to our knowledge, near the hydrogen liquefaction temperature thus it is\na highly suitable material for hydrogen liquefaction and low temperature\nmagnetic cooling applications.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 08:52:28 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["de Castro", "Pedro Baptista", ""], ["Terashima", "Kensei", ""], ["Yamamoto", "Takafumi D", ""], ["Hou", "Zhufeng", ""], ["Iwasaki", "Suguru", ""], ["Matsumoto", "Ryo", ""], ["Adachi", "Shintaro", ""], ["Saito", "Yoshito", ""], ["Song", "Peng", ""], ["Takeya", "Hiroyuki", ""], ["Takano", "Yoshihiko", ""]]}, {"id": "2005.05650", "submitter": "Mingqing Xiao", "authors": "Mingqing Xiao, Shuxin Zheng, Chang Liu, Yaolong Wang, Di He, Guolin\n  Ke, Jiang Bian, Zhouchen Lin, and Tie-Yan Liu", "title": "Invertible Image Rescaling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-resolution digital images are usually downscaled to fit various display\nscreens or save the cost of storage and bandwidth, meanwhile the post-upscaling\nis adpoted to recover the original resolutions or the details in the zoom-in\nimages. However, typical image downscaling is a non-injective mapping due to\nthe loss of high-frequency information, which leads to the ill-posed problem of\nthe inverse upscaling procedure and poses great challenges for recovering\ndetails from the downscaled low-resolution images. Simply upscaling with image\nsuper-resolution methods results in unsatisfactory recovering performance. In\nthis work, we propose to solve this problem by modeling the downscaling and\nupscaling processes from a new perspective, i.e. an invertible bijective\ntransformation, which can largely mitigate the ill-posed nature of image\nupscaling. We develop an Invertible Rescaling Net (IRN) with deliberately\ndesigned framework and objectives to produce visually-pleasing low-resolution\nimages and meanwhile capture the distribution of the lost information using a\nlatent variable following a specified distribution in the downscaling process.\nIn this way, upscaling is made tractable by inversely passing a randomly-drawn\nlatent variable with the low-resolution image through the network. Experimental\nresults demonstrate the significant improvement of our model over existing\nmethods in terms of both quantitative and qualitative evaluations of image\nupscaling reconstruction from downscaled images.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 09:55:53 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Xiao", "Mingqing", ""], ["Zheng", "Shuxin", ""], ["Liu", "Chang", ""], ["Wang", "Yaolong", ""], ["He", "Di", ""], ["Ke", "Guolin", ""], ["Bian", "Jiang", ""], ["Lin", "Zhouchen", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2005.05652", "submitter": "Thomas Tilak", "authors": "Thomas Tilak (1), Arnaud Braun (1), David Chandler (1), Nicolas David\n  (1), Sylvain Galopin (1), Am\\'elie Lombard (2), Micha\\\"el Michaud (1),\n  Camille Parisel (1), Matthieu Porte (1), and Marjorie Robert (1) ((1)\n  Institut National de l'Information G\\'eographique et Foresti\\`ere, (2)\n  CEREMA)", "title": "Very High Resolution Land Cover Mapping of Urban Areas at Global Scale\n  with Convolutional Neural Networks", "comments": "8 pages, 14 figures, ISPRS Archives of the Photogrammetry, Remote\n  Sensing and Spatial Information Sciences", "journal-ref": "XXIV ISPRS Congress, Commission III, Volume XLIII-B3-2020, 2020", "doi": "10.5194/isprs-archives-XLIII-B3-2020-201-2020", "report-no": "Volume XLIII-B3-2020", "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper describes a methodology to produce a 7-classes land cover map of\nurban areas from very high resolution images and limited noisy labeled data.\nThe objective is to make a segmentation map of a large area (a french\ndepartment) with the following classes: asphalt, bare soil, building,\ngrassland, mineral material (permeable artificialized areas), forest and water\nfrom 20cm aerial images and Digital Height Model. We created a training dataset\non a few areas of interest aggregating databases, semi-automatic\nclassification, and manual annotation to get a complete ground truth in each\nclass. A comparative study of different encoder-decoder architectures (U-Net,\nU-Net with Resnet encoders, Deeplab v3+) is presented with different loss\nfunctions. The final product is a highly valuable land cover map computed from\nmodel predictions stitched together, binarized, and refined before\nvectorization.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 10:03:20 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Tilak", "Thomas", ""], ["Braun", "Arnaud", ""], ["Chandler", "David", ""], ["David", "Nicolas", ""], ["Galopin", "Sylvain", ""], ["Lombard", "Am\u00e9lie", ""], ["Michaud", "Micha\u00ebl", ""], ["Parisel", "Camille", ""], ["Porte", "Matthieu", ""], ["Robert", "Marjorie", ""]]}, {"id": "2005.05684", "submitter": "Xinting Zhu", "authors": "Xinting Zhu and Lishuai Li", "title": "Flight Time Prediction for Fuel Loading Decisions with a Deep Learning\n  Approach", "comments": null, "journal-ref": null, "doi": "10.1016/j.trc.2021.103179", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under increasing economic and environmental pressure, airlines are constantly\nseeking new technologies and optimizing flight operations to reduce fuel\nconsumption. However, the current practice on fuel loading, which has a\nsignificant impact on aircraft weight and fuel consumption, has yet to be\nthoroughly addressed by existing studies. Excess fuel is loaded by dispatchers\nand (or) pilots to handle fuel consumption uncertainties, primarily caused by\nflight time uncertainties, which cannot be predicted by current Flight Planning\nSystems. In this paper, we develop a novel spatial weighted recurrent neural\nnetwork model to provide better flight time predictions by capturing air\ntraffic information at a national scale based on multiple data sources,\nincluding Automatic Dependent Surveillance-Broadcast, Meteorological Aerodrome\nReports, and airline records. In this model, a spatial weighted layer is\ndesigned to extract spatial dependences among network delay states. Then, a new\ntraining procedure associated with the spatial weighted layer is introduced to\nextract OD-specific spatial weights. Long short-term memory networks are used\nto extract the temporal behavior patterns of network delay states. Finally,\nfeatures from delays, weather, and flight schedules are fed into a fully\nconnected neural network to predict the flight time of a particular flight. The\nproposed model was evaluated using one year of historical data from an\nairline's real operations. Results show that our model can provide more\naccurate flight time predictions than baseline methods, especially for flights\nwith extreme delays. We also show that, with the improved flight time\nprediction, fuel loading can be optimized and resulting in reduced fuel\nconsumption by 0.016%-1.915% without increasing the fuel depletion risk.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 11:05:42 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 07:29:15 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zhu", "Xinting", ""], ["Li", "Lishuai", ""]]}, {"id": "2005.05701", "submitter": "Thomas Kurbiel", "authors": "Thomas Kurbiel and Shahrzad Khaleghian", "title": "RetinotopicNet: An Iterative Attention Mechanism Using Local Descriptors\n  with Global Context", "comments": "7 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Convolutional Neural Networks (CNNs) were the driving force behind many\nadvancements in Computer Vision research in recent years. This progress has\nspawned many practical applications and we see an increased need to efficiently\nmove CNNs to embedded systems today. However traditional CNNs lack the property\nof scale and rotation invariance: two of the most frequently encountered\ntransformations in natural images. As a consequence CNNs have to learn\ndifferent features for same objects at different scales. This redundancy is the\nmain reason why CNNs need to be very deep in order to achieve the desired\naccuracy. In this paper we develop an efficient solution by reproducing how\nnature has solved the problem in the human brain. To this end we let our CNN\noperate on small patches extracted using the log-polar transform, which is\nknown to be scale and rotation equivariant. Patches extracted in this way have\nthe nice property of magnifying the central field and compressing the\nperiphery. Hence we obtain local descriptors with global context information.\nHowever the processing of a single patch is usually not sufficient to achieve\nhigh accuracies in e.g. classification tasks. We therefore successively jump to\nseveral different locations, called saccades, thus building an understanding of\nthe whole image. Since log-polar patches contain global context information, we\ncan efficiently calculate following saccades using only the small patches.\nSaccades efficiently compensate for the lack of translation equivariance of the\nlog-polar transform.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 11:54:56 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Kurbiel", "Thomas", ""], ["Khaleghian", "Shahrzad", ""]]}, {"id": "2005.05704", "submitter": "Dania Humaidan", "authors": "Dania Humaidan, Sebastian Otte, Martin V. Butz", "title": "Fostering Event Compression using Gated Surprise", "comments": "submitted to ICANN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our brain receives a dynamically changing stream of sensorimotor data. Yet,\nwe perceive a rather organized world, which we segment into and perceive as\nevents. Computational theories of cognitive science on event-predictive\ncognition suggest that our brain forms generative, event-predictive models by\nsegmenting sensorimotor data into suitable chunks of contextual experiences.\nHere, we introduce a hierarchical, surprise-gated recurrent neural network\narchitecture, which models this process and develops compact compressions of\ndistinct event-like contexts. The architecture contains a contextual LSTM\nlayer, which develops generative compressions of ongoing and subsequent\ncontexts. These compressions are passed into a GRU-like layer, which uses\nsurprise signals to update its recurrent latent state. The latent state is\npassed forward into another LSTM layer, which processes actual dynamic sensory\nflow in the light of the provided latent, contextual compression signals. Our\nmodel shows to develop distinct event compressions and achieves the best\nperformance on multiple event processing tasks. The architecture may be very\nuseful for the further development of resource-efficient learning, hierarchical\nmodel-based reinforcement learning, as well as the development of artificial\nevent-predictive cognition and intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 11:57:46 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Humaidan", "Dania", ""], ["Otte", "Sebastian", ""], ["Butz", "Martin V.", ""]]}, {"id": "2005.05716", "submitter": "Bla\\v{z} \\v{S}krlj", "authors": "Bla\\v{z} \\v{S}krlj, Nika Er\\v{z}en, Shane Sheehan, Saturnino Luz,\n  Marko Robnik-\\v{S}ikonja, Senja Pollak", "title": "AttViz: Online exploration of self-attention for transparent neural\n  language modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language models are becoming the prevailing methodology for the tasks\nof query answering, text classification, disambiguation, completion and\ntranslation. Commonly comprised of hundreds of millions of parameters, these\nneural network models offer state-of-the-art performance at the cost of\ninterpretability; humans are no longer capable of tracing and understanding how\ndecisions are being made. The attention mechanism, introduced initially for the\ntask of translation, has been successfully adopted for other language-related\ntasks. We propose AttViz, an online toolkit for exploration of\nself-attention---real values associated with individual text tokens. We show\nhow existing deep learning pipelines can produce outputs suitable for AttViz,\noffering novel visualizations of the attention heads and their aggregations\nwith minimal effort, online. We show on examples of news segments how the\nproposed system can be used to inspect and potentially better understand what a\nmodel has learned (or emphasized).\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 12:21:40 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["\u0160krlj", "Bla\u017e", ""], ["Er\u017een", "Nika", ""], ["Sheehan", "Shane", ""], ["Luz", "Saturnino", ""], ["Robnik-\u0160ikonja", "Marko", ""], ["Pollak", "Senja", ""]]}, {"id": "2005.05719", "submitter": "Antonin Raffin", "authors": "Antonin Raffin, Jens Kober, Freek Stulp", "title": "Smooth Exploration for Robotic Reinforcement Learning", "comments": "Code: https://github.com/DLR-RM/stable-baselines3/ Training scripts:\n  https://github.com/DLR-RM/rl-baselines3-zoo/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Reinforcement learning (RL) enables robots to learn skills from interactions\nwith the real world. In practice, the unstructured step-based exploration used\nin Deep RL -- often very successful in simulation -- leads to jerky motion\npatterns on real robots. Consequences of the resulting shaky behavior are poor\nexploration, or even damage to the robot. We address these issues by adapting\nstate-dependent exploration (SDE) to current Deep RL algorithms. To enable this\nadaptation, we propose two extensions to the original SDE, using more general\nfeatures and re-sampling the noise periodically, which leads to a new\nexploration method generalized state-dependent exploration (gSDE). We evaluate\ngSDE both in simulation, on PyBullet continuous control tasks, and directly on\nthree different real robots: a tendon-driven elastic robot, a quadruped and an\nRC car. The noise sampling interval of gSDE permits to have a compromise\nbetween performance and smoothness, which allows training directly on the real\nrobots without loss of performance. The code is available at\nhttps://github.com/DLR-RM/stable-baselines3.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 12:28:25 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2021 09:49:35 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Raffin", "Antonin", ""], ["Kober", "Jens", ""], ["Stulp", "Freek", ""]]}, {"id": "2005.05727", "submitter": "Ruiying Geng", "authors": "Ruiying Geng, Binhua Li, Yongbin Li, Jian Sun, Xiaodan Zhu", "title": "Dynamic Memory Induction Networks for Few-Shot Text Classification", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes Dynamic Memory Induction Networks (DMIN) for few-shot\ntext classification. The model utilizes dynamic routing to provide more\nflexibility to memory-based few-shot learning in order to better adapt the\nsupport sets, which is a critical capacity of few-shot classification models.\nBased on that, we further develop induction models with query information,\naiming to enhance the generalization ability of meta-learning. The proposed\nmodel achieves new state-of-the-art results on the miniRCV1 and ODIC dataset,\nimproving the best performance (accuracy) by 2~4%. Detailed analysis is further\nperformed to show the effectiveness of each component.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 12:41:14 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Geng", "Ruiying", ""], ["Li", "Binhua", ""], ["Li", "Yongbin", ""], ["Sun", "Jian", ""], ["Zhu", "Xiaodan", ""]]}, {"id": "2005.05732", "submitter": "Kfir Aberman", "authors": "Kfir Aberman, Peizhuo Li, Dani Lischinski, Olga Sorkine-Hornung,\n  Daniel Cohen-Or, Baoquan Chen", "title": "Skeleton-Aware Networks for Deep Motion Retargeting", "comments": "SIGGRAPH 2020. Project page:\n  https://deepmotionediting.github.io/retargeting , Video:\n  https://www.youtube.com/watch?v=ym8Tnmiz5N8", "journal-ref": null, "doi": "10.1145/3386569.3392462", "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel deep learning framework for data-driven motion\nretargeting between skeletons, which may have different structure, yet\ncorresponding to homeomorphic graphs. Importantly, our approach learns how to\nretarget without requiring any explicit pairing between the motions in the\ntraining set. We leverage the fact that different homeomorphic skeletons may be\nreduced to a common primal skeleton by a sequence of edge merging operations,\nwhich we refer to as skeletal pooling. Thus, our main technical contribution is\nthe introduction of novel differentiable convolution, pooling, and unpooling\noperators. These operators are skeleton-aware, meaning that they explicitly\naccount for the skeleton's hierarchical structure and joint adjacency, and\ntogether they serve to transform the original motion into a collection of deep\ntemporal features associated with the joints of the primal skeleton. In other\nwords, our operators form the building blocks of a new deep motion processing\nframework that embeds the motion into a common latent space, shared by a\ncollection of homeomorphic skeletons. Thus, retargeting can be achieved simply\nby encoding to, and decoding from this latent space. Our experiments show the\neffectiveness of our framework for motion retargeting, as well as motion\nprocessing in general, compared to existing approaches. Our approach is also\nquantitatively evaluated on a synthetic dataset that contains pairs of motions\napplied to different skeletons. To the best of our knowledge, our method is the\nfirst to perform retargeting between skeletons with differently sampled\nkinematic chains, without any paired examples.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 12:51:40 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Aberman", "Kfir", ""], ["Li", "Peizhuo", ""], ["Lischinski", "Dani", ""], ["Sorkine-Hornung", "Olga", ""], ["Cohen-Or", "Daniel", ""], ["Chen", "Baoquan", ""]]}, {"id": "2005.05750", "submitter": "George Adam", "authors": "George Adam and Romain Speciel", "title": "Evaluating Ensemble Robustness Against Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples, which are slightly perturbed inputs generated with the\naim of fooling a neural network, are known to transfer between models;\nadversaries which are effective on one model will often fool another. This\nconcept of transferability poses grave security concerns as it leads to the\npossibility of attacking models in a black box setting, during which the\ninternal parameters of the target model are unknown. In this paper, we seek to\nanalyze and minimize the transferability of adversaries between models within\nan ensemble. To this end, we introduce a gradient based measure of how\neffectively an ensemble's constituent models collaborate to reduce the space of\nadversarial examples targeting the ensemble itself. Furthermore, we demonstrate\nthat this measure can be utilized during training as to increase an ensemble's\nrobustness to adversarial examples.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 13:20:54 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Adam", "George", ""], ["Speciel", "Romain", ""]]}, {"id": "2005.05751", "submitter": "Kfir Aberman", "authors": "Kfir Aberman, Yijia Weng, Dani Lischinski, Daniel Cohen-Or, Baoquan\n  Chen", "title": "Unpaired Motion Style Transfer from Video to Animation", "comments": "SIGGRAPH 2020. Project page:\n  https://deepmotionediting.github.io/style_transfer , Video:\n  https://www.youtube.com/watch?v=m04zuBSdGrc , Code:\n  https://github.com/DeepMotionEditing/deep-motion-editing", "journal-ref": null, "doi": "10.1145/3386569.3392469", "report-no": null, "categories": "cs.GR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transferring the motion style from one animation clip to another, while\npreserving the motion content of the latter, has been a long-standing problem\nin character animation. Most existing data-driven approaches are supervised and\nrely on paired data, where motions with the same content are performed in\ndifferent styles. In addition, these approaches are limited to transfer of\nstyles that were seen during training. In this paper, we present a novel\ndata-driven framework for motion style transfer, which learns from an unpaired\ncollection of motions with style labels, and enables transferring motion styles\nnot observed during training. Furthermore, our framework is able to extract\nmotion styles directly from videos, bypassing 3D reconstruction, and apply them\nto the 3D input motion. Our style transfer network encodes motions into two\nlatent codes, for content and for style, each of which plays a different role\nin the decoding (synthesis) process. While the content code is decoded into the\noutput motion by several temporal convolutional layers, the style code modifies\ndeep features via temporally invariant adaptive instance normalization (AdaIN).\nMoreover, while the content code is encoded from 3D joint rotations, we learn a\ncommon embedding for style from either 3D or 2D joint positions, enabling style\nextraction from videos. Our results are comparable to the state-of-the-art,\ndespite not requiring paired training data, and outperform other methods when\ntransferring previously unseen styles. To our knowledge, we are the first to\ndemonstrate style transfer directly from videos to 3D animations - an ability\nwhich enables one to extend the set of style examples far beyond motions\ncaptured by MoCap systems.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 13:21:27 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Aberman", "Kfir", ""], ["Weng", "Yijia", ""], ["Lischinski", "Dani", ""], ["Cohen-Or", "Daniel", ""], ["Chen", "Baoquan", ""]]}, {"id": "2005.05752", "submitter": "Yi Liu", "authors": "Yi Liu, Jialiang Peng, Jiawen Kang, Abdullah M. Iliyasu, Dusit Niyato,\n  and Ahmed A. Abd El-Latif", "title": "A Secure Federated Learning Framework for 5G Networks", "comments": "This paper was accepted by IEEE Wireless Communications Magazine", "journal-ref": null, "doi": "10.1109/MWC.01.1900525", "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) has been recently proposed as an emerging paradigm to\nbuild machine learning models using distributed training datasets that are\nlocally stored and maintained on different devices in 5G networks while\nproviding privacy preservation for participants. In FL, the central aggregator\naccumulates local updates uploaded by participants to update a global model.\nHowever, there are two critical security threats: poisoning and membership\ninference attacks. These attacks may be carried out by malicious or unreliable\nparticipants, resulting in the construction failure of global models or privacy\nleakage of FL models. Therefore, it is crucial for FL to develop security means\nof defense. In this article, we propose a blockchain-based secure FL framework\nto create smart contracts and prevent malicious or unreliable participants from\ninvolving in FL. In doing so, the central aggregator recognizes malicious and\nunreliable participants by automatically executing smart contracts to defend\nagainst poisoning attacks. Further, we use local differential privacy\ntechniques to prevent membership inference attacks. Numerical results suggest\nthat the proposed framework can effectively deter poisoning and membership\ninference attacks, thereby improving the security of FL in 5G networks.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 13:27:23 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Liu", "Yi", ""], ["Peng", "Jialiang", ""], ["Kang", "Jiawen", ""], ["Iliyasu", "Abdullah M.", ""], ["Niyato", "Dusit", ""], ["El-Latif", "Ahmed A. Abd", ""]]}, {"id": "2005.05784", "submitter": "Mengjia Xu", "authors": "Mengjia Xu, David Lopez Sanz, Pilar Garces, Fernando Maestu, Quanzheng\n  Li, Dimitrios Pantazis", "title": "A Graph Gaussian Embedding Method for Predicting Alzheimer's Disease\n  Progression with MEG Brain Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing the subtle changes of functional brain networks associated\nwith the pathological cascade of Alzheimer's disease (AD) is important for\nearly diagnosis and prediction of disease progression prior to clinical\nsymptoms. We developed a new deep learning method, termed multiple graph\nGaussian embedding model (MG2G), which can learn highly informative network\nfeatures by mapping high-dimensional resting-state brain networks into a\nlow-dimensional latent space. These latent distribution-based embeddings enable\na quantitative characterization of subtle and heterogeneous brain connectivity\npatterns at different regions and can be used as input to traditional\nclassifiers for various downstream graph analytic tasks, such as AD early stage\nprediction, and statistical evaluation of between-group significant alterations\nacross brain regions. We used MG2G to detect the intrinsic latent\ndimensionality of MEG brain networks, predict the progression of patients with\nmild cognitive impairment (MCI) to AD, and identify brain regions with network\nalterations related to MCI.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 02:29:24 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 21:00:39 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Xu", "Mengjia", ""], ["Sanz", "David Lopez", ""], ["Garces", "Pilar", ""], ["Maestu", "Fernando", ""], ["Li", "Quanzheng", ""], ["Pantazis", "Dimitrios", ""]]}, {"id": "2005.05810", "submitter": "Lucas Baier", "authors": "Lucas Baier, Josua Reimold, Niklas K\\\"uhl", "title": "Handling Concept Drift for Predictions in Business Process Mining", "comments": null, "journal-ref": "Proceedings of 2020 IEEE 22nd Conference on Business Informatics\n  (CBI)", "doi": "10.1109/CBI49978.2020.00016", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive services nowadays play an important role across all business\nsectors. However, deployed machine learning models are challenged by changing\ndata streams over time which is described as concept drift. Prediction quality\nof models can be largely influenced by this phenomenon. Therefore, concept\ndrift is usually handled by retraining of the model. However, current research\nlacks a recommendation which data should be selected for the retraining of the\nmachine learning model. Therefore, we systematically analyze different data\nselection strategies in this work. Subsequently, we instantiate our findings on\na use case in process mining which is strongly affected by concept drift. We\ncan show that we can improve accuracy from 0.5400 to 0.7010 with concept drift\nhandling. Furthermore, we depict the effects of the different data selection\nstrategies.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 14:22:24 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 13:24:30 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Baier", "Lucas", ""], ["Reimold", "Josua", ""], ["K\u00fchl", "Niklas", ""]]}, {"id": "2005.05812", "submitter": "Kashyap Rajeevsarathy", "authors": "Ambar Jain, Shivam Pal, and Kashyap Rajeevsarathy", "title": "Estimating the Cheeger constant using machine learning", "comments": "8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use machine learning to show that the Cheeger constant of a\nconnected regular graph has a predominant linear dependence on the largest two\neigenvalues of the graph spectrum. We also show that a trained deep neural\nnetwork on graphs of smaller sizes can be used as an effective estimator in\nestimating the Cheeger constant of larger graphs.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 14:24:48 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Jain", "Ambar", ""], ["Pal", "Shivam", ""], ["Rajeevsarathy", "Kashyap", ""]]}, {"id": "2005.05814", "submitter": "Debanjan Ghosh", "authors": "Debanjan Ghosh and Avijit Vajpayee and Smaranda Muresan", "title": "A Report on the 2020 Sarcasm Detection Shared Task", "comments": "2nd Workshop on Figurative Language Processing (FigLang2020) at ACL\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting sarcasm and verbal irony is critical for understanding people's\nactual sentiments and beliefs. Thus, the field of sarcasm analysis has become a\npopular research problem in natural language processing. As the community\nworking on computational approaches for sarcasm detection is growing, it is\nimperative to conduct benchmarking studies to analyze the current\nstate-of-the-art, facilitating progress in this area. We report on the shared\ntask on sarcasm detection we conducted as a part of the 2nd Workshop on\nFigurative Language Processing (FigLang 2020) at ACL 2020.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 14:27:19 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 20:31:11 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Ghosh", "Debanjan", ""], ["Vajpayee", "Avijit", ""], ["Muresan", "Smaranda", ""]]}, {"id": "2005.05815", "submitter": "Aditya M. Deshpande", "authors": "Aditya M. Deshpande and Ali A. Minai and Manish Kumar", "title": "One-Shot Recognition of Manufacturing Defects in Steel Surfaces", "comments": "Accepted for publication in NAMRC 48", "journal-ref": "Procedia Manufacturing 48 (2020) 1064-1071", "doi": "10.1016/j.promfg.2020.05.146", "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality control is an essential process in manufacturing to make the product\ndefect-free as well as to meet customer needs. The automation of this process\nis important to maintain high quality along with the high manufacturing\nthroughput. With recent developments in deep learning and computer vision\ntechnologies, it has become possible to detect various features from the images\nwith near-human accuracy. However, many of these approaches are data intensive.\nTraining and deployment of such a system on manufacturing floors may become\nexpensive and time-consuming. The need for large amounts of training data is\none of the limitations of the applicability of these approaches in real-world\nmanufacturing systems. In this work, we propose the application of a Siamese\nconvolutional neural network to do one-shot recognition for such a task. Our\nresults demonstrate how one-shot learning can be used in quality control of\nsteel by identification of defects on the steel surface. This method can\nsignificantly reduce the requirements of training data and can also be run in\nreal-time.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 14:30:03 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Deshpande", "Aditya M.", ""], ["Minai", "Ali A.", ""], ["Kumar", "Manish", ""]]}, {"id": "2005.05823", "submitter": "Justin Grana", "authors": "Justin Grana", "title": "Perturbing Inputs to Prevent Model Stealing", "comments": null, "journal-ref": "IEEE Conference on Communication and Network Securtiy, Sixth\n  Workshop on Security and Privacy in the Cloud, 2020", "doi": "10.1109/CNS48642.2020.9162336", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how perturbing inputs to machine learning services (ML-service)\ndeployed in the cloud can protect against model stealing attacks. In our\nformulation, there is an ML-service that receives inputs from users and returns\nthe output of the model. There is an attacker that is interested in learning\nthe parameters of the ML-service. We use the linear and logistic regression\nmodels to illustrate how strategically adding noise to the inputs fundamentally\nalters the attacker's estimation problem. We show that even with infinite\nsamples, the attacker would not be able to recover the true model parameters.\nWe focus on characterizing the trade-off between the error in the attacker's\nestimate of the parameters with the error in the ML-service's output.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 14:38:53 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Grana", "Justin", ""]]}, {"id": "2005.05837", "submitter": "Yancey Wang", "authors": "Yu Wang, Rong Ge and Shuang Qiu", "title": "Energy-Aware DNN Graph Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike existing work in deep neural network (DNN) graphs optimization for\ninference performance, we explore DNN graph optimization for energy awareness\nand savings for power- and resource-constrained machine learning devices. We\npresent a method that allows users to optimize energy consumption or balance\nbetween energy and inference performance for DNN graphs. This method\nefficiently searches through the space of equivalent graphs, and identifies a\ngraph and the corresponding algorithms that incur the least cost in execution.\nWe implement the method and evaluate it with multiple DNN models on a GPU-based\nmachine. Results show that our method achieves significant energy savings,\ni.e., 24% with negligible performance impact.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 14:56:19 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Wang", "Yu", ""], ["Ge", "Rong", ""], ["Qiu", "Shuang", ""]]}, {"id": "2005.05847", "submitter": "Yuan Sun", "authors": "Yuan Sun, Andreas Ernst, Xiaodong Li and Jake Weiner", "title": "Generalization of Machine Learning for Problem Reduction: A Case Study\n  on Travelling Salesman Problems", "comments": "Published as a regular article at OR Spectrum (https://rdcu.be/b6ECv)", "journal-ref": null, "doi": "10.1007/s00291-020-00604-x", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Combinatorial optimization plays an important role in real-world problem\nsolving. In the big data era, the dimensionality of a combinatorial\noptimization problem is usually very large, which poses a significant challenge\nto existing solution methods. In this paper, we examine the generalization\ncapability of a machine learning model for problem reduction on the classic\ntravelling salesman problems (TSP). We demonstrate that our method can greedily\nremove decision variables from an optimization problem that are predicted not\nto be part of an optimal solution. More specifically, we investigate our\nmodel's capability to generalize on test instances that have not been seen\nduring the training phase. We consider three scenarios where training and test\ninstances are different in terms of: 1) problem characteristics; 2) problem\nsizes; and 3) problem types. Our experiments show that this machine learning\nbased technique can generalize reasonably well over a wide range of TSP test\ninstances with different characteristics or sizes. While the accuracy of\npredicting unused variables naturally deteriorates as a test instance is\nfurther away from the training set, we observe that even when tested on a\ndifferent TSP problem variant, the machine learning model still makes useful\npredictions about which variables can be eliminated without significantly\nimpacting solution quality.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 15:09:20 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 03:13:18 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Sun", "Yuan", ""], ["Ernst", "Andreas", ""], ["Li", "Xiaodong", ""], ["Weiner", "Jake", ""]]}, {"id": "2005.05854", "submitter": "Preslav Nakov", "authors": "Giovanni Da San Martino, Shaden Shaar, Yifan Zhang, Seunghak Yu,\n  Alberto Barr\\'on-Cede\\~no, Preslav Nakov", "title": "Prta: A System to Support the Analysis of Propaganda Techniques in the\n  News", "comments": "propaganda, disinformation, fake news, media bias, COVID-19", "journal-ref": "ACL-2020", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent events, such as the 2016 US Presidential Campaign, Brexit and the\nCOVID-19 \"infodemic\", have brought into the spotlight the dangers of online\ndisinformation. There has been a lot of research focusing on fact-checking and\ndisinformation detection. However, little attention has been paid to the\nspecific rhetorical and psychological techniques used to convey propaganda\nmessages. Revealing the use of such techniques can help promote media literacy\nand critical thinking, and eventually contribute to limiting the impact of\n\"fake news\" and disinformation campaigns. Prta (Propaganda Persuasion\nTechniques Analyzer) allows users to explore the articles crawled on a regular\nbasis by highlighting the spans in which propaganda techniques occur and to\ncompare them on the basis of their use of propaganda techniques. The system\nfurther reports statistics about the use of such techniques, overall and over\ntime, or according to filtering criteria specified by the user based on time\ninterval, keywords, and/or political orientation of the media. Moreover, it\nallows users to analyze any text or URL through a dedicated interface or via an\nAPI. The system is available online: https://www.tanbih.org/prta\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 15:20:55 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Martino", "Giovanni Da San", ""], ["Shaar", "Shaden", ""], ["Zhang", "Yifan", ""], ["Yu", "Seunghak", ""], ["Barr\u00f3n-Cede\u00f1o", "Alberto", ""], ["Nakov", "Preslav", ""]]}, {"id": "2005.05859", "submitter": "Vishnu Naresh Boddeti", "authors": "Zhichao Lu, Gautam Sreekumar, Erik Goodman, Wolfgang Banzhaf,\n  Kalyanmoy Deb, and Vishnu Naresh Boddeti", "title": "Neural Architecture Transfer", "comments": "Code is available at\n  https://github.com/human-analysis/neural-architecture-transfer", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2021", "doi": "10.1109/TPAMI.2021.3052758", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) has emerged as a promising avenue for\nautomatically designing task-specific neural networks. Existing NAS approaches\nrequire one complete search for each deployment specification of hardware or\nobjective. This is a computationally impractical endeavor given the potentially\nlarge number of application scenarios. In this paper, we propose Neural\nArchitecture Transfer (NAT) to overcome this limitation. NAT is designed to\nefficiently generate task-specific custom models that are competitive under\nmultiple conflicting objectives. To realize this goal we learn task-specific\nsupernets from which specialized subnets can be sampled without any additional\ntraining. The key to our approach is an integrated online transfer learning and\nmany-objective evolutionary search procedure. A pre-trained supernet is\niteratively adapted while simultaneously searching for task-specific subnets.\nWe demonstrate the efficacy of NAT on 11 benchmark image classification tasks\nranging from large-scale multi-class to small-scale fine-grained datasets. In\nall cases, including ImageNet, NATNets improve upon the state-of-the-art under\nmobile settings ($\\leq$ 600M Multiply-Adds). Surprisingly, small-scale\nfine-grained datasets benefit the most from NAT. At the same time, the\narchitecture search and transfer is orders of magnitude more efficient than\nexisting NAS methods. Overall, the experimental evaluation indicates that,\nacross diverse image classification tasks and computational objectives, NAT is\nan appreciably more effective alternative to conventional transfer learning of\nfine-tuning weights of an existing network architecture learned on standard\ndatasets. Code is available at\nhttps://github.com/human-analysis/neural-architecture-transfer\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 15:30:36 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 00:32:53 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Lu", "Zhichao", ""], ["Sreekumar", "Gautam", ""], ["Goodman", "Erik", ""], ["Banzhaf", "Wolfgang", ""], ["Deb", "Kalyanmoy", ""], ["Boddeti", "Vishnu Naresh", ""]]}, {"id": "2005.05862", "submitter": "Souvik Chakraborty", "authors": "Souvik Chakraborty and Sondipon Adhikari", "title": "Machine learning based digital twin for dynamical systems with multiple\n  time-scales", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital twin technology has a huge potential for widespread applications in\ndifferent industrial sectors such as infrastructure, aerospace, and automotive.\nHowever, practical adoptions of this technology have been slower, mainly due to\na lack of application-specific details. Here we focus on a digital twin\nframework for linear single-degree-of-freedom structural dynamic systems\nevolving in two different operational time scales in addition to its intrinsic\ndynamic time-scale. Our approach strategically separates into two components --\n(a) a physics-based nominal model for data processing and response predictions,\nand (b) a data-driven machine learning model for the time-evolution of the\nsystem parameters. The physics-based nominal model is system-specific and\nselected based on the problem under consideration. On the other hand, the\ndata-driven machine learning model is generic. For tracking the multi-scale\nevolution of the system parameters, we propose to exploit a mixture of experts\nas the data-driven model. Within the mixture of experts model, Gaussian Process\n(GP) is used as the expert model. The primary idea is to let each expert track\nthe evolution of the system parameters at a single time-scale. For learning the\nhyperparameters of the `mixture of experts using GP', an efficient framework\nthe exploits expectation-maximization and sequential Monte Carlo sampler is\nused. Performance of the digital twin is illustrated on a multi-timescale\ndynamical system with stiffness and/or mass variations. The digital twin is\nfound to be robust and yields reasonably accurate results. One exciting feature\nof the proposed digital twin is its capability to provide reasonable\npredictions at future time-steps. Aspects related to the data quality and data\nquantity are also investigated.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 15:33:25 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 05:12:55 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Chakraborty", "Souvik", ""], ["Adhikari", "Sondipon", ""]]}, {"id": "2005.05865", "submitter": "Selim F{\\i}rat Y{\\i}lmaz", "authors": "Selim F. Yilmaz and Suleyman S. Kozat", "title": "Unsupervised Anomaly Detection via Deep Metric Learning with End-to-End\n  Optimization", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate unsupervised anomaly detection for high-dimensional data and\nintroduce a deep metric learning (DML) based framework. In particular, we learn\na distance metric through a deep neural network. Through this metric, we\nproject the data into the metric space that better separates the anomalies from\nthe normal data and reduces the effect of the curse of dimensionality for\nhigh-dimensional data. We present a novel data distillation method through\nself-supervision to remedy the conventional practice of assuming all data as\nnormal. We also employ the hard mining technique from the DML literature. We\nshow these components improve the performance of our model and significantly\nreduce the running time. Through an extensive set of experiments on the 14\nreal-world datasets, our method demonstrates significant performance gains\ncompared to the state-of-the-art unsupervised anomaly detection methods, e.g.,\nan absolute improvement between 4.44% and 11.74% on the average over the 14\ndatasets. Furthermore, we share the source code of our method on Github to\nfacilitate further research.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 15:36:21 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Yilmaz", "Selim F.", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "2005.05868", "submitter": "Neil Getty", "authors": "Neil Getty, Zixuan Zhao, Stephan Gruessner, Liaohai Chen, Fangfang Xia", "title": "Recurrent and Spiking Modeling of Sparse Surgical Kinematics", "comments": "5 pages, 8 figures, accepted ICONS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robot-assisted minimally invasive surgery is improving surgeon performance\nand patient outcomes. This innovation is also turning what has been a\nsubjective practice into motion sequences that can be precisely measured. A\ngrowing number of studies have used machine learning to analyze video and\nkinematic data captured from surgical robots. In these studies, models are\ntypically trained on benchmark datasets for representative surgical tasks to\nassess surgeon skill levels. While they have shown that novices and experts can\nbe accurately classified, it is not clear whether machine learning can separate\nhighly proficient surgeons from one another, especially without video data. In\nthis study, we explore the possibility of using only kinematic data to predict\nsurgeons of similar skill levels. We focus on a new dataset created from\nsurgical exercises on a simulation device for skill training. A simple,\nefficient encoding scheme was devised to encode kinematic sequences so that\nthey were amenable to edge learning. We report that it is possible to identify\nsurgical fellows receiving near perfect scores in the simulation exercises\nbased on their motion characteristics alone. Further, our model could be\nconverted to a spiking neural network to train and infer on the Nengo\nsimulation framework with no loss in accuracy. Overall, this study suggests\nthat building neuromorphic models from sparse motion features may be a\npotentially useful strategy for identifying surgeons and gestures with chips\ndeployed on robotic systems to offer adaptive assistance during surgery and\ntraining with additional latency and privacy benefits.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 15:41:45 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 16:01:48 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Getty", "Neil", ""], ["Zhao", "Zixuan", ""], ["Gruessner", "Stephan", ""], ["Chen", "Liaohai", ""], ["Xia", "Fangfang", ""]]}, {"id": "2005.05888", "submitter": "Ankush Chakrabarty", "authors": "Ankush Chakrabarty and Mouhacine Benosman", "title": "Safe Learning-based Observers for Unknown Nonlinear Systems using\n  Bayesian Optimization", "comments": "23 pages, post-review draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data generated from dynamical systems with unknown dynamics enable the\nlearning of state observers that are: robust to modeling error, computationally\ntractable to design, and capable of operating with guaranteed performance. In\nthis paper, a modular design methodology is formulated, that consists of three\ndesign phases: (i) an initial robust observer design that enables one to learn\nthe dynamics without allowing the state estimation error to diverge (hence,\nsafe); (ii) a learning phase wherein the unmodeled components are estimated\nusing Bayesian optimization and Gaussian processes; and, (iii) a re-design\nphase that leverages the learned dynamics to improve convergence rate of the\nstate estimation error. The potential of our proposed learning-based observer\nis demonstrated on a benchmark nonlinear system. Additionally, certificates of\nguaranteed estimation performance are provided.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 16:04:51 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 16:05:51 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Chakrabarty", "Ankush", ""], ["Benosman", "Mouhacine", ""]]}, {"id": "2005.05889", "submitter": "Borja Rodr\\'iguez G\\'alvez", "authors": "Borja Rodr\\'iguez-G\\'alvez, Germ\\'an Bassi, and Mikael Skoglund", "title": "Upper Bounds on the Generalization Error of Private Algorithms", "comments": "31 pages, 2 figures, submitted for possible publication (revised)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we study the generalization capability of algorithms from an\ninformation-theoretic perspective. It has been shown that the expected\ngeneralization error of an algorithm is bounded from above by a function of the\nrelative entropy between the conditional probability distribution of the\nalgorithm's output hypothesis, given the dataset with which it was trained, and\nits marginal probability distribution. We build upon this fact and introduce a\nmathematical formulation to obtain upper bounds on this relative entropy. We\nthen develop a strategy using this formulation, based on the method of types\nand typicality, to find explicit upper bounds on the generalization error of\nstable algorithms, i.e., algorithms that produce similar output hypotheses\ngiven similar input datasets. In particular, we show the bounds obtained with\nthis strategy for the case of $\\epsilon$-DP and $\\mu$-GDP algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 16:05:39 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 17:27:24 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Rodr\u00edguez-G\u00e1lvez", "Borja", ""], ["Bassi", "Germ\u00e1n", ""], ["Skoglund", "Mikael", ""]]}, {"id": "2005.05890", "submitter": "Benjamin Peherstorfer", "authors": "Wayne Isaac Tan Uy and Benjamin Peherstorfer", "title": "Probabilistic error estimation for non-intrusive reduced models learned\n  from data of systems governed by linear parabolic partial differential\n  equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work derives a residual-based a posteriori error estimator for reduced\nmodels learned with non-intrusive model reduction from data of high-dimensional\nsystems governed by linear parabolic partial differential equations with\ncontrol inputs. It is shown that quantities that are necessary for the error\nestimator can be either obtained exactly as the solutions of least-squares\nproblems in a non-intrusive way from data such as initial conditions, control\ninputs, and high-dimensional solution trajectories or bounded in a\nprobabilistic sense. The computational procedure follows an offline/online\ndecomposition. In the offline (training) phase, the high-dimensional system is\njudiciously solved in a black-box fashion to generate data and to set up the\nerror estimator. In the online phase, the estimator is used to bound the error\nof the reduced-model predictions for new initial conditions and new control\ninputs without recourse to the high-dimensional system. Numerical results\ndemonstrate the workflow of the proposed approach from data to reduced models\nto certified predictions.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 16:08:05 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Uy", "Wayne Isaac Tan", ""], ["Peherstorfer", "Benjamin", ""]]}, {"id": "2005.05898", "submitter": "Takayuki Katsuki", "authors": "Takayuki Katsuki, Kun Zhao, Takayuki Yoshizumi", "title": "Learning to Estimate Driver Drowsiness from Car Acceleration Sensors\n  using Weakly Labeled Data", "comments": "Accepted by ICASSP2020", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9053100", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the learning task of estimating driver drowsiness from\nthe signals of car acceleration sensors. Since even drivers themselves cannot\nperceive their own drowsiness in a timely manner unless they use burdensome\ninvasive sensors, obtaining labeled training data for each timestamp is not a\nrealistic goal. To deal with this difficulty, we formulate the task as a weakly\nsupervised learning. We only need to add labels for each complete trip, not for\nevery timestamp independently. By assuming that some aspects of driver\ndrowsiness increase over time due to tiredness, we formulate an algorithm that\ncan learn from such weakly labeled data. We derive a scalable stochastic\noptimization method as a way of implementing the algorithm. Numerical\nexperiments on real driving datasets demonstrate the advantages of our\nalgorithm against baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 16:20:25 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Katsuki", "Takayuki", ""], ["Zhao", "Kun", ""], ["Yoshizumi", "Takayuki", ""]]}, {"id": "2005.05909", "submitter": "John Morris", "authors": "John X. Morris, Eli Lifland, Jin Yong Yoo, Jake Grigsby, Di Jin and\n  Yanjun Qi", "title": "TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and\n  Adversarial Training in NLP", "comments": "6 pages. More details are shared at\n  https://github.com/QData/TextAttack", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there has been substantial research using adversarial attacks to\nanalyze NLP models, each attack is implemented in its own code repository. It\nremains challenging to develop NLP attacks and utilize them to improve model\nperformance. This paper introduces TextAttack, a Python framework for\nadversarial attacks, data augmentation, and adversarial training in NLP.\nTextAttack builds attacks from four components: a goal function, a set of\nconstraints, a transformation, and a search method. TextAttack's modular design\nenables researchers to easily construct attacks from combinations of novel and\nexisting components. TextAttack provides implementations of 16 adversarial\nattacks from the literature and supports a variety of models and datasets,\nincluding BERT and other transformers, and all GLUE tasks. TextAttack also\nincludes data augmentation and adversarial training modules for using\ncomponents of adversarial attacks to improve model accuracy and robustness.\nTextAttack is democratizing NLP: anyone can try data augmentation and\nadversarial training on any model or dataset, with just a few lines of code.\nCode and tutorials are available at https://github.com/QData/TextAttack.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 21:33:35 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 17:37:21 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 19:33:10 GMT"}, {"version": "v4", "created": "Mon, 5 Oct 2020 00:10:24 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Morris", "John X.", ""], ["Lifland", "Eli", ""], ["Yoo", "Jin Yong", ""], ["Grigsby", "Jake", ""], ["Jin", "Di", ""], ["Qi", "Yanjun", ""]]}, {"id": "2005.05913", "submitter": "Aleksandr Beznosikov", "authors": "Aleksandr Beznosikov, Abdurakhmon Sadiev, Alexander Gasnikov", "title": "Gradient-Free Methods for Saddle-Point Problem", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-58657-7_11", "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper, we generalize the approach Gasnikov et. al, 2017, which allows\nto solve (stochastic) convex optimization problems with an inexact\ngradient-free oracle, to the convex-concave saddle-point problem. The proposed\napproach works, at least, like the best existing approaches. But for a special\nset-up (simplex type constraints and closeness of Lipschitz constants in 1 and\n2 norms) our approach reduces $\\frac{n}{\\log n}$ times the required number of\noracle calls (function calculations). Our method uses a stochastic\napproximation of the gradient via finite differences. In this case, the\nfunction must be specified not only on the optimization set itself, but in a\ncertain neighbourhood of it. In the second part of the paper, we analyze the\ncase when such an assumption cannot be made, we propose a general approach on\nhow to modernize the method to solve this problem, and also we apply this\napproach to particular cases of some classical sets.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 16:44:27 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 22:03:46 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 20:59:28 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Beznosikov", "Aleksandr", ""], ["Sadiev", "Abdurakhmon", ""], ["Gasnikov", "Alexander", ""]]}, {"id": "2005.05930", "submitter": "Mantas Luko\\v{s}evi\\v{c}ius", "authors": "Arnas Uselis, Mantas Luko\\v{s}evi\\v{c}ius, Lukas Stasytis", "title": "Localized convolutional neural networks for geospatial wind forecasting", "comments": null, "journal-ref": "Energies, 13 (13), pp. 3440, 2020", "doi": "10.3390/en13133440", "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) possess many positive qualities when it\ncomes to spatial raster data. Translation invariance enables CNNs to detect\nfeatures regardless of their position in the scene. However, in some domains,\nlike geospatial, not all locations are exactly equal. In this work, we propose\nlocalized convolutional neural networks that enable convolutional architectures\nto learn local features in addition to the global ones. We investigate their\ninstantiations in the form of learnable inputs, local weights, and a more\ngeneral form. They can be added to any convolutional layers, easily end-to-end\ntrained, introduce minimal additional complexity, and let CNNs retain most of\ntheir benefits to the extent that they are needed. In this work we address\nspatio-temporal prediction: test the effectiveness of our methods on a\nsynthetic benchmark dataset and tackle three real-world wind prediction\ndatasets. For one of them, we propose a method to spatially order the unordered\ndata. We compare the recent state-of-the-art spatio-temporal prediction models\non the same data. Models that use convolutional layers can be and are extended\nwith our localizations. In all these cases our extensions improve the results,\nand thus often the state-of-the-art. We share all the code at a public\nrepository.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 17:14:49 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 14:56:21 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 16:13:17 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Uselis", "Arnas", ""], ["Luko\u0161evi\u010dius", "Mantas", ""], ["Stasytis", "Lukas", ""]]}, {"id": "2005.05941", "submitter": "Sneha Aenugu", "authors": "Sneha Aenugu", "title": "Training spiking neural networks using reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurons in the brain communicate with each other through discrete action\nspikes as opposed to continuous signal transmission in artificial neural\nnetworks. Therefore, the traditional techniques for optimization of parameters\nin neural networks which rely on the assumption of differentiability of\nactivation functions are no longer applicable to modeling the learning\nprocesses in the brain. In this project, we propose biologically-plausible\nalternatives to backpropagation to facilitate the training of spiking neural\nnetworks. We primarily focus on investigating the candidacy of reinforcement\nlearning (RL) rules in solving the spatial and temporal credit assignment\nproblems to enable decision-making in complex tasks. In one approach, we\nconsider each neuron in a multi-layer neural network as an independent RL agent\nforming a different representation of the feature space while the network as a\nwhole forms the representation of the complex policy to solve the task at hand.\nIn other approach, we apply the reparameterization trick to enable\ndifferentiation through stochastic transformations in spiking neural networks.\nWe compare and contrast the two approaches by applying them to traditional RL\ndomains such as gridworld, cartpole and mountain car. Further we also suggest\nvariations and enhancements to enable future research in this area.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 17:40:36 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Aenugu", "Sneha", ""]]}, {"id": "2005.05951", "submitter": "Aravind Rajeswaran", "authors": "Rahul Kidambi, Aravind Rajeswaran, Praneeth Netrapalli, Thorsten\n  Joachims", "title": "MOReL : Model-Based Offline Reinforcement Learning", "comments": "First two authors contributed equally. Published at NeurIPS 2020.\n  After publication at NeurIPS 2020, (1) D4RL benchmark results have been\n  added; (2) hyper-parameter ablation studies have been added; (3) scope of\n  Lemma 3 has been extended", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In offline reinforcement learning (RL), the goal is to learn a highly\nrewarding policy based solely on a dataset of historical interactions with the\nenvironment. The ability to train RL policies offline can greatly expand the\napplicability of RL, its data efficiency, and its experimental velocity. Prior\nwork in offline RL has been confined almost exclusively to model-free RL\napproaches. In this work, we present MOReL, an algorithmic framework for\nmodel-based offline RL. This framework consists of two steps: (a) learning a\npessimistic MDP (P-MDP) using the offline dataset; and (b) learning a\nnear-optimal policy in this P-MDP. The learned P-MDP has the property that for\nany policy, the performance in the real environment is approximately\nlower-bounded by the performance in the P-MDP. This enables it to serve as a\ngood surrogate for purposes of policy evaluation and learning, and overcome\ncommon pitfalls of model-based RL like model exploitation. Theoretically, we\nshow that MOReL is minimax optimal (up to log factors) for offline RL. Through\nexperiments, we show that MOReL matches or exceeds state-of-the-art results in\nwidely studied offline RL benchmarks. Moreover, the modular design of MOReL\nenables future advances in its components (e.g. generative modeling,\nuncertainty estimation, planning etc.) to directly translate into advances for\noffline RL.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 17:52:43 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 19:00:20 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 04:35:04 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Kidambi", "Rahul", ""], ["Rajeswaran", "Aravind", ""], ["Netrapalli", "Praneeth", ""], ["Joachims", "Thorsten", ""]]}, {"id": "2005.05954", "submitter": "Md. Tawkat Islam Khondaker", "authors": "Junaed Younus Khan, Md. Tawkat Islam Khondaker, Iram Tazim Hoque,\n  Hamada Al-Absi, Mohammad Saifur Rahman, Tanvir Alam, M. Sohel Rahman", "title": "COVID-19Base: A knowledgebase to explore biomedical entities related to\n  COVID-19", "comments": "10 pages, 3 figures", "journal-ref": "JMIR Med Inform 2020;8(11):e21648", "doi": "10.2196/21648", "report-no": null, "categories": "cs.IR cs.CL cs.DL cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are presenting COVID-19Base, a knowledgebase highlighting the biomedical\nentities related to COVID-19 disease based on literature mining. To develop\nCOVID-19Base, we mine the information from publicly available scientific\nliterature and related public resources. We considered seven topic-specific\ndictionaries, including human genes, human miRNAs, human lncRNAs, diseases,\nProtein Databank, drugs, and drug side effects, are integrated to mine all\nscientific evidence related to COVID-19. We have employed an automated\nliterature mining and labeling system through a novel approach to measure the\neffectiveness of drugs against diseases based on natural language processing,\nsentiment analysis, and deep learning. To the best of our knowledge, this is\nthe first knowledgebase dedicated to COVID-19, which integrates such large\nvariety of related biomedical entities through literature mining. Proper\ninvestigation of the mined biomedical entities along with the identified\ninteractions among those, reported in COVID-19Base, would help the research\ncommunity to discover possible ways for the therapeutic treatment of COVID-19.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 17:55:00 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Khan", "Junaed Younus", ""], ["Khondaker", "Md. Tawkat Islam", ""], ["Hoque", "Iram Tazim", ""], ["Al-Absi", "Hamada", ""], ["Rahman", "Mohammad Saifur", ""], ["Alam", "Tanvir", ""], ["Rahman", "M. Sohel", ""]]}, {"id": "2005.05955", "submitter": "Rohun Tripathi", "authors": "Rohun Tripathi and Bharat Singh", "title": "RSO: A Gradient Free Sampling Based Approach For Training Deep Neural\n  Networks", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose RSO (random search optimization), a gradient free Markov Chain\nMonte Carlo search based approach for training deep neural networks. To this\nend, RSO adds a perturbation to a weight in a deep neural network and tests if\nit reduces the loss on a mini-batch. If this reduces the loss, the weight is\nupdated, otherwise the existing weight is retained. Surprisingly, we find that\nrepeating this process a few times for each weight is sufficient to train a\ndeep neural network. The number of weight updates for RSO is an order of\nmagnitude lesser when compared to backpropagation with SGD. RSO can make\naggressive weight updates in each step as there is no concept of learning rate.\nThe weight update step for individual layers is also not coupled with the\nmagnitude of the loss. RSO is evaluated on classification tasks on MNIST and\nCIFAR-10 datasets with deep neural networks of 6 to 10 layers where it achieves\nan accuracy of 99.1% and 81.8% respectively. We also find that after updating\nthe weights just 5 times, the algorithm obtains a classification accuracy of\n98% on MNIST.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 17:55:16 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Tripathi", "Rohun", ""], ["Singh", "Bharat", ""]]}, {"id": "2005.05957", "submitter": "Rafael Valle", "authors": "Rafael Valle, Kevin Shih, Ryan Prenger, Bryan Catanzaro", "title": "Flowtron: an Autoregressive Flow-based Generative Network for\n  Text-to-Speech Synthesis", "comments": "10 pages, 7 pictures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose Flowtron: an autoregressive flow-based generative\nnetwork for text-to-speech synthesis with control over speech variation and\nstyle transfer. Flowtron borrows insights from IAF and revamps Tacotron in\norder to provide high-quality and expressive mel-spectrogram synthesis.\nFlowtron is optimized by maximizing the likelihood of the training data, which\nmakes training simple and stable. Flowtron learns an invertible mapping of data\nto a latent space that can be manipulated to control many aspects of speech\nsynthesis (pitch, tone, speech rate, cadence, accent). Our mean opinion scores\n(MOS) show that Flowtron matches state-of-the-art TTS models in terms of speech\nquality. In addition, we provide results on control of speech variation,\ninterpolation between samples and style transfer between speakers seen and\nunseen during training. Code and pre-trained models will be made publicly\navailable at https://github.com/NVIDIA/flowtron\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 17:57:17 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 01:54:35 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 15:10:18 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Valle", "Rafael", ""], ["Shih", "Kevin", ""], ["Prenger", "Ryan", ""], ["Catanzaro", "Bryan", ""]]}, {"id": "2005.05960", "submitter": "Deepak Pathak", "authors": "Ramanan Sekar, Oleh Rybkin, Kostas Daniilidis, Pieter Abbeel, Danijar\n  Hafner, Deepak Pathak", "title": "Planning to Explore via Self-Supervised World Models", "comments": "Accepted at ICML 2020. Videos and code at\n  https://ramanans1.github.io/plan2explore/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning allows solving complex tasks, however, the learning\ntends to be task-specific and the sample efficiency remains a challenge. We\npresent Plan2Explore, a self-supervised reinforcement learning agent that\ntackles both these challenges through a new approach to self-supervised\nexploration and fast adaptation to new tasks, which need not be known during\nexploration. During exploration, unlike prior methods which retrospectively\ncompute the novelty of observations after the agent has already reached them,\nour agent acts efficiently by leveraging planning to seek out expected future\nnovelty. After exploration, the agent quickly adapts to multiple downstream\ntasks in a zero or a few-shot manner. We evaluate on challenging control tasks\nfrom high-dimensional image inputs. Without any training supervision or\ntask-specific interaction, Plan2Explore outperforms prior self-supervised\nexploration methods, and in fact, almost matches the performances oracle which\nhas access to rewards. Videos and code at\nhttps://ramanans1.github.io/plan2explore/\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 17:59:45 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 23:05:50 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Sekar", "Ramanan", ""], ["Rybkin", "Oleh", ""], ["Daniilidis", "Kostas", ""], ["Abbeel", "Pieter", ""], ["Hafner", "Danijar", ""], ["Pathak", "Deepak", ""]]}, {"id": "2005.05968", "submitter": "Minsoo Rhu", "authors": "Ranggi Hwang, Taehun Kim, Youngeun Kwon, Minsoo Rhu", "title": "Centaur: A Chiplet-based, Hybrid Sparse-Dense Accelerator for\n  Personalized Recommendations", "comments": "Accepted for publication at the 47th IEEE/ACM International Symposium\n  on Computer Architecture (ISCA-47), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized recommendations are the backbone machine learning (ML) algorithm\nthat powers several important application domains (e.g., ads, e-commerce, etc)\nserviced from cloud datacenters. Sparse embedding layers are a crucial building\nblock in designing recommendations yet little attention has been paid in\nproperly accelerating this important ML algorithm. This paper first provides a\ndetailed workload characterization on personalized recommendations and\nidentifies two significant performance limiters: memory-intensive embedding\nlayers and compute-intensive multi-layer perceptron (MLP) layers. We then\npresent Centaur, a chiplet-based hybrid sparse-dense accelerator that addresses\nboth the memory throughput challenges of embedding layers and the compute\nlimitations of MLP layers. We implement and demonstrate our proposal on an\nIntel HARPv2, a package-integrated CPU+FPGA device, which shows a 1.7-17.2x\nperformance speedup and 1.7-19.5x energy-efficiency improvement than\nconventional approaches.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 07:53:35 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Hwang", "Ranggi", ""], ["Kim", "Taehun", ""], ["Kwon", "Youngeun", ""], ["Rhu", "Minsoo", ""]]}, {"id": "2005.06001", "submitter": "Greg Ongie", "authors": "Gregory Ongie, Ajil Jalal, Christopher A. Metzler, Richard G.\n  Baraniuk, Alexandros G. Dimakis, Rebecca Willett", "title": "Deep Learning Techniques for Inverse Problems in Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in machine learning shows that deep neural networks can be used\nto solve a wide variety of inverse problems arising in computational imaging.\nWe explore the central prevailing themes of this emerging area and present a\ntaxonomy that can be used to categorize different problems and reconstruction\nmethods. Our taxonomy is organized along two central axes: (1) whether or not a\nforward model is known and to what extent it is used in training and testing,\nand (2) whether or not the learning is supervised or unsupervised, i.e.,\nwhether or not the training relies on access to matched ground truth image and\nmeasurement pairs. We also discuss the trade-offs associated with these\ndifferent reconstruction approaches, caveats and common failure modes, plus\nopen problems and avenues for future work.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 18:35:55 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Ongie", "Gregory", ""], ["Jalal", "Ajil", ""], ["Metzler", "Christopher A.", ""], ["Baraniuk", "Richard G.", ""], ["Dimakis", "Alexandros G.", ""], ["Willett", "Rebecca", ""]]}, {"id": "2005.06022", "submitter": "Carlos Toxtli", "authors": "Carlos Toxtli, Angela Richmond-Fuller, Saiph Savage", "title": "Reputation Agent: Prompting Fair Reviews in Gig Markets", "comments": "12 pages, 5 figures, The Web Conference 2020, ACM WWW 2020", "journal-ref": null, "doi": "10.1145/3366423.3380199", "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Our study presents a new tool, Reputation Agent, to promote fairer reviews\nfrom requesters (employers or customers) on gig markets. Unfair reviews,\ncreated when requesters consider factors outside of a worker's control, are\nknown to plague gig workers and can result in lost job opportunities and even\ntermination from the marketplace. Our tool leverages machine learning to\nimplement an intelligent interface that: (1) uses deep learning to\nautomatically detect when an individual has included unfair factors into her\nreview (factors outside the worker's control per the policies of the market);\nand (2) prompts the individual to reconsider her review if she has incorporated\nunfair factors. To study the effectiveness of Reputation Agent, we conducted a\ncontrolled experiment over different gig markets. Our experiment illustrates\nthat across markets, Reputation Agent, in contrast with traditional approaches,\nmotivates requesters to review gig workers' performance more fairly. We discuss\nhow tools that bring more transparency to employers about the policies of a gig\nmarket can help build empathy thus resulting in reasoned discussions around\npotential injustices towards workers generated by these interfaces. Our vision\nis that with tools that promote truth and transparency we can bring fairer\ntreatment to gig workers.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 01:56:10 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Toxtli", "Carlos", ""], ["Richmond-Fuller", "Angela", ""], ["Savage", "Saiph", ""]]}, {"id": "2005.06038", "submitter": "Krishna Somandepalli", "authors": "Krishna Somandepalli and Shrikanth Narayanan", "title": "Generalized Multi-view Shared Subspace Learning using View Bootstrapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.SD eess.AS eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key objective in multi-view learning is to model the information common to\nmultiple parallel views of a class of objects/events to improve downstream\nlearning tasks. In this context, two open research questions remain: How can we\nmodel hundreds of views per event? Can we learn robust multi-view embeddings\nwithout any knowledge of how these views are acquired? We present a neural\nmethod based on multi-view correlation to capture the information shared across\na large number of views by subsampling them in a view-agnostic manner during\ntraining. To provide an upper bound on the number of views to subsample for a\ngiven embedding dimension, we analyze the error of the bootstrapped multi-view\ncorrelation objective using matrix concentration theory. Our experiments on\nspoken word recognition, 3D object classification and pose-invariant face\nrecognition demonstrate the robustness of view bootstrapping to model a large\nnumber of views. Results underscore the applicability of our method for a\nview-agnostic learning setting.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 20:35:14 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Somandepalli", "Krishna", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "2005.06041", "submitter": "Brandon Houghton", "authors": "Brandon Houghton, Stephanie Milani, Nicholay Topin, William Guss,\n  Katja Hofmann, Diego Perez-Liebana, Manuela Veloso, Ruslan Salakhutdinov", "title": "Guaranteeing Reproducibility in Deep Learning Competitions", "comments": "Accepted as a poster presentation to the 2019 NeruIPS Challenges in\n  Machine Learning workshop (CiML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To encourage the development of methods with reproducible and robust training\nbehavior, we propose a challenge paradigm where competitors are evaluated\ndirectly on the performance of their learning procedures rather than\npre-trained agents. Since competition organizers re-train proposed methods in a\ncontrolled setting they can guarantee reproducibility, and -- by retraining\nsubmissions using a held-out test set -- help ensure generalization past the\nenvironments on which they were trained.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 20:43:05 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Houghton", "Brandon", ""], ["Milani", "Stephanie", ""], ["Topin", "Nicholay", ""], ["Guss", "William", ""], ["Hofmann", "Katja", ""], ["Perez-Liebana", "Diego", ""], ["Veloso", "Manuela", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2005.06043", "submitter": "Tarek Elgamal", "authors": "Tarek Elgamal, Klara Nahrstedt", "title": "Serdab: An IoT Framework for Partitioning Neural Networks Computation\n  across Multiple Enclaves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Deep Neural Networks (DNN) and Edge Computing have made it\npossible to automatically analyze streams of videos from home/security cameras\nover hierarchical clusters that include edge devices, close to the video\nsource, as well as remote cloud compute resources. However, preserving the\nprivacy and confidentiality of users' sensitive data as it passes through\ndifferent devices remains a concern to most users. Private user data is subject\nto attacks by malicious attackers or misuse by internal administrators who may\nuse the data in activities that are not explicitly approved by the user. To\naddress this challenge, we present Serdab, a distributed orchestration\nframework for deploying deep neural network computation across multiple secure\nenclaves (e.g., Intel SGX). Secure enclaves provide a guarantee on the privacy\nof the data/code deployed inside it. However, their limited hardware resources\nmake them inefficient when solely running an entire deep neural network. To\nbridge this gap, Serdab presents a DNN partitioning strategy to distribute the\nlayers of the neural network across multiple enclave devices or across an\nenclave device and other hardware accelerators. Our partitioning strategy\nachieves up to 4.7x speedup compared to executing the entire neural network in\none enclave.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 20:51:47 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Elgamal", "Tarek", ""], ["Nahrstedt", "Klara", ""]]}, {"id": "2005.06050", "submitter": "Marvin Klingner", "authors": "Marvin Klingner, Andreas B\\\"ar, Philipp Donn and Tim Fingscheidt", "title": "Class-Incremental Learning for Semantic Segmentation Re-Using Neither\n  Old Data Nor Old Labels", "comments": "ITSC 2020 Conference Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural networks trained for semantic segmentation are essential for\nperception in autonomous driving, most current algorithms assume a fixed number\nof classes, presenting a major limitation when developing new autonomous\ndriving systems with the need of additional classes. In this paper we present a\ntechnique implementing class-incremental learning for semantic segmentation\nwithout using the labeled data the model was initially trained on. Previous\napproaches still either rely on labels for both old and new classes, or fail to\nproperly distinguish between them. We show how to overcome these problems with\na novel class-incremental learning technique, which nonetheless requires labels\nonly for the new classes. Specifically, (i) we introduce a new loss function\nthat neither relies on old data nor on old labels, (ii) we show how new classes\ncan be integrated in a modular fashion into pretrained semantic segmentation\nmodels, and finally (iii) we re-implement previous approaches in a unified\nsetting to compare them to ours. We evaluate our method on the Cityscapes\ndataset, where we exceed the mIoU performance of all baselines by 3.5% absolute\nreaching a result, which is only 2.2% absolute below the upper performance\nlimit of single-stage training, relying on all data and labels simultaneously.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 21:03:29 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Klingner", "Marvin", ""], ["B\u00e4r", "Andreas", ""], ["Donn", "Philipp", ""], ["Fingscheidt", "Tim", ""]]}, {"id": "2005.06057", "submitter": "Joachim Meyer", "authors": "Salomon Eisler, Joachim Meyer", "title": "Visual Analytics and Human Involvement in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapidly developing AI systems and applications still require human\ninvolvement in practically all parts of the analytics process. Human decisions\nare largely based on visualizations, providing data scientists details of data\nproperties and the results of analytical procedures. Different visualizations\nare used in the different steps of the Machine Learning (ML) process. The\ndecision which visualization to use depends on factors, such as the data\ndomain, the data model and the step in the ML process. In this chapter, we\ndescribe the seven steps in the ML process and review different visualization\ntechniques that are relevant for the different steps for different types of\ndata, models and purposes.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 21:22:47 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Eisler", "Salomon", ""], ["Meyer", "Joachim", ""]]}, {"id": "2005.06058", "submitter": "Preslav Nakov", "authors": "Shaden Shaar, Giovanni Da San Martino, Nikolay Babulkov, Preslav Nakov", "title": "That is a Known Lie: Detecting Previously Fact-Checked Claims", "comments": "detecting previously fact-checked claims, fact-checking,\n  disinformation, fake news, social media, political debates", "journal-ref": "ACL-2020", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent proliferation of \"fake news\" has triggered a number of responses,\nmost notably the emergence of several manual fact-checking initiatives. As a\nresult and over time, a large number of fact-checked claims have been\naccumulated, which increases the likelihood that a new claim in social media or\na new statement by a politician might have already been fact-checked by some\ntrusted fact-checking organization, as viral claims often come back after a\nwhile in social media, and politicians like to repeat their favorite\nstatements, true or false, over and over again. As manual fact-checking is very\ntime-consuming (and fully automatic fact-checking has credibility issues), it\nis important to try to save this effort and to avoid wasting time on claims\nthat have already been fact-checked. Interestingly, despite the importance of\nthe task, it has been largely ignored by the research community so far. Here,\nwe aim to bridge this gap. In particular, we formulate the task and we discuss\nhow it relates to, but also differs from, previous work. We further create a\nspecialized dataset, which we release to the research community. Finally, we\npresent learning-to-rank experiments that demonstrate sizable improvements over\nstate-of-the-art retrieval and textual similarity approaches.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 21:25:37 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Shaar", "Shaden", ""], ["Martino", "Giovanni Da San", ""], ["Babulkov", "Nikolay", ""], ["Nakov", "Preslav", ""]]}, {"id": "2005.06059", "submitter": "Carlo Lipizzi", "authors": "Carlo Lipizzi, Dario Borrelli, Fernanda de Oliveira Capela", "title": "A computational model implementing subjectivity with the 'Room Theory'.\n  The case of detecting Emotion from Text", "comments": "15 pages, 9 figures, 3 Tables - Under second round of review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a new method to consider subjectivity and general\ncontext dependency in text analysis and uses as example the detection of\nemotions conveyed in text. The proposed method takes into account subjectivity\nusing a computational version of the Framework Theory by Marvin Minsky (1974)\nleveraging on the Word2Vec approach to text vectorization by Mikolov et al.\n(2013), used to generate distributed representation of words based on the\ncontext where they appear. Our approach is based on three components: 1. a\nframework/'room' representing the point of view; 2. a benchmark representing\nthe criteria for the analysis - in this case the emotion classification, from a\nstudy of human emotions by Robert Plutchik (1980); and 3. the document to be\nanalyzed. By using similarity measure between words, we are able to extract the\nrelative relevance of the elements in the benchmark - intensities of emotions\nin our case study - for the document to be analyzed. Our method provides a\nmeasure that take into account the point of view of the entity reading the\ndocument. This method could be applied to all the cases where evaluating\nsubjectivity is relevant to understand the relative value or meaning of a text.\nSubjectivity can be not limited to human reactions, but it could be used to\nprovide a text with an interpretation related to a given domain (\"room\"). To\nevaluate our method, we used a test case in the political domain.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 21:26:04 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Lipizzi", "Carlo", ""], ["Borrelli", "Dario", ""], ["Capela", "Fernanda de Oliveira", ""]]}, {"id": "2005.06061", "submitter": "Zhaoheng Yin", "authors": "Zhao-Heng Yin, Wu-Jun Li", "title": "TOMA: Topological Map Abstraction for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animals are able to discover the topological map (graph) of surrounding\nenvironment, which will be used for navigation. Inspired by this biological\nphenomenon, researchers have recently proposed to generate graph representation\nfor Markov decision process (MDP) and use such graphs for planning in\nreinforcement learning (RL). However, existing graph generation methods suffer\nfrom many drawbacks. One drawback is that existing methods do not learn an\nabstraction for graphs, which results in high memory and computation cost. This\ndrawback also makes generated graph non-robust, which degrades the planning\nperformance. Another drawback is that existing methods cannot be used for\nfacilitating exploration which is important in RL. In this paper, we propose a\nnew method, called topological map abstraction (TOMA), for graph generation.\nTOMA can generate an abstract graph representation for MDP, which costs much\nless memory and computation cost than existing methods. Furthermore, TOMA can\nbe used for facilitating exploration. In particular, we propose planning to\nexplore, in which TOMA is used to accelerate exploration by guiding the agent\ntowards unexplored states. A novel experience replay module called vertex\nmemory is also proposed to improve exploration performance. Experimental\nresults show that TOMA can outperform existing methods to achieve the\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 05:24:47 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 11:12:44 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Yin", "Zhao-Heng", ""], ["Li", "Wu-Jun", ""]]}, {"id": "2005.06068", "submitter": "Tugba Erpek", "authors": "Tugba Erpek, Timothy J. O'Shea, Yalin E. Sagduyu, Yi Shi, T. Charles\n  Clancy", "title": "Deep Learning for Wireless Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing communication systems exhibit inherent limitations in translating\ntheory to practice when handling the complexity of optimization for emerging\nwireless applications with high degrees of freedom. Deep learning has a strong\npotential to overcome this challenge via data-driven solutions and improve the\nperformance of wireless systems in utilizing limited spectrum resources. In\nthis chapter, we first describe how deep learning is used to design an\nend-to-end communication system using autoencoders. This flexible design\neffectively captures channel impairments and optimizes transmitter and receiver\noperations jointly in single-antenna, multiple-antenna, and multiuser\ncommunications. Next, we present the benefits of deep learning in spectrum\nsituation awareness ranging from channel modeling and estimation to signal\ndetection and classification tasks. Deep learning improves the performance when\nthe model-based methods fail. Finally, we discuss how deep learning applies to\nwireless communication security. In this context, adversarial machine learning\nprovides novel means to launch and defend against wireless attacks. These\napplications demonstrate the power of deep learning in providing novel means to\ndesign, optimize, adapt, and secure wireless communications.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 21:58:44 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Erpek", "Tugba", ""], ["O'Shea", "Timothy J.", ""], ["Sagduyu", "Yalin E.", ""], ["Shi", "Yi", ""], ["Clancy", "T. Charles", ""]]}, {"id": "2005.06070", "submitter": "Ali H\\\"urriyeto\\u{g}lu", "authors": "Ali H\\\"urriyeto\\u{g}lu, Vanni Zavarella, Hristo Tanev, Erdem\n  Y\\\"or\\\"uk, Ali Safaya, Osman Mutlu", "title": "Automated Extraction of Socio-political Events from News (AESPEN):\n  Workshop and Shared Task Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our effort on automated extraction of socio-political events from\nnews in the scope of a workshop and a shared task we organized at Language\nResources and Evaluation Conference (LREC 2020). We believe the event\nextraction studies in computational linguistics and social and political\nsciences should further support each other in order to enable large scale\nsocio-political event information collection across sources, countries, and\nlanguages. The event consists of regular research papers and a shared task,\nwhich is about event sentence coreference identification (ESCI), tracks. All\nsubmissions were reviewed by five members of the program committee. The\nworkshop attracted research papers related to evaluation of machine learning\nmethodologies, language resources, material conflict forecasting, and a shared\ntask participation report in the scope of socio-political event information\ncollection. It has shown us the volume and variety of both the data sources and\nevent information collection approaches related to socio-political events and\nthe need to fill the gap between automated text processing techniques and\nrequirements of social and political sciences.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 22:07:14 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["H\u00fcrriyeto\u011flu", "Ali", ""], ["Zavarella", "Vanni", ""], ["Tanev", "Hristo", ""], ["Y\u00f6r\u00fck", "Erdem", ""], ["Safaya", "Ali", ""], ["Mutlu", "Osman", ""]]}, {"id": "2005.06083", "submitter": "Sinong Geng", "authors": "Sinong Geng, Zhaobin Kuang, Jie Liu, Stephen Wright, David Page", "title": "Stochastic Learning for Sparse Discrete Markov Random Fields with\n  Controlled Gradient Approximation Error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the $L_1$-regularized maximum likelihood estimator/estimation (MLE)\nproblem for discrete Markov random fields (MRFs), where efficient and scalable\nlearning requires both sparse regularization and approximate inference. To\naddress these challenges, we consider a stochastic learning framework called\nstochastic proximal gradient (SPG; Honorio 2012a, Atchade et al.\n2014,Miasojedow and Rejchel 2016). SPG is an inexact proximal gradient\nalgorithm [Schmidtet al., 2011], whose inexactness stems from the stochastic\noracle (Gibbs sampling) for gradient approximation - exact gradient evaluation\nis infeasible in general due to the NP-hard inference problem for discrete MRFs\n[Koller and Friedman, 2009]. Theoretically, we provide novel verifiable bounds\nto inspect and control the quality of gradient approximation. Empirically, we\npropose the tighten asymptotically (TAY) learning strategy based on the\nverifiable bounds to boost the performance of SPG.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 22:48:42 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Geng", "Sinong", ""], ["Kuang", "Zhaobin", ""], ["Liu", "Jie", ""], ["Wright", "Stephen", ""], ["Page", "David", ""]]}, {"id": "2005.06091", "submitter": "Pooyan Jamshidi", "authors": "Yang Ren, Gregory Gay, Christian K\\\"astner, Pooyan Jamshidi", "title": "Understanding the Nature of System-Related Issues in Machine Learning\n  Frameworks: An Exploratory Study", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern systems are built using development frameworks. These frameworks have\na major impact on how the resulting system executes, how configurations are\nmanaged, how it is tested, and how and where it is deployed. Machine learning\n(ML) frameworks and the systems developed using them differ greatly from\ntraditional frameworks. Naturally, the issues that manifest in such frameworks\nmay differ as well---as may the behavior of developers addressing those issues.\nWe are interested in characterizing the system-related issues---issues\nimpacting performance, memory and resource usage, and other quality\nattributes---that emerge in ML frameworks, and how they differ from those in\ntraditional frameworks. We have conducted a moderate-scale exploratory study\nanalyzing real-world system-related issues from 10 popular machine learning\nframeworks. Our findings offer implications for the development of machine\nlearning systems, including differences in the frequency of occurrence of\ncertain issue types, observations regarding the impact of debate and time on\nissue correction, and differences in the specialization of developers. We hope\nthat this exploratory study will enable developers to improve their\nexpectations, plan for risk, and allocate resources accordingly when making use\nof the tools provided by these frameworks to develop ML-based systems.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 00:09:40 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Ren", "Yang", ""], ["Gay", "Gregory", ""], ["K\u00e4stner", "Christian", ""], ["Jamshidi", "Pooyan", ""]]}, {"id": "2005.06092", "submitter": "Xiaojin Zhang", "authors": "Xiaojin Zhang, Honglei Zhuang, Shengyu Zhang, Yuan Zhou", "title": "Adaptive Double-Exploration Tradeoff for Outlier Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a variant of the thresholding bandit problem (TBP) in the context of\noutlier detection, where the objective is to identify the outliers whose\nrewards are above a threshold. Distinct from the traditional TBP, the threshold\nis defined as a function of the rewards of all the arms, which is motivated by\nthe criterion for identifying outliers. The learner needs to explore the\nrewards of the arms as well as the threshold. We refer to this problem as\n\"double exploration for outlier detection\". We construct an adaptively updated\nconfidence interval for the threshold, based on the estimated value of the\nthreshold in the previous rounds. Furthermore, by automatically trading off\nexploring the individual arms and exploring the outlier threshold, we provide\nan efficient algorithm in terms of the sample complexity. Experimental results\non both synthetic datasets and real-world datasets demonstrate the efficiency\nof our algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 00:12:31 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Zhang", "Xiaojin", ""], ["Zhuang", "Honglei", ""], ["Zhang", "Shengyu", ""], ["Zhou", "Yuan", ""]]}, {"id": "2005.06105", "submitter": "Han Cha", "authors": "Han Cha, Jihong Park, Hyesung Kim, Mehdi Bennis, Seong-Lyun Kim", "title": "Proxy Experience Replay: Federated Distillation for Distributed\n  Reinforcement Learning", "comments": "8 pages, 5 figures, This paper is accepted to IEEE Intelligent\n  Systems special issue of July/Aug 2020 - Federated Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional distributed deep reinforcement learning (RL) commonly relies on\nexchanging the experience replay memory (RM) of each agent. Since the RM\ncontains all state observations and action policy history, it may incur huge\ncommunication overhead while violating the privacy of each agent.\nAlternatively, this article presents a communication-efficient and\nprivacy-preserving distributed RL framework, coined federated reinforcement\ndistillation (FRD). In FRD, each agent exchanges its proxy experience replay\nmemory (ProxRM), in which policies are locally averaged with respect to proxy\nstates clustering actual states. To provide FRD design insights, we present\nablation studies on the impact of ProxRM structures, neural network\narchitectures, and communication intervals. Furthermore, we propose an improved\nversion of FRD, coined mixup augmented FRD (MixFRD), in which ProxRM is\ninterpolated using the mixup data augmentation algorithm. Simulations in a\nCartpole environment validate the effectiveness of MixFRD in reducing the\nvariance of mission completion time and communication cost, compared to the\nbenchmark schemes, vanilla FRD, federated reinforcement learning (FRL), and\npolicy distillation (PD).\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 01:36:34 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 12:44:25 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Cha", "Han", ""], ["Park", "Jihong", ""], ["Kim", "Hyesung", ""], ["Bennis", "Mehdi", ""], ["Kim", "Seong-Lyun", ""]]}, {"id": "2005.06107", "submitter": "Ali Borji", "authors": "Ali Borji", "title": "Adversarial examples are useful too!", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has come a long way and has enjoyed an unprecedented success.\nDespite high accuracy, however, deep models are brittle and are easily fooled\nby imperceptible adversarial perturbations. In contrast to common\ninference-time attacks, Backdoor (\\aka Trojan) attacks target the training\nphase of model construction, and are extremely difficult to combat since a) the\nmodel behaves normally on a pristine testing set and b) the augmented\nperturbations can be minute and may only affect few training samples. Here, I\npropose a new method to tell whether a model has been subject to a backdoor\nattack. The idea is to generate adversarial examples, targeted or untargeted,\nusing conventional attacks such as FGSM and then feed them back to the\nclassifier. By computing the statistics (here simply mean maps) of the images\nin different categories and comparing them with the statistics of a reference\nmodel, it is possible to visually locate the perturbed regions and unveil the\nattack.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 01:38:56 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Borji", "Ali", ""]]}, {"id": "2005.06133", "submitter": "Sainyam Galhotra Mr", "authors": "Sainyam Galhotra, Behzad Golshan and Wang-Chiew Tan", "title": "Adaptive Rule Discovery for Labeling Text Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Creating and collecting labeled data is one of the major bottlenecks in\nmachine learning pipelines and the emergence of automated feature generation\ntechniques such as deep learning, which typically requires a lot of training\ndata, has further exacerbated the problem. While weak-supervision techniques\nhave circumvented this bottleneck, existing frameworks either require users to\nwrite a set of diverse, high-quality rules to label data (e.g., Snorkel), or\nrequire a labeled subset of the data to automatically mine rules (e.g., Snuba).\nThe process of manually writing rules can be tedious and time consuming. At the\nsame time, creating a labeled subset of the data can be costly and even\ninfeasible in imbalanced settings. This is due to the fact that a random sample\nin imbalanced settings often contains only a few positive instances.\n  To address these shortcomings, we present Darwin, an interactive system\ndesigned to alleviate the task of writing rules for labeling text data in\nweakly-supervised settings. Given an initial labeling rule, Darwin\nautomatically generates a set of candidate rules for the labeling task at hand,\nand utilizes the annotator's feedback to adapt the candidate rules. We describe\nhow Darwin is scalable and versatile. It can operate over large text corpora\n(i.e., more than 1 million sentences) and supports a wide range of labeling\nfunctions (i.e., any function that can be specified using a context free\ngrammar). Finally, we demonstrate with a suite of experiments over five\nreal-world datasets that Darwin enables annotators to generate\nweakly-supervised labels efficiently and with a small cost. In fact, our\nexperiments show that rules discovered by Darwin on average identify 40% more\npositive instances compared to Snuba even when it is provided with 1000 labeled\ninstances.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 03:29:12 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Galhotra", "Sainyam", ""], ["Golshan", "Behzad", ""], ["Tan", "Wang-Chiew", ""]]}, {"id": "2005.06139", "submitter": "Yu Lu", "authors": "Yu Lu, Deliang Wang, Qinggang Meng, Penghe Chen", "title": "Towards Interpretable Deep Learning Models for Knowledge Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an important technique for modeling the knowledge states of learners, the\ntraditional knowledge tracing (KT) models have been widely used to support\nintelligent tutoring systems and MOOC platforms. Driven by the fast\nadvancements of deep learning techniques, deep neural network has been recently\nadopted to design new KT models for achieving better prediction performance.\nHowever, the lack of interpretability of these models has painfully impeded\ntheir practical applications, as their outputs and working mechanisms suffer\nfrom the intransparent decision process and complex inner structures. We thus\npropose to adopt the post-hoc method to tackle the interpretability issue for\ndeep learning based knowledge tracing (DLKT) models. Specifically, we focus on\napplying the layer-wise relevance propagation (LRP) method to interpret\nRNN-based DLKT model by backpropagating the relevance from the model's output\nlayer to its input layer. The experiment results show the feasibility using the\nLRP method for interpreting the DLKT model's predictions, and partially\nvalidate the computed relevance scores from both question level and concept\nlevel. We believe it can be a solid step towards fully interpreting the DLKT\nmodels and promote their practical applications in the education domain.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 04:03:21 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Lu", "Yu", ""], ["Wang", "Deliang", ""], ["Meng", "Qinggang", ""], ["Chen", "Penghe", ""]]}, {"id": "2005.06149", "submitter": "Yaxin Li", "authors": "Yaxin Li, Wei Jin, Han Xu, Jiliang Tang", "title": "DeepRobust: A PyTorch Library for Adversarial Attacks and Defenses", "comments": "Adversarial attacks and defenses, Pytorch library", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DeepRobust is a PyTorch adversarial learning library which aims to build a\ncomprehensive and easy-to-use platform to foster this research field. It\ncurrently contains more than 10 attack algorithms and 8 defense algorithms in\nimage domain and 9 attack algorithms and 4 defense algorithms in graph domain,\nunder a variety of deep learning architectures. In this manual, we introduce\nthe main contents of DeepRobust with detailed instructions. The library is kept\nupdated and can be found at https://github.com/DSE-MSU/DeepRobust.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 04:43:46 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Li", "Yaxin", ""], ["Jin", "Wei", ""], ["Xu", "Han", ""], ["Tang", "Jiliang", ""]]}, {"id": "2005.06166", "submitter": "Boliang Zhang", "authors": "Boliang Zhang, Ajay Nagesh, and Kevin Knight", "title": "Parallel Corpus Filtering via Pre-trained Language Models", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web-crawled data provides a good source of parallel corpora for training\nmachine translation models. It is automatically obtained, but extremely noisy,\nand recent work shows that neural machine translation systems are more\nsensitive to noise than traditional statistical machine translation methods. In\nthis paper, we propose a novel approach to filter out noisy sentence pairs from\nweb-crawled corpora via pre-trained language models. We measure sentence\nparallelism by leveraging the multilingual capability of BERT and use the\nGenerative Pre-training (GPT) language model as a domain filter to balance data\ndomains. We evaluate the proposed method on the WMT 2018 Parallel Corpus\nFiltering shared task, and on our own web-crawled Japanese-Chinese parallel\ncorpus. Our method significantly outperforms baselines and achieves a new\nstate-of-the-art. In an unsupervised setting, our method achieves comparable\nperformance to the top-1 supervised method. We also evaluate on a web-crawled\nJapanese-Chinese parallel corpus that we make publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 06:06:23 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Zhang", "Boliang", ""], ["Nagesh", "Ajay", ""], ["Knight", "Kevin", ""]]}, {"id": "2005.06173", "submitter": "Kristian Miok", "authors": "Kristian Miok, Dong Nguyen-Doan, Marko Robnik-\\v{S}ikonja and Daniela\n  Zaharie", "title": "Multiple Imputation for Biomedical Data using Monte Carlo Dropout\n  Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to complex experimental settings, missing values are common in biomedical\ndata. To handle this issue, many methods have been proposed, from ignoring\nincomplete instances to various data imputation approaches. With the recent\nrise of deep neural networks, the field of missing data imputation has oriented\ntowards modelling of the data distribution. This paper presents an approach\nbased on Monte Carlo dropout within (Variational) Autoencoders which offers not\nonly very good adaptation to the distribution of the data but also allows\ngeneration of new data, adapted to each specific instance. The evaluation shows\nthat the imputation error and predictive similarity can be improved with the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 06:28:13 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Miok", "Kristian", ""], ["Nguyen-Doan", "Dong", ""], ["Robnik-\u0160ikonja", "Marko", ""], ["Zaharie", "Daniela", ""]]}, {"id": "2005.06182", "submitter": "Hyuntae Lim", "authors": "Hyuntae Lim and YounJoon Jung", "title": "MLSolv-A: A Novel Machine Learning-Based Prediction of Solvation Free\n  Energies from Pairwise Atomistic Interactions", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.soft cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in machine learning and their applications have lead to the\ndevelopment of diverse structure-property relationship models for crucial\nchemical properties, and the solvation free energy is one of them. Here, we\nintroduce a novel ML-based solvation model, which calculates the solvation\nenergy from pairwise atomistic interactions. The novelty of the proposed model\nconsists of a simple architecture: two encoding functions extract atomic\nfeature vectors from the given chemical structure, while the inner product\nbetween two atomistic features calculates their interactions. The results on\n6,493 experimental measurements achieve outstanding performance and\ntransferability for enlarging training data due to its solvent-non-specific\nnature. Analysis of the interaction map shows there is a great potential that\nour model reproduces group contributions on the solvation energy, which makes\nus believe that the model not only provides the predicted target property but\nalso gives us more detailed physicochemical insights.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 06:53:54 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 13:18:02 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Lim", "Hyuntae", ""], ["Jung", "YounJoon", ""]]}, {"id": "2005.06194", "submitter": "Alex Wozniakowski", "authors": "Alex Wozniakowski, Jayne Thompson, Mile Gu, Felix Binder", "title": "Boosting on the shoulders of giants in quantum device calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional machine learning applications, such as optical character\nrecognition, arose from the inability to explicitly program a computer to\nperform a routine task. In this context, learning algorithms usually derive a\nmodel exclusively from the evidence present in a massive dataset. Yet in some\nscientific disciplines, obtaining an abundance of data is an impractical\nluxury, however; there is an explicit model of the domain based upon previous\nscientific discoveries. Here we introduce a new approach to machine learning\nthat is able to leverage prior scientific discoveries in order to improve\ngeneralizability over a scientific model. We show its efficacy in predicting\nthe entire energy spectrum of a Hamiltonian on a superconducting quantum\ndevice, a key task in present quantum computer calibration. Our accuracy\nsurpasses the current state-of-the-art by over $20\\%.$ Our approach thus\ndemonstrates how artificial intelligence can be further enhanced by \"standing\non the shoulders of giants.\"\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 07:59:57 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Wozniakowski", "Alex", ""], ["Thompson", "Jayne", ""], ["Gu", "Mile", ""], ["Binder", "Felix", ""]]}, {"id": "2005.06195", "submitter": "Isac Arnekvist", "authors": "Isac Arnekvist, J. Frederico Carvalho, Danica Kragic and Johannes A.\n  Stork", "title": "The effect of Target Normalization and Momentum on Dying ReLU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing parameters with momentum, normalizing data values, and using\nrectified linear units (ReLUs) are popular choices in neural network (NN)\nregression. Although ReLUs are popular, they can collapse to a constant\nfunction and \"die\", effectively removing their contribution from the model.\nWhile some mitigations are known, the underlying reasons of ReLUs dying during\noptimization are currently poorly understood. In this paper, we consider the\neffects of target normalization and momentum on dying ReLUs. We find\nempirically that unit variance targets are well motivated and that ReLUs die\nmore easily, when target variance approaches zero. To further investigate this\nmatter, we analyze a discrete-time linear autonomous system, and show\ntheoretically how this relates to a model with a single ReLU and how common\nproperties can result in dying ReLU. We also analyze the gradients of a\nsingle-ReLU model to identify saddle points and regions corresponding to dying\nReLU and how parameters evolve into these regions when momentum is used.\nFinally, we show empirically that this problem persist, and is aggravated, for\ndeeper models including residual networks.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 08:01:13 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Arnekvist", "Isac", ""], ["Carvalho", "J. Frederico", ""], ["Kragic", "Danica", ""], ["Stork", "Johannes A.", ""]]}, {"id": "2005.06216", "submitter": "Onur Tasar", "authors": "Onur Tasar, Alain Giros, Yuliya Tarabalka, Pierre Alliez, S\\'ebastien\n  Clerc", "title": "DAugNet: Unsupervised, Multi-source, Multi-target, and Life-long Domain\n  Adaptation for Semantic Segmentation of Satellite Images", "comments": null, "journal-ref": null, "doi": "10.1109/TGRS.2020.3006161", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The domain adaptation of satellite images has recently gained an increasing\nattention to overcome the limited generalization abilities of machine learning\nmodels when segmenting large-scale satellite images. Most of the existing\napproaches seek for adapting the model from one domain to another. However,\nsuch single-source and single-target setting prevents the methods from being\nscalable solutions, since nowadays multiple source and target domains having\ndifferent data distributions are usually available. Besides, the continuous\nproliferation of satellite images necessitates the classifiers to adapt to\ncontinuously increasing data. We propose a novel approach, coined DAugNet, for\nunsupervised, multi-source, multi-target, and life-long domain adaptation of\nsatellite images. It consists of a classifier and a data augmentor. The data\naugmentor, which is a shallow network, is able to perform style transfer\nbetween multiple satellite images in an unsupervised manner, even when new data\nare added over the time. In each training iteration, it provides the classifier\nwith diversified data, which makes the classifier robust to large data\ndistribution difference between the domains. Our extensive experiments prove\nthat DAugNet significantly better generalizes to new geographic locations than\nthe existing approaches.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 09:11:22 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 11:48:20 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Tasar", "Onur", ""], ["Giros", "Alain", ""], ["Tarabalka", "Yuliya", ""], ["Alliez", "Pierre", ""], ["Clerc", "S\u00e9bastien", ""]]}, {"id": "2005.06223", "submitter": "Stephane Doncieux", "authors": "Stephane Doncieux (ISIR), Nicolas Bredeche (ISIR), L\\'eni Le Goff\n  (ISIR), Beno\\^it Girard (ISIR), Alexandre Coninx (ISIR), Olivier Sigaud\n  (ISIR), Mehdi Khamassi (ISIR), Natalia D\\'iaz-Rodr\\'iguez (U2IS), David\n  Filliat (U2IS), Timothy Hospedales (ICSA), A. Eiben (VU), Richard Duro", "title": "DREAM Architecture: a Developmental Approach to Open-Ended Learning in\n  Robotics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots are still limited to controlled conditions, that the robot designer\nknows with enough details to endow the robot with the appropriate models or\nbehaviors. Learning algorithms add some flexibility with the ability to\ndiscover the appropriate behavior given either some demonstrations or a reward\nto guide its exploration with a reinforcement learning algorithm. Reinforcement\nlearning algorithms rely on the definition of state and action spaces that\ndefine reachable behaviors. Their adaptation capability critically depends on\nthe representations of these spaces: small and discrete spaces result in fast\nlearning while large and continuous spaces are challenging and either require a\nlong training period or prevent the robot from converging to an appropriate\nbehavior. Beside the operational cycle of policy execution and the learning\ncycle, which works at a slower time scale to acquire new policies, we introduce\nthe redescription cycle, a third cycle working at an even slower time scale to\ngenerate or adapt the required representations to the robot, its environment\nand the task. We introduce the challenges raised by this cycle and we present\nDREAM (Deferred Restructuring of Experience in Autonomous Machines), a\ndevelopmental cognitive architecture to bootstrap this redescription process\nstage by stage, build new state representations with appropriate motivations,\nand transfer the acquired knowledge across domains or tasks or even across\nrobots. We describe results obtained so far with this approach and end up with\na discussion of the questions it raises in Neuroscience.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 09:29:40 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Doncieux", "Stephane", "", "ISIR"], ["Bredeche", "Nicolas", "", "ISIR"], ["Goff", "L\u00e9ni Le", "", "ISIR"], ["Girard", "Beno\u00eet", "", "ISIR"], ["Coninx", "Alexandre", "", "ISIR"], ["Sigaud", "Olivier", "", "ISIR"], ["Khamassi", "Mehdi", "", "ISIR"], ["D\u00edaz-Rodr\u00edguez", "Natalia", "", "U2IS"], ["Filliat", "David", "", "U2IS"], ["Hospedales", "Timothy", "", "ICSA"], ["Eiben", "A.", "", "VU"], ["Duro", "Richard", ""]]}, {"id": "2005.06224", "submitter": "Stephane Doncieux", "authors": "Stephane Doncieux (ISIR), Giuseppe Paolo (ISIR), Alban Laflaqui\\`ere,\n  Alexandre Coninx (ISIR)", "title": "Novelty Search makes Evolvability Inevitable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolvability is an important feature that impacts the ability of evolutionary\nprocesses to find interesting novel solutions and to deal with changing\nconditions of the problem to solve. The estimation of evolvability is not\nstraightforward and is generally too expensive to be directly used as selective\npressure in the evolutionary process. Indirectly promoting evolvability as a\nside effect of other easier and faster to compute selection pressures would\nthus be advantageous. In an unbounded behavior space, it has already been shown\nthat evolvable individuals naturally appear and tend to be selected as they are\nmore likely to invade empty behavior niches. Evolvability is thus a natural\nbyproduct of the search in this context. However, practical agents and\nenvironments often impose limits on the reach-able behavior space. How do these\nboundaries impact evolvability? In this context, can evolvability still be\npromoted without explicitly rewarding it? We show that Novelty Search\nimplicitly creates a pressure for high evolvability even in bounded behavior\nspaces, and explore the reasons for such a behavior. More precisely we show\nthat, throughout the search, the dynamic evaluation of novelty rewards\nindividuals which are very mobile in the behavior space, which in turn promotes\nevolvability.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 09:32:07 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Doncieux", "Stephane", "", "ISIR"], ["Paolo", "Giuseppe", "", "ISIR"], ["Laflaqui\u00e8re", "Alban", "", "ISIR"], ["Coninx", "Alexandre", "", "ISIR"]]}, {"id": "2005.06247", "submitter": "Erika Puiutta", "authors": "Erika Puiutta and Eric MSP Veith", "title": "Explainable Reinforcement Learning: A Survey", "comments": "20 pages, 8 figures, 2 tables; submitted to CD-MAKE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable Artificial Intelligence (XAI), i.e., the development of more\ntransparent and interpretable AI models, has gained increased traction over the\nlast few years. This is due to the fact that, in conjunction with their growth\ninto powerful and ubiquitous tools, AI models exhibit one detrimential\ncharacteristic: a performance-transparency trade-off. This describes the fact\nthat the more complex a model's inner workings, the less clear it is how its\npredictions or decisions were achieved. But, especially considering Machine\nLearning (ML) methods like Reinforcement Learning (RL) where the system learns\nautonomously, the necessity to understand the underlying reasoning for their\ndecisions becomes apparent. Since, to the best of our knowledge, there exists\nno single work offering an overview of Explainable Reinforcement Learning (XRL)\nmethods, this survey attempts to address this gap. We give a short summary of\nthe problem, a definition of important terms, and offer a classification and\nassessment of current XRL methods. We found that a) the majority of XRL methods\nfunction by mimicking and simplifying a complex model instead of designing an\ninherently simple one, and b) XRL (and XAI) methods often neglect to consider\nthe human side of the equation, not taking into account research from related\nfields like psychology or philosophy. Thus, an interdisciplinary effort is\nneeded to adapt the generated explanations to a (non-expert) human user in\norder to effectively progress in the field of XRL and XAI in general.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 10:52:49 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Puiutta", "Erika", ""], ["Veith", "Eric MSP", ""]]}, {"id": "2005.06249", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Hai Zhao, Rui Wang", "title": "Machine Reading Comprehension: The Role of Contextualized Language\n  Models and Beyond", "comments": "51 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine reading comprehension (MRC) aims to teach machines to read and\ncomprehend human languages, which is a long-standing goal of natural language\nprocessing (NLP). With the burst of deep neural networks and the evolution of\ncontextualized language models (CLMs), the research of MRC has experienced two\nsignificant breakthroughs. MRC and CLM, as a phenomenon, have a great impact on\nthe NLP community. In this survey, we provide a comprehensive and comparative\nreview on MRC covering overall research topics about 1) the origin and\ndevelopment of MRC and CLM, with a particular focus on the role of CLMs; 2) the\nimpact of MRC and CLM to the NLP community; 3) the definition, datasets, and\nevaluation of MRC; 4) general MRC architecture and technical methods in the\nview of two-stage Encoder-Decoder solving architecture from the insights of the\ncognitive process of humans; 5) previous highlights, emerging topics, and our\nempirical analysis, among which we especially focus on what works in different\nperiods of MRC researches. We propose a full-view categorization and new\ntaxonomies on these topics. The primary views we have arrived at are that 1)\nMRC boosts the progress from language processing to understanding; 2) the rapid\nimprovement of MRC systems greatly benefits from the development of CLMs; 3)\nthe theme of MRC is gradually moving from shallow text matching to cognitive\nreasoning.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 10:58:50 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Zhao", "Hai", ""], ["Wang", "Rui", ""]]}, {"id": "2005.06251", "submitter": "Tao Meng", "authors": "Shengyu Jia, Tao Meng, Jieyu Zhao and Kai-Wei Chang", "title": "Mitigating Gender Bias Amplification in Distribution by Posterior\n  Regularization", "comments": "7 pages, 3 figures, published in ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced machine learning techniques have boosted the performance of natural\nlanguage processing. Nevertheless, recent studies, e.g., Zhao et al. (2017)\nshow that these techniques inadvertently capture the societal bias hidden in\nthe corpus and further amplify it. However, their analysis is conducted only on\nmodels' top predictions. In this paper, we investigate the gender bias\namplification issue from the distribution perspective and demonstrate that the\nbias is amplified in the view of predicted probability distribution over\nlabels. We further propose a bias mitigation approach based on posterior\nregularization. With little performance loss, our method can almost remove the\nbias amplification in the distribution. Our study sheds the light on\nunderstanding the bias amplification.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 11:07:10 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Jia", "Shengyu", ""], ["Meng", "Tao", ""], ["Zhao", "Jieyu", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "2005.06276", "submitter": "Jie Peng", "authors": "Jie Peng, Weiyu Li, Qing Ling", "title": "Byzantine-Robust Decentralized Stochastic Optimization over Static and\n  Time-Varying Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we consider the Byzantine-robust stochastic optimization\nproblem defined over decentralized static and time-varying networks, where the\nagents collaboratively minimize the summation of expectations of stochastic\nlocal cost functions, but some of the agents are unreliable due to data\ncorruptions, equipment failures or cyber-attacks. The unreliable agents, which\nare called as Byzantine agents thereafter, can send faulty values to their\nneighbors and bias the optimization process. Our key idea to handle the\nByzantine attacks is to formulate a total variation (TV) norm-penalized\napproximation of the Byzantine-free problem, where the penalty term forces the\nlocal models of regular agents to be close, but also allows the existence of\noutliers from the Byzantine agents. A stochastic subgradient method is applied\nto solve the penalized problem. We prove that the proposed method reaches a\nneighborhood of the Byzantine-free optimal solution, and the size of\nneighborhood is determined by the number of Byzantine agents and the network\ntopology. Numerical experiments corroborate the theoretical analysis, as well\nas demonstrate the robustness of the proposed method to Byzantine attacks and\nits superior performance comparing to existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 04:18:39 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 04:41:36 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Peng", "Jie", ""], ["Li", "Weiyu", ""], ["Ling", "Qing", ""]]}, {"id": "2005.06282", "submitter": "Sudipto Mukherjee", "authors": "Sudipto Mukherjee, Subhabrata Mukherjee, Marcello Hasegawa, Ahmed\n  Hassan Awadallah, Ryen White", "title": "Smart To-Do : Automatic Generation of To-Do Items from Emails", "comments": "58th annual meeting of the Association for Computational Linguistics\n  (ACL), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent features in email service applications aim to increase\nproductivity by helping people organize their folders, compose their emails and\nrespond to pending tasks. In this work, we explore a new application,\nSmart-To-Do, that helps users with task management over emails. We introduce a\nnew task and dataset for automatically generating To-Do items from emails where\nthe sender has promised to perform an action. We design a two-stage process\nleveraging recent advances in neural text generation and sequence-to-sequence\nlearning, obtaining BLEU and ROUGE scores of 0:23 and 0:63 for this task. To\nthe best of our knowledge, this is the first work to address the problem of\ncomposing To-Do items from emails.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 02:21:40 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Mukherjee", "Sudipto", ""], ["Mukherjee", "Subhabrata", ""], ["Hasegawa", "Marcello", ""], ["Awadallah", "Ahmed Hassan", ""], ["White", "Ryen", ""]]}, {"id": "2005.06284", "submitter": "Evgeny Mirkes", "authors": "Evgeny M Mirkes", "title": "Artificial Neural Network Pruning to Extract Knowledge", "comments": "IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Neural Networks (NN) are widely used for solving complex problems\nfrom medical diagnostics to face recognition. Despite notable successes, the\nmain disadvantages of NN are also well known: the risk of overfitting, lack of\nexplainability (inability to extract algorithms from trained NN), and high\nconsumption of computing resources. Determining the appropriate specific NN\nstructure for each problem can help overcome these difficulties: Too poor NN\ncannot be successfully trained, but too rich NN gives unexplainable results and\nmay have a high chance of overfitting. Reducing precision of NN parameters\nsimplifies the implementation of these NN, saves computing resources, and makes\nthe NN skills more transparent. This paper lists the basic NN simplification\nproblems and controlled pruning procedures to solve these problems. All the\ndescribed pruning procedures can be implemented in one framework. The developed\nprocedures, in particular, find the optimal structure of NN for each task,\nmeasure the influence of each input signal and NN parameter, and provide a\ndetailed verbal description of the algorithms and skills of NN. The described\nmethods are illustrated by a simple example: the generation of explicit\nalgorithms for predicting the results of the US presidential election.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 12:24:40 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Mirkes", "Evgeny M", ""]]}, {"id": "2005.06305", "submitter": "Hai Phan", "authors": "Hai Phan, Zechun Liu, Dang Huynh, Marios Savvides, Kwang-Ting Cheng,\n  Zhiqiang Shen", "title": "Binarizing MobileNet via Evolution-based Searching", "comments": "Accepted by CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary Neural Networks (BNNs), known to be one among the effectively compact\nnetwork architectures, have achieved great outcomes in the visual tasks.\nDesigning efficient binary architectures is not trivial due to the binary\nnature of the network. In this paper, we propose a use of evolutionary search\nto facilitate the construction and training scheme when binarizing MobileNet, a\ncompact network with separable depth-wise convolution. Inspired by one-shot\narchitecture search frameworks, we manipulate the idea of group convolution to\ndesign efficient 1-Bit Convolutional Neural Networks (CNNs), assuming an\napproximately optimal trade-off between computational cost and model accuracy.\nOur objective is to come up with a tiny yet efficient binary neural\narchitecture by exploring the best candidates of the group convolution while\noptimizing the model performance in terms of complexity and latency. The\napproach is threefold. First, we train strong baseline binary networks with a\nwide range of random group combinations at each convolutional layer. This\nset-up gives the binary neural networks a capability of preserving essential\ninformation through layers. Second, to find a good set of hyperparameters for\ngroup convolutions we make use of the evolutionary search which leverages the\nexploration of efficient 1-bit models. Lastly, these binary models are trained\nfrom scratch in a usual manner to achieve the final binary model. Various\nexperiments on ImageNet are conducted to show that following our construction\nguideline, the final model achieves 60.09% Top-1 accuracy and outperforms the\nstate-of-the-art CI-BCNN with the same computational cost.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 13:25:51 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 15:48:58 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Phan", "Hai", ""], ["Liu", "Zechun", ""], ["Huynh", "Dang", ""], ["Savvides", "Marios", ""], ["Cheng", "Kwang-Ting", ""], ["Shen", "Zhiqiang", ""]]}, {"id": "2005.06316", "submitter": "Masanobu Horie", "authors": "Masanobu Horie, Naoki Morita, Toshiaki Hishinuma, Yu Ihara, Naoto\n  Mitsume", "title": "Isometric Transformation Invariant and Equivariant Graph Convolutional\n  Networks", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are one of the most important data structures for representing\npairwise relations between objects. Specifically, a graph embedded in a\nEuclidean space is essential to solving real problems, such as physical\nsimulations. A crucial requirement for applying graphs in Euclidean spaces to\nphysical simulations is learning and inferring the isometric transformation\ninvariant and equivariant features in a computationally efficient manner. In\nthis paper, we propose a set of transformation invariant and equivariant models\nbased on graph convolutional networks, called IsoGCNs. We demonstrate that the\nproposed model has a competitive performance compared to state-of-the-art\nmethods on tasks related to geometrical and physical simulation data. Moreover,\nthe proposed model can scale up to graphs with 1M vertices and conduct an\ninference faster than a conventional finite element analysis, which the\nexisting equivariant models cannot achieve.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 13:44:44 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 05:22:12 GMT"}, {"version": "v3", "created": "Mon, 21 Dec 2020 18:30:44 GMT"}, {"version": "v4", "created": "Wed, 10 Mar 2021 12:41:51 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Horie", "Masanobu", ""], ["Morita", "Naoki", ""], ["Hishinuma", "Toshiaki", ""], ["Ihara", "Yu", ""], ["Mitsume", "Naoto", ""]]}, {"id": "2005.06331", "submitter": "Jacek Dabrowski", "authors": "Anna Wroblewska (1 and 2), Jacek Dabrowski (1), Michal Pastuszak (1),\n  Andrzej Michalowski (1), Michal Daniluk (1), Barbara Rychalska (1 and 2),\n  Mikolaj Wieczorek (1), Sylwia Sysko-Romanczuk (2) ((1) Synerise, (2) Warsaw\n  University of Technology)", "title": "Multi-modal Embedding Fusion-based Recommender", "comments": "7 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation systems have lately been popularized globally, with primary\nuse cases in online interaction systems, with significant focus on e-commerce\nplatforms. We have developed a machine learning-based recommendation platform,\nwhich can be easily applied to almost any items and/or actions domain. Contrary\nto existing recommendation systems, our platform supports multiple types of\ninteraction data with multiple modalities of metadata natively. This is\nachieved through multi-modal fusion of various data representations. We\ndeployed the platform into multiple e-commerce stores of different kinds, e.g.\nfood and beverages, shoes, fashion items, telecom operators. Here, we present\nour system, its flexibility and performance. We also show benchmark results on\nopen datasets, that significantly outperform state-of-the-art prior work.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 14:13:35 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 11:45:22 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Wroblewska", "Anna", "", "1 and 2"], ["Dabrowski", "Jacek", "", "1 and 2"], ["Pastuszak", "Michal", "", "1 and 2"], ["Michalowski", "Andrzej", "", "1 and 2"], ["Daniluk", "Michal", "", "1 and 2"], ["Rychalska", "Barbara", "", "1 and 2"], ["Wieczorek", "Mikolaj", ""], ["Sysko-Romanczuk", "Sylwia", ""]]}, {"id": "2005.06334", "submitter": "Stefan Lenz", "authors": "Stefan Lenz, Maren Hackenberg, Harald Binder", "title": "The JuliaConnectoR: a functionally oriented interface for integrating\n  Julia in R", "comments": "23 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LG cs.PL stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like many groups considering the new programming language Julia, we faced the\nchallenge of accessing the algorithms that we develop in Julia from R.\nTherefore, we developed the R package JuliaConnectoR, available from the CRAN\nrepository and GitHub (https://github.com/stefan-m-lenz/JuliaConnectoR), in\nparticular for making advanced deep learning tools available. For\nmaintainability and stability, we decided to base communication between R and\nJulia on TCP, using an optimized binary format for exchanging data. Our package\nalso specifically contains features that allow for a convenient interactive use\nin R. This makes it easy to develop R extensions with Julia or to simply call\nfunctionality from Julia packages in R. Interacting with Julia objects and\ncalling Julia functions becomes user-friendly, as Julia functions and variables\nare made directly available as objects in the R workspace. We illustrate the\nfurther features of our package with code examples, and also discuss advantages\nover the two alternative packages JuliaCall and XRJulia. Finally, we\ndemonstrate the usage of the package with a more extensive example for\nemploying neural ordinary differential equations, a recent deep learning\ntechnique that has received much attention. This example also provides more\ngeneral guidance for integrating deep learning techniques from Julia into R.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 14:18:34 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 19:14:29 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Lenz", "Stefan", ""], ["Hackenberg", "Maren", ""], ["Binder", "Harald", ""]]}, {"id": "2005.06364", "submitter": "Vicen\\c{c} G\\'omez", "authors": "Dominik Thalmeier, Hilbert J. Kappen, Simone Totaro, Vicen\\c{c}\n  G\\'omez", "title": "Adaptive Smoothing Path Integral Control", "comments": "23 pages, 5 figures, NeurIPS 2019 Optimization Foundations of\n  Reinforcement Learning Workshop (OptRL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Path Integral control problems a representation of an optimally controlled\ndynamical system can be formally computed and serve as a guidepost to learn a\nparametrized policy. The Path Integral Cross-Entropy (PICE) method tries to\nexploit this, but is hampered by poor sample efficiency. We propose a\nmodel-free algorithm called ASPIC (Adaptive Smoothing of Path Integral Control)\nthat applies an inf-convolution to the cost function to speedup convergence of\npolicy optimization. We identify PICE as the infinite smoothing limit of such\ntechnique and show that the sample efficiency problems that PICE suffers\ndisappear for finite levels of smoothing. For zero smoothing this method\nbecomes a greedy optimization of the cost, which is the standard approach in\ncurrent reinforcement learning. We show analytically and empirically that\nintermediate levels of smoothing are optimal, which renders the new method\nsuperior to both PICE and direct cost-optimization.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 15:17:35 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Thalmeier", "Dominik", ""], ["Kappen", "Hilbert J.", ""], ["Totaro", "Simone", ""], ["G\u00f3mez", "Vicen\u00e7", ""]]}, {"id": "2005.06368", "submitter": "Wietske Bastiaansen", "authors": "Wietske A.P. Bastiaansen, Melek Rousian, R\\'egine P.M.\n  Steegers-Theunissen, Wiro J. Niessen, Anton Koning and Stefan Klein", "title": "Towards segmentation and spatial alignment of the human embryonic brain\n  using deep learning for atlas-based registration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an unsupervised deep learning method for atlas based registration\nto achieve segmentation and spatial alignment of the embryonic brain in a\nsingle framework. Our approach consists of two sequential networks with a\nspecifically designed loss function to address the challenges in 3D first\ntrimester ultrasound. The first part learns the affine transformation and the\nsecond part learns the voxelwise nonrigid deformation between the target image\nand the atlas. We trained this network end-to-end and validated it against a\nground truth on synthetic datasets designed to resemble the challenges present\nin 3D first trimester ultrasound. The method was tested on a dataset of human\nembryonic ultrasound volumes acquired at 9 weeks gestational age, which showed\nalignment of the brain in some cases and gave insight in open challenges for\nthe proposed method. We conclude that our method is a promising approach\ntowards fully automated spatial alignment and segmentation of embryonic brains\nin 3D ultrasound.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 15:23:44 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Bastiaansen", "Wietske A. P.", ""], ["Rousian", "Melek", ""], ["Steegers-Theunissen", "R\u00e9gine P. M.", ""], ["Niessen", "Wiro J.", ""], ["Koning", "Anton", ""], ["Klein", "Stefan", ""]]}, {"id": "2005.06369", "submitter": "Mayalen Etcheverry", "authors": "Mayalen Etcheverry, Pierre-Yves Oudeyer, Chris Reinke", "title": "Progressive growing of self-organized hierarchical representations for\n  exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing agent that can autonomously discover and learn a diversity of\nstructures and skills in unknown changing environments is key for lifelong\nmachine learning. A central challenge is how to learn incrementally\nrepresentations in order to progressively build a map of the discovered\nstructures and re-use it to further explore. To address this challenge, we\nidentify and target several key functionalities. First, we aim to build lasting\nrepresentations and avoid catastrophic forgetting throughout the exploration\nprocess. Secondly we aim to learn a diversity of representations allowing to\ndiscover a \"diversity of diversity\" of structures (and associated skills) in\ncomplex high-dimensional environments. Thirdly, we target representations that\ncan structure the agent discoveries in a coarse-to-fine manner. Finally, we\ntarget the reuse of such representations to drive exploration toward an\n\"interesting\" type of diversity, for instance leveraging human guidance.\nCurrent approaches in state representation learning rely generally on\nmonolithic architectures which do not enable all these functionalities.\nTherefore, we present a novel technique to progressively construct a Hierarchy\nof Observation Latent Models for Exploration Stratification, called HOLMES.\nThis technique couples the use of a dynamic modular model architecture for\nrepresentation learning with intrinsically-motivated goal exploration processes\n(IMGEPs). The paper shows results in the domain of automated discovery of\ndiverse self-organized patterns, considering as testbed the experimental\nframework from Reinke et al. (2019).\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 15:24:42 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Etcheverry", "Mayalen", ""], ["Oudeyer", "Pierre-Yves", ""], ["Reinke", "Chris", ""]]}, {"id": "2005.06370", "submitter": "Tomer Wullach", "authors": "Tomer Wullach, Amir Adler, Einat Minkov", "title": "Towards Hate Speech Detection at Large via Deep Generative Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hate speech detection is a critical problem in social media platforms, being\noften accused for enabling the spread of hatred and igniting physical violence.\nHate speech detection requires overwhelming resources including\nhigh-performance computing for online posts and tweets monitoring as well as\nthousands of human experts for daily screening of suspected posts or tweets.\nRecently, Deep Learning (DL)-based solutions have been proposed for automatic\ndetection of hate speech, using modest-sized training datasets of few thousands\nof hate speech sequences. While these methods perform well on the specific\ndatasets, their ability to detect new hate speech sequences is limited and has\nnot been investigated. Being a data-driven approach, it is well known that DL\nsurpasses other methods whenever a scale-up in train dataset size and diversity\nis achieved. Therefore, we first present a dataset of 1 million realistic hate\nand non-hate sequences, produced by a deep generative language model. We\nfurther utilize the generated dataset to train a well-studied DL-based hate\nspeech detector, and demonstrate consistent and significant performance\nimprovements across five public hate speech datasets. Therefore, the proposed\nsolution enables high sensitivity detection of a very large variety of hate\nspeech sequences, paving the way to a fully automatic solution.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 15:25:59 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Wullach", "Tomer", ""], ["Adler", "Amir", ""], ["Minkov", "Einat", ""]]}, {"id": "2005.06376", "submitter": "Petros Stavropoulos", "authors": "Petros Stavropoulos, Dimitris Pappas, Ion Androutsopoulos, Ryan\n  McDonald", "title": "BIOMRC: A Dataset for Biomedical Machine Reading Comprehension", "comments": "10 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce BIOMRC, a large-scale cloze-style biomedical MRC dataset. Care\nwas taken to reduce noise, compared to the previous BIOREAD dataset of Pappas\net al. (2018). Experiments show that simple heuristics do not perform well on\nthe new dataset, and that two neural MRC models that had been tested on BIOREAD\nperform much better on BIOMRC, indicating that the new dataset is indeed less\nnoisy or at least that its task is more feasible. Non-expert human performance\nis also higher on the new dataset compared to BIOREAD, and biomedical experts\nperform even better. We also introduce a new BERT-based MRC model, the best\nversion of which substantially outperforms all other methods tested, reaching\nor surpassing the accuracy of biomedical experts in some experiments. We make\nthe new dataset available in three different sizes, also releasing our code,\nand providing a leaderboard.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 15:38:12 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Stavropoulos", "Petros", ""], ["Pappas", "Dimitris", ""], ["Androutsopoulos", "Ion", ""], ["McDonald", "Ryan", ""]]}, {"id": "2005.06377", "submitter": "Forrest Bao", "authors": "Forrest Sheng Bao, Hebi Li, Ge Luo, Cen Chen, Yinfei Yang, Youbiao He,\n  Minghui Qiu", "title": "End-to-end Semantics-based Summary Quality Assessment for\n  Single-document Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical automatic summary evaluation metrics, such as ROUGE, suffer from\ntwo drawbacks. First, semantic similarity and linguistic quality are not\ncaptured well. Second, a reference summary, which is expensive or impossible to\nobtain in many cases, is needed. Existing efforts to address the two drawbacks\nare done separately and have limitations. To holistically address them, we\nintroduce an end-to-end approach for summary quality assessment by leveraging\nsentence or document embedding and introducing two negative sampling approaches\nto create training data for this supervised approach. The proposed approach\nexhibits promising results on several summarization datasets of various domains\nincluding news, legislative bills, scientific papers, and patents. When rating\nmachine-generated summaries in TAC2010, our approach outperforms ROUGE in terms\nof linguistic quality, and achieves a correlation coefficient of up to 0.5702\nwith human evaluations in terms of modified pyramid scores. We hope our\napproach can facilitate summarization research or applications when reference\nsummaries are infeasible or costly to obtain, or when linguistic quality is a\nfocus.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 15:40:13 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 22:43:05 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Bao", "Forrest Sheng", ""], ["Li", "Hebi", ""], ["Luo", "Ge", ""], ["Chen", "Cen", ""], ["Yang", "Yinfei", ""], ["He", "Youbiao", ""], ["Qiu", "Minghui", ""]]}, {"id": "2005.06386", "submitter": "Peter Ormosi", "authors": "Ivan Slobozhan, Peter Ormosi, Rajesh Sharma", "title": "Which bills are lobbied? Predicting and interpreting lobbying activity\n  in the US", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CL cs.LG q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using lobbying data from OpenSecrets.org, we offer several experiments\napplying machine learning techniques to predict if a piece of legislation (US\nbill) has been subjected to lobbying activities or not. We also investigate the\ninfluence of the intensity of the lobbying activity on how discernible a\nlobbied bill is from one that was not subject to lobbying. We compare the\nperformance of a number of different models (logistic regression, random\nforest, CNN and LSTM) and text embedding representations (BOW, TF-IDF, GloVe,\nLaw2Vec). We report results of above 0.85% ROC AUC scores, and 78% accuracy.\nModel performance significantly improves (95% ROC AUC, and 88% accuracy) when\nbills with higher lobbying intensity are looked at. We also propose a method\nthat could be used for unlabelled data. Through this we show that there is a\nconsiderably large number of previously unlabelled US bills where our\npredictions suggest that some lobbying activity took place. We believe our\nmethod could potentially contribute to the enforcement of the US Lobbying\nDisclosure Act (LDA) by indicating the bills that were likely to have been\naffected by lobbying but were not filed as such.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 10:46:33 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Slobozhan", "Ivan", ""], ["Ormosi", "Peter", ""], ["Sharma", "Rajesh", ""]]}, {"id": "2005.06392", "submitter": "Jincheng Mei", "authors": "Jincheng Mei, Chenjun Xiao, Csaba Szepesvari, Dale Schuurmans", "title": "On the Global Convergence Rates of Softmax Policy Gradient Methods", "comments": "64 pages, 5 figures. Published in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We make three contributions toward better understanding policy gradient\nmethods in the tabular setting. First, we show that with the true gradient,\npolicy gradient with a softmax parametrization converges at a $O(1/t)$ rate,\nwith constants depending on the problem and initialization. This result\nsignificantly expands the recent asymptotic convergence results. The analysis\nrelies on two findings: that the softmax policy gradient satisfies a\n\\L{}ojasiewicz inequality, and the minimum probability of an optimal action\nduring optimization can be bounded in terms of its initial value. Second, we\nanalyze entropy regularized policy gradient and show that it enjoys a\nsignificantly faster linear convergence rate $O(e^{-t})$ toward softmax optimal\npolicy. This result resolves an open question in the recent literature.\nFinally, combining the above two results and additional new $\\Omega(1/t)$ lower\nbound results, we explain how entropy regularization improves policy\noptimization, even with the true gradient, from the perspective of convergence\nrate. The separation of rates is further explained using the notion of\nnon-uniform \\L{}ojasiewicz degree. These results provide a theoretical\nunderstanding of the impact of entropy and corroborate existing empirical\nstudies.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 16:01:39 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 06:42:59 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Mei", "Jincheng", ""], ["Xiao", "Chenjun", ""], ["Szepesvari", "Csaba", ""], ["Schuurmans", "Dale", ""]]}, {"id": "2005.06394", "submitter": "Minh Tu Hoang", "authors": "Minh Tu Hoang, Brosnan Yuen, Kai Ren, Xiaodai Dong, Tao Lu, Robert\n  Westendorp, Kishore Reddy", "title": "A CNN-LSTM Quantifier for Single Access Point CSI Indoor Localization", "comments": "Channel state information (CSI), WiFi indoor localization,\n  convolutional neural network, long short-term memory, fingerprint-based\n  localization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a combined network structure between convolutional neural\nnetwork (CNN) and long-short term memory (LSTM) quantifier for WiFi\nfingerprinting indoor localization. In contrast to conventional methods that\nutilize only spatial data with classification models, our CNN-LSTM network\nextracts both space and time features of the received channel state information\n(CSI) from a single router. Furthermore, the proposed network builds a\nquantification model rather than a limited classification model as in most of\nthe literature work, which enables the estimation of testing points that are\nnot identical to the reference points. We analyze the instability of CSI and\ndemonstrate a mitigation solution using a comprehensive filter and\nnormalization scheme. The localization accuracy is investigated through\nextensive on-site experiments with several mobile devices including mobile\nphone (Nexus 5) and laptop (Intel 5300 NIC) on hundreds of testing locations.\nUsing only a single WiFi router, our structure achieves an average localization\nerror of 2.5~m with $\\mathrm{80\\%}$ of the errors under 4~m, which outperforms\nthe other reported algorithms by approximately $\\mathrm{50\\%}$ under the same\ntest environment.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 16:54:31 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Hoang", "Minh Tu", ""], ["Yuen", "Brosnan", ""], ["Ren", "Kai", ""], ["Dong", "Xiaodai", ""], ["Lu", "Tao", ""], ["Westendorp", "Robert", ""], ["Reddy", "Kishore", ""]]}, {"id": "2005.06398", "submitter": "Noam Razin", "authors": "Noam Razin, Nadav Cohen", "title": "Implicit Regularization in Deep Learning May Not Be Explainable by Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematically characterizing the implicit regularization induced by\ngradient-based optimization is a longstanding pursuit in the theory of deep\nlearning. A widespread hope is that a characterization based on minimization of\nnorms may apply, and a standard test-bed for studying this prospect is matrix\nfactorization (matrix completion via linear neural networks). It is an open\nquestion whether norms can explain the implicit regularization in matrix\nfactorization. The current paper resolves this open question in the negative,\nby proving that there exist natural matrix factorization problems on which the\nimplicit regularization drives all norms (and quasi-norms) towards infinity.\nOur results suggest that, rather than perceiving the implicit regularization\nvia norms, a potentially more useful interpretation is minimization of rank. We\ndemonstrate empirically that this interpretation extends to a certain class of\nnon-linear neural networks, and hypothesize that it may be key to explaining\ngeneralization in deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 16:13:30 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 16:47:36 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Razin", "Noam", ""], ["Cohen", "Nadav", ""]]}, {"id": "2005.06401", "submitter": "Mathieu Serrurier", "authors": "Gilles Richard and Mathieu Serrurier", "title": "Dyslexia and Dysgraphia prediction: A new machine learning approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning disabilities like dysgraphia, dyslexia, dyspraxia, etc. interfere\nwith academic achievements but have also long terms consequences beyond the\nacademic time. It is widely admitted that between 5% to 10% of the world\npopulation is subject to this kind of disabilities. For assessing such\ndisabilities in early childhood, children have to solve a battery of tests.\nHuman experts score these tests, and decide whether the children require\nspecific education strategy on the basis of their marks. The assessment can be\nlengthy, costly and emotionally painful. In this paper, we investigate how\nArtificial Intelligence can help in automating this assessment. Gathering a\ndataset of handwritten text pictures and audio recordings, both from standard\nchildren and from dyslexic and/or dysgraphic children, we apply machine\nlearning techniques for classification in order to analyze the differences\nbetween dyslexic/dysgraphic and standard readers/writers and to build a model.\nThe model is trained on simple features obtained by analysing the pictures and\nthe audio files. Our preliminary implementation shows relatively high\nperformances on the dataset we have used. This suggests the possibility to\nscreen dyslexia and dysgraphia via non-invasive methods in an accurate way as\nsoon as enough data are available.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 09:31:51 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Richard", "Gilles", ""], ["Serrurier", "Mathieu", ""]]}, {"id": "2005.06409", "submitter": "Hyounghun Kim", "authors": "Hyounghun Kim, Zineng Tang, Mohit Bansal", "title": "Dense-Caption Matching and Frame-Selection Gating for Temporal\n  Localization in VideoQA", "comments": "ACL 2020 (11 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Videos convey rich information. Dynamic spatio-temporal relationships between\npeople/objects, and diverse multimodal events are present in a video clip.\nHence, it is important to develop automated models that can accurately extract\nsuch information from videos. Answering questions on videos is one of the tasks\nwhich can evaluate such AI abilities. In this paper, we propose a video\nquestion answering model which effectively integrates multi-modal input sources\nand finds the temporally relevant information to answer questions.\nSpecifically, we first employ dense image captions to help identify objects and\ntheir detailed salient regions and actions, and hence give the model useful\nextra information (in explicit textual format to allow easier matching) for\nanswering questions. Moreover, our model is also comprised of dual-level\nattention (word/object and frame level), multi-head self/cross-integration for\ndifferent sources (video and dense captions), and gates which pass more\nrelevant information to the classifier. Finally, we also cast the frame\nselection problem as a multi-label classification task and introduce two loss\nfunctions, In-andOut Frame Score Margin (IOFSM) and Balanced Binary\nCross-Entropy (BBCE), to better supervise the model with human importance\nannotations. We evaluate our model on the challenging TVQA dataset, where each\nof our model components provides significant gains, and our overall model\noutperforms the state-of-the-art by a large margin (74.09% versus 70.52%). We\nalso present several word, object, and frame level visualization studies. Our\ncode is publicly available at:\nhttps://github.com/hyounghk/VideoQADenseCapFrameGate-ACL2020\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 16:35:27 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Kim", "Hyounghun", ""], ["Tang", "Zineng", ""], ["Bansal", "Mohit", ""]]}, {"id": "2005.06413", "submitter": "Louis Abraham", "authors": "Louis Abraham, Gary B\\'ecigneul, Bernhard Sch\\\"olkopf", "title": "Crackovid: Optimizing Group Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem usually referred to as group testing in the context of\nCOVID-19. Given $n$ samples taken from patients, how should we select mixtures\nof samples to be tested, so as to maximize information and minimize the number\nof tests? We consider both adaptive and non-adaptive strategies, and take a\nBayesian approach with a prior both for infection of patients and test errors.\nWe start by proposing a mathematically principled objective, grounded in\ninformation theory. We then optimize non-adaptive optimization strategies using\ngenetic algorithms, and leverage the mathematical framework of adaptive\nsub-modularity to obtain theoretical guarantees for the greedy-adaptive method.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 16:40:09 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Abraham", "Louis", ""], ["B\u00e9cigneul", "Gary", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2005.06417", "submitter": "Sushrut Karmalkar", "authors": "Ilias Diakonikolas, Samuel B. Hopkins, Daniel Kane, Sushrut Karmalkar", "title": "Robustly Learning any Clusterable Mixture of Gaussians", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the efficient learnability of high-dimensional Gaussian mixtures in\nthe outlier-robust setting, where a small constant fraction of the data is\nadversarially corrupted. We resolve the polynomial learnability of this problem\nwhen the components are pairwise separated in total variation distance.\nSpecifically, we provide an algorithm that, for any constant number of\ncomponents $k$, runs in polynomial time and learns the components of an\n$\\epsilon$-corrupted $k$-mixture within information theoretically near-optimal\nerror of $\\tilde{O}(\\epsilon)$, under the assumption that the overlap between\nany pair of components $P_i, P_j$ (i.e., the quantity $1-TV(P_i, P_j)$) is\nbounded by $\\mathrm{poly}(\\epsilon)$.\n  Our separation condition is the qualitatively weakest assumption under which\naccurate clustering of the samples is possible. In particular, it allows for\ncomponents with arbitrary covariances and for components with identical means,\nas long as their covariances differ sufficiently. Ours is the first polynomial\ntime algorithm for this problem, even for $k=2$.\n  Our algorithm follows the Sum-of-Squares based proofs to algorithms approach.\nOur main technical contribution is a new robust identifiability proof of\nclusters from a Gaussian mixture, which can be captured by the constant-degree\nSum of Squares proof system. The key ingredients of this proof are a novel use\nof SoS-certifiable anti-concentration and a new characterization of pairs of\nGaussians with small (dimension-independent) overlap in terms of their\nparameter distance.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 16:44:12 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Hopkins", "Samuel B.", ""], ["Kane", "Daniel", ""], ["Karmalkar", "Sushrut", ""]]}, {"id": "2005.06420", "submitter": "James Henderson", "authors": "James Henderson", "title": "The Unstoppable Rise of Computational Linguistics in Deep Learning", "comments": "13 pages. Accepted for publication at ACL 2020, in the theme track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we trace the history of neural networks applied to natural\nlanguage understanding tasks, and identify key contributions which the nature\nof language has made to the development of neural network architectures. We\nfocus on the importance of variable binding and its instantiation in\nattention-based models, and argue that Transformer is not a sequence model but\nan induced-structure model. This perspective leads to predictions of the\nchallenges facing research in deep learning architectures for natural language\nunderstanding.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 16:51:02 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 10:07:40 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 07:58:28 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Henderson", "James", ""]]}, {"id": "2005.06422", "submitter": "Changlin Jiang", "authors": "Changlin Jiang, Amir Barati Farimani", "title": "Deep Learning Convective Flow Using Conditional Generative Adversarial\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed a general deep learning framework, FluidGAN, that is capable of\nlearning and predicting time-dependent convective flow coupled with energy\ntransport. FluidGAN is thoroughly data-driven with high speed and accuracy and\nsatisfies the physics of fluid without any prior knowledge of underlying fluid\nand energy transport physics. FluidGAN also learns the coupling between\nvelocity, pressure and temperature fields. Our framework could be used to learn\ndeterministic multiphysics phenomena where the underlying physical model is\ncomplex or unknown.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 16:52:27 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Jiang", "Changlin", ""], ["Farimani", "Amir Barati", ""]]}, {"id": "2005.06434", "submitter": "Mohamed Ghalwash", "authors": "Mohamed Ghalwash, Zijun Yao, Prithwish Chakrabotry, James Codella,\n  Daby Sow", "title": "ODVICE: An Ontology-Driven Visual Analytic Tool for Interactive Cohort\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increased availability of electronic health records (EHR) has enabled\nresearchers to study various medical questions. Cohort selection for the\nhypothesis under investigation is one of the main consideration for EHR\nanalysis. For uncommon diseases, cohorts extracted from EHRs contain very\nlimited number of records - hampering the robustness of any analysis. Data\naugmentation methods have been successfully applied in other domains to address\nthis issue mainly using simulated records. In this paper, we present ODVICE, a\ndata augmentation framework that leverages the medical concept ontology to\nsystematically augment records using a novel ontologically guided Monte-Carlo\ngraph spanning algorithm. The tool allows end users to specify a small set of\ninteractive controls to control the augmentation process. We analyze the\nimportance of ODVICE by conducting studies on MIMIC-III dataset for two\nlearning tasks. Our results demonstrate the predictive performance of ODVICE\naugmented cohorts, showing ~30% improvement in area under the curve (AUC) over\nthe non-augmented dataset and other data augmentation strategies.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 17:15:51 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Ghalwash", "Mohamed", ""], ["Yao", "Zijun", ""], ["Chakrabotry", "Prithwish", ""], ["Codella", "James", ""], ["Sow", "Daby", ""]]}, {"id": "2005.06437", "submitter": "Siddhant Arora", "authors": "Siddhant Arora, Srikanta Bedathur", "title": "On Embeddings in Relational Databases", "comments": "9 pages, 6 Figures, Proceedings of Knowledge Representation &\n  Reasoning Meets Machine Learning Workshop, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of learning a distributed representation of entities\nin a relational database using a low-dimensional embedding. Low-dimensional\nembeddings aim to encapsulate a concise vector representation for an underlying\ndataset with minimum loss of information. Embeddings across entities in a\nrelational database have been less explored due to the intricate data relations\nand representation complexity involved. Relational databases are an\ninter-weaved collection of relations that not only model relationships between\nentities but also record complex domain-specific quantitative and temporal\nattributes of data defining complex relationships among entities. Recent\nmethods for learning an embedding constitute of a naive approach to consider\ncomplete denormalization of the database by materializing the full join of all\ntables and representing as a knowledge graph. This popular approach has certain\nlimitations as it fails to capture the inter-row relationships and additional\nsemantics encoded in the relational databases. In this paper we demonstrate; a\nbetter methodology for learning representations by exploiting the underlying\nsemantics of columns in a table while using the relation joins and the latent\ninter-row relationships. Empirical results over a real-world database with\nevaluations on similarity join and table completion tasks support our\nproposition.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 17:21:27 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Arora", "Siddhant", ""], ["Bedathur", "Srikanta", ""]]}, {"id": "2005.06462", "submitter": "Sinong Geng", "authors": "Sinong Geng, Zhaobin Kuang, Peggy Peissig, David Page", "title": "Temporal Poisson Square Root Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose temporal Poisson square root graphical models (TPSQRs), a\ngeneralization of Poisson square root graphical models (PSQRs) specifically\ndesigned for modeling longitudinal event data. By estimating the temporal\nrelationships for all possible pairs of event types, TPSQRs can offer a\nholistic perspective about whether the occurrences of any given event type\ncould excite or inhibit any other type. A TPSQR is learned by estimating a\ncollection of interrelated PSQRs that share the same template parameterization.\nThese PSQRs are estimated jointly in a pseudo-likelihood fashion, where Poisson\npseudo-likelihood is used to approximate the original more\ncomputationally-intensive pseudo-likelihood problem stemming from PSQRs.\nTheoretically, we demonstrate that under mild assumptions, the Poisson\npseudo-likelihood approximation is sparsistent for recovering the underlying\nPSQR. Empirically, we learn TPSQRs from Marshfield Clinic electronic health\nrecords (EHRs) with millions of drug prescription and condition diagnosis\nevents, for adverse drug reaction (ADR) detection. Experimental results\ndemonstrate that the learned TPSQRs can recover ADR signals from the EHR\neffectively and efficiently.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 22:49:45 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Geng", "Sinong", ""], ["Kuang", "Zhaobin", ""], ["Peissig", "Peggy", ""], ["Page", "David", ""]]}, {"id": "2005.06465", "submitter": "Anton Vladzymyrskyy", "authors": "S.P. Morozov, A.E. Andreychenko, N.A. Pavlov, A.V. Vladzymyrskyy, N.V.\n  Ledikhova, V.A. Gombolevskiy, I.A. Blokhin, P.B. Gelezhe, A.V. Gonchar, V.Yu.\n  Chernina", "title": "MosMedData: Chest CT Scans With COVID-19 Related Findings Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This dataset contains anonymised human lung computed tomography (CT) scans\nwith COVID-19 related findings, as well as without such findings. A small\nsubset of studies has been annotated with binary pixel masks depicting regions\nof interests (ground-glass opacifications and consolidations). CT scans were\nobtained between 1st of March, 2020 and 25th of April, 2020, and provided by\nmunicipal hospitals in Moscow, Russia. Permanent link:\nhttps://mosmed.ai/datasets/covid19_1110. This dataset is licensed under a\nCreative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported (CC BY-NC-ND\n3.0) License. Key words: artificial intelligence, COVID-19, machine learning,\ndataset, CT, chest, imaging\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 13:04:37 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Morozov", "S. P.", ""], ["Andreychenko", "A. E.", ""], ["Pavlov", "N. A.", ""], ["Vladzymyrskyy", "A. V.", ""], ["Ledikhova", "N. V.", ""], ["Gombolevskiy", "V. A.", ""], ["Blokhin", "I. A.", ""], ["Gelezhe", "P. B.", ""], ["Gonchar", "A. V.", ""], ["Chernina", "V. Yu.", ""]]}, {"id": "2005.06509", "submitter": "Sahar Imtiaz", "authors": "Sahar Imtiaz, Sebastian Schiessl, Georgios P. Koudouridis and James\n  Gross", "title": "Coordinates-based Resource Allocation Through Supervised Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Appropriate allocation of system resources is essential for meeting the\nincreased user-traffic demands in the next generation wireless technologies.\nTraditionally, the system relies on channel state information (CSI) of the\nusers for optimizing the resource allocation, which becomes costly for\nfast-varying channel conditions. Considering that future wireless technologies\nwill be based on dense network deployment, where the mobile terminals are in\nline-of-sight of the transmitters, the position information of terminals\nprovides an alternative to estimate the channel condition. In this work, we\npropose a coordinates-based resource allocation scheme using supervised machine\nlearning techniques, and investigate how efficiently this scheme performs in\ncomparison to the traditional approach under various propagation conditions. We\nconsider a simplistic system set up as a first step, where a single transmitter\nserves a single mobile user. The performance results show that the\ncoordinates-based resource allocation scheme achieves a performance very close\nto the CSI-based scheme, even when the available coordinates of terminals are\nerroneous. The proposed scheme performs consistently well with realistic-system\nsimulation, requiring only 4 s of training time, and the appropriate resource\nallocation is predicted in less than 90 microseconds with a learnt model of\nsize less than 1 kB.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 18:33:23 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Imtiaz", "Sahar", ""], ["Schiessl", "Sebastian", ""], ["Koudouridis", "Georgios P.", ""], ["Gross", "James", ""]]}, {"id": "2005.06527", "submitter": "Artuur Leeuwenberg", "authors": "Artuur Leeuwenberg, Marie-Francine Moens", "title": "A Survey on Temporal Reasoning for Temporal Information Extraction from\n  Text (Extended Abstract)", "comments": "Extended abstract of a JAIR article, which is to appear in the\n  proceedings of IJCAI 2020 (the copyright of this abstract is held by IJCAI\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time is deeply woven into how people perceive, and communicate about the\nworld. Almost unconsciously, we provide our language utterances with temporal\ncues, like verb tenses, and we can hardly produce sentences without such cues.\nExtracting temporal cues from text, and constructing a global temporal view\nabout the order of described events is a major challenge of automatic natural\nlanguage understanding. Temporal reasoning, the process of combining different\ntemporal cues into a coherent temporal view, plays a central role in temporal\ninformation extraction. This article presents a comprehensive survey of the\nresearch from the past decades on temporal reasoning for automatic temporal\ninformation extraction from text, providing a case study on the integration of\nsymbolic reasoning with machine learning-based information extraction systems.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 18:53:15 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 11:35:51 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Leeuwenberg", "Artuur", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "2005.06540", "submitter": "Slava Jankin Mikhaylov", "authors": "Kakia Chatsiou and Slava Jankin Mikhaylov", "title": "Deep Learning for Political Science", "comments": null, "journal-ref": "The SAGE Handbook of Research Methods in Political Science and\n  International Relations, 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Political science, and social science in general, have traditionally been\nusing computational methods to study areas such as voting behavior, policy\nmaking, international conflict, and international development. More recently,\nincreasingly available quantities of data are being combined with improved\nalgorithms and affordable computational resources to predict, learn, and\ndiscover new insights from data that is large in volume and variety. New\ndevelopments in the areas of machine learning, deep learning, natural language\nprocessing (NLP), and, more generally, artificial intelligence (AI) are opening\nup new opportunities for testing theories and evaluating the impact of\ninterventions and programs in a more dynamic and effective way. Applications\nusing large volumes of structured and unstructured data are becoming common in\ngovernment and industry, and increasingly also in social science research. This\nchapter offers an introduction to such methods drawing examples from political\nscience. Focusing on the areas where the strengths of the methods coincide with\nchallenges in these fields, the chapter first presents an introduction to AI\nand its core technology - machine learning, with its rapidly developing\nsubfield of deep learning. The discussion of deep neural networks is\nillustrated with the NLP tasks that are relevant to political science. The\nlatest advances in deep learning methods for NLP are also reviewed, together\nwith their potential for improving information extraction and pattern\nrecognition from political science texts.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 19:14:37 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Chatsiou", "Kakia", ""], ["Mikhaylov", "Slava Jankin", ""]]}, {"id": "2005.06546", "submitter": "Forrest Bao", "authors": "Forrest Sheng Bao, Youbiao He, Jie Liu, Yuanfang Chen, Qian Li,\n  Christina R. Zhang, Lei Han, Baoli Zhu, Yaorong Ge, Shi Chen, Ming Xu, Liu\n  Ouyang", "title": "Triaging moderate COVID-19 and other viral pneumonias from routine blood\n  tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 is sweeping the world with deadly consequences. Its contagious\nnature and clinical similarity to other pneumonias make separating subjects\ncontracted with COVID-19 and non-COVID-19 viral pneumonia a priority and a\nchallenge. However, COVID-19 testing has been greatly limited by the\navailability and cost of existing methods, even in developed countries like the\nUS. Intrigued by the wide availability of routine blood tests, we propose to\nleverage them for COVID-19 testing using the power of machine learning. Two\nproven-robust machine learning model families, random forests (RFs) and support\nvector machines (SVMs), are employed to tackle the challenge. Trained on blood\ndata from 208 moderate COVID-19 subjects and 86 subjects with non-COVID-19\nmoderate viral pneumonia, the best result is obtained in an SVM-based\nclassifier with an accuracy of 84%, a sensitivity of 88%, a specificity of 80%,\nand a precision of 92%. The results are found explainable from both machine\nlearning and medical perspectives. A privacy-protected web portal is set up to\nhelp medical personnel in their practice and the trained models are released\nfor developers to further build other applications. We hope our results can\nhelp the world fight this pandemic and welcome clinical verification of our\napproach on larger populations.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 19:24:07 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Bao", "Forrest Sheng", ""], ["He", "Youbiao", ""], ["Liu", "Jie", ""], ["Chen", "Yuanfang", ""], ["Li", "Qian", ""], ["Zhang", "Christina R.", ""], ["Han", "Lei", ""], ["Zhu", "Baoli", ""], ["Ge", "Yaorong", ""], ["Chen", "Shi", ""], ["Xu", "Ming", ""], ["Ouyang", "Liu", ""]]}, {"id": "2005.06549", "submitter": "Alex Beatson", "authors": "Alex Beatson, Jordan T. Ash, Geoffrey Roeder, Tianju Xue, Ryan P.\n  Adams", "title": "Learning Composable Energy Surrogates for PDE Order Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-materials are an important emerging class of engineered materials in\nwhich complex macroscopic behaviour--whether electromagnetic, thermal, or\nmechanical--arises from modular substructure. Simulation and optimization of\nthese materials are computationally challenging, as rich substructures\nnecessitate high-fidelity finite element meshes to solve the governing PDEs. To\naddress this, we leverage parametric modular structure to learn component-level\nsurrogates, enabling cheaper high-fidelity simulation. We use a neural network\nto model the stored potential energy in a component given boundary conditions.\nThis yields a structured prediction task: macroscopic behavior is determined by\nthe minimizer of the system's total potential energy, which can be approximated\nby composing these surrogate models. Composable energy surrogates thus permit\nsimulation in the reduced basis of component boundaries. Costly ground-truth\nsimulation of the full structure is avoided, as training data are generated by\nperforming finite element analysis with individual components. Using dataset\naggregation to choose training boundary conditions allows us to learn energy\nsurrogates which produce accurate macroscopic behavior when composed,\naccelerating simulation of parametric meta-materials.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 19:41:24 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 12:29:19 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Beatson", "Alex", ""], ["Ash", "Jordan T.", ""], ["Roeder", "Geoffrey", ""], ["Xue", "Tianju", ""], ["Adams", "Ryan P.", ""]]}, {"id": "2005.06550", "submitter": "Shreshth Saini Mr.", "authors": "Shreshth Saini (1), Divij Gupta (1), Anil Kumar Tiwari (1) ((1) Indian\n  Institute of Technology Jodhpur)", "title": "Detector-SegMentor Network for Skin Lesion Localization and Segmentation", "comments": "9 pages, 7 figures, accepted at NCVPRIPG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Melanoma is a life-threatening form of skin cancer when left undiagnosed at\nthe early stages. Although there are more cases of non-melanoma cancer than\nmelanoma cancer, melanoma cancer is more deadly. Early detection of melanoma is\ncrucial for the timely diagnosis of melanoma cancer and prohibit its spread to\ndistant body parts. Segmentation of skin lesion is a crucial step in the\nclassification of melanoma cancer from the cancerous lesions in dermoscopic\nimages. Manual segmentation of dermoscopic skin images is very time consuming\nand error-prone resulting in an urgent need for an intelligent and accurate\nalgorithm. In this study, we propose a simple yet novel network-in-network\nconvolution neural network(CNN) based approach for segmentation of the skin\nlesion. A Faster Region-based CNN (Faster RCNN) is used for preprocessing to\npredict bounding boxes of the lesions in the whole image which are subsequently\ncropped and fed into the segmentation network to obtain the lesion mask. The\nsegmentation network is a combination of the UNet and Hourglass networks. We\ntrained and evaluated our models on ISIC 2018 dataset and also cross-validated\non PH\\textsuperscript{2} and ISBI 2017 datasets. Our proposed method surpassed\nthe state-of-the-art with Dice Similarity Coefficient of 0.915 and Accuracy\n0.959 on ISIC 2018 dataset and Dice Similarity Coefficient of 0.947 and\nAccuracy 0.971 on ISBI 2017 dataset.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 19:41:27 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Saini", "Shreshth", ""], ["Gupta", "Divij", ""], ["Tiwari", "Anil Kumar", ""]]}, {"id": "2005.06584", "submitter": "Yusan Lin", "authors": "Maryam Moosaei, Yusan Lin, Hao Yang", "title": "Fashion Recommendation and Compatibility Prediction Using Relational\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Fashion is an inherently visual concept and computer vision and artificial\nintelligence (AI) are playing an increasingly important role in shaping the\nfuture of this domain. Many research has been done on recommending fashion\nproducts based on the learned user preferences. However, in addition to\nrecommending single items, AI can also help users create stylish outfits from\nitems they already have, or purchase additional items that go well with their\ncurrent wardrobe. Compatibility is the key factor in creating stylish outfits\nfrom single items. Previous studies have mostly focused on modeling pair-wise\ncompatibility. There are a few approaches that consider an entire outfit, but\nthese approaches have limitations such as requiring rich semantic information,\ncategory labels, and fixed order of items. Thus, they fail to effectively\ndetermine compatibility when such information is not available. In this work,\nwe adopt a Relation Network (RN) to develop new compatibility learning models,\nFashion RN and FashionRN-VSE, that addresses the limitations of existing\napproaches. FashionRN learns the compatibility of an entire outfit, with an\narbitrary number of items, in an arbitrary order. We evaluated our model using\na large dataset of 49,740 outfits that we collected from Polyvore website.\nQuantitatively, our experimental results demonstrate state of the art\nperformance compared with alternative methods in the literature in both\ncompatibility prediction and fill-in-the-blank test. Qualitatively, we also\nshow that the item embedding learned by FashionRN indicate the compatibility\namong fashion items.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 21:00:54 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Moosaei", "Maryam", ""], ["Lin", "Yusan", ""], ["Yang", "Hao", ""]]}, {"id": "2005.06586", "submitter": "Ruriko Yoshida", "authors": "Ruriko Yoshida", "title": "Tropical Data Science", "comments": "22 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.LG q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phylogenomics is a new field which applies to tools in phylogenetics to\ngenome data. Due to a new technology and increasing amount of data, we face new\nchallenges to analyze them over a space of phylogenetic trees. Because a space\nof phylogenetic trees with a fixed set of labels on leaves is not Euclidean, we\ncannot simply apply tools in data science. In this paper we survey some new\ndevelopments of machine learning models using tropical geometry to analyze a\nset of phylogenetic trees over a tree space.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 21:03:41 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Yoshida", "Ruriko", ""]]}, {"id": "2005.06587", "submitter": "Bhanu Pratap Singh Rawat", "authors": "Bhanu Pratap Singh Rawat, Wei-Hung Weng, So Yeon Min, Preethi\n  Raghavan, Peter Szolovits", "title": "Entity-Enriched Neural Models for Clinical Question Answering", "comments": null, "journal-ref": "BioNLP Workshop, ACL'2020", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore state-of-the-art neural models for question answering on\nelectronic medical records and improve their ability to generalize better on\npreviously unseen (paraphrased) questions at test time. We enable this by\nlearning to predict logical forms as an auxiliary task along with the main task\nof answer span detection. The predicted logical forms also serve as a rationale\nfor the answer. Further, we also incorporate medical entity information in\nthese models via the ERNIE architecture. We train our models on the large-scale\nemrQA dataset and observe that our multi-task entity-enriched models generalize\nto paraphrased questions ~5% better than the baseline BERT model.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 21:04:29 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 00:50:27 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Rawat", "Bhanu Pratap Singh", ""], ["Weng", "Wei-Hung", ""], ["Min", "So Yeon", ""], ["Raghavan", "Preethi", ""], ["Szolovits", "Peter", ""]]}, {"id": "2005.06594", "submitter": "Mohi Khansari", "authors": "Mohi Khansari, Daniel Kappler, Jianlan Luo, Jeff Bingham, Mrinal\n  Kalakrishnan", "title": "Action Image Representation: Learning Scalable Deep Grasping Policies\n  with Zero Real World Data", "comments": "7 pages, 10 figures, and 3 tables. To be published in International\n  Conference on Robotics and Automation, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Action Image, a new grasp proposal representation that\nallows learning an end-to-end deep-grasping policy. Our model achieves $84\\%$\ngrasp success on $172$ real world objects while being trained only in\nsimulation on $48$ objects with just naive domain randomization. Similar to\ncomputer vision problems, such as object detection, Action Image builds on the\nidea that object features are invariant to translation in image space.\nTherefore, grasp quality is invariant when evaluating the object-gripper\nrelationship; a successful grasp for an object depends on its local context,\nbut is independent of the surrounding environment. Action Image represents a\ngrasp proposal as an image and uses a deep convolutional network to infer grasp\nquality. We show that by using an Action Image representation, trained networks\nare able to extract local, salient features of grasping tasks that generalize\nacross different objects and environments. We show that this representation\nworks on a variety of inputs, including color images (RGB), depth images (D),\nand combined color-depth (RGB-D). Our experimental results demonstrate that\nnetworks utilizing an Action Image representation exhibit strong domain\ntransfer between training on simulated data and inference on real-world sensor\nstreams. Finally, our experiments show that a network trained with Action Image\nimproves grasp success ($84\\%$ vs. $53\\%$) over a baseline model with the same\nstructure, but using actions encoded as vectors.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 21:40:21 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Khansari", "Mohi", ""], ["Kappler", "Daniel", ""], ["Luo", "Jianlan", ""], ["Bingham", "Jeff", ""], ["Kalakrishnan", "Mrinal", ""]]}, {"id": "2005.06599", "submitter": "Pavlos Papadopoulos", "authors": "Orestis Christou and Nikolaos Pitropakis and Pavlos Papadopoulos and\n  Sean McKeown and William J. Buchanan", "title": "Phishing URL Detection Through Top-level Domain Analysis: A Descriptive\n  Approach", "comments": "In Proceedings of the 6th ICISSP", "journal-ref": "ICISSP, Volume 1, pages 289-298 (2020)", "doi": "10.5220/0008902202890298", "report-no": null, "categories": "cs.CR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phishing is considered to be one of the most prevalent cyber-attacks because\nof its immense flexibility and alarmingly high success rate. Even with adequate\ntraining and high situational awareness, it can still be hard for users to\ncontinually be aware of the URL of the website they are visiting. Traditional\ndetection methods rely on blocklists and content analysis, both of which\nrequire time-consuming human verification. Thus, there have been attempts\nfocusing on the predictive filtering of such URLs. This study aims to develop a\nmachine-learning model to detect fraudulent URLs which can be used within the\nSplunk platform. Inspired from similar approaches in the literature, we trained\nthe SVM and Random Forests algorithms using malicious and benign datasets found\nin the literature and one dataset that we created. We evaluated the algorithms'\nperformance with precision and recall, reaching up to 85% precision and 87%\nrecall in the case of Random Forests while SVM achieved up to 90% precision and\n88% recall using only descriptive features.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 21:41:29 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Christou", "Orestis", ""], ["Pitropakis", "Nikolaos", ""], ["Papadopoulos", "Pavlos", ""], ["McKeown", "Sean", ""], ["Buchanan", "William J.", ""]]}, {"id": "2005.06600", "submitter": "Yu Wang", "authors": "Yu Wang, Yuelin Wang, Jie Liu, Zhuo Liu", "title": "A Comprehensive Survey of Grammar Error Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammar error correction (GEC) is an important application aspect of natural\nlanguage processing techniques. The past decade has witnessed significant\nprogress achieved in GEC for the sake of increasing popularity of machine\nlearning and deep learning, especially in late 2010s when near human-level GEC\nsystems are available. However, there is no prior work focusing on the whole\nrecapitulation of the progress. We present the first survey in GEC for a\ncomprehensive retrospect of the literature in this area. We first give the\nintroduction of five public datasets, data annotation schema, two important\nshared tasks and four standard evaluation metrics. More importantly, we discuss\nfour kinds of basic approaches, including statistical machine translation based\napproach, neural machine translation based approach, classification based\napproach and language model based approach, six commonly applied performance\nboosting techniques for GEC systems and two data augmentation methods. Since\nGEC is typically viewed as a sister task of machine translation, many GEC\nsystems are based on neural machine translation (NMT) approaches, where the\nneural sequence-to-sequence model is applied. Similarly, some performance\nboosting techniques are adapted from machine translation and are successfully\ncombined with GEC systems for enhancement on the final performance.\nFurthermore, we conduct an analysis in level of basic approaches, performance\nboosting techniques and integrated GEC systems based on their experiment\nresults respectively for more clear patterns and conclusions. Finally, we\ndiscuss five prospective directions for future GEC researches.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 04:46:52 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Wang", "Yu", ""], ["Wang", "Yuelin", ""], ["Liu", "Jie", ""], ["Liu", "Zhuo", ""]]}, {"id": "2005.06602", "submitter": "Martin P\\\"omsl", "authors": "Martin P\\\"omsl (Osnabr\\\"uck University) and Roman Lyapin (Cogent Labs\n  Inc.)", "title": "CIRCE at SemEval-2020 Task 1: Ensembling Context-Free and\n  Context-Dependent Word Representations", "comments": "Accepted at SemEval-2020 Task 1 @ COLING 2020. Code available at\n  https://github.com/mpoemsl/circe", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the winning contribution to SemEval-2020 Task 1:\nUnsupervised Lexical Semantic Change Detection (Subtask 2) handed in by team UG\nStudent Intern. We present an ensemble model that makes predictions based on\ncontext-free and context-dependent word representations. The key findings are\nthat (1) context-free word representations are a powerful and robust baseline,\n(2) a sentence classification objective can be used to obtain useful\ncontext-dependent word representations, and (3) combining those representations\nincreases performance on some datasets while decreasing performance on others.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 13:18:29 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 10:10:05 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 13:50:47 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["P\u00f6msl", "Martin", "", "Osnabr\u00fcck University"], ["Lyapin", "Roman", "", "Cogent Labs\n  Inc."]]}, {"id": "2005.06605", "submitter": "Oren Halvani", "authors": "Oren Halvani and Lukas Graner", "title": "POSNoise: An Effective Countermeasure Against Topic Biases in Authorship\n  Analysis", "comments": "Paper has been accepted for publication in: The 16th International\n  Conference on Availability, Reliability and Security (ARES 2021)", "journal-ref": null, "doi": "10.1145/3465481.3470050", "report-no": null, "categories": "cs.CL cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authorship verification (AV) is a fundamental research task in digital text\nforensics, which addresses the problem of whether two texts were written by the\nsame person. In recent years, a variety of AV methods have been proposed that\nfocus on this problem and can be divided into two categories: The first\ncategory refers to such methods that are based on explicitly defined features,\nwhere one has full control over which features are considered and what they\nactually represent. The second category, on the other hand, relates to such AV\nmethods that are based on implicitly defined features, where no control\nmechanism is involved, so that any character sequence in a text can serve as a\npotential feature. However, AV methods belonging to the second category bear\nthe risk that the topic of the texts may bias their classification predictions,\nwhich in turn may lead to misleading conclusions regarding their results. To\ntackle this problem, we propose a preprocessing technique called POSNoise,\nwhich effectively masks topic-related content in a given text. In this way, AV\nmethods are forced to focus on such text units that are more related to the\nwriting style. Our empirical evaluation based on six AV methods (falling into\nthe second category) and seven corpora shows that POSNoise leads to better\nresults compared to a well-known topic masking approach in 34 out of 42 cases,\nwith an increase in accuracy of up to 10%.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 21:10:24 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 09:16:06 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Halvani", "Oren", ""], ["Graner", "Lukas", ""]]}, {"id": "2005.06606", "submitter": "Xuanli He", "authors": "Xuanli He, Gholamreza Haffari, Mohammad Norouzi", "title": "Dynamic Programming Encoding for Subword Segmentation in Neural Machine\n  Translation", "comments": "update related work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Dynamic Programming Encoding (DPE), a new segmentation\nalgorithm for tokenizing sentences into subword units. We view the subword\nsegmentation of output sentences as a latent variable that should be\nmarginalized out for learning and inference. A mixed character-subword\ntransformer is proposed, which enables exact log marginal likelihood estimation\nand exact MAP inference to find target segmentations with maximum posterior\nprobability. DPE uses a lightweight mixed character-subword transformer as a\nmeans of pre-processing parallel data to segment output sentences using dynamic\nprogramming. Empirical results on machine translation suggest that DPE is\neffective for segmenting output sentences and can be combined with BPE dropout\nfor stochastic segmentation of source sentences. DPE achieves an average\nimprovement of 0.9 BLEU over BPE (Sennrich et al., 2016) and an average\nimprovement of 0.55 BLEU over BPE dropout (Provilkov et al., 2019) on several\nWMT datasets including English <=> (German, Romanian, Estonian, Finnish,\nHungarian).\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 05:00:50 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 09:30:27 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["He", "Xuanli", ""], ["Haffari", "Gholamreza", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "2005.06608", "submitter": "El Moatez Billah Nagoudi", "authors": "Ali Alshehri, El Moatez Billah Nagoudi, Muhammad Abdul-Mageed", "title": "Understanding and Detecting Dangerous Speech in Social Media", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media communication has become a significant part of daily activity in\nmodern societies. For this reason, ensuring safety in social media platforms is\na necessity. Use of dangerous language such as physical threats in online\nenvironments is a somewhat rare, yet remains highly important. Although several\nworks have been performed on the related issue of detecting offensive and\nhateful language, dangerous speech has not previously been treated in any\nsignificant way. Motivated by these observations, we report our efforts to\nbuild a labeled dataset for dangerous speech. We also exploit our dataset to\ndevelop highly effective models to detect dangerous content. Our best model\nperforms at 59.60% macro F1, significantly outperforming a competitive\nbaseline.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 09:42:09 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Alshehri", "Ali", ""], ["Nagoudi", "El Moatez Billah", ""], ["Abdul-Mageed", "Muhammad", ""]]}, {"id": "2005.06609", "submitter": "Laura Martinus", "authors": "Laura Martinus, Jason Webster, Joanne Moonsamy, Moses Shaba Jnr, Ridha\n  Moosa, Robert Fairon", "title": "Neural Machine Translation for South Africa's Official Languages", "comments": "workshop paper at AfricaNLP, ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in neural machine translation (NMT) have led to\nstate-of-the-art results for many European-based translation tasks. However,\ndespite these advances, there is has been little focus in applying these\nmethods to African languages. In this paper, we seek to address this gap by\ncreating an NMT benchmark BLEU score between English and the ten remaining\nofficial languages in South Africa.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 08:36:59 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Martinus", "Laura", ""], ["Webster", "Jason", ""], ["Moonsamy", "Joanne", ""], ["Jnr", "Moses Shaba", ""], ["Moosa", "Ridha", ""], ["Fairon", "Robert", ""]]}, {"id": "2005.06610", "submitter": "Massimo La Morgia", "authors": "Massimo La Morgia, Alessandro Mei, Francesco Sassi, Julinda Stefa", "title": "Pump and Dumps in the Bitcoin Era: Real Time Detection of Cryptocurrency\n  Market Manipulations", "comments": "Accepted for publication at The 29th International Conference on\n  Computer Communications and Networks (ICCCN 2020)", "journal-ref": null, "doi": "10.1109/ICCCN49398.2020.9209660", "report-no": null, "categories": "cs.CY cs.CR cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years, cryptocurrencies are increasingly popular. Even people who\nare not experts have started to invest in these securities and nowadays\ncryptocurrency exchanges process transactions for over 100 billion US dollars\nper month. However, many cryptocurrencies have low liquidity and therefore they\nare highly prone to market manipulation schemes. In this paper, we perform an\nin-depth analysis of pump and dump schemes organized by communities over the\nInternet. We observe how these communities are organized and how they carry out\nthe fraud. Then, we report on two case studies related to pump and dump groups.\nLastly, we introduce an approach to detect the fraud in real time that\noutperforms the current state of the art, so to help investors stay out of the\nmarket when a pump and dump scheme is in action.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 21:36:18 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["La Morgia", "Massimo", ""], ["Mei", "Alessandro", ""], ["Sassi", "Francesco", ""], ["Stefa", "Julinda", ""]]}, {"id": "2005.06613", "submitter": "Charlie Kirkwood", "authors": "Charlie Kirkwood, Theo Economou, Henry Odbert, Nicolas Pugeault", "title": "A framework for probabilistic weather forecast post-processing across\n  models and lead times using machine learning", "comments": "17 pages, 9 figures, to be published in Philosophical Transactions of\n  the Royal Society A", "journal-ref": null, "doi": "10.1098/rsta.2020.0099", "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting the weather is an increasingly data intensive exercise. Numerical\nWeather Prediction (NWP) models are becoming more complex, with higher\nresolutions, and there are increasing numbers of different models in operation.\nWhile the forecasting skill of NWP models continues to improve, the number and\ncomplexity of these models poses a new challenge for the operational\nmeteorologist: how should the information from all available models, each with\ntheir own unique biases and limitations, be combined in order to provide\nstakeholders with well-calibrated probabilistic forecasts to use in decision\nmaking? In this paper, we use a road surface temperature example to demonstrate\na three-stage framework that uses machine learning to bridge the gap between\nsets of separate forecasts from NWP models and the 'ideal' forecast for\ndecision support: probabilities of future weather outcomes. First, we use\nQuantile Regression Forests to learn the error profile of each numerical model,\nand use these to apply empirically-derived probability distributions to\nforecasts. Second, we combine these probabilistic forecasts using quantile\naveraging. Third, we interpolate between the aggregate quantiles in order to\ngenerate a full predictive distribution, which we demonstrate has properties\nsuitable for decision support. Our results suggest that this approach provides\nan effective and operationally viable framework for the cohesive\npost-processing of weather forecasts across multiple models and lead times to\nproduce a well-calibrated probabilistic output.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 16:46:02 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 09:45:25 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Kirkwood", "Charlie", ""], ["Economou", "Theo", ""], ["Odbert", "Henry", ""], ["Pugeault", "Nicolas", ""]]}, {"id": "2005.06616", "submitter": "Iulian Vlad Serban", "authors": "Iulian Vlad Serban, Varun Gupta, Ekaterina Kochmar, Dung D. Vu, Robert\n  Belfer, Joelle Pineau, Aaron Courville, Laurent Charlin, Yoshua Bengio", "title": "A Large-Scale, Open-Domain, Mixed-Interface Dialogue-Based ITS for STEM", "comments": "6 pages, 1 figure, 1 table, accepted for publication in the 21st\n  International Conference on Artificial Intelligence in Education (AIED 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Korbit, a large-scale, open-domain, mixed-interface,\ndialogue-based intelligent tutoring system (ITS). Korbit uses machine learning,\nnatural language processing and reinforcement learning to provide interactive,\npersonalized learning online. Korbit has been designed to easily scale to\nthousands of subjects, by automating, standardizing and simplifying the content\ncreation process. Unlike other ITS, a teacher can develop new learning modules\nfor Korbit in a matter of hours. To facilitate learning across a widerange of\nSTEM subjects, Korbit uses a mixed-interface, which includes videos,\ninteractive dialogue-based exercises, question-answering, conceptual diagrams,\nmathematical exercises and gamification elements. Korbit has been built to\nscale to millions of students, by utilizing a state-of-the-art cloud-based\nmicro-service architecture. Korbit launched its first course in 2019 on machine\nlearning, and since then over 7,000 students have enrolled. Although Korbit was\ndesigned to be open-domain and highly scalable, A/B testing experiments with\nreal-world students demonstrate that both student learning outcomes and student\nmotivation are substantially improved compared to typical online courses.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 02:45:43 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Serban", "Iulian Vlad", ""], ["Gupta", "Varun", ""], ["Kochmar", "Ekaterina", ""], ["Vu", "Dung D.", ""], ["Belfer", "Robert", ""], ["Pineau", "Joelle", ""], ["Courville", "Aaron", ""], ["Charlin", "Laurent", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2005.06618", "submitter": "Procheta Sen", "authors": "Procheta Sen, Debasis Ganguly", "title": "Towards Socially Responsible AI: Cognitive Bias-Aware Multi-Objective\n  Learning", "comments": null, "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human society had a long history of suffering from cognitive biases leading\nto social prejudices and mass injustice. The prevalent existence of cognitive\nbiases in large volumes of historical data can pose a threat of being\nmanifested as unethical and seemingly inhuman predictions as outputs of AI\nsystems trained on such data. To alleviate this problem, we propose a\nbias-aware multi-objective learning framework that given a set of identity\nattributes (e.g. gender, ethnicity etc.) and a subset of sensitive categories\nof the possible classes of prediction outputs, learns to reduce the frequency\nof predicting certain combinations of them, e.g. predicting stereotypes such as\n`most blacks use abusive language', or `fear is a virtue of women'. Our\nexperiments conducted on an emotion prediction task with balanced class priors\nshows that a set of baseline bias-agnostic models exhibit cognitive biases with\nrespect to gender, such as women are prone to be afraid whereas men are more\nprone to be angry. In contrast, our proposed bias-aware multi-objective\nlearning methodology is shown to reduce such biases in the predictied emotions.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 17:01:53 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 07:20:09 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Sen", "Procheta", ""], ["Ganguly", "Debasis", ""]]}, {"id": "2005.06619", "submitter": "Ramit Debnath", "authors": "Ramit Debnath and Ronita Bardhan", "title": "India nudges to contain COVID-19 pandemic: a reactive public policy\n  analysis using machine-learning based topic modelling", "comments": "25 pages with 10 figures and 9 tables", "journal-ref": "PLoS ONE 15(9): e0238972 (2020)", "doi": "10.1371/journal.pone.0238972", "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  India locked down 1.3 billion people on March 25, 2020 in the wake of\nCOVID-19 pandemic. The economic cost of it was estimated at USD 98 billion,\nwhile the social costs are still unknown. This study investigated how\ngovernment formed reactive policies to fight coronavirus across its policy\nsectors. Primary data was collected from the Press Information Bureau (PIB) in\nthe form press releases of government plans, policies, programme initiatives\nand achievements. A text corpus of 260,852 words was created from 396 documents\nfrom the PIB. An unsupervised machine-based topic modelling using Latent\nDirichlet Allocation (LDA) algorithm was performed on the text corpus. It was\ndone to extract high probability topics in the policy sectors. The\ninterpretation of the extracted topics was made through a nudge theoretic lens\nto derive the critical policy heuristics of the government. Results showed that\nmost interventions were targeted to generate endogenous nudge by using external\ntriggers. Notably, the nudges from the Prime Minister of India was critical in\ncreating herd effect on lockdown and social distancing norms across the nation.\nA similar effect was also observed around the public health (e.g., masks in\npublic spaces; Yoga and Ayurveda for immunity), transport (e.g., old trains\nconverted to isolation wards), micro, small and medium enterprises (e.g., rapid\nproduction of PPE and masks), science and technology sector (e.g., diagnostic\nkits, robots and nano-technology), home affairs (e.g., surveillance and\nlockdown), urban (e.g. drones, GIS-tools) and education (e.g., online\nlearning). A conclusion was drawn on leveraging these heuristics are crucial\nfor lockdown easement planning.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 04:14:09 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 08:09:16 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Debnath", "Ramit", ""], ["Bardhan", "Ronita", ""]]}, {"id": "2005.06624", "submitter": "Aurelie Mascio", "authors": "Aurelie Mascio, Zeljko Kraljevic, Daniel Bean, Richard Dobson, Robert\n  Stewart, Rebecca Bendayan, Angus Roberts", "title": "Comparative Analysis of Text Classification Approaches in Electronic\n  Health Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification tasks which aim at harvesting and/or organizing\ninformation from electronic health records are pivotal to support clinical and\ntranslational research. However these present specific challenges compared to\nother classification tasks, notably due to the particular nature of the medical\nlexicon and language used in clinical records. Recent advances in embedding\nmethods have shown promising results for several clinical tasks, yet there is\nno exhaustive comparison of such approaches with other commonly used word\nrepresentations and classification models. In this work, we analyse the impact\nof various word representations, text pre-processing and classification\nalgorithms on the performance of four different text classification tasks. The\nresults show that traditional approaches, when tailored to the specific\nlanguage and structure of the text inherent to the classification task, can\nachieve or exceed the performance of more recent ones based on contextual\nembeddings such as BERT.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 14:04:18 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Mascio", "Aurelie", ""], ["Kraljevic", "Zeljko", ""], ["Bean", "Daniel", ""], ["Dobson", "Richard", ""], ["Stewart", "Robert", ""], ["Bendayan", "Rebecca", ""], ["Roberts", "Angus", ""]]}, {"id": "2005.06625", "submitter": "Oguzhan Gencoglu", "authors": "Oguzhan Gencoglu", "title": "Cyberbullying Detection with Fairness Constraints", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": "10.1109/MIC.2020.3032461", "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyberbullying is a widespread adverse phenomenon among online social\ninteractions in today's digital society. While numerous computational studies\nfocus on enhancing the cyberbullying detection performance of machine learning\nalgorithms, proposed models tend to carry and reinforce unintended social\nbiases. In this study, we try to answer the research question of \"Can we\nmitigate the unintended bias of cyberbullying detection models by guiding the\nmodel training with fairness constraints?\". For this purpose, we propose a\nmodel training scheme that can employ fairness constraints and validate our\napproach with different datasets. We demonstrate that various types of\nunintended biases can be successfully mitigated without impairing the model\nquality. We believe our work contributes to the pursuit of unbiased,\ntransparent, and ethical machine learning solutions for cyber-social health.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 13:04:26 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 21:54:00 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Gencoglu", "Oguzhan", ""]]}, {"id": "2005.06627", "submitter": "Junhua Liu", "authors": "Junhua Liu, Trisha Singhal, Lucienne T.M. Blessing, Kristin L. Wood\n  and Kwan Hui Lim", "title": "CrisisBERT: a Robust Transformer for Crisis Classification and\n  Contextual Crisis Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification of crisis events, such as natural disasters, terrorist attacks\nand pandemics, is a crucial task to create early signals and inform relevant\nparties for spontaneous actions to reduce overall damage. Despite crisis such\nas natural disasters can be predicted by professional institutions, certain\nevents are first signaled by civilians, such as the recent COVID-19 pandemics.\nSocial media platforms such as Twitter often exposes firsthand signals on such\ncrises through high volume information exchange over half a billion tweets\nposted daily. Prior works proposed various crisis embeddings and classification\nusing conventional Machine Learning and Neural Network models. However, none of\nthe works perform crisis embedding and classification using state of the art\nattention-based deep neural networks models, such as Transformers and\ndocument-level contextual embeddings. This work proposes CrisisBERT, an\nend-to-end transformer-based model for two crisis classification tasks, namely\ncrisis detection and crisis recognition, which shows promising results across\naccuracy and f1 scores. The proposed model also demonstrates superior\nrobustness over benchmark, as it shows marginal performance compromise while\nextending from 6 to 36 events with only 51.4% additional data points. We also\nproposed Crisis2Vec, an attention-based, document-level contextual embedding\narchitecture for crisis embedding, which achieve better performance than\nconventional crisis embedding methods such as Word2Vec and GloVe. To the best\nof our knowledge, our works are first to propose using transformer-based crisis\nclassification and document-level contextual crisis embedding in the\nliterature.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 09:57:24 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 07:58:23 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Liu", "Junhua", ""], ["Singhal", "Trisha", ""], ["Blessing", "Lucienne T. M.", ""], ["Wood", "Kristin L.", ""], ["Lim", "Kwan Hui", ""]]}, {"id": "2005.06628", "submitter": "Amazon Khetan", "authors": "Ashish Khetan, Zohar Karnin", "title": "schuBERT: Optimizing Elements of BERT", "comments": "11 pages, 6 figures, Accepted for publication in ACL 2020 as a long\n  paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers \\citep{vaswani2017attention} have gradually become a key\ncomponent for many state-of-the-art natural language representation models. A\nrecent Transformer based model- BERT \\citep{devlin2018bert} achieved\nstate-of-the-art results on various natural language processing tasks,\nincluding GLUE, SQuAD v1.1, and SQuAD v2.0. This model however is\ncomputationally prohibitive and has a huge number of parameters. In this work\nwe revisit the architecture choices of BERT in efforts to obtain a lighter\nmodel. We focus on reducing the number of parameters yet our methods can be\napplied towards other objectives such FLOPs or latency. We show that much\nefficient light BERT models can be obtained by reducing algorithmically chosen\ncorrect architecture design dimensions rather than reducing the number of\nTransformer encoder layers. In particular, our schuBERT gives $6.6\\%$ higher\naverage accuracy on GLUE and SQuAD datasets as compared to BERT with three\nencoder layers while having the same number of parameters.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 21:56:04 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Khetan", "Ashish", ""], ["Karnin", "Zohar", ""]]}, {"id": "2005.06630", "submitter": "Ahmed Allam", "authors": "Ahmed Allam, Matthias Dittberner, Anna Sintsova, Dominique Brodbeck,\n  Michael Krauthammer", "title": "Patient Similarity Analysis with Longitudinal Health Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY q-bio.QM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Healthcare professionals have long envisioned using the enormous processing\npowers of computers to discover new facts and medical knowledge locked inside\nelectronic health records. These vast medical archives contain time-resolved\ninformation about medical visits, tests and procedures, as well as outcomes,\nwhich together form individual patient journeys. By assessing the similarities\namong these journeys, it is possible to uncover clusters of common disease\ntrajectories with shared health outcomes. The assignment of patient journeys to\nspecific clusters may in turn serve as the basis for personalized outcome\nprediction and treatment selection. This procedure is a non-trivial\ncomputational problem, as it requires the comparison of patient data with\nmulti-dimensional and multi-modal features that are captured at different times\nand resolutions. In this review, we provide a comprehensive overview of the\ntools and methods that are used in patient similarity analysis with\nlongitudinal data and discuss its potential for improving clinical decision\nmaking.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 07:06:02 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Allam", "Ahmed", ""], ["Dittberner", "Matthias", ""], ["Sintsova", "Anna", ""], ["Brodbeck", "Dominique", ""], ["Krauthammer", "Michael", ""]]}, {"id": "2005.06632", "submitter": "Somaieh Goudarzvand", "authors": "Somaieh Goudarzvand, Gharib Gharibi, Yugyung Lee", "title": "SCAT: Second Chance Autoencoder for Textual Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a k-competitive learning approach for textual autoencoders named\nSecond Chance Autoencoder (SCAT). SCAT selects the $k$ largest and smallest\npositive activations as the winner neurons, which gain the activation values of\nthe loser neurons during the learning process, and thus focus on retrieving\nwell-representative features for topics. Our experiments show that SCAT\nachieves outstanding performance in classification, topic modeling, and\ndocument visualization compared to LDA, K-Sparse, NVCTM, and KATE.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 19:04:31 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 21:22:00 GMT"}, {"version": "v3", "created": "Tue, 8 Sep 2020 20:45:09 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Goudarzvand", "Somaieh", ""], ["Gharibi", "Gharib", ""], ["Lee", "Yugyung", ""]]}, {"id": "2005.06634", "submitter": "Lee Moore", "authors": "Amy Breden, Lee Moore", "title": "Detecting Adverse Drug Reactions from Twitter through Domain-Specific\n  Preprocessing and BERT Ensembling", "comments": "6 pages, 3 figures, uses acl2018.sty", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automation of adverse drug reaction (ADR) detection in social media would\nrevolutionize the practice of pharmacovigilance, supporting drug regulators,\nthe pharmaceutical industry and the general public in ensuring the safety of\nthe drugs prescribed in daily practice. Following from the published\nproceedings of the Social Media Mining for Health (SMM4H) Applications Workshop\n& Shared Task in August 2019, we aimed to develop a deep learning model to\nclassify ADRs within Twitter tweets that contain drug mentions. Our approach\ninvolved fine-tuning $BERT_{LARGE}$ and two domain-specific BERT\nimplementations, $BioBERT$ and $Bio + clinicalBERT$, applying a domain-specific\npreprocessor, and developing a max-prediction ensembling approach. Our final\nmodel resulted in state-of-the-art performance on both $F_1$-score (0.6681) and\nrecall (0.7700) outperforming all models submitted in SMM4H 2019 and during\npost-evaluation to date.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 20:49:24 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Breden", "Amy", ""], ["Moore", "Lee", ""]]}, {"id": "2005.06647", "submitter": "MohammadNoor Injadat", "authors": "MohammadNoor Injadat, Abdallah Moubayed, Ali Bou Nassif, Abdallah\n  Shami", "title": "Systematic Ensemble Model Selection Approach for Educational Data Mining", "comments": "47 Pages, 20 figures, 13 tables, accepted in Elsevier's\n  Knowledge-Based Systems", "journal-ref": null, "doi": "10.1016/j.knosys.2020.105992", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A plethora of research has been done in the past focusing on predicting\nstudent's performance in order to support their development. Many institutions\nare focused on improving the performance and the education quality; and this\ncan be achieved by utilizing data mining techniques to analyze and predict\nstudents' performance and to determine possible factors that may affect their\nfinal marks. To address this issue, this work starts by thoroughly exploring\nand analyzing two different datasets at two separate stages of course delivery\n(20 percent and 50 percent respectively) using multiple graphical, statistical,\nand quantitative techniques. The feature analysis provides insights into the\nnature of the different features considered and helps in the choice of the\nmachine learning algorithms and their parameters. Furthermore, this work\nproposes a systematic approach based on Gini index and p-value to select a\nsuitable ensemble learner from a combination of six potential machine learning\nalgorithms. Experimental results show that the proposed ensemble models achieve\nhigh accuracy and low false positive rate at all stages for both datasets.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 22:25:58 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Injadat", "MohammadNoor", ""], ["Moubayed", "Abdallah", ""], ["Nassif", "Ali Bou", ""], ["Shami", "Abdallah", ""]]}, {"id": "2005.06649", "submitter": "Andreas Loukas", "authors": "Andreas Loukas", "title": "How hard is to distinguish graphs with graph neural networks?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hallmark of graph neural networks is their ability to distinguish the\nisomorphism class of their inputs. This study derives hardness results for the\nclassification variant of graph isomorphism in the message-passing model\n(MPNN). MPNN encompasses the majority of graph neural networks used today and\nis universal when nodes are given unique features. The analysis relies on the\nintroduced measure of communication capacity. Capacity measures how much\ninformation the nodes of a network can exchange during the forward pass and\ndepends on the depth, message-size, global state, and width of the\narchitecture. It is shown that the capacity of MPNN needs to grow linearly with\nthe number of nodes so that a network can distinguish trees and quadratically\nfor general connected graphs. The derived bounds concern both worst- and\naverage-case behavior and apply to networks with/without unique features and\nadaptive architecture -- they are also up to two orders of magnitude tighter\nthan those given by simpler arguments. An empirical study involving 12 graph\nclassification tasks and 420 networks reveals strong alignment between actual\nperformance and theoretical predictions.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 22:28:46 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 12:48:57 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Loukas", "Andreas", ""]]}, {"id": "2005.06650", "submitter": "Arjun Pankajakshan", "authors": "Arjun Pankajakshan, Helen L. Bear, Vinod Subramanian, Emmanouil\n  Benetos", "title": "Memory Controlled Sequential Self Attention for Sound Recognition", "comments": "Accepted to INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we investigate the importance of the extent of memory in\nsequential self attention for sound recognition. We propose to use a memory\ncontrolled sequential self attention mechanism on top of a convolutional\nrecurrent neural network (CRNN) model for polyphonic sound event detection\n(SED). Experiments on the URBAN-SED dataset demonstrate the impact of the\nextent of memory on sound recognition performance with the self attention\ninduced SED model. We extend the proposed idea with a multi-head self attention\nmechanism where each attention head processes the audio embedding with explicit\nattention width values. The proposed use of memory controlled sequential self\nattention offers a way to induce relations among frames of sound event tokens.\nWe show that our memory controlled self attention model achieves an event based\nF -score of 33.92% on the URBAN-SED dataset, outperforming the F -score of\n20.10% reported by the model without self attention.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 22:29:59 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 13:29:03 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 09:43:00 GMT"}, {"version": "v4", "created": "Thu, 6 Aug 2020 00:32:51 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Pankajakshan", "Arjun", ""], ["Bear", "Helen L.", ""], ["Subramanian", "Vinod", ""], ["Benetos", "Emmanouil", ""]]}, {"id": "2005.06653", "submitter": "Brigit Schroeder", "authors": "Brigit Schroeder, Subarna Tripathi", "title": "Structured Query-Based Image Retrieval Using Scene Graphs", "comments": "Accepted to Diagram Image Retrieval and Analysis (DIRA) Workshop at\n  CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A structured query can capture the complexity of object interactions (e.g.\n'woman rides motorcycle') unlike single objects (e.g. 'woman' or 'motorcycle').\nRetrieval using structured queries therefore is much more useful than single\nobject retrieval, but a much more challenging problem. In this paper we present\na method which uses scene graph embeddings as the basis for an approach to\nimage retrieval. We examine how visual relationships, derived from scene\ngraphs, can be used as structured queries. The visual relationships are\ndirected subgraphs of the scene graph with a subject and object as nodes\nconnected by a predicate relationship. Notably, we are able to achieve high\nrecall even on low to medium frequency objects found in the long-tailed\nCOCO-Stuff dataset, and find that adding a visual relationship-inspired loss\nboosts our recall by 10% in the best case.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 22:40:32 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Schroeder", "Brigit", ""], ["Tripathi", "Subarna", ""]]}, {"id": "2005.06654", "submitter": "Dario Kneubuehler", "authors": "Dario Kneubuehler, Shuhang Gu, Luc Van Gool, Radu Timofte", "title": "Flexible Example-based Image Enhancement with Task Adaptive Global\n  Feature Self-Guided Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the first practical multitask image enhancement network, that is\nable to learn one-to-many and many-to-one image mappings. We show that our\nmodel outperforms the current state of the art in learning a single enhancement\nmapping, while having significantly fewer parameters than its competitors.\nFurthermore, the model achieves even higher performance on learning multiple\nmappings simultaneously, by taking advantage of shared representations. Our\nnetwork is based on the recently proposed SGN architecture, with modifications\ntargeted at incorporating global features and style adaption. Finally, we\npresent an unpaired learning method for multitask image enhancement, that is\nbased on generative adversarial networks (GANs).\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 22:45:07 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 12:59:50 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Kneubuehler", "Dario", ""], ["Gu", "Shuhang", ""], ["Van Gool", "Luc", ""], ["Timofte", "Radu", ""]]}, {"id": "2005.06670", "submitter": "Tan Li", "authors": "Tan Li, Linqi Song and Christina Fragouli", "title": "Federated Recommendation System via Differential Privacy", "comments": "This paper is accepted by 2020 IEEE International Symposium on\n  Information Theory(ISIT 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we are interested in what we term the federated private\nbandits framework, that combines differential privacy with multi-agent bandit\nlearning. We explore how differential privacy based Upper Confidence Bound\n(UCB) methods can be applied to multi-agent environments, and in particular to\nfederated learning environments both in `master-worker' and `fully\ndecentralized' settings. We provide a theoretical analysis on the privacy and\nregret performance of the proposed methods and explore the tradeoffs between\nthese two.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 00:00:16 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 04:11:01 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Li", "Tan", ""], ["Song", "Linqi", ""], ["Fragouli", "Christina", ""]]}, {"id": "2005.06674", "submitter": "Sen Na", "authors": "Sen Na, Sungho Shin, Mihai Anitescu, Victor M. Zavala", "title": "On the Convergence of Overlapping Schwarz Decomposition for Nonlinear\n  Optimal Control", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the convergence properties of an overlapping Schwarz\ndecomposition~algorithm for solving nonlinear optimal control problems (OCPs).\nThe approach decomposes the time domain into a set of overlapping subdomains,\nand solves subproblems defined over such subdomains in parallel. Convergence is\nattained by updating primal-dual information at the boundaries of the\noverlapping regions. We show that the algorithm exhibits local linear\nconvergence and that the convergence rate improves exponentially with the\noverlap size. Our convergence results rely on a sensitivity result for OCPs\nthat we call \"exponential decay of sensitivity\" (EDS). Intuitively, EDS states\nthat the impact of parametric perturbations at the boundaries of the domain\n(initial and final time) decays exponentially as one moves into the domain. We\nshow that EDS holds for nonlinear OCPs under a uniform second-order sufficient\ncondition, a controllability condition, and a uniform boundedness condition. We\nconduct numerical experiments using a quadrotor motion planning problem and a\nPDE control problem; and show that the approach is significantly more efficient\nthan ADMM and as efficient as the centralized solver Ipopt.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 00:19:28 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 16:35:53 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 14:57:19 GMT"}, {"version": "v4", "created": "Wed, 7 Jul 2021 17:24:17 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Na", "Sen", ""], ["Shin", "Sungho", ""], ["Anitescu", "Mihai", ""], ["Zavala", "Victor M.", ""]]}, {"id": "2005.06676", "submitter": "Xiaochuang Han", "authors": "Xiaochuang Han, Byron C. Wallace, Yulia Tsvetkov", "title": "Explaining Black Box Predictions and Unveiling Data Artifacts through\n  Influence Functions", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep learning models for NLP are notoriously opaque. This has\nmotivated the development of methods for interpreting such models, e.g., via\ngradient-based saliency maps or the visualization of attention weights. Such\napproaches aim to provide explanations for a particular model prediction by\nhighlighting important words in the corresponding input text. While this might\nbe useful for tasks where decisions are explicitly influenced by individual\ntokens in the input, we suspect that such highlighting is not suitable for\ntasks where model decisions should be driven by more complex reasoning. In this\nwork, we investigate the use of influence functions for NLP, providing an\nalternative approach to interpreting neural text classifiers. Influence\nfunctions explain the decisions of a model by identifying influential training\nexamples. Despite the promise of this approach, influence functions have not\nyet been extensively evaluated in the context of NLP, a gap addressed by this\nwork. We conduct a comparison between influence functions and common\nword-saliency methods on representative tasks. As suspected, we find that\ninfluence functions are particularly useful for natural language inference, a\ntask in which 'saliency maps' may not have clear interpretation. Furthermore,\nwe develop a new quantitative measure based on influence functions that can\nreveal artifacts in training data.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 00:45:23 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Han", "Xiaochuang", ""], ["Wallace", "Byron C.", ""], ["Tsvetkov", "Yulia", ""]]}, {"id": "2005.06678", "submitter": "Chichun Zhou", "authors": "Chi-Chun Zhou, Hai-Long Tu, Yi Liu, and Jian Hua", "title": "Activation functions are not needed: the ratio net", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The function approximator that finds the function mapping the feature to the\nlabel is an important component in a deep neural network for classification\ntasks. To overcome nonlinearity, which is the main difficulty in designing the\nfunction approximator, one usually uses the method based on the nonlinear\nactivation function or the nonlinear kernel function and yields classical\nnetworks such as the feed-forward neural network (MLP) and the radial basis\nfunction network (RBF). Although, classical networks such as the MLP are robust\nin most of the classification task, they are not the most efficient. E.g., they\nuse large amount of parameters and take long times to train. Additionally, the\nchoice of activation functions has a non-negligible influence on the\neffectiveness and efficiency of the network. In this paper, we propose a new\nnetwork that is efficient in finding the function that maps the feature to the\nlabel. Instead of using the nonlinear activation function, the new proposed\nnetwork uses the fractional form to overcome the nonlinearity, thus for the\nsake of convenience, we name the network the ratio net. We compare the\neffectiveness and efficiency of the ratio net and the classical networks such\nas the MLP and the RBF in the classification task on the mnist database of\nhandwritten digits and the IMDb dataset which is a binary sentiment analysis\ndataset. The result shows that the ratio net outperforms both the MLP and the\nRBF.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 01:07:56 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Zhou", "Chi-Chun", ""], ["Tu", "Hai-Long", ""], ["Liu", "Yi", ""], ["Hua", "Jian", ""]]}, {"id": "2005.06684", "submitter": "Abenezer Teklemariam", "authors": "Rohit Saha, Abenezer Teklemariam, Ian Hsu, Alan M. Moses", "title": "W-Cell-Net: Multi-frame Interpolation of Cellular Microscopy Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks are increasingly used in video frame interpolation tasks\nsuch as frame rate changes as well as generating fake face videos. Our project\naims to apply recent advances in Deep video interpolation to increase the\ntemporal resolution of fluorescent microscopy time-lapse movies. To our\nknowledge, there is no previous work that uses Convolutional Neural Networks\n(CNN) to generate frames between two consecutive microscopy images. We propose\na fully convolutional autoencoder network that takes as input two images and\ngenerates upto seven intermediate images. Our architecture has two encoders\neach with a skip connection to a single decoder. We evaluate the performance of\nseveral variants of our model that differ in network architecture and loss\nfunction. Our best model out-performs state of the art video frame\ninterpolation algorithms. We also show qualitative and quantitative comparisons\nwith state-of-the-art video frame interpolation algorithms. We believe deep\nvideo interpolation represents a new approach to improve the time-resolution of\nfluorescent microscopy.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 01:33:38 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Saha", "Rohit", ""], ["Teklemariam", "Abenezer", ""], ["Hsu", "Ian", ""], ["Moses", "Alan M.", ""]]}, {"id": "2005.06692", "submitter": "Dehong Gao", "authors": "Dehong Gao, Wenjing Yang, Huiling Zhou, Yi Wei, Yi Hu and Hao Wang", "title": "Deep Hierarchical Classification for Category Prediction in E-commerce\n  System", "comments": "5pages, to be published in ECNLP workshop of ACL20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In e-commerce system, category prediction is to automatically predict\ncategories of given texts. Different from traditional classification where\nthere are no relations between classes, category prediction is reckoned as a\nstandard hierarchical classification problem since categories are usually\norganized as a hierarchical tree. In this paper, we address hierarchical\ncategory prediction. We propose a Deep Hierarchical Classification framework,\nwhich incorporates the multi-scale hierarchical information in neural networks\nand introduces a representation sharing strategy according to the category\ntree. We also define a novel combined loss function to punish hierarchical\nprediction losses. The evaluation shows that the proposed approach outperforms\nexisting approaches in accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 02:29:14 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Gao", "Dehong", ""], ["Yang", "Wenjing", ""], ["Zhou", "Huiling", ""], ["Wei", "Yi", ""], ["Hu", "Yi", ""], ["Wang", "Hao", ""]]}, {"id": "2005.06706", "submitter": "Yucheng Lu", "authors": "Yucheng Lu, Jack Nash, Christopher De Sa", "title": "MixML: A Unified Analysis of Weakly Consistent Parallel Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallelism is a ubiquitous method for accelerating machine learning\nalgorithms. However, theoretical analysis of parallel learning is usually done\nin an algorithm- and protocol-specific setting, giving little insight about how\nchanges in the structure of communication could affect convergence. In this\npaper we propose MixML, a general framework for analyzing convergence of weakly\nconsistent parallel machine learning. Our framework includes: (1) a unified way\nof modeling the communication process among parallel workers; (2) a new\nparameter, the mixing time tmix, that quantifies how the communication process\naffects convergence; and (3) a principled way of converting a convergence proof\nfor a sequential algorithm into one for a parallel version that depends only on\ntmix. We show MixML recovers and improves on known convergence bounds for\nasynchronous and/or decentralized versions of many algorithms, includingSGD and\nAMSGrad. Our experiments substantiate the theory and show the dependency of\nconvergence on the underlying mixing time.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 03:38:20 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 19:12:55 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Lu", "Yucheng", ""], ["Nash", "Jack", ""], ["De Sa", "Christopher", ""]]}, {"id": "2005.06707", "submitter": "Shaoning Zeng", "authors": "Shaoning Zeng and Bob Zhang", "title": "Noise Homogenization via Multi-Channel Wavelet Filtering for\n  High-Fidelity Sample Generation in GANs", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the generator of typical Generative Adversarial Networks (GANs), a noise\nis inputted to generate fake samples via a series of convolutional operations.\nHowever, current noise generation models merely relies on the information from\nthe pixel space, which increases the difficulty to approach the target\ndistribution. Fortunately, the long proven wavelet transformation is able to\ndecompose multiple spectral information from the images. In this work, we\npropose a novel multi-channel wavelet-based filtering method for GANs, to cope\nwith this problem. When embedding a wavelet deconvolution layer in the\ngenerator, the resultant GAN, called WaveletGAN, takes advantage of the wavelet\ndeconvolution to learn a filtering with multiple channels, which can\nefficiently homogenize the generated noise via an averaging operation, so as to\ngenerate high-fidelity samples. We conducted benchmark experiments on the\nFashion-MNIST, KMNIST and SVHN datasets through an open GAN benchmark tool. The\nresults show that WaveletGAN has excellent performance in generating\nhigh-fidelity samples, thanks to the smallest FIDs obtained on these datasets.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 03:40:11 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Zeng", "Shaoning", ""], ["Zhang", "Bob", ""]]}, {"id": "2005.06716", "submitter": "Mohsen Imani", "authors": "Behnam Khaleghi, Mohsen Imani, Tajana Rosing", "title": "Prive-HD: Privacy-Preserved Hyperdimensional Computing", "comments": "Accepted in Design Automation Conference (DAC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The privacy of data is a major challenge in machine learning as a trained\nmodel may expose sensitive information of the enclosed dataset. Besides, the\nlimited computation capability and capacity of edge devices have made\ncloud-hosted inference inevitable. Sending private information to remote\nservers makes the privacy of inference also vulnerable because of susceptible\ncommunication channels or even untrustworthy hosts. In this paper, we target\nprivacy-preserving training and inference of brain-inspired Hyperdimensional\n(HD) computing, a new learning algorithm that is gaining traction due to its\nlight-weight computation and robustness particularly appealing for edge devices\nwith tight constraints. Indeed, despite its promising attributes, HD computing\nhas virtually no privacy due to its reversible computation. We present an\naccuracy-privacy trade-off method through meticulous quantization and pruning\nof hypervectors, the building blocks of HD, to realize a differentially private\nmodel as well as to obfuscate the information sent for cloud-hosted inference.\nFinally, we show how the proposed techniques can be also leveraged for\nefficient hardware implementation.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 04:19:34 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Khaleghi", "Behnam", ""], ["Imani", "Mohsen", ""], ["Rosing", "Tajana", ""]]}, {"id": "2005.06725", "submitter": "Zhiming Huang", "authors": "Zhiming Huang, Yifan Xu, Bingshan Hu, Qipeng Wang, Jianping Pan", "title": "Thompson Sampling for Combinatorial Semi-bandits with Sleeping Arms and\n  Long-Term Fairness Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the combinatorial sleeping multi-armed semi-bandit problem with\nlong-term fairness constraints~(CSMAB-F). To address the problem, we adopt\nThompson Sampling~(TS) to maximize the total rewards and use virtual queue\ntechniques to handle the fairness constraints, and design an algorithm called\n\\emph{TS with beta priors and Bernoulli likelihoods for CSMAB-F~(TSCSF-B)}.\nFurther, we prove TSCSF-B can satisfy the fairness constraints, and the\ntime-averaged regret is upper bounded by $\\frac{N}{2\\eta} +\nO\\left(\\frac{\\sqrt{mNT\\ln T}}{T}\\right)$, where $N$ is the total number of\narms, $m$ is the maximum number of arms that can be pulled simultaneously in\neach round~(the cardinality constraint) and $\\eta$ is the parameter trading off\nfairness for rewards. By relaxing the fairness constraints (i.e., let $\\eta\n\\rightarrow \\infty$), the bound boils down to the first problem-independent\nbound of TS algorithms for combinatorial sleeping multi-armed semi-bandit\nproblems. Finally, we perform numerical experiments and use a high-rating movie\nrecommendation application to show the effectiveness and efficiency of the\nproposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 05:24:53 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Huang", "Zhiming", ""], ["Xu", "Yifan", ""], ["Hu", "Bingshan", ""], ["Wang", "Qipeng", ""], ["Pan", "Jianping", ""]]}, {"id": "2005.06727", "submitter": "Jesmin Jahan Tithi", "authors": "Jesmin Jahan Tithi and Fabrizio Petrini", "title": "An Efficient Shared-memory Parallel Sinkhorn-Knopp Algorithm to Compute\n  the Word Mover's Distance", "comments": "10 pages, 1 page for reference, total 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Word Mover's Distance (WMD) is a metric that measures the semantic\ndissimilarity between two text documents by computing the cost of moving all\nwords of a source/query document to the most similar words of a target document\noptimally. Computing WMD between two documents is costly because it requires\nsolving an optimization problem that costs \\(O(V^3log(V))\\) where \\(V\\) is the\nnumber of unique words in the document. Fortunately, the WMD can be framed as\nthe Earth Mover's Distance (EMD) (also known as the Optimal Transportation\nDistance) for which it has been shown that the algorithmic complexity can be\nreduced to \\(O(V^2)\\) by adding an entropy penalty to the optimization problem\nand a similar idea can be adapted to compute WMD efficiently. Additionally, the\ncomputation can be made highly parallel by computing WMD of a single query\ndocument against multiple target documents at once (e.g., finding whether a\ngiven tweet is similar to any other tweets happened in a day). In this paper,\nwe present a shared-memory parallel Sinkhorn-Knopp Algorithm to compute the WMD\nof one document against many other documents by adopting the \\(O(V^2)\\) EMD\nalgorithm. We used algorithmic transformations to change the original dense\ncompute-heavy kernel to a sparse compute kernel and obtained \\(67\\times\\)\nspeedup using \\(96\\) cores on the state-of-the-art of Intel\\textregistered{}\n4-sockets Cascade Lake machine w.r.t. its sequential run. Our parallel\nalgorithm is over \\(700\\times\\) faster than the naive parallel python code that\ninternally uses optimized matrix library calls.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 05:30:18 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 23:06:41 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 20:35:08 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Tithi", "Jesmin Jahan", ""], ["Petrini", "Fabrizio", ""]]}, {"id": "2005.06728", "submitter": "Yemao Xu Mr", "authors": "Yemao Xu and Dezun Dong and Weixia Xu and Xiangke Liao", "title": "OD-SGD: One-step Delay Stochastic Gradient Descent for Distributed\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The training of modern deep learning neural network calls for large amounts\nof computation, which is often provided by GPUs or other specific accelerators.\nTo scale out to achieve faster training speed, two update algorithms are mainly\napplied in the distributed training process, i.e. the Synchronous SGD algorithm\n(SSGD) and Asynchronous SGD algorithm (ASGD). SSGD obtains good convergence\npoint while the training speed is slowed down by the synchronous barrier. ASGD\nhas faster training speed but the convergence point is lower when compared to\nSSGD. To sufficiently utilize the advantages of SSGD and ASGD, we propose a\nnovel technology named One-step Delay SGD (OD-SGD) to combine their strengths\nin the training process. Therefore, we can achieve similar convergence point\nand training speed as SSGD and ASGD separately. To the best of our knowledge,\nwe make the first attempt to combine the features of SSGD and ASGD to improve\ndistributed training performance. Each iteration of OD-SGD contains a global\nupdate in the parameter server node and local updates in the worker nodes, the\nlocal update is introduced to update and compensate the delayed local weights.\nWe evaluate our proposed algorithm on MNIST, CIFAR-10 and ImageNet datasets.\nExperimental results show that OD-SGD can obtain similar or even slightly\nbetter accuracy than SSGD, while its training speed is much faster, which even\nexceeds the training speed of ASGD.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 05:33:36 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Xu", "Yemao", ""], ["Dong", "Dezun", ""], ["Xu", "Weixia", ""], ["Liao", "Xiangke", ""]]}, {"id": "2005.06731", "submitter": "Yun-Cheng Tsai", "authors": "Chia-Ying Tsao, Jun-Hao Chen, Samuel Yen-Chi Chen, and Yun-Cheng Tsai", "title": "Data Augmentation for Deep Candlestick Learner", "comments": "12 pages, 9 figures, 2 tables, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To successfully build a deep learning model, it will need a large amount of\nlabeled data. However, labeled data are hard to collect in many use cases. To\ntackle this problem, a bunch of data augmentation methods have been introduced\nrecently and have demonstrated successful results in computer vision, natural\nlanguage and so on. For financial trading data, to our best knowledge,\nsuccessful data augmentation framework has rarely been studied. Here we propose\na Modified Local Search Attack Sampling method to augment the candlestick data,\nwhich is a very important tool for professional trader. Our results show that\nthe proposed method can generate high-quality data which are hard to\ndistinguish by human and will open a new way for finance community to employ\nexisting machine learning techniques even if the dataset is small.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 06:02:31 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 06:02:46 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Tsao", "Chia-Ying", ""], ["Chen", "Jun-Hao", ""], ["Chen", "Samuel Yen-Chi", ""], ["Tsai", "Yun-Cheng", ""]]}, {"id": "2005.06800", "submitter": "Younggyo Seo", "authors": "Kimin Lee, Younggyo Seo, Seunghyun Lee, Honglak Lee, Jinwoo Shin", "title": "Context-aware Dynamics Model for Generalization in Model-Based\n  Reinforcement Learning", "comments": "Accepted in ICML2020. First two authors contributed equally, website:\n  https://sites.google.com/view/cadm code: https://github.com/younggyoseo/CaDM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning (RL) enjoys several benefits, such as\ndata-efficiency and planning, by learning a model of the environment's\ndynamics. However, learning a global model that can generalize across different\ndynamics is a challenging task. To tackle this problem, we decompose the task\nof learning a global dynamics model into two stages: (a) learning a context\nlatent vector that captures the local dynamics, then (b) predicting the next\nstate conditioned on it. In order to encode dynamics-specific information into\nthe context latent vector, we introduce a novel loss function that encourages\nthe context latent vector to be useful for predicting both forward and backward\ndynamics. The proposed method achieves superior generalization ability across\nvarious simulated robotics and control tasks, compared to existing RL schemes.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 08:10:54 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 05:09:57 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 06:41:27 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Lee", "Kimin", ""], ["Seo", "Younggyo", ""], ["Lee", "Seunghyun", ""], ["Lee", "Honglak", ""], ["Shin", "Jinwoo", ""]]}, {"id": "2005.06821", "submitter": "Yehui Tang", "authors": "Yehui Tang, Yunhe Wang, Yixing Xu, Hanting Chen, Chunjing Xu, Boxin\n  Shi, Chao Xu, Qi Tian, Chang Xu", "title": "A Semi-Supervised Assessor of Neural Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) aims to automatically design deep neural\nnetworks of satisfactory performance. Wherein, architecture performance\npredictor is critical to efficiently value an intermediate neural architecture.\nBut for the training of this predictor, a number of neural architectures and\ntheir corresponding real performance often have to be collected. In contrast\nwith classical performance predictor optimized in a fully supervised way, this\npaper suggests a semi-supervised assessor of neural architectures. We employ an\nauto-encoder to discover meaningful representations of neural architectures.\nTaking each neural architecture as an individual instance in the search space,\nwe construct a graph to capture their intrinsic similarities, where both\nlabeled and unlabeled architectures are involved. A graph convolutional neural\nnetwork is introduced to predict the performance of architectures based on the\nlearned representations and their relation modeled by the graph. Extensive\nexperimental results on the NAS-Benchmark-101 dataset demonstrated that our\nmethod is able to make a significant reduction on the required fully trained\narchitectures for finding efficient architectures.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 09:02:33 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Tang", "Yehui", ""], ["Wang", "Yunhe", ""], ["Xu", "Yixing", ""], ["Chen", "Hanting", ""], ["Xu", "Chunjing", ""], ["Shi", "Boxin", ""], ["Xu", "Chao", ""], ["Tian", "Qi", ""], ["Xu", "Chang", ""]]}, {"id": "2005.06828", "submitter": "Luo Chunjie", "authors": "Chunjie Luo, Jianfeng Zhan, Lei Wang, Wanling Gao", "title": "Finet: Using Fine-grained Batch Normalization to Train Light-weight\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To build light-weight network, we propose a new normalization, Fine-grained\nBatch Normalization (FBN). Different from Batch Normalization (BN), which\nnormalizes the final summation of the weighted inputs, FBN normalizes the\nintermediate state of the summation. We propose a novel light-weight network\nbased on FBN, called Finet. At training time, the convolutional layer with FBN\ncan be seen as an inverted bottleneck mechanism. FBN can be fused into\nconvolution at inference time. After fusion, Finet uses the standard\nconvolution with equal channel width, thus makes the inference more efficient.\nOn ImageNet classification dataset, Finet achieves the state-of-art performance\n(65.706% accuracy with 43M FLOPs, and 73.786% accuracy with 303M FLOPs),\nMoreover, experiments show that Finet is more efficient than other state-of-art\nlight-weight networks.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 09:16:13 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Luo", "Chunjie", ""], ["Zhan", "Jianfeng", ""], ["Wang", "Lei", ""], ["Gao", "Wanling", ""]]}, {"id": "2005.06835", "submitter": "Baudouin Denis de Senneville PhD", "authors": "Baudouin Denis de Senneville, Jos\\'e V. Manjon, Pierrick Coup\\'e", "title": "RegQCNET: Deep Quality Control for Image-to-template Brain MRI Affine\n  Registration", "comments": null, "journal-ref": "Physics in Medicine and Biology, 2020", "doi": "10.1088/1361-6560/abb6be", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Affine registration of one or several brain image(s) onto a common reference\nspace is a necessary prerequisite for many image processing tasks, such as\nbrain segmentation or functional analysis. Manual assessment of registration\nquality is a tedious and time-consuming task, especially in studies comprising\na large amount of data. An automated and reliable quality control (QC) becomes\nmandatory. Moreover, the computation time of the QC must be also compatible\nwith the processing of massive datasets. Therefore, an automated deep neural\nnetwork approaches appear as a method of choice to automatically assess\nregistration quality.\n  In the current study, a compact 3D convolutional neural network (CNN),\nreferred to as RegQCNET, is introduced to quantitatively predict the amplitude\nof an affine registration mismatch between a registered image and a reference\ntemplate. This quantitative estimation of registration error is expressed using\nmetric unit system. Therefore, a meaningful task-specific threshold can be\nmanually or automatically defined in order to distinguish usable and non-usable\nimages.\n  The robustness of the proposed RegQCNET is first analyzed on lifespan brain\nimages undergoing various simulated spatial transformations and intensity\nvariations between training and testing. Secondly, the potential of RegQCNET to\nclassify images as usable or non-usable is evaluated using both manual and\nautomatic thresholds. During our experiments, automatic thresholds are\nestimated using several computer-assisted classification models through\ncross-validation. To this end we used expert's visual quality control estimated\non a lifespan cohort of 3953 brains. Finally, the RegQCNET accuracy is compared\nto usual image features.\n  Results show that the proposed deep learning QC is robust, fast and accurate\nto estimate affine registration error in processing pipeline.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 09:27:24 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 16:58:46 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["de Senneville", "Baudouin Denis", ""], ["Manjon", "Jos\u00e9 V.", ""], ["Coup\u00e9", "Pierrick", ""]]}, {"id": "2005.06850", "submitter": "Thomas Hiessl", "authors": "Thomas Hiessl, Daniel Schall, Jana Kemnitz, Stefan Schulte", "title": "Industrial Federated Learning -- Requirements and System Design", "comments": "12 pages, accepted for https://www.paams.net/workshops/agedai", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a very promising approach for improving\ndecentralized Machine Learning (ML) models by exchanging knowledge between\nparticipating clients without revealing private data. Nevertheless, FL is still\nnot tailored to the industrial context as strong data similarity is assumed for\nall FL tasks. This is rarely the case in industrial machine data with\nvariations in machine type, operational- and environmental conditions.\nTherefore, we introduce an Industrial Federated Learning (IFL) system\nsupporting knowledge exchange in continuously evaluated and updated FL cohorts\nof learning tasks with sufficient data similarity. This enables optimal\ncollaboration of business partners in common ML problems, prevents negative\nknowledge transfer, and ensures resource optimization of involved edge devices.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 10:07:48 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Hiessl", "Thomas", ""], ["Schall", "Daniel", ""], ["Kemnitz", "Jana", ""], ["Schulte", "Stefan", ""]]}, {"id": "2005.06852", "submitter": "Pieter Delobelle", "authors": "Pieter Delobelle and Paul Temple and Gilles Perrouin and Beno\\^it\n  Fr\\'enay and Patrick Heymans and Bettina Berendt", "title": "Ethical Adversaries: Towards Mitigating Unfairness with Adversarial\n  Machine Learning", "comments": "15 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is being integrated into a growing number of critical\nsystems with far-reaching impacts on society. Unexpected behaviour and unfair\ndecision processes are coming under increasing scrutiny due to this widespread\nuse and its theoretical considerations. Individuals, as well as organisations,\nnotice, test, and criticize unfair results to hold model designers and\ndeployers accountable. We offer a framework that assists these groups in\nmitigating unfair representations stemming from the training datasets. Our\nframework relies on two inter-operating adversaries to improve fairness. First,\na model is trained with the goal of preventing the guessing of protected\nattributes' values while limiting utility losses. This first step optimizes the\nmodel's parameters for fairness. Second, the framework leverages evasion\nattacks from adversarial machine learning to generate new examples that will be\nmisclassified. These new examples are then used to retrain and improve the\nmodel in the first step. These two steps are iteratively applied until a\nsignificant improvement in fairness is obtained. We evaluated our framework on\nwell-studied datasets in the fairness literature -- including COMPAS -- where\nit can surpass other approaches concerning demographic parity, equality of\nopportunity and also the model's utility. We also illustrate our findings on\nthe subtle difficulties when mitigating unfairness and highlight how our\nframework can assist model designers.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 10:10:19 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 16:47:17 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Delobelle", "Pieter", ""], ["Temple", "Paul", ""], ["Perrouin", "Gilles", ""], ["Fr\u00e9nay", "Beno\u00eet", ""], ["Heymans", "Patrick", ""], ["Berendt", "Bettina", ""]]}, {"id": "2005.06870", "submitter": "Junjie Liu", "authors": "Junjie Liu, Zhe Xu, Runbin Shi, Ray C. C. Cheung, Hayden K.H. So", "title": "Dynamic Sparse Training: Find Efficient Sparse Network From Scratch With\n  Trainable Masked Layers", "comments": "ICLR 2020, camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel network pruning algorithm called Dynamic Sparse Training\nthat can jointly find the optimal network parameters and sparse network\nstructure in a unified optimization process with trainable pruning thresholds.\nThese thresholds can have fine-grained layer-wise adjustments dynamically via\nbackpropagation. We demonstrate that our dynamic sparse training algorithm can\neasily train very sparse neural network models with little performance loss\nusing the same number of training epochs as dense models. Dynamic Sparse\nTraining achieves the state of the art performance compared with other sparse\ntraining algorithms on various network architectures. Additionally, we have\nseveral surprising observations that provide strong evidence for the\neffectiveness and efficiency of our algorithm. These observations reveal the\nunderlying problems of traditional three-stage pruning algorithms and present\nthe potential guidance provided by our algorithm to the design of more compact\nnetwork architectures.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 11:05:21 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Liu", "Junjie", ""], ["Xu", "Zhe", ""], ["Shi", "Runbin", ""], ["Cheung", "Ray C. C.", ""], ["So", "Hayden K. H.", ""]]}, {"id": "2005.06879", "submitter": "Shikui Tu", "authors": "Zhihao Xing, Shikui Tu, Lei Xu", "title": "Solve Traveling Salesman Problem by Monte Carlo Tree Search and Deep\n  Neural Network", "comments": "Was previously submitted to ICAPS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a self-learning approach that combines deep reinforcement learning\nand Monte Carlo tree search to solve the traveling salesman problem. The\nproposed approach has two advantages. First, it adopts deep reinforcement\nlearning to compute the value functions for decision, which removes the need of\nhand-crafted features and labelled data. Second, it uses Monte Carlo tree\nsearch to select the best policy by comparing different value functions, which\nincreases its generalization ability. Experimental results show that the\nproposed method performs favorably against other methods in small-to-medium\nproblem settings. And it shows comparable performance as state-of-the-art in\nlarge problem setting.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 11:36:40 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Xing", "Zhihao", ""], ["Tu", "Shikui", ""], ["Xu", "Lei", ""]]}, {"id": "2005.06892", "submitter": "David Gschwend", "authors": "David Gschwend", "title": "ZynqNet: An FPGA-Accelerated Embedded Convolutional Neural Network", "comments": "85 pages, 26 figures. Code available at\n  http://github.com/dgschwend/zynqnet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image Understanding is becoming a vital feature in ever more applications\nranging from medical diagnostics to autonomous vehicles. Many applications\ndemand for embedded solutions that integrate into existing systems with tight\nreal-time and power constraints. Convolutional Neural Networks (CNNs) presently\nachieve record-breaking accuracies in all image understanding benchmarks, but\nhave a very high computational complexity. Embedded CNNs thus call for small\nand efficient, yet very powerful computing platforms. This master thesis\nexplores the potential of FPGA-based CNN acceleration and demonstrates a fully\nfunctional proof-of-concept CNN implementation on a Zynq System-on-Chip. The\nZynqNet Embedded CNN is designed for image classification on ImageNet and\nconsists of ZynqNet CNN, an optimized and customized CNN topology, and the\nZynqNet FPGA Accelerator, an FPGA-based architecture for its evaluation.\nZynqNet CNN is a highly efficient CNN topology. Detailed analysis and\noptimization of prior topologies using the custom-designed Netscope CNN\nAnalyzer have enabled a CNN with 84.5% top-5 accuracy at a computational\ncomplexity of only 530 million multiplyaccumulate operations. The topology is\nhighly regular and consists exclusively of convolutional layers, ReLU\nnonlinearities and one global pooling layer. The CNN fits ideally onto the FPGA\naccelerator. The ZynqNet FPGA Accelerator allows an efficient evaluation of\nZynqNet CNN. It accelerates the full network based on a nested-loop algorithm\nwhich minimizes the number of arithmetic operations and memory accesses. The\nFPGA accelerator has been synthesized using High-Level Synthesis for the Xilinx\nZynq XC-7Z045, and reaches a clock frequency of 200MHz with a device\nutilization of 80% to 90 %.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 11:54:04 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Gschwend", "David", ""]]}, {"id": "2005.06897", "submitter": "Daniel Weber", "authors": "Daniel Weber, Clemens G\\\"uhmann and Thomas Seel", "title": "Neural Networks Versus Conventional Filters for Inertial-Sensor-based\n  Attitude Estimation", "comments": "accepted for the 23rd International Conference on Information Fusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inertial measurement units are commonly used to estimate the attitude of\nmoving objects. Numerous nonlinear filter approaches have been proposed for\nsolving the inherent sensor fusion problem. However, when a large range of\ndifferent dynamic and static rotational and translational motions is\nconsidered, the attainable accuracy is limited by the need for\nsituation-dependent adjustment of accelerometer and gyroscope fusion weights.\nWe investigate to what extent these limitations can be overcome by means of\nartificial neural networks and how much domain-specific optimization of the\nneural network model is required to outperform the conventional filter\nsolution. A diverse set of motion recordings with a marker-based optical ground\ntruth is used for performance evaluation and comparison. The proposed neural\nnetworks are found to outperform the conventional filter across all motions\nonly if domain-specific optimizations are introduced. We conclude that they are\na promising tool for inertial-sensor-based real-time attitude estimation, but\nboth expert knowledge and rich datasets are required to achieve top\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 11:59:19 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 20:50:55 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Weber", "Daniel", ""], ["G\u00fchmann", "Clemens", ""], ["Seel", "Thomas", ""]]}, {"id": "2005.06898", "submitter": "Susan Leavy Dr", "authors": "Susan Leavy, Gerardine Meaney, Karen Wade, Derek Greene", "title": "Mitigating Gender Bias in Machine Learning Data Sets", "comments": "10 pages, 5 figures, 5 Tables, Presented as Bias2020 workshop (as\n  part of the ECIR Conference) - http://bias.disim.univaq.it", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence has the capacity to amplify and perpetuate societal\nbiases and presents profound ethical implications for society. Gender bias has\nbeen identified in the context of employment advertising and recruitment tools,\ndue to their reliance on underlying language processing and recommendation\nalgorithms. Attempts to address such issues have involved testing learned\nassociations, integrating concepts of fairness to machine learning and\nperforming more rigorous analysis of training data. Mitigating bias when\nalgorithms are trained on textual data is particularly challenging given the\ncomplex way gender ideology is embedded in language. This paper proposes a\nframework for the identification of gender bias in training data for machine\nlearning.The work draws upon gender theory and sociolinguistics to\nsystematically indicate levels of bias in textual training data and associated\nneural word embedding models, thus highlighting pathways for both removing bias\nfrom training data and critically assessing its impact.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 12:06:02 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 08:04:53 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Leavy", "Susan", ""], ["Meaney", "Gerardine", ""], ["Wade", "Karen", ""], ["Greene", "Derek", ""]]}, {"id": "2005.06902", "submitter": "Muhammad Bilal", "authors": "Amin Ullah, Syed M. Anwar, Muhammad Bilal, and Raja M Mehmood", "title": "Classification of Arrhythmia by Using Deep Learning with 2-D ECG\n  Spectral Image Representation", "comments": "14 pages, 5 figures, accepted for future publication in Remote\n  Sensing MDPI Journal", "journal-ref": "Remote Sensing. 2020; 12(10):1685", "doi": "10.3390/rs12101685", "report-no": null, "categories": "eess.SP cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The electrocardiogram (ECG) is one of the most extensively employed signals\nused in the diagnosis and prediction of cardiovascular diseases (CVDs). The ECG\nsignals can capture the heart's rhythmic irregularities, commonly known as\narrhythmias. A careful study of ECG signals is crucial for precise diagnoses of\npatients' acute and chronic heart conditions. In this study, we propose a\ntwo-dimensional (2-D) convolutional neural network (CNN) model for the\nclassification of ECG signals into eight classes; namely, normal beat,\npremature ventricular contraction beat, paced beat, right bundle branch block\nbeat, left bundle branch block beat, atrial premature contraction beat,\nventricular flutter wave beat, and ventricular escape beat. The one-dimensional\nECG time series signals are transformed into 2-D spectrograms through\nshort-time Fourier transform. The 2-D CNN model consisting of four\nconvolutional layers and four pooling layers is designed for extracting robust\nfeatures from the input spectrograms. Our proposed methodology is evaluated on\na publicly available MIT-BIH arrhythmia dataset. We achieved a state-of-the-art\naverage classification accuracy of 99.11\\%, which is better than those of\nrecently reported results in classifying similar types of arrhythmias. The\nperformance is significant in other indices as well, including sensitivity and\nspecificity, which indicates the success of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 12:11:41 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 16:44:45 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Ullah", "Amin", ""], ["Anwar", "Syed M.", ""], ["Bilal", "Muhammad", ""], ["Mehmood", "Raja M", ""]]}, {"id": "2005.06922", "submitter": "Priyanka Golia", "authors": "Priyanka Golia, Subhajit Roy, and Kuldeep S. Meel", "title": "Manthan: A Data Driven Approach for Boolean Function Synthesis", "comments": "24 pages including references, and 8 figures. To be published in 32nd\n  International Conference on Computer-Aided Verification (CAV-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean functional synthesis is a fundamental problem in computer science\nwith wide-ranging applications and has witnessed a surge of interest resulting\nin progressively improved techniques over the past decade. Despite intense\nalgorithmic development, a large number of problems remain beyond the reach of\nthe state of the art techniques. Motivated by the progress in machine learning,\nwe propose Manthan, a novel data-driven approach to Boolean functional\nsynthesis. Manthan views functional synthesis as a classification problem,\nrelying on advances in constrained sampling for data generation, and advances\nin automated reasoning for a novel proof-guided refinement and provable\nverification. On an extensive and rigorous evaluation over 609 benchmarks, we\ndemonstrate that Manthan significantly improves upon the current state of the\nart, solving 356 benchmarks in comparison to 280, which is the most solved by a\nstate of the art technique; thereby, we demonstrate an increase of 76\nbenchmarks over the current state of the art. Furthermore, Manthan solves 60\nbenchmarks that none of the current state of the art techniques could solve.\nThe significant performance improvements, along with our detailed analysis,\nhighlights several interesting avenues of future work at the intersection of\nmachine learning, constrained sampling, and automated reasoning.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 12:44:21 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Golia", "Priyanka", ""], ["Roy", "Subhajit", ""], ["Meel", "Kuldeep S.", ""]]}, {"id": "2005.06928", "submitter": "Christian Berghoff", "authors": "Christian Berghoff", "title": "Protecting the integrity of the training procedure of neural networks", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to significant improvements in performance in recent years, neural\nnetworks are currently used for an ever-increasing number of applications.\nHowever, neural networks have the drawback that their decisions are not readily\ninterpretable and traceable for a human. This creates several problems, for\ninstance in terms of safety and IT security for high-risk applications, where\nassuring these properties is crucial. One of the most striking IT security\nproblems aggravated by the opacity of neural networks is the possibility of\nso-called poisoning attacks during the training phase, where an attacker\ninserts specially crafted data to manipulate the resulting model. We propose an\napproach to this problem which allows provably verifying the integrity of the\ntraining procedure by making use of standard cryptographic mechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 12:57:23 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Berghoff", "Christian", ""]]}, {"id": "2005.06935", "submitter": "Gerome Vivar", "authors": "Gerome Vivar, Anees Kazi, Hendrik Burwinkel, Andreas Zwergal, Nassir\n  Navab, Seyed-Ahmad Ahmadi", "title": "Simultaneous imputation and disease classification in incomplete medical\n  datasets using Multigraph Geometric Matrix Completion (MGMC)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale population-based studies in medicine are a key resource towards\nbetter diagnosis, monitoring, and treatment of diseases. They also serve as\nenablers of clinical decision support systems, in particular Computer Aided\nDiagnosis (CADx) using machine learning (ML). Numerous ML approaches for CADx\nhave been proposed in literature. However, these approaches assume full data\navailability, which is not always feasible in clinical data. To account for\nmissing data, incomplete data samples are either removed or imputed, which\ncould lead to data bias and may negatively affect classification performance.\nAs a solution, we propose an end-to-end learning of imputation and disease\nprediction of incomplete medical datasets via Multigraph Geometric Matrix\nCompletion (MGMC). MGMC uses multiple recurrent graph convolutional networks,\nwhere each graph represents an independent population model based on a key\nclinical meta-feature like age, sex, or cognitive function. Graph signal\naggregation from local patient neighborhoods, combined with multigraph signal\nfusion via self-attention, has a regularizing effect on both matrix\nreconstruction and classification performance. Our proposed approach is able to\nimpute class relevant features as well as perform accurate classification on\ntwo publicly available medical datasets. We empirically show the superiority of\nour proposed approach in terms of classification and imputation performance\nwhen compared with state-of-the-art approaches. MGMC enables disease prediction\nin multimodal and incomplete medical datasets. These findings could serve as\nbaseline for future CADx approaches which utilize incomplete datasets.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 13:11:35 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Vivar", "Gerome", ""], ["Kazi", "Anees", ""], ["Burwinkel", "Hendrik", ""], ["Zwergal", "Andreas", ""], ["Navab", "Nassir", ""], ["Ahmadi", "Seyed-Ahmad", ""]]}, {"id": "2005.06967", "submitter": "Allen Hart", "authors": "Allen G Hart and James L Hook and Jonathan H P Dawes", "title": "Echo State Networks trained by Tikhonov least squares are L2({\\mu})\n  approximators of ergodic dynamical systems", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": "10.1016/j.physd.2021.132882", "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Echo State Networks (ESNs) are a class of single-layer recurrent neural\nnetworks with randomly generated internal weights, and a single layer of\ntuneable outer weights, which are usually trained by regularised linear least\nsquares regression. Remarkably, ESNs still enjoy the universal approximation\nproperty despite the training procedure being entirely linear. In this paper,\nwe prove that an ESN trained on a sequence of observations from an ergodic\ndynamical system (with invariant measure $\\mu$) using Tikhonov least squares\nregression against a set of targets, will approximate the target function in\nthe $L^2(\\mu)$ norm. In the special case that the targets are future\nobservations, the ESN is learning the next step map, which allows time series\nforecasting. We demonstrate the theory numerically by training an ESN using\nTikhonov least squares on a sequence of scalar observations of the Lorenz\nsystem.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 13:39:07 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 16:23:05 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Hart", "Allen G", ""], ["Hook", "James L", ""], ["Dawes", "Jonathan H P", ""]]}, {"id": "2005.06968", "submitter": "Xinsheng Wang", "authors": "Xinsheng Wang, Tingting Qiao, Jihua Zhu, Alan Hanjalic, Odette\n  Scharenborg", "title": "S2IGAN: Speech-to-Image Generation via Adversarial Learning", "comments": "Accepted to Interspeech2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An estimated half of the world's languages do not have a written form, making\nit impossible for these languages to benefit from any existing text-based\ntechnologies. In this paper, a speech-to-image generation (S2IG) framework is\nproposed which translates speech descriptions to photo-realistic images without\nusing any text information, thus allowing unwritten languages to potentially\nbenefit from this technology. The proposed S2IG framework, named S2IGAN,\nconsists of a speech embedding network (SEN) and a relation-supervised\ndensely-stacked generative model (RDG). SEN learns the speech embedding with\nthe supervision of the corresponding visual information. Conditioned on the\nspeech embedding produced by SEN, the proposed RDG synthesizes images that are\nsemantically consistent with the corresponding speech descriptions. Extensive\nexperiments on two public benchmark datasets CUB and Oxford-102 demonstrate the\neffectiveness of the proposed S2IGAN on synthesizing high-quality and\nsemantically-consistent images from the speech signal, yielding a good\nperformance and a solid baseline for the S2IG task.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 13:39:56 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 08:17:22 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Wang", "Xinsheng", ""], ["Qiao", "Tingting", ""], ["Zhu", "Jihua", ""], ["Hanjalic", "Alan", ""], ["Scharenborg", "Odette", ""]]}, {"id": "2005.06978", "submitter": "Niklas K\\\"uhl", "authors": "Tristan Karb, Niklas K\\\"uhl, Robin Hirt, Varvara Glivici-Cotruta", "title": "A network-based transfer learning approach to improve sales forecasting\n  of new products", "comments": "28th European Conference on Information Systems (ECIS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Data-driven methods -- such as machine learning and time series forecasting\n-- are widely used for sales forecasting in the food retail domain. However,\nfor newly introduced products insufficient training data is available to train\naccurate models. In this case, human expert systems are implemented to improve\nprediction performance. Human experts rely on their implicit and explicit\ndomain knowledge and transfer knowledge about historical sales of similar\nproducts to forecast new product sales. By applying the concept of Transfer\nLearning, we propose an analytical approach to transfer knowledge between\nlisted stock products and new products. A network-based Transfer Learning\napproach for deep neural networks is designed to investigate the efficiency of\nTransfer Learning in the domain of food sales forecasting. Furthermore, we\nexamine how knowledge can be shared across different products and how to\nidentify the products most suitable for transfer. To test the proposed\napproach, we conduct a comprehensive case study for a newly introduced product,\nbased on data of an Austrian food retailing company. The experimental results\nshow, that the prediction accuracy of deep neural networks for food sales\nforecasting can be effectively increased using the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 15:08:47 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Karb", "Tristan", ""], ["K\u00fchl", "Niklas", ""], ["Hirt", "Robin", ""], ["Glivici-Cotruta", "Varvara", ""]]}, {"id": "2005.06980", "submitter": "Rajarshi Haldar", "authors": "Rajarshi Haldar, Lingfei Wu, Jinjun Xiong and Julia Hockenmaier", "title": "A Multi-Perspective Architecture for Semantic Code Search", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.LG cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ability to match pieces of code to their corresponding natural language\ndescriptions and vice versa is fundamental for natural language search\ninterfaces to software repositories. In this paper, we propose a novel\nmulti-perspective cross-lingual neural framework for code--text matching,\ninspired in part by a previous model for monolingual text-to-text matching, to\ncapture both global and local similarities. Our experiments on the CoNaLa\ndataset show that our proposed model yields better performance on this\ncross-lingual text-to-code matching task than previous approaches that map code\nand text to a single joint embedding space.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 04:46:11 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Haldar", "Rajarshi", ""], ["Wu", "Lingfei", ""], ["Xiong", "Jinjun", ""], ["Hockenmaier", "Julia", ""]]}, {"id": "2005.06993", "submitter": "Tomoya Koike", "authors": "Tomoya Koike and Kun Qian and Bj\\\"orn W. Schuller and Yoshiharu\n  Yamamoto", "title": "deepSELF: An Open Source Deep Self End-to-End Learning Framework", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an open-source toolkit, i.e., the deep Self End-to-end Learning\nFramework (deepSELF), as a toolkit of deep self end-to-end learning framework\nfor multi-modal signals. To the best of our knowledge, it is the first public\ntoolkit assembling a series of state-of-the-art deep learning technologies.\nHighlights of the proposed deepSELF toolkit include: First, it can be used to\nanalyse a variety of multi-modal signals, including images, audio, and single\nor multi-channel sensor data. Second, we provide multiple options for\npre-processing, e.g., filtering, or spectrum image generation by Fourier or\nwavelet transformation. Third, plenty of topologies in terms of NN, 1D/2D/3D\nCNN, and RNN/LSTM/GRU can be customised and a series of pretrained 2D CNN\nmodels, e.g., AlexNet, VGGNet, ResNet can be used easily. Last but not least,\nabove these features, deepSELF can be flexibly used not only as a single model\nbut also as a fusion of such.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 13:50:01 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Koike", "Tomoya", ""], ["Qian", "Kun", ""], ["Schuller", "Bj\u00f6rn W.", ""], ["Yamamoto", "Yoshiharu", ""]]}, {"id": "2005.07006", "submitter": "Mauricio Michel Olvera Zambrano", "authors": "Michel Olvera (MULTISPEECH), Emmanuel Vincent (MULTISPEECH), Romain\n  Serizel (MULTISPEECH), Gilles Gasso (LITIS)", "title": "Foreground-Background Ambient Sound Scene Separation", "comments": null, "journal-ref": "28th European Signal Processing Conference (EUSIPCO), Jan 2021,\n  Amsterdam, Netherlands", "doi": null, "report-no": "EUSIPCO 2020", "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ambient sound scenes typically comprise multiple short events occurring on\ntop of a somewhat stationary background. We consider the task of separating\nthese events from the background, which we call foreground-background ambient\nsound scene separation. We propose a deep learning-based separation framework\nwith a suitable feature normaliza-tion scheme and an optional auxiliary network\ncapturing the background statistics, and we investigate its ability to handle\nthe great variety of sound classes encountered in ambient sound scenes, which\nhave often not been seen in training. To do so, we create single-channel\nforeground-background mixtures using isolated sounds from the DESED and\nAudioset datasets, and we conduct extensive experiments with mixtures of seen\nor unseen sound classes at various signal-to-noise ratios. Our experimental\nfindings demonstrate the generalization ability of the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 06:59:46 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 14:00:00 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Olvera", "Michel", "", "MULTISPEECH"], ["Vincent", "Emmanuel", "", "MULTISPEECH"], ["Serizel", "Romain", "", "MULTISPEECH"], ["Gasso", "Gilles", "", "LITIS"]]}, {"id": "2005.07019", "submitter": "Zhijie Sasha Dong", "authors": "Zhijie Sasha Dong, Lingyu Meng, Lauren Christenson, Lawrence Fulton", "title": "Social Media Information Sharing for Natural Disaster Response", "comments": "24 pages, 14 figures", "journal-ref": "Nat Hazards 107, 2077 - 2104 (2021)", "doi": "10.1007/s11069-021-04528-9", "report-no": null, "categories": "cs.SI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social media has become an essential channel for posting disaster-related\ninformation, which provide governments and relief agencies real-time data for\nbetter disaster management. However, research in this field has not received\nsufficient attention and extracting useful information is still challenging.\nThis paper aims to improve disaster relief efficiency via mining and analyzing\nsocial media data like public attitudes towards disaster response and public\ndemands for targeted relief supplies during different types of disasters. We\nfocus on different natural disasters based on properties such as types,\ndurations, and damages, which contains a total of 41,993 tweets. In this paper,\npublic perception is assessed qualitatively by manually classified tweets,\nwhich contain information like the demand for targeted relief supplies,\nsatisfactions of disaster response, and public fear. Public attitudes to\nnatural disasters are studied via a quantitative analysis using eight machine\nlearning models. To better provide decision-makers with the appropriate model,\nthe comparison of machine learning models based on computational time and\nprediction accuracy is conducted. The change of public opinion during different\nnatural disasters and the evolution of people's behavior of using social media\nfor disaster relief in the face of the identical type of natural disasters as\nTwitter continues to evolve are studied. The results in this paper demonstrate\nthe feasibility and validation of the proposed research approach and provide\nrelief agencies with insights into better disaster management.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 21:11:39 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 19:35:38 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 21:03:00 GMT"}, {"version": "v4", "created": "Wed, 3 Mar 2021 10:24:40 GMT"}, {"version": "v5", "created": "Sun, 11 Jul 2021 15:59:40 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Dong", "Zhijie Sasha", ""], ["Meng", "Lingyu", ""], ["Christenson", "Lauren", ""], ["Fulton", "Lawrence", ""]]}, {"id": "2005.07023", "submitter": "Alessandro Paolo Capasso", "authors": "Alessandro Paolo Capasso, Giulio Bacchiani, Alberto Broggi", "title": "From Simulation to Real World Maneuver Execution using Deep\n  Reinforcement Learning", "comments": "Intelligent Vehicle Symposium 2020 (IV2020)", "journal-ref": "2020 IEEE Intelligent Vehicles Symposium (IV)", "doi": "10.1109/IV47402.2020.9304593", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning has proved to be able to solve many control tasks\nin different fields, but the behavior of these systems is not always as\nexpected when deployed in real-world scenarios. This is mainly due to the lack\nof domain adaptation between simulated and real-world data together with the\nabsence of distinction between train and test datasets. In this work, we\ninvestigate these problems in the autonomous driving field, especially for a\nmaneuver planning module for roundabout insertions. In particular, we present a\nsystem based on multiple environments in which agents are trained\nsimultaneously, evaluating the behavior of the model in different scenarios.\nFinally, we analyze techniques aimed at reducing the gap between simulated and\nreal-world data showing that this increased the generalization capabilities of\nthe system both on unseen and real-world scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 14:22:20 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 11:57:30 GMT"}, {"version": "v3", "created": "Sat, 26 Dec 2020 18:19:21 GMT"}, {"version": "v4", "created": "Wed, 28 Apr 2021 08:11:02 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Capasso", "Alessandro Paolo", ""], ["Bacchiani", "Giulio", ""], ["Broggi", "Alberto", ""]]}, {"id": "2005.07026", "submitter": "Fahad Shamshad", "authors": "Fahad Shamshad, Asif Hanif, Ali Ahmed", "title": "Subsampled Fourier Ptychography using Pretrained Invertible and\n  Untrained Network Priors", "comments": "Part of this work has been accepted in NeurIPS Deep Inverse Workshop,\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.IR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently pretrained generative models have shown promising results for\nsubsampled Fourier Ptychography (FP) in terms of quality of reconstruction for\nextremely low sampling rate and high noise. However, one of the significant\ndrawbacks of these pretrained generative priors is their limited representation\ncapabilities. Moreover, training these generative models requires access to a\nlarge number of fully-observed clean samples of a particular class of images\nlike faces or digits that is prohibitive to obtain in the context of FP. In\nthis paper, we propose to leverage the power of pretrained invertible and\nuntrained generative models to mitigate the representation error issue and\nrequirement of a large number of example images (for training generative\nmodels) respectively. Through extensive experiments, we demonstrate the\neffectiveness of proposed approaches in the context of FP for low sampling\nrates and high noise levels.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 16:13:01 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Shamshad", "Fahad", ""], ["Hanif", "Asif", ""], ["Ahmed", "Ali", ""]]}, {"id": "2005.07029", "submitter": "Yi-Chen Chen", "authors": "Yi-Chen Chen, Jui-Yang Hsu, Cheng-Kuang Lee, Hung-yi Lee", "title": "DARTS-ASR: Differentiable Architecture Search for Multilingual Speech\n  Recognition and Adaptation", "comments": "Accepted at INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In previous works, only parameter weights of ASR models are optimized under\nfixed-topology architecture. However, the design of successful model\narchitecture has always relied on human experience and intuition. Besides, many\nhyperparameters related to model architecture need to be manually tuned.\nTherefore in this paper, we propose an ASR approach with efficient\ngradient-based architecture search, DARTS-ASR. In order to examine the\ngeneralizability of DARTS-ASR, we apply our approach not only on many languages\nto perform monolingual ASR, but also on a multilingual ASR setting. Following\nprevious works, we conducted experiments on a multilingual dataset, IARPA\nBABEL. The experiment results show that our approach outperformed the baseline\nfixed-topology architecture by 10.2% and 10.0% relative reduction on character\nerror rates under monolingual and multilingual ASR settings respectively.\nFurthermore, we perform some analysis on the searched architectures by\nDARTS-ASR.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 11:32:27 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 02:40:53 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Chen", "Yi-Chen", ""], ["Hsu", "Jui-Yang", ""], ["Lee", "Cheng-Kuang", ""], ["Lee", "Hung-yi", ""]]}, {"id": "2005.07031", "submitter": "Gabriel Michau Dr.", "authors": "Gabriel Rodriguez Garcia, Gabriel Michau, M\\'elanie Ducoffe, Jayant\n  Sen Gupta, Olga Fink", "title": "Temporal signals to images: Monitoring the condition of industrial\n  assets with deep learning image processing algorithms", "comments": "13 pages, 5 figures, 2 tables", "journal-ref": null, "doi": "10.1177/1748006X21994446", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to detect anomalies in time series is considered highly valuable\nin numerous application domains. The sequential nature of time series objects\nis responsible for an additional feature complexity, ultimately requiring\nspecialized approaches in order to solve the task. Essential characteristics of\ntime series, situated outside the time domain, are often difficult to capture\nwith state-of-the-art anomaly detection methods when no transformations have\nbeen applied to the time series. Inspired by the success of deep learning\nmethods in computer vision, several studies have proposed transforming time\nseries into image-like representations, used as inputs for deep learning\nmodels, and have led to very promising results in classification tasks. In this\npaper, we first review the signal to image encoding approaches found in the\nliterature. Second, we propose modifications to some of their original\nformulations to make them more robust to the variability in large datasets.\nThird, we compare them on the basis of a common unsupervised task to\ndemonstrate how the choice of the encoding can impact the results when used in\nthe same deep learning architecture. We thus provide a comparison between six\nencoding algorithms with and without the proposed modifications. The selected\nencoding methods are Gramian Angular Field, Markov Transition Field, recurrence\nplot, grey scale encoding, spectrogram, and scalogram. We also compare the\nresults achieved with the raw signal used as input for another deep learning\nmodel. We demonstrate that some encodings have a competitive advantage and\nmight be worth considering within a deep learning framework. The comparison is\nperformed on a dataset collected and released by Airbus SAS, containing highly\ncomplex vibration measurements from real helicopter flight tests. The different\nencodings provide competitive results for anomaly detection.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 14:42:06 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 08:59:54 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 12:55:08 GMT"}, {"version": "v4", "created": "Fri, 26 Feb 2021 07:47:14 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Garcia", "Gabriel Rodriguez", ""], ["Michau", "Gabriel", ""], ["Ducoffe", "M\u00e9lanie", ""], ["Gupta", "Jayant Sen", ""], ["Fink", "Olga", ""]]}, {"id": "2005.07036", "submitter": "Xuewen Yao", "authors": "Xuewen Yao, Megan Micheletti, Mckensey Johnson, Kaya de Barbaro", "title": "Detection of Infant Crying in Real-World Home Environments Using Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the domain of social signal processing, audio event detection is a\npromising avenue for accessing daily behaviors that contribute to health and\nwell-being. However, despite advances in mobile computing and machine learning,\naudio behavior detection models are largely constrained to data collected in\ncontrolled settings, such as call centers. This is problematic as it means\ntheir performance is unlikely to generalize to real-world applications. In this\npaper, we present a novel dataset of infant distress vocalizations compiled\nfrom over 780 hours of real-world audio data, collected via recorders worn by\ninfants. We develop a model that combines deep spectrum and acoustic features\nto detect and classify infant distress vocalizations, which dramatically\noutperforms models trained on equivalent real-world data (F1 score of 0.630 vs\n0.166). We end by discussing how dataset size can facilitate such gains in\naccuracy, critical when considering noisy and complex naturalistic data.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 18:25:44 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 15:19:46 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 04:28:20 GMT"}, {"version": "v4", "created": "Fri, 16 Apr 2021 21:06:18 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Yao", "Xuewen", ""], ["Micheletti", "Megan", ""], ["Johnson", "Mckensey", ""], ["de Barbaro", "Kaya", ""]]}, {"id": "2005.07037", "submitter": "Nicolo Colombo", "authors": "Nicolo Colombo and Vladimir Vovk", "title": "Training conformal predictors", "comments": "8 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficiency criteria for conformal prediction, such as \\emph{observed\nfuzziness} (i.e., the sum of p-values associated with false labels), are\ncommonly used to \\emph{evaluate} the performance of given conformal predictors.\nHere, we investigate whether it is possible to exploit efficiency criteria to\n\\emph{learn} classifiers, both conformal predictors and point classifiers, by\nusing such criteria as training objective functions. The proposed idea is\nimplemented for the problem of binary classification of hand-written digits. By\nchoosing a 1-dimensional model class (with one real-valued free parameter), we\ncan solve the optimization problems through an (approximate) exhaustive search\nover (a discrete version of) the parameter space. Our empirical results suggest\nthat conformal predictors trained by minimizing their observed fuzziness\nperform better than conformal predictors trained in the traditional way by\nminimizing the \\emph{prediction error} of the corresponding point classifier.\nThey also have a reasonable performance in terms of their prediction error on\nthe test set.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 14:47:30 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Colombo", "Nicolo", ""], ["Vovk", "Vladimir", ""]]}, {"id": "2005.07041", "submitter": "Navjot Singh", "authors": "Navjot Singh, Deepesh Data, Jemin George, Suhas Diggavi", "title": "SQuARM-SGD: Communication-Efficient Momentum SGD for Decentralized\n  Optimization", "comments": "50 pages, 9 figures. arXiv admin note: text overlap with\n  arXiv:1910.14280", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study communication-efficient decentralized training of\nlarge-scale machine learning models over a network. We propose and analyze\nSQuARM-SGD, a decentralized training algorithm, employing momentum and\ncompressed communication between nodes regulated by a locally computable\ntriggering rule. In SQuARM-SGD, each node performs a fixed number of local SGD\n(stochastic gradient descent) steps using Nesterov's momentum and then sends\nsparisified and quantized updates to its neighbors only when there is a\nsignificant change in its model parameters since the last time communication\noccurred. We provide convergence guarantees of our algorithm for\nstrongly-convex and non-convex smooth objectives. We believe that ours is the\nfirst theoretical analysis for compressed decentralized SGD with momentum\nupdates. We show that SQuARM-SGD converges at rate\n$\\mathcal{O}\\left(\\frac{1}{nT}\\right)$ for strongly-convex objectives, while\nfor non-convex objectives it converges at rate\n$\\mathcal{O}\\left(\\frac{1}{\\sqrt{nT}}\\right)$, thus matching the convergence\nrate of \\emph{vanilla} distributed SGD in both these settings. We corroborate\nour theoretical understanding with experiments and compare the performance of\nour algorithm with the state-of-the-art, showing that without sacrificing much\non the accuracy, SQuARM-SGD converges at a similar rate while saving\nsignificantly in total communicated bits.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 02:11:14 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 22:28:32 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Singh", "Navjot", ""], ["Data", "Deepesh", ""], ["George", "Jemin", ""], ["Diggavi", "Suhas", ""]]}, {"id": "2005.07045", "submitter": "Hufei Zhu", "authors": "Hufei Zhu", "title": "Efficient and Stable Algorithms to Extend Greville's Method to\n  Partitioned Matrices Based on Inverse Cholesky Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Greville's method has been utilized in (Broad Learn-ing System) BLS to\npropose an effective and efficient incremental learning system without\nretraining the whole network from the beginning. For a column-partitioned\nmatrix where the second part consists of p columns, Greville's method requires\np iterations to compute the pseudoinverse of the whole matrix from the\npseudoinverse of the first part. The incremental algorithms in BLS extend\nGreville's method to compute the pseudoinverse of the whole matrix from the\npseudoinverse of the first part by just 1 iteration, which have neglected some\npossible cases, and need further improvements in efficiency and numerical\nstability. In this paper, we propose an efficient and numerical stable\nalgorithm from Greville's method, to compute the pseudoinverse of the whole\nmatrix from the pseudoinverse of the first part by just 1 iteration, where all\npossible cases are considered, and the recently proposed inverse Cholesky\nfactorization can be applied to further reduce the computational complexity.\nFinally, we give the whole algorithm for column-partitioned matrices in BLS. On\nthe other hand, we also give the proposed algorithm for row-partitioned\nmatrices in BLS.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 14:53:19 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Zhu", "Hufei", ""]]}, {"id": "2005.07057", "submitter": "Diego Alberto Mercado-Ravell Dr.", "authors": "Luis A. Pinedo-Sanchez, Diego A. Mercado-Ravell, Carlos A.\n  Carballo-Monsivais", "title": "Vibration Analysis in Bearings for Failure Prevention using CNN", "comments": "This paper is a preprint of a paper submitted to Journal of the\n  Brazilian Society of Mechanical Sciences and Engineering", "journal-ref": "J Braz. Soc. Mech. Sci. Eng. 42, 628 (2020)", "doi": "10.1007/s40430-020-02711-w", "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timely failure detection for bearings is of great importance to prevent\neconomic loses in the industry. In this article we propose a method based on\nConvolutional Neural Networks (CNN) to estimate the level of wear in bearings.\nFirst of all, an automatic labeling of the raw vibration data is performed to\nobtain different levels of bearing wear, by means of the Root Mean Square\nfeatures along with the Shannon's entropy to extract features from the raw\ndata, which is then grouped in seven different classes using the K-means\nalgorithm to obtain the labels. Then, the raw vibration data is converted into\nsmall square images, each sample of the data representing one pixel of the\nimage. Following this, we propose a CNN model based on the AlexNet architecture\nto classify the wear level and diagnose the rotatory system. To train the\nnetwork and validate our proposal, we use a dataset from the center of\nIntelligent Maintenance Systems (IMS), and extensively compare it with other\nmethods reported in the literature. The effectiveness of the proposed strategy\nproved to be excellent, outperforming other approaches in the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 23:32:05 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 15:52:55 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Pinedo-Sanchez", "Luis A.", ""], ["Mercado-Ravell", "Diego A.", ""], ["Carballo-Monsivais", "Carlos A.", ""]]}, {"id": "2005.07058", "submitter": "Tuan Tran Anh", "authors": "Tuan Tran Anh, Khoa Nguyen-Tuan, Tran Minh Quan, and Won-Ki Jeong", "title": "Reinforced Coloring for End-to-End Instance Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instance segmentation is one of the actively studied research topics in\ncomputer vision in which many objects of interest should be separated\nindividually. While many feed-forward networks produce high-quality\nsegmentation on different types of images, their results often suffer from\ntopological errors (merging or splitting) for segmentation of many objects,\nrequiring post-processing. Existing iterative methods, on the other hand,\nextract a single object at a time using discriminative knowledge-based\nproperties (shapes, boundaries, etc.) without relying on post-processing, but\nthey do not scale well. To exploit the advantages of conventional\nsingle-object-per-step segmentation methods without impairing the scalability,\nwe propose a novel iterative deep reinforcement learning agent that learns how\nto differentiate multiple objects in parallel. Our reward function for the\ntrainable agent is designed to favor grouping pixels belonging to the same\nobject using a graph coloring algorithm. We demonstrate that the proposed\nmethod can efficiently perform instance segmentation of many objects without\nheavy post-processing.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 15:15:47 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 02:40:36 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Anh", "Tuan Tran", ""], ["Nguyen-Tuan", "Khoa", ""], ["Quan", "Tran Minh", ""], ["Jeong", "Won-Ki", ""]]}, {"id": "2005.07062", "submitter": "Christian Schroeder de Witt", "authors": "Christian Schroeder de Witt, Bradley Gram-Hansen, Nantas Nardelli,\n  Andrew Gambardella, Rob Zinkov, Puneet Dokania, N. Siddharth, Ana Belen\n  Espinosa-Gonzalez, Ara Darzi, Philip Torr, At{\\i}l{\\i}m G\\\"une\\c{s} Baydin", "title": "Simulation-Based Inference for Global Health Decisions", "comments": null, "journal-ref": "ICML Workshop on Machine Learning for Global Health,\n  Thirty-Seventh International Conference on Machine Learning (ICML 2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has highlighted the importance of in-silico\nepidemiological modelling in predicting the dynamics of infectious diseases to\ninform health policy and decision makers about suitable prevention and\ncontainment strategies. Work in this setting involves solving challenging\ninference and control problems in individual-based models of ever increasing\ncomplexity. Here we discuss recent breakthroughs in machine learning,\nspecifically in simulation-based inference, and explore its potential as a\nnovel venue for model calibration to support the design and evaluation of\npublic health interventions. To further stimulate research, we are developing\nsoftware interfaces that turn two cornerstone COVID-19 and malaria epidemiology\nmodels COVID-sim, (https://github.com/mrc-ide/covid-sim/) and OpenMalaria\n(https://github.com/SwissTPH/openmalaria) into probabilistic programs, enabling\nefficient interpretable Bayesian inference within those simulators.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 15:29:45 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["de Witt", "Christian Schroeder", ""], ["Gram-Hansen", "Bradley", ""], ["Nardelli", "Nantas", ""], ["Gambardella", "Andrew", ""], ["Zinkov", "Rob", ""], ["Dokania", "Puneet", ""], ["Siddharth", "N.", ""], ["Espinosa-Gonzalez", "Ana Belen", ""], ["Darzi", "Ara", ""], ["Torr", "Philip", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""]]}, {"id": "2005.07064", "submitter": "Angeliki  Lazaridou", "authors": "Angeliki Lazaridou, Anna Potapenko, Olivier Tieleman", "title": "Multi-agent Communication meets Natural Language: Synergies between\n  Functional and Structural Language Learning", "comments": "to appear at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for combining multi-agent communication and traditional\ndata-driven approaches to natural language learning, with an end goal of\nteaching agents to communicate with humans in natural language. Our starting\npoint is a language model that has been trained on generic, not task-specific\nlanguage data. We then place this model in a multi-agent self-play environment\nthat generates task-specific rewards used to adapt or modulate the model,\nturning it into a task-conditional language model. We introduce a new way for\ncombining the two types of learning based on the idea of reranking language\nmodel samples, and show that this method outperforms others in communicating\nwith humans in a visual referential communication task. Finally, we present a\ntaxonomy of different types of language drift that can occur alongside a set of\nmeasures to detect them.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 15:32:23 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Lazaridou", "Angeliki", ""], ["Potapenko", "Anna", ""], ["Tieleman", "Olivier", ""]]}, {"id": "2005.07069", "submitter": "Sebastian Lunz", "authors": "Sebastian Lunz, Andreas Hauptmann, Tanja Tarvainen, Carola-Bibiane\n  Sch\\\"onlieb, Simon Arridge", "title": "On Learned Operator Correction in Inverse Problems", "comments": "28 pages, 11 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CV cs.LG cs.NA eess.IV math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the possibility to learn a data-driven explicit model correction\nfor inverse problems and whether such a model correction can be used within a\nvariational framework to obtain regularised reconstructions. This paper\ndiscusses the conceptual difficulty to learn such a forward model correction\nand proceeds to present a possible solution as forward-adjoint correction that\nexplicitly corrects in both data and solution spaces. We then derive conditions\nunder which solutions to the variational problem with a learned correction\nconverge to solutions obtained with the correct operator. The proposed approach\nis evaluated on an application to limited view photoacoustic tomography and\ncompared to the established framework of Bayesian approximation error method.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 15:37:28 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 13:41:59 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Lunz", "Sebastian", ""], ["Hauptmann", "Andreas", ""], ["Tarvainen", "Tanja", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""], ["Arridge", "Simon", ""]]}, {"id": "2005.07076", "submitter": "Yi\\u{g}it Oktar", "authors": "Yigit Oktar, Mehmet Turkan", "title": "Evolutionary Simplicial Learning as a Generative and Compact Sparse\n  Framework for Classification", "comments": null, "journal-ref": null, "doi": "10.1016/j.sigpro.2020.107634", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dictionary learning for sparse representations has been successful in many\nreconstruction tasks. Simplicial learning is an adaptation of dictionary\nlearning, where subspaces become clipped and acquire arbitrary offsets, taking\nthe form of simplices. Such adaptation is achieved through additional\nconstraints on sparse codes. Furthermore, an evolutionary approach can be\nchosen to determine the number and the dimensionality of simplices composing\nthe simplicial, in which most generative and compact simplicials are favored.\nThis paper proposes an evolutionary simplicial learning method as a generative\nand compact sparse framework for classification. The proposed approach is first\napplied on a one-class classification task and it appears as the most reliable\nmethod within the considered benchmark. Most surprising results are observed\nwhen evolutionary simplicial learning is considered within a multi-class\nclassification task. Since sparse representations are generative in nature,\nthey bear a fundamental problem of not being capable of distinguishing two\nclasses lying on the same subspace. This claim is validated through synthetic\nexperiments and superiority of simplicial learning even as a generative-only\napproach is demonstrated. Simplicial learning loses its superiority over\ndiscriminative methods in high-dimensional cases but can further be modified\nwith discriminative elements to achieve state-of-the-art performance in\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 15:44:56 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Oktar", "Yigit", ""], ["Turkan", "Mehmet", ""]]}, {"id": "2005.07078", "submitter": "Gabriel Michau Dr.", "authors": "Oliver Ammann, Gabriel Michau, Olga Fink", "title": "Anomaly Detection And Classification In Time Series With Kervolutional\n  Neural Networks", "comments": "9 pages, 1 figure, 4 tables", "journal-ref": "Proceedings of the 30th European Safety and Reliability Conference\n  and 15th Probabilistic Safety Assessment and Management Conference (ESREL2020\n  PSAM15)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, with the development of deep learning, end-to-end neural network\narchitectures have been increasingly applied to condition monitoring signals.\nThey have demonstrated superior performance for fault detection and\nclassification, in particular using convolutional neural networks. Even more\nrecently, an extension of the concept of convolution to the concept of\nkervolution has been proposed with some promising results in image\nclassification tasks. In this paper, we explore the potential of kervolutional\nneural networks applied to time series data. We demonstrate that using a\nmixture of convolutional and kervolutional layers improves the model\nperformance. The mixed model is first applied to a classification task in time\nseries, as a benchmark dataset. Subsequently, the proposed mixed architecture\nis used to detect anomalies in time series data recorded by accelerometers on\nhelicopters. We propose a residual-based anomaly detection approach using a\ntemporal auto-encoder. We demonstrate that mixing kervolutional with\nconvolutional layers in the encoder is more sensitive to variations in the\ninput data and is able to detect anomalous time series in a better way.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 15:45:11 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Ammann", "Oliver", ""], ["Michau", "Gabriel", ""], ["Fink", "Olga", ""]]}, {"id": "2005.07091", "submitter": "Yiming Wu", "authors": "Yiming Wu, Tristan Carsault, Eita Nakamura, Kazuyoshi Yoshii", "title": "Semi-supervised Neural Chord Estimation Based on a Variational\n  Autoencoder with Latent Chord Labels and Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes a statistically-principled semi-supervised method of\nautomatic chord estimation (ACE) that can make effective use of music signals\nregardless of the availability of chord annotations. The typical approach to\nACE is to train a deep classification model (neural chord estimator) in a\nsupervised manner by using only annotated music signals. In this discriminative\napproach, prior knowledge about chord label sequences (model output) has\nscarcely been taken into account. In contrast, we propose a unified generative\nand discriminative approach in the framework of amortized variational\ninference. More specifically, we formulate a deep generative model that\nrepresents the generative process of chroma vectors (observed variables) from\ndiscrete labels and continuous features (latent variables), which are assumed\nto follow a Markov model favoring self-transitions and a standard Gaussian\ndistribution, respectively. Given chroma vectors as observed data, the\nposterior distributions of the latent labels and features are computed\napproximately by using deep classification and recognition models,\nrespectively. These three models form a variational autoencoder and can be\ntrained jointly in a semi-supervised manner. The experimental results show that\nthe regularization of the classification model based on the Markov prior of\nchord labels and the generative model of chroma vectors improved the\nperformance of ACE even under the supervised condition. The semi-supervised\nlearning using additional non-annotated data can further improve the\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 15:58:36 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 04:31:08 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Wu", "Yiming", ""], ["Carsault", "Tristan", ""], ["Nakamura", "Eita", ""], ["Yoshii", "Kazuyoshi", ""]]}, {"id": "2005.07093", "submitter": "Mart van Baalen", "authors": "Mart van Baalen and Christos Louizos and Markus Nagel and Rana Ali\n  Amjad and Ying Wang and Tijmen Blankevoort and Max Welling", "title": "Bayesian Bits: Unifying Quantization and Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Bayesian Bits, a practical method for joint mixed precision\nquantization and pruning through gradient based optimization. Bayesian Bits\nemploys a novel decomposition of the quantization operation, which sequentially\nconsiders doubling the bit width. At each new bit width, the residual error\nbetween the full precision value and the previously rounded value is quantized.\nWe then decide whether or not to add this quantized residual error for a higher\neffective bit width and lower quantization noise. By starting with a\npower-of-two bit width, this decomposition will always produce\nhardware-friendly configurations, and through an additional 0-bit option,\nserves as a unified view of pruning and quantization. Bayesian Bits then\nintroduces learnable stochastic gates, which collectively control the bit width\nof the given tensor. As a result, we can obtain low bit solutions by performing\napproximate inference over the gates, with prior distributions that encourage\nmost of them to be switched off. We experimentally validate our proposed method\non several benchmark datasets and show that we can learn pruned, mixed\nprecision networks that provide a better trade-off between accuracy and\nefficiency than their static bit width equivalents.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 16:00:34 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 10:10:46 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 11:27:24 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["van Baalen", "Mart", ""], ["Louizos", "Christos", ""], ["Nagel", "Markus", ""], ["Amjad", "Rana Ali", ""], ["Wang", "Ying", ""], ["Blankevoort", "Tijmen", ""], ["Welling", "Max", ""]]}, {"id": "2005.07099", "submitter": "Jianwen Sun Dr", "authors": "Jianwen Sun, Tianwei Zhang, Xiaofei Xie, Lei Ma, Yan Zheng, Kangjie\n  Chen, Yang Liu", "title": "Stealthy and Efficient Adversarial Attacks against Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks against conventional Deep Learning (DL) systems and\nalgorithms have been widely studied, and various defenses were proposed.\nHowever, the possibility and feasibility of such attacks against Deep\nReinforcement Learning (DRL) are less explored. As DRL has achieved great\nsuccess in various complex tasks, designing effective adversarial attacks is an\nindispensable prerequisite towards building robust DRL algorithms. In this\npaper, we introduce two novel adversarial attack techniques to\n\\emph{stealthily} and \\emph{efficiently} attack the DRL agents. These two\ntechniques enable an adversary to inject adversarial samples in a minimal set\nof critical moments while causing the most severe damage to the agent. The\nfirst technique is the \\emph{critical point attack}: the adversary builds a\nmodel to predict the future environmental states and agent's actions, assesses\nthe damage of each possible attack strategy, and selects the optimal one. The\nsecond technique is the \\emph{antagonist attack}: the adversary automatically\nlearns a domain-agnostic model to discover the critical moments of attacking\nthe agent in an episode. Experimental results demonstrate the effectiveness of\nour techniques. Specifically, to successfully attack the DRL agent, our\ncritical point technique only requires 1 (TORCS) or 2 (Atari Pong and Breakout)\nsteps, and the antagonist technique needs fewer than 5 steps (4 Mujoco tasks),\nwhich are significant improvements over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 16:06:38 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Sun", "Jianwen", ""], ["Zhang", "Tianwei", ""], ["Xie", "Xiaofei", ""], ["Ma", "Lei", ""], ["Zheng", "Yan", ""], ["Chen", "Kangjie", ""], ["Liu", "Yang", ""]]}, {"id": "2005.07107", "submitter": "Alexey Kutalev", "authors": "Alexey Kutalev", "title": "Natural Way to Overcome the Catastrophic Forgetting in Neural Networks", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": "10.25559/SITITO.16.202002.331-337", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Not so long ago, a method was discovered that successfully overcomes the\ncatastrophic forgetting in neural networks. Although we know about the cases of\nusing this method to preserve skills when adapting pre-trained networks to\nparticular tasks, it has not obtained widespread distribution yet. In this\npaper, we would like to propose an alternative method of overcoming\ncatastrophic forgetting based on the total absolute signal passing through each\nconnection in the network. This method has a simple implementation and seems to\nus essentially close to the processes occurring in the brain of animals to\npreserve previously learned skills during subsequent learning. We hope that the\nease of implementation of this method will serve its wide application.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 11:17:57 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 17:44:46 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Kutalev", "Alexey", ""]]}, {"id": "2005.07111", "submitter": "Madhumita Sushil", "authors": "Madhumita Sushil and Simon \\v{S}uster and Walter Daelemans", "title": "Distilling neural networks into skipgram-level decision lists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several previous studies on explanation for recurrent neural networks focus\non approaches that find the most important input segments for a network as its\nexplanations. In that case, the manner in which these input segments combine\nwith each other to form an explanatory pattern remains unknown. To overcome\nthis, some previous work tries to find patterns (called rules) in the data that\nexplain neural outputs. However, their explanations are often insensitive to\nmodel parameters, which limits the scalability of text explanations. To\novercome these limitations, we propose a pipeline to explain RNNs by means of\ndecision lists (also called rules) over skipgrams. For evaluation of\nexplanations, we create a synthetic sepsis-identification dataset, as well as\napply our technique on additional clinical and sentiment analysis datasets. We\nfind that our technique persistently achieves high explanation fidelity and\nqualitatively interpretable rules.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 16:25:42 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 08:43:42 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Sushil", "Madhumita", ""], ["\u0160uster", "Simon", ""], ["Daelemans", "Walter", ""]]}, {"id": "2005.07114", "submitter": "Harshvardhan Sikka", "authors": "Harshvardhan Sikka", "title": "A Deeper Look at the Unsupervised Learning of Disentangled\n  Representations in $\\beta$-VAE from the Perspective of Core Object\n  Recognition", "comments": "65 Pages, 6 Figures, Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ability to recognize objects despite there being differences in\nappearance, known as Core Object Recognition, forms a critical part of human\nperception. While it is understood that the brain accomplishes Core Object\nRecognition through feedforward, hierarchical computations through the visual\nstream, the underlying algorithms that allow for invariant representations to\nform downstream is still not well understood. (DiCarlo et al., 2012) Various\ncomputational perceptual models have been built to attempt and tackle the\nobject identification task in an artificial perceptual setting. Artificial\nNeural Networks, computational graphs consisting of weighted edges and\nmathematical operations at vertices, are loosely inspired by neural networks in\nthe brain and have proven effective at various visual perceptual tasks,\nincluding object characterization and identification. (Pinto et al., 2008)\n(DiCarlo et al., 2012) For many data analysis tasks, learning representations\nwhere each dimension is statistically independent and thus disentangled from\nthe others is useful. If the underlying generative factors of the data are also\nstatistically independent, Bayesian inference of latent variables can form\ndisentangled representations. This thesis constitutes a research project\nexploring a generalization of the Variational Autoencoder (VAE), $\\beta$-VAE,\nthat aims to learn disentangled representations using variational inference.\n$\\beta$-VAE incorporates the hyperparameter $\\beta$, and enforces conditional\nindependence of its bottleneck neurons, which is in general not compatible with\nthe statistical independence of latent variables. This text examines this\narchitecture, and provides analytical and numerical arguments, with the goal of\ndemonstrating that this incompatibility leads to a non-monotonic inference\nperformance in $\\beta$-VAE with a finite optimal $\\beta$.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 08:14:03 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Sikka", "Harshvardhan", ""]]}, {"id": "2005.07115", "submitter": "Ziheng Duan", "authors": "Haoyan Xu, Runjian Chen, Yunsheng Bai, Ziheng Duan, Jie Feng, Yizhou\n  Sun, Wei Wang", "title": "CoSimGNN: Towards Large-scale Graph Similarity Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to compute similarity scores between graphs based on metrics such\nas Graph Edit Distance (GED) is important in many real-world applications, such\nas 3D action recognition and biological molecular identification. Computing\nexact GED values is typically an NP-hard problem and traditional algorithms\nusually achieve an unsatisfactory trade-off between accuracy and efficiency.\nRecently, Graph Neural Networks (GNNs) provide a data-driven solution for this\ntask, which is more efficient while maintaining prediction accuracy in small\ngraph (around 10 nodes per graph) similarity computation. Existing GNN-based\nmethods, which either respectively embed two graphs (lack of low-level\ncross-graph interactions) or deploy cross-graph interactions for whole graph\npairs (redundant and time-consuming), are still not able to achieve competitive\nresults when the number of nodes in graphs increases. In this paper, we focus\non similarity computation for large-scale graphs and propose the\n\"embedding-coarsening-matching\" framework, which first embeds and coarsens\nlarge graphs to coarsened graphs with denser local topology and then deploys\nfine-grained interactions on the coarsened graphs for the final similarity\nscores.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 16:33:13 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 18:06:11 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 11:53:48 GMT"}, {"version": "v4", "created": "Tue, 15 Sep 2020 10:21:57 GMT"}, {"version": "v5", "created": "Mon, 28 Jun 2021 16:48:45 GMT"}, {"version": "v6", "created": "Tue, 29 Jun 2021 15:20:19 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Xu", "Haoyan", ""], ["Chen", "Runjian", ""], ["Bai", "Yunsheng", ""], ["Duan", "Ziheng", ""], ["Feng", "Jie", ""], ["Sun", "Yizhou", ""], ["Wang", "Wei", ""]]}, {"id": "2005.07121", "submitter": "Edward Pyzer-Knapp", "authors": "Edward O. Pyzer-Knapp", "title": "Using Bayesian Optimization to Accelerate Virtual Screening for the\n  Discovery of Therapeutics Appropriate for Repurposing for COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novel Wuhan coronavirus known as SARS-CoV-2 has brought almost\nunprecedented effects for a non-wartime setting, hitting social, economic and\nhealth systems hard.~ Being able to bring to bear pharmaceutical interventions\nto counteract its effects will represent a major turning point in the fight to\nturn the tides in this ongoing battle.~ Recently, the World's most powerful\nsupercomputer, SUMMIT, was used to identify existing small molecule\npharmaceuticals which may have the desired activity against SARS-CoV-2 through\na high throughput virtual screening approach. In this communication, we\ndemonstrate how the use of Bayesian optimization can provide a valuable service\nfor the prioritisation of these calculations, leading to the accelerated\nidentification of high-performing candidates, and thus expanding the scope of\nthe utility of HPC systems for time critical screening\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 10:11:14 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Pyzer-Knapp", "Edward O.", ""]]}, {"id": "2005.07134", "submitter": "Christos Chatzichristos", "authors": "Christos Chatzichristos, Eleftherios Kofidis, Lieven De Lathauwer,\n  Sergios Theodoridis, Sabine Van Huffel", "title": "Early soft and flexible fusion of EEG and fMRI via tensor decompositions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data fusion refers to the joint analysis of multiple datasets which provide\ncomplementary views of the same task. In this preprint, the problem of jointly\nanalyzing electroencephalography (EEG) and functional Magnetic Resonance\nImaging (fMRI) data is considered. Jointly analyzing EEG and fMRI measurements\nis highly beneficial for studying brain function because these modalities have\ncomplementary spatiotemporal resolution: EEG offers good temporal resolution\nwhile fMRI is better in its spatial resolution. The fusion methods reported so\nfar ignore the underlying multi-way nature of the data in at least one of the\nmodalities and/or rely on very strong assumptions about the relation of the two\ndatasets. In this preprint, these two points are addressed by adopting for the\nfirst time tensor models in the two modalities while also exploring double\ncoupled tensor decompositions and by following soft and flexible coupling\napproaches to implement the multi-modal analysis. To cope with the Event\nRelated Potential (ERP) variability in EEG, the PARAFAC2 model is adopted. The\nresults obtained are compared against those of parallel Independent Component\nAnalysis (ICA) and hard coupling alternatives in both simulated and real data.\nOur results confirm the superiority of tensorial methods over methods based on\nICA. In scenarios that do not meet the assumptions underlying hard coupling,\nthe advantage of soft and flexible coupled decompositions is clearly\ndemonstrated.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 15:57:33 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Chatzichristos", "Christos", ""], ["Kofidis", "Eleftherios", ""], ["De Lathauwer", "Lieven", ""], ["Theodoridis", "Sergios", ""], ["Van Huffel", "Sabine", ""]]}, {"id": "2005.07151", "submitter": "Tianhang Zheng", "authors": "Tianhang Zheng, Sheng Liu, Changyou Chen, Junsong Yuan, Baochun Li,\n  Kui Ren", "title": "Towards Understanding the Adversarial Vulnerability of Skeleton-based\n  Action Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skeleton-based action recognition has attracted increasing attention due to\nits strong adaptability to dynamic circumstances and potential for broad\napplications such as autonomous and anonymous surveillance. With the help of\ndeep learning techniques, it has also witnessed substantial progress and\ncurrently achieved around 90\\% accuracy in benign environment. On the other\nhand, research on the vulnerability of skeleton-based action recognition under\ndifferent adversarial settings remains scant, which may raise security concerns\nabout deploying such techniques into real-world systems. However, filling this\nresearch gap is challenging due to the unique physical constraints of skeletons\nand human actions. In this paper, we attempt to conduct a thorough study\ntowards understanding the adversarial vulnerability of skeleton-based action\nrecognition. We first formulate generation of adversarial skeleton actions as a\nconstrained optimization problem by representing or approximating the\nphysiological and physical constraints with mathematical formulations. Since\nthe primal optimization problem with equality constraints is intractable, we\npropose to solve it by optimizing its unconstrained dual problem using ADMM. We\nthen specify an efficient plug-in defense, inspired by recent theories and\nempirical observations, against the adversarial skeleton actions. Extensive\nevaluations demonstrate the effectiveness of the attack and defense method\nunder different settings.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 17:12:52 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 15:21:59 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Zheng", "Tianhang", ""], ["Liu", "Sheng", ""], ["Chen", "Changyou", ""], ["Yuan", "Junsong", ""], ["Li", "Baochun", ""], ["Ren", "Kui", ""]]}, {"id": "2005.07157", "submitter": "Aleksandr Laptev", "authors": "Aleksandr Laptev, Roman Korostik, Aleksey Svischev, Andrei Andrusenko,\n  Ivan Medennikov, Sergey Rybin", "title": "You Do Not Need More Data: Improving End-To-End Speech Recognition by\n  Text-To-Speech Data Augmentation", "comments": null, "journal-ref": null, "doi": "10.1109/CISP-BMEI51763.2020.9263564", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is one of the most effective ways to make end-to-end\nautomatic speech recognition (ASR) perform close to the conventional hybrid\napproach, especially when dealing with low-resource tasks. Using recent\nadvances in speech synthesis (text-to-speech, or TTS), we build our TTS system\non an ASR training database and then extend the data with synthesized speech to\ntrain a recognition model. We argue that, when the training data amount is\nrelatively low, this approach can allow an end-to-end model to reach hybrid\nsystems' quality. For an artificial low-to-medium-resource setup, we compare\nthe proposed augmentation with the semi-supervised learning technique. We also\ninvestigate the influence of vocoder usage on final ASR performance by\ncomparing Griffin-Lim algorithm with our modified LPCNet. When applied with an\nexternal language model, our approach outperforms a semi-supervised setup for\nLibriSpeech test-clean and only 33% worse than a comparable supervised setup.\nOur system establishes a competitive result for end-to-end ASR trained on\nLibriSpeech train-clean-100 set with WER 4.3% for test-clean and 13.5% for\ntest-other.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 17:24:57 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 20:26:57 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Laptev", "Aleksandr", ""], ["Korostik", "Roman", ""], ["Svischev", "Aleksey", ""], ["Andrusenko", "Andrei", ""], ["Medennikov", "Ivan", ""], ["Rybin", "Sergey", ""]]}, {"id": "2005.07173", "submitter": "Daniel Fremont", "authors": "Daniel J. Fremont, Johnathan Chiu, Dragos D. Margineantu, Denis\n  Osipychev, and Sanjit A. Seshia", "title": "Formal Analysis and Redesign of a Neural Network-Based Aircraft Taxiing\n  System with VerifAI", "comments": "Full version of a CAV 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate a unified approach to rigorous design of safety-critical\nautonomous systems using the VerifAI toolkit for formal analysis of AI-based\nsystems. VerifAI provides an integrated toolchain for tasks spanning the design\nprocess, including modeling, falsification, debugging, and ML component\nretraining. We evaluate all of these applications in an industrial case study\non an experimental autonomous aircraft taxiing system developed by Boeing,\nwhich uses a neural network to track the centerline of a runway. We define\nrunway scenarios using the Scenic probabilistic programming language, and use\nthem to drive tests in the X-Plane flight simulator. We first perform\nfalsification, automatically finding environment conditions causing the system\nto violate its specification by deviating significantly from the centerline (or\neven leaving the runway entirely). Next, we use counterexample analysis to\nidentify distinct failure cases, and confirm their root causes with specialized\ntesting. Finally, we use the results of falsification and debugging to retrain\nthe network, eliminating several failure cases and improving the overall\nperformance of the closed-loop system.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 17:42:14 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Fremont", "Daniel J.", ""], ["Chiu", "Johnathan", ""], ["Margineantu", "Dragos D.", ""], ["Osipychev", "Denis", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "2005.07174", "submitter": "Elena Kochkina", "authors": "Elena Kochkina and Maria Liakata", "title": "Estimating predictive uncertainty for rumour verification models", "comments": "Accepted to the Annual Conference of the Association for\n  Computational Linguistics (ACL) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The inability to correctly resolve rumours circulating online can have\nharmful real-world consequences. We present a method for incorporating model\nand data uncertainty estimates into natural language processing models for\nautomatic rumour verification. We show that these estimates can be used to\nfilter out model predictions likely to be erroneous, so that these difficult\ninstances can be prioritised by a human fact-checker. We propose two methods\nfor uncertainty-based instance rejection, supervised and unsupervised. We also\nshow how uncertainty estimates can be used to interpret model performance as a\nrumour unfolds.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 17:42:25 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Kochkina", "Elena", ""], ["Liakata", "Maria", ""]]}, {"id": "2005.07184", "submitter": "Swanand Kadhe", "authors": "Swanand Kadhe, O. Ozan Koyluoglu, and Kannan Ramchandran", "title": "Communication-Efficient Gradient Coding for Straggler Mitigation in\n  Distributed Learning", "comments": "Shorter version accepted in 2020 IEEE International Symposium on\n  Information Theory (ISIT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Distributed implementations of gradient-based methods, wherein a server\ndistributes gradient computations across worker machines, need to overcome two\nlimitations: delays caused by slow running machines called 'stragglers', and\ncommunication overheads. Recently, Ye and Abbe [ICML 2018] proposed a\ncoding-theoretic paradigm to characterize a fundamental trade-off between\ncomputation load per worker, communication overhead per worker, and straggler\ntolerance. However, their proposed coding schemes suffer from heavy decoding\ncomplexity and poor numerical stability. In this paper, we develop a\ncommunication-efficient gradient coding framework to overcome these drawbacks.\nOur proposed framework enables using any linear code to design the encoding and\ndecoding functions. When a particular code is used in this framework, its\nblock-length determines the computation load, dimension determines the\ncommunication overhead, and minimum distance determines the straggler\ntolerance. The flexibility of choosing a code allows us to gracefully trade-off\nthe straggler threshold and communication overhead for smaller decoding\ncomplexity and higher numerical stability. Further, we show that using a\nmaximum distance separable (MDS) code generated by a random Gaussian matrix in\nour framework yields a gradient code that is optimal with respect to the\ntrade-off and, in addition, satisfies stronger guarantees on numerical\nstability as compared to the previously proposed schemes. Finally, we evaluate\nour proposed framework on Amazon EC2 and demonstrate that it reduces the\naverage iteration time by 16% as compared to prior gradient coding schemes.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 17:57:13 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Kadhe", "Swanand", ""], ["Koyluoglu", "O. Ozan", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "2005.07186", "submitter": "Michael Dusenberry", "authors": "Michael W. Dusenberry, Ghassen Jerfel, Yeming Wen, Yi-An Ma, Jasper\n  Snoek, Katherine Heller, Balaji Lakshminarayanan, Dustin Tran", "title": "Efficient and Scalable Bayesian Neural Nets with Rank-1 Factors", "comments": "Published in the International Conference on Machine Learning (ICML)\n  2020. Code available at https://github.com/google/edward2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks (BNNs) demonstrate promising success in improving\nthe robustness and uncertainty quantification of modern deep learning. However,\nthey generally struggle with underfitting at scale and parameter efficiency. On\nthe other hand, deep ensembles have emerged as alternatives for uncertainty\nquantification that, while outperforming BNNs on certain problems, also suffer\nfrom efficiency issues. It remains unclear how to combine the strengths of\nthese two approaches and remediate their common issues. To tackle this\nchallenge, we propose a rank-1 parameterization of BNNs, where each weight\nmatrix involves only a distribution on a rank-1 subspace. We also revisit the\nuse of mixture approximate posteriors to capture multiple modes, where unlike\ntypical mixtures, this approach admits a significantly smaller memory increase\n(e.g., only a 0.4% increase for a ResNet-50 mixture of size 10). We perform a\nsystematic empirical study on the choices of prior, variational posterior, and\nmethods to improve training. For ResNet-50 on ImageNet, Wide ResNet 28-10 on\nCIFAR-10/100, and an RNN on MIMIC-III, rank-1 BNNs achieve state-of-the-art\nperformance across log-likelihood, accuracy, and calibration on the test sets\nand out-of-distribution variants.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 17:58:59 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 20:39:11 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Dusenberry", "Michael W.", ""], ["Jerfel", "Ghassen", ""], ["Wen", "Yeming", ""], ["Ma", "Yi-An", ""], ["Snoek", "Jasper", ""], ["Heller", "Katherine", ""], ["Lakshminarayanan", "Balaji", ""], ["Tran", "Dustin", ""]]}, {"id": "2005.07243", "submitter": "Athanasios Davvetas", "authors": "Athanasios Davvetas, Iraklis A. Klampanos", "title": "Unsupervised Severe Weather Detection Via Joint Representation Learning\n  Over Textual and Weather Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When observing a phenomenon, severe cases or anomalies are often\ncharacterised by deviation from the expected data distribution. However,\nnon-deviating data samples may also implicitly lead to severe outcomes. In the\ncase of unsupervised severe weather detection, these data samples can lead to\nmispredictions, since the predictors of severe weather are often not directly\nobserved as features. We posit that incorporating external or auxiliary\ninformation, such as the outcome of an external task or an observation, can\nimprove the decision boundaries of an unsupervised detection algorithm. In this\npaper, we increase the effectiveness of a clustering method to detect cases of\nsevere weather by learning augmented and linearly separable latent\nrepresentations.We evaluate our solution against three individual cases of\nsevere weather, namely windstorms, floods and tornado outbreaks.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 20:13:39 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Davvetas", "Athanasios", ""], ["Klampanos", "Iraklis A.", ""]]}, {"id": "2005.07275", "submitter": "Tim Barfoot", "authors": "Timothy D. Barfoot and Gabriele M. T. D'Eleuterio", "title": "Variational Inference as Iterative Projection in a Bayesian Hilbert\n  Space", "comments": "28 pages, 7 figures, submitted to Annals of Mathematics and\n  Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Bayesian inference is an important machine-learning tool that\nfinds application from statistics to robotics. The goal is to find an\napproximate probability density function (PDF) from a chosen family that is in\nsome sense `closest' to the full Bayesian posterior. Closeness is typically\ndefined through the selection of an appropriate loss functional such as the\nKullback-Leibler (KL) divergence. In this paper, we explore a new formulation\nof variational inference by exploiting the fact that the set of PDFs\nconstitutes a Bayesian Hilbert space under careful definitions of vector\naddition, scalar multiplication and an inner product. We show that variational\ninference based on KL divergence then amounts to an iterative projection of the\nBayesian posterior onto a subspace corresponding to the selected approximation\nfamily. In fact, the inner product chosen for the Bayesian Hilbert space\nsuggests the definition of a new measure of the information contained in a PDF\nand in turn a new divergence is introduced. Each step in the iterative\nprojection is equivalent to a local minimization of this divergence. We present\nan example Bayesian subspace based on exponentiated Hermite polynomials as well\nas work through the details of this general framework for the specific case of\nthe multivariate Gaussian approximation family and show the equivalence to\nanother Gaussian variational inference approach. We furthermore discuss the\nimplications for systems that exhibit sparsity, which is handled naturally in\nBayesian space.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 21:33:31 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Barfoot", "Timothy D.", ""], ["D'Eleuterio", "Gabriele M. T.", ""]]}, {"id": "2005.07289", "submitter": "Soren Pirk", "authors": "Yao Lu, S\\\"oren Pirk, Jan Dlabal, Anthony Brohan, Ankita Pasad, Zhao\n  Chen, Vincent Casser, Anelia Angelova, Ariel Gordon", "title": "Taskology: Utilizing Task Relations at Scale", "comments": "IEEE Conference on Computer Vision and Pattern Recognition, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many computer vision tasks address the problem of scene understanding and are\nnaturally interrelated e.g. object classification, detection, scene\nsegmentation, depth estimation, etc. We show that we can leverage the inherent\nrelationships among collections of tasks, as they are trained jointly,\nsupervising each other through their known relationships via consistency\nlosses. Furthermore, explicitly utilizing the relationships between tasks\nallows improving their performance while dramatically reducing the need for\nlabeled data, and allows training with additional unsupervised or simulated\ndata. We demonstrate a distributed joint training algorithm with task-level\nparallelism, which affords a high degree of asynchronicity and robustness. This\nallows learning across multiple tasks, or with large amounts of input data, at\nscale. We demonstrate our framework on subsets of the following collection of\ntasks: depth and normal prediction, semantic segmentation, 3D motion and\nego-motion estimation, and object tracking and 3D detection in point clouds. We\nobserve improved performance across these tasks, especially in the low-label\nregime.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 22:53:46 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 04:10:16 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Lu", "Yao", ""], ["Pirk", "S\u00f6ren", ""], ["Dlabal", "Jan", ""], ["Brohan", "Anthony", ""], ["Pasad", "Ankita", ""], ["Chen", "Zhao", ""], ["Casser", "Vincent", ""], ["Angelova", "Anelia", ""], ["Gordon", "Ariel", ""]]}, {"id": "2005.07292", "submitter": "Ekaterina Lobacheva Ms", "authors": "Nadezhda Chirkova, Ekaterina Lobacheva, Dmitry Vetrov", "title": "Deep Ensembles on a Fixed Memory Budget: One Wide Network or Several\n  Thinner Ones?", "comments": "Under review by the International Conference on Machine Learning\n  (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the generally accepted views of modern deep learning is that\nincreasing the number of parameters usually leads to better quality. The two\neasiest ways to increase the number of parameters is to increase the size of\nthe network, e.g. width, or to train a deep ensemble; both approaches improve\nthe performance in practice. In this work, we consider a fixed memory budget\nsetting, and investigate, what is more effective: to train a single wide\nnetwork, or to perform a memory split -- to train an ensemble of several\nthinner networks, with the same total number of parameters? We find that, for\nlarge enough budgets, the number of networks in the ensemble, corresponding to\nthe optimal memory split, is usually larger than one. Interestingly, this\neffect holds for the commonly used sizes of the standard architectures. For\nexample, one WideResNet-28-10 achieves significantly worse test accuracy on\nCIFAR-100 than an ensemble of sixteen thinner WideResNets: 80.6% and 82.52%\ncorrespondingly. We call the described effect the Memory Split Advantage and\nshow that it holds for a variety of datasets and model architectures.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 23:08:31 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Chirkova", "Nadezhda", ""], ["Lobacheva", "Ekaterina", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "2005.07293", "submitter": "Ninareh Mehrabi", "authors": "Ninareh Mehrabi, Yuzhong Huang, Fred Morstatter", "title": "Statistical Equity: A Fairness Classification Objective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems have been shown to propagate the societal errors of\nthe past. In light of this, a wealth of research focuses on designing solutions\nthat are \"fair.\" Even with this abundance of work, there is no singular\ndefinition of fairness, mainly because fairness is subjective and context\ndependent. We propose a new fairness definition, motivated by the principle of\nequity, that considers existing biases in the data and attempts to make\nequitable decisions that account for these previous historical biases. We\nformalize our definition of fairness, and motivate it with its appropriate\ncontexts. Next, we operationalize it for equitable classification. We perform\nmultiple automatic and human evaluations to show the effectiveness of our\ndefinition and demonstrate its utility for aspects of fairness, such as the\nfeedback loop.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 23:19:38 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Mehrabi", "Ninareh", ""], ["Huang", "Yuzhong", ""], ["Morstatter", "Fred", ""]]}, {"id": "2005.07308", "submitter": "Fl\\'avia Alves", "authors": "Fl\\'avia Alves, Martin Gairing, Frans A. Oliehoek and Thanh-Toan Do", "title": "Sensor Data for Human Activity Recognition: Feature Representation and\n  Benchmarking", "comments": "28 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of Human Activity Recognition (HAR) focuses on obtaining and\nanalysing data captured from monitoring devices (e.g. sensors). There is a wide\nrange of applications within the field; for instance, assisted living, security\nsurveillance, and intelligent transportation. In HAR, the development of\nActivity Recognition models is dependent upon the data captured by these\ndevices and the methods used to analyse them, which directly affect performance\nmetrics. In this work, we address the issue of accurately recognising human\nactivities using different Machine Learning (ML) techniques. We propose a new\nfeature representation based on consecutive occurring observations and compare\nit against previously used feature representations using a wide range of\nclassification methods. Experimental results demonstrate that techniques based\non the proposed representation outperform the baselines and a better accuracy\nwas achieved for both highly and less frequent actions. We also investigate how\nthe addition of further features and their pre-processing techniques affect\nperformance results leading to state-of-the-art accuracy on a Human Activity\nRecognition dataset.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 00:46:55 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Alves", "Fl\u00e1via", ""], ["Gairing", "Martin", ""], ["Oliehoek", "Frans A.", ""], ["Do", "Thanh-Toan", ""]]}, {"id": "2005.07347", "submitter": "Tianhang Zheng", "authors": "Tianhang Zheng, Di Wang, Baochun Li, Jinhui Xu", "title": "Towards Assessment of Randomized Smoothing Mechanisms for Certifying\n  Adversarial Robustness", "comments": "Correct the some details of the theorems and proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a certified defensive technique, randomized smoothing has received\nconsiderable attention due to its scalability to large datasets and neural\nnetworks. However, several important questions remain unanswered, such as (i)\nwhether the Gaussian mechanism is an appropriate option for certifying\n$\\ell_2$-norm robustness, and (ii) whether there is an appropriate randomized\n(smoothing) mechanism to certify $\\ell_\\infty$-norm robustness. To shed light\non these questions, we argue that the main difficulty is how to assess the\nappropriateness of each randomized mechanism. In this paper, we propose a\ngeneric framework that connects the existing frameworks in\n\\cite{lecuyer2018certified, li2019certified}, to assess randomized mechanisms.\nUnder our framework, for a randomized mechanism that can certify a certain\nextent of robustness, we define the magnitude of its required additive noise as\nthe metric for assessing its appropriateness. We also prove lower bounds on\nthis metric for the $\\ell_2$-norm and $\\ell_\\infty$-norm cases as the criteria\nfor assessment. Based on our framework, we assess the Gaussian and Exponential\nmechanisms by comparing the magnitude of additive noise required by these\nmechanisms and the lower bounds (criteria). We first conclude that the Gaussian\nmechanism is indeed an appropriate option to certify $\\ell_2$-norm robustness.\nSurprisingly, we show that the Gaussian mechanism is also an appropriate option\nfor certifying $\\ell_\\infty$-norm robustness, instead of the Exponential\nmechanism. Finally, we generalize our framework to $\\ell_p$-norm for any\n$p\\geq2$. Our theoretical findings are verified by evaluations on CIFAR10 and\nImageNet.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 03:54:53 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 15:49:06 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 18:39:33 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Zheng", "Tianhang", ""], ["Wang", "Di", ""], ["Li", "Baochun", ""], ["Xu", "Jinhui", ""]]}, {"id": "2005.07353", "submitter": "Jacob Montiel", "authors": "Jacob Montiel, Rory Mitchell, Eibe Frank, Bernhard Pfahringer, Talel\n  Abdessalem, Albert Bifet", "title": "Adaptive XGBoost for Evolving Data Streams", "comments": "To be published in Proceedings of the International Joint Conference\n  on Neural Networks (IJCNN) 2020, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting is an ensemble method that combines base models in a sequential\nmanner to achieve high predictive accuracy. A popular learning algorithm based\non this ensemble method is eXtreme Gradient Boosting (XGB). We present an\nadaptation of XGB for classification of evolving data streams. In this setting,\nnew data arrives over time and the relationship between the class and the\nfeatures may change in the process, thus exhibiting concept drift. The proposed\nmethod creates new members of the ensemble from mini-batches of data as new\ndata becomes available. The maximum ensemble size is fixed, but learning does\nnot stop when this size is reached because the ensemble is updated on new data\nto ensure consistency with the current concept. We also explore the use of\nconcept drift detection to trigger a mechanism to update the ensemble. We test\nour method on real and synthetic data with concept drift and compare it against\nbatch-incremental and instance-incremental classification methods for data\nstreams.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 04:28:15 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Montiel", "Jacob", ""], ["Mitchell", "Rory", ""], ["Frank", "Eibe", ""], ["Pfahringer", "Bernhard", ""], ["Abdessalem", "Talel", ""], ["Bifet", "Albert", ""]]}, {"id": "2005.07360", "submitter": "Preetum Nakkiran", "authors": "Preetum Nakkiran", "title": "Learning Rate Annealing Can Provably Help Generalization, Even for\n  Convex Problems", "comments": "4 pages plus appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning rate schedule can significantly affect generalization performance in\nmodern neural networks, but the reasons for this are not yet understood.\nLi-Wei-Ma (2019) recently proved this behavior can exist in a simplified\nnon-convex neural-network setting. In this note, we show that this phenomenon\ncan exist even for convex learning problems -- in particular, linear regression\nin 2 dimensions.\n  We give a toy convex problem where learning rate annealing (large initial\nlearning rate, followed by small learning rate) can lead gradient descent to\nminima with provably better generalization than using a small learning rate\nthroughout. In our case, this occurs due to a combination of the mismatch\nbetween the test and train loss landscapes, and early-stopping.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 05:16:32 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Nakkiran", "Preetum", ""]]}, {"id": "2005.07383", "submitter": "Achintya Sarkar", "authors": "Achintya Kumar Sarkar and Zheng-Hua Tan", "title": "On Bottleneck Features for Text-Dependent Speaker Verification Using\n  X-vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying x-vectors for speaker verification has recently attracted great\ninterest, with the focus being on text-independent speaker verification. In\nthis paper, we study x-vectors for text-dependent speaker verification (TD-SV),\nwhich remains unexplored. We further investigate the impact of the different\nbottleneck (BN) features on the performance of x-vectors, including the\nrecently-introduced time-contrastive-learning (TCL) BN features and\nphone-discriminant BN features. TCL is a weakly supervised learning approach\nthat constructs training data by uniformly partitioning each utterance into a\npredefined number of segments and then assigning each segment a class label\ndepending on their position in the utterance. We also compare TD-SV performance\nfor different modeling techniques, including the Gaussian mixture\nmodels-universal background model (GMM-UBM), i-vector, and x-vector.\nExperiments are conducted on the RedDots 2016 challenge database. It is found\nthat the type of features has a marginal impact on the performance of x-vectors\nwith the TCL BN feature achieving the lowest equal error rate, while the impact\nof features is significant for i-vector and GMM-UBM. The fusion of x-vector and\ni-vector systems gives a large gain in performance. The GMM-UBM technique shows\nits advantage for TD-SV using short utterances.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 07:10:53 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 14:21:11 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Sarkar", "Achintya Kumar", ""], ["Tan", "Zheng-Hua", ""]]}, {"id": "2005.07385", "submitter": "Mattias Tiger", "authors": "Mattias Tiger, David Bergstr\\\"om, Andreas Norrstig, Fredrik Heintz", "title": "Enhancing Lattice-based Motion Planning with Introspective Learning and\n  Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lattice-based motion planning is a hybrid planning method where a plan made\nup of discrete actions simultaneously is a physically feasible trajectory. The\nplanning takes both discrete and continuous aspects into account, for example\naction pre-conditions and collision-free action-duration in the configuration\nspace. Safe motion planing rely on well-calibrated safety-margins for collision\nchecking. The trajectory tracking controller must further be able to reliably\nexecute the motions within this safety margin for the execution to be safe. In\nthis work we are concerned with introspective learning and reasoning about\ncontroller performance over time. Normal controller execution of the different\nactions is learned using reliable and uncertainty-aware machine learning\ntechniques. By correcting for execution bias we manage to substantially reduce\nthe safety margin of motion actions. Reasoning takes place to both verify that\nthe learned models stays safe and to improve collision checking effectiveness\nin the motion planner by the use of more accurate execution predictions with a\nsmaller safety margin. The presented approach allows for explicit awareness of\ncontroller performance under normal circumstances, and timely detection of\nincorrect performance in abnormal circumstances. Evaluation is made on the\nnonlinear dynamics of a quadcopter in 3D using simulation. Video:\nhttps://youtu.be/STmZduvSUMM\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 07:16:51 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Tiger", "Mattias", ""], ["Bergstr\u00f6m", "David", ""], ["Norrstig", "Andreas", ""], ["Heintz", "Fredrik", ""]]}, {"id": "2005.07402", "submitter": "Hideaki Ishibashi Ph.D", "authors": "Hideaki Ishibashi and Hideitsu Hino", "title": "Stopping criterion for active learning based on deterministic\n  generalization bounds", "comments": "Accepted for publication at AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning is a framework in which the learning machine can select the\nsamples to be used for training. This technique is promising, particularly when\nthe cost of data acquisition and labeling is high. In active learning,\ndetermining the timing at which learning should be stopped is a critical issue.\nIn this study, we propose a criterion for automatically stopping active\nlearning. The proposed stopping criterion is based on the difference in the\nexpected generalization errors and hypothesis testing. We derive a novel upper\nbound for the difference in expected generalization errors before and after\nobtaining a new training datum based on PAC-Bayesian theory. Unlike ordinary\nPAC-Bayesian bounds, though, the proposed bound is deterministic; hence, there\nis no uncontrollable trade-off between the confidence and tightness of the\ninequality. We combine the upper bound with a statistical test to derive a\nstopping criterion for active learning. We demonstrate the effectiveness of the\nproposed method via experiments with both artificial and real datasets.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 08:15:47 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Ishibashi", "Hideaki", ""], ["Hino", "Hideitsu", ""]]}, {"id": "2005.07404", "submitter": "Thomas Moerland", "authors": "Thomas M. Moerland, Anna Deichler, Simone Baldi, Joost Broekens and\n  Catholijn M. Jonker", "title": "Think Too Fast Nor Too Slow: The Computational Trade-off Between\n  Planning And Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning and reinforcement learning are two key approaches to sequential\ndecision making. Multi-step approximate real-time dynamic programming, a\nrecently successful algorithm class of which AlphaZero [Silver et al., 2018] is\nan example, combines both by nesting planning within a learning loop. However,\nthe combination of planning and learning introduces a new question: how should\nwe balance time spend on planning, learning and acting? The importance of this\ntrade-off has not been explicitly studied before. We show that it is actually\nof key importance, with computational results indicating that we should neither\nplan too long nor too short. Conceptually, we identify a new spectrum of\nplanning-learning algorithms which ranges from exhaustive search (long\nplanning) to model-free RL (no planning), with optimal performance achieved\nmidway.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 08:20:08 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Moerland", "Thomas M.", ""], ["Deichler", "Anna", ""], ["Baldi", "Simone", ""], ["Broekens", "Joost", ""], ["Jonker", "Catholijn M.", ""]]}, {"id": "2005.07421", "submitter": "Haoran Huang", "authors": "Shaohua Zhang, Haoran Huang, Jicong Liu and Hang Li", "title": "Spelling Error Correction with Soft-Masked BERT", "comments": "To be published at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spelling error correction is an important yet challenging task because a\nsatisfactory solution of it essentially needs human-level language\nunderstanding ability. Without loss of generality we consider Chinese spelling\nerror correction (CSC) in this paper. A state-of-the-art method for the task\nselects a character from a list of candidates for correction (including\nnon-correction) at each position of the sentence on the basis of BERT, the\nlanguage representation model. The accuracy of the method can be sub-optimal,\nhowever, because BERT does not have sufficient capability to detect whether\nthere is an error at each position, apparently due to the way of pre-training\nit using mask language modeling. In this work, we propose a novel neural\narchitecture to address the aforementioned issue, which consists of a network\nfor error detection and a network for error correction based on BERT, with the\nformer being connected to the latter with what we call soft-masking technique.\nOur method of using `Soft-Masked BERT' is general, and it may be employed in\nother language detection-correction problems. Experimental results on two\ndatasets demonstrate that the performance of our proposed method is\nsignificantly better than the baselines including the one solely based on BERT.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 09:02:38 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Zhang", "Shaohua", ""], ["Huang", "Haoran", ""], ["Liu", "Jicong", ""], ["Li", "Hang", ""]]}, {"id": "2005.07427", "submitter": "Chen Luo", "authors": "Lei Cai, Zhengzhang Chen, Chen Luo, Jiaping Gui, Jingchao Ni, Ding Li,\n  Haifeng Chen", "title": "Structural Temporal Graph Neural Networks for Anomaly Detection in\n  Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting anomalies in dynamic graphs is a vital task, with numerous\npractical applications in areas such as security, finance, and social media.\nPrevious network embedding based methods have been mostly focusing on learning\ngood node representations, whereas largely ignoring the subgraph structural\nchanges related to the target nodes in dynamic graphs. In this paper, we\npropose StrGNN, an end-to-end structural temporal Graph Neural Network model\nfor detecting anomalous edges in dynamic graphs. In particular, we first\nextract the $h$-hop enclosing subgraph centered on the target edge and propose\nthe node labeling function to identify the role of each node in the subgraph.\nThen, we leverage graph convolution operation and Sortpooling layer to extract\nthe fixed-size feature from each snapshot/timestamp. Based on the extracted\nfeatures, we utilize Gated recurrent units (GRUs) to capture the temporal\ninformation for anomaly detection. Extensive experiments on six benchmark\ndatasets and a real enterprise security system demonstrate the effectiveness of\nStrGNN.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 09:17:08 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 08:38:54 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Cai", "Lei", ""], ["Chen", "Zhengzhang", ""], ["Luo", "Chen", ""], ["Gui", "Jiaping", ""], ["Ni", "Jingchao", ""], ["Li", "Ding", ""], ["Chen", "Haifeng", ""]]}, {"id": "2005.07443", "submitter": "Alonso Marco", "authors": "Alonso Marco, Alexander von Rohr, Dominik Baumann, Jos\\'e Miguel\n  Hern\\'andez-Lobato and Sebastian Trimpe", "title": "Excursion Search for Constrained Bayesian Optimization under a Limited\n  Budget of Failures", "comments": "14 pages, 4 figures, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When learning to ride a bike, a child falls down a number of times before\nachieving the first success. As falling down usually has only mild\nconsequences, it can be seen as a tolerable failure in exchange for a faster\nlearning process, as it provides rich information about an undesired behavior.\nIn the context of Bayesian optimization under unknown constraints (BOC),\ntypical strategies for safe learning explore conservatively and avoid failures\nby all means. On the other side of the spectrum, non conservative BOC\nalgorithms that allow failing may fail an unbounded number of times before\nreaching the optimum. In this work, we propose a novel decision maker grounded\nin control theory that controls the amount of risk we allow in the search as a\nfunction of a given budget of failures. Empirical validation shows that our\nalgorithm uses the failures budget more efficiently in a variety of\noptimization experiments, and generally achieves lower regret, than\nstate-of-the-art methods. In addition, we propose an original algorithm for\nunconstrained Bayesian optimization inspired by the notion of excursion sets in\nstochastic processes, upon which the failures-aware algorithm is built.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 09:54:09 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Marco", "Alonso", ""], ["von Rohr", "Alexander", ""], ["Baumann", "Dominik", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "2005.07456", "submitter": "Marko Robnik-Sikonja", "authors": "Marko Robnik-Sikonja, Kristjan Reba, Igor Mozetic", "title": "Cross-lingual Transfer of Sentiment Classifiers", "comments": "18 pages, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings represent words in a numeric space so that semantic relations\nbetween words are represented as distances and directions in the vector space.\nCross-lingual word embeddings transform vector spaces of different languages so\nthat similar words are aligned. This is done by constructing a mapping between\nvector spaces of two languages or learning a joint vector space for multiple\nlanguages. Cross-lingual embeddings can be used to transfer machine learning\nmodels between languages, thereby compensating for insufficient data in\nless-resourced languages. We use cross-lingual word embeddings to transfer\nmachine learning prediction models for Twitter sentiment between 13 languages.\nWe focus on two transfer mechanisms that recently show superior transfer\nperformance. The first mechanism uses the trained models whose input is the\njoint numerical space for many languages as implemented in the LASER library.\nThe second mechanism uses large pretrained multilingual BERT language models.\nOur experiments show that the transfer of models between similar languages is\nsensible, even with no target language data. The performance of cross-lingual\nmodels obtained with the multilingual BERT and LASER library is comparable, and\nthe differences are language-dependent. The transfer with CroSloEngual BERT,\npretrained on only three languages, is superior on these and some closely\nrelated languages.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 10:15:27 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 06:29:45 GMT"}, {"version": "v3", "created": "Wed, 24 Mar 2021 15:18:53 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Robnik-Sikonja", "Marko", ""], ["Reba", "Kristjan", ""], ["Mozetic", "Igor", ""]]}, {"id": "2005.07462", "submitter": "Kelei He", "authors": "Kelei He, Chunfeng Lian, Ehsan Adeli, Jing Huo, Yang Gao, Bing Zhang,\n  Junfeng Zhang, Dinggang Shen", "title": "MetricUNet: Synergistic Image- and Voxel-Level Learning for Precise CT\n  Prostate Segmentation via Online Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fully convolutional networks (FCNs), including UNet and VNet, are widely-used\nnetwork architectures for semantic segmentation in recent studies. However,\nconventional FCN is typically trained by the cross-entropy or Dice loss, which\nonly calculates the error between predictions and ground-truth labels for\npixels individually. This often results in non-smooth neighborhoods in the\npredicted segmentation. To address this problem, we propose a two-stage\nframework, with the first stage to quickly localize the prostate region and the\nsecond stage to precisely segment the prostate by a multi-task UNet\narchitecture. We introduce a novel online metric learning module through\nvoxel-wise sampling in the multi-task network. Therefore, the proposed network\nhas a dual-branch architecture that tackles two tasks: 1) a segmentation\nsub-network aiming to generate the prostate segmentation, and 2) a voxel-metric\nlearning sub-network aiming to improve the quality of the learned feature space\nsupervised by a metric loss. Specifically, the voxel-metric learning\nsub-network samples tuples (including triplets and pairs) in voxel-level\nthrough the intermediate feature maps. Unlike conventional deep metric learning\nmethods that generate triplets or pairs in image-level before the training\nphase, our proposed voxel-wise tuples are sampled in an online manner and\noperated in an end-to-end fashion via multi-task learning. To evaluate the\nproposed method, we implement extensive experiments on a real CT image dataset\nconsisting of 339 patients. The ablation studies show that our method can\neffectively learn more representative voxel-level features compared with the\nconventional learning methods with cross-entropy or Dice loss. And the\ncomparisons show that the proposed method outperforms the state-of-the-art\nmethods by a reasonable margin.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 10:37:02 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 13:05:03 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 08:19:15 GMT"}, {"version": "v4", "created": "Sat, 23 Jan 2021 17:18:35 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["He", "Kelei", ""], ["Lian", "Chunfeng", ""], ["Adeli", "Ehsan", ""], ["Huo", "Jing", ""], ["Gao", "Yang", ""], ["Zhang", "Bing", ""], ["Zhang", "Junfeng", ""], ["Shen", "Dinggang", ""]]}, {"id": "2005.07473", "submitter": "Fabricio Murai", "authors": "B\\'arbara Silveira, Henrique S. Silva, Fabricio Murai, Ana Paula Couto\n  da Silva", "title": "Predicting User Emotional Tone in Mental Disorder Online Communities", "comments": "8 pages, 3 figures, 3 tables", "journal-ref": "Future Generation Computer Systems, Volume 125, 2021, Pages\n  641-651, ISSN 0167-739X", "doi": "10.1016/j.future.2021.07.014", "report-no": null, "categories": "cs.LG cs.CL cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Online Social Networks have become an important medium for\npeople who suffer from mental disorders to share moments of hardship, and\nreceive emotional and informational support. In this work, we analyze how\ndiscussions in Reddit communities related to mental disorders can help improve\nthe health conditions of their users. Using the emotional tone of users'\nwriting as a proxy for emotional state, we uncover relationships between user\ninteractions and state changes. First, we observe that authors of negative\nposts often write rosier comments after engaging in discussions, indicating\nthat users' emotional state can improve due to social support. Second, we build\nmodels based on SOTA text embedding techniques and RNNs to predict shifts in\nemotional tone. This differs from most of related work, which focuses primarily\non detecting mental disorders from user activity. We demonstrate the\nfeasibility of accurately predicting the users' reactions to the interactions\nexperienced in these platforms, and present some examples which illustrate that\nthe models are correctly capturing the effects of comments on the author's\nemotional tone. Our models hold promising implications for interventions to\nprovide support for people struggling with mental illnesses.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 11:25:08 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 12:48:29 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Silveira", "B\u00e1rbara", ""], ["Silva", "Henrique S.", ""], ["Murai", "Fabricio", ""], ["da Silva", "Ana Paula Couto", ""]]}, {"id": "2005.07486", "submitter": "Prajjwal Bhargava", "authors": "Prajjwal Bhargava", "title": "Adaptive Transformers for Learning Multimodal Representations", "comments": "Accepted at ACL SRW 2020. Code can be found here\n  https://github.com/prajjwal1/adaptive_transformer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The usage of transformers has grown from learning about language semantics to\nforming meaningful visiolinguistic representations. These architectures are\noften over-parametrized, requiring large amounts of computation. In this work,\nwe extend adaptive approaches to learn more about model interpretability and\ncomputational efficiency. Specifically, we study attention spans, sparse, and\nstructured dropout methods to help understand how their attention mechanism\nextends for vision and language tasks. We further show that these approaches\ncan help us learn more about how the network perceives the complexity of input\nsequences, sparsity preferences for different modalities, and other related\nphenomena.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 12:12:57 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 06:40:52 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 12:26:12 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Bhargava", "Prajjwal", ""]]}, {"id": "2005.07493", "submitter": "Shubham Agarwal", "authors": "Shubham Agarwal, Trung Bui, Joon-Young Lee, Ioannis Konstas, Verena\n  Rieser", "title": "History for Visual Dialog: Do we really need it?", "comments": "ACL'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Dialog involves \"understanding\" the dialog history (what has been\ndiscussed previously) and the current question (what is asked), in addition to\ngrounding information in the image, to generate the correct response. In this\npaper, we show that co-attention models which explicitly encode dialog history\noutperform models that don't, achieving state-of-the-art performance (72 % NDCG\non val set). However, we also expose shortcomings of the crowd-sourcing dataset\ncollection procedure by showing that history is indeed only required for a\nsmall amount of the data and that the current evaluation metric encourages\ngeneric replies. To that end, we propose a challenging subset (VisDialConv) of\nthe VisDial val set and provide a benchmark of 63% NDCG.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 14:58:09 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Agarwal", "Shubham", ""], ["Bui", "Trung", ""], ["Lee", "Joon-Young", ""], ["Konstas", "Ioannis", ""], ["Rieser", "Verena", ""]]}, {"id": "2005.07496", "submitter": "Joakim Skarding", "authors": "Joakim Skarding, Bogdan Gabrys and Katarzyna Musial", "title": "Foundations and modelling of dynamic networks using Dynamic Graph Neural\n  Networks: A survey", "comments": "28 pages, 9 figures, 8 tables", "journal-ref": "in IEEE Access, vol. 9, pp. 79143-79168, 2021", "doi": "10.1109/ACCESS.2021.3082932", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic networks are used in a wide range of fields, including social network\nanalysis, recommender systems, and epidemiology. Representing complex networks\nas structures changing over time allow network models to leverage not only\nstructural but also temporal patterns. However, as dynamic network literature\nstems from diverse fields and makes use of inconsistent terminology, it is\nchallenging to navigate. Meanwhile, graph neural networks (GNNs) have gained a\nlot of attention in recent years for their ability to perform well on a range\nof network science tasks, such as link prediction and node classification.\nDespite the popularity of graph neural networks and the proven benefits of\ndynamic network models, there has been little focus on graph neural networks\nfor dynamic networks. To address the challenges resulting from the fact that\nthis research crosses diverse fields as well as to survey dynamic graph neural\nnetworks, this work is split into two main parts. First, to address the\nambiguity of the dynamic network terminology we establish a foundation of\ndynamic networks with consistent, detailed terminology and notation. Second, we\npresent a comprehensive survey of dynamic graph neural network models using the\nproposed terminology\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 23:56:38 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 07:05:05 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Skarding", "Joakim", ""], ["Gabrys", "Bogdan", ""], ["Musial", "Katarzyna", ""]]}, {"id": "2005.07503", "submitter": "Martin Muller", "authors": "Martin M\\\"uller, Marcel Salath\\'e, Per E Kummervold", "title": "COVID-Twitter-BERT: A Natural Language Processing Model to Analyse\n  COVID-19 Content on Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we release COVID-Twitter-BERT (CT-BERT), a transformer-based\nmodel, pretrained on a large corpus of Twitter messages on the topic of\nCOVID-19. Our model shows a 10-30% marginal improvement compared to its base\nmodel, BERT-Large, on five different classification datasets. The largest\nimprovements are on the target domain. Pretrained transformer models, such as\nCT-BERT, are trained on a specific target domain and can be used for a wide\nvariety of natural language processing tasks, including classification,\nquestion-answering and chatbots. CT-BERT is optimised to be used on COVID-19\ncontent, in particular social media posts from Twitter.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 12:40:46 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["M\u00fcller", "Martin", ""], ["Salath\u00e9", "Marcel", ""], ["Kummervold", "Per E", ""]]}, {"id": "2005.07513", "submitter": "Sandy Huang", "authors": "Abbas Abdolmaleki, Sandy H. Huang, Leonard Hasenclever, Michael\n  Neunert, H. Francis Song, Martina Zambelli, Murilo F. Martins, Nicolas Heess,\n  Raia Hadsell, Martin Riedmiller", "title": "A Distributional View on Multi-Objective Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world problems require trading off multiple competing objectives.\nHowever, these objectives are often in different units and/or scales, which can\nmake it challenging for practitioners to express numerical preferences over\nobjectives in their native units. In this paper we propose a novel algorithm\nfor multi-objective reinforcement learning that enables setting desired\npreferences for objectives in a scale-invariant way. We propose to learn an\naction distribution for each objective, and we use supervised learning to fit a\nparametric policy to a combination of these distributions. We demonstrate the\neffectiveness of our approach on challenging high-dimensional real and\nsimulated robotics tasks, and show that setting different preferences in our\nframework allows us to trace out the space of nondominated solutions.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 13:02:17 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Abdolmaleki", "Abbas", ""], ["Huang", "Sandy H.", ""], ["Hasenclever", "Leonard", ""], ["Neunert", "Michael", ""], ["Song", "H. Francis", ""], ["Zambelli", "Martina", ""], ["Martins", "Murilo F.", ""], ["Heess", "Nicolas", ""], ["Hadsell", "Raia", ""], ["Riedmiller", "Martin", ""]]}, {"id": "2005.07518", "submitter": "Morten Goodwin Dr.", "authors": "Kristian Muri Knausg{\\aa}rd, Arne Wiklund, Tonje Knutsen S{\\o}rdalen,\n  Kim Halvorsen, Alf Ring Kleiven, Lei Jiao, Morten Goodwin", "title": "Temperate Fish Detection and Classification: a Deep Learning based\n  Approach", "comments": "arXiv admin note: substantial text overlap with arXiv:1904.02768", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide range of applications in marine ecology extensively uses underwater\ncameras. Still, to efficiently process the vast amount of data generated, we\nneed to develop tools that can automatically detect and recognize species\ncaptured on film. Classifying fish species from videos and images in natural\nenvironments can be challenging because of noise and variation in illumination\nand the surrounding habitat. In this paper, we propose a two-step deep learning\napproach for the detection and classification of temperate fishes without\npre-filtering. The first step is to detect each single fish in an image,\nindependent of species and sex. For this purpose, we employ the You Only Look\nOnce (YOLO) object detection technique. In the second step, we adopt a\nConvolutional Neural Network (CNN) with the Squeeze-and-Excitation (SE)\narchitecture for classifying each fish in the image without pre-filtering. We\napply transfer learning to overcome the limited training samples of temperate\nfishes and to improve the accuracy of the classification. This is done by\ntraining the object detection model with ImageNet and the fish classifier via a\npublic dataset (Fish4Knowledge), whereupon both the object detection and\nclassifier are updated with temperate fishes of interest. The weights obtained\nfrom pre-training are applied to post-training as a priori. Our solution\nachieves the state-of-the-art accuracy of 99.27\\% on the pre-training. The\npercentage values for accuracy on the post-training are good; 83.68\\% and\n87.74\\% with and without image augmentation, respectively, indicating that the\nsolution is viable with a more extensive dataset.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 12:40:57 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Knausg\u00e5rd", "Kristian Muri", ""], ["Wiklund", "Arne", ""], ["S\u00f8rdalen", "Tonje Knutsen", ""], ["Halvorsen", "Kim", ""], ["Kleiven", "Alf Ring", ""], ["Jiao", "Lei", ""], ["Goodwin", "Morten", ""]]}, {"id": "2005.07519", "submitter": "Dongqi Han", "authors": "Dongqi Han, Zhiliang Wang, Ying Zhong, Wenqi Chen, Jiahai Yang,\n  Shuqiang Lu, Xingang Shi, Xia Yin", "title": "Evaluating and Improving Adversarial Robustness of Machine\n  Learning-Based Network Intrusion Detectors", "comments": "This article has been accepted for publication by IEEE JSAC", "journal-ref": null, "doi": "10.1109/JSAC.2021.3087242", "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML), especially deep learning (DL) techniques have been\nincreasingly used in anomaly-based network intrusion detection systems (NIDS).\nHowever, ML/DL has shown to be extremely vulnerable to adversarial attacks,\nespecially in such security-sensitive systems. Many adversarial attacks have\nbeen proposed to evaluate the robustness of ML-based NIDSs. Unfortunately,\nexisting attacks mostly focused on feature-space and/or white-box attacks,\nwhich make impractical assumptions in real-world scenarios, leaving the study\non practical gray/black-box attacks largely unexplored.\n  To bridge this gap, we conduct the first systematic study of the\ngray/black-box traffic-space adversarial attacks to evaluate the robustness of\nML-based NIDSs. Our work outperforms previous ones in the following aspects:\n(i) practical-the proposed attack can automatically mutate original traffic\nwith extremely limited knowledge and affordable overhead while preserving its\nfunctionality; (ii) generic-the proposed attack is effective for evaluating the\nrobustness of various NIDSs using diverse ML/DL models and non-payload-based\nfeatures; (iii) explainable-we propose an explanation method for the fragile\nrobustness of ML-based NIDSs. Based on this, we also propose a defense scheme\nagainst adversarial attacks to improve system robustness. We extensively\nevaluate the robustness of various NIDSs using diverse feature sets and ML/DL\nmodels. Experimental results show our attack is effective (e.g., >97% evasion\nrate in half cases for Kitsune, a state-of-the-art NIDS) with affordable\nexecution cost and the proposed defense method can effectively mitigate such\nattacks (evasion rate is reduced by >50% in most cases).\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 13:06:00 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 18:21:42 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 09:25:47 GMT"}, {"version": "v4", "created": "Tue, 8 Jun 2021 07:25:11 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Han", "Dongqi", ""], ["Wang", "Zhiliang", ""], ["Zhong", "Ying", ""], ["Chen", "Wenqi", ""], ["Yang", "Jiahai", ""], ["Lu", "Shuqiang", ""], ["Shi", "Xingang", ""], ["Yin", "Xia", ""]]}, {"id": "2005.07530", "submitter": "Ine Jernelv", "authors": "Ine L. Jernelv, Dag Roar Hjelme, Yuji Matsuura, Astrid Aksnes", "title": "Convolutional neural networks for classification and regression analysis\n  of one-dimensional spectral data", "comments": "10 pages of article, 8 pages of Supplementary Information, 6 figures\n  in article, 3 figures in SI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Convolutional neural networks (CNNs) are widely used for image recognition\nand text analysis, and have been suggested for application on one-dimensional\ndata as a way to reduce the need for pre-processing steps. Pre-processing is an\nintegral part of multivariate analysis, but determination of the optimal\npre-processing methods can be time-consuming due to the large number of\navailable methods. In this work, the performance of a CNN was investigated for\nclassification and regression analysis of spectral data. The CNN was compared\nwith various other chemometric methods, including support vector machines\n(SVMs) for classification and partial least squares regression (PLSR) for\nregression analysis. The comparisons were made both on raw data, and on data\nthat had gone through pre-processing and/or feature selection methods. The\nmodels were used on spectral data acquired with methods based on near-infrared,\nmid-infrared, and Raman spectroscopy. For the classification datasets the\nmodels were evaluated based on the percentage of correctly classified\nobservations, while for regression analysis the models were assessed based on\nthe coefficient of determination (R$^2$). Our results show that CNNs can\noutperform standard chemometric methods, especially for classification tasks\nwhere no pre-processing is used. However, both CNN and the standard chemometric\nmethods see improved performance when proper pre-processing and feature\nselection methods are used. These results demonstrate some of the capabilities\nand limitations of CNNs used on one-dimensional data.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 13:20:05 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Jernelv", "Ine L.", ""], ["Hjelme", "Dag Roar", ""], ["Matsuura", "Yuji", ""], ["Aksnes", "Astrid", ""]]}, {"id": "2005.07541", "submitter": "Tim Hertweck", "authors": "Tim Hertweck, Martin Riedmiller, Michael Bloesch, Jost Tobias\n  Springenberg, Noah Siegel, Markus Wulfmeier, Roland Hafner, Nicolas Heess", "title": "Simple Sensor Intentions for Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern reinforcement learning algorithms can learn solutions to increasingly\ndifficult control problems while at the same time reduce the amount of prior\nknowledge needed for their application. One of the remaining challenges is the\ndefinition of reward schemes that appropriately facilitate exploration without\nbiasing the solution in undesirable ways, and that can be implemented on real\nrobotic systems without expensive instrumentation. In this paper we focus on a\nsetting in which goal tasks are defined via simple sparse rewards, and\nexploration is facilitated via agent-internal auxiliary tasks. We introduce the\nidea of simple sensor intentions (SSIs) as a generic way to define auxiliary\ntasks. SSIs reduce the amount of prior knowledge that is required to define\nsuitable rewards. They can further be computed directly from raw sensor streams\nand thus do not require expensive and possibly brittle state estimation on real\nsystems. We demonstrate that a learning system based on these rewards can solve\ncomplex robotic tasks in simulation and in real world settings. In particular,\nwe show that a real robotic arm can learn to grasp and lift and solve a\nBall-in-a-Cup task from scratch, when only raw sensor streams are used for both\ncontroller input and in the auxiliary reward definition.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 13:46:55 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Hertweck", "Tim", ""], ["Riedmiller", "Martin", ""], ["Bloesch", "Michael", ""], ["Springenberg", "Jost Tobias", ""], ["Siegel", "Noah", ""], ["Wulfmeier", "Markus", ""], ["Hafner", "Roland", ""], ["Heess", "Nicolas", ""]]}, {"id": "2005.07549", "submitter": "Zitao Liu", "authors": "Hang Li, Zhiwei Wang, Jiliang Tang, Wenbiao Ding, Zitao Liu", "title": "Siamese Neural Networks for Class Activity Detection", "comments": "The 21th International Conference on Artificial Intelligence in\n  Education(AIED), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classroom activity detection (CAD) aims at accurately recognizing speaker\nroles (either teacher or student) in classrooms. A CAD solution helps teachers\nget instant feedback on their pedagogical instructions. However, CAD is very\nchallenging because (1) classroom conversations contain many conversational\nturn-taking overlaps between teachers and students; (2) the CAD model needs to\nbe generalized well enough for different teachers and students; and (3)\nclassroom recordings may be very noisy and low-quality. In this work, we\naddress the above challenges by building a Siamese neural framework to\nautomatically identify teacher and student utterances from classroom\nrecordings. The proposed model is evaluated on real-world educational datasets.\nThe results demonstrate that (1) our approach is superior on the prediction\ntasks for both online and offline classroom environments; and (2) our framework\nexhibits robustness and generalization ability on new teachers (i.e., teachers\nnever appear in training data).\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 14:03:35 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Li", "Hang", ""], ["Wang", "Zhiwei", ""], ["Tang", "Jiliang", ""], ["Ding", "Wenbiao", ""], ["Liu", "Zitao", ""]]}, {"id": "2005.07567", "submitter": "Guangcun Shan Prof.", "authors": "Lu Han, G.C. Shan, H.Y. Wang, S.Q. Gao, W.X. Zhou", "title": "Accelerating drug repurposing for COVID-19 via modeling drug mechanism\n  of action with large scale gene-expression profiles", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novel coronavirus disease, named COVID-19, emerged in China in December\n2019, and has rapidly spread around the world. It is clearly urgent to fight\nCOVID-19 at global scale. The development of methods for identifying drug uses\nbased on phenotypic data can improve the efficiency of drug development.\nHowever, there are still many difficulties in identifying drug applications\nbased on cell picture data. This work reported one state-of-the-art machine\nlearning method to identify drug uses based on the cell image features of 1024\ndrugs generated in the LINCS program. Because the multi-dimensional features of\nthe image are affected by non-experimental factors, the characteristics of\nsimilar drugs vary greatly, and the current sample number is not enough to use\ndeep learning and other methods are used for learning optimization. As a\nconsequence, this study is based on the supervised ITML algorithm to convert\nthe characteristics of drugs. The results show that the characteristics of ITML\nconversion are more conducive to the recognition of drug functions. The\nanalysis of feature conversion shows that different features play important\nroles in identifying different drug functions. For the current COVID-19,\nChloroquine and Hydroxychloroquine achieve antiviral effects by inhibiting\nendocytosis, etc., and were classified to the same community. And Clomiphene in\nthe same community inibited the entry of Ebola Virus, indicated a similar MoAs\nthat could be reflected by cell image.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 14:28:56 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Han", "Lu", ""], ["Shan", "G. C.", ""], ["Wang", "H. Y.", ""], ["Gao", "S. Q.", ""], ["Zhou", "W. X.", ""]]}, {"id": "2005.07572", "submitter": "Donald Martin Jr.", "authors": "Donald Martin Jr. (1), Vinodkumar Prabhakaran (1), Jill Kuhlberg (2),\n  Andrew Smart (1), William S. Isaac (3) ((1) Google (2) System Stars (3)\n  DeepMind)", "title": "Participatory Problem Formulation for Fairer Machine Learning Through\n  Community Based System Dynamics", "comments": "Eighth Annual Conference on Learning Representations (ICLR 2020),\n  Virtual Workshop: Machine Learning in Real Life, April 26, 2020, 6 pages, 1\n  figure, fix comment typo, fix author name", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research on algorithmic fairness has highlighted that the problem\nformulation phase of ML system development can be a key source of bias that has\nsignificant downstream impacts on ML system fairness outcomes. However, very\nlittle attention has been paid to methods for improving the fairness efficacy\nof this critical phase of ML system development. Current practice neither\naccounts for the dynamic complexity of high-stakes domains nor incorporates the\nperspectives of vulnerable stakeholders. In this paper we introduce community\nbased system dynamics (CBSD) as an approach to enable the participation of\ntypically excluded stakeholders in the problem formulation phase of the ML\nsystem development process and facilitate the deep problem understanding\nrequired to mitigate bias during this crucial stage.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 14:41:43 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 03:54:30 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 13:57:28 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Martin", "Donald", "Jr."], ["Prabhakaran", "Vinodkumar", ""], ["Kuhlberg", "Jill", ""], ["Smart", "Andrew", ""], ["Isaac", "William S.", ""]]}, {"id": "2005.07578", "submitter": "Tina Raissi", "authors": "Tina Raissi, Eugen Beck, Ralf Schl\\\"uter, Hermann Ney", "title": "Context-Dependent Acoustic Modeling without Explicit Phone Clustering", "comments": "Proceedings of Interspeech 2020", "journal-ref": null, "doi": "10.21437/Interspeech.2020-1244", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phoneme-based acoustic modeling of large vocabulary automatic speech\nrecognition takes advantage of phoneme context. The large number of\ncontext-dependent (CD) phonemes and their highly varying statistics require\ntying or smoothing to enable robust training. Usually, classification and\nregression trees are used for phonetic clustering, which is standard in hidden\nMarkov model (HMM)-based systems. However, this solution introduces a secondary\ntraining objective and does not allow for end-to-end training. In this work, we\naddress a direct phonetic context modeling for the hybrid deep neural network\n(DNN)/HMM, that does not build on any phone clustering algorithm for the\ndetermination of the HMM state inventory. By performing different\ndecompositions of the joint probability of the center phoneme state and its\nleft and right contexts, we obtain a factorized network consisting of different\ncomponents, trained jointly. Moreover, the representation of the phonetic\ncontext for the network relies on phoneme embeddings. The recognition accuracy\nof our proposed models on the Switchboard task is comparable and outperforms\nslightly the hybrid model using the standard state-tying decision trees.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 14:45:32 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 12:32:37 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Raissi", "Tina", ""], ["Beck", "Eugen", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "2005.07604", "submitter": "Felix Hamann", "authors": "Nadja Kurz, Felix Hamann, Adrian Ulges", "title": "Neural Entity Linking on Technical Service Tickets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity linking, the task of mapping textual mentions to known entities, has\nrecently been tackled using contextualized neural networks. We address the\nquestion whether these results -- reported for large, high-quality datasets\nsuch as Wikipedia -- transfer to practical business use cases, where labels are\nscarce, text is low-quality, and terminology is highly domain-specific. Using\nan entity linking model based on BERT, a popular transformer network in natural\nlanguage processing, we show that a neural approach outperforms and complements\nhand-coded heuristics, with improvements of about 20% top-1 accuracy. Also, the\nbenefits of transfer learning on a large corpus are demonstrated, while\nfine-tuning proves difficult. Finally, we compare different BERT-based\narchitectures and show that a simple sentence-wise encoding (Bi-Encoder) offers\na fast yet efficient search in practice.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 15:47:02 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 14:11:16 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Kurz", "Nadja", ""], ["Hamann", "Felix", ""], ["Ulges", "Adrian", ""]]}, {"id": "2005.07605", "submitter": "Ambuj Tewari", "authors": "A. Philip Dawid and Ambuj Tewari", "title": "On Learnability under General Stochastic Processes", "comments": "The sandwiching result for the first definition of learnability in\n  the previous version is replaced by an equivalence with online learnability", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical learning theory under independent and identically distributed\n(iid) sampling and online learning theory for worst case individual sequences\nare two of the best developed branches of learning theory. Statistical learning\nunder general non-iid stochastic processes is less mature. We provide two\nnatural notions of learnability of a function class under a general stochastic\nprocess. We show that both notions are in fact equivalent to online\nlearnability. Our results are sharpest in the binary classification setting but\nwe also show that similar results continue to hold in the regression setting.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 15:49:23 GMT"}, {"version": "v2", "created": "Sat, 24 Apr 2021 21:15:13 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Dawid", "A. Philip", ""], ["Tewari", "Ambuj", ""]]}, {"id": "2005.07606", "submitter": "Xunguang Wang", "authors": "Xunguang Wang, Ship Peng Xu, and Eric Ke Wang", "title": "Initializing Perturbations in Multiple Directions for Fast Adversarial\n  Training", "comments": "has no contribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in the filed of Deep Learning have demonstrated that Deep\nNeural Networks(DNNs) are vulnerable to adversarial examples. Specifically, in\nimage classification, an adversarial example can fool the well trained deep\nneural networks by adding barely imperceptible perturbations to clean images.\nAdversarial Training, one of the most direct and effective methods, minimizes\nthe losses of perturbed-data to learn robust deep networks against adversarial\nattacks. It has been proven that using the fast gradient sign method (FGSM) can\nachieve Fast Adversarial Training. However, FGSM-based adversarial training may\nfinally obtain a failed model because of overfitting to FGSM samples. In this\npaper, we proposed the Diversified Initialized Perturbations Adversarial\nTraining (DIP-FAT) which involves seeking the initialization of the\nperturbation via enlarging the output distances of the target model in a random\ndirections. Due to the diversity of random directions, the embedded fast\nadversarial training using FGSM increases the information from the adversary\nand reduces the possibility of overfitting. In addition to preventing\noverfitting, the extensive results show that our proposed DIP-FAT technique can\nalso improve the accuracy of the clean data. The biggest advantage of DIP-FAT\nmethod: achieving the best banlance among clean-data, perturbed-data and\nefficiency.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 15:52:33 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 07:59:28 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Wang", "Xunguang", ""], ["Xu", "Ship Peng", ""], ["Wang", "Eric Ke", ""]]}, {"id": "2005.07609", "submitter": "Zekun Ren", "authors": "Zekun Ren, Juhwan Noh, Siyu Tian, Felipe Oviedo, Guangzong Xing,\n  Qiaohao Liang, Armin Aberle, Yi Liu, Qianxiao Li, Senthilnath Jayavelu, Kedar\n  Hippalgaonkar, Yousung Jung, Tonio Buonassisi", "title": "Inverse design of crystals using generalized invertible crystallographic\n  representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has fostered many novel applications in materials informatics.\nHowever, the inverse design of inorganic crystals, $\\textit{i.e.}$ generating\nnew crystal structure with targeted properties, remains a grand challenge. An\nimportant ingredient for such generative models is an invertible representation\nthat accesses the full periodic table. This is challenging due to limited data\navailability and the complexity of 3D periodic crystal structures. In this\npaper, we present a generalized invertible representation that encodes the\ncrystallographic information into the descriptors in both real space and\nreciprocal space. Combining with a generative variational autoencoder (VAE), a\nwide range of crystallographic structures and chemistries with desired\nproperties can be inverse-designed. We show that our VAE model predicts novel\ncrystal structures that do not exist in the training and test database\n(Materials Project) with targeted formation energies and band gaps. We validate\nthose predicted crystals by first-principles calculations. Finally, to design\nsolids with practical applications, we address the sparse label problem by\nbuilding a semi-supervised VAE and demonstrate its successful prediction of\nunique thermoelectric materials\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 15:58:31 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 08:55:46 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Ren", "Zekun", ""], ["Noh", "Juhwan", ""], ["Tian", "Siyu", ""], ["Oviedo", "Felipe", ""], ["Xing", "Guangzong", ""], ["Liang", "Qiaohao", ""], ["Aberle", "Armin", ""], ["Liu", "Yi", ""], ["Li", "Qianxiao", ""], ["Jayavelu", "Senthilnath", ""], ["Hippalgaonkar", "Kedar", ""], ["Jung", "Yousung", ""], ["Buonassisi", "Tonio", ""]]}, {"id": "2005.07623", "submitter": "Daniel Kohlsdorf", "authors": "Daniel Kohlsdorf, Denise Herzing, Thad Starner", "title": "An Auto Encoder For Audio Dolphin Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in dolphin communication and cognition requires detailed inspection\nof audible dolphin signals. The manual analysis of these signals is cumbersome\nand time-consuming. We seek to automate parts of the analysis using modern deep\nlearning methods. We propose to learn an autoencoder constructed from\nconvolutional and recurrent layers trained in an unsupervised fashion. The\nresulting model embeds patterns in audible dolphin communication. In several\nexperiments, we show that the embeddings can be used for clustering as well as\nsignal detection and signal type classification.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 16:30:04 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Kohlsdorf", "Daniel", ""], ["Herzing", "Denise", ""], ["Starner", "Thad", ""]]}, {"id": "2005.07631", "submitter": "Hongsheng Chen", "authors": "Hongsheng Chen, Teng Xiang, Kai Chen, Jing Lu", "title": "Nonlinear Residual Echo Suppression Based on Multi-stream Conv-TasNet", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic echo cannot be entirely removed by linear adaptive filters due to\nthe nonlinear relationship between the echo and far-end signal. Usually a post\nprocessing module is required to further suppress the echo. In this paper, we\npropose a residual echo suppression method based on the modification of fully\nconvolutional time-domain audio separation network (Conv-TasNet). Both the\nresidual signal of the linear acoustic echo cancellation system, and the output\nof the adaptive filter are adopted to form multiple streams for the\nConv-TasNet, resulting in more effective echo suppression while keeping a lower\nlatency of the whole system. Simulation results validate the efficacy of the\nproposed method in both single-talk and double-talk situations.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 16:41:16 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Chen", "Hongsheng", ""], ["Xiang", "Teng", ""], ["Chen", "Kai", ""], ["Lu", "Jing", ""]]}, {"id": "2005.07647", "submitter": "Xavier Suau Cuadros", "authors": "Xavier Suau, Luca Zappella, Nicholas Apostoloff", "title": "Finding Experts in Transformer Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this work we study the presence of expert units in pre-trained Transformer\nModels (TM), and how they impact a model's performance. We define expert units\nto be neurons that are able to classify a concept with a given average\nprecision, where a concept is represented by a binary set of sentences\ncontaining the concept (or not). Leveraging the OneSec dataset (Scarlini et\nal., 2019), we compile a dataset of 1641 concepts that allows diverse expert\nunits in TM to be discovered. We show that expert units are important in\nseveral ways: (1) The presence of expert units is correlated ($r^2=0.833$) with\nthe generalization power of TM, which allows ranking TM without requiring\nfine-tuning on suites of downstream tasks. We further propose an empirical\nmethod to decide how accurate such experts should be to evaluate\ngeneralization. (2) The overlap of top experts between concepts provides a\nsensible way to quantify concept co-learning, which can be used for\nexplainability of unknown concepts. (3) We show how to self-condition\noff-the-shelf pre-trained language models to generate text with a given concept\nby forcing the top experts to be active, without requiring re-training the\nmodel or using additional parameters.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:07:02 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Suau", "Xavier", ""], ["Zappella", "Luca", ""], ["Apostoloff", "Nicholas", ""]]}, {"id": "2005.07649", "submitter": "Hugo Mitre-Hernandez", "authors": "Rodolfo Ferro-P\\'erez, Hugo Mitre-Hernandez", "title": "ResMoNet: A Residual Mobile-based Network for Facial Emotion Recognition\n  in Resource-Limited Systems", "comments": "11 pages, 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Deep Neural Networks (DNNs) models have contributed a high accuracy for\nthe classification of human emotional states from facial expression recognition\ndata sets, where efficiency is an important factor for resource-limited systems\nas mobile devices and embedded systems. There are efficient Convolutional\nNeural Networks (CNN) models as MobileNet, PeleeNet, Extended Deep Neural\nNetwork (EDNN) and Inception-Based Deep Neural Network (IDNN) in terms of model\narchitecture results: parameters, Floating-point OPerations (FLOPs) and\naccuracy. Although these results are satisfactory, it is necessary to evaluate\nother computational resources related to the trained model such as main memory\nutilization and response time to complete the emotion recognition. In this\npaper, we compare our proposed model inspired in depthwise separable\nconvolutions and residual blocks with MobileNet, PeleeNet, EDNN and IDNN. The\ncomparative results of the CNN architectures and the trained models --with\nRadboud Faces Database (RaFD)-- installed in a resource-limited device are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:09:10 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Ferro-P\u00e9rez", "Rodolfo", ""], ["Mitre-Hernandez", "Hugo", ""]]}, {"id": "2005.07652", "submitter": "Omar Montasser", "authors": "Omar Montasser, Surbhi Goel, Ilias Diakonikolas, Nathan Srebro", "title": "Efficiently Learning Adversarially Robust Halfspaces with Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning adversarially robust halfspaces in the\ndistribution-independent setting. In the realizable setting, we provide\nnecessary and sufficient conditions on the adversarial perturbation sets under\nwhich halfspaces are efficiently robustly learnable. In the presence of random\nlabel noise, we give a simple computationally efficient algorithm for this\nproblem with respect to any $\\ell_p$-perturbation.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:13:54 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Montasser", "Omar", ""], ["Goel", "Surbhi", ""], ["Diakonikolas", "Ilias", ""], ["Srebro", "Nathan", ""]]}, {"id": "2005.07656", "submitter": "Luis Miralles PHD", "authors": "Luis Miralles-Pechu\\'an, Fernando Jim\\'enez, Hiram Ponce, Lourdes\n  Mart\\'inez-Villase\\~nor", "title": "A Deep Q-learning/genetic Algorithms Based Novel Methodology For\n  Optimizing Covid-19 Pandemic Government Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whenever countries are threatened by a pandemic, as is the case with the\nCOVID-19 virus, governments should take the right actions to safeguard public\nhealth as well as to mitigate the negative effects on the economy. In this\nregard, there are two completely different approaches governments can take: a\nrestrictive one, in which drastic measures such as self-isolation can seriously\ndamage the economy, and a more liberal one, where more relaxed restrictions may\nput at risk a high percentage of the population. The optimal approach could be\nsomewhere in between, and, in order to make the right decisions, it is\nnecessary to accurately estimate the future effects of taking one or other\nmeasures. In this paper, we use the SEIR epidemiological model (Susceptible -\nExposed - Infected - Recovered) for infectious diseases to represent the\nevolution of the virus COVID-19 over time in the population. To optimize the\nbest sequences of actions governments can take, we propose a methodology with\ntwo approaches, one based on Deep Q-Learning and another one based on Genetic\nAlgorithms. The sequences of actions (confinement, self-isolation, two-meter\ndistance or not taking restrictions) are evaluated according to a reward system\nfocused on meeting two objectives: firstly, getting few people infected so that\nhospitals are not overwhelmed with critical patients, and secondly, avoiding\ntaking drastic measures for too long which can potentially cause serious damage\nto the economy. The conducted experiments prove that our methodology is a valid\ntool to discover actions governments can take to reduce the negative effects of\na pandemic in both senses. We also prove that the approach based on Deep\nQ-Learning overcomes the one based on Genetic Algorithms for optimizing the\nsequences of actions.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:17:45 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Miralles-Pechu\u00e1n", "Luis", ""], ["Jim\u00e9nez", "Fernando", ""], ["Ponce", "Hiram", ""], ["Mart\u00ednez-Villase\u00f1or", "Lourdes", ""]]}, {"id": "2005.07666", "submitter": "Tegg Sung", "authors": "Tegg Taekyong Sung, Jeongsoo Ha, Jeewoo Kim, Alex Yahja, Chae-Bong\n  Sohn, Bo Ryu", "title": "DeepSoCS: A Neural Scheduler for Heterogeneous System-on-Chip (SoC)\n  Resource Scheduling", "comments": "18 pages, Accepted by Electronics 2020", "journal-ref": null, "doi": "10.3390/electronics9060936", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we~present a novel scheduling solution for a class of\nSystem-on-Chip (SoC) systems where heterogeneous chip resources (DSP, FPGA,\nGPU, etc.) must be efficiently scheduled for continuously arriving hierarchical\njobs with their tasks represented by a directed acyclic graph. Traditionally,\nheuristic algorithms have been widely used for many resource scheduling\ndomains, and Heterogeneous Earliest Finish Time (HEFT) has been a dominating\nstate-of-the-art technique across a broad range of heterogeneous resource\nscheduling domains over many years. Despite their long-standing popularity,\nHEFT-like algorithms are known to be vulnerable to a small amount of noise\nadded to the environment. Our Deep Reinforcement Learning (DRL)-based SoC\nScheduler (DeepSoCS), capable of learning the \"best\" task ordering under\ndynamic environment changes, overcomes the brittleness of rule-based schedulers\nsuch as HEFT with significantly higher performance across different types of\njobs. We~describe a DeepSoCS design process using a real-time heterogeneous SoC\nscheduling emulator, discuss major challenges, and present two novel neural\nnetwork design features that lead to outperforming HEFT: (i) hierarchical job-\nand task-graph embedding; and (ii) efficient use of real-time task information\nin the state space. Furthermore, we~introduce effective techniques to address\ntwo fundamental challenges present in our environment: delayed consequences and\njoint actions. Through an extensive simulation study, we~show that our DeepSoCS\nexhibits the significantly higher performance of job execution time than that\nof HEFT with a higher level of robustness under realistic noise conditions.\nWe~conclude with a discussion of the potential improvements for our DeepSoCS\nneural scheduler.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:31:27 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 09:53:01 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Sung", "Tegg Taekyong", ""], ["Ha", "Jeongsoo", ""], ["Kim", "Jeewoo", ""], ["Yahja", "Alex", ""], ["Sohn", "Chae-Bong", ""], ["Ryu", "Bo", ""]]}, {"id": "2005.07667", "submitter": "Jovan Kalajdjieski", "authors": "Jovan Kalajdjieski, Martina Toshevska, Frosina Stojanovska", "title": "Recent Advances in SQL Query Generation: A Survey", "comments": "Part of the 17th International Conference on Informatics and\n  Information Technologies. Received best paper award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Natural language is hypothetically the best user interface for many domains.\nHowever, general models that provide an interface between natural language and\nany other domain still do not exist. Providing natural language interface to\nrelational databases could possibly attract a vast majority of users that are\nor are not proficient with query languages. With the rise of deep learning\ntechniques, there is extensive ongoing research in designing a suitable natural\nlanguage interface to relational databases.\n  This survey aims to overview some of the latest methods and models proposed\nin the area of SQL query generation from natural language. We describe models\nwith various architectures such as convolutional neural networks, recurrent\nneural networks, pointer networks, reinforcement learning, etc. Several\ndatasets intended to address the problem of SQL query generation are\ninterpreted and briefly overviewed. In the end, evaluation metrics utilized in\nthe field are presented mainly as a combination of execution accuracy and\nlogical form accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:31:29 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Kalajdjieski", "Jovan", ""], ["Toshevska", "Martina", ""], ["Stojanovska", "Frosina", ""]]}, {"id": "2005.07669", "submitter": "Jeovane Hon\\'orio Alves", "authors": "Jeovane Honorio Alves, Lucas Ferrari de Oliveira", "title": "Optimizing Neural Architecture Search using Limited GPU Time in a\n  Dynamic Search Space: A Gene Expression Programming Approach", "comments": "Accepted for presentation at the IEEE Congress on Evolutionary\n  Computation (IEEE CEC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient identification of people and objects, segmentation of regions of\ninterest and extraction of relevant data in images, texts, audios and videos\nare evolving considerably in these past years, which deep learning methods,\ncombined with recent improvements in computational resources, contributed\ngreatly for this achievement. Although its outstanding potential, development\nof efficient architectures and modules requires expert knowledge and amount of\nresource time available. In this paper, we propose an evolutionary-based neural\narchitecture search approach for efficient discovery of convolutional models in\na dynamic search space, within only 24 GPU hours. With its efficient search\nenvironment and phenotype representation, Gene Expression Programming is\nadapted for network's cell generation. Despite having limited GPU resource time\nand broad search space, our proposal achieved similar state-of-the-art to\nmanually-designed convolutional networks and also NAS-generated ones, even\nbeating similar constrained evolutionary-based NAS works. The best cells in\ndifferent runs achieved stable results, with a mean error of 2.82% in CIFAR-10\ndataset (which the best model achieved an error of 2.67%) and 18.83% for\nCIFAR-100 (best model with 18.16%). For ImageNet in the mobile setting, our\nbest model achieved top-1 and top-5 errors of 29.51% and 10.37%, respectively.\nAlthough evolutionary-based NAS works were reported to require a considerable\namount of GPU time for architecture search, our approach obtained promising\nresults in little time, encouraging further experiments in evolutionary-based\nNAS, for search and network representation improvements.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:32:30 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Alves", "Jeovane Honorio", ""], ["de Oliveira", "Lucas Ferrari", ""]]}, {"id": "2005.07675", "submitter": "Brian Kim", "authors": "Brian Kim and Yalin E. Sagduyu and Kemal Davaslioglu and Tugba Erpek\n  and Sennur Ulukus", "title": "How to Make 5G Communications \"Invisible\": Adversarial Machine Learning\n  for Wireless Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of hiding wireless communications from an\neavesdropper that employs a deep learning (DL) classifier to detect whether any\ntransmission of interest is present or not. There exists one transmitter that\ntransmits to its receiver in the presence of an eavesdropper, while a\ncooperative jammer (CJ) transmits carefully crafted adversarial perturbations\nover the air to fool the eavesdropper into classifying the received\nsuperposition of signals as noise. The CJ puts an upper bound on the strength\nof perturbation signal to limit its impact on the bit error rate (BER) at the\nreceiver. We show that this adversarial perturbation causes the eavesdropper to\nmisclassify the received signals as noise with high probability while\nincreasing the BER only slightly. On the other hand, the CJ cannot fool the\neavesdropper by simply transmitting Gaussian noise as in conventional jamming\nand instead needs to craft perturbation signals built by adversarial machine\nlearning to enable covert communications. Our results show that signals with\ndifferent modulation types and eventually 5G communications can be effectively\nhidden from an eavesdropper even if it is equipped with a DL classifier to\ndetect transmissions.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:45:11 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Kim", "Brian", ""], ["Sagduyu", "Yalin E.", ""], ["Davaslioglu", "Kemal", ""], ["Erpek", "Tugba", ""], ["Ulukus", "Sennur", ""]]}, {"id": "2005.07677", "submitter": "Miguel Gonz\\'alez-Duque", "authors": "Miguel Gonz\\'alez-Duque, Rasmus Berg Palm, David Ha, Sebastian Risi", "title": "Finding Game Levels with the Right Difficulty in a Few Trials through\n  Intelligent Trial-and-Error", "comments": "To be presented in the Conference on Games 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Methods for dynamic difficulty adjustment allow games to be tailored to\nparticular players to maximize their engagement. However, current methods often\nonly modify a limited set of game features such as the difficulty of the\nopponents, or the availability of resources. Other approaches, such as\nexperience-driven Procedural Content Generation (PCG), can generate complete\nlevels with desired properties such as levels that are neither too hard nor too\neasy, but require many iterations. This paper presents a method that can\ngenerate and search for complete levels with a specific target difficulty in\nonly a few trials. This advance is enabled by through an Intelligent\nTrial-and-Error algorithm, originally developed to allow robots to adapt\nquickly. Our algorithm first creates a large variety of different levels that\nvary across predefined dimensions such as leniency or map coverage. The\nperformance of an AI playing agent on these maps gives a proxy for how\ndifficult the level would be for another AI agent (e.g. one that employs Monte\nCarlo Tree Search instead of Greedy Tree Search); using this information, a\nBayesian Optimization procedure is deployed, updating the difficulty of the\nprior map to reflect the ability of the agent. The approach can reliably find\nlevels with a specific target difficulty for a variety of planning agents in\nonly a few trials, while maintaining an understanding of their skill landscape.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:48:18 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 12:55:08 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Gonz\u00e1lez-Duque", "Miguel", ""], ["Palm", "Rasmus Berg", ""], ["Ha", "David", ""], ["Risi", "Sebastian", ""]]}, {"id": "2005.07683", "submitter": "Victor Sanh", "authors": "Victor Sanh, Thomas Wolf, Alexander M. Rush", "title": "Movement Pruning: Adaptive Sparsity by Fine-Tuning", "comments": "14 pages, 6 figures, 3 tables. Published at NeurIPS2020. Code:\n  \\url{huggingface.co/mvp}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnitude pruning is a widely used strategy for reducing model size in pure\nsupervised learning; however, it is less effective in the transfer learning\nregime that has become standard for state-of-the-art natural language\nprocessing applications. We propose the use of movement pruning, a simple,\ndeterministic first-order weight pruning method that is more adaptive to\npretrained model fine-tuning. We give mathematical foundations to the method\nand compare it to existing zeroth- and first-order pruning methods. Experiments\nshow that when pruning large pretrained language models, movement pruning shows\nsignificant improvements in high-sparsity regimes. When combined with\ndistillation, the approach achieves minimal accuracy loss with down to only 3%\nof the model parameters.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:54:15 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 16:14:58 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Sanh", "Victor", ""], ["Wolf", "Thomas", ""], ["Rush", "Alexander M.", ""]]}, {"id": "2005.07688", "submitter": "Aythami Morales", "authors": "Aythami Morales and Alejandro Acien and Julian Fierrez and John V.\n  Monaco and Ruben Tolosana and Ruben Vera-Rodriguez and Javier Ortega-Garcia", "title": "Keystroke Biometrics in Response to Fake News Propagation in a Global\n  Pandemic", "comments": "arXiv admin note: text overlap with arXiv:2004.03627", "journal-ref": "IEEE International Workshop on Secure Digital Identity Management\n  (SDIM) 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes and analyzes the use of keystroke biometrics for content\nde-anonymization. Fake news have become a powerful tool to manipulate public\nopinion, especially during major events. In particular, the massive spread of\nfake news during the COVID-19 pandemic has forced governments and companies to\nfight against missinformation. In this context, the ability to link multiple\naccounts or profiles that spread such malicious content on the Internet while\nhiding in anonymity would enable proactive identification and blacklisting.\nBehavioral biometrics can be powerful tools in this fight. In this work, we\nhave analyzed how the latest advances in keystroke biometric recognition can\nhelp to link behavioral typing patterns in experiments involving 100,000 users\nand more than 1 million typed sequences. Our proposed system is based on\nRecurrent Neural Networks adapted to the context of content de-anonymization.\nAssuming the challenge to link the typed content of a target user in a pool of\ncandidate profiles, our results show that keystroke recognition can be used to\nreduce the list of candidate profiles by more than 90%. In addition, when\nkeystroke is combined with auxiliary data (such as location), our system\nachieves a Rank-1 identification performance equal to 52.6% and 10.9% for a\nbackground candidate list composed of 1K and 100K profiles, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:56:11 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 06:23:56 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Morales", "Aythami", ""], ["Acien", "Alejandro", ""], ["Fierrez", "Julian", ""], ["Monaco", "John V.", ""], ["Tolosana", "Ruben", ""], ["Vera-Rodriguez", "Ruben", ""], ["Ortega-Garcia", "Javier", ""]]}, {"id": "2005.07692", "submitter": "Altan Cakir", "authors": "Gizem Aras, Didem Makaroglu, Seniz Demir, Altan Cakir", "title": "An Evaluation of Recent Neural Sequence Tagging Models in Turkish Named\n  Entity Recognition", "comments": "Submitted to Expert Systems with Applications", "journal-ref": null, "doi": null, "report-no": "ITUAI08", "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition (NER) is an extensively studied task that extracts\nand classifies named entities in a text. NER is crucial not only in downstream\nlanguage processing applications such as relation extraction and question\nanswering but also in large scale big data operations such as real-time\nanalysis of online digital media content. Recent research efforts on Turkish, a\nless studied language with morphologically rich nature, have demonstrated the\neffectiveness of neural architectures on well-formed texts and yielded\nstate-of-the art results by formulating the task as a sequence tagging problem.\nIn this work, we empirically investigate the use of recent neural architectures\n(Bidirectional long short-term memory and Transformer-based networks) proposed\nfor Turkish NER tagging in the same setting. Our results demonstrate that\ntransformer-based networks which can model long-range context overcome the\nlimitations of BiLSTM networks where different input features at the character,\nsubword, and word levels are utilized. We also propose a transformer-based\nnetwork with a conditional random field (CRF) layer that leads to the\nstate-of-the-art result (95.95\\% f-measure) on a common dataset. Our study\ncontributes to the literature that quantifies the impact of transfer learning\non processing morphologically rich languages.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 06:54:07 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 05:53:16 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Aras", "Gizem", ""], ["Makaroglu", "Didem", ""], ["Demir", "Seniz", ""], ["Cakir", "Altan", ""]]}, {"id": "2005.07694", "submitter": "Hector Javier Hortua", "authors": "H\\'ector J. Hort\\'ua, Luigi Malago, Riccardo Volpi", "title": "Constraining the Reionization History using Bayesian Normalizing Flows", "comments": "17 pages, 5 figures. arXiv admin note: substantial text overlap with\n  arXiv:2005.02299", "journal-ref": "Mach. Learn.: Sci. Technol. 1 035014, 2020", "doi": "10.1088/2632-2153/aba6f1", "report-no": null, "categories": "astro-ph.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The next generation 21 cm surveys open a new window onto the early stages of\ncosmic structure formation and provide new insights about the Epoch of\nReionization (EoR). However, the non-Gaussian nature of the 21 cm signal along\nwith the huge amount of data generated from these surveys will require more\nadvanced techniques capable to efficiently extract the necessary information to\nconstrain the Reionization History of the Universe. In this paper we present\nthe use of Bayesian Neural Networks (BNNs) to predict the posterior\ndistribution for four astrophysical and cosmological parameters. Besides\nachieving state-of-the-art prediction performances, the proposed methods\nprovide accurate estimation of parameters uncertainties and infer correlations\namong them. Additionally, we demonstrate the advantages of Normalizing Flows\n(NF) combined with BNNs, being able to model more complex output distributions\nand thus capture key information as non-Gaussianities in the parameter\nconditional density distribution for astrophysical and cosmological dataset.\nFinally, we propose novel calibration methods employing Normalizing Flows after\ntraining, to produce reliable predictions, and we demonstrate the advantages of\nthis approach both in terms of computational cost and prediction performances.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 23:00:55 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Hort\u00faa", "H\u00e9ctor J.", ""], ["Malago", "Luigi", ""], ["Volpi", "Riccardo", ""]]}, {"id": "2005.07702", "submitter": "Filip Andersson", "authors": "Filip Andersson, Simon Arvidsson", "title": "Generative Adversarial Networks for photo to Hayao Miyazaki style\n  cartoons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper takes on the problem of transferring the style of cartoon images\nto real-life photographic images by implementing previous work done by\nCartoonGAN. We trained a Generative Adversial Network(GAN) on over 60 000\nimages from works by Hayao Miyazaki at Studio Ghibli. To evaluate our results,\nwe conducted a qualitative survey comparing our results with two\nstate-of-the-art methods. 117 survey results indicated that our model on\naverage outranked state-of-the-art methods on cartoon-likeness.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 19:26:11 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Andersson", "Filip", ""], ["Arvidsson", "Simon", ""]]}, {"id": "2005.07704", "submitter": "Derek Jones", "authors": "Derek Jones, Hyojin Kim, Xiaohua Zhang, Adam Zemla, Garrett Stevenson,\n  William D. Bennett, Dan Kirshner, Sergio Wong, Felice Lightstone and Jonathan\n  E. Allen", "title": "Improved Protein-ligand Binding Affinity Prediction with Structure-Based\n  Deep Fusion Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting accurate protein-ligand binding affinity is important in drug\ndiscovery but remains a challenge even with computationally expensive\nbiophysics-based energy scoring methods and state-of-the-art deep learning\napproaches. Despite the recent advances in the deep convolutional and graph\nneural network based approaches, the model performance depends on the input\ndata representation and suffers from distinct limitations. It is natural to\ncombine complementary features and their inference from the individual models\nfor better predictions. We present fusion models to benefit from different\nfeature representations of two neural network models to improve the binding\naffinity prediction. We demonstrate effectiveness of the proposed approach by\nperforming experiments with the PDBBind 2016 dataset and its docking pose\ncomplexes. The results show that the proposed approach improves the overall\nprediction compared to the individual neural network models with greater\ncomputational efficiency than related biophysics based energy scoring\nfunctions. We also discuss the benefit of the proposed fusion inference with\nseveral example complexes. The software is made available as open source at\nhttps://github.com/llnl/fast.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 22:26:27 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Jones", "Derek", ""], ["Kim", "Hyojin", ""], ["Zhang", "Xiaohua", ""], ["Zemla", "Adam", ""], ["Stevenson", "Garrett", ""], ["Bennett", "William D.", ""], ["Kirshner", "Dan", ""], ["Wong", "Sergio", ""], ["Lightstone", "Felice", ""], ["Allen", "Jonathan E.", ""]]}, {"id": "2005.07724", "submitter": "Atish Agarwala", "authors": "Atish Agarwala, Abhimanyu Das, Rina Panigrahy, Qiuyi Zhang", "title": "Learning the gravitational force law and other analytic functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large neural network models have been successful in learning functions of\nimportance in many branches of science, including physics, chemistry and\nbiology. Recent theoretical work has shown explicit learning bounds for wide\nnetworks and kernel methods on some simple classes of functions, but not on\nmore complex functions which arise in practice. We extend these techniques to\nprovide learning bounds for analytic functions on the sphere for any kernel\nmethod or equivalent infinitely-wide network with the corresponding activation\nfunction trained with SGD. We show that a wide, one-hidden layer ReLU network\ncan learn analytic functions with a number of samples proportional to the\nderivative of a related function. Many functions important in the sciences are\ntherefore efficiently learnable. As an example, we prove explicit bounds on\nlearning the many-body gravitational force function given by Newton's law of\ngravitation. Our theoretical bounds suggest that very wide ReLU networks (and\nthe corresponding NTK kernel) are better at learning analytic functions as\ncompared to kernel learning with Gaussian kernels. We present experimental\nevidence that the many-body gravitational force function is easier to learn\nwith ReLU networks as compared to networks with exponential activations.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 18:11:48 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Agarwala", "Atish", ""], ["Das", "Abhimanyu", ""], ["Panigrahy", "Rina", ""], ["Zhang", "Qiuyi", ""]]}, {"id": "2005.07727", "submitter": "David Bau iii", "authors": "David Bau, Hendrik Strobelt, William Peebles, Jonas Wulff, Bolei Zhou,\n  Jun-Yan Zhu, Antonio Torralba", "title": "Semantic Photo Manipulation with a Generative Image Prior", "comments": "SIGGRAPH 2019", "journal-ref": "ACM Transactions on Graphics (TOG) 38.4 (2019)", "doi": "10.1145/3306346.3323023", "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent success of GANs in synthesizing images conditioned on\ninputs such as a user sketch, text, or semantic labels, manipulating the\nhigh-level attributes of an existing natural photograph with GANs is\nchallenging for two reasons. First, it is hard for GANs to precisely reproduce\nan input image. Second, after manipulation, the newly synthesized pixels often\ndo not fit the original image. In this paper, we address these issues by\nadapting the image prior learned by GANs to image statistics of an individual\nimage. Our method can accurately reconstruct the input image and synthesize new\ncontent, consistent with the appearance of the input image. We demonstrate our\ninteractive system on several semantic image editing tasks, including\nsynthesizing new objects consistent with background, removing unwanted objects,\nand changing the appearance of an object. Quantitative and qualitative\ncomparisons against several existing methods demonstrate the effectiveness of\nour method.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 18:22:05 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 19:53:55 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Bau", "David", ""], ["Strobelt", "Hendrik", ""], ["Peebles", "William", ""], ["Wulff", "Jonas", ""], ["Zhou", "Bolei", ""], ["Zhu", "Jun-Yan", ""], ["Torralba", "Antonio", ""]]}, {"id": "2005.07728", "submitter": "Yotam Nitzan", "authors": "Yotam Nitzan, Amit Bermano, Yangyan Li, Daniel Cohen-Or", "title": "Face Identity Disentanglement via Latent Space Mapping", "comments": "23 pages, 24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning disentangled representations of data is a fundamental problem in\nartificial intelligence. Specifically, disentangled latent representations\nallow generative models to control and compose the disentangled factors in the\nsynthesis process. Current methods, however, require extensive supervision and\ntraining, or instead, noticeably compromise quality. In this paper, we present\na method that learns how to represent data in a disentangled way, with minimal\nsupervision, manifested solely using available pre-trained networks. Our key\ninsight is to decouple the processes of disentanglement and synthesis, by\nemploying a leading pre-trained unconditional image generator, such as\nStyleGAN. By learning to map into its latent space, we leverage both its\nstate-of-the-art quality, and its rich and expressive latent space, without the\nburden of training it. We demonstrate our approach on the complex and high\ndimensional domain of human heads. We evaluate our method qualitatively and\nquantitatively, and exhibit its success with de-identification operations and\nwith temporal identity coherency in image sequences. Through extensive\nexperimentation, we show that our method successfully disentangles identity\nfrom other facial attributes, surpassing existing methods, even though they\nrequire more training and supervision.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 18:24:49 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 16:24:06 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 12:24:42 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Nitzan", "Yotam", ""], ["Bermano", "Amit", ""], ["Li", "Yangyan", ""], ["Cohen-Or", "Daniel", ""]]}, {"id": "2005.07731", "submitter": "Michael Haus", "authors": "Michael Haus, J\\\"org Ott, Aaron Yi Ding", "title": "Enabling Seamless Device Association with DevLoc using Light Bulb\n  Networks for Indoor IoT Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To enable serendipitous interaction for indoor IoT environments, spontaneous\ndevice associations are of particular interest so that users set up a\nconnection in an ad-hoc manner. Based on the similarity of light signals, our\nsystem named DevLoc takes advantage of ubiquitous light sources around us to\nperform continuous and seamless device grouping. We provide a configuration\nframework to control the spatial granularity of user's proximity by managing\nthe lighting infrastructure through customized visible light communication. To\nrealize either proximity-based or location-based services, we support two modes\nof device associations between different entities: device-to-device and\ndevice-to-area. Regarding the best performing method for device grouping,\nmachine learning-based signal similarity performs in general best compared to\ndistance and correlation metrics. Furthermore, we analyze patterns of device\nassociations to improve the data privacy by recognizing semantic device groups,\nsuch as personal and stranger's devices, allowing automated data sharing\npolicies.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 18:33:42 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Haus", "Michael", ""], ["Ott", "J\u00f6rg", ""], ["Ding", "Aaron Yi", ""]]}, {"id": "2005.07755", "submitter": "Ziyi Chen", "authors": "Ziyi Chen, Yi Zhou", "title": "Momentum with Variance Reduction for Nonconvex Composition Optimization", "comments": "36 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Composition optimization is widely-applied in nonconvex machine learning.\nVarious advanced stochastic algorithms that adopt momentum and variance\nreduction techniques have been developed for composition optimization. However,\nthese algorithms do not fully exploit both techniques to accelerate the\nconvergence and are lack of convergence guarantee in nonconvex optimization.\nThis paper complements the existing literature by developing various momentum\nschemes with SPIDER-based variance reduction for non-convex composition\noptimization. In particular, our momentum design requires less number of\nproximal mapping evaluations per-iteration than that required by the existing\nKatyusha momentum. Furthermore, our algorithm achieves near-optimal sample\ncomplexity results in both non-convex finite-sum and online composition\noptimization and achieves a linear convergence rate under the gradient dominant\ncondition. Numerical experiments demonstrate that our algorithm converges\nsignificantly faster than existing algorithms in nonconvex composition\noptimization.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 19:29:33 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Chen", "Ziyi", ""], ["Zhou", "Yi", ""]]}, {"id": "2005.07757", "submitter": "Mostafa M. Mohamed", "authors": "Mostafa M. Mohamed and Bj\\\"orn W. Schuller", "title": "\"I have vxxx bxx connexxxn!\": Facing Packet Loss in Deep Speech Emotion\n  Recognition", "comments": "Submitted to INTERSPEECH 2020. 4 Pages + 1 page for references. 4\n  Figures and 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In applications that use emotion recognition via speech, frame-loss can be a\nsevere issue given manifold applications, where the audio stream loses some\ndata frames, for a variety of reasons like low bandwidth. In this contribution,\nwe investigate for the first time the effects of frame-loss on the performance\nof emotion recognition via speech. Reproducible extensive experiments are\nreported on the popular RECOLA corpus using a state-of-the-art end-to-end deep\nneural network, which mainly consists of convolution blocks and recurrent\nlayers. A simple environment based on a Markov Chain model is used to model the\nloss mechanism based on two main parameters. We explore matched, mismatched,\nand multi-condition training settings. As one expects, the matched setting\nyields the best performance, while the mismatched yields the lowest.\nFurthermore, frame-loss as a data augmentation technique is introduced as a\ngeneral-purpose strategy to overcome the effects of frame-loss. It can be used\nduring training, and we observed it to produce models that are more robust\nagainst frame-loss in run-time environments.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 19:33:40 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Mohamed", "Mostafa M.", ""], ["Schuller", "Bj\u00f6rn W.", ""]]}, {"id": "2005.07776", "submitter": "Amir Sonee", "authors": "Amir Sonee and Stefano Rini", "title": "Efficient Federated Learning over Multiple Access Channel with\n  Differential Privacy Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of federated learning (FL) through digital\ncommunication between clients and a parameter server (PS) over a multiple\naccess channel (MAC), also subject to differential privacy (DP) constraints, is\nstudied. More precisely, we consider the setting in which clients in a\ncentralized network are prompted to train a machine learning model using their\nlocal datasets. The information exchange between the clients and the PS takes\nplaces over a MAC channel and must also preserve the DP of the local datasets.\nAccordingly, the objective of the clients is to minimize the training loss\nsubject to (i) rate constraints for reliable communication over the MAC and\n(ii) DP constraint over the local datasets. For this optimization scenario, we\nproposed a novel consensus scheme in which digital distributed stochastic\ngradient descent (D-DSGD) is performed by each client. To preserve DP, a\ndigital artificial noise is also added by the users to the locally quantized\ngradients. The performance of the scheme is evaluated in terms of the\nconvergence rate and DP level for a given MAC capacity. The performance is\noptimized over the choice of the quantization levels and the artificial noise\nparameters. Numerical evaluations are presented to validate the performance of\nthe proposed scheme.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 20:38:04 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 14:39:45 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Sonee", "Amir", ""], ["Rini", "Stefano", ""]]}, {"id": "2005.07777", "submitter": "Mostafa M. Mohamed", "authors": "Mostafa M. Mohamed and Bj\\\"orn W. Schuller", "title": "ConcealNet: An End-to-end Neural Network for Packet Loss Concealment in\n  Deep Speech Emotion Recognition", "comments": "Submission for INTERSPEECH 2020. 4 Pages + 1 references page. 4\n  Tables, 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Packet loss is a common problem in data transmission, including speech data\ntransmission. This may affect a wide range of applications that stream audio\ndata, like streaming applications or speech emotion recognition (SER). Packet\nLoss Concealment (PLC) is any technique of facing packet loss. Simple PLC\nbaselines are 0-substitution or linear interpolation. In this paper, we present\na concealment wrapper, which can be used with stacked recurrent neural cells.\nThe concealment cell can provide a recurrent neural network (ConcealNet), that\nperforms real-time step-wise end-to-end PLC at inference time. Additionally,\nextending this with an end-to-end emotion prediction neural network provides a\nnetwork that performs SER from audio with lost frames, end-to-end. The proposed\nmodel is compared against the fore-mentioned baselines. Additionally, a\nbidirectional variant with better performance is utilised. For evaluation, we\nchose the public RECOLA dataset given its long audio tracks with continuous\nemotion labels. ConcealNet is evaluated on the reconstruction of the audio and\nthe quality of corresponding emotions predicted after that. The proposed\nConcealNet model has shown considerable improvement, for both audio\nreconstruction and the corresponding emotion prediction, in environments that\ndo not have losses with long duration, even when the losses occur frequently.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 20:43:02 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Mohamed", "Mostafa M.", ""], ["Schuller", "Bj\u00f6rn W.", ""]]}, {"id": "2005.07781", "submitter": "Forrest Huang", "authors": "Forrest Huang, Eldon Schoop, David Ha, John Canny", "title": "Scones: Towards Conversational Authoring of Sketches", "comments": "Long Paper, IUI '20: Proceedings of the 25th International Conference\n  on Intelligent User Interfaces", "journal-ref": null, "doi": "10.1145/3377325.3377485", "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iteratively refining and critiquing sketches are crucial steps to developing\neffective designs. We introduce Scones, a mixed-initiative,\nmachine-learning-driven system that enables users to iteratively author\nsketches from text instructions. Scones is a novel deep-learning-based system\nthat iteratively generates scenes of sketched objects composed with semantic\nspecifications from natural language. Scones exceeds state-of-the-art\nperformance on a text-based scene modification task, and introduces a\nmask-conditioned sketching model that can generate sketches with poses\nspecified by high-level scene information. In an exploratory user evaluation of\nScones, participants reported enjoying an iterative drawing task with Scones,\nand suggested additional features for further applications. We believe Scones\nis an early step towards automated, intelligent systems that support\nhuman-in-the-loop applications for communicating ideas through sketching in art\nand design.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 00:02:25 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Huang", "Forrest", ""], ["Schoop", "Eldon", ""], ["Ha", "David", ""], ["Canny", "John", ""]]}, {"id": "2005.07782", "submitter": "Huihui Zhang", "authors": "Huihui Zhang and Wu Huang", "title": "Unbiased Deep Reinforcement Learning: A General Training Framework for\n  Existing and Future Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years deep neural networks have been successfully applied to the\ndomains of reinforcement learning\n\\cite{bengio2009learning,krizhevsky2012imagenet,hinton2006reducing}. Deep\nreinforcement learning \\cite{mnih2015human} is reported to have the advantage\nof learning effective policies directly from high-dimensional sensory inputs\nover traditional agents. However, within the scope of the literature, there is\nno fundamental change or improvement on the existing training framework. Here\nwe propose a novel training framework that is conceptually comprehensible and\npotentially easy to be generalized to all feasible algorithms for reinforcement\nlearning. We employ Monte-carlo sampling to achieve raw data inputs, and train\nthem in batch to achieve Markov decision process sequences and synchronously\nupdate the network parameters instead of experience replay. This training\nframework proves to optimize the unbiased approximation of loss function whose\nestimation exactly matches the real probability distribution data inputs\nfollow, and thus have overwhelming advantages of sample efficiency and\nconvergence rate over existing deep reinforcement learning after evaluating it\non both discrete action spaces and continuous control problems. Besides, we\npropose several algorithms embedded with our new framework to deal with typical\ndiscrete and continuous scenarios. These algorithms prove to be far more\nefficient than their original versions under the framework of deep\nreinforcement learning, and provide examples for existing and future algorithms\nto generalize to our new framework.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 01:51:08 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Zhang", "Huihui", ""], ["Huang", "Wu", ""]]}, {"id": "2005.07783", "submitter": "Nicol\\'as Igor Tapia", "authors": "Nicol\\'as I. Tapia, Pablo A. Est\\'evez", "title": "On the Information Plane of Autoencoders", "comments": "8 pages, 9 figures. In proceedings of the 2020 International Joint\n  Conference on Neural Networks (IJCNN 2020)", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207269", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The training dynamics of hidden layers in deep learning are poorly understood\nin theory. Recently, the Information Plane (IP) was proposed to analyze them,\nwhich is based on the information-theoretic concept of mutual information (MI).\nThe Information Bottleneck (IB) theory predicts that layers maximize relevant\ninformation and compress irrelevant information. Due to the limitations in MI\nestimation from samples, there is an ongoing debate about the properties of the\nIP for the supervised learning case. In this work, we derive a theoretical\nconvergence for the IP of autoencoders. The theory predicts that ideal\nautoencoders with a large bottleneck layer size do not compress input\ninformation, whereas a small size causes compression only in the encoder\nlayers. For the experiments, we use a Gram-matrix based MI estimator recently\nproposed in the literature. We propose a new rule to adjust its parameters that\ncompensates scale and dimensionality effects. Using our proposed rule, we\nobtain experimental IPs closer to the theory. Our theoretical IP for\nautoencoders could be used as a benchmark to validate new methods to estimate\nMI in neural networks. In this way, experimental limitations could be\nrecognized and corrected, helping with the ongoing debate on the supervised\nlearning case.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 21:05:49 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 18:43:57 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Tapia", "Nicol\u00e1s I.", ""], ["Est\u00e9vez", "Pablo A.", ""]]}, {"id": "2005.07784", "submitter": "Ze Wang", "authors": "Danfeng Xie, Yiran Li, Hanlu Yang, Li Bai, Lei Zhang, Ze Wang", "title": "A Learning-from-noise Dilated Wide Activation Network for denoising\n  Arterial Spin Labeling (ASL) Perfusion Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arterial spin labeling (ASL) perfusion MRI provides a non-invasive way to\nquantify cerebral blood flow (CBF) but it still suffers from a low\nsignal-to-noise-ratio (SNR). Using deep machine learning (DL), several groups\nhave shown encouraging denoising results. Interestingly, the improvement was\nobtained when the deep neural network was trained using noise-contaminated\nsurrogate reference because of the lack of golden standard high quality ASL CBF\nimages. More strikingly, the output of these DL ASL networks (ASLDN) showed\neven higher SNR than the surrogate reference. This phenomenon indicates a\nlearning-from-noise capability of deep networks for ASL CBF image denoising,\nwhich can be further enhanced by network optimization. In this study, we\nproposed a new ASLDN to test whether similar or even better ASL CBF image\nquality can be achieved in the case of highly noisy training reference.\nDifferent experiments were performed to validate the learning-from-noise\nhypothesis. The results showed that the learning-from-noise strategy produced\nbetter output quality than ASLDN trained with relatively high SNR reference.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 21:05:56 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Xie", "Danfeng", ""], ["Li", "Yiran", ""], ["Yang", "Hanlu", ""], ["Bai", "Li", ""], ["Zhang", "Lei", ""], ["Wang", "Ze", ""]]}, {"id": "2005.07785", "submitter": "Usman Khan", "authors": "Muhammad I. Qureshi, Ran Xin, Soummya Kar, and Usman A. Khan", "title": "S-ADDOPT: Decentralized stochastic first-order optimization over\n  directed graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we study decentralized stochastic optimization to minimize a\nsum of smooth and strongly convex cost functions when the functions are\ndistributed over a directed network of nodes. In contrast to the existing work,\nwe use gradient tracking to improve certain aspects of the resulting algorithm.\nIn particular, we propose the~\\textbf{\\texttt{S-ADDOPT}} algorithm that assumes\na stochastic first-order oracle at each node and show that for a constant\nstep-size~$\\alpha$, each node converges linearly inside an error ball around\nthe optimal solution, the size of which is controlled by~$\\alpha$. For decaying\nstep-sizes~$\\mathcal{O}(1/k)$, we show that~\\textbf{\\texttt{S-ADDOPT}} reaches\nthe exact solution sublinearly at~$\\mathcal{O}(1/k)$ and its convergence is\nasymptotically network-independent. Thus the asymptotic behavior\nof~\\textbf{\\texttt{S-ADDOPT}} is comparable to the centralized stochastic\ngradient descent. Numerical experiments over both strongly convex and\nnon-convex problems illustrate the convergence behavior and the performance\ncomparison of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 21:14:22 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 04:26:55 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 19:15:28 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Qureshi", "Muhammad I.", ""], ["Xin", "Ran", ""], ["Kar", "Soummya", ""], ["Khan", "Usman A.", ""]]}, {"id": "2005.07786", "submitter": "Yerlan Idelbayev", "authors": "Yerlan Idelbayev and Miguel \\'A. Carreira-Perpi\\~n\\'an", "title": "A flexible, extensible software framework for model compression based on\n  the LC algorithm", "comments": "15 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a software framework based on the ideas of the\nLearning-Compression (LC) algorithm, that allows a user to compress a neural\nnetwork or other machine learning model using different compression schemes\nwith minimal effort. Currently, the supported compressions include pruning,\nquantization, low-rank methods (including automatically learning the layer\nranks), and combinations of those, and the user can choose different\ncompression types for different parts of a neural network.\n  The LC algorithm alternates two types of steps until convergence: a learning\n(L) step, which trains a model on a dataset (using an algorithm such as SGD);\nand a compression (C) step, which compresses the model parameters (using a\ncompression scheme such as low-rank or quantization). This decoupling of the\n\"machine learning\" aspect from the \"signal compression\" aspect means that\nchanging the model or the compression type amounts to calling the corresponding\nsubroutine in the L or C step, respectively. The library fully supports this by\ndesign, which makes it flexible and extensible. This does not come at the\nexpense of performance: the runtime needed to compress a model is comparable to\nthat of training the model in the first place; and the compressed model is\ncompetitive in terms of prediction accuracy and compression ratio with other\nalgorithms (which are often specialized for specific models or compression\nschemes). The library is written in Python and PyTorch and available in Github.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 21:14:48 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Idelbayev", "Yerlan", ""], ["Carreira-Perpi\u00f1\u00e1n", "Miguel \u00c1.", ""]]}, {"id": "2005.07787", "submitter": "Mohammad Ebrahimpour", "authors": "Mohammad K. Ebrahimpour, J. Ben Falandays, Samuel Spevack, Ming-Hsuan\n  Yang, and David C. Noelle", "title": "WW-Nets: Dual Neural Networks for Object Detection", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new deep convolutional neural network framework that uses object\nlocation knowledge implicit in network connection weights to guide selective\nattention in object detection tasks. Our approach is called What-Where Nets\n(WW-Nets), and it is inspired by the structure of human visual pathways. In the\nbrain, vision incorporates two separate streams, one in the temporal lobe and\nthe other in the parietal lobe, called the ventral stream and the dorsal\nstream, respectively. The ventral pathway from primary visual cortex is\ndominated by \"what\" information, while the dorsal pathway is dominated by\n\"where\" information. Inspired by this structure, we have proposed an object\ndetection framework involving the integration of a \"What Network\" and a \"Where\nNetwork\". The aim of the What Network is to provide selective attention to the\nrelevant parts of the input image. The Where Network uses this information to\nlocate and classify objects of interest. In this paper, we compare this\napproach to state-of-the-art algorithms on the PASCAL VOC 2007 and 2012 and\nCOCO object detection challenge datasets. Also, we compare out approach to\nhuman \"ground-truth\" attention. We report the results of an eye-tracking\nexperiment on human subjects using images from PASCAL VOC 2007, and we\ndemonstrate interesting relationships between human overt attention and\ninformation processing in our WW-Nets. Finally, we provide evidence that our\nproposed method performs favorably in comparison to other object detection\napproaches, often by a large margin. The code and the eye-tracking ground-truth\ndataset can be found at: https://github.com/mkebrahimpour.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 21:16:22 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Ebrahimpour", "Mohammad K.", ""], ["Falandays", "J. Ben", ""], ["Spevack", "Samuel", ""], ["Yang", "Ming-Hsuan", ""], ["Noelle", "David C.", ""]]}, {"id": "2005.07788", "submitter": "Saumitra Mishra", "authors": "Saumitra Mishra, Emmanouil Benetos, Bob L. Sturm, Simon Dixon", "title": "Reliable Local Explanations for Machine Listening", "comments": "8 pages plus references. Accepted at the IJCNN 2020 Special Session\n  on Explainable Computational/Artificial Intelligence. Camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One way to analyse the behaviour of machine learning models is through local\nexplanations that highlight input features that maximally influence model\npredictions. Sensitivity analysis, which involves analysing the effect of input\nperturbations on model predictions, is one of the methods to generate local\nexplanations. Meaningful input perturbations are essential for generating\nreliable explanations, but there exists limited work on what such perturbations\nare and how to perform them. This work investigates these questions in the\ncontext of machine listening models that analyse audio. Specifically, we use a\nstate-of-the-art deep singing voice detection (SVD) model to analyse whether\nexplanations from SoundLIME (a local explanation method) are sensitive to how\nthe method perturbs model inputs. The results demonstrate that SoundLIME\nexplanations are sensitive to the content in the occluded input regions. We\nfurther propose and demonstrate a novel method for quantitatively identifying\nsuitable content type(s) for reliably occluding inputs of machine listening\nmodels. The results for the SVD model suggest that the average magnitude of\ninput mel-spectrogram bins is the most suitable content type for temporal\nexplanations.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 21:17:06 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Mishra", "Saumitra", ""], ["Benetos", "Emmanouil", ""], ["Sturm", "Bob L.", ""], ["Dixon", "Simon", ""]]}, {"id": "2005.07794", "submitter": "Mostafa M. Mohamed", "authors": "Mostafa M. Mohamed, Mina A. Nessiem, and Bj\\\"orn W. Schuller", "title": "On Deep Speech Packet Loss Concealment: A Mini-Survey", "comments": "Submission for INTERSPEECH 2020. 4 pages + 1 references page. 3\n  Figures and 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Packet-loss is a common problem in data transmission, using Voice over IP.\nThe problem is an old problem, and there has been a variety of classical\napproaches that were developed to overcome this problem. However, with the rise\nof deep learning and generative models like Generative Adversarial Networks and\nAutoencoders, a new avenue has emerged for attempting to solve packet-loss\nusing deep learning, by generating replacements for lost packets. In this\nmini-survey, we review all the literature we found to date, that attempt to\nsolve the packet-loss in speech using deep learning methods. Additionally, we\nbriefly review how the problem of packet-loss in a realistic setting is\nmodelled, and how to evaluate Packet Loss Concealment techniques. Moreover, we\nreview a few modern deep learning techniques in related domains that have shown\npromising results. These techniques shed light on future potentially better\nsolutions for PLC and additional challenges that need to be considered\nsimultaneously with packet-loss.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 21:37:13 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Mohamed", "Mostafa M.", ""], ["Nessiem", "Mina A.", ""], ["Schuller", "Bj\u00f6rn W.", ""]]}, {"id": "2005.07795", "submitter": "Nicol\\'as Igor Tapia", "authors": "Nicol\\'as I. Tapia, Pablo A. Est\\'evez", "title": "RED: Deep Recurrent Neural Networks for Sleep EEG Event Detection", "comments": "8 pages, 5 figures. In proceedings of the 2020 International Joint\n  Conference on Neural Networks (IJCNN 2020)", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207719", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain electrical activity presents several short events during sleep that\ncan be observed as distinctive micro-structures in the electroencephalogram\n(EEG), such as sleep spindles and K-complexes. These events have been\nassociated with biological processes and neurological disorders, making them a\nresearch topic in sleep medicine. However, manual detection limits their study\nbecause it is time-consuming and affected by significant inter-expert\nvariability, motivating automatic approaches. We propose a deep learning\napproach based on convolutional and recurrent neural networks for sleep EEG\nevent detection called Recurrent Event Detector (RED). RED uses one of two\ninput representations: a) the time-domain EEG signal, or b) a complex\nspectrogram of the signal obtained with the Continuous Wavelet Transform (CWT).\nUnlike previous approaches, a fixed time window is avoided and temporal context\nis integrated to better emulate the visual criteria of experts. When evaluated\non the MASS dataset, our detectors outperform the state of the art in both\nsleep spindle and K-complex detection with a mean F1-score of at least 80.9%\nand 82.6%, respectively. Although the CWT-domain model obtained a similar\nperformance than its time-domain counterpart, the former allows in principle a\nmore interpretable input representation due to the use of a spectrogram. The\nproposed approach is event-agnostic and can be used directly to detect other\ntypes of sleep events.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 21:48:26 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 18:42:32 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Tapia", "Nicol\u00e1s I.", ""], ["Est\u00e9vez", "Pablo A.", ""]]}, {"id": "2005.07796", "submitter": "Sohini Roychowdhury", "authors": "Francesco Piccoli, Rajarathnam Balakrishnan, Maria Jesus Perez,\n  Moraldeepsingh Sachdeo, Carlos Nunez, Matthew Tang, Kajsa Andreasson, Kalle\n  Bjurek, Ria Dass Raj, Ebba Davidsson, Colin Eriksson, Victor Hagman, Jonas\n  Sjoberg, Ying Li, L. Srikar Muppirisetty, Sohini Roychowdhury", "title": "FuSSI-Net: Fusion of Spatio-temporal Skeletons for Intention Prediction\n  Network", "comments": "5 pages, 6 figures, 5 tables, IEEE Asilomar SSC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pedestrian intention recognition is very important to develop robust and safe\nautonomous driving (AD) and advanced driver assistance systems (ADAS)\nfunctionalities for urban driving. In this work, we develop an end-to-end\npedestrian intention framework that performs well on day- and night- time\nscenarios. Our framework relies on objection detection bounding boxes combined\nwith skeletal features of human pose. We study early, late, and combined (early\nand late) fusion mechanisms to exploit the skeletal features and reduce false\npositives as well to improve the intention prediction performance. The early\nfusion mechanism results in AP of 0.89 and precision/recall of 0.79/0.89 for\npedestrian intention classification. Furthermore, we propose three new metrics\nto properly evaluate the pedestrian intention systems. Under these new\nevaluation metrics for the intention prediction, the proposed end-to-end\nnetwork offers accurate pedestrian intention up to half a second ahead of the\nactual risky maneuver.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 21:52:42 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Piccoli", "Francesco", ""], ["Balakrishnan", "Rajarathnam", ""], ["Perez", "Maria Jesus", ""], ["Sachdeo", "Moraldeepsingh", ""], ["Nunez", "Carlos", ""], ["Tang", "Matthew", ""], ["Andreasson", "Kajsa", ""], ["Bjurek", "Kalle", ""], ["Raj", "Ria Dass", ""], ["Davidsson", "Ebba", ""], ["Eriksson", "Colin", ""], ["Hagman", "Victor", ""], ["Sjoberg", "Jonas", ""], ["Li", "Ying", ""], ["Muppirisetty", "L. Srikar", ""], ["Roychowdhury", "Sohini", ""]]}, {"id": "2005.07799", "submitter": "Dan Lim", "authors": "Dan Lim, Won Jang, Gyeonghwan O, Heayoung Park, Bongwan Kim, Jaesam\n  Yoon", "title": "JDI-T: Jointly trained Duration Informed Transformer for Text-To-Speech\n  without Explicit Alignment", "comments": "Accepted for publication in Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Jointly trained Duration Informed Transformer (JDI-T), a\nfeed-forward Transformer with a duration predictor jointly trained without\nexplicit alignments in order to generate an acoustic feature sequence from an\ninput text. In this work, inspired by the recent success of the duration\ninformed networks such as FastSpeech and DurIAN, we further simplify its\nsequential, two-stage training pipeline to a single-stage training.\nSpecifically, we extract the phoneme duration from the autoregressive\nTransformer on the fly during the joint training instead of pretraining the\nautoregressive model and using it as a phoneme duration extractor. To our best\nknowledge, it is the first implementation to jointly train the feed-forward\nTransformer without relying on a pre-trained phoneme duration extractor in a\nsingle training pipeline. We evaluate the effectiveness of the proposed model\non the publicly available Korean Single speaker Speech (KSS) dataset compared\nto the baseline text-to-speech (TTS) models trained by ESPnet-TTS.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 22:06:13 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 01:42:11 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 02:48:58 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Lim", "Dan", ""], ["Jang", "Won", ""], ["O", "Gyeonghwan", ""], ["Park", "Heayoung", ""], ["Kim", "Bongwan", ""], ["Yoon", "Jaesam", ""]]}, {"id": "2005.07804", "submitter": "Jwala Dhamala", "authors": "Jwala Dhamala, Sandesh Ghimire, John L. Sapp, B. Milan Hor\\'acek,\n  Linwei Wang", "title": "High-dimensional Bayesian Optimization of Personalized Cardiac Model\n  Parameters via an Embedded Generative Model", "comments": "MICCAI 2018", "journal-ref": null, "doi": "10.1007/978-3-030-00934-2_56", "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of patient-specific tissue properties in the form of model\nparameters is important for personalized physiological models. However, these\ntissue properties are spatially varying across the underlying anatomical model,\npresenting a significance challenge of high-dimensional (HD) optimization at\nthe presence of limited measurement data. A common solution to reduce the\ndimension of the parameter space is to explicitly partition the anatomical\nmesh, either into a fixed small number of segments or a multi-scale hierarchy.\nThis anatomy-based reduction of parameter space presents a fundamental\nbottleneck to parameter estimation, resulting in solutions that are either too\nlow in resolution to reflect tissue heterogeneity, or too high in dimension to\nbe reliably estimated within feasible computation. In this paper, we present a\nnovel concept that embeds a generative variational auto-encoder (VAE) into the\nobjective function of Bayesian optimization, providing an implicit\nlow-dimensional (LD) search space that represents the generative code of the HD\nspatially-varying tissue properties. In addition, the VAE-encoded knowledge\nabout the generative code is further used to guide the exploration of the\nsearch space. The presented method is applied to estimating tissue excitability\nin a cardiac electrophysiological model. Synthetic and real-data experiments\ndemonstrate its ability to improve the accuracy of parameter estimation with\nmore than 10x gain in efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 22:14:16 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Dhamala", "Jwala", ""], ["Ghimire", "Sandesh", ""], ["Sapp", "John L.", ""], ["Hor\u00e1cek", "B. Milan", ""], ["Wang", "Linwei", ""]]}, {"id": "2005.07810", "submitter": "Mohammad Asif Khan", "authors": "Mohammad Asif Khan, Fabien Cardinaux, Stefan Uhlich, Marc Ferras, Asja\n  Fischer", "title": "Unsupervised Cross-Domain Speech-to-Speech Conversion with\n  Time-Frequency Consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years generative adversarial network (GAN) based models have been\nsuccessfully applied for unsupervised speech-to-speech conversion.The rich\ncompact harmonic view of the magnitude spectrogram is considered a suitable\nchoice for training these models with audio data. To reconstruct the speech\nsignal first a magnitude spectrogram is generated by the neural network, which\nis then utilized by methods like the Griffin-Lim algorithm to reconstruct a\nphase spectrogram. This procedure bears the problem that the generated\nmagnitude spectrogram may not be consistent, which is required for finding a\nphase such that the full spectrogram has a natural-sounding speech waveform. In\nthis work, we approach this problem by proposing a condition encouraging\nspectrogram consistency during the adversarial training procedure. We\ndemonstrate our approach on the task of translating the voice of a male speaker\nto that of a female speaker, and vice versa. Our experimental results on the\nLibrispeech corpus show that the model trained with the TF consistency provides\na perceptually better quality of speech-to-speech conversion.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 22:27:07 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 01:16:49 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Khan", "Mohammad Asif", ""], ["Cardinaux", "Fabien", ""], ["Uhlich", "Stefan", ""], ["Ferras", "Marc", ""], ["Fischer", "Asja", ""]]}, {"id": "2005.07820", "submitter": "Saja Khaled Tawalbeh", "authors": "Saja Khaled Tawalbeh, Mahmoud Hammad and Mohammad AL-Smadi", "title": "KEIS@JUST at SemEval-2020 Task 12: Identifying Multilingual Offensive\n  Tweets Using Weighted Ensemble and Fine-Tuned BERT", "comments": "8 pages without references, 4 figures, SemEval 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This research presents our team KEIS@JUST participation at SemEval-2020 Task\n12 which represents shared task on multilingual offensive language. We\nparticipated in all the provided languages for all subtasks except sub-task-A\nfor the English language. Two main approaches have been developed the first is\nperformed to tackle both languages Arabic and English, a weighted ensemble\nconsists of Bi-GRU and CNN followed by Gaussian noise and global pooling layer\nmultiplied by weights to improve the overall performance. The second is\nperformed for other languages, a transfer learning from BERT beside the\nrecurrent neural networks such as Bi-LSTM and Bi-GRU followed by a global\naverage pooling layer. Word embedding and contextual embedding have been used\nas features, moreover, data augmentation has been used only for the Arabic\nlanguage.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 23:11:03 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Tawalbeh", "Saja Khaled", ""], ["Hammad", "Mahmoud", ""], ["AL-Smadi", "Mohammad", ""]]}, {"id": "2005.07839", "submitter": "Le Thanh Nguyen-Meidine", "authors": "Le Thanh Nguyen-Meidine, Eric Granger, Madhu Kiran, Jose Dolz,\n  Louis-Antoine Blais-Morin", "title": "Joint Progressive Knowledge Distillation and Unsupervised Domain\n  Adaptation", "comments": "Accepted to WCCI/IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, the divergence in distributions of design and operational data,\nand large computational complexity are limiting factors in the adoption of CNNs\nin real-world applications. For instance, person re-identification systems\ntypically rely on a distributed set of cameras, where each camera has different\ncapture conditions. This can translate to a considerable shift between source\n(e.g. lab setting) and target (e.g. operational camera) domains. Given the cost\nof annotating image data captured for fine-tuning in each target domain,\nunsupervised domain adaptation (UDA) has become a popular approach to adapt\nCNNs. Moreover, state-of-the-art deep learning models that provide a high level\nof accuracy often rely on architectures that are too complex for real-time\napplications. Although several compression and UDA approaches have recently\nbeen proposed to overcome these limitations, they do not allow optimizing a CNN\nto simultaneously address both. In this paper, we propose an unexplored\ndirection -- the joint optimization of CNNs to provide a compressed model that\nis adapted to perform well for a given target domain. In particular, the\nproposed approach performs unsupervised knowledge distillation (KD) from a\ncomplex teacher model to a compact student model, by leveraging both source and\ntarget data. It also improves upon existing UDA techniques by progressively\nteaching the student about domain-invariant features, instead of directly\nadapting a compact model on target domain data. Our method is compared against\nstate-of-the-art compression and UDA techniques, using two popular\nclassification datasets for UDA -- Office31 and ImageClef-DA. In both datasets,\nresults indicate that our method can achieve the highest level of accuracy\nwhile requiring a comparable or lower time complexity.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 01:07:03 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Nguyen-Meidine", "Le Thanh", ""], ["Granger", "Eric", ""], ["Kiran", "Madhu", ""], ["Dolz", "Jose", ""], ["Blais-Morin", "Louis-Antoine", ""]]}, {"id": "2005.07845", "submitter": "Zitao Liu", "authors": "Gale Yan Huang, Jiahao Chen, Haochen Liu, Weiping Fu, Wenbiao Ding,\n  Jiliang Tang, Songfan Yang, Guoliang Li, Zitao Liu", "title": "Neural Multi-Task Learning for Teacher Question Detection in Online\n  Classrooms", "comments": "The 21th International Conference on Artificial Intelligence in\n  Education(AIED), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asking questions is one of the most crucial pedagogical techniques used by\nteachers in class. It not only offers open-ended discussions between teachers\nand students to exchange ideas but also provokes deeper student thought and\ncritical analysis. Providing teachers with such pedagogical feedback will\nremarkably help teachers improve their overall teaching quality over time in\nclassrooms. Therefore, in this work, we build an end-to-end neural framework\nthat automatically detects questions from teachers' audio recordings. Compared\nwith traditional methods, our approach not only avoids cumbersome feature\nengineering, but also adapts to the task of multi-class question detection in\nreal education scenarios. By incorporating multi-task learning techniques, we\nare able to strengthen the understanding of semantic relations among different\ntypes of questions. We conducted extensive experiments on the question\ndetection tasks in a real-world online classroom dataset and the results\ndemonstrate the superiority of our model in terms of various evaluation\nmetrics.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 02:17:04 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Huang", "Gale Yan", ""], ["Chen", "Jiahao", ""], ["Liu", "Haochen", ""], ["Fu", "Weiping", ""], ["Ding", "Wenbiao", ""], ["Tang", "Jiliang", ""], ["Yang", "Songfan", ""], ["Li", "Guoliang", ""], ["Liu", "Zitao", ""]]}, {"id": "2005.07852", "submitter": "Reda Chhaibi", "authors": "Tariq Daouda, Reda Chhaibi, Prudencio Tossou, Alexandra-Chlo\\'e\n  Villani", "title": "Geodesics in fibered latent spaces: A geometric approach to learning\n  correspondences between conditions", "comments": "36 pages, many figures. v1: Preliminary version. v2: Minor ref fix.\n  v3: Submitted version with enhanced presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a geometric framework and a novel network architecture\nfor creating correspondences between samples of different conditions. Under\nthis formalism, the latent space is a fiber bundle stratified into a base space\nencoding conditions, and a fiber space encoding the variations within\nconditions. Furthermore, this latent space is endowed with a natural pull-back\nmetric. The correspondences between conditions are obtained by minimizing an\nenergy functional, resulting in diffeomorphism flows between fibers.\n  We illustrate this approach using MNIST and Olivetti and benchmark its\nperformances on the task of batch correction, which is the problem of\nintegrating multiple biological datasets together.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 03:14:52 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 22:27:21 GMT"}, {"version": "v3", "created": "Sun, 27 Dec 2020 11:46:48 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Daouda", "Tariq", ""], ["Chhaibi", "Reda", ""], ["Tossou", "Prudencio", ""], ["Villani", "Alexandra-Chlo\u00e9", ""]]}, {"id": "2005.07855", "submitter": "Zheng Chen", "authors": "Zheng Chen, Xinli Yu, Yuan Ling, Xiaohua Hu", "title": "Neural Stochastic Block Model & Scalable Community-Based Graph Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a novel scalable community-based neural framework for\ngraph learning. The framework learns the graph topology through the task of\ncommunity detection and link prediction by optimizing with our proposed joint\nSBM loss function, which results from a non-trivial adaptation of the\nlikelihood function of the classic Stochastic Block Model (SBM). Compared with\nSBM, our framework is flexible, naturally allows soft labels and digestion of\ncomplex node attributes. The main goal is efficient valuation of complex graph\ndata, therefore our design carefully aims at accommodating large data, and\nensures there is a single forward pass for efficient evaluation. For large\ngraph, it remains an open problem of how to efficiently leverage its underlying\nstructure for various graph learning tasks. Previously it can be heavy work.\nWith our community-based framework, this becomes less difficult and allows the\ntask models to basically plug-in-and-play and perform joint training. We\ncurrently look into two particular applications, the graph alignment and the\nanomalous correlation detection, and discuss how to make use of our framework\nto tackle both problems. Extensive experiments are conducted to demonstrate the\neffectiveness of our approach. We also contributed tweaks of classic techniques\nwhich we find helpful for performance and scalability. For example, 1) the\nGAT+, an improved design of GAT (Graph Attention Network), the scaled-cosine\nsimilarity, and a unified implementation of the convolution/attention based and\nthe random-walk based neural graph models.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 03:28:50 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Chen", "Zheng", ""], ["Yu", "Xinli", ""], ["Ling", "Yuan", ""], ["Hu", "Xiaohua", ""]]}, {"id": "2005.07866", "submitter": "Deepesh Data", "authors": "Deepesh Data and Suhas Diggavi", "title": "Byzantine-Resilient SGD in High Dimensions on Heterogeneous Data", "comments": "57 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributed stochastic gradient descent (SGD) in the master-worker\narchitecture under Byzantine attacks. We consider the heterogeneous data model,\nwhere different workers may have different local datasets, and we do not make\nany probabilistic assumptions on data generation. At the core of our algorithm,\nwe use the polynomial-time outlier-filtering procedure for robust mean\nestimation proposed by Steinhardt et al. (ITCS 2018) to filter-out corrupt\ngradients. In order to be able to apply their filtering procedure in our {\\em\nheterogeneous} data setting where workers compute {\\em stochastic} gradients,\nwe derive a new matrix concentration result, which may be of independent\ninterest.\n  We provide convergence analyses for smooth strongly-convex and non-convex\nobjectives. We derive our results under the bounded variance assumption on\nlocal stochastic gradients and a {\\em deterministic} condition on datasets,\nnamely, gradient dissimilarity; and for both these quantities, we provide\nconcrete bounds in the statistical heterogeneous data model. We give a\ntrade-off between the mini-batch size for stochastic gradients and the\napproximation error. Our algorithm can tolerate up to $\\frac{1}{4}$ fraction\nByzantine workers. It can find approximate optimal parameters in the\nstrongly-convex setting exponentially fast and reach to an approximate\nstationary point in the non-convex setting with a linear speed, thus, matching\nthe convergence rates of vanilla SGD in the Byzantine-free setting.\n  We also propose and analyze a Byzantine-resilient SGD algorithm with gradient\ncompression, where workers send $k$ random coordinates of their gradients.\nUnder mild conditions, we show a $\\frac{d}{k}$-factor saving in communication\nbits as well as decoding complexity over our compression-free algorithm without\naffecting its convergence rate (order-wise) and the approximation error.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 04:15:27 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Data", "Deepesh", ""], ["Diggavi", "Suhas", ""]]}, {"id": "2005.07869", "submitter": "Yufan Zhou", "authors": "Yufan Zhou, Jiayi Xian, Changyou Chen, Jinhui Xu", "title": "Graph Neural Networks with Composite Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning on graph structured data has drawn increasing interest in recent\nyears. Frameworks like Graph Convolutional Networks (GCNs) have demonstrated\ntheir ability to capture structural information and obtain good performance in\nvarious tasks. In these frameworks, node aggregation schemes are typically used\nto capture structural information: a node's feature vector is recursively\ncomputed by aggregating features of its neighboring nodes. However, most of\naggregation schemes treat all connections in a graph equally, ignoring node\nfeature similarities. In this paper, we re-interpret node aggregation from the\nperspective of kernel weighting, and present a framework to consider feature\nsimilarity in an aggregation scheme. Specifically, we show that normalized\nadjacency matrix is equivalent to a neighbor-based kernel matrix in a Krein\nSpace. We then propose feature aggregation as the composition of the original\nneighbor-based kernel and a learnable kernel to encode feature similarities in\na feature space. We further show how the proposed method can be extended to\nGraph Attention Network (GAT). Experimental results demonstrate better\nperformance of our proposed framework in several real-world applications.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 04:44:29 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Zhou", "Yufan", ""], ["Xian", "Jiayi", ""], ["Chen", "Changyou", ""], ["Xu", "Jinhui", ""]]}, {"id": "2005.07877", "submitter": "Zhongxia Yan", "authors": "Zhongxia Yan, Hanrui Wang, Demi Guo, Song Han", "title": "MicroNet for Efficient Language Modeling", "comments": "Accepted by PMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is important to design compact language models for efficient deployment.\nWe improve upon recent advances in both the language modeling domain and the\nmodel-compression domain to construct parameter and computation efficient\nlanguage models. We use an efficient transformer-based architecture with\nadaptive embedding and softmax, differentiable non-parametric cache, Hebbian\nsoftmax, knowledge distillation, network pruning, and low-bit quantization. In\nthis paper, we provide the winning solution to the NeurIPS 2019 MicroNet\nChallenge in the language modeling track. Compared to the baseline language\nmodel provided by the MicroNet Challenge, our model is 90 times more\nparameter-efficient and 36 times more computation-efficient while achieving the\nrequired test perplexity of 35 on the Wikitext-103 dataset. We hope that this\nwork will aid future research into efficient language models, and we have\nreleased our full source code at\nhttps://github.com/mit-han-lab/neurips-micronet.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 05:42:57 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Yan", "Zhongxia", ""], ["Wang", "Hanrui", ""], ["Guo", "Demi", ""], ["Han", "Song", ""]]}, {"id": "2005.07882", "submitter": "Chandan Singh", "authors": "Nick Altieri, Rebecca L. Barter, James Duncan, Raaz Dwivedi, Karl\n  Kumbier, Xiao Li, Robert Netzorg, Briton Park, Chandan Singh, Yan Shuo Tan,\n  Tiffany Tang, Yu Wang, Chao Zhang, Bin Yu", "title": "Curating a COVID-19 data repository and forecasting county-level death\n  counts in the United States", "comments": "Authors ordered alphabetically. All authors contributed significantly\n  to this work. All collected data, modeling code, forecasts, and\n  visualizations are updated daily and available at\n  \\url{https://github.com/Yu-Group/covid19-severity-prediction}", "journal-ref": "Published in Harvard Data Science Review, 2020", "doi": "10.1162/99608f92.1d4e0dae", "report-no": null, "categories": "stat.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the COVID-19 outbreak evolves, accurate forecasting continues to play an\nextremely important role in informing policy decisions. In this paper, we\npresent our continuous curation of a large data repository containing COVID-19\ninformation from a range of sources. We use this data to develop predictions\nand corresponding prediction intervals for the short-term trajectory of\nCOVID-19 cumulative death counts at the county-level in the United States up to\ntwo weeks ahead. Using data from January 22 to June 20, 2020, we develop and\ncombine multiple forecasts using ensembling techniques, resulting in an\nensemble we refer to as Combined Linear and Exponential Predictors (CLEP). Our\nindividual predictors include county-specific exponential and linear\npredictors, a shared exponential predictor that pools data together across\ncounties, an expanded shared exponential predictor that uses data from\nneighboring counties, and a demographics-based shared exponential predictor. We\nuse prediction errors from the past five days to assess the uncertainty of our\ndeath predictions, resulting in generally-applicable prediction intervals,\nMaximum (absolute) Error Prediction Intervals (MEPI). MEPI achieves a coverage\nrate of more than 94% when averaged across counties for predicting cumulative\nrecorded death counts two weeks in the future. Our forecasts are currently\nbeing used by the non-profit organization, Response4Life, to determine the\nmedical supply need for individual hospitals and have directly contributed to\nthe distribution of medical supplies across the country. We hope that our\nforecasts and data repository at https://covidseverity.com can help guide\nnecessary county-specific decision-making and help counties prepare for their\ncontinued fight against COVID-19.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 06:00:28 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2020 20:54:26 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Altieri", "Nick", ""], ["Barter", "Rebecca L.", ""], ["Duncan", "James", ""], ["Dwivedi", "Raaz", ""], ["Kumbier", "Karl", ""], ["Li", "Xiao", ""], ["Netzorg", "Robert", ""], ["Park", "Briton", ""], ["Singh", "Chandan", ""], ["Tan", "Yan Shuo", ""], ["Tang", "Tiffany", ""], ["Wang", "Yu", ""], ["Zhang", "Chao", ""], ["Yu", "Bin", ""]]}, {"id": "2005.07890", "submitter": "Zonghao Huang", "authors": "Zonghao Huang and Yanmin Gong", "title": "Differentially Private ADMM for Convex Distributed Learning: Improved\n  Accuracy via Multi-Step Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alternating Direction Method of Multipliers (ADMM) is a popular algorithm for\ndistributed learning, where a network of nodes collaboratively solve a\nregularized empirical risk minimization by iterative local computation\nassociated with distributed data and iterate exchanges. When the training data\nis sensitive, the exchanged iterates will cause serious privacy concern. In\nthis paper, we aim to propose a new differentially private distributed ADMM\nalgorithm with improved accuracy for a wide range of convex learning problems.\nIn our proposed algorithm, we adopt the approximation of the objective function\nin the local computation to introduce calibrated noise into iterate updates\nrobustly, and allow multiple primal variable updates per node in each\niteration. Our theoretical results demonstrate that our approach can obtain\nhigher utility by such multiple approximate updates, and achieve the error\nbounds asymptotic to the state-of-art ones for differentially private empirical\nrisk minimization.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 07:17:31 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Huang", "Zonghao", ""], ["Gong", "Yanmin", ""]]}, {"id": "2005.07893", "submitter": "Hyokun Yun", "authors": "Hyokun Yun, Michael Froh, Roshan Makhijani, Brian Luc, Alex Smola,\n  Trishul Chilimbi", "title": "Tiering as a Stochastic Submodular Optimization Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tiering is an essential technique for building large-scale information\nretrieval systems. While the selection of documents for high priority tiers\ncritically impacts the efficiency of tiering, past work focuses on optimizing\nit with respect to a static set of queries in the history, and generalizes\npoorly to the future traffic. Instead, we formulate the optimal tiering as a\nstochastic optimization problem, and follow the methodology of regularized\nempirical risk minimization to maximize the \\emph{generalization performance}\nof the system. We also show that the optimization problem can be cast as a\nstochastic submodular optimization problem with a submodular knapsack\nconstraint, and we develop efficient optimization algorithms by leveraging this\nconnection.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 07:39:29 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Yun", "Hyokun", ""], ["Froh", "Michael", ""], ["Makhijani", "Roshan", ""], ["Luc", "Brian", ""], ["Smola", "Alex", ""], ["Chilimbi", "Trishul", ""]]}, {"id": "2005.07916", "submitter": "Dongxiao Zhang", "authors": "Hao Xu, Dongxiao Zhang, and Junsheng Zeng", "title": "Deep-learning of Parametric Partial Differential Equations from Sparse\n  and Noisy Data", "comments": "30 pages, 6 figures, and 7 tables", "journal-ref": "Phys. Fluids, 33, 037132, 10.1063/5.0042868, 2021", "doi": "10.1063/5.0042868", "report-no": null, "categories": "physics.comp-ph cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven methods have recently made great progress in the discovery of\npartial differential equations (PDEs) from spatial-temporal data. However,\nseveral challenges remain to be solved, including sparse noisy data, incomplete\ncandidate library, and spatially- or temporally-varying coefficients. In this\nwork, a new framework, which combines neural network, genetic algorithm and\nadaptive methods, is put forward to address all of these challenges\nsimultaneously. In the framework, a trained neural network is utilized to\ncalculate derivatives and generate a large amount of meta-data, which solves\nthe problem of sparse noisy data. Next, genetic algorithm is utilized to\ndiscover the form of PDEs and corresponding coefficients with an incomplete\ncandidate library. Finally, a two-step adaptive method is introduced to\ndiscover parametric PDEs with spatially- or temporally-varying coefficients. In\nthis method, the structure of a parametric PDE is first discovered, and then\nthe general form of varying coefficients is identified. The proposed algorithm\nis tested on the Burgers equation, the convection-diffusion equation, the wave\nequation, and the KdV equation. The results demonstrate that this method is\nrobust to sparse and noisy data, and is able to discover parametric PDEs with\nan incomplete candidate library.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 09:09:57 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Xu", "Hao", ""], ["Zhang", "Dongxiao", ""], ["Zeng", "Junsheng", ""]]}, {"id": "2005.07923", "submitter": "Junfeng Jiang", "authors": "Chao Xiong, Che Liu, Zijun Xu, Junfeng Jiang, Jieping Ye", "title": "Sequential Sentence Matching Network for Multi-turn Response Selection\n  in Retrieval-based Chatbots", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, open domain multi-turn chatbots have attracted much interest from\nlots of researchers in both academia and industry. The dominant retrieval-based\nmethods use context-response matching mechanisms for multi-turn response\nselection. Specifically, the state-of-the-art methods perform the\ncontext-response matching by word or segment similarity. However, these models\nlack a full exploitation of the sentence-level semantic information, and make\nsimple mistakes that humans can easily avoid. In this work, we propose a\nmatching network, called sequential sentence matching network (S2M), to use the\nsentence-level semantic information to address the problem. Firstly and most\nimportantly, we find that by using the sentence-level semantic information, the\nnetwork successfully addresses the problem and gets a significant improvement\non matching, resulting in a state-of-the-art performance. Furthermore, we\nintegrate the sentence matching we introduced here and the usual word\nsimilarity matching reported in the current literature, to match at different\nsemantic levels. Experiments on three public data sets show that such\nintegration further improves the model performance.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 09:47:19 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Xiong", "Chao", ""], ["Liu", "Che", ""], ["Xu", "Zijun", ""], ["Jiang", "Junfeng", ""], ["Ye", "Jieping", ""]]}, {"id": "2005.07927", "submitter": "Mauricio Barahona", "authors": "Stamatina Lamprinakou, Emma McCoy, Mauricio Barahona, Axel Gandy, Seth\n  Flaxman, Sarah Filippi", "title": "BART-based inference for Poisson processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effectiveness of Bayesian Additive Regression Trees (BART) has been\ndemonstrated in a variety of contexts including non parametric regression and\nclassification. Here we introduce a BART scheme for estimating the intensity of\ninhomogeneous Poisson Processes. Poisson intensity estimation is a vital task\nin various applications including medical imaging, astrophysics and network\ntraffic analysis. Our approach enables full posterior inference of the\nintensity in a nonparametric regression setting. We demonstrate the performance\nof our scheme through simulation studies on synthetic and real datasets in one\nand two dimensions, and compare our approach to alternative approaches.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 10:01:54 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Lamprinakou", "Stamatina", ""], ["McCoy", "Emma", ""], ["Barahona", "Mauricio", ""], ["Gandy", "Axel", ""], ["Flaxman", "Seth", ""], ["Filippi", "Sarah", ""]]}, {"id": "2005.07939", "submitter": "Hanna Meyer", "authors": "Hanna Meyer and Edzer Pebesma", "title": "Predicting into unknown space? Estimating the area of applicability of\n  spatial prediction models", "comments": "16 pages, 10 figures, to be submitted to Methods in Ecology and\n  Evolution", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive modelling using machine learning has become very popular for\nspatial mapping of the environment. Models are often applied to make\npredictions far beyond sampling locations where new geographic locations might\nconsiderably differ from the training data in their environmental properties.\nHowever, areas in the predictor space without support of training data are\nproblematic. Since the model has no knowledge about these environments,\npredictions have to be considered uncertain.\n  Estimating the area to which a prediction model can be reliably applied is\nrequired. Here, we suggest a methodology that delineates the \"area of\napplicability\" (AOA) that we define as the area, for which the cross-validation\nerror of the model applies. We first propose a \"dissimilarity index\" (DI) that\nis based on the minimum distance to the training data in the predictor space,\nwith predictors being weighted by their respective importance in the model. The\nAOA is then derived by applying a threshold based on the DI of the training\ndata where the DI is calculated with respect to the cross-validation strategy\nused for model training. We test for the ideal threshold by using simulated\ndata and compare the prediction error within the AOA with the cross-validation\nerror of the model. We illustrate the approach using a simulated case study.\n  Our simulation study suggests a threshold on DI to define the AOA at the .95\nquantile of the DI in the training data. Using this threshold, the prediction\nerror within the AOA is comparable to the cross-validation RMSE of the model,\nwhile the cross-validation error does not apply outside the AOA. This applies\nto models being trained with randomly distributed training data, as well as\nwhen training data are clustered in space and where spatial cross-validation is\napplied.\n  We suggest to report the AOA alongside predictions, complementary to\nvalidation measures.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 10:31:55 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Meyer", "Hanna", ""], ["Pebesma", "Edzer", ""]]}, {"id": "2005.07946", "submitter": "Peter Rousseeuw", "authors": "Jakob Raymaekers and Peter J. Rousseeuw", "title": "Transforming variables to central normality", "comments": null, "journal-ref": null, "doi": "10.1007/s10994-021-05960-5", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real data sets contain numerical features (variables) whose distribution\nis far from normal (gaussian). Instead, their distribution is often skewed. In\norder to handle such data it is customary to preprocess the variables to make\nthem more normal. The Box-Cox and Yeo-Johnson transformations are well-known\ntools for this. However, the standard maximum likelihood estimator of their\ntransformation parameter is highly sensitive to outliers, and will often try to\nmove outliers inward at the expense of the normality of the central part of the\ndata. We propose a modification of these transformations as well as an\nestimator of the transformation parameter that is robust to outliers, so the\ntransformed data can be approximately normal in the center and a few outliers\nmay deviate from it. It compares favorably to existing techniques in an\nextensive simulation study and on real data.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 10:50:42 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 17:41:33 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Raymaekers", "Jakob", ""], ["Rousseeuw", "Peter J.", ""]]}, {"id": "2005.07952", "submitter": "Oguzhan Gencoglu", "authors": "Oguzhan Gencoglu and Mathias Gruber", "title": "Causal Modeling of Twitter Activity During COVID-19", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": "10.3390/computation8040085", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the characteristics of public attention and sentiment is an\nessential prerequisite for appropriate crisis management during adverse health\nevents. This is even more crucial during a pandemic such as COVID-19, as\nprimary responsibility of risk management is not centralized to a single\ninstitution, but distributed across society. While numerous studies utilize\nTwitter data in descriptive or predictive context during COVID-19 pandemic,\ncausal modeling of public attention has not been investigated. In this study,\nwe propose a causal inference approach to discover and quantify causal\nrelationships between pandemic characteristics (e.g. number of infections and\ndeaths) and Twitter activity as well as public sentiment. Our results show that\nthe proposed method can successfully capture the epidemiological domain\nknowledge and identify variables that affect public attention and sentiment. We\nbelieve our work contributes to the field of infodemiology by distinguishing\nevents that correlate with public attention from events that cause public\nattention.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 11:07:19 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 10:55:11 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2020 20:05:12 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Gencoglu", "Oguzhan", ""], ["Gruber", "Mathias", ""]]}, {"id": "2005.07959", "submitter": "Benedek Rozemberczki", "authors": "Benedek Rozemberczki and Rik Sarkar", "title": "Characteristic Functions on Graphs: Birds of a Feather, from Statistical\n  Descriptors to Parametric Models", "comments": "Source code is available at:\n  https://github.com/benedekrozemberczki/FEATHER", "journal-ref": "CIKM 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.DM cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a flexible notion of characteristic functions\ndefined on graph vertices to describe the distribution of vertex features at\nmultiple scales. We introduce FEATHER, a computationally efficient algorithm to\ncalculate a specific variant of these characteristic functions where the\nprobability weights of the characteristic function are defined as the\ntransition probabilities of random walks. We argue that features extracted by\nthis procedure are useful for node level machine learning tasks. We discuss the\npooling of these node representations, resulting in compact descriptors of\ngraphs that can serve as features for graph classification algorithms. We\nanalytically prove that FEATHER describes isomorphic graphs with the same\nrepresentation and exhibits robustness to data corruption. Using the node\nfeature characteristic functions we define parametric models where evaluation\npoints of the functions are learned parameters of supervised classifiers.\nExperiments on real world large datasets show that our proposed algorithm\ncreates high quality representations, performs transfer learning efficiently,\nexhibits robustness to hyperparameter changes, and scales linearly with the\ninput size.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 11:47:05 GMT"}, {"version": "v2", "created": "Sun, 16 Aug 2020 16:21:09 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Rozemberczki", "Benedek", ""], ["Sarkar", "Rik", ""]]}, {"id": "2005.07960", "submitter": "George Vouros", "authors": "Alevizos Bastas, Theocharis Kravaris and George A. Vouros", "title": "Data Driven Aircraft Trajectory Prediction with Deep Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The current Air Traffic Management (ATM) system worldwide has reached its\nlimits in terms of predictability, efficiency and cost effectiveness. Different\ninitiatives worldwide propose trajectory-oriented transformations that require\nhigh fidelity aircraft trajectory planning and prediction capabilities,\nsupporting the trajectory life cycle at all stages efficiently. Recently\nproposed data-driven trajectory prediction approaches provide promising\nresults. In this paper we approach the data-driven trajectory prediction\nproblem as an imitation learning task, where we aim to imitate experts\n\"shaping\" the trajectory. Towards this goal we present a comprehensive\nframework comprising the Generative Adversarial Imitation Learning state of the\nart method, in a pipeline with trajectory clustering and classification\nmethods. This approach, compared to other approaches, can provide accurate\npredictions for the whole trajectory (i.e. with a prediction horizon until\nreaching the destination) both at the pre-tactical (i.e. starting at the\ndeparture airport at a specific time instant) and at the tactical (i.e. from\nany state while flying) stages, compared to state of the art approaches.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 11:53:19 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Bastas", "Alevizos", ""], ["Kravaris", "Theocharis", ""], ["Vouros", "George A.", ""]]}, {"id": "2005.07972", "submitter": "Matteo Fontana", "authors": "Gianluca Zeni and Matteo Fontana and Simone Vantini", "title": "Conformal Prediction: a Unified Review of Theory and New Challenges", "comments": "arXiv admin note: text overlap with arXiv:0706.3188,\n  arXiv:1604.04173, arXiv:1709.06233, arXiv:1203.5422 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we provide a review of basic ideas and novel developments about\nConformal Prediction -- an innovative distribution-free, non-parametric\nforecasting method, based on minimal assumptions -- that is able to yield in a\nvery straightforward way predictions sets that are valid in a statistical sense\nalso in in the finite sample case. The in-depth discussion provided in the\npaper covers the theoretical underpinnings of Conformal Prediction, and then\nproceeds to list the more advanced developments and adaptations of the original\nidea.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 12:38:19 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Zeni", "Gianluca", ""], ["Fontana", "Matteo", ""], ["Vantini", "Simone", ""]]}, {"id": "2005.07995", "submitter": "Cesar H Comin Prof.", "authors": "Eric K. Tokuda, Cesar H. Comin and Luciano da F. Costa", "title": "Revisiting Agglomerative Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important issue in clustering concerns the avoidance of false positives\nwhile searching for clusters. This work addressed this problem considering\nagglomerative methods, namely single, average, median, complete, centroid and\nWard's approaches applied to unimodal and bimodal datasets obeying uniform,\ngaussian, exponential and power-law distributions. A model of clusters was also\nadopted, involving a higher density nucleus surrounded by a transition,\nfollowed by outliers. This paved the way to defining an objective means for\nidentifying the clusters from dendrograms. The adopted model also allowed the\nrelevance of the clusters to be quantified in terms of the height of their\nsubtrees. The obtained results include the verification that many methods\ndetect two clusters in unimodal data. The single-linkage method was found to be\nmore resilient to false positives. Also, several methods detected clusters not\ncorresponding directly to the nucleus. The possibility of identifying the type\nof distribution was also investigated.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 14:07:25 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 23:00:41 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Tokuda", "Eric K.", ""], ["Comin", "Cesar H.", ""], ["Costa", "Luciano da F.", ""]]}, {"id": "2005.07998", "submitter": "Maung Maung April Pyone", "authors": "MaungMaung AprilPyone and Hitoshi Kiya", "title": "Encryption Inspired Adversarial Defense for Visual Classification", "comments": "To be appeared on 27th IEEE International Conference on Image\n  Processing (ICIP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional adversarial defenses reduce classification accuracy whether or\nnot a model is under attacks. Moreover, most of image processing based defenses\nare defeated due to the problem of obfuscated gradients. In this paper, we\npropose a new adversarial defense which is a defensive transform for both\ntraining and test images inspired by perceptual image encryption methods. The\nproposed method utilizes a block-wise pixel shuffling method with a secret key.\nThe experiments are carried out on both adaptive and non-adaptive maximum-norm\nbounded white-box attacks while considering obfuscated gradients. The results\nshow that the proposed defense achieves high accuracy (91.55 %) on clean images\nand (89.66 %) on adversarial examples with noise distance of 8/255 on CIFAR-10\ndataset. Thus, the proposed defense outperforms state-of-the-art adversarial\ndefenses including latent adversarial training, adversarial training and\nthermometer encoding.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 14:18:07 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["AprilPyone", "MaungMaung", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "2005.08006", "submitter": "Ioannis Boukas", "authors": "Simone Totaro, Ioannis Boukas, Anders Jonsson and Bertrand\n  Corn\\'elusse", "title": "Lifelong Control of Off-grid Microgrid with Model Based Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lifelong control problem of an off-grid microgrid is composed of two\ntasks, namely estimation of the condition of the microgrid devices and\noperational planning accounting for the uncertainties by forecasting the future\nconsumption and the renewable production. The main challenge for the effective\ncontrol arises from the various changes that take place over time. In this\npaper, we present an open-source reinforcement framework for the modeling of an\noff-grid microgrid for rural electrification. The lifelong control problem of\nan isolated microgrid is formulated as a Markov Decision Process (MDP). We\ncategorize the set of changes that can occur in progressive and abrupt changes.\nWe propose a novel model based reinforcement learning algorithm that is able to\naddress both types of changes. In particular the proposed algorithm\ndemonstrates generalisation properties, transfer capabilities and better\nrobustness in case of fast-changing system dynamics. The proposed algorithm is\ncompared against a rule-based policy and a model predictive controller with\nlook-ahead. The results show that the trained agent is able to outperform both\nbenchmarks in the lifelong setting where the system dynamics are changing over\ntime.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 14:45:55 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Totaro", "Simone", ""], ["Boukas", "Ioannis", ""], ["Jonsson", "Anders", ""], ["Corn\u00e9lusse", "Bertrand", ""]]}, {"id": "2005.08008", "submitter": "Ziheng Duan", "authors": "Haoyan Xu, Ziheng Duan, Jie Feng, Runjian Chen, Qianru Zhang, Zhongbin\n  Xu, Yueyang Wang", "title": "Graph Partitioning and Graph Neural Network based Hierarchical Graph\n  Matching for Graph Similarity Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph similarity computation aims to predict a similarity score between one\npair of graphs to facilitate downstream applications, such as finding the most\nsimilar chemical compounds similar to a query compound or Fewshot 3D Action\nRecognition. Recently, some graph similarity computation models based on neural\nnetworks have been proposed, which are either based on graph-level interaction\nor node-level comparison. However, when the number of nodes in the graph\nincreases, it will inevitably bring about reduced representation ability or\nhigh computation cost. Motivated by this observation, we propose a graph\npartitioning and graph neural network-based model, called PSimGNN, to\neffectively resolve this issue. Specifically, each of the input graphs is\npartitioned into a set of subgraphs to extract the local structural features\ndirectly. Next, a novel graph neural network with an attention mechanism is\ndesigned to map each subgraph into an embedding vector. Some of these subgraph\npairs are automatically selected for node-level comparison to supplement the\nsubgraph-level embedding with fine-grained information. Finally, coarse-grained\ninteraction information among subgraphs and fine-grained comparison information\namong nodes in different subgraphs are integrated to predict the final\nsimilarity score. Experimental results on graph datasets with different graph\nsizes demonstrate that PSimGNN outperforms state-of-the-art methods in graph\nsimilarity computation tasks using approximate Graph Edit Distance (GED) as the\ngraph similarity metric.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 15:01:58 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 11:18:54 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2021 00:19:12 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Xu", "Haoyan", ""], ["Duan", "Ziheng", ""], ["Feng", "Jie", ""], ["Chen", "Runjian", ""], ["Zhang", "Qianru", ""], ["Xu", "Zhongbin", ""], ["Wang", "Yueyang", ""]]}, {"id": "2005.08017", "submitter": "Jean Barbier Dr.", "authors": "Jean Barbier and Galen Reeves", "title": "Information-theoretic limits of a multiview low-rank symmetric spiked\n  matrix model", "comments": "Presented at the 2020 International Symposium on Information Theory\n  (ISIT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cond-mat.dis-nn cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a generalization of an important class of high-dimensional\ninference problems, namely spiked symmetric matrix models, often used as\nprobabilistic models for principal component analysis. Such paradigmatic models\nhave recently attracted a lot of attention from a number of communities due to\ntheir phenomenological richness with statistical-to-computational gaps, while\nremaining tractable. We rigorously establish the information-theoretic limits\nthrough the proof of single-letter formulas for the mutual information and\nminimum mean-square error. On a technical side we improve the recently\nintroduced adaptive interpolation method, so that it can be used to study\nlow-rank models (i.e., estimation problems of \"tall matrices\") in full\ngenerality, an important step towards the rigorous analysis of more complicated\ninference and learning models.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 15:31:07 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Barbier", "Jean", ""], ["Reeves", "Galen", ""]]}, {"id": "2005.08027", "submitter": "Aijun Zhang", "authors": "Zebin Yang, Hengtao Zhang, Agus Sudjianto, Aijun Zhang", "title": "An Effective and Efficient Initialization Scheme for Training\n  Multi-layer Feedforward Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network initialization is the first and critical step for training neural\nnetworks. In this paper, we propose a novel network initialization scheme based\non the celebrated Stein's identity. By viewing multi-layer feedforward neural\nnetworks as cascades of multi-index models, the projection weights to the first\nhidden layer are initialized using eigenvectors of the cross-moment matrix\nbetween the input's second-order score function and the response. The input\ndata is then forward propagated to the next layer and such a procedure can be\nrepeated until all the hidden layers are initialized. Finally, the weights for\nthe output layer are initialized by generalized linear modeling. Such a\nproposed SteinGLM method is shown through extensive numerical results to be\nmuch faster and more accurate than other popular methods commonly used for\ntraining neural networks.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 16:17:37 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 05:36:21 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 12:51:00 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Yang", "Zebin", ""], ["Zhang", "Hengtao", ""], ["Sudjianto", "Agus", ""], ["Zhang", "Aijun", ""]]}, {"id": "2005.08033", "submitter": "Satyapriya Krishna", "authors": "Aarsh Patel, Rahul Gupta, Mukund Harakere, Satyapriya Krishna, Aman\n  Alok, Peng Liu", "title": "Towards classification parity across cohorts", "comments": "Published in ML-IRL ICLR 2020 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been a lot of interest in ensuring algorithmic fairness\nin machine learning where the central question is how to prevent sensitive\ninformation (e.g. knowledge about the ethnic group of an individual) from\nadding \"unfair\" bias to a learning algorithm (Feldman et al. (2015), Zemel et\nal. (2013)). This has led to several debiasing algorithms on word embeddings\n(Qian et al. (2019) , Bolukbasi et al. (2016)), coreference resolution (Zhao et\nal. (2018a)), semantic role labeling (Zhao et al. (2017)), etc. Most of these\nexisting work deals with explicit sensitive features such as gender,\noccupations or race which doesn't work with data where such features are not\ncaptured due to privacy concerns. In this research work, we aim to achieve\nclassification parity across explicit as well as implicit sensitive features.\nWe define explicit cohorts as groups of people based on explicit sensitive\nattributes provided in the data (age, gender, race) whereas implicit cohorts\nare defined as groups of people with similar language usage. We obtain implicit\ncohorts by clustering embeddings of each individual trained on the language\ngenerated by them using a language model. We achieve two primary objectives in\nthis work : [1.] We experimented and discovered classification performance\ndifferences across cohorts based on implicit and explicit features , [2] We\nimproved classification parity by introducing modification to the loss function\naimed to minimize the range of model performances across cohorts.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 16:31:08 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Patel", "Aarsh", ""], ["Gupta", "Rahul", ""], ["Harakere", "Mukund", ""], ["Krishna", "Satyapriya", ""], ["Alok", "Aman", ""], ["Liu", "Peng", ""]]}, {"id": "2005.08035", "submitter": "Matthew Leming", "authors": "Matthew Leming, Simon Baron-Cohen, John Suckling", "title": "Single-participant structural connectivity matrices lead to greater\n  accuracy in classification of participants than function in autism in MRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce a technique of deriving symmetric connectivity\nmatrices from regional histograms of grey-matter volume estimated from\nT1-weighted MRIs. We then validated the technique by inputting the connectivity\nmatrices into a convolutional neural network (CNN) to classify between\nparticipants with autism and age-, motion-, and intracranial-volume-matched\ncontrols from six different databases (29,288 total connectomes, mean age =\n30.72, range 0.42-78.00, including 1555 subjects with autism). We compared this\nmethod to similar classifications of the same participants using fMRI\nconnectivity matrices as well as univariate estimates of grey-matter volumes.\nWe further applied graph-theoretical metrics on output class activation maps to\nidentify areas of the matrices that the CNN preferentially used to make the\nclassification, focusing particularly on hubs. Our results gave AUROCs of\n0.7298 (69.71% accuracy) when classifying by only structural connectivity,\n0.6964 (67.72% accuracy) when classifying by only functional connectivity, and\n0.7037 (66.43% accuracy) when classifying by univariate grey matter volumes.\nCombining structural and functional connectivities gave an AUROC of 0.7354\n(69.40% accuracy). Graph analysis of class activation maps revealed no\ndistinguishable network patterns for functional inputs, but did reveal\nlocalized differences between groups in bilateral Heschl's gyrus and upper\nvermis for structural connectivity. This work provides a simple means of\nfeature extraction for inputting large numbers of structural MRIs into machine\nlearning models.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 16:36:06 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 16:09:21 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Leming", "Matthew", ""], ["Baron-Cohen", "Simon", ""], ["Suckling", "John", ""]]}, {"id": "2005.08041", "submitter": "Alberto Marchisio", "authors": "Valerio Venceslai, Alberto Marchisio, Ihsen Alouani, Maurizio Martina,\n  Muhammad Shafique", "title": "NeuroAttack: Undermining Spiking Neural Networks Security through\n  Externally Triggered Bit-Flips", "comments": "Accepted for publication at the 2020 International Joint Conference\n  on Neural Networks (IJCNN)", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207351", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their proven efficiency, machine-learning systems are deployed in a\nwide range of complex real-life problems. More specifically, Spiking Neural\nNetworks (SNNs) emerged as a promising solution to the accuracy,\nresource-utilization, and energy-efficiency challenges in machine-learning\nsystems. While these systems are going mainstream, they have inherent security\nand reliability issues. In this paper, we propose NeuroAttack, a cross-layer\nattack that threatens the SNNs integrity by exploiting low-level reliability\nissues through a high-level attack. Particularly, we trigger a fault-injection\nbased sneaky hardware backdoor through a carefully crafted adversarial input\nnoise. Our results on Deep Neural Networks (DNNs) and SNNs show a serious\nintegrity threat to state-of-the art machine-learning techniques.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 16:54:00 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Venceslai", "Valerio", ""], ["Marchisio", "Alberto", ""], ["Alouani", "Ihsen", ""], ["Martina", "Maurizio", ""], ["Shafique", "Muhammad", ""]]}, {"id": "2005.08044", "submitter": "Fredrik Hellstr\\\"om", "authors": "Fredrik Hellstr\\\"om and Giuseppe Durisi", "title": "Generalization Bounds via Information Density and Conditional\n  Information Density", "comments": "Published in Journal on Selected Areas in Information Theory (JSAIT).\n  Important note: the proof of the data-dependent bounds provided in the paper\n  contains an error, which is rectified in the following document:\n  https://gdurisi.github.io/files/2021/jsait-correction.pdf", "journal-ref": "IEEE J. Sel. Areas Inf. Theory 1.3 (2020) 824-839", "doi": "10.1109/JSAIT.2020.3040992", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general approach, based on an exponential inequality, to derive\nbounds on the generalization error of randomized learning algorithms. Using\nthis approach, we provide bounds on the average generalization error as well as\nbounds on its tail probability, for both the PAC-Bayesian and single-draw\nscenarios. Specifically, for the case of subgaussian loss functions, we obtain\nnovel bounds that depend on the information density between the training data\nand the output hypothesis. When suitably weakened, these bounds recover many of\nthe information-theoretic available bounds in the literature. We also extend\nthe proposed exponential-inequality approach to the setting recently introduced\nby Steinke and Zakynthinou (2020), where the learning algorithm depends on a\nrandomly selected subset of the available training data. For this setup, we\npresent bounds for bounded loss functions in terms of the conditional\ninformation density between the output hypothesis and the random variable\ndetermining the subset choice, given all training data. Through our approach,\nwe recover the average generalization bound presented by Steinke and\nZakynthinou (2020) and extend it to the PAC-Bayesian and single-draw scenarios.\nFor the single-draw scenario, we also obtain novel bounds in terms of the\nconditional $\\alpha$-mutual information and the conditional maximal leakage.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 17:04:24 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 09:22:29 GMT"}, {"version": "v3", "created": "Fri, 27 Nov 2020 21:50:21 GMT"}, {"version": "v4", "created": "Fri, 4 Dec 2020 18:10:31 GMT"}, {"version": "v5", "created": "Fri, 19 Mar 2021 09:12:12 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Hellstr\u00f6m", "Fredrik", ""], ["Durisi", "Giuseppe", ""]]}, {"id": "2005.08047", "submitter": "Lele Cao", "authors": "Lele Cao, Sahar Asadi, Wenfei Zhu, Christian Schmidli, Michael\n  Sj\\\"oberg", "title": "Simple, Scalable, and Stable Variational Deep Clustering", "comments": "17 pages, 5 figures, source code: https://github.com/king/s3vdc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep clustering (DC) has become the state-of-the-art for unsupervised\nclustering. In principle, DC represents a variety of unsupervised methods that\njointly learn the underlying clusters and the latent representation directly\nfrom unstructured datasets. However, DC methods are generally poorly applied\ndue to high operational costs, low scalability, and unstable results. In this\npaper, we first evaluate several popular DC variants in the context of\nindustrial applicability using eight empirical criteria. We then choose to\nfocus on variational deep clustering (VDC) methods, since they mostly meet\nthose criteria except for simplicity, scalability, and stability. To address\nthese three unmet criteria, we introduce four generic algorithmic improvements:\ninitial $\\gamma$-training, periodic $\\beta$-annealing, mini-batch GMM (Gaussian\nmixture model) initialization, and inverse min-max transform. We also propose a\nnovel clustering algorithm S3VDC (simple, scalable, and stable VDC) that\nincorporates all those improvements. Our experiments show that S3VDC\noutperforms the state-of-the-art on both benchmark tasks and a large\nunstructured industrial dataset without any ground truth label. In addition, we\nanalytically evaluate the usability and interpretability of S3VDC.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 17:24:01 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 10:24:56 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Cao", "Lele", ""], ["Asadi", "Sahar", ""], ["Zhu", "Wenfei", ""], ["Schmidli", "Christian", ""], ["Sj\u00f6berg", "Michael", ""]]}, {"id": "2005.08054", "submitter": "Vidya Muthukumar", "authors": "Vidya Muthukumar, Adhyyan Narang, Vignesh Subramanian, Mikhail Belkin,\n  Daniel Hsu, Anant Sahai", "title": "Classification vs regression in overparameterized regimes: Does the loss\n  function matter?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare classification and regression tasks in the overparameterized\nlinear model with Gaussian features. On the one hand, we show that with\nsufficient overparameterization all training points are support vectors:\nsolutions obtained by least-squares minimum-norm interpolation, typically used\nfor regression, are identical to those produced by the hard-margin support\nvector machine (SVM) that minimizes the hinge loss, typically used for training\nclassifiers. On the other hand, we show that there exist regimes where these\nsolutions are near-optimal when evaluated by the 0-1 test loss function, but do\nnot generalize if evaluated by the square loss function, i.e. they achieve the\nnull risk. Our results demonstrate the very different roles and properties of\nloss functions used at the training phase (optimization) and the testing phase\n(generalization).\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 17:58:25 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Muthukumar", "Vidya", ""], ["Narang", "Adhyyan", ""], ["Subramanian", "Vignesh", ""], ["Belkin", "Mikhail", ""], ["Hsu", "Daniel", ""], ["Sahai", "Anant", ""]]}, {"id": "2005.08056", "submitter": "Hongyu Gong", "authors": "Hongyu Gong, Yelong Shen, Dian Yu, Jianshu Chen, Dong Yu", "title": "Recurrent Chunking Mechanisms for Long-Text Machine Reading\n  Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study machine reading comprehension (MRC) on long texts,\nwhere a model takes as inputs a lengthy document and a question and then\nextracts a text span from the document as an answer. State-of-the-art models\ntend to use a pretrained transformer model (e.g., BERT) to encode the joint\ncontextual information of document and question. However, these\ntransformer-based models can only take a fixed-length (e.g., 512) text as its\ninput. To deal with even longer text inputs, previous approaches usually chunk\nthem into equally-spaced segments and predict answers based on each segment\nindependently without considering the information from other segments. As a\nresult, they may form segments that fail to cover the correct answer span or\nretain insufficient contexts around it, which significantly degrades the\nperformance. Moreover, they are less capable of answering questions that need\ncross-segment information.\n  We propose to let a model learn to chunk in a more flexible way via\nreinforcement learning: a model can decide the next segment that it wants to\nprocess in either direction. We also employ recurrent mechanisms to enable\ninformation to flow across segments. Experiments on three MRC datasets -- CoQA,\nQuAC, and TriviaQA -- demonstrate the effectiveness of our proposed recurrent\nchunking mechanisms: we can obtain segments that are more likely to contain\ncomplete answers and at the same time provide sufficient contexts around the\nground truth answers for better predictions.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 18:08:58 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 14:29:08 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Gong", "Hongyu", ""], ["Shen", "Yelong", ""], ["Yu", "Dian", ""], ["Chen", "Jianshu", ""], ["Yu", "Dong", ""]]}, {"id": "2005.08057", "submitter": "Yang Feng", "authors": "Yang Feng and Qingfeng Liu", "title": "Nested Model Averaging on Solution Path for High-dimensional Linear\n  Regression", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG econ.EM stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the nested model averaging method on the solution path for a\nhigh-dimensional linear regression problem. In particular, we propose to\ncombine model averaging with regularized estimators (e.g., lasso and SLOPE) on\nthe solution path for high-dimensional linear regression. In simulation\nstudies, we first conduct a systematic investigation on the impact of predictor\nordering on the behavior of nested model averaging, then show that nested model\naveraging with lasso and SLOPE compares favorably with other competing methods,\nincluding the infeasible lasso and SLOPE with the tuning parameter optimally\nselected. A real data analysis on predicting the per capita violent crime in\nthe United States shows an outstanding performance of the nested model\naveraging with lasso.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 18:09:57 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Feng", "Yang", ""], ["Liu", "Qingfeng", ""]]}, {"id": "2005.08067", "submitter": "Markus L\\\"oning", "authors": "Markus L\\\"oning, Franz Kir\\'aly", "title": "Forecasting with sktime: Designing sktime's New Forecasting API and\n  Applying It to Replicate and Extend the M4 Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new open-source framework for forecasting in Python. Our\nframework forms part of sktime, a more general machine learning toolbox for\ntime series with scikit-learn compatible interfaces for different learning\ntasks. Our new framework provides dedicated forecasting algorithms and tools to\nbuild, tune and evaluate composite models. We use sktime to both replicate and\nextend key results from the M4 forecasting study. In particular, we further\ninvestigate the potential of simple off-the-shelf machine learning approaches\nfor univariate forecasting. Our main results are that simple hybrid approaches\ncan boost the performance of statistical models, and that simple pure\napproaches can achieve competitive performance on the hourly data set,\noutperforming the statistical algorithms and coming close to the M4 winner.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 19:15:09 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 17:57:30 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["L\u00f6ning", "Markus", ""], ["Kir\u00e1ly", "Franz", ""]]}, {"id": "2005.08068", "submitter": "Ignasi Clavera", "authors": "Ignasi Clavera, Violet Fu, Pieter Abbeel", "title": "Model-Augmented Actor-Critic: Backpropagating through Paths", "comments": "Accepted paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current model-based reinforcement learning approaches use the model simply as\na learned black-box simulator to augment the data for policy optimization or\nvalue function learning. In this paper, we show how to make more effective use\nof the model by exploiting its differentiability. We construct a policy\noptimization algorithm that uses the pathwise derivative of the learned model\nand policy across future timesteps. Instabilities of learning across many\ntimesteps are prevented by using a terminal value function, learning the policy\nin an actor-critic fashion. Furthermore, we present a derivation on the\nmonotonic improvement of our objective in terms of the gradient error in the\nmodel and value function. We show that our approach (i) is consistently more\nsample efficient than existing state-of-the-art model-based algorithms, (ii)\nmatches the asymptotic performance of model-free algorithms, and (iii) scales\nto long horizons, a regime where typically past model-based approaches have\nstruggled.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 19:18:10 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Clavera", "Ignasi", ""], ["Fu", "Violet", ""], ["Abbeel", "Pieter", ""]]}, {"id": "2005.08072", "submitter": "Huanru Henry Mao", "authors": "Huanru Henry Mao, Shuyang Li, Julian McAuley and Garrison Cottrell", "title": "Speech Recognition and Multi-Speaker Diarization of Long Conversations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech recognition (ASR) and speaker diarization (SD) models have\ntraditionally been trained separately to produce rich conversation transcripts\nwith speaker labels. Recent advances have shown that joint ASR and SD models\ncan learn to leverage audio-lexical inter-dependencies to improve word\ndiarization performance. We introduce a new benchmark of hour-long podcasts\ncollected from the weekly This American Life radio program to better compare\nthese approaches when applied to extended multi-speaker conversations. We find\nthat training separate ASR and SD models perform better when utterance\nboundaries are known but otherwise joint models can perform better. To handle\nlong conversations with unknown utterance boundaries, we introduce a striding\nattention decoding algorithm and data augmentation techniques which, combined\nwith model pre-training, improves ASR and SD.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 19:29:33 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 03:28:08 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Mao", "Huanru Henry", ""], ["Li", "Shuyang", ""], ["McAuley", "Julian", ""], ["Cottrell", "Garrison", ""]]}, {"id": "2005.08081", "submitter": "Fenglin Liu", "authors": "Fenglin Liu, Xuancheng Ren, Guangxiang Zhao, Xu Sun", "title": "Layer-Wise Cross-View Decoding for Sequence-to-Sequence Learning", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In sequence-to-sequence learning, the decoder relies on the attention\nmechanism to efficiently extract information from the encoder. While it is\ncommon practice to draw information from only the last encoder layer, recent\nwork has proposed to use representations from different encoder layers for\ndiversified levels of information. Nonetheless, the decoder still obtains only\na single view of the source sequences, which might lead to insufficient\ntraining of the encoder layer stack due to the hierarchy bypassing problem. In\nthis work, we propose layer-wise cross-view decoding, where for each decoder\nlayer, together with the representations from the last encoder layer, which\nserve as a global view, those from other encoder layers are supplemented for a\nstereoscopic view of the source sequences. Systematic experiments show that we\nsuccessfully address the hierarchy bypassing problem and substantially improve\nthe performance of sequence-to-sequence learning with deep representations on\ndiverse tasks.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 20:00:39 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 10:21:33 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 05:58:38 GMT"}, {"version": "v4", "created": "Sat, 15 May 2021 08:52:22 GMT"}, {"version": "v5", "created": "Sun, 4 Jul 2021 08:38:40 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Liu", "Fenglin", ""], ["Ren", "Xuancheng", ""], ["Zhao", "Guangxiang", ""], ["Sun", "Xu", ""]]}, {"id": "2005.08083", "submitter": "Alex De Sa'", "authors": "Alex G. C. de S\\'a, Cristiano G. Pimenta, Gisele L. Pappa and Alex A.\n  Freitas", "title": "A Robust Experimental Evaluation of Automated Multi-Label Classification\n  Methods", "comments": "GECCO'2020 paper: Submitted and accepted", "journal-ref": null, "doi": "10.1145/3377930.3390231", "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated Machine Learning (AutoML) has emerged to deal with the selection\nand configuration of algorithms for a given learning task. With the progression\nof AutoML, several effective methods were introduced, especially for\ntraditional classification and regression problems. Apart from the AutoML\nsuccess, several issues remain open. One issue, in particular, is the lack of\nability of AutoML methods to deal with different types of data. Based on this\nscenario, this paper approaches AutoML for multi-label classification (MLC)\nproblems. In MLC, each example can be simultaneously associated to several\nclass labels, unlike the standard classification task, where an example is\nassociated to just one class label. In this work, we provide a general\ncomparison of five automated multi-label classification methods -- two\nevolutionary methods, one Bayesian optimization method, one random search and\none greedy search -- on 14 datasets and three designed search spaces. Overall,\nwe observe that the most prominent method is the one based on a canonical\ngrammar-based genetic programming (GGP) search method, namely\nAuto-MEKA$_{GGP}$. Auto-MEKA$_{GGP}$ presented the best average results in our\ncomparison and was statistically better than all the other methods in different\nsearch spaces and evaluated measures, except when compared to the greedy search\nmethod.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 20:08:04 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 16:48:27 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["de S\u00e1", "Alex G. C.", ""], ["Pimenta", "Cristiano G.", ""], ["Pappa", "Gisele L.", ""], ["Freitas", "Alex A.", ""]]}, {"id": "2005.08087", "submitter": "Ashutosh Chaubey", "authors": "Ashutosh Chaubey, Nikhil Agrawal, Kavya Barnwal, Keerat K. Guliani,\n  Pramod Mehta", "title": "Universal Adversarial Perturbations: A Survey", "comments": "20 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, Deep Learning has emerged as a useful and efficient\ntool to solve a wide variety of complex learning problems ranging from image\nclassification to human pose estimation, which is challenging to solve using\nstatistical machine learning algorithms. However, despite their superior\nperformance, deep neural networks are susceptible to adversarial perturbations,\nwhich can cause the network's prediction to change without making perceptible\nchanges to the input image, thus creating severe security issues at the time of\ndeployment of such systems. Recent works have shown the existence of Universal\nAdversarial Perturbations, which, when added to any image in a dataset,\nmisclassifies it when passed through a target model. Such perturbations are\nmore practical to deploy since there is minimal computation done during the\nactual attack. Several techniques have also been proposed to defend the neural\nnetworks against these perturbations. In this paper, we attempt to provide a\ndetailed discussion on the various data-driven and data-independent methods for\ngenerating universal perturbations, along with measures to defend against such\nperturbations. We also cover the applications of such universal perturbations\nin various deep learning tasks.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 20:18:26 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Chaubey", "Ashutosh", ""], ["Agrawal", "Nikhil", ""], ["Barnwal", "Kavya", ""], ["Guliani", "Keerat K.", ""], ["Mehta", "Pramod", ""]]}, {"id": "2005.08088", "submitter": "Ningyuan Chen", "authors": "Ningyuan Chen, Chun Wang, Longlin Wang", "title": "Learning and Optimization with Seasonal Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seasonality is a common form of non-stationary patterns in the business\nworld. We study a decision maker who tries to learn the optimal decision over\ntime when the environment is unknown and evolving with seasonality. We consider\na multi-armed bandit (MAB) framework where the mean rewards are periodic. The\nunknown periods of the arms can be different and scale with the length of the\nhorizon $T$ polynomially. We propose a two-staged policy that combines Fourier\nanalysis with a confidence-bound based learning procedure to learn the periods\nand minimize the regret. In stage one, the policy is able to correctly estimate\nthe periods of all arms with high probability. In stage two, the policy\nexplores mean rewards of arms in each phase using the periods estimated in\nstage one and exploits the optimal arm in the long run. We show that our policy\nachieves the rate of regret $\\tilde{O}(\\sqrt{T\\sum_{k=1}^K T_k})$, where $K$ is\nthe number of arms and $T_k$ is the period of arm $k$. It matches the optimal\nrate of regret of the classic MAB problem $O(\\sqrt{TK})$ if we regard each\nphase of an arm as a separate arm.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 20:19:25 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 14:15:15 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 16:30:49 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Chen", "Ningyuan", ""], ["Wang", "Chun", ""], ["Wang", "Longlin", ""]]}, {"id": "2005.08098", "submitter": "Zhi-Gang Liu", "authors": "Zhi-Gang Liu, Paul N. Whatmough, Matthew Mattina", "title": "Systolic Tensor Array: An Efficient Structured-Sparse GEMM Accelerator\n  for Mobile CNN Inference", "comments": "Accepted by IEEE Computer Architecture Letters on 3/4/2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network (CNN) inference on mobile devices demands\nefficient hardware acceleration of low-precision (INT8) general matrix\nmultiplication (GEMM). The systolic array (SA) is a pipelined 2D array of\nprocessing elements (PEs), with very efficient local data movement, well suited\nto accelerating GEMM, and widely deployed in industry. In this work, we\ndescribe two significant improvements to the traditional SA architecture, to\nspecifically optimize for CNN inference. Firstly, we generalize the traditional\nscalar PE, into a Tensor-PE, which gives rise to a family of new Systolic\nTensor Array (STA) microarchitectures. The STA family increases intra-PE\noperand reuse and datapath efficiency, resulting in circuit area and power\ndissipation reduction of as much as 2.08x and 1.36x respectively, compared to\nthe conventional SA at iso-throughput with INT8 operands. Secondly, we extend\nthis design to support a novel block-sparse data format called density-bound\nblock (DBB). This variant (STA-DBB) achieves a 3.14x and 1.97x improvement over\nthe SA baseline at iso-throughput in area and power respectively, when\nprocessing specially-trained DBB-sparse models, while remaining fully backwards\ncompatible with dense models.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 20:47:56 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Liu", "Zhi-Gang", ""], ["Whatmough", "Paul N.", ""], ["Mattina", "Matthew", ""]]}, {"id": "2005.08099", "submitter": "Matthew Brennan", "authors": "Matthew Brennan, Guy Bresler", "title": "Reducibility and Statistical-Computational Gaps from Secret Leakage", "comments": "175 pages; subsumes preliminary draft arXiv:1908.06130; accepted for\n  presentation at the Conference on Learning Theory (COLT) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference problems with conjectured statistical-computational gaps are\nubiquitous throughout modern statistics, computer science and statistical\nphysics. While there has been success evidencing these gaps from the failure of\nrestricted classes of algorithms, progress towards a more traditional\nreduction-based approach to computational complexity in statistical inference\nhas been limited. Existing reductions have largely been limited to inference\nproblems with similar structure -- primarily mapping among problems\nrepresentable as a sparse submatrix signal plus a noise matrix, which are\nsimilar to the common hardness assumption of planted clique.\n  The insight in this work is that a slight generalization of the planted\nclique conjecture -- secret leakage planted clique -- gives rise to a variety\nof new average-case reduction techniques, yielding a web of reductions among\nproblems with very different structure. Using variants of the planted clique\nconjecture for specific forms of secret leakage planted clique, we deduce tight\nstatistical-computational tradeoffs for a diverse range of problems including\nrobust sparse mean estimation, mixtures of sparse linear regressions, robust\nsparse linear regression, tensor PCA, variants of dense $k$-block stochastic\nblock models, negatively correlated sparse PCA, semirandom planted dense\nsubgraph, detection in hidden partition models and a universality principle for\nlearning sparse mixtures. In particular, a $k$-partite hypergraph variant of\nthe planted clique conjecture is sufficient to establish all of our\ncomputational lower bounds. Our techniques also reveal novel connections to\ncombinatorial designs and to random matrix theory. This work gives the first\nevidence that an expanded set of hardness assumptions, such as for secret\nleakage planted clique, may be a key first step towards a more complete theory\nof reductions among statistical problems.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 20:56:09 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 21:59:41 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Brennan", "Matthew", ""], ["Bresler", "Guy", ""]]}, {"id": "2005.08100", "submitter": "Anmol Gulati", "authors": "Anmol Gulati, James Qin, Chung-Cheng Chiu, Niki Parmar, Yu Zhang,\n  Jiahui Yu, Wei Han, Shibo Wang, Zhengdong Zhang, Yonghui Wu, Ruoming Pang", "title": "Conformer: Convolution-augmented Transformer for Speech Recognition", "comments": "Submitted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently Transformer and Convolution neural network (CNN) based models have\nshown promising results in Automatic Speech Recognition (ASR), outperforming\nRecurrent neural networks (RNNs). Transformer models are good at capturing\ncontent-based global interactions, while CNNs exploit local features\neffectively. In this work, we achieve the best of both worlds by studying how\nto combine convolution neural networks and transformers to model both local and\nglobal dependencies of an audio sequence in a parameter-efficient way. To this\nregard, we propose the convolution-augmented transformer for speech\nrecognition, named Conformer. Conformer significantly outperforms the previous\nTransformer and CNN based models achieving state-of-the-art accuracies. On the\nwidely used LibriSpeech benchmark, our model achieves WER of 2.1%/4.3% without\nusing a language model and 1.9%/3.9% with an external language model on\ntest/testother. We also observe competitive performance of 2.7%/6.3% with a\nsmall model of only 10M parameters.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 20:56:25 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Gulati", "Anmol", ""], ["Qin", "James", ""], ["Chiu", "Chung-Cheng", ""], ["Parmar", "Niki", ""], ["Zhang", "Yu", ""], ["Yu", "Jiahui", ""], ["Han", "Wei", ""], ["Wang", "Shibo", ""], ["Zhang", "Zhengdong", ""], ["Wu", "Yonghui", ""], ["Pang", "Ruoming", ""]]}, {"id": "2005.08104", "submitter": "Nikita Araslanov", "authors": "Nikita Araslanov and Stefan Roth", "title": "Single-Stage Semantic Segmentation from Image Labels", "comments": "To appear at CVPR 2020; minor corrections in Eq. (9). Code:\n  https://github.com/visinf/1-stage-wseg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen a rapid growth in new approaches improving the\naccuracy of semantic segmentation in a weakly supervised setting, i.e. with\nonly image-level labels available for training. However, this has come at the\ncost of increased model complexity and sophisticated multi-stage training\nprocedures. This is in contrast to earlier work that used only a single stage\n$-$ training one segmentation network on image labels $-$ which was abandoned\ndue to inferior segmentation accuracy. In this work, we first define three\ndesirable properties of a weakly supervised method: local consistency, semantic\nfidelity, and completeness. Using these properties as guidelines, we then\ndevelop a segmentation-based network model and a self-supervised training\nscheme to train for semantic masks from image-level annotations in a single\nstage. We show that despite its simplicity, our method achieves results that\nare competitive with significantly more complex pipelines, substantially\noutperforming earlier single-stage methods.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 21:10:10 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Araslanov", "Nikita", ""], ["Roth", "Stefan", ""]]}, {"id": "2005.08106", "submitter": "Boyana Buyuklieva", "authors": "Boyana Buyuklieva", "title": "Machine Learning for Exploring Spatial Affordance Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This dissertation uses supervised and unsupervised data mining techniques to\nanalyse office floor plans in an attempt to gain a better understanding of\ntheir geometry-to-function relationship. This question was deemed relevant\nafter a background review of the state-of-the-art in automated floor-plan\ngeneration tools showed that such tools have been prototyped since the 1960s,\nbut their search space is ill-informed because there are few formalisms to\ndescribe spatial affordance. To show and evaluate the relationship of geometry\nand use, data from visual graph analysis were used to train three supervised\nlearners and compare these to a baseline accuracy established with a ZeroR\nclassifier. This showed that for the office dataset examined, visual mean depth\nand integration are most tightly linked to usage and that the supervised\nlearning algorithm J48 can correctly predict class performance on unseen\nexamples to up to 79.5%. The thesis also includes an evaluation of the layout\ncase studies with unsupervised learners, which showed that use could not be\nimmediately reverse-engineered based solemnly on the VGA information to achieve\na strong cluster-to-class evaluation.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 21:12:06 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Buyuklieva", "Boyana", ""]]}, {"id": "2005.08110", "submitter": "Meet Vadera", "authors": "Meet P. Vadera, Brian Jalaian and Benjamin M. Marlin", "title": "Generalized Bayesian Posterior Expectation Distillation for Deep Neural\n  Networks", "comments": "Accepted at UAI '20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a general framework for distilling expectations\nwith respect to the Bayesian posterior distribution of a deep neural network\nclassifier, extending prior work on the Bayesian Dark Knowledge framework. The\nproposed framework takes as input \"teacher\" and student model architectures and\na general posterior expectation of interest. The distillation method performs\nan online compression of the selected posterior expectation using iteratively\ngenerated Monte Carlo samples. We focus on the posterior predictive\ndistribution and expected entropy as distillation targets. We investigate\nseveral aspects of this framework including the impact of uncertainty and the\nchoice of student model architecture. We study methods for student model\narchitecture search from a speed-storage-accuracy perspective and evaluate\ndown-stream tasks leveraging entropy distillation including uncertainty ranking\nand out-of-distribution detection.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 21:40:47 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Vadera", "Meet P.", ""], ["Jalaian", "Brian", ""], ["Marlin", "Benjamin M.", ""]]}, {"id": "2005.08119", "submitter": "Xiangyu Y Hu", "authors": "Hao Ma and Xiangyu Hu and Yuxuan Zhang and Nils Thuerey and Oskar J.\n  Haidn", "title": "A Combined Data-driven and Physics-driven Method for Steady Heat\n  Conduction Prediction using Deep Convolutional Neural Networks", "comments": "23 pages 12 figures 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With several advantages and as an alternative to predict physics field,\nmachine learning methods can be classified into two distinct types: data-driven\nrelying on training data and physics-driven using physics law. Choosing heat\nconduction problem as an example, we compared the data- and physics-driven\nlearning process with deep Convolutional Neural Networks (CNN). It shows that\nthe convergences of the error to ground truth solution and the residual of heat\nconduction equation exhibit remarkable differences. Based on this observation,\nwe propose a combined-driven method for learning acceleration and more accurate\nsolutions. With a weighted loss function, reference data and physical equation\nare able to simultaneously drive the learning. Several numerical experiments\nare conducted to investigate the effectiveness of the combined method. For the\ndata-driven based method, the introduction of physical equation not only is\nable to speed up the convergence, but also produces physically more consistent\nsolutions. For the physics-driven based method, it is observed that the\ncombined method is able to speed up the convergence up to 49.0\\% by using a not\nvery restrictive coarse reference.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 22:29:37 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Ma", "Hao", ""], ["Hu", "Xiangyu", ""], ["Zhang", "Yuxuan", ""], ["Thuerey", "Nils", ""], ["Haidn", "Oskar J.", ""]]}, {"id": "2005.08126", "submitter": "Ashwin Samudre", "authors": "Nikita Moriakov, Ashwin Samudre, Michela Negro, Fabian Gieseke, Sydney\n  Otten, Luc Hendriks", "title": "Inferring astrophysical X-ray polarization with deep learning", "comments": "Accepted to International Conference on Learning Representations\n  (ICLR) 2020 Workshop: Fundamental Science in the Era of AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.HE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of deep learning in the context of X-ray polarization\ndetection from astrophysical sources as will be observed by the Imaging X-ray\nPolarimetry Explorer (IXPE), a future NASA selected space-based mission\nexpected to be operative in 2021. In particular, we propose two models that can\nbe used to estimate the impact point as well as the polarization direction of\nthe incoming radiation. The results obtained show that data-driven approaches\ndepict a promising alternative to the existing analytical approaches. We also\ndiscuss problems and challenges to be addressed in the near future.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 23:19:07 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Moriakov", "Nikita", ""], ["Samudre", "Ashwin", ""], ["Negro", "Michela", ""], ["Gieseke", "Fabian", ""], ["Otten", "Sydney", ""], ["Hendriks", "Luc", ""]]}, {"id": "2005.08128", "submitter": "Aswin Sivaraman", "authors": "Aswin Sivaraman, Minje Kim", "title": "Sparse Mixture of Local Experts for Efficient Speech Enhancement", "comments": "5 pages, 5 figures", "journal-ref": "Published in Interspeech 2020", "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we investigate a deep learning approach for speech denoising\nthrough an efficient ensemble of specialist neural networks. By splitting up\nthe speech denoising task into non-overlapping subproblems and introducing a\nclassifier, we are able to improve denoising performance while also reducing\ncomputational complexity. More specifically, the proposed model incorporates a\ngating network which assigns noisy speech signals to an appropriate specialist\nnetwork based on either speech degradation level or speaker gender. In our\nexperiments, a baseline recurrent network is compared against an ensemble of\nsimilarly-designed smaller recurrent networks regulated by the auxiliary gating\nnetwork. Using stochastically generated batches from a large noisy speech\ncorpus, the proposed model learns to estimate a time-frequency masking matrix\nbased on the magnitude spectrogram of an input mixture signal. Both baseline\nand specialist networks are trained to estimate the ideal ratio mask, while the\ngating network is trained to perform subproblem classification. Our findings\ndemonstrate that a fine-tuned ensemble network is able to exceed the speech\ndenoising capabilities of a generalist network, doing so with fewer model\nparameters.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 23:23:22 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Sivaraman", "Aswin", ""], ["Kim", "Minje", ""]]}, {"id": "2005.08129", "submitter": "Yongfeng Zhang", "authors": "Hanxiong Chen, Shaoyun Shi, Yunqi Li, Yongfeng Zhang", "title": "Neural Collaborative Reasoning", "comments": "Accepted to the 30th Web Conference (WWW 2021)", "journal-ref": null, "doi": "10.1145/3442381.3449973", "report-no": null, "categories": "cs.IR cs.AI cs.LG cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Collaborative Filtering (CF) methods are mostly designed based on\nthe idea of matching, i.e., by learning user and item embeddings from data\nusing shallow or deep models, they try to capture the associative relevance\npatterns in data, so that a user embedding can be matched with relevant item\nembeddings using designed or learned similarity functions. However, as a\ncognition rather than a perception intelligent task, recommendation requires\nnot only the ability of pattern recognition and matching from data, but also\nthe ability of cognitive reasoning in data. In this paper, we propose to\nadvance Collaborative Filtering (CF) to Collaborative Reasoning (CR), which\nmeans that each user knows part of the reasoning space, and they collaborate\nfor reasoning in the space to estimate preferences for each other. Technically,\nwe propose a Neural Collaborative Reasoning (NCR) framework to bridge learning\nand reasoning. Specifically, we integrate the power of representation learning\nand logical reasoning, where representations capture similarity patterns in\ndata from perceptual perspectives, and logic facilitates cognitive reasoning\nfor informed decision making. An important challenge, however, is to bridge\ndifferentiable neural networks and symbolic reasoning in a shared architecture\nfor optimization and inference. To solve the problem, we propose a modularized\nreasoning architecture, which learns logical operations such as AND ($\\wedge$),\nOR ($\\vee$) and NOT ($\\neg$) as neural modules for implication reasoning\n($\\rightarrow$). In this way, logical expressions can be equivalently organized\nas neural networks, so that logical reasoning and prediction can be conducted\nin a continuous space. Experiments on real-world datasets verified the\nadvantages of our framework compared with both shallow, deep and reasoning\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 23:29:31 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 17:58:21 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 23:03:39 GMT"}, {"version": "v4", "created": "Tue, 20 Apr 2021 23:16:22 GMT"}, {"version": "v5", "created": "Mon, 3 May 2021 02:06:05 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Chen", "Hanxiong", ""], ["Shi", "Shaoyun", ""], ["Li", "Yunqi", ""], ["Zhang", "Yongfeng", ""]]}, {"id": "2005.08140", "submitter": "Sebastian Ober", "authors": "Sebastian W. Ober, Laurence Aitchison", "title": "Global inducing point variational posteriors for Bayesian neural\n  networks and deep Gaussian processes", "comments": "Accepted for publication at the 38th International Conference on\n  Machine Learning (ICML 2021, PMLR 139), 33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the optimal approximate posterior over the top-layer weights in a\nBayesian neural network for regression, and show that it exhibits strong\ndependencies on the lower-layer weights. We adapt this result to develop a\ncorrelated approximate posterior over the weights at all layers in a Bayesian\nneural network. We extend this approach to deep Gaussian processes, unifying\ninference in the two model classes. Our approximate posterior uses learned\n\"global\" inducing points, which are defined only at the input layer and\npropagated through the network to obtain inducing inputs at subsequent layers.\nBy contrast, standard, \"local\", inducing point methods from the deep Gaussian\nprocess literature optimise a separate set of inducing inputs at every layer,\nand thus do not model correlations across layers. Our method gives\nstate-of-the-art performance for a variational Bayesian method, without data\naugmentation or tempering, on CIFAR-10 of 86.7%, which is comparable to SGMCMC\nwithout tempering but with data augmentation (88% in Wenzel et al. 2020).\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 01:10:37 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 00:10:04 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 12:14:08 GMT"}, {"version": "v4", "created": "Sun, 4 Oct 2020 14:39:42 GMT"}, {"version": "v5", "created": "Tue, 22 Jun 2021 13:39:01 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Ober", "Sebastian W.", ""], ["Aitchison", "Laurence", ""]]}, {"id": "2005.08144", "submitter": "Christopher Choy", "authors": "Christopher Choy, Junha Lee, Rene Ranftl, Jaesik Park, Vladlen Koltun", "title": "High-dimensional Convolutional Networks for Geometric Pattern\n  Recognition", "comments": "Accepted for CVPR 2020 oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many problems in science and engineering can be formulated in terms of\ngeometric patterns in high-dimensional spaces. We present high-dimensional\nconvolutional networks (ConvNets) for pattern recognition problems that arise\nin the context of geometric registration. We first study the effectiveness of\nconvolutional networks in detecting linear subspaces in high-dimensional spaces\nwith up to 32 dimensions: much higher dimensionality than prior applications of\nConvNets. We then apply high-dimensional ConvNets to 3D registration under\nrigid motions and image correspondence estimation. Experiments indicate that\nour high-dimensional ConvNets outperform prior approaches that relied on deep\nnetworks based on global pooling operators.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 01:46:12 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Choy", "Christopher", ""], ["Lee", "Junha", ""], ["Ranftl", "Rene", ""], ["Park", "Jaesik", ""], ["Koltun", "Vladlen", ""]]}, {"id": "2005.08147", "submitter": "Wenqi Fan", "authors": "Wenqi Fan, Tyler Derr, Xiangyu Zhao, Yao Ma, Hui Liu, Jianping Wang,\n  Jiliang Tang, Qing Li", "title": "Attacking Black-box Recommendations via Copying Cross-domain User\n  Profiles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, recommender systems that aim to suggest personalized lists of items\nfor users to interact with online have drawn a lot of attention. In fact, many\nof these state-of-the-art techniques have been deep learning based. Recent\nstudies have shown that these deep learning models (in particular for\nrecommendation systems) are vulnerable to attacks, such as data poisoning,\nwhich generates users to promote a selected set of items. However, more\nrecently, defense strategies have been developed to detect these generated\nusers with fake profiles. Thus, advanced injection attacks of creating more\n`realistic' user profiles to promote a set of items is still a key challenge in\nthe domain of deep learning based recommender systems. In this work, we present\nour framework CopyAttack, which is a reinforcement learning based black-box\nattack method that harnesses real users from a source domain by copying their\nprofiles into the target domain with the goal of promoting a subset of items.\nCopyAttack is constructed to both efficiently and effectively learn policy\ngradient networks that first select, and then further refine/craft, user\nprofiles from the source domain to ultimately copy into the target domain.\nCopyAttack's goal is to maximize the hit ratio of the targeted items in the\nTop-$k$ recommendation list of the users in the target domain. We have\nconducted experiments on two real-world datasets and have empirically verified\nthe effectiveness of our proposed framework and furthermore performed a\nthorough model analysis.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 02:10:38 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Fan", "Wenqi", ""], ["Derr", "Tyler", ""], ["Zhao", "Xiangyu", ""], ["Ma", "Yao", ""], ["Liu", "Hui", ""], ["Wang", "Jianping", ""], ["Tang", "Jiliang", ""], ["Li", "Qing", ""]]}, {"id": "2005.08148", "submitter": "Mohammad Maghsoudi Mehrabani", "authors": "Mohammad Maghsoudi Mehrabani, Hamid Mohayeji and Ali Moeini", "title": "A Hybrid Approach to Enhance Pure Collaborative Filtering based on\n  Content Feature Relationship", "comments": "The 10th Conference on Information and Knowledge Technology (IKT2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recommendation systems get expanding significance because of their\napplications in both the scholarly community and industry. With the development\nof additional data sources and methods of extracting new information other than\nthe rating history of clients on items, hybrid recommendation algorithms, in\nwhich some methods have usually been combined to improve performance, have\nbecome pervasive. In this work, we first introduce a novel method to extract\nthe implicit relationship between content features using a sort of well-known\nmethods from the natural language processing domain, namely Word2Vec. In\ncontrast to the typical use of Word2Vec, we utilize some features of items as\nwords of sentences to produce neural feature embeddings, through which we can\ncalculate the similarity between features. Next, we propose a novel\ncontent-based recommendation system that employs the relationship to determine\nvector representations for items by which the similarity between items can be\ncomputed (RELFsim). Our evaluation results demonstrate that it can predict the\npreference a user would have for a set of items as good as pure collaborative\nfiltering. This content-based algorithm is also embedded in a pure item-based\ncollaborative filtering algorithm to deal with the cold-start problem and\nenhance its accuracy. Our experiments on a benchmark movie dataset corroborate\nthat the proposed approach improves the accuracy of the system.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 02:20:45 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Mehrabani", "Mohammad Maghsoudi", ""], ["Mohayeji", "Hamid", ""], ["Moeini", "Ali", ""]]}, {"id": "2005.08158", "submitter": "Yash Chandak", "authors": "Yash Chandak, Georgios Theocharous, Shiv Shankar, Martha White,\n  Sridhar Mahadevan, Philip S. Thomas", "title": "Optimizing for the Future in Non-Stationary MDPs", "comments": "Thirty-seventh International Conference on Machine Learning (ICML\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most reinforcement learning methods are based upon the key assumption that\nthe transition dynamics and reward functions are fixed, that is, the underlying\nMarkov decision process is stationary. However, in many real-world\napplications, this assumption is violated, and using existing algorithms may\nresult in a performance lag. To proactively search for a good future policy, we\npresent a policy gradient algorithm that maximizes a forecast of future\nperformance. This forecast is obtained by fitting a curve to the\ncounter-factual estimates of policy performance over time, without explicitly\nmodeling the underlying non-stationarity. The resulting algorithm amounts to a\nnon-uniform reweighting of past data, and we observe that minimizing\nperformance over some of the data from past episodes can be beneficial when\nsearching for a policy that maximizes future performance. We show that our\nalgorithm, called Prognosticator, is more robust to non-stationarity than two\nonline adaptation techniques, on three simulated problems motivated by\nreal-world applications.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 03:41:19 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 17:28:24 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 02:45:46 GMT"}, {"version": "v4", "created": "Mon, 21 Sep 2020 23:28:01 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Chandak", "Yash", ""], ["Theocharous", "Georgios", ""], ["Shankar", "Shiv", ""], ["White", "Martha", ""], ["Mahadevan", "Sridhar", ""], ["Thomas", "Philip S.", ""]]}, {"id": "2005.08164", "submitter": "Hui Li", "authors": "Chen Lin, Si Chen, Hui Li, Yanghua Xiao, Lianyun Li, Qian Yang", "title": "Attacking Recommender Systems with Augmented User Profiles", "comments": "CIKM 2020. 10 pages, 2 figures", "journal-ref": null, "doi": "10.1145/3340531.3411884", "report-no": null, "categories": "cs.IR cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation Systems (RS) have become an essential part of many online\nservices. Due to its pivotal role in guiding customers towards purchasing,\nthere is a natural motivation for unscrupulous parties to spoof RS for profits.\nIn this paper, we study the shilling attack: a subsistent and profitable attack\nwhere an adversarial party injects a number of user profiles to promote or\ndemote a target item. Conventional shilling attack models are based on simple\nheuristics that can be easily detected, or directly adopt adversarial attack\nmethods without a special design for RS. Moreover, the study on the attack\nimpact on deep learning based RS is missing in the literature, making the\neffects of shilling attack against real RS doubtful. We present a novel\nAugmented Shilling Attack framework (AUSH) and implement it with the idea of\nGenerative Adversarial Network. AUSH is capable of tailoring attacks against RS\naccording to budget and complex attack goals, such as targeting a specific user\ngroup. We experimentally show that the attack impact of AUSH is noticeable on a\nwide range of RS including both classic and modern deep learning based RS,\nwhile it is virtually undetectable by the state-of-the-art attack detection\nmodel.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 04:44:52 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 14:22:49 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Lin", "Chen", ""], ["Chen", "Si", ""], ["Li", "Hui", ""], ["Xiao", "Yanghua", ""], ["Li", "Lianyun", ""], ["Yang", "Qian", ""]]}, {"id": "2005.08170", "submitter": "Shashi Kant", "authors": "Fengzi Li, Shashi Kant, Shunichi Araki, Sumer Bangera, Swapna Samir\n  Shukla", "title": "Neural Networks for Fashion Image Classification and Visual Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss two potentially challenging problems faced by the ecommerce\nindustry. One relates to the problem faced by sellers while uploading pictures\nof products on the platform for sale and the consequent manual tagging\ninvolved. It gives rise to misclassifications leading to its absence from\nsearch results. The other problem concerns with the potential bottleneck in\nplacing orders when a customer may not know the right keywords but has a visual\nimpression of an image. An image based search algorithm can unleash the true\npotential of ecommerce by enabling customers to click a picture of an object\nand search for similar products without the need for typing. In this paper, we\nexplore machine learning algorithms which can help us solve both these\nproblems.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 05:25:41 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Li", "Fengzi", ""], ["Kant", "Shashi", ""], ["Araki", "Shunichi", ""], ["Bangera", "Sumer", ""], ["Shukla", "Swapna Samir", ""]]}, {"id": "2005.08177", "submitter": "Tyler Chang", "authors": "Tyler A. Chang and Anna N. Rafferty", "title": "Encodings of Source Syntax: Similarities in NMT Representations Across\n  Target Languages", "comments": "To appear at the 5th Workshop on Representation Learning for NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train neural machine translation (NMT) models from English to six target\nlanguages, using NMT encoder representations to predict ancestor constituent\nlabels of source language words. We find that NMT encoders learn similar source\nsyntax regardless of NMT target language, relying on explicit morphosyntactic\ncues to extract syntactic features from source sentences. Furthermore, the NMT\nencoders outperform RNNs trained directly on several of the constituent label\nprediction tasks, suggesting that NMT encoder representations can be used\neffectively for natural language tasks involving syntax. However, both the NMT\nencoders and the directly-trained RNNs learn substantially different syntactic\ninformation from a probabilistic context-free grammar (PCFG) parser. Despite\nlower overall accuracy scores, the PCFG often performs well on sentences for\nwhich the RNN-based models perform poorly, suggesting that RNN architectures\nare constrained in the types of syntax they can learn.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 06:41:32 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Chang", "Tyler A.", ""], ["Rafferty", "Anna N.", ""]]}, {"id": "2005.08189", "submitter": "Sezin Kircali Ata Dr.", "authors": "Sezin Kircali Ata, Yuan Fang, Min Wu, Jiaqi Shi, Chee Keong Kwoh and\n  Xiaoli Li", "title": "Multi-View Collaborative Network Embedding", "comments": "Accepted for publication in the ACM Transactions on Knowledge\n  Discovery from Data, TKDD", "journal-ref": "ACM Trans. Knowl. Discov. Data 15, 3, Article 39 (April 2021), 18\n  pages", "doi": "10.1145/3441450", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world networks often exist with multiple views, where each view\ndescribes one type of interaction among a common set of nodes. For example, on\na video-sharing network, while two user nodes are linked if they have common\nfavorite videos in one view, they can also be linked in another view if they\nshare common subscribers. Unlike traditional single-view networks, multiple\nviews maintain different semantics to complement each other. In this paper, we\npropose MANE, a multi-view network embedding approach to learn low-dimensional\nrepresentations. Similar to existing studies, MANE hinges on diversity and\ncollaboration - while diversity enables views to maintain their individual\nsemantics, collaboration enables views to work together. However, we also\ndiscover a novel form of second-order collaboration that has not been explored\npreviously, and further unify it into our framework to attain superior node\nrepresentations. Furthermore, as each view often has varying importance w.r.t.\ndifferent nodes, we propose MANE+, an attention-based extension of MANE to\nmodel node-wise view importance. Finally, we conduct comprehensive experiments\non three public, real-world multi-view networks, and the results demonstrate\nthat our models consistently outperform state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 08:12:53 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 14:34:41 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Ata", "Sezin Kircali", ""], ["Fang", "Yuan", ""], ["Wu", "Min", ""], ["Shi", "Jiaqi", ""], ["Kwoh", "Chee Keong", ""], ["Li", "Xiaoli", ""]]}, {"id": "2005.08209", "submitter": "Rudrabha Mukhopadhyay", "authors": "K R Prajwal, Rudrabha Mukhopadhyay, Vinay Namboodiri, C V Jawahar", "title": "Learning Individual Speaking Styles for Accurate Lip to Speech Synthesis", "comments": "10 pages (including references), 5 figures, Accepted in CVPR, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans involuntarily tend to infer parts of the conversation from lip\nmovements when the speech is absent or corrupted by external noise. In this\nwork, we explore the task of lip to speech synthesis, i.e., learning to\ngenerate natural speech given only the lip movements of a speaker.\nAcknowledging the importance of contextual and speaker-specific cues for\naccurate lip-reading, we take a different path from existing works. We focus on\nlearning accurate lip sequences to speech mappings for individual speakers in\nunconstrained, large vocabulary settings. To this end, we collect and release a\nlarge-scale benchmark dataset, the first of its kind, specifically to train and\nevaluate the single-speaker lip to speech task in natural settings. We propose\na novel approach with key design choices to achieve accurate, natural lip to\nspeech synthesis in such unconstrained scenarios for the first time. Extensive\nevaluation using quantitative, qualitative metrics and human evaluation shows\nthat our method is four times more intelligible than previous works in this\nspace. Please check out our demo video for a quick overview of the paper,\nmethod, and qualitative results.\nhttps://www.youtube.com/watch?v=HziA-jmlk_4&feature=youtu.be\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 10:29:19 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Prajwal", "K R", ""], ["Mukhopadhyay", "Rudrabha", ""], ["Namboodiri", "Vinay", ""], ["Jawahar", "C V", ""]]}, {"id": "2005.08225", "submitter": "Fanzhen Liu", "authors": "Fanzhen Liu, Shan Xue, Jia Wu, Chuan Zhou, Wenbin Hu, Cecile Paris,\n  Surya Nepal, Jian Yang, Philip S. Yu", "title": "Deep Learning for Community Detection: Progress, Challenges and\n  Opportunities", "comments": "Accepted Paper in the 29th International Joint Conference on\n  Artificial Intelligence (IJCAI 20), Survey Track", "journal-ref": "IJCAI 2020: 4981-4987", "doi": "10.24963/ijcai.2020/693", "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As communities represent similar opinions, similar functions, similar\npurposes, etc., community detection is an important and extremely useful tool\nin both scientific inquiry and data analytics. However, the classic methods of\ncommunity detection, such as spectral clustering and statistical inference, are\nfalling by the wayside as deep learning techniques demonstrate an increasing\ncapacity to handle high-dimensional graph data with impressive performance.\nThus, a survey of current progress in community detection through deep learning\nis timely. Structured into three broad research streams in this domain - deep\nneural networks, deep graph embedding, and graph neural networks, this article\nsummarizes the contributions of the various frameworks, models, and algorithms\nin each stream along with the current challenges that remain unsolved and the\nfuture research opportunities yet to be explored.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 11:22:11 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 09:34:17 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Liu", "Fanzhen", ""], ["Xue", "Shan", ""], ["Wu", "Jia", ""], ["Zhou", "Chuan", ""], ["Hu", "Wenbin", ""], ["Paris", "Cecile", ""], ["Nepal", "Surya", ""], ["Yang", "Jian", ""], ["Yu", "Philip S.", ""]]}, {"id": "2005.08226", "submitter": "Arnab Kumar Mondal", "authors": "Arnab Kumar Mondal, Arnab Bhattacharya, Sudipto Mukherjee, Prathosh\n  AP, Sreeram Kannan, Himanshu Asnani", "title": "C-MI-GAN : Estimation of Conditional Mutual Information using MinMax\n  formulation", "comments": "Updated for UAI, 2020 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of information theoretic quantities such as mutual information and\nits conditional variant has drawn interest in recent times owing to their\nmultifaceted applications. Newly proposed neural estimators for these\nquantities have overcome severe drawbacks of classical $k$NN-based estimators\nin high dimensions. In this work, we focus on conditional mutual information\n(CMI) estimation by utilizing its formulation as a minmax optimization problem.\nSuch a formulation leads to a joint training procedure similar to that of\ngenerative adversarial networks. We find that our proposed estimator provides\nbetter estimates than the existing approaches on a variety of simulated data\nsets comprising linear and non-linear relations between variables. As an\napplication of CMI estimation, we deploy our estimator for conditional\nindependence (CI) testing on real data and obtain better results than\nstate-of-the-art CI testers.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 11:22:12 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 06:02:58 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Mondal", "Arnab Kumar", ""], ["Bhattacharya", "Arnab", ""], ["Mukherjee", "Sudipto", ""], ["AP", "Prathosh", ""], ["Kannan", "Sreeram", ""], ["Asnani", "Himanshu", ""]]}, {"id": "2005.08230", "submitter": "Boris Knyazev", "authors": "Boris Knyazev, Harm de Vries, C\\u{a}t\\u{a}lina Cangea, Graham W.\n  Taylor, Aaron Courville, Eugene Belilovsky", "title": "Graph Density-Aware Losses for Novel Compositions in Scene Graph\n  Generation", "comments": "accepted at BMVC 2020, the code is available at\n  https://github.com/bknyaz/sgg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene graph generation (SGG) aims to predict graph-structured descriptions of\ninput images, in the form of objects and relationships between them. This task\nis becoming increasingly useful for progress at the interface of vision and\nlanguage. Here, it is important - yet challenging - to perform well on novel\n(zero-shot) or rare (few-shot) compositions of objects and relationships. In\nthis paper, we identify two key issues that limit such generalization. Firstly,\nwe show that the standard loss used in this task is unintentionally a function\nof scene graph density. This leads to the neglect of individual edges in large\nsparse graphs during training, even though these contain diverse few-shot\nexamples that are important for generalization. Secondly, the frequency of\nrelationships can create a strong bias in this task, such that a blind model\npredicting the most frequent relationship achieves good performance.\nConsequently, some state-of-the-art models exploit this bias to improve\nresults. We show that such models can suffer the most in their ability to\ngeneralize to rare compositions, evaluating two different models on the Visual\nGenome dataset and its more recent, improved version, GQA. To address these\nissues, we introduce a density-normalized edge loss, which provides more than a\ntwo-fold improvement in certain generalization metrics. Compared to other works\nin this direction, our enhancements require only a few lines of code and no\nadded computational cost. We also highlight the difficulty of accurately\nevaluating models using existing metrics, especially on zero/few shots, and\nintroduce a novel weighted metric.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 11:45:29 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 00:47:17 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Knyazev", "Boris", ""], ["de Vries", "Harm", ""], ["Cangea", "C\u0103t\u0103lina", ""], ["Taylor", "Graham W.", ""], ["Courville", "Aaron", ""], ["Belilovsky", "Eugene", ""]]}, {"id": "2005.08238", "submitter": "Zhibing Zhao", "authors": "Zhibing Zhao, Yingce Xia, Tao Qin, Lirong Xia, Tie-Yan Liu", "title": "Dual Learning: Theoretical Study and an Algorithmic Extension", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dual learning has been successfully applied in many machine learning\napplications including machine translation, image-to-image transformation, etc.\nThe high-level idea of dual learning is very intuitive: if we map an $x$ from\none domain to another and then map it back, we should recover the original $x$.\nAlthough its effectiveness has been empirically verified, theoretical\nunderstanding of dual learning is still very limited. In this paper, we aim at\nunderstanding why and when dual learning works. Based on our theoretical\nanalysis, we further extend dual learning by introducing more related mappings\nand propose multi-step dual learning, in which we leverage feedback signals\nfrom additional domains to improve the qualities of the mappings. We prove that\nmulti-step dual learn-ing can boost the performance of standard dual learning\nunder mild conditions. Experiments on WMT 14 English$\\leftrightarrow$German and\nMultiUNEnglish$\\leftrightarrow$French translations verify our theoretical\nfindings on dual learning, and the results on the translations among English,\nFrench, and Spanish of MultiUN demonstrate the effectiveness of multi-step dual\nlearning.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 12:14:35 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Zhao", "Zhibing", ""], ["Xia", "Yingce", ""], ["Qin", "Tao", ""], ["Xia", "Lirong", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2005.08245", "submitter": "Liming Jiang", "authors": "Liming Jiang, Yuanchang Xie, Danjue Chen, Tienan Li, Nicholas G. Evans", "title": "Dampen the Stop-and-Go Traffic with Connected and Automated Vehicles --\n  A Deep Reinforcement Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stop-and-go traffic poses many challenges to tranportation system, but its\nformation and mechanism are still under exploration.however, it has been proved\nthat by introducing Connected Automated Vehicles(CAVs) with carefully designed\ncontrollers one could dampen the stop-and-go waves in the vehicle fleet.\nInstead of using analytical model, this study adopts reinforcement learning to\ncontrol the behavior of CAV and put a single CAV at the 2nd position of a\nvehicle fleet with the purpose to dampen the speed oscillation from the fleet\nleader and help following human drivers adopt more smooth driving behavior. The\nresult show that our controller could decrease the spped oscillation of the CAV\nby 54% and 8%-28% for those following human-driven vehicles. Significant fuel\nconsumption savings are also observed. Additionally, the result suggest that\nCAVs may act as a traffic stabilizer if they choose to behave slightly\naltruistically.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 12:46:22 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Jiang", "Liming", ""], ["Xie", "Yuanchang", ""], ["Chen", "Danjue", ""], ["Li", "Tienan", ""], ["Evans", "Nicholas G.", ""]]}, {"id": "2005.08271", "submitter": "Vladimir Iashin", "authors": "Vladimir Iashin and Esa Rahtu", "title": "A Better Use of Audio-Visual Cues: Dense Video Captioning with Bi-modal\n  Transformer", "comments": "Accepted by BMVC 2020. More experiments. Code:\n  https://github.com/v-iashin/bmt Project page: https://v-iashin.github.io/bmt", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dense video captioning aims to localize and describe important events in\nuntrimmed videos. Existing methods mainly tackle this task by exploiting only\nvisual features, while completely neglecting the audio track. Only a few prior\nworks have utilized both modalities, yet they show poor results or demonstrate\nthe importance on a dataset with a specific domain. In this paper, we introduce\nBi-modal Transformer which generalizes the Transformer architecture for a\nbi-modal input. We show the effectiveness of the proposed model with audio and\nvisual modalities on the dense video captioning task, yet the module is capable\nof digesting any two modalities in a sequence-to-sequence task. We also show\nthat the pre-trained bi-modal encoder as a part of the bi-modal transformer can\nbe used as a feature extractor for a simple proposal generation module. The\nperformance is demonstrated on a challenging ActivityNet Captions dataset where\nour model achieves outstanding performance. The code is available:\nv-iashin.github.io/bmt\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 15:00:05 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 09:17:48 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Iashin", "Vladimir", ""], ["Rahtu", "Esa", ""]]}, {"id": "2005.08281", "submitter": "Francesc Wilhelmi", "authors": "Francesc Wilhelmi, Marc Carrascosa, Cristina Cano, Anders Jonsson,\n  Vishnu Ram, Boris Bellalta", "title": "Usage of Network Simulators in Machine-Learning-Assisted 5G/6G Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Without any doubt, Machine Learning (ML) will be an important driver of\nfuture communications due to its foreseen performance when applied to complex\nproblems. However, the application of ML to networking systems raises concerns\namong network operators and other stakeholders, especially regarding\ntrustworthiness and reliability. In this paper, we devise the role of network\nsimulators for bridging the gap between ML and communications systems. In\nparticular, we present an architectural integration of simulators in ML-aware\nnetworks for training, testing, and validating ML models before being applied\nto the operative network. Moreover, we provide insights on the main challenges\nresulting from this integration, and then give hints discussing how they can be\novercome. Finally, we illustrate the integration of network simulators into\nML-assisted communications through a proof-of-concept testbed implementation of\na residential Wi-Fi network.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 15:32:59 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 10:34:33 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Wilhelmi", "Francesc", ""], ["Carrascosa", "Marc", ""], ["Cano", "Cristina", ""], ["Jonsson", "Anders", ""], ["Ram", "Vishnu", ""], ["Bellalta", "Boris", ""]]}, {"id": "2005.08302", "submitter": "Patrick Schwab", "authors": "Patrick Schwab, August DuMont Sch\\\"utte, Benedikt Dietz, Stefan Bauer", "title": "Clinical Predictive Models for COVID-19: Systematic Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coronavirus Disease 2019 (COVID-19) is a rapidly emerging respiratory disease\ncaused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Due\nto the rapid human-to-human transmission of SARS-CoV-2, many healthcare systems\nare at risk of exceeding their healthcare capacities, in particular in terms of\nSARS-CoV-2 tests, hospital and intensive care unit (ICU) beds and mechanical\nventilators. Predictive algorithms could potentially ease the strain on\nhealthcare systems by identifying those who are most likely to receive a\npositive SARS-CoV-2 test, be hospitalised or admitted to the ICU. Here, we\nstudy clinical predictive models that estimate, using machine learning and\nbased on routinely collected clinical data, which patients are likely to\nreceive a positive SARS-CoV-2 test, require hospitalisation or intensive care.\nTo evaluate the predictive performance of our models, we perform a\nretrospective evaluation on clinical and blood analysis data from a cohort of\n5644 patients. Our experimental results indicate that our predictive models\nidentify (i) patients that test positive for SARS-CoV-2 a priori at a\nsensitivity of 75% (95% CI: 67%, 81%) and a specificity of 49% (95% CI: 46%,\n51%), (ii) SARS-CoV-2 positive patients that require hospitalisation with 0.92\nAUC (95% CI: 0.81, 0.98), and (iii) SARS-CoV-2 positive patients that require\ncritical care with 0.98 AUC (95% CI: 0.95, 1.00). In addition, we determine\nwhich clinical features are predictive to what degree for each of the\naforementioned clinical tasks. Our results indicate that predictive models\ntrained on routinely collected clinical data could be used to predict clinical\npathways for COVID-19, and therefore help inform care and prioritise resources.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 17:10:39 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 20:21:29 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Schwab", "Patrick", ""], ["Sch\u00fctte", "August DuMont", ""], ["Dietz", "Benedikt", ""], ["Bauer", "Stefan", ""]]}, {"id": "2005.08304", "submitter": "Kwangjun Ahn", "authors": "Kwangjun Ahn", "title": "From Proximal Point Method to Nesterov's Acceleration", "comments": "14 pages; Section 4 updated; Remark 5 added; comments would be\n  appreciated!", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proximal point method (PPM) is a fundamental method in optimization that\nis often used as a building block for fast optimization algorithms. In this\nwork, building on a recent work by Defazio (2019), we provide a complete\nunderstanding of Nesterov's accelerated gradient method (AGM) by establishing\nquantitative and analytical connections between PPM and AGM. The main\nobservation in this paper is that AGM is in fact equal to a simple\napproximation of PPM, which results in an elementary derivation of the\nmysterious updates of AGM as well as its step sizes. This connection also leads\nto a conceptually simple analysis of AGM based on the standard analysis of PPM.\nThis view naturally extends to the strongly convex case and also motivates\nother accelerated methods for practically relevant settings.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 17:17:18 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 16:36:09 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Ahn", "Kwangjun", ""]]}, {"id": "2005.08307", "submitter": "Alessia Bertugli", "authors": "Alessia Bertugli, Simone Calderara, Pasquale Coscia, Lamberto Ballan,\n  Rita Cucchiara", "title": "AC-VRNN: Attentive Conditional-VRNN for Multi-Future Trajectory\n  Prediction", "comments": "Accepted at Computer Vision and Image Understanding (CVIU)", "journal-ref": null, "doi": "10.1016/j.cviu.2021.103245", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anticipating human motion in crowded scenarios is essential for developing\nintelligent transportation systems, social-aware robots and advanced video\nsurveillance applications. A key component of this task is represented by the\ninherently multi-modal nature of human paths which makes socially acceptable\nmultiple futures when human interactions are involved. To this end, we propose\na generative architecture for multi-future trajectory predictions based on\nConditional Variational Recurrent Neural Networks (C-VRNNs). Conditioning\nmainly relies on prior belief maps, representing most likely moving directions\nand forcing the model to consider past observed dynamics in generating future\npositions. Human interactions are modeled with a graph-based attention\nmechanism enabling an online attentive hidden state refinement of the recurrent\nestimation. To corroborate our model, we perform extensive experiments on\npublicly-available datasets (e.g., ETH/UCY, Stanford Drone Dataset, STATS\nSportVU NBA, Intersection Drone Dataset and TrajNet++) and demonstrate its\neffectiveness in crowded scenes compared to several state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 17:21:23 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 08:23:15 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Bertugli", "Alessia", ""], ["Calderara", "Simone", ""], ["Coscia", "Pasquale", ""], ["Ballan", "Lamberto", ""], ["Cucchiara", "Rita", ""]]}, {"id": "2005.08314", "submitter": "Pengcheng Yin", "authors": "Pengcheng Yin, Graham Neubig, Wen-tau Yih, Sebastian Riedel", "title": "TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data", "comments": "To Appear at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent years have witnessed the burgeoning of pretrained language models\n(LMs) for text-based natural language (NL) understanding tasks. Such models are\ntypically trained on free-form NL text, hence may not be suitable for tasks\nlike semantic parsing over structured data, which require reasoning over both\nfree-form NL questions and structured tabular data (e.g., database tables). In\nthis paper we present TaBERT, a pretrained LM that jointly learns\nrepresentations for NL sentences and (semi-)structured tables. TaBERT is\ntrained on a large corpus of 26 million tables and their English contexts. In\nexperiments, neural semantic parsers using TaBERT as feature representation\nlayers achieve new best results on the challenging weakly-supervised semantic\nparsing benchmark WikiTableQuestions, while performing competitively on the\ntext-to-SQL dataset Spider. Implementation of the model will be available at\nhttp://fburl.com/TaBERT .\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 17:26:40 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Yin", "Pengcheng", ""], ["Neubig", "Graham", ""], ["Yih", "Wen-tau", ""], ["Riedel", "Sebastian", ""]]}, {"id": "2005.08321", "submitter": "Mahdieh Abbasi", "authors": "Mahdieh Abbasi and Arezoo Rajabi and Christian Gagne and Rakesh B.\n  Bobba", "title": "Toward Adversarial Robustness by Diversity in an Ensemble of Specialized\n  Deep Neural Networks", "comments": "Published by Springer in the Lecture Notes in Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim at demonstrating the influence of diversity in the ensemble of CNNs on\nthe detection of black-box adversarial instances and hardening the generation\nof white-box adversarial attacks. To this end, we propose an ensemble of\ndiverse specialized CNNs along with a simple voting mechanism. The diversity in\nthis ensemble creates a gap between the predictive confidences of adversaries\nand those of clean samples, making adversaries detectable. We then analyze how\ndiversity in such an ensemble of specialists may mitigate the risk of the\nblack-box and white-box adversarial examples. Using MNIST and CIFAR-10, we\nempirically verify the ability of our ensemble to detect a large portion of\nwell-known black-box adversarial examples, which leads to a significant\nreduction in the risk rate of adversaries, at the expense of a small increase\nin the risk rate of clean samples. Moreover, we show that the success rate of\ngenerating white-box attacks by our ensemble is remarkably decreased compared\nto a vanilla CNN and an ensemble of vanilla CNNs, highlighting the beneficial\nrole of diversity in the ensemble for developing more robust models.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 17:54:49 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Abbasi", "Mahdieh", ""], ["Rajabi", "Arezoo", ""], ["Gagne", "Christian", ""], ["Bobba", "Rakesh B.", ""]]}, {"id": "2005.08323", "submitter": "Liming Zhang", "authors": "Liming Zhang, Liang Zhao, Shan Qin, Dieter Pfoser", "title": "TG-GAN: Continuous-time Temporal Graph Generation with Deep Generative\n  Models", "comments": null, "journal-ref": "thewebconf 2021", "doi": "10.1145/3442381.3449818", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent deep generative models for static graphs that are now being\nactively developed have achieved significant success in areas such as molecule\ndesign. However, many real-world problems involve temporal graphs whose\ntopology and attribute values evolve dynamically over time, including important\napplications such as protein folding, human mobility networks, and social\nnetwork growth. As yet, deep generative models for temporal graphs are not yet\nwell understood and existing techniques for static graphs are not adequate for\ntemporal graphs since they cannot 1) encode and decode continuously-varying\ngraph topology chronologically, 2) enforce validity via temporal constraints,\nor 3) ensure efficiency for information-lossless temporal resolution. To\naddress these challenges, we propose a new model, called ``Temporal Graph\nGenerative Adversarial Network'' (TG-GAN) for continuous-time temporal graph\ngeneration, by modeling the deep generative process for truncated temporal\nrandom walks and their compositions. Specifically, we first propose a novel\ntemporal graph generator that jointly model truncated edge sequences, time\nbudgets, and node attributes, with novel activation functions that enforce\ntemporal validity constraints under recurrent architecture. In addition, a new\ntemporal graph discriminator is proposed, which combines time and node encoding\noperations over a recurrent architecture to distinguish the generated sequences\nfrom the real ones sampled by a newly-developed truncated temporal random walk\nsampler. Extensive experiments on both synthetic and real-world datasets\ndemonstrate TG-GAN significantly outperforms the comparison methods in\nefficiency and effectiveness.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 17:59:12 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 19:47:40 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Zhang", "Liming", ""], ["Zhao", "Liang", ""], ["Qin", "Shan", ""], ["Pfoser", "Dieter", ""]]}, {"id": "2005.08334", "submitter": "Fernando Llorente Fern\\'andez", "authors": "Fernando Llorente, Luca Martino, David Delgado, Javier Lopez-Santiago", "title": "Marginal likelihood computation for model selection and hypothesis\n  testing: an extensive review", "comments": "Keywords: Marginal likelihood, Bayesian evidence, numerical\n  integration, model selection, hypothesis testing, quadrature rules,\n  double-intractable posteriors, partition functions", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is an up-to-date introduction to, and overview of, marginal likelihood\ncomputation for model selection and hypothesis testing. Computing normalizing\nconstants of probability models (or ratio of constants) is a fundamental issue\nin many applications in statistics, applied mathematics, signal processing and\nmachine learning. This article provides a comprehensive study of the\nstate-of-the-art of the topic. We highlight limitations, benefits, connections\nand differences among the different techniques. Problems and possible solutions\nwith the use of improper priors are also described. Some of the most relevant\nmethodologies are compared through theoretical comparisons and numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 18:31:58 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 11:29:04 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Llorente", "Fernando", ""], ["Martino", "Luca", ""], ["Delgado", "David", ""], ["Lopez-Santiago", "Javier", ""]]}, {"id": "2005.08350", "submitter": "Mahboobeh Parsapoor", "authors": "M.Parsapoor, U.Bilstrup, B.Svensson", "title": "Forecasting Solar Activity with Two Computational Intelligence Models (A\n  Comparative Study)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solar activity It is vital to accurately predict solar activity, in order to\ndecrease the plausible damage of electronic equipment in the event of a large\nhigh-intensity solar eruption. Recently, we have proposed BELFIS (Brain\nEmotional Learning-based Fuzzy Inference System) as a tool for the forecasting\nof chaotic systems. The structure of BELFIS is designed based on the neural\nstructure of fear conditioning. The function of BELFIS is implemented by\nassigning adaptive networks to the components of the BELFIS structure. This\npaper especially focuses on performance evaluation of BELFIS as a predictor by\nforecasting solar cycles 16 to 24. The performance of BELFIS is compared with\nother computational models used for this purpose, and in particular with\nadaptive neuro-fuzzy inference system (ANFIS).\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 19:29:15 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Parsapoor", "M.", ""], ["Bilstrup", "U.", ""], ["Svensson", "B.", ""]]}, {"id": "2005.08357", "submitter": "Rishikesh Ranade", "authors": "Rishikesh Ranade, Chris Hill and Jay Pathak", "title": "DiscretizationNet: A Machine-Learning based solver for Navier-Stokes\n  Equations using Finite Volume Discretization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few decades, existing Partial Differential Equation (PDE)\nsolvers have demonstrated a tremendous success in solving complex, non-linear\nPDEs. Although accurate, these PDE solvers are computationally costly. With the\nadvances in Machine Learning (ML) technologies, there has been a significant\nincrease in the research of using ML to solve PDEs. The goal of this work is to\ndevelop an ML-based PDE solver, that couples important characteristics of\nexisting PDE solvers with ML technologies. The two solver characteristics that\nhave been adopted in this work are: 1) the use of discretization-based schemes\nto approximate spatio-temporal partial derivatives and 2) the use of iterative\nalgorithms to solve linearized PDEs in their discrete form. In the presence of\nhighly non-linear, coupled PDE solutions, these strategies can be very\nimportant in achieving good accuracy, better stability and faster convergence.\nOur ML-solver, DiscretizationNet, employs a generative CNN-based\nencoder-decoder model with PDE variables as both input and output features.\nDuring training, the discretization schemes are implemented inside the\ncomputational graph to enable faster GPU computation of PDE residuals, which\nare used to update network weights that result into converged solutions. A\nnovel iterative capability is implemented during the network training to\nimprove the stability and convergence of the ML-solver. The ML-Solver is\ndemonstrated to solve the steady, incompressible Navier-Stokes equations in 3-D\nfor several cases such as, lid-driven cavity, flow past a cylinder and\nconjugate heat transfer.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 19:54:19 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Ranade", "Rishikesh", ""], ["Hill", "Chris", ""], ["Pathak", "Jay", ""]]}, {"id": "2005.08374", "submitter": "Solmaz Niknam", "authors": "Solmaz Niknam, Abhishek Roy, Harpreet S. Dhillon, Sukhdeep Singh,\n  Rahul Banerji, Jeffery H. Reed, Navrati Saxena, Seungil Yoon", "title": "Intelligent O-RAN for Beyond 5G and 6G Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on the principles of openness and intelligence, there has been a\nconcerted global effort from the operators towards enhancing the radio access\nnetwork (RAN) architecture. The objective is to build an operator-defined RAN\narchitecture (and associated interfaces) on open hardware that provides\nintelligent radio control for beyond fifth generation (5G) as well as future\nsixth generation (6G) wireless networks. Specifically, the open-radio access\nnetwork (O-RAN) alliance has been formed by merging xRAN forum and C-RAN\nalliance to formally define the requirements that would help achieve this\nobjective. Owing to the importance of O-RAN in the current wireless landscape,\nthis article provides an introduction to the concepts, principles, and\nrequirements of the Open RAN as specified by the O-RAN alliance. In order to\nillustrate the role of intelligence in O-RAN, we propose an intelligent radio\nresource management scheme to handle traffic congestion and demonstrate its\nefficacy on a real-world dataset obtained from a large operator. A high-level\narchitecture of this deployment scenario that is compliant with the O-RAN\nrequirements is also discussed. The article concludes with key technical\nchallenges and open problems for future research and development.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 21:20:48 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Niknam", "Solmaz", ""], ["Roy", "Abhishek", ""], ["Dhillon", "Harpreet S.", ""], ["Singh", "Sukhdeep", ""], ["Banerji", "Rahul", ""], ["Reed", "Jeffery H.", ""], ["Saxena", "Navrati", ""], ["Yoon", "Seungil", ""]]}, {"id": "2005.08377", "submitter": "Sumegha Garg", "authors": "Mark Braverman and Sumegha Garg", "title": "The Role of Randomness and Noise in Strategic Classification", "comments": "22 pages. Appeared in FORC, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of designing optimal classifiers in the strategic\nclassification setting, where the classification is part of a game in which\nplayers can modify their features to attain a favorable classification outcome\n(while incurring some cost). Previously, the problem has been considered from a\nlearning-theoretic perspective and from the algorithmic fairness perspective.\nOur main contributions include 1. Showing that if the objective is to maximize\nthe efficiency of the classification process (defined as the accuracy of the\noutcome minus the sunk cost of the qualified players manipulating their\nfeatures to gain a better outcome), then using randomized classifiers (that is,\nones where the probability of a given feature vector to be accepted by the\nclassifier is strictly between 0 and 1) is necessary. 2. Showing that in many\nnatural cases, the imposed optimal solution (in terms of efficiency) has the\nstructure where players never change their feature vectors (the randomized\nclassifier is structured in a way, such that the gain in the probability of\nbeing classified as a 1 does not justify the expense of changing one's\nfeatures). 3. Observing that the randomized classification is not a stable\nbest-response from the classifier's viewpoint, and that the classifier doesn't\nbenefit from randomized classifiers without creating instability in the system.\n4. Showing that in some cases, a noisier signal leads to better equilibria\noutcomes -- improving both accuracy and fairness when more than one\nsubpopulation with different feature adjustment costs are involved. This is\ninteresting from a policy perspective, since it is hard to force institutions\nto stick to a particular randomized classification strategy (especially in a\ncontext of a market with multiple classifiers), but it is possible to alter the\ninformation environment to make the feature signals inherently noisier.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 21:49:41 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Braverman", "Mark", ""], ["Garg", "Sumegha", ""]]}, {"id": "2005.08392", "submitter": "Yu-An Chung", "authors": "Yu-An Chung, Hao Tang, James Glass", "title": "Vector-Quantized Autoregressive Predictive Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoregressive Predictive Coding (APC), as a self-supervised objective, has\nenjoyed success in learning representations from large amounts of unlabeled\ndata, and the learned representations are rich for many downstream tasks.\nHowever, the connection between low self-supervised loss and strong performance\nin downstream tasks remains unclear. In this work, we propose Vector-Quantized\nAutoregressive Predictive Coding (VQ-APC), a novel model that produces\nquantized representations, allowing us to explicitly control the amount of\ninformation encoded in the representations. By studying a sequence of\nincreasingly limited models, we reveal the constituents of the learned\nrepresentations. In particular, we confirm the presence of information with\nprobing tasks, while showing the absence of information with mutual\ninformation, uncovering the model's preference in preserving speech information\nas its capacity becomes constrained. We find that there exists a point where\nphonetic and speaker information are amplified to maximize a self-supervised\nobjective. As a byproduct, the learned codes for a particular model capacity\ncorrespond well to English phones.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 23:06:09 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Chung", "Yu-An", ""], ["Tang", "Hao", ""], ["Glass", "James", ""]]}, {"id": "2005.08413", "submitter": "Chiranjib Saha", "authors": "Keerthana Bhogi, Chiranjib Saha, and Harpreet S. Dhillon", "title": "Learning on a Grassmann Manifold: CSI Quantization for Massive MIMO\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the design of beamforming codebooks that maximize the\naverage normalized beamforming gain for any underlying channel distribution.\nWhile the existing techniques use statistical channel models, we utilize a\nmodel-free data-driven approach with foundations in machine learning to\ngenerate beamforming codebooks that adapt to the surrounding propagation\nconditions. The key technical contribution lies in reducing the codebook design\nproblem to an unsupervised clustering problem on a Grassmann manifold where the\ncluster centroids form the finite-sized beamforming codebook for the channel\nstate information (CSI), which can be efficiently solved using K-means\nclustering. This approach is extended to develop a remarkably efficient\nprocedure for designing product codebooks for full-dimension (FD)\nmultiple-input multiple-output (MIMO) systems with uniform planar array (UPA)\nantennas. Simulation results demonstrate the capability of the proposed design\ncriterion in learning the codebooks, reducing the codebook size and producing\nnoticeably higher beamforming gains compared to the existing state-of-the-art\nCSI quantization techniques.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 01:01:36 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Bhogi", "Keerthana", ""], ["Saha", "Chiranjib", ""], ["Dhillon", "Harpreet S.", ""]]}, {"id": "2005.08419", "submitter": "Zhenyu Yuan", "authors": "Zhenyu Yuan, Yuxin Jiang, Jingjing Li, Handong Huang", "title": "Hybrid-DNNs: Hybrid Deep Neural Networks for Mixed Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid development of big data and high-performance computing have encouraged\nexplosive studies of deep learning in geoscience. However, most studies only\ntake single-type data as input, frittering away invaluable multisource,\nmulti-scale information. We develop a general architecture of hybrid deep\nneural networks (HDNNs) to support mixed inputs. Regarding as a combination of\nfeature learning and target learning, the new proposed networks provide great\ncapacity in high-hierarchy feature extraction and in-depth data mining.\nFurthermore, the hybrid architecture is an aggregation of multiple networks,\ndemonstrating good flexibility and wide applicability. The configuration of\nmultiple networks depends on application tasks and varies with inputs and\ntargets. Concentrating on reservoir production prediction, a specific HDNN\nmodel is configured and applied to an oil development block. Considering their\ncontributions to hydrocarbon production, core photos, logging images and\ncurves, geologic and engineering parameters can all be taken as inputs. After\npreprocessing, the mixed inputs are prepared as regular-sampled structural and\nnumerical data. For feature learning, convolutional neural networks (CNN) and\nmultilayer perceptron (MLP) network are configured to separately process\nstructural and numerical inputs. Learned features are then concatenated and fed\nto subsequent networks for target learning. Comparison with typical MLP model\nand CNN model highlights the superiority of proposed HDNN model with high\naccuracy and good generalization.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 01:40:48 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Yuan", "Zhenyu", ""], ["Jiang", "Yuxin", ""], ["Li", "Jingjing", ""], ["Huang", "Handong", ""]]}, {"id": "2005.08430", "submitter": "Young-Eun Lee", "authors": "Young-Eun Lee and Minji Lee and Seong-Whan Lee", "title": "Reconstructing ERP Signals Using Generative Adversarial Networks for\n  Mobile Brain-Machine Interface", "comments": "Submitted to IEEE International Conference on System, Man, and\n  Cybernetics (SMC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Practical brain-machine interfaces have been widely studied to accurately\ndetect human intentions using brain signals in the real world. However, the\nelectroencephalography (EEG) signals are distorted owing to the artifacts such\nas walking and head movement, so brain signals may be large in amplitude rather\nthan desired EEG signals. Due to these artifacts, detecting accurately human\nintention in the mobile environment is challenging. In this paper, we proposed\nthe reconstruction framework based on generative adversarial networks using the\nevent-related potentials (ERP) during walking. We used a pre-trained\nconvolutional encoder to represent latent variables and reconstructed ERP\nthrough the generative model which shape similar to the opposite of encoder.\nFinally, the ERP was classified using the discriminative model to demonstrate\nthe validity of our proposed framework. As a result, the reconstructed signals\nhad important components such as N200 and P300 similar to ERP during standing.\nThe accuracy of reconstructed EEG was similar to raw noisy EEG signals during\nwalking. The signal-to-noise ratio of reconstructed EEG was significantly\nincreased as 1.3. The loss of the generative model was 0.6301, which is\ncomparatively low, which means training generative model had high performance.\nThe reconstructed ERP consequentially showed an improvement in classification\nperformance during walking through the effects of noise reduction. The proposed\nframework could help recognize human intention based on the brain-machine\ninterface even in the mobile environment.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 02:39:16 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Lee", "Young-Eun", ""], ["Lee", "Minji", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2005.08431", "submitter": "Gengyan Zhao", "authors": "Gengyan Zhao, Gyujoon Hwang, Cole J. Cook, Fang Liu, Mary E. Meyerand\n  and Rasmus M. Birn", "title": "Deep Learning and Bayesian Deep Learning Based Gender Prediction in\n  Multi-Scale Brain Functional Connectivity", "comments": "40 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain gender differences have been known for a long time and are the possible\nreason for many psychological, psychiatric and behavioral differences between\nmales and females. Predicting genders from brain functional connectivity (FC)\ncan build the relationship between brain activities and gender, and extracting\nimportant gender related FC features from the prediction model offers a way to\ninvestigate the brain gender difference. Current predictive models applied to\ngender prediction demonstrate good accuracies, but usually extract individual\nfunctional connections instead of connectivity patterns in the whole\nconnectivity matrix as features. In addition, current models often omit the\neffect of the input brain FC scale on prediction and cannot give any model\nuncertainty information. Hence, in this study we propose to predict gender from\nmultiple scales of brain FC with deep learning, which can extract full FC\npatterns as features. We further develop the understanding of the feature\nextraction mechanism in deep neural network (DNN) and propose a DNN feature\nranking method to extract the highly important features based on their\ncontributions to the prediction. Moreover, we apply Bayesian deep learning to\nthe brain FC gender prediction, which as a probabilistic model can not only\nmake accurate predictions but also generate model uncertainty for each\nprediction. Experiments were done on the high-quality Human Connectome Project\nS1200 release dataset comprising the resting state functional MRI data of 1003\nhealthy adults. First, DNN reaches 83.0%, 87.6%, 92.0%, 93.5% and 94.1%\naccuracies respectively with the FC input derived from 25, 50, 100, 200, 300\nindependent component analysis (ICA) components. DNN outperforms the\nconventional machine learning methods on the 25-ICA-component scale FC, but the\nlinear machine learning method catches up as the number of ICA components\nincreases...\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 02:43:26 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Zhao", "Gengyan", ""], ["Hwang", "Gyujoon", ""], ["Cook", "Cole J.", ""], ["Liu", "Fang", ""], ["Meyerand", "Mary E.", ""], ["Birn", "Rasmus M.", ""]]}, {"id": "2005.08435", "submitter": "Sara Mohammadinejad", "authors": "Sara Mohammadinejad, Jyotirmoy V. Deshmukh, Aniruddh G. Puranic", "title": "Mining Environment Assumptions for Cyber-Physical System Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many complex cyber-physical systems can be modeled as heterogeneous\ncomponents interacting with each other in real-time. We assume that the\ncorrectness of each component can be specified as a requirement satisfied by\nthe output signals produced by the component, and that such an output guarantee\nis expressed in a real-time temporal logic such as Signal Temporal Logic (STL).\nIn this paper, we hypothesize that a large subset of input signals for which\nthe corresponding output signals satisfy the output requirement can also be\ncompactly described using an STL formula that we call the environment\nassumption. We propose an algorithm to mine such an environment assumption\nusing a supervised learning technique. Essentially, our algorithm treats the\nenvironment assumption as a classifier that labels input signals as good if the\ncorresponding output signal satisfies the output requirement, and as bad\notherwise. Our learning method simultaneously learns the structure of the STL\nformula as well as the values of the numeric constants appearing in the\nformula. To achieve this, we combine a procedure to systematically enumerate\ncandidate Parametric STL (PSTL) formulas, with a decision-tree based approach\nto learn parameter values. We demonstrate experimental results on real world\ndata from several domains including transportation and health care.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 03:05:21 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Mohammadinejad", "Sara", ""], ["Deshmukh", "Jyotirmoy V.", ""], ["Puranic", "Aniruddh G.", ""]]}, {"id": "2005.08442", "submitter": "Snehanshu Saha", "authors": "Shailesh Sridhar, Snehanshu Saha, Azhar Shaikh, Rahul Yedida, Sriparna\n  Saha", "title": "Parsimonious Computing: A Minority Training Regime for Effective\n  Prediction in Large Microarray Expression Data Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rigorous mathematical investigation of learning rates used in\nback-propagation in shallow neural networks has become a necessity. This is\nbecause experimental evidence needs to be endorsed by a theoretical background.\nSuch theory may be helpful in reducing the volume of experimental effort to\naccomplish desired results. We leveraged the functional property of Mean Square\nError, which is Lipschitz continuous to compute learning rate in shallow neural\nnetworks. We claim that our approach reduces tuning efforts, especially when a\nsignificant corpus of data has to be handled. We achieve remarkable improvement\nin saving computational cost while surpassing prediction accuracy reported in\nliterature. The learning rate, proposed here, is the inverse of the Lipschitz\nconstant. The work results in a novel method for carrying out gene expression\ninference on large microarray data sets with a shallow architecture constrained\nby limited computing resources. A combination of random sub-sampling of the\ndataset, an adaptive Lipschitz constant inspired learning rate and a new\nactivation function, A-ReLU helped accomplish the results reported in the\npaper.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 03:45:05 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Sridhar", "Shailesh", ""], ["Saha", "Snehanshu", ""], ["Shaikh", "Azhar", ""], ["Yedida", "Rahul", ""], ["Saha", "Sriparna", ""]]}, {"id": "2005.08449", "submitter": "Di Hu", "authors": "Di Hu, Xuhong Li, Lichao Mou, Pu Jin, Dong Chen, Liping Jing,\n  Xiaoxiang Zhu, Dejing Dou", "title": "Cross-Task Transfer for Geotagged Audiovisual Aerial Scene Recognition", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aerial scene recognition is a fundamental task in remote sensing and has\nrecently received increased interest. While the visual information from\noverhead images with powerful models and efficient algorithms yields\nconsiderable performance on scene recognition, it still suffers from the\nvariation of ground objects, lighting conditions etc. Inspired by the\nmulti-channel perception theory in cognition science, in this paper, for\nimproving the performance on the aerial scene recognition, we explore a novel\naudiovisual aerial scene recognition task using both images and sounds as\ninput. Based on an observation that some specific sound events are more likely\nto be heard at a given geographic location, we propose to exploit the knowledge\nfrom the sound events to improve the performance on the aerial scene\nrecognition. For this purpose, we have constructed a new dataset named AuDio\nVisual Aerial sceNe reCognition datasEt (ADVANCE). With the help of this\ndataset, we evaluate three proposed approaches for transferring the sound event\nknowledge to the aerial scene recognition task in a multimodal learning\nframework, and show the benefit of exploiting the audio information for the\naerial scene recognition. The source code is publicly available for\nreproducibility purposes.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 04:14:16 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 03:33:17 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Hu", "Di", ""], ["Li", "Xuhong", ""], ["Mou", "Lichao", ""], ["Jin", "Pu", ""], ["Chen", "Dong", ""], ["Jing", "Liping", ""], ["Zhu", "Xiaoxiang", ""], ["Dou", "Dejing", ""]]}, {"id": "2005.08454", "submitter": "Bushra Sabir", "authors": "Bushra Sabir (University of Adelaide, CREST - The Centre for Research\n  on Engineering Software Technologies, CSIROs Data61) and M. Ali Babar\n  (University of Adelaide, CREST - The Centre for Research on Engineering\n  Software Technologies) and Raj Gaire (CSIROs Data61)", "title": "An Evasion Attack against ML-based Phishing URL Detectors", "comments": "Draft for ACM TOPs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Over the year, Machine Learning Phishing URL classification\n(MLPU) systems have gained tremendous popularity to detect phishing URLs\nproactively. Despite this vogue, the security vulnerabilities of MLPUs remain\nmostly unknown. Aim: To address this concern, we conduct a study to understand\nthe test time security vulnerabilities of the state-of-the-art MLPU systems,\naiming at providing guidelines for the future development of these systems.\nMethod: In this paper, we propose an evasion attack framework against MLPU\nsystems. To achieve this, we first develop an algorithm to generate adversarial\nphishing URLs. We then reproduce 41 MLPU systems and record their baseline\nperformance. Finally, we simulate an evasion attack to evaluate these MLPU\nsystems against our generated adversarial URLs. Results: In comparison to\nprevious works, our attack is: (i) effective as it evades all the models with\nan average success rate of 66% and 85% for famous (such as Netflix, Google) and\nless popular phishing targets (e.g., Wish, JBHIFI, Officeworks) respectively;\n(ii) realistic as it requires only 23ms to produce a new adversarial URL\nvariant that is available for registration with a median cost of only\n$11.99/year. We also found that popular online services such as Google\nSafeBrowsing and VirusTotal are unable to detect these URLs. (iii) We find that\nAdversarial training (successful defence against evasion attack) does not\nsignificantly improve the robustness of these systems as it decreases the\nsuccess rate of our attack by only 6% on average for all the models. (iv)\nFurther, we identify the security vulnerabilities of the considered MLPU\nsystems. Our findings lead to promising directions for future research.\nConclusion: Our study not only illustrate vulnerabilities in MLPU systems but\nalso highlights implications for future study towards assessing and improving\nthese systems.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 04:24:42 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Sabir", "Bushra", "", "University of Adelaide, CREST - The Centre for Research\n  on Engineering Software Technologies, CSIROs Data61"], ["Babar", "M. Ali", "", "University of Adelaide, CREST - The Centre for Research on Engineering\n  Software Technologies"], ["Gaire", "Raj", "", "CSIROs Data61"]]}, {"id": "2005.08467", "submitter": "Haitao Liu", "authors": "Haitao Liu, Yew-Soon Ong, Xiaomo Jiang, Xiaofang Wang", "title": "Deep Latent-Variable Kernel Learning", "comments": "13 pages, 8 figures, preprint under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep kernel learning (DKL) leverages the connection between Gaussian process\n(GP) and neural networks (NN) to build an end-to-end, hybrid model. It combines\nthe capability of NN to learn rich representations under massive data and the\nnon-parametric property of GP to achieve automatic regularization that\nincorporates a trade-off between model fit and model complexity. However, the\ndeterministic encoder may weaken the model regularization of the following GP\npart, especially on small datasets, due to the free latent representation. We\ntherefore present a complete deep latent-variable kernel learning (DLVKL) model\nwherein the latent variables perform stochastic encoding for regularized\nrepresentation. We further enhance the DLVKL from two aspects: (i) the\nexpressive variational posterior through neural stochastic differential\nequation (NSDE) to improve the approximation quality, and (ii) the hybrid prior\ntaking knowledge from both the SDE prior and the posterior to arrive at a\nflexible trade-off. Intensive experiments imply that the DLVKL-NSDE performs\nsimilarly to the well calibrated GP on small datasets, and outperforms existing\ndeep GPs on large datasets.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 05:55:08 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 04:46:29 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Liu", "Haitao", ""], ["Ong", "Yew-Soon", ""], ["Jiang", "Xiaomo", ""], ["Wang", "Xiaofang", ""]]}, {"id": "2005.08479", "submitter": "Wenjing Fang", "authors": "Wenjing Fang, Chaochao Chen, Jin Tan, Chaofan Yu, Yufei Lu, Li Wang,\n  Lei Wang, Jun Zhou and Alex X", "title": "A Hybrid-Domain Framework for Secure Gradient Tree Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient tree boosting (e.g. XGB) is one of the most widely usedmachine\nlearning models in practice. How to build a secure XGB inface of data isolation\nproblem becomes a hot research topic. However, existing works tend to leak\nintermediate information and thusraise potential privacy risk. In this paper,\nwe propose a novel framework for two parties to build secure XGB with\nvertically partitioneddata. Specifically, we associate Homomorphic Encryption\n(HE) domain with Secret Sharing (SS) domain by providing the\ntwo-waytransformation primitives. The framework generally promotes\ntheefficiency for privacy preserving machine learning and offers theflexibility\nto implement other machine learning models. Then weelaborate two secure XGB\ntraining algorithms as well as a corresponding prediction algorithm under the\nhybrid security domains.Next, we compare our proposed two training algorithms\nthroughboth complexity analysis and experiments. Finally, we verify themodel\nperformance on benchmark dataset and further apply ourwork to a real-world\nscenario.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 06:31:10 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Fang", "Wenjing", ""], ["Chen", "Chaochao", ""], ["Tan", "Jin", ""], ["Yu", "Chaofan", ""], ["Lu", "Yufei", ""], ["Wang", "Li", ""], ["Wang", "Lei", ""], ["Zhou", "Jun", ""], ["X", "Alex", ""]]}, {"id": "2005.08480", "submitter": "Nan Wang", "authors": "Nan Wang, Xuanhui Wang, Hongning Wang", "title": "Unbiased Learning to Rank via Propensity Ratio Scoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit feedback, such as user clicks, is a major source of supervision for\nlearning to rank (LTR) model estimation in modern retrieval systems. However,\nthe inherent bias in such feedback greatly restricts the quality of the learnt\nranker. Recent advances in unbiased LTR leverage Inverse Propensity Scoring\n(IPS) to tackle the bias issue. Though effective, it only corrects the bias\nintroduced by treating clicked documents as relevant, but cannot handle the\nbias caused by treating unclicked ones as irrelevant. Because non-clicks do not\nnecessarily stand for irrelevance (they might not be examined), IPS-based\nmethods inevitably include loss from comparisons on relevant-relevant document\npairs. This directly limits the effectiveness of ranking model learning.\n  In this work, we first prove that in a LTR algorithm that is based on\npairwise comparisons, only pairs with different labels (e.g.,\nrelevant-irrelevant pairs in binary case) should contribute to the loss\nfunction. The proof asserts sub-optimal results of the existing IPS-based\nmethods in practice. We then derive a new weighting scheme called Propensity\nRatio Scoring (PRS) that takes a holistic treatment on both clicks and\nnon-clicks. Besides correcting the bias in clicked documents, PRS avoids\nrelevant-relevant comparisons in LTR training in expectation and enjoys a lower\nvariability. Our empirical study confirms that PRS ensures a more effective use\nof click data in various situations, which leads to its superior performance in\nan extensive set of LTR benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 06:31:12 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Wang", "Nan", ""], ["Wang", "Xuanhui", ""], ["Wang", "Hongning", ""]]}, {"id": "2005.08482", "submitter": "Phuoc Nguyen", "authors": "Phuoc Nguyen, Truyen Tran, Sunil Gupta, Santu Rana, Hieu-Chi Dam,\n  Svetha Venkatesh", "title": "HyperVAE: A Minimum Description Length Variational Hyper-Encoding\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework called HyperVAE for encoding distributions of\ndistributions. When a target distribution is modeled by a VAE, its neural\nnetwork parameters \\theta is drawn from a distribution p(\\theta) which is\nmodeled by a hyper-level VAE. We propose a variational inference using Gaussian\nmixture models to implicitly encode the parameters \\theta into a low\ndimensional Gaussian distribution. Given a target distribution, we predict the\nposterior distribution of the latent code, then use a matrix-network decoder to\ngenerate a posterior distribution q(\\theta). HyperVAE can encode the parameters\n\\theta in full in contrast to common hyper-networks practices, which generate\nonly the scale and bias vectors as target-network parameters. Thus HyperVAE\npreserves much more information about the model for each task in the latent\nspace. We discuss HyperVAE using the minimum description length (MDL) principle\nand show that it helps HyperVAE to generalize. We evaluate HyperVAE in density\nestimation tasks, outlier detection and discovery of novel design classes,\ndemonstrating its efficacy.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 06:46:09 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Nguyen", "Phuoc", ""], ["Tran", "Truyen", ""], ["Gupta", "Sunil", ""], ["Rana", "Santu", ""], ["Dam", "Hieu-Chi", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2005.08485", "submitter": "Kyuyong Shin", "authors": "Kyuyong Shin, Wonyoung Shin, Jung-Woo Ha, Sunyoung Kwon", "title": "Graphs, Entities, and Step Mixture", "comments": "5 pages, 4 figures, 3 tables accepted for ICML 2020 workshop on Graph\n  Representation Learning and Beyond (GRL+ 2020)", "journal-ref": "ICML 2020 GRL+ workshop", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches for graph neural networks commonly suffer from the\noversmoothing issue, regardless of how neighborhoods are aggregated. Most\nmethods also focus on transductive scenarios for fixed graphs, leading to poor\ngeneralization for unseen graphs. To address these issues, we propose a new\ngraph neural network that considers both edge-based neighborhood relationships\nand node-based entity features, i.e. Graph Entities with Step Mixture via\nrandom walk (GESM). GESM employs a mixture of various steps through random walk\nto alleviate the oversmoothing problem, attention to dynamically reflect\ninterrelations depending on node information, and structure-based\nregularization to enhance embedding representation. With intensive experiments,\nwe show that the proposed GESM achieves state-of-the-art or comparable\nperformances on eight benchmark graph datasets comprising transductive and\ninductive learning tasks. Furthermore, we empirically demonstrate the\nsignificance of considering global information.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 06:57:02 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 05:46:48 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Shin", "Kyuyong", ""], ["Shin", "Wonyoung", ""], ["Ha", "Jung-Woo", ""], ["Kwon", "Sunyoung", ""]]}, {"id": "2005.08510", "submitter": "Chengjian Sun", "authors": "Chengjian Sun, Jiajun Wu and Chenyang Yang", "title": "Reducing Sample Complexity of Deep Learning with Symmetric Prior of\n  Wireless Tasks", "comments": "Submitted to IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been applied to deal with various wireless\nproblems, which usually need a large number of samples for training.\nConsidering that wireless environments are highly dynamic and gathering data is\nexpensive, reducing sample complexity is paramount for learning wireless tasks.\nIncorporating domain knowledge into learning is a promising way of improving\nsample efficiency, which is an emerging topic in the wireless community. In\nthis article, we first briefly summarize several approaches to address this\ncore issue. Then, we show that a kind of symmetric property, permutation\nequivariance, widely exists in wireless tasks. To harness such a generic prior,\nwe introduce a simple data representation method to compress the training set,\nwhich is to jointly sort the input and output of the DNNs. We use power\nallocation among subcarriers, probabilistic content caching, and interference\ncoordination to illustrate how to apply this method, i.e., ranking, and how\nmuch the sample complexity can be reduced. From the case study, we find an\ninteresting phenomenon: \"sample hardening\", where the required number of\ntraining samples decreases with the number of subchannels or contents. We\ncompare this method of data representation with the DNNs embedded with the same\nprior or without any prior. Simulation results show that the samples required\nto train a DNN after ranking can be reduced by $15 \\sim 2400$ folds to achieve\nthe same learning performance as the non-prior counterpart.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 07:57:34 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 09:24:40 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2021 06:59:15 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Sun", "Chengjian", ""], ["Wu", "Jiajun", ""], ["Yang", "Chenyang", ""]]}, {"id": "2005.08514", "submitter": "Xiao Ma", "authors": "Cunjun Yu, Xiao Ma, Jiawei Ren, Haiyu Zhao, Shuai Yi", "title": "Spatio-Temporal Graph Transformer Networks for Pedestrian Trajectory\n  Prediction", "comments": "ECCV camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding crowd motion dynamics is critical to real-world applications,\ne.g., surveillance systems and autonomous driving. This is challenging because\nit requires effectively modeling the socially aware crowd spatial interaction\nand complex temporal dependencies. We believe attention is the most important\nfactor for trajectory prediction. In this paper, we present STAR, a\nSpatio-Temporal grAph tRansformer framework, which tackles trajectory\nprediction by only attention mechanisms. STAR models intra-graph crowd\ninteraction by TGConv, a novel Transformer-based graph convolution mechanism.\nThe inter-graph temporal dependencies are modeled by separate temporal\nTransformers. STAR captures complex spatio-temporal interactions by\ninterleaving between spatial and temporal Transformers. To calibrate the\ntemporal prediction for the long-lasting effect of disappeared pedestrians, we\nintroduce a read-writable external memory module, consistently being updated by\nthe temporal Transformer. We show that with only attention mechanism, STAR\nachieves state-of-the-art performance on 5 commonly used real-world pedestrian\nprediction datasets.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 08:08:09 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 03:32:07 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Yu", "Cunjun", ""], ["Ma", "Xiao", ""], ["Ren", "Jiawei", ""], ["Zhao", "Haiyu", ""], ["Yi", "Shuai", ""]]}, {"id": "2005.08516", "submitter": "Swaroop Mishra", "authors": "Swaroop Mishra, Arindam Mitra, Neeraj Varshney, Bhavdeep Sachdeva and\n  Chitta Baral", "title": "Towards Question Format Independent Numerical Reasoning: A Set of\n  Prerequisite Tasks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical reasoning is often important to accurately understand the world.\nRecently, several format-specific datasets have been proposed, such as\nnumerical reasoning in the settings of Natural Language Inference (NLI),\nReading Comprehension (RC), and Question Answering (QA). Several\nformat-specific models and architectures in response to those datasets have\nalso been proposed. However, there exists a strong need for a benchmark which\ncan evaluate the abilities of models, in performing question format independent\nnumerical reasoning, as (i) the numerical reasoning capabilities we want to\nteach are not controlled by question formats, (ii) for numerical reasoning\ntechnology to have the best possible application, it must be able to process\nlanguage and reason in a way that is not exclusive to a single format, task,\ndataset or domain. In pursuit of this goal, we introduce NUMBERGAME, a\nmultifaceted benchmark to evaluate model performance across numerical reasoning\ntasks of eight diverse formats. We add four existing question types in our\ncompilation. Two of the new types we add are about questions that require\nexternal numerical knowledge, commonsense knowledge and domain knowledge. For\nbuilding a more practical numerical reasoning system, NUMBERGAME demands four\ncapabilities beyond numerical reasoning: (i) detecting question format directly\nfrom data (ii) finding intermediate common format to which every format can be\nconverted (iii) incorporating commonsense knowledge (iv) handling data\nimbalance across formats. We build several baselines, including a new model\nbased on knowledge hunting using a cheatsheet. However, all baselines perform\npoorly in contrast to the human baselines, indicating the hardness of our\nbenchmark. Our work takes forward the recent progress in generic system\ndevelopment, demonstrating the scope of these under-explored tasks.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 08:14:04 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Mishra", "Swaroop", ""], ["Mitra", "Arindam", ""], ["Varshney", "Neeraj", ""], ["Sachdeva", "Bhavdeep", ""], ["Baral", "Chitta", ""]]}, {"id": "2005.08520", "submitter": "Adrian Lancucki", "authors": "Adrian {\\L}a\\'ncucki, Jan Chorowski, Guillaume Sanchez, Ricard Marxer,\n  Nanxin Chen, Hans J.G.A. Dolfing, Sameer Khurana, Tanel Alum\\\"ae, Antoine\n  Laurent", "title": "Robust Training of Vector Quantized Bottleneck Models", "comments": "Published at IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we demonstrate methods for reliable and efficient training of\ndiscrete representation using Vector-Quantized Variational Auto-Encoder models\n(VQ-VAEs). Discrete latent variable models have been shown to learn nontrivial\nrepresentations of speech, applicable to unsupervised voice conversion and\nreaching state-of-the-art performance on unit discovery tasks. For unsupervised\nrepresentation learning, they became viable alternatives to continuous latent\nvariable models such as the Variational Auto-Encoder (VAE). However, training\ndeep discrete variable models is challenging, due to the inherent\nnon-differentiability of the discretization operation. In this paper we focus\non VQ-VAE, a state-of-the-art discrete bottleneck model shown to perform on par\nwith its continuous counterparts. It quantizes encoder outputs with on-line\n$k$-means clustering. We show that the codebook learning can suffer from poor\ninitialization and non-stationarity of clustered encoder outputs. We\ndemonstrate that these can be successfully overcome by increasing the learning\nrate for the codebook and periodic date-dependent codeword re-initialization.\nAs a result, we achieve more robust training across different tasks, and\nsignificantly increase the usage of latent codewords even for large codebooks.\nThis has practical benefit, for instance, in unsupervised representation\nlearning, where large codebooks may lead to disentanglement of latent\nrepresentations.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 08:23:41 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["\u0141a\u0144cucki", "Adrian", ""], ["Chorowski", "Jan", ""], ["Sanchez", "Guillaume", ""], ["Marxer", "Ricard", ""], ["Chen", "Nanxin", ""], ["Dolfing", "Hans J. G. A.", ""], ["Khurana", "Sameer", ""], ["Alum\u00e4e", "Tanel", ""], ["Laurent", "Antoine", ""]]}, {"id": "2005.08526", "submitter": "Jen-Yu Liu", "authors": "Jen-Yu Liu, Yu-Hua Chen, Yin-Cheng Yeh, Yi-Hsuan Yang", "title": "Unconditional Audio Generation with Generative Adversarial Networks and\n  Cycle Regularization", "comments": null, "journal-ref": null, "doi": "10.21437/Interspeech.2020-1137", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper, we have presented a generative adversarial network\n(GAN)-based model for unconditional generation of the mel-spectrograms of\nsinging voices. As the generator of the model is designed to take a\nvariable-length sequence of noise vectors as input, it can generate\nmel-spectrograms of variable length. However, our previous listening test shows\nthat the quality of the generated audio leaves room for improvement. The\npresent paper extends and expands that previous work in the following aspects.\nFirst, we employ a hierarchical architecture in the generator to induce some\nstructure in the temporal dimension. Second, we introduce a cycle\nregularization mechanism to the generator to avoid mode collapse. Third, we\nevaluate the performance of the new model not only for generating singing\nvoices, but also for generating speech voices. Evaluation result shows that new\nmodel outperforms the prior one both objectively and subjectively. We also\nemploy the model to unconditionally generate sequences of piano and violin\nmusic and find the result promising. Audio examples, as well as the code for\nimplementing our model, will be publicly available online upon paper\npublication.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 08:35:16 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Liu", "Jen-Yu", ""], ["Chen", "Yu-Hua", ""], ["Yeh", "Yin-Cheng", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "2005.08531", "submitter": "Leonardo Cella", "authors": "Leonardo Cella, Alessandro Lazaric, Massimiliano Pontil", "title": "Meta-learning with Stochastic Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate meta-learning procedures in the setting of stochastic linear\nbandits tasks. The goal is to select a learning algorithm which works well on\naverage over a class of bandits tasks, that are sampled from a\ntask-distribution. Inspired by recent work on learning-to-learn linear\nregression, we consider a class of bandit algorithms that implement a\nregularized version of the well-known OFUL algorithm, where the regularization\nis a square euclidean distance to a bias vector. We first study the benefit of\nthe biased OFUL algorithm in terms of regret minimization. We then propose two\nstrategies to estimate the bias within the learning-to-learn setting. We show\nboth theoretically and experimentally, that when the number of tasks grows and\nthe variance of the task-distribution is small, our strategies have a\nsignificant advantage over learning the tasks in isolation.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 08:41:39 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Cella", "Leonardo", ""], ["Lazaric", "Alessandro", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "2005.08566", "submitter": "Xinchi Qiu", "authors": "Xinchi Qiu, Titouan Parcollet, Mirco Ravanelli, Nicholas Lane, Mohamed\n  Morchid", "title": "Quaternion Neural Networks for Multi-channel Distant Speech Recognition", "comments": "4 pages", "journal-ref": null, "doi": "10.13140/RG.2.2.17061.52969", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the significant progress in automatic speech recognition (ASR),\ndistant ASR remains challenging due to noise and reverberation. A common\napproach to mitigate this issue consists of equipping the recording devices\nwith multiple microphones that capture the acoustic scene from different\nperspectives. These multi-channel audio recordings contain specific internal\nrelations between each signal. In this paper, we propose to capture these\ninter- and intra- structural dependencies with quaternion neural networks,\nwhich can jointly process multiple signals as whole quaternion entities. The\nquaternion algebra replaces the standard dot product with the Hamilton one,\nthus offering a simple and elegant way to model dependencies between elements.\nThe quaternion layers are then coupled with a recurrent neural network, which\ncan learn long-term dependencies in the time domain. We show that a quaternion\nlong-short term memory neural network (QLSTM), trained on the concatenated\nmulti-channel speech signals, outperforms equivalent real-valued LSTM on two\ndifferent tasks of multi-channel distant speech recognition.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 10:26:27 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 10:06:54 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Qiu", "Xinchi", ""], ["Parcollet", "Titouan", ""], ["Ravanelli", "Mirco", ""], ["Lane", "Nicholas", ""], ["Morchid", "Mohamed", ""]]}, {"id": "2005.08598", "submitter": "Wendi Ji", "authors": "Wendi Ji, Keqiang Wang, Xiaoling Wang, TingWei Chen and Alexandra\n  Cristea", "title": "Sequential Recommender via Time-aware Attentive Memory Network", "comments": "10 pages, 6 figures", "journal-ref": "CIKM 2020", "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation systems aim to assist users to discover most preferred\ncontents from an ever-growing corpus of items. Although recommenders have been\ngreatly improved by deep learning, they still faces several challenges: (1)\nBehaviors are much more complex than words in sentences, so traditional\nattentive and recurrent models may fail in capturing the temporal dynamics of\nuser preferences. (2) The preferences of users are multiple and evolving, so it\nis difficult to integrate long-term memory and short-term intent.\n  In this paper, we propose a temporal gating methodology to improve attention\nmechanism and recurrent units, so that temporal information can be considered\nin both information filtering and state transition. Additionally, we propose a\nMulti-hop Time-aware Attentive Memory network (MTAM) to integrate long-term and\nshort-term preferences. We use the proposed time-aware GRU network to learn the\nshort-term intent and maintain prior records in user memory. We treat the\nshort-term intent as a query and design a multi-hop memory reading operation\nvia the proposed time-aware attention to generate user representation based on\nthe current intent and long-term memory. Our approach is scalable for candidate\nretrieval tasks and can be viewed as a non-linear generalization of latent\nfactorization for dot-product based Top-K recommendation. Finally, we conduct\nextensive experiments on six benchmark datasets and the experimental results\ndemonstrate the effectiveness of our MTAM and temporal gating methodology.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 11:29:38 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 05:39:13 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Ji", "Wendi", ""], ["Wang", "Keqiang", ""], ["Wang", "Xiaoling", ""], ["Chen", "TingWei", ""], ["Cristea", "Alexandra", ""]]}, {"id": "2005.08622", "submitter": "Riccardo La Grassa", "authors": "Riccardo La Grassa, Ignazio Gallo, Nicola Landro", "title": "Learn Class Hierarchy using Convolutional Neural Networks", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A large amount of research on Convolutional Neural Networks has focused on\nflat Classification in the multi-class domain. In the real world, many problems\nare naturally expressed as problems of hierarchical classification, in which\nthe classes to be predicted are organized in a hierarchy of classes. In this\npaper, we propose a new architecture for hierarchical classification of images,\nintroducing a stack of deep linear layers with cross-entropy loss functions and\ncenter loss combined. The proposed architecture can extend any neural network\nmodel and simultaneously optimizes loss functions to discover local\nhierarchical class relationships and a loss function to discover global\ninformation from the whole class hierarchy while penalizing class hierarchy\nviolations. We experimentally show that our hierarchical classifier presents\nadvantages to the traditional classification approaches finding application in\ncomputer vision tasks.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 12:06:43 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["La Grassa", "Riccardo", ""], ["Gallo", "Ignazio", ""], ["Landro", "Nicola", ""]]}, {"id": "2005.08628", "submitter": "Takato Yasuno", "authors": "Takato Yasuno, Michihiro Nakajima, Tomoharu Sekiguchi, Kazuhiro Noda,\n  Kiyoshi Aoyanagi, Sakura Kato", "title": "Synthetic Image Augmentation for Damage Region Segmentation using\n  Conditional GAN with Structure Edge", "comments": "4 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:2004.10126", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, social infrastructure is aging, and its predictive maintenance has\nbecome important issue. To monitor the state of infrastructures, bridge\ninspection is performed by human eye or bay drone. For diagnosis, primary\ndamage region are recognized for repair targets. But, the degradation at worse\nlevel has rarely occurred, and the damage regions of interest are often narrow,\nso their ratio per image is extremely small pixel count, as experienced 0.6 to\n1.5 percent. The both scarcity and imbalance property on the damage region of\ninterest influences limited performance to detect damage. If additional data\nset of damaged images can be generated, it may enable to improve accuracy in\ndamage region segmentation algorithm. We propose a synthetic augmentation\nprocedure to generate damaged images using the image-to-image translation\nmapping from the tri-categorical label that consists the both semantic label\nand structure edge to the real damage image. We use the Sobel gradient operator\nto enhance structure edge. Actually, in case of bridge inspection, we apply the\nRC concrete structure with the number of 208 eye-inspection photos that rebar\nexposure have occurred, which are prepared 840 block images with size 224 by\n224. We applied popular per-pixel segmentation algorithms such as the FCN-8s,\nSegNet, and DeepLabv3+Xception-v2. We demonstrates that re-training a data set\nadded with synthetic augmentation procedure make higher accuracy based on\nindices the mean IoU, damage region of interest IoU, precision, recall, BF\nscore when we predict test images.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 06:04:02 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Yasuno", "Takato", ""], ["Nakajima", "Michihiro", ""], ["Sekiguchi", "Tomoharu", ""], ["Noda", "Kazuhiro", ""], ["Aoyanagi", "Kiyoshi", ""], ["Kato", "Sakura", ""]]}, {"id": "2005.08629", "submitter": "Milad Sikaroudi", "authors": "Milad Sikaroudi, Amir Safarpoor, Benyamin Ghojogh, Sobhan Shafiei,\n  Mark Crowley, H.R. Tizhoosh", "title": "Supervision and Source Domain Impact on Representation Learning: A\n  Histopathology Case Study", "comments": "Accepted for presentation at the 42nd Annual International Conference\n  of the IEEE Engineering in Medicine and Biology Society (EMBC'20)", "journal-ref": "2020 42nd Annual International Conference of the IEEE Engineering\n  in Medicine & Biology Society (EMBC), pp. 1400-1403", "doi": "10.1109/EMBC44109.2020.9176279", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As many algorithms depend on a suitable representation of data, learning\nunique features is considered a crucial task. Although supervised techniques\nusing deep neural networks have boosted the performance of representation\nlearning, the need for a large set of labeled data limits the application of\nsuch methods. As an example, high-quality delineations of regions of interest\nin the field of pathology is a tedious and time-consuming task due to the large\nimage dimensions. In this work, we explored the performance of a deep neural\nnetwork and triplet loss in the area of representation learning. We\ninvestigated the notion of similarity and dissimilarity in pathology\nwhole-slide images and compared different setups from unsupervised and\nsemi-supervised to supervised learning in our experiments. Additionally,\ndifferent approaches were tested, applying few-shot learning on two publicly\navailable pathology image datasets. We achieved high accuracy and\ngeneralization when the learned representations were applied to two different\npathology datasets.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 21:27:38 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Sikaroudi", "Milad", ""], ["Safarpoor", "Amir", ""], ["Ghojogh", "Benyamin", ""], ["Shafiei", "Sobhan", ""], ["Crowley", "Mark", ""], ["Tizhoosh", "H. R.", ""]]}, {"id": "2005.08630", "submitter": "Sungrack Yun", "authors": "Seungwoo Yoo, Heeseok Lee, Heesoo Myeong, Sungrack Yun, Hyoungwoo\n  Park, Janghoon Cho, Duck Hoon Kim", "title": "End-to-End Lane Marker Detection via Row-wise Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In autonomous driving, detecting reliable and accurate lane marker positions\nis a crucial yet challenging task. The conventional approaches for the lane\nmarker detection problem perform a pixel-level dense prediction task followed\nby sophisticated post-processing that is inevitable since lane markers are\ntypically represented by a collection of line segments without thickness. In\nthis paper, we propose a method performing direct lane marker vertex prediction\nin an end-to-end manner, i.e., without any post-processing step that is\nrequired in the pixel-level dense prediction task. Specifically, we translate\nthe lane marker detection problem into a row-wise classification task, which\ntakes advantage of the innate shape of lane markers but, surprisingly, has not\nbeen explored well. In order to compactly extract sufficient information about\nlane markers which spread from the left to the right in an image, we devise a\nnovel layer, which is utilized to successively compress horizontal components\nso enables an end-to-end lane marker detection system where the final lane\nmarker positions are simply obtained via argmax operations in testing time.\nExperimental results demonstrate the effectiveness of the proposed method,\nwhich is on par or outperforms the state-of-the-art methods on two popular lane\nmarker detection benchmarks, i.e., TuSimple and CULane.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 12:48:46 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Yoo", "Seungwoo", ""], ["Lee", "Heeseok", ""], ["Myeong", "Heesoo", ""], ["Yun", "Sungrack", ""], ["Park", "Hyoungwoo", ""], ["Cho", "Janghoon", ""], ["Kim", "Duck Hoon", ""]]}, {"id": "2005.08632", "submitter": "Sandesh Kamath K", "authors": "Sandesh Kamath, Amit Deshpande, K V Subrahmanyam", "title": "Universalization of any adversarial attack using very few test examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning models are known to be vulnerable not only to input-dependent\nadversarial attacks but also to input-agnostic or universal adversarial\nattacks. Dezfooli et al. \\cite{Dezfooli17,Dezfooli17anal} construct universal\nadversarial attack on a given model by looking at a large number of training\ndata points and the geometry of the decision boundary near them. Subsequent\nwork \\cite{Khrulkov18} constructs universal attack by looking only at test\nexamples and intermediate layers of the given model. In this paper, we propose\na simple universalization technique to take any input-dependent adversarial\nattack and construct a universal attack by only looking at very few adversarial\ntest examples. We do not require details of the given model and have negligible\ncomputational overhead for universalization. We theoretically justify our\nuniversalization technique by a spectral property common to many\ninput-dependent adversarial perturbations, e.g., gradients, Fast Gradient Sign\nMethod (FGSM) and DeepFool. Using matrix concentration inequalities and\nspectral perturbation bounds, we show that the top singular vector of\ninput-dependent adversarial directions on a small test sample gives an\neffective and simple universal adversarial attack. For VGG16 and VGG19 models\ntrained on ImageNet, our simple universalization of Gradient, FGSM, and\nDeepFool perturbations using a test sample of 64 images gives fooling rates\ncomparable to state-of-the-art universal attacks \\cite{Dezfooli17,Khrulkov18}\nfor reasonable norms of perturbation.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 12:17:38 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Kamath", "Sandesh", ""], ["Deshpande", "Amit", ""], ["Subrahmanyam", "K V", ""]]}, {"id": "2005.08638", "submitter": "Moonseop Kim", "authors": "Moonseop Kim, Huayi Yin, Guang Lin", "title": "Multi-Fidelity Gaussian Process based Empirical Potential Development\n  for Si:H Nanowires", "comments": "7pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In material modeling, the calculation speed using the empirical potentials is\nfast compared to the first principle calculations, but the results are not as\naccurate as of the first principle calculations. First principle calculations\nare accurate but slow and very expensive to calculate. In this work, first, the\nH-H binding energy and H$_2$-H$_2$ interaction energy are calculated using the\nfirst principle calculations which can be applied to the Tersoff empirical\npotential. Second, the H-H parameters are estimated. After fitting H-H\nparameters, the mechanical properties are obtained. Finally, to integrate both\nthe low-fidelity empirical potential data and the data from the high-fidelity\nfirst-principle calculations, the multi-fidelity Gaussian process regression is\nemployed to predict the H-H binding energy and the H$_2$-H$_2$ interaction\nenergy. Numerical results demonstrate the accuracy of the developed empirical\npotentials.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 02:37:09 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Kim", "Moonseop", ""], ["Yin", "Huayi", ""], ["Lin", "Guang", ""]]}, {"id": "2005.08640", "submitter": "Prashant Gupta", "authors": "Joydip Dhar, Ashaya Shukla, Mukul Kumar, Prashant Gupta", "title": "A Weighted Mutual k-Nearest Neighbour for Classification Mining", "comments": "5 pages, 1 figure, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  kNN is a very effective Instance based learning method, and it is easy to\nimplement. Due to heterogeneous nature of data, noises from different possible\nsources are also widespread in nature especially in case of large-scale\ndatabases. For noise elimination and effect of pseudo neighbours, in this\npaper, we propose a new learning algorithm which performs the task of anomaly\ndetection and removal of pseudo neighbours from the dataset so as to provide\ncomparative better results. This algorithm also tries to minimize effect of\nthose neighbours which are distant. A concept of certainty measure is also\nintroduced for experimental results. The advantage of using concept of mutual\nneighbours and distance-weighted voting is that, dataset will be refined after\nremoval of anomaly and weightage concept compels to take into account more\nconsideration of those neighbours, which are closer. Consequently, finally the\nperformance of proposed algorithm is calculated.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 18:11:30 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Dhar", "Joydip", ""], ["Shukla", "Ashaya", ""], ["Kumar", "Mukul", ""], ["Gupta", "Prashant", ""]]}, {"id": "2005.08641", "submitter": "Lalit Lakshmanan", "authors": "Lalit Lakshmanan, Yash Vora, Raj Ghate", "title": "Deep Learning Based Vehicle Tracking System Using License Plate\n  Detection And Recognition", "comments": "6 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle tracking is an integral part of intelligent traffic management\nsystems. Previous implementations of vehicle tracking used Global Positioning\nSystem(GPS) based systems that gave location of the vehicle of an individual on\ntheir smartphones.The proposed system uses a novel approach to vehicle tracking\nusing Vehicle License plate detection and recognition (VLPR) technique, which\ncan be integrated on a large scale with traffic management systems. Initial\nmethods of implementing VLPR used simple image processing techniques which were\nquite experimental and heuristic. With the onset of Deep learning and Computer\nVision, one can create robust VLPR systems that can produce results close to\nhuman efficiency. Previous implementations, based on deep learning, made use of\nobject detection and support vector machines for detection and a heuristic\nimage processing based approach for recognition. The proposed system makes use\nof scene text detection model architecture for License plate detection and for\nrecognition it uses the Optical character recognition engine (OCR) Tesseract.\nThe proposed system obtained extraordinary results when it was tested on a\nhighway video using NVIDIA Ge-force RTX 2080ti GPU, results were obtained at a\nspeed of 30 frames per second with accuracy close to human.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 14:03:33 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Lakshmanan", "Lalit", ""], ["Vora", "Yash", ""], ["Ghate", "Raj", ""]]}, {"id": "2005.08642", "submitter": "Ritam Guha Mr.", "authors": "Kushal Kanti Ghosh, Ritam Guha, Soulib Ghosh, Suman Kumar Bera, Ram\n  Sarkar", "title": "Atom Search Optimization with Simulated Annealing -- a Hybrid\n  Metaheuristic Approach for Feature Selection", "comments": "39 pages, submitted to Expert Systems with Applications, Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  'Hybrid meta-heuristics' is one of the most interesting recent trends in the\nfield of optimization and feature selection (FS). In this paper, we have\nproposed a binary variant of Atom Search Optimization (ASO) and its hybrid with\nSimulated Annealing called ASO-SA techniques for FS. In order to map the real\nvalues used by ASO to the binary domain of FS, we have used two different\ntransfer functions: S-shaped and V-shaped. We have hybridized this technique\nwith a local search technique called, SA We have applied the proposed feature\nselection methods on 25 datasets from 4 different categories: UCI, Handwritten\ndigit recognition, Text, non-text separation, and Facial emotion recognition.\nWe have used 3 different classifiers (K-Nearest Neighbor, Multi-Layer\nPerceptron and Random Forest) for evaluating the strength of the selected\nfeatured by the binary ASO, ASO-SA and compared the results with some recent\nwrapper-based algorithms. The experimental results confirm the superiority of\nthe proposed method both in terms of classification accuracy and number of\nselected features.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 07:56:58 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Ghosh", "Kushal Kanti", ""], ["Guha", "Ritam", ""], ["Ghosh", "Soulib", ""], ["Bera", "Suman Kumar", ""], ["Sarkar", "Ram", ""]]}, {"id": "2005.08644", "submitter": "Utkarsh Srivastava", "authors": "Utkarsh Chandra Srivastava, Dhruv Upadhyay, Vinayak Sharma", "title": "Intracranial Hemorrhage Detection Using Neural Network Based Methods\n  With Federated Learning", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intracranial hemorrhage, bleeding that occurs inside the cranium, is a\nserious health problem requiring rapid and often intensive medical treatment.\nSuch a condition is traditionally diagnosed by highly-trained specialists\nanalyzing computed tomography (CT) scan of the patient and identifying the\nlocation and type of hemorrhage if one exists. We propose a neural network\napproach to find and classify the condition based upon the CT scan. The model\narchitecture implements a time distributed convolutional network. We observed\naccuracy above 92% from such an architecture, provided enough data. We propose\nfurther extensions to our approach involving the deployment of federated\nlearning. This would be helpful in pooling learned parameters without violating\nthe inherent privacy of the data involved.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 05:35:15 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Srivastava", "Utkarsh Chandra", ""], ["Upadhyay", "Dhruv", ""], ["Sharma", "Vinayak", ""]]}, {"id": "2005.08645", "submitter": "Jevgenij Gamper", "authors": "Jevgenij Gamper, Navid Alemi Kooohbanani, Nasir Rajpoot", "title": "Multi-Task Learning in Histo-pathology for Widely Generalizable Model", "comments": null, "journal-ref": "AI4CC ICLR 2020 workshop", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we show preliminary results of deep multi-task learning in the\narea of computational pathology. We combine 11 tasks ranging from patch-wise\noral cancer classification, one of the most prevalent cancers in the developing\nworld, to multi-tissue nuclei instance segmentation and classification.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 12:13:43 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Gamper", "Jevgenij", ""], ["Kooohbanani", "Navid Alemi", ""], ["Rajpoot", "Nasir", ""]]}, {"id": "2005.08649", "submitter": "Chih-Fan Hsu", "authors": "Chih-Fan Hsu, Chia-Ching Lin, Ting-Yang Hung, Chin-Laung Lei and\n  Kuan-Ta Chen", "title": "A Detailed Look At CNN-based Approaches In Facial Landmark Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial landmark detection has been studied over decades. Numerous neural\nnetwork (NN)-based approaches have been proposed for detecting landmarks,\nespecially the convolutional neural network (CNN)-based approaches. In general,\nCNN-based approaches can be divided into regression and heatmap approaches.\nHowever, no research systematically studies the characteristics of different\napproaches. In this paper, we investigate both CNN-based approaches, generalize\ntheir advantages and disadvantages, and introduce a variation of the heatmap\napproach, a pixel-wise classification (PWC) model. To the best of our\nknowledge, using the PWC model to detect facial landmarks have not been\ncomprehensively studied. We further design a hybrid loss function and a\ndiscrimination network for strengthening the landmarks' interrelationship\nimplied in the PWC model to improve the detection accuracy without modifying\nthe original model architecture. Six common facial landmark datasets, AFW,\nHelen, LFPW, 300-W, IBUG, and COFW are adopted to train or evaluate our model.\nA comprehensive evaluation is conducted and the result shows that the proposed\nmodel outperforms other models in all tested datasets.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 16:17:42 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Hsu", "Chih-Fan", ""], ["Lin", "Chia-Ching", ""], ["Hung", "Ting-Yang", ""], ["Lei", "Chin-Laung", ""], ["Chen", "Kuan-Ta", ""]]}, {"id": "2005.08650", "submitter": "Marek Rychlik", "authors": "Marek Rychlik, and Dwight Nwaigwe and Yan Han and Dylan Murphy", "title": "Development of a New Image-to-text Conversion System for Pashto, Farsi\n  and Traditional Chinese", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report upon the results of a research and prototype building project\n\\emph{Worldly~OCR} dedicated to developing new, more accurate image-to-text\nconversion software for several languages and writing systems. These include\nthe cursive scripts Farsi and Pashto, and Latin cursive scripts. We also\ndescribe approaches geared towards Traditional Chinese, which is non-cursive,\nbut features an extremely large character set of 65,000 characters. Our\nmethodology is based on Machine Learning, especially Deep Learning, and Data\nScience, and is directed towards vast quantities of original documents,\nexceeding a billion pages. The target audience of this paper is a general\naudience with interest in Digital Humanities or in retrieval of accurate\nfull-text and metadata from digital images.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 17:58:48 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Rychlik", "Marek", ""], ["Nwaigwe", "Dwight", ""], ["Han", "Yan", ""], ["Murphy", "Dylan", ""]]}, {"id": "2005.08665", "submitter": "Shixiang Zhu", "authors": "Shixiang Zhu, Ruyi Ding, Minghe Zhang, Pascal Van Hentenryck, Yao Xie", "title": "Spatio-Temporal Point Processes with Attention for Traffic Congestion\n  Event Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel framework for modeling traffic congestion events over road\nnetworks. Using multi-modal data by combining count data from traffic sensors\nwith police reports that report traffic incidents, we aim to capture two types\nof triggering effect for congestion events. Current traffic congestion at one\nlocation may cause future congestion over the road network, and traffic\nincidents may cause spread traffic congestion. To model the non-homogeneous\ntemporal dependence of the event on the past, we use a novel attention-based\nmechanism based on neural networks embedding for point processes. To\nincorporate the directional spatial dependence induced by the road network, we\nadapt the \"tail-up\" model from the context of spatial statistics to the traffic\nnetwork setting. We demonstrate our approach's superior performance compared to\nthe state-of-the-art methods for both synthetic and real data.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 04:22:18 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 19:54:08 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Zhu", "Shixiang", ""], ["Ding", "Ruyi", ""], ["Zhang", "Minghe", ""], ["Van Hentenryck", "Pascal", ""], ["Xie", "Yao", ""]]}, {"id": "2005.08672", "submitter": "Puoya Tabaghi", "authors": "Puoya Tabaghi, Ivan Dokmani\\'c", "title": "Hyperbolic Distance Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperbolic space is a natural setting for mining and visualizing data with\nhierarchical structure. In order to compute a hyperbolic embedding from\ncomparison or similarity information, one has to solve a hyperbolic distance\ngeometry problem. In this paper, we propose a unified framework to compute\nhyperbolic embeddings from an arbitrary mix of noisy metric and non-metric\ndata. Our algorithms are based on semidefinite programming and the notion of a\nhyperbolic distance matrix, in many ways parallel to its famous Euclidean\ncounterpart. A central ingredient we put forward is a semidefinite\ncharacterization of the hyperbolic Gramian -- a matrix of Lorentzian inner\nproducts. This characterization allows us to formulate a semidefinite\nrelaxation to efficiently compute hyperbolic embeddings in two stages: first,\nwe complete and denoise the observed hyperbolic distance matrix; second, we\npropose a spectral factorization method to estimate the embedded points from\nthe hyperbolic distance matrix. We show through numerical experiments how the\nflexibility to mix metric and non-metric constraints allows us to efficiently\ncompute embeddings from arbitrary data.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 12:59:49 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 17:02:32 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Tabaghi", "Puoya", ""], ["Dokmani\u0107", "Ivan", ""]]}, {"id": "2005.08679", "submitter": "Emiliano De Cristofaro", "authors": "Emiliano De Cristofaro", "title": "An Overview of Privacy in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, providers such as Google, Microsoft, and Amazon have\nstarted to provide customers with access to software interfaces allowing them\nto easily embed machine learning tasks into their applications. Overall,\norganizations can now use Machine Learning as a Service (MLaaS) engines to\noutsource complex tasks, e.g., training classifiers, performing predictions,\nclustering, etc. They can also let others query models trained on their data.\nNaturally, this approach can also be used (and is often advocated) in other\ncontexts, including government collaborations, citizen science projects, and\nbusiness-to-business partnerships. However, if malicious users were able to\nrecover data used to train these models, the resulting information leakage\nwould create serious issues. Likewise, if the inner parameters of the model are\nconsidered proprietary information, then access to the model should not allow\nan adversary to learn such parameters. In this document, we set to review\nprivacy challenges in this space, providing a systematic review of the relevant\nresearch literature, also exploring possible countermeasures. More\nspecifically, we provide ample background information on relevant concepts\naround machine learning and privacy. Then, we discuss possible adversarial\nmodels and settings, cover a wide range of attacks that relate to private\nand/or sensitive information leakage, and review recent results attempting to\ndefend against such attacks. Finally, we conclude with a list of open problems\nthat require more work, including the need for better evaluations, more\ntargeted defenses, and the study of the relation to policy and data protection\nefforts.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 13:05:17 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["De Cristofaro", "Emiliano", ""]]}, {"id": "2005.08689", "submitter": "Abdolrahman Peimankar Dr", "authors": "Abdolrahman Peimankar and Sadasivan Puthusserypady", "title": "DENS-ECG: A Deep Learning Approach for ECG Signal Delineation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objectives: With the technological advancements in the field of tele-health\nmonitoring, it is now possible to gather huge amounts of electro-physiological\nsignals such as electrocardiogram (ECG). It is therefore necessary to develop\nmodels/algorithms that are capable of analysing these massive amounts of data\nin real-time. This paper proposes a deep learning model for real-time\nsegmentation of heartbeats. Methods: The proposed algorithm, named as the\nDENS-ECG algorithm, combines convolutional neural network (CNN) and long\nshort-term memory (LSTM) model to detect onset, peak, and offset of different\nheartbeat waveforms such as the P-wave, QRS complex, T-wave, and No wave (NW).\nUsing ECG as the inputs, the model learns to extract high level features\nthrough the training process, which, unlike other classical machine learning\nbased methods, eliminates the feature engineering step. Results: The proposed\nDENS-ECG model was trained and validated on a dataset with 105 ECGs of length\n15 minutes each and achieved an average sensitivity and precision of 97.95% and\n95.68%, respectively, using a 5-fold cross validation. Additionally, the model\nwas evaluated on an unseen dataset to examine its robustness in QRS detection,\nwhich resulted in a sensitivity of 99.61% and precision of 99.52%. Conclusion:\nThe empirical results show the flexibility and accuracy of the combined\nCNN-LSTM model for ECG signal delineation. Significance: This paper proposes an\nefficient and easy to use approach using deep learning for heartbeat\nsegmentation, which could potentially be used in real-time tele-health\nmonitoring systems.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 13:13:41 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Peimankar", "Abdolrahman", ""], ["Puthusserypady", "Sadasivan", ""]]}, {"id": "2005.08697", "submitter": "Xuetong Wu", "authors": "Xuetong Wu, Jonathan H. Manton, Uwe Aickelin, Jingge Zhu", "title": "Information-theoretic analysis for transfer learning", "comments": "Accepted paper in 2020 IEEE International Symposium on Information\n  Theory (ISIT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning, or domain adaptation, is concerned with machine learning\nproblems in which training and testing data come from possibly different\ndistributions (denoted as $\\mu$ and $\\mu'$, respectively). In this work, we\ngive an information-theoretic analysis on the generalization error and the\nexcess risk of transfer learning algorithms, following a line of work initiated\nby Russo and Zhou. Our results suggest, perhaps as expected, that the\nKullback-Leibler (KL) divergence $D(mu||mu')$ plays an important role in\ncharacterizing the generalization error in the settings of domain adaptation.\nSpecifically, we provide generalization error upper bounds for general transfer\nlearning algorithms and extend the results to a specific empirical risk\nminimization (ERM) algorithm where data from both distributions are available\nin the training phase. We further apply the method to iterative, noisy gradient\ndescent algorithms, and obtain upper bounds which can be easily calculated,\nonly using parameters from the learning algorithms. A few illustrative examples\nare provided to demonstrate the usefulness of the results. In particular, our\nbound is tighter in specific classification problems than the bound derived\nusing Rademacher complexity.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 13:23:20 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 00:57:09 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Wu", "Xuetong", ""], ["Manton", "Jonathan H.", ""], ["Aickelin", "Uwe", ""], ["Zhu", "Jingge", ""]]}, {"id": "2005.08701", "submitter": "Taegeun Song", "authors": "Woo Seok Lee, Junghyo Jo, and Taegeun Song", "title": "Machine learning for the diagnosis of early stage diabetes using\n  temporal glucose profiles", "comments": "4 pages, 2 figure", "journal-ref": null, "doi": "10.1007/s40042-021-00056-8", "report-no": null, "categories": "q-bio.QM cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning shows remarkable success for recognizing patterns in data.\nHere we apply the machine learning (ML) for the diagnosis of early stage\ndiabetes, which is known as a challenging task in medicine. Blood glucose\nlevels are tightly regulated by two counter-regulatory hormones, insulin and\nglucagon, and the failure of the glucose homeostasis leads to the common\nmetabolic disease, diabetes mellitus. It is a chronic disease that has a long\nlatent period the complicates detection of the disease at an early stage. The\nvast majority of diabetics result from that diminished effectiveness of insulin\naction. The insulin resistance must modify the temporal profile of blood\nglucose. Thus we propose to use ML to detect the subtle change in the temporal\npattern of glucose concentration. Time series data of blood glucose with\nsufficient resolution is currently unavailable, so we confirm the proposal\nusing synthetic data of glucose profiles produced by a biophysical model that\nconsiders the glucose regulation and hormone action. Multi-layered perceptrons,\nconvolutional neural networks, and recurrent neural networks all identified the\ndegree of insulin resistance with high accuracy above $85\\%$.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 13:31:12 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Lee", "Woo Seok", ""], ["Jo", "Junghyo", ""], ["Song", "Taegeun", ""]]}, {"id": "2005.08702", "submitter": "John Brandt", "authors": "John Brandt, Fred Stolle", "title": "A global method to identify trees outside of closed-canopy forests with\n  medium-resolution satellite imagery", "comments": null, "journal-ref": null, "doi": "10.1080/01431161.2020.1841324", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scattered trees outside of dense, closed-canopy forests are very important\nfor carbon sequestration, supporting livelihoods, maintaining ecosystem\nintegrity, and climate change adaptation and mitigation. In contrast to trees\ninside of closed-canopy forests, not much is known about the spatial extent and\ndistribution of scattered trees at a global scale. Due to the cost of\nhigh-resolution satellite imagery, global monitoring systems rely on\nmedium-resolution satellites to monitor land use. Here we present a globally\nconsistent method to identify trees with canopy diameters greater than three\nmeters with medium-resolution optical and radar imagery. Biweekly cloud-free,\npan-sharpened 10 meter Sentinel-2 optical imagery and Sentinel-1 radar imagery\nare used to train a fully convolutional network, consisting of a convolutional\ngated recurrent unit layer and a feature pyramid attention layer. Tested across\nmore than 215,000 Sentinel-1 and Sentinel-2 pixels distributed from -60 to +60\nlatitude, the proposed model exceeds 75% user's and producer's accuracy\nidentifying trees in hectares with a low to medium density (less than 40%) of\ntree cover, and 95% user's and producer's accuracy in hectares with dense\n(greater than 40%) tree cover. The proposed method increases the accuracy of\nmonitoring tree presence in areas with sparse and scattered tree cover (less\nthan 40%) by as much as 20%, and reduces commission and omission error in\nmountainous and very cloudy regions by nearly half. When applied across large,\nheterogeneous landscapes, the results demonstrate potential to map trees in\nhigh detail and accuracy over diverse landscapes across the globe. This\ninformation is important for understanding current land cover and can be used\nto detect changes in land cover such as agroforestry, buffer zones around\nbiological hotspots, and expansion or encroachment of forests.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 15:58:01 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 13:56:50 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Brandt", "John", ""], ["Stolle", "Fred", ""]]}, {"id": "2005.08704", "submitter": "Weipeng Cao", "authors": "Zhongwu Xie, Weipeng Cao, Xizhao Wang, Zhong Ming, Jingjing Zhang,\n  Jiyong Zhang", "title": "A Biologically Inspired Feature Enhancement Framework for Zero-Shot\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the Zero-Shot Learning (ZSL) algorithms currently use pre-trained\nmodels as their feature extractors, which are usually trained on the ImageNet\ndata set by using deep neural networks. The richness of the feature information\nembedded in the pre-trained models can help the ZSL model extract more useful\nfeatures from its limited training samples. However, sometimes the difference\nbetween the training data set of the current ZSL task and the ImageNet data set\nis too large, which may lead to the use of pre-trained models has no obvious\nhelp or even negative impact on the performance of the ZSL model. To solve this\nproblem, this paper proposes a biologically inspired feature enhancement\nframework for ZSL. Specifically, we design a dual-channel learning framework\nthat uses auxiliary data sets to enhance the feature extractor of the ZSL model\nand propose a novel method to guide the selection of the auxiliary data sets\nbased on the knowledge of biological taxonomy. Extensive experimental results\nshow that our proposed method can effectively improve the generalization\nability of the ZSL model and achieve state-of-the-art results on three\nbenchmark ZSL tasks. We also explained the experimental phenomena through the\nway of feature visualization.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 13:25:22 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Xie", "Zhongwu", ""], ["Cao", "Weipeng", ""], ["Wang", "Xizhao", ""], ["Ming", "Zhong", ""], ["Zhang", "Jingjing", ""], ["Zhang", "Jiyong", ""]]}, {"id": "2005.08722", "submitter": "Maurice Gerczuk", "authors": "Shahin Amiriparian, Pawel Winokurow, Vincent Karas, Sandra Ottl,\n  Maurice Gerczuk, Bj\\\"orn W. Schuller", "title": "A Novel Fusion of Attention and Sequence to Sequence Autoencoders to\n  Predict Sleepiness From Speech", "comments": "5 pages, 2 figures, submitted to INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the attention mechanism of the human visual system and recent\ndevelopments in the field of machine translation, we introduce our\nattention-based and recurrent sequence to sequence autoencoders for fully\nunsupervised representation learning from audio files. In particular, we test\nthe efficacy of our novel approach on the task of speech-based sleepiness\nrecognition. We evaluate the learnt representations from both autoencoders, and\nthen conduct an early fusion to ascertain possible complementarity between\nthem. In our frameworks, we first extract Mel-spectrograms from raw audio\nfiles. Second, we train recurrent autoencoders on these spectrograms which are\nconsidered as time-dependent frequency vectors. Afterwards, we extract the\nactivations of specific fully connected layers of the autoencoders which\nrepresent the learnt features of spectrograms for the corresponding audio\ninstances. Finally, we train support vector regressors on these representations\nto obtain the predictions. On the development partition of the data, we achieve\nSpearman's correlation coefficients of .324, .283, and .320 with the targets on\nthe Karolinska Sleepiness Scale by utilising attention and non-attention\nautoencoders, and the fusion of both autoencoders' representations,\nrespectively. In the same order, we achieve .311, .359, and .367 Spearman's\ncorrelation coefficients on the test data, indicating the suitability of our\nproposed fusion strategy.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 12:02:52 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 16:30:41 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Amiriparian", "Shahin", ""], ["Winokurow", "Pawel", ""], ["Karas", "Vincent", ""], ["Ottl", "Sandra", ""], ["Gerczuk", "Maurice", ""], ["Schuller", "Bj\u00f6rn W.", ""]]}, {"id": "2005.08739", "submitter": "Andriy Miranskyy", "authors": "Mohammad Saiful Islam and Andriy Miranskyy", "title": "Anomaly Detection in Cloud Components", "comments": "Accepted for publication in Proceedings of the IEEE International\n  Conference on Cloud Computing (CLOUD 2020). Fix dataset description", "journal-ref": null, "doi": "10.1109/CLOUD49709.2020.00008", "report-no": null, "categories": "cs.SE cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud platforms, under the hood, consist of a complex inter-connected stack\nof hardware and software components. Each of these components can fail which\nmay lead to an outage. Our goal is to improve the quality of Cloud services\nthrough early detection of such failures by analyzing resource utilization\nmetrics. We tested Gated-Recurrent-Unit-based autoencoder with a likelihood\nfunction to detect anomalies in various multi-dimensional time series and\nachieved high performance.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 14:06:38 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 14:34:41 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Islam", "Mohammad Saiful", ""], ["Miranskyy", "Andriy", ""]]}, {"id": "2005.08741", "submitter": "Samuel Rudy", "authors": "Samuel H. Rudy and Themistoklis P. Sapsis", "title": "Sparse Methods for Automatic Relevance Determination", "comments": null, "journal-ref": null, "doi": "10.1016/j.physd.2021.132843", "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers methods for imposing sparsity in Bayesian regression with\napplications in nonlinear system identification. We first review automatic\nrelevance determination (ARD) and analytically demonstrate the need to\nadditional regularization or thresholding to achieve sparse models. We then\ndiscuss two classes of methods, regularization based and thresholding based,\nwhich build on ARD to learn parsimonious solutions to linear problems. In the\ncase of orthogonal covariates, we analytically demonstrate favorable\nperformance with regards to learning a small set of active terms in a linear\nsystem with a sparse solution. Several example problems are presented to\ncompare the set of proposed methods in terms of advantages and limitations to\nARD in bases with hundreds of elements. The aim of this paper is to analyze and\nunderstand the assumptions that lead to several algorithms and to provide\ntheoretical and empirical results so that the reader may gain insight and make\nmore informed choices regarding sparse Bayesian regression.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 14:08:49 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Rudy", "Samuel H.", ""], ["Sapsis", "Themistoklis P.", ""]]}, {"id": "2005.08748", "submitter": "Peter Gr\\\"onquist", "authors": "Peter Gr\\\"onquist, Chengyuan Yao, Tal Ben-Nun, Nikoli Dryden, Peter\n  Dueben, Shigang Li, Torsten Hoefler", "title": "Deep Learning for Post-Processing Ensemble Weather Forecasts", "comments": null, "journal-ref": null, "doi": "10.1098/rsta.2020.0092", "report-no": null, "categories": "cs.LG eess.SP physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying uncertainty in weather forecasts is critical, especially for\npredicting extreme weather events. This is typically accomplished with ensemble\nprediction systems, which consist of many perturbed numerical weather\nsimulations, or trajectories, run in parallel. These systems are associated\nwith a high computational cost and often involve statistical post-processing\nsteps to inexpensively improve their raw prediction qualities. We propose a\nmixed model that uses only a subset of the original weather trajectories\ncombined with a post-processing step using deep neural networks. These enable\nthe model to account for non-linear relationships that are not captured by\ncurrent numerical models or post-processing methods. Applied to global data,\nour mixed models achieve a relative improvement in ensemble forecast skill\n(CRPS) of over 14%. Furthermore, we demonstrate that the improvement is larger\nfor extreme weather events on select case studies. We also show that our\npost-processing can use fewer trajectories to achieve comparable results to the\nfull ensemble. By using fewer trajectories, the computational costs of an\nensemble prediction system can be reduced, allowing it to run at higher\nresolution and produce more accurate forecasts.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 14:23:26 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 11:08:47 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Gr\u00f6nquist", "Peter", ""], ["Yao", "Chengyuan", ""], ["Ben-Nun", "Tal", ""], ["Dryden", "Nikoli", ""], ["Dueben", "Peter", ""], ["Li", "Shigang", ""], ["Hoefler", "Torsten", ""]]}, {"id": "2005.08749", "submitter": "Sofia Triantafillou", "authors": "Sofia Triantafillou and Gregory Cooper", "title": "Learning Adjustment Sets from Observational and Limited Experimental\n  Data", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating causal effects from observational data is not always possible due\nto confounding. Identifying a set of appropriate covariates (adjustment set)\nand adjusting for their influence can remove confounding bias; however, such a\nset is typically not identifiable from observational data alone. Experimental\ndata do not have confounding bias, but are typically limited in sample size and\ncan therefore yield imprecise estimates. Furthermore, experimental data often\ninclude a limited set of covariates, and therefore provide limited insight into\nthe causal structure of the underlying system. In this work we introduce a\nmethod that combines large observational and limited experimental data to\nidentify adjustment sets and improve the estimation of causal effects. The\nmethod identifies an adjustment set (if possible) by calculating the marginal\nlikelihood for the experimental data given observationally-derived prior\nprobabilities of potential adjustmen sets. In this way, the method can make\ninferences that are not possible using only the conditional dependencies and\nindependencies in all the observational and experimental data. We show that the\nmethod successfully identifies adjustment sets and improves causal effect\nestimation in simulated data, and it can sometimes make additional inferences\nwhen compared to state-of-the-art methods for combining experimental and\nobservational data.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 14:23:32 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 20:35:49 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Triantafillou", "Sofia", ""], ["Cooper", "Gregory", ""]]}, {"id": "2005.08752", "submitter": "Junjun Jiang", "authors": "Junjun Jiang, He Sun, Xianming Liu, and Jiayi Ma", "title": "Learning Spatial-Spectral Prior for Super-Resolution of Hyperspectral\n  Imagery", "comments": "Accepted for publication at IEEE Transactions on Computational\n  Imaging", "journal-ref": null, "doi": "10.1109/TCI.2020.2996075", "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, single gray/RGB image super-resolution reconstruction task has been\nextensively studied and made significant progress by leveraging the advanced\nmachine learning techniques based on deep convolutional neural networks\n(DCNNs). However, there has been limited technical development focusing on\nsingle hyperspectral image super-resolution due to the high-dimensional and\ncomplex spectral patterns in hyperspectral image. In this paper, we make a step\nforward by investigating how to adapt state-of-the-art residual learning based\nsingle gray/RGB image super-resolution approaches for computationally efficient\nsingle hyperspectral image super-resolution, referred as SSPSR. Specifically,\nwe introduce a spatial-spectral prior network (SSPN) to fully exploit the\nspatial information and the correlation between the spectra of the\nhyperspectral data. Considering that the hyperspectral training samples are\nscarce and the spectral dimension of hyperspectral image data is very high, it\nis nontrivial to train a stable and effective deep network. Therefore, a group\nconvolution (with shared network parameters) and progressive upsampling\nframework is proposed. This will not only alleviate the difficulty in feature\nextraction due to high-dimension of the hyperspectral data, but also make the\ntraining process more stable. To exploit the spatial and spectral prior, we\ndesign a spatial-spectral block (SSB), which consists of a spatial residual\nmodule and a spectral attention residual module. Experimental results on some\nhyperspectral images demonstrate that the proposed SSPSR method enhances the\ndetails of the recovered high-resolution hyperspectral images, and outperforms\nstate-of-the-arts. The source code is available at\n\\url{https://github.com/junjun-jiang/SSPSR\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 14:25:50 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 03:26:38 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Jiang", "Junjun", ""], ["Sun", "He", ""], ["Liu", "Xianming", ""], ["Ma", "Jiayi", ""]]}, {"id": "2005.08773", "submitter": "Francisco J\\'a\\~nez-Martino", "authors": "Francisco J\\'a\\~nez-Martino, Eduardo Fidalgo, Santiago\n  Gonz\\'alez-Mart\\'inez, Javier Velasco-Mata", "title": "Classification of Spam Emails through Hierarchical Clustering and\n  Supervised Learning", "comments": "4 pages, 2 figures, to be published in conference JNIC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spammers take advantage of email popularity to send indiscriminately\nunsolicited emails. Although researchers and organizations continuously develop\nanti-spam filters based on binary classification, spammers bypass them through\nnew strategies, like word obfuscation or image-based spam. For the first time\nin literature, we propose to classify spam email in categories to improve the\nhandle of already detected spam emails, instead of just using a binary model.\nFirst, we applied a hierarchical clustering algorithm to create SPEMC-$11$K\n(SPam EMail Classification), the first multi-class dataset, which contains\nthree types of spam emails: Health and Technology, Personal Scams, and Sexual\nContent. Then, we used SPEMC-$11$K to evaluate the combination of TF-IDF and\nBOW encodings with Na\\\"ive Bayes, Decision Trees and SVM classifiers. Finally,\nwe recommend for the task of multi-class spam classification the use of (i)\nTF-IDF combined with SVM for the best micro F1 score performance, $95.39\\%$,\nand (ii) TD-IDF along with NB for the fastest spam classification, analyzing an\nemail in $2.13$ms.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 14:41:22 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 15:36:25 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["J\u00e1\u00f1ez-Martino", "Francisco", ""], ["Fidalgo", "Eduardo", ""], ["Gonz\u00e1lez-Mart\u00ednez", "Santiago", ""], ["Velasco-Mata", "Javier", ""]]}, {"id": "2005.08781", "submitter": "Chien-Yu Huang", "authors": "Chien-yu Huang, Yist Y. Lin, Hung-yi Lee, Lin-shan Lee", "title": "Defending Your Voice: Adversarial Attack on Voice Conversion", "comments": "Accepted by SLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Substantial improvements have been achieved in recent years in voice\nconversion, which converts the speaker characteristics of an utterance into\nthose of another speaker without changing the linguistic content of the\nutterance. Nonetheless, the improved conversion technologies also led to\nconcerns about privacy and authentication. It thus becomes highly desired to be\nable to prevent one's voice from being improperly utilized with such voice\nconversion technologies. This is why we report in this paper the first known\nattempt to perform adversarial attack on voice conversion. We introduce human\nimperceptible noise into the utterances of a speaker whose voice is to be\ndefended. Given these adversarial examples, voice conversion models cannot\nconvert other utterances so as to sound like being produced by the defended\nspeaker. Preliminary experiments were conducted on two currently\nstate-of-the-art zero-shot voice conversion models. Objective and subjective\nevaluation results in both white-box and black-box scenarios are reported. It\nwas shown that the speaker characteristics of the converted utterances were\nmade obviously different from those of the defended speaker, while the\nadversarial examples of the defended speaker are not distinguishable from the\nauthentic utterances.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 14:51:54 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 11:14:30 GMT"}, {"version": "v3", "created": "Tue, 4 May 2021 15:02:26 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Huang", "Chien-yu", ""], ["Lin", "Yist Y.", ""], ["Lee", "Hung-yi", ""], ["Lee", "Lin-shan", ""]]}, {"id": "2005.08785", "submitter": "Laurent Schmalen", "authors": "Boris Karanov, Mathieu Chagnon, Vahid Aref, Domanic Lavery, Polina\n  Bayvel, Laurent Schmalen", "title": "Optical Fiber Communication Systems Based on End-to-End Deep Learning", "comments": "Invited paper at IEEE Photonics Conference (IPC), Special Symposium\n  for Machine Learning in Photonic Systems (SS MLPS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate end-to-end optimized optical transmission systems based on\nfeedforward or bidirectional recurrent neural networks (BRNN) and deep\nlearning. In particular, we report the first experimental demonstration of a\nBRNN auto-encoder, highlighting the performance improvement achieved with\nrecurrent processing for communication over dispersive nonlinear channels.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 15:02:42 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Karanov", "Boris", ""], ["Chagnon", "Mathieu", ""], ["Aref", "Vahid", ""], ["Lavery", "Domanic", ""], ["Bayvel", "Polina", ""], ["Schmalen", "Laurent", ""]]}, {"id": "2005.08790", "submitter": "Laurent Schmalen", "authors": "Boris Karanov, Mathieu Chagnon, Vahid Aref, Filipe Ferreira, Domanic\n  Lavery, Polina Bayvel, Laurent Schmalen", "title": "Experimental Investigation of Deep Learning for Digital Signal\n  Processing in Short Reach Optical Fiber Communications", "comments": "Invited paper at the IEEE International Workshop on Signal Processing\n  Systems (SiPS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate methods for experimental performance enhancement of\nauto-encoders based on a recurrent neural network (RNN) for communication over\ndispersive nonlinear channels. In particular, our focus is on the recently\nproposed sliding window bidirectional RNN (SBRNN) optical fiber autoencoder. We\nshow that adjusting the processing window in the sequence estimation algorithm\nat the receiver improves the reach of simple systems trained on a channel model\nand applied \"as is\" to the transmission link. Moreover, the collected\nexperimental data was used to optimize the receiver neural network parameters,\nallowing to transmit 42 Gb/s with bit-error rate (BER) below the 6.7%\nhard-decision forward error correction threshold at distances up to 70km as\nwell as 84 Gb/s at 20 km. The investigation of digital signal processing (DSP)\noptimized on experimental data is extended to pulse amplitude modulation with\nreceivers performing sliding window sequence estimation using a feed-forward or\na recurrent neural network as well as classical nonlinear Volterra\nequalization. Our results show that, for fixed algorithm memory, the DSP based\non deep learning achieves an improved BER performance, allowing to increase the\nreach of the system.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 15:09:41 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Karanov", "Boris", ""], ["Chagnon", "Mathieu", ""], ["Aref", "Vahid", ""], ["Ferreira", "Filipe", ""], ["Lavery", "Domanic", ""], ["Bayvel", "Polina", ""], ["Schmalen", "Laurent", ""]]}, {"id": "2005.08792", "submitter": "David Kinney", "authors": "David Kinney and David Watson", "title": "Causal Feature Learning for Utility-Maximizing Agents", "comments": "Forthcoming in the Proceedings of the 10th International Conference\n  on Probabilistic Graphical Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering high-level causal relations from low-level data is an important\nand challenging problem that comes up frequently in the natural and social\nsciences. In a series of papers, Chalupka et al. (2015, 2016a, 2016b, 2017)\ndevelop a procedure for causal feature learning (CFL) in an effort to automate\nthis task. We argue that CFL does not recommend coarsening in cases where\npragmatic considerations rule in favor of it, and recommends coarsening in\ncases where pragmatic considerations rule against it. We propose a new\ntechnique, pragmatic causal feature learning (PCFL), which extends the original\nCFL algorithm in useful and intuitive ways. We show that PCFL has the same\nattractive measure-theoretic properties as the original CFL algorithm. We\ncompare the performance of both methods through theoretical analysis and\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 15:13:59 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 11:38:12 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 10:31:05 GMT"}, {"version": "v4", "created": "Thu, 27 Aug 2020 18:56:41 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Kinney", "David", ""], ["Watson", "David", ""]]}, {"id": "2005.08797", "submitter": "Xin Wang", "authors": "Youle Wang, Guangxi Li, Xin Wang", "title": "Variational quantum Gibbs state preparation with a truncated Taylor\n  series", "comments": "23 pages including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cond-mat.stat-mech cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The preparation of quantum Gibbs state is an essential part of quantum\ncomputation and has wide-ranging applications in various areas, including\nquantum simulation, quantum optimization, and quantum machine learning. In this\npaper, we propose variational hybrid quantum-classical algorithms for quantum\nGibbs state preparation. We first utilize a truncated Taylor series to evaluate\nthe free energy and choose the truncated free energy as the loss function. Our\nprotocol then trains the parameterized quantum circuits to learn the desired\nquantum Gibbs state. Notably, this algorithm can be implemented on near-term\nquantum computers equipped with parameterized quantum circuits. By performing\nnumerical experiments, we show that shallow parameterized circuits with only\none additional qubit can be trained to prepare the Ising chain and spin chain\nGibbs states with a fidelity higher than 95%. In particular, for the Ising\nchain model, we find that a simplified circuit ansatz with only one parameter\nand one additional qubit can be trained to realize a 99% fidelity in Gibbs\nstate preparation at inverse temperatures larger than 2.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 15:17:09 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Wang", "Youle", ""], ["Li", "Guangxi", ""], ["Wang", "Xin", ""]]}, {"id": "2005.08803", "submitter": "Ehsan Haghighat", "authors": "Ehsan Haghighat and Ruben Juanes", "title": "SciANN: A Keras/Tensorflow wrapper for scientific computations and\n  physics-informed deep learning using artificial neural networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2020.113552", "report-no": null, "categories": "cs.OH cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce SciANN, a Python package for scientific computing\nand physics-informed deep learning using artificial neural networks. SciANN\nuses the widely used deep-learning packages Tensorflow and Keras to build deep\nneural networks and optimization models, thus inheriting many of Keras's\nfunctionalities, such as batch optimization and model reuse for transfer\nlearning. SciANN is designed to abstract neural network construction for\nscientific computations and solution and discovery of partial differential\nequations (PDE) using the physics-informed neural networks (PINN) architecture,\ntherefore providing the flexibility to set up complex functional forms. We\nillustrate, in a series of examples, how the framework can be used for curve\nfitting on discrete data, and for solution and discovery of PDEs in strong and\nweak forms. We summarize the features currently available in SciANN, and also\noutline ongoing and future developments.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 22:55:15 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 03:18:44 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Haghighat", "Ehsan", ""], ["Juanes", "Ruben", ""]]}, {"id": "2005.08812", "submitter": "Jiangning Zhang", "authors": "Jiangning Zhang, Liang Liu, Chao Xu, Yong Liu", "title": "Hierarchical and Efficient Learning for Person Re-Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works in the person re-identification task mainly focus on the model\naccuracy while ignore factors related to the efficiency, e.g. model size and\nlatency, which are critical for practical application. In this paper, we\npropose a novel Hierarchical and Efficient Network (HENet) that learns\nhierarchical global, partial, and recovery features ensemble under the\nsupervision of multiple loss combinations. To further improve the robustness\nagainst the irregular occlusion, we propose a new dataset augmentation\napproach, dubbed Random Polygon Erasing (RPE), to random erase irregular area\nof the input image for imitating the body part missing. We also propose an\nEfficiency Score (ES) metric to evaluate the model efficiency. Extensive\nexperiments on Market1501, DukeMTMC-ReID, and CUHK03 datasets shows the\nefficiency and superiority of our approach compared with epoch-making methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 15:45:25 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Zhang", "Jiangning", ""], ["Liu", "Liang", ""], ["Xu", "Chao", ""], ["Liu", "Yong", ""]]}, {"id": "2005.08837", "submitter": "Ahmed Alaa", "authors": "Zhaozhi Qian, Ahmed M. Alaa, Mihaela van der Schaar", "title": "When and How to Lift the Lockdown? Global COVID-19 Scenario Analysis and\n  Policy Assessment using Compartmental Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coronavirus disease 2019 (COVID-19) global pandemic has led many\ncountries to impose unprecedented lockdown measures in order to slow down the\noutbreak. Questions on whether governments have acted promptly enough, and\nwhether lockdown measures can be lifted soon have since been central in public\ndiscourse. Data-driven models that predict COVID-19 fatalities under different\nlockdown policy scenarios are essential for addressing these questions and\ninforming governments on future policy directions. To this end, this paper\ndevelops a Bayesian model for predicting the effects of COVID-19 lockdown\npolicies in a global context -- we treat each country as a distinct data point,\nand exploit variations of policies across countries to learn country-specific\npolicy effects. Our model utilizes a two-layer Gaussian process (GP) prior --\nthe lower layer uses a compartmental SEIR (Susceptible, Exposed, Infected,\nRecovered) model as a prior mean function with \"country-and-policy-specific\"\nparameters that capture fatality curves under \"counterfactual\" policies within\neach country, whereas the upper layer is shared across all countries, and\nlearns lower-layer SEIR parameters as a function of a country's features and\nits policy indicators. Our model combines the solid mechanistic foundations of\nSEIR models (Bayesian priors) with the flexible data-driven modeling and\ngradient-based optimization routines of machine learning (Bayesian posteriors)\n-- i.e., the entire model is trained end-to-end via stochastic variational\ninference. We compare the projections of COVID-19 fatalities by our model with\nother models listed by the Center for Disease Control (CDC), and provide\nscenario analyses for various lockdown and reopening strategies highlighting\ntheir impact on COVID-19 fatalities.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 18:21:50 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 16:55:22 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Qian", "Zhaozhi", ""], ["Alaa", "Ahmed M.", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2005.08844", "submitter": "Donghoon Lee", "authors": "Donghoon Lee", "title": "Entropy-Augmented Entropy-Regularized Reinforcement Learning and a\n  Continuous Path from Policy Gradient to Q-Learning", "comments": "16 pages, 1 figure. refined a few expressions, proofs. added source\n  code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy augmented to reward is known to soften the greedy argmax policy to\nsoftmax policy. Entropy augmentation is reformulated and leads to a motivation\nto introduce an additional entropy term to the objective function in the form\nof KL-divergence to regularize optimization process. It results in a policy\nwhich monotonically improves while interpolating from the current policy to the\nsoftmax greedy policy. This policy is used to build a continuously\nparameterized algorithm which optimize policy and Q-function simultaneously and\nwhose extreme limits correspond to policy gradient and Q-learning,\nrespectively. Experiments show that there can be a performance gain using an\nintermediate algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 16:15:44 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 17:21:40 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Lee", "Donghoon", ""]]}, {"id": "2005.08848", "submitter": "Jack Weston", "authors": "Raphael Lenain, Jack Weston, Abhishek Shivkumar, Emil Fristed", "title": "Surfboard: Audio Feature Extraction for Modern Machine Learning", "comments": "5 pages. 0 figures. Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Surfboard, an open-source Python library for extracting audio\nfeatures with application to the medical domain. Surfboard is written with the\naim of addressing pain points of existing libraries and facilitating joint use\nwith modern machine learning frameworks. The package can be accessed both\nprogrammatically in Python and via its command line interface, allowing it to\nbe easily integrated within machine learning workflows. It builds on\nstate-of-the-art audio analysis packages and offers multiprocessing support for\nprocessing large workloads. We review similar frameworks and describe\nSurfboard's architecture, including the clinical motivation for its features.\nUsing the mPower dataset, we illustrate Surfboard's application to a\nParkinson's disease classification task, highlighting common pitfalls in\nexisting research. The source code is opened up to the research community to\nfacilitate future audio research in the clinical domain.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 16:20:20 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Lenain", "Raphael", ""], ["Weston", "Jack", ""], ["Shivkumar", "Abhishek", ""], ["Fristed", "Emil", ""]]}, {"id": "2005.08854", "submitter": "Waheed Bajwa", "authors": "Matthew Nokleby, Haroon Raja, and Waheed U. Bajwa", "title": "Scaling-up Distributed Processing of Data Streams for Machine Learning", "comments": "45 pages, 9 figures; preprint of a journal paper published in\n  Proceedings of the IEEE (Special Issue on Optimization for Data-driven\n  Learning and Control)", "journal-ref": "Proc. of the IEEE, vol. 108, no. 11, pp. 1984-2012, Nov. 2020", "doi": "10.1109/JPROC.2020.3021381", "report-no": null, "categories": "cs.LG cs.DC eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging applications of machine learning in numerous areas involve\ncontinuous gathering of and learning from streams of data. Real-time\nincorporation of streaming data into the learned models is essential for\nimproved inference in these applications. Further, these applications often\ninvolve data that are either inherently gathered at geographically distributed\nentities or that are intentionally distributed across multiple machines for\nmemory, computational, and/or privacy reasons. Training of models in this\ndistributed, streaming setting requires solving stochastic optimization\nproblems in a collaborative manner over communication links between the\nphysical entities. When the streaming data rate is high compared to the\nprocessing capabilities of compute nodes and/or the rate of the communications\nlinks, this poses a challenging question: how can one best leverage the\nincoming data for distributed training under constraints on computing\ncapabilities and/or communications rate? A large body of research has emerged\nin recent decades to tackle this and related problems. This paper reviews\nrecently developed methods that focus on large-scale distributed stochastic\noptimization in the compute- and bandwidth-limited regime, with an emphasis on\nconvergence analysis that explicitly accounts for the mismatch between\ncomputation, communication and streaming rates. In particular, it focuses on\nmethods that solve: (i) distributed stochastic convex problems, and (ii)\ndistributed principal component analysis, which is a nonconvex problem with\ngeometric structure that permits global convergence. For such methods, the\npaper discusses recent advances in terms of distributed algorithmic designs\nwhen faced with high-rate streaming data. Further, it reviews guarantees\nunderlying these methods, which show there exist regimes in which systems can\nlearn from distributed, streaming data at order-optimal rates.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 16:28:54 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 23:48:59 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Nokleby", "Matthew", ""], ["Raja", "Haroon", ""], ["Bajwa", "Waheed U.", ""]]}, {"id": "2005.08859", "submitter": "Khashayar Filom", "authors": "Khashayar Filom, Konrad Paul Kording, Roozbeh Farhoodi", "title": "PDE constraints on smooth hierarchical functions computed by neural\n  networks", "comments": "52 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are versatile tools for computation, having the ability to\napproximate a broad range of functions. An important problem in the theory of\ndeep neural networks is expressivity; that is, we want to understand the\nfunctions that are computable by a given network. We study real infinitely\ndifferentiable (smooth) hierarchical functions implemented by feedforward\nneural networks via composing simpler functions in two cases:\n  1) each constituent function of the composition has fewer inputs than the\nresulting function;\n  2) constituent functions are in the more specific yet prevalent form of a\nnon-linear univariate function (e.g. tanh) applied to a linear multivariate\nfunction.\n  We establish that in each of these regimes there exist non-trivial algebraic\npartial differential equations (PDEs), which are satisfied by the computed\nfunctions. These PDEs are purely in terms of the partial derivatives and are\ndependent only on the topology of the network. For compositions of polynomial\nfunctions, the algebraic PDEs yield non-trivial equations (of degrees dependent\nonly on the architecture) in the ambient polynomial space that are satisfied on\nthe associated functional varieties. Conversely, we conjecture that such PDE\nconstraints, once accompanied by appropriate non-singularity conditions and\nperhaps certain inequalities involving partial derivatives, guarantee that the\nsmooth function under consideration can be represented by the network. The\nconjecture is verified in numerous examples including the case of tree\narchitectures which are of neuroscientific interest. Our approach is a step\ntoward formulating an algebraic description of functional spaces associated\nwith specific neural networks, and may provide new, useful tools for\nconstructing neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 16:34:11 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Filom", "Khashayar", ""], ["Kording", "Konrad Paul", ""], ["Farhoodi", "Roozbeh", ""]]}, {"id": "2005.08868", "submitter": "Mostafa Shahriari", "authors": "M. Shahriari, D. Pardo, J. A. Rivera, C. Torres-Verd\\'in, A. Picon, J.\n  Del Ser, S. Ossand\\'on, V. M. Calo", "title": "Error Control and Loss Functions for the Deep Learning Inversion of\n  Borehole Resistivity Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) is a numerical method that approximates functions.\nRecently, its use has become attractive for the simulation and inversion of\nmultiple problems in computational mechanics, including the inversion of\nborehole logging measurements for oil and gas applications. In this context, DL\nmethods exhibit two key attractive features: a) once trained, they enable to\nsolve an inverse problem in a fraction of a second, which is convenient for\nborehole geosteering operations as well as in other real-time inversion\napplications. b) DL methods exhibit a superior capability for approximating\nhighly-complex functions across different areas of knowledge. Nevertheless, as\nit occurs with most numerical methods, DL also relies on expert design\ndecisions that are problem specific to achieve reliable and robust results.\nHerein, we investigate two key aspects of deep neural networks (DNNs) when\napplied to the inversion of borehole resistivity measurements: error control\nand adequate selection of the loss function. As we illustrate via theoretical\nconsiderations and extensive numerical experiments, these interrelated aspects\nare critical to recover accurate inversion results.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 15:14:59 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 14:37:04 GMT"}, {"version": "v3", "created": "Thu, 28 May 2020 10:59:04 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Shahriari", "M.", ""], ["Pardo", "D.", ""], ["Rivera", "J. A.", ""], ["Torres-Verd\u00edn", "C.", ""], ["Picon", "A.", ""], ["Del Ser", "J.", ""], ["Ossand\u00f3n", "S.", ""], ["Calo", "V. M.", ""]]}, {"id": "2005.08869", "submitter": "Tom Van Sonsbeek", "authors": "Tom van Sonsbeek and Veronika Cheplygina", "title": "Predicting Scores of Medical Imaging Segmentation Methods with\n  Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has led to state-of-the-art results for many medical imaging\ntasks, such as segmentation of different anatomical structures. With the\nincreased numbers of deep learning publications and openly available code, the\napproach to choosing a model for a new task becomes more complicated, while\ntime and (computational) resources are limited. A possible solution to choosing\na model efficiently is meta-learning, a learning method in which prior\nperformance of a model is used to predict the performance for new tasks. We\ninvestigate meta-learning for segmentation across ten datasets of different\norgans and modalities. We propose four ways to represent each dataset by\nmeta-features: one based on statistical features of the images and three are\nbased on deep learning features. We use support vector regression and deep\nneural networks to learn the relationship between the meta-features and prior\nmodel performance. On three external test datasets these methods give Dice\nscores within 0.10 of the true performance. These results demonstrate the\npotential of meta-learning in medical imaging.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 07:47:52 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["van Sonsbeek", "Tom", ""], ["Cheplygina", "Veronika", ""]]}, {"id": "2005.08874", "submitter": "Tobias Huber", "authors": "Tobias Huber, Katharina Weitz, Elisabeth Andr\\'e, Ofra Amir", "title": "Local and Global Explanations of Agent Behavior: Integrating Strategy\n  Summaries with Saliency Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With advances in reinforcement learning (RL), agents are now being developed\nin high-stakes application domains such as healthcare and transportation.\nExplaining the behavior of these agents is challenging, as the environments in\nwhich they act have large state spaces, and their decision-making can be\naffected by delayed rewards, making it difficult to analyze their behavior. To\naddress this problem, several approaches have been developed. Some approaches\nattempt to convey the $\\textit{global}$ behavior of the agent, describing the\nactions it takes in different states. Other approaches devised $\\textit{local}$\nexplanations which provide information regarding the agent's decision-making in\na particular state. In this paper, we combine global and local explanation\nmethods, and evaluate their joint and separate contributions, providing (to the\nbest of our knowledge) the first user study of combined local and global\nexplanations for RL agents. Specifically, we augment strategy summaries that\nextract important trajectories of states from simulations of the agent with\nsaliency maps which show what information the agent attends to. Our results\nshow that the choice of what states to include in the summary (global\ninformation) strongly affects people's understanding of agents: participants\nshown summaries that included important states significantly outperformed\nparticipants who were presented with agent behavior in a randomly set of chosen\nworld-states. We find mixed results with respect to augmenting demonstrations\nwith saliency maps (local information), as the addition of saliency maps did\nnot significantly improve performance in most cases. However, we do find some\nevidence that saliency maps can help users better understand what information\nthe agent relies on in its decision making, suggesting avenues for future work\nthat can further improve explanations of RL agents.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 16:44:55 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 17:34:10 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 17:54:59 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Huber", "Tobias", ""], ["Weitz", "Katharina", ""], ["Andr\u00e9", "Elisabeth", ""], ["Amir", "Ofra", ""]]}, {"id": "2005.08877", "submitter": "Danhang Tang", "authors": "Danhang Tang and Saurabh Singh and Philip A. Chou and Christian Haene\n  and Mingsong Dou and Sean Fanello and Jonathan Taylor and Philip Davidson and\n  Onur G. Guleryuz and Yinda Zhang and Shahram Izadi and Andrea Tagliasacchi\n  and Sofien Bouaziz and Cem Keskin", "title": "Deep Implicit Volume Compression", "comments": "Danhang Tang and Saurabh Singh have equal contribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We describe a novel approach for compressing truncated signed distance fields\n(TSDF) stored in 3D voxel grids, and their corresponding textures. To compress\nthe TSDF, our method relies on a block-based neural network architecture\ntrained end-to-end, achieving state-of-the-art rate-distortion trade-off. To\nprevent topological errors, we losslessly compress the signs of the TSDF, which\nalso upper bounds the reconstruction error by the voxel size. To compress the\ncorresponding texture, we designed a fast block-based UV parameterization,\ngenerating coherent texture maps that can be effectively compressed using\nexisting video compression algorithms. We demonstrate the performance of our\nalgorithms on two 4D performance capture datasets, reducing bitrate by 66% for\nthe same distortion, or alternatively reducing the distortion by 50% for the\nsame bitrate, compared to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 16:46:13 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Tang", "Danhang", ""], ["Singh", "Saurabh", ""], ["Chou", "Philip A.", ""], ["Haene", "Christian", ""], ["Dou", "Mingsong", ""], ["Fanello", "Sean", ""], ["Taylor", "Jonathan", ""], ["Davidson", "Philip", ""], ["Guleryuz", "Onur G.", ""], ["Zhang", "Yinda", ""], ["Izadi", "Shahram", ""], ["Tagliasacchi", "Andrea", ""], ["Bouaziz", "Sofien", ""], ["Keskin", "Cem", ""]]}, {"id": "2005.08892", "submitter": "Christopher Ren", "authors": "Christopher X. Ren, Amanda Ziemann, James Theiler, Alice M. S. Durieux", "title": "Deep Snow: Synthesizing Remote Sensing Imagery with Generative\n  Adversarial Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we demonstrate that generative adversarial networks (GANs) can\nbe used to generate realistic pervasive changes in remote sensing imagery, even\nin an unpaired training setting. We investigate some transformation quality\nmetrics based on deep embedding of the generated and real images which enable\nvisualization and understanding of the training dynamics of the GAN, and may\nprovide a useful measure in terms of quantifying how distinguishable the\ngenerated images are from real images. We also identify some artifacts\nintroduced by the GAN in the generated images, which are likely to contribute\nto the differences seen between the real and generated samples in the deep\nembedding feature space even in cases where the real and generated samples\nappear perceptually similar.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 17:05:00 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Ren", "Christopher X.", ""], ["Ziemann", "Amanda", ""], ["Theiler", "James", ""], ["Durieux", "Alice M. S.", ""]]}, {"id": "2005.08898", "submitter": "Tian Tong", "authors": "Tian Tong, Cong Ma, Yuejie Chi", "title": "Accelerating Ill-Conditioned Low-Rank Matrix Estimation via Scaled\n  Gradient Descent", "comments": "Accepted to Journal of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank matrix estimation is a canonical problem that finds numerous\napplications in signal processing, machine learning and imaging science. A\npopular approach in practice is to factorize the matrix into two compact\nlow-rank factors, and then optimize these factors directly via simple iterative\nmethods such as gradient descent and alternating minimization. Despite\nnonconvexity, recent literatures have shown that these simple heuristics in\nfact achieve linear convergence when initialized properly for a growing number\nof problems of interest. However, upon closer examination, existing approaches\ncan still be computationally expensive especially for ill-conditioned matrices:\nthe convergence rate of gradient descent depends linearly on the condition\nnumber of the low-rank matrix, while the per-iteration cost of alternating\nminimization is often prohibitive for large matrices. The goal of this paper is\nto set forth a competitive algorithmic approach dubbed Scaled Gradient Descent\n(ScaledGD) which can be viewed as pre-conditioned or diagonally-scaled gradient\ndescent, where the pre-conditioners are adaptive and iteration-varying with a\nminimal computational overhead. With tailored variants for low-rank matrix\nsensing, robust principal component analysis and matrix completion, we\ntheoretically show that ScaledGD achieves the best of both worlds: it converges\nlinearly at a rate independent of the condition number of the low-rank matrix\nsimilar as alternating minimization, while maintaining the low per-iteration\ncost of gradient descent. Our analysis is also applicable to general loss\nfunctions that are restricted strongly convex and smooth over low-rank\nmatrices. To the best of our knowledge, ScaledGD is the first algorithm that\nprovably has such properties over a wide range of low-rank matrix estimation\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 17:17:16 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 03:13:06 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 18:20:43 GMT"}, {"version": "v4", "created": "Mon, 14 Jun 2021 20:11:50 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Tong", "Tian", ""], ["Ma", "Cong", ""], ["Chi", "Yuejie", ""]]}, {"id": "2005.08919", "submitter": "Sergey Alyaev", "authors": "Sergey Alyaev, Mostafa Shahriari, David Pardo, Angel Javier Omella,\n  David Larsen, Nazanin Jahani, Erich Suter", "title": "Modeling extra-deep EM logs using a deep neural network", "comments": "Submitted to SEG Geophysics", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern geosteering is heavily dependent on real-time interpretation of deep\nelectromagnetic (EM) measurements. This work presents a deep neural network\n(DNN) model trained to reproduce the full set of extra-deep real-time EM logs\nconsisting of 22 measurements per logging position. The model is trained in a\n1D layered environment and has sensitivity for up to seven layers with\ndifferent resistivity values. A commercial simulator provided by a tool vendor\nis utilized to generate a training dataset. The impossibility of parallel\nexecution of the simulator effectively limits the permissible dataset size.\nTherefore, the geological rules and geosteering specifics supported by the\nforward model are embraced when designing the dataset. It is then used to\nproduce a fully parallel EM simulator based on a DNN without access to the\nproprietary information about the EM tool configuration or the original\nsimulator source code. Despite a relatively small training set size, the\nresulting DNN forward model is quite accurate for synthetic geosteering cases,\nyet independent of the logging instrument vendor. The observed average\nevaluation time of 0.15 milliseconds per logging position makes it also\nsuitable for future use as part of evaluation-hungry statistical and/or\nMonte-Carlo inversion algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 17:45:46 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 09:32:54 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Alyaev", "Sergey", ""], ["Shahriari", "Mostafa", ""], ["Pardo", "David", ""], ["Omella", "Angel Javier", ""], ["Larsen", "David", ""], ["Jahani", "Nazanin", ""], ["Suter", "Erich", ""]]}, {"id": "2005.08926", "submitter": "Patrick Kidger", "authors": "Patrick Kidger, James Morrill, James Foster, Terry Lyons", "title": "Neural Controlled Differential Equations for Irregular Time Series", "comments": "Accepted at NeurIPS 2020 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural ordinary differential equations are an attractive option for modelling\ntemporal dynamics. However, a fundamental issue is that the solution to an\nordinary differential equation is determined by its initial condition, and\nthere is no mechanism for adjusting the trajectory based on subsequent\nobservations. Here, we demonstrate how this may be resolved through the\nwell-understood mathematics of \\emph{controlled differential equations}. The\nresulting \\emph{neural controlled differential equation} model is directly\napplicable to the general setting of partially-observed irregularly-sampled\nmultivariate time series, and (unlike previous work on this problem) it may\nutilise memory-efficient adjoint-based backpropagation even across\nobservations. We demonstrate that our model achieves state-of-the-art\nperformance against similar (ODE or RNN based) models in empirical studies on a\nrange of datasets. Finally we provide theoretical results demonstrating\nuniversal approximation, and that our model subsumes alternative ODE models.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 17:52:21 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 17:45:39 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Kidger", "Patrick", ""], ["Morrill", "James", ""], ["Foster", "James", ""], ["Lyons", "Terry", ""]]}, {"id": "2005.08931", "submitter": "Zechun Liu", "authors": "Zechun Liu and Xiangyu Zhang and Zhiqiang Shen and Zhe Li and Yichen\n  Wei and Kwang-Ting Cheng and Jian Sun", "title": "Joint Multi-Dimension Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present joint multi-dimension pruning (named as JointPruning), a new\nperspective of pruning a network on three crucial aspects: spatial, depth and\nchannel simultaneously. The joint strategy enables to search a better status\nthan previous studies that focused on individual dimension solely, as our\nmethod is optimized collaboratively across the three dimensions in a single\nend-to-end training. Moreover, each dimension that we consider can promote to\nget better performance through colluding with the other two. Our method is\nrealized by the adapted stochastic gradient estimation. Extensive experiments\non large-scale ImageNet dataset across a variety of network architectures\nMobileNet V1&V2 and ResNet demonstrate the effectiveness of our proposed\nmethod. For instance, we achieve significant margins of 2.5% and 2.6%\nimprovement over the state-of-the-art approach on the already compact MobileNet\nV1&V2 under an extremely large compression ratio.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 17:57:09 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Liu", "Zechun", ""], ["Zhang", "Xiangyu", ""], ["Shen", "Zhiqiang", ""], ["Li", "Zhe", ""], ["Wei", "Yichen", ""], ["Cheng", "Kwang-Ting", ""], ["Sun", "Jian", ""]]}, {"id": "2005.08942", "submitter": "J\\'anos V\\'egh", "authors": "J\\'anos V\\'egh", "title": "Which scaling rule applies to Artificial Neural Networks", "comments": "14 pages; 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although an ANN is a biology-mimicking system, it is built from components\ndesigned/fabricated for use in conventional computing, and it is created by\nexperts trained in conventional computing; all of them are using the classic\ncomputing paradigm. As von Neumann in his classic \"First Draft\" warned, because\nthe data transfer time is neglected in the model he used, using a \"too fast\nprocessor\" vitiates the procedure, furthermore, that using his paradigm for\nimitating neuronal operations, is unsound. This means that at least doubly\nunsound to apply his paradigm to describe scaling ANNs. The common experience\nshows that making actively cooperating and communicating computing systems,\nusing segregated single processors, has severe performance limitations; which\nfact cannot be explained using his classic paradigm. The achievable payload\ncomputing performance of those systems sensitively depends on their workload\ntype, and this effect is only poorly known. The type of the workload that the\nAI-based systems generate, leads to an exceptionally low payload computational\nperformance. Unfortunately, the initial successes of demo systems that comprise\nonly a few \"neurons\" and solve simple tasks are misleading: the scaling of\nprocessor-based ANN systems is strongly nonlinear. The paper discusses some\nmajor limiting factors that affect their performance. It points out that for\nbuilding biology-mimicking large systems, it is inevitable to perform drastic\nchanges in the present computing paradigm. Namely, instead of neglecting the\ntransfer time, a proper method to consider it shall be developed. The temporal\nbehavior enables us to comprehend the technical implementation of computing\ncomponents and architectures.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 19:52:55 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 01:02:45 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 18:38:09 GMT"}, {"version": "v4", "created": "Sat, 11 Jul 2020 15:53:02 GMT"}, {"version": "v5", "created": "Sun, 26 Jul 2020 18:22:44 GMT"}, {"version": "v6", "created": "Sat, 26 Sep 2020 18:40:40 GMT"}, {"version": "v7", "created": "Sun, 18 Oct 2020 08:38:24 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["V\u00e9gh", "J\u00e1nos", ""]]}, {"id": "2005.08948", "submitter": "Nuri Mert Vural", "authors": "N. Mert Vural, Fatih Ilhan, Selim F. Yilmaz, Salih Erg\\\"ut and\n  Suleyman S. Kozat", "title": "Achieving Online Regression Performance of LSTMs with Simple RNNs", "comments": "arXiv admin note: substantial text overlap with arXiv:2003.03601", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are widely used for online regression due to\ntheir ability to generalize nonlinear temporal dependencies. As an RNN model,\nLong-Short-Term-Memory Networks (LSTMs) are commonly preferred in practice, as\nthese networks are capable of learning long-term dependencies while avoiding\nthe vanishing gradient problem. However, due to their large number of\nparameters, training LSTMs requires considerably longer training time compared\nto simple RNNs (SRNNs). In this paper, we achieve the online regression\nperformance of LSTMs with SRNNs efficiently. To this end, we introduce a\nfirst-order training algorithm with a linear time complexity in the number of\nparameters. We show that when SRNNs are trained with our algorithm, they\nprovide very similar regression performance with the LSTMs in two to three\ntimes shorter training time. We provide strong theoretical analysis to support\nour experimental results by providing regret bounds on the convergence rate of\nour algorithm. Through an extensive set of experiments, we verify our\ntheoretical work and demonstrate significant performance improvements of our\nalgorithm with respect to LSTMs and the other state-of-the-art learning models.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 11:41:13 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 15:22:57 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Vural", "N. Mert", ""], ["Ilhan", "Fatih", ""], ["Yilmaz", "Selim F.", ""], ["Erg\u00fct", "Salih", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "2005.08968", "submitter": "Fengqi You", "authors": "Abdulelah S. Alshehri, Rafiqul Gani, Fengqi You", "title": "Deep Learning and Knowledge-Based Methods for Computer Aided Molecular\n  Design -- Toward a Unified Approach: State-of-the-Art and Future Directions", "comments": null, "journal-ref": "Computers and Chemical Engineering 141 (2020) 107005", "doi": "10.1016/j.compchemeng.2020.107005", "report-no": null, "categories": "q-bio.BM cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimal design of compounds through manipulating properties at the\nmolecular level is often the key to considerable scientific advances and\nimproved process systems performance. This paper highlights key trends,\nchallenges, and opportunities underpinning the Computer-Aided Molecular Design\n(CAMD) problems. A brief review of knowledge-driven property estimation methods\nand solution techniques, as well as corresponding CAMD tools and applications,\nare first presented. In view of the computational challenges plaguing\nknowledge-based methods and techniques, we survey the current state-of-the-art\napplications of deep learning to molecular design as a fertile approach towards\novercoming computational limitations and navigating uncharted territories of\nthe chemical space. The main focus of the survey is given to deep generative\nmodeling of molecules under various deep learning architectures and different\nmolecular representations. Further, the importance of benchmarking and\nempirical rigor in building deep learning models is spotlighted. The review\narticle also presents a detailed discussion of the current perspectives and\nchallenges of knowledge-based and data-driven CAMD and identifies key areas for\nfuture research directions. Special emphasis is on the fertile avenue of hybrid\nmodeling paradigm, in which deep learning approaches are exploited while\nleveraging the accumulated wealth of knowledge-driven CAMD methods and tools.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 14:17:51 GMT"}, {"version": "v2", "created": "Sun, 5 Jul 2020 15:00:54 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Alshehri", "Abdulelah S.", ""], ["Gani", "Rafiqul", ""], ["You", "Fengqi", ""]]}, {"id": "2005.09015", "submitter": "Hana Alghamdi", "authors": "Hana Alghamdi, Rozenn Dahyot", "title": "Patch based Colour Transfer using SIFT Flow", "comments": "8 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new colour transfer method with Optimal Transport (OT) to\ntransfer the colour of a sourceimage to match the colour of a target image of\nthe same scene that may exhibit large motion changes betweenimages. By\ndefinition OT does not take into account any available information about\ncorrespondences whencomputing the optimal solution. To tackle this problem we\npropose to encode overlapping neighborhoodsof pixels using both their colour\nand spatial correspondences estimated using motion estimation. We solvethe high\ndimensional problem in 1D space using an iterative projection approach. We\nfurther introducesmoothing as part of the iterative algorithms for solving\noptimal transport namely Iterative DistributionTransport (IDT) and its variant\nthe Sliced Wasserstein Distance (SWD). Experiments show quantitative\nandqualitative improvements over previous state of the art colour transfer\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 18:22:36 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Alghamdi", "Hana", ""], ["Dahyot", "Rozenn", ""]]}, {"id": "2005.09020", "submitter": "Anthony Constantinou", "authors": "Anthony C. Constantinou, Yang Liu, Kiattikun Chobtham, Zhigao Guo and\n  Neville K. Kitson", "title": "Large-scale empirical validation of Bayesian Network structure learning\n  algorithms with noisy data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous Bayesian Network (BN) structure learning algorithms have been\nproposed in the literature over the past few decades. Each publication makes an\nempirical or theoretical case for the algorithm proposed in that publication\nand results across studies are often inconsistent in their claims about which\nalgorithm is 'best'. This is partly because there is no agreed evaluation\napproach to determine their effectiveness. Moreover, each algorithm is based on\na set of assumptions, such as complete data and causal sufficiency, and tend to\nbe evaluated with data that conforms to these assumptions, however unrealistic\nthese assumptions may be in the real world. As a result, it is widely accepted\nthat synthetic performance overestimates real performance, although to what\ndegree this may happen remains unknown. This paper investigates the performance\nof 15 structure learning algorithms. We propose a methodology that applies the\nalgorithms to data that incorporates synthetic noise, in an effort to better\nunderstand the performance of structure learning algorithms when applied to\nreal data. Each algorithm is tested over multiple case studies, sample sizes,\ntypes of noise, and assessed with multiple evaluation criteria. This work\ninvolved approximately 10,000 graphs with a total structure learning runtime of\nseven months. It provides the first large-scale empirical validation of BN\nstructure learning algorithms under different assumptions of data noise. The\nresults suggest that traditional synthetic performance may overestimate\nreal-world performance by anywhere between 10% and more than 50%. They also\nshow that while score-based learning is generally superior to constraint-based\nlearning, a higher fitting score does not necessarily imply a more accurate\ncausal graph. To facilitate comparisons with future studies, we have made all\ndata, raw results, graphs and BN models freely available online.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 18:40:09 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 13:12:00 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Constantinou", "Anthony C.", ""], ["Liu", "Yang", ""], ["Chobtham", "Kiattikun", ""], ["Guo", "Zhigao", ""], ["Kitson", "Neville K.", ""]]}, {"id": "2005.09021", "submitter": "Tal Amir", "authors": "Tal Amir, Ronen Basri, Boaz Nadler", "title": "The Trimmed Lasso: Sparse Recovery Guarantees and Practical Optimization\n  by the Generalized Soft-Min Penalty", "comments": "49 pages; 7 figures; To appear in SIAM Journal on Mathematics of Data\n  Science (SIMODS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to solve the sparse approximation or best subset\nselection problem, namely find a $k$-sparse vector ${\\bf x}\\in\\mathbb{R}^d$\nthat minimizes the $\\ell_2$ residual $\\lVert A{\\bf x}-{\\bf y} \\rVert_2$. We\nconsider a regularized approach, whereby this residual is penalized by the\nnon-convex $\\textit{trimmed lasso}$, defined as the $\\ell_1$-norm of ${\\bf x}$\nexcluding its $k$ largest-magnitude entries. We prove that the trimmed lasso\nhas several appealing theoretical properties, and in particular derive sparse\nrecovery guarantees assuming successful optimization of the penalized\nobjective. Next, we show empirically that directly optimizing this objective\ncan be quite challenging. Instead, we propose a surrogate for the trimmed\nlasso, called the $\\textit{generalized soft-min}$. This penalty smoothly\ninterpolates between the classical lasso and the trimmed lasso, while taking\ninto account all possible $k$-sparse patterns. The generalized soft-min penalty\ninvolves summation over $\\binom{d}{k}$ terms, yet we derive a polynomial-time\nalgorithm to compute it. This, in turn, yields a practical method for the\noriginal sparse approximation problem. Via simulations, we demonstrate its\ncompetitive performance compared to current state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 18:43:06 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 21:50:13 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 21:44:57 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Amir", "Tal", ""], ["Basri", "Ronen", ""], ["Nadler", "Boaz", ""]]}, {"id": "2005.09023", "submitter": "Guido Novati", "authors": "Guido Novati, Hugues Lascombes de Laroussilhe, and Petros Koumoutsakos", "title": "Automating Turbulence Modeling by Multi-Agent Reinforcement Learning", "comments": "To be published in Nature Machine Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modeling of turbulent flows is critical to scientific and engineering\nproblems ranging from aircraft design to weather forecasting and climate\nprediction. Over the last sixty years numerous turbulence models have been\nproposed, largely based on physical insight and engineering intuition. Recent\nadvances in machine learning and data science have incited new efforts to\ncomplement these approaches. To date, all such efforts have focused on\nsupervised learning which, despite demonstrated promise, encounters\ndifficulties in generalizing beyond the distributions of the training data. In\nthis work we introduce multi-agent reinforcement learning (MARL) as an\nautomated discovery tool of turbulence models. We demonstrate the potential of\nthis approach on Large Eddy Simulations of homogeneous and isotropic turbulence\nusing as reward the recovery of the statistical properties of Direct Numerical\nSimulations. Here, the closure model is formulated as a control policy enacted\nby cooperating agents, which detect critical spatio-temporal patterns in the\nflow field to estimate the unresolved sub-grid scale (SGS) physics. The present\nresults are obtained with state-of-the-art algorithms based on experience\nreplay and compare favorably with established dynamic SGS modeling approaches.\nMoreover, we show that the present turbulence models generalize across grid\nsizes and flow conditions as expressed by the Reynolds numbers.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 18:45:09 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 11:25:26 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Novati", "Guido", ""], ["de Laroussilhe", "Hugues Lascombes", ""], ["Koumoutsakos", "Petros", ""]]}, {"id": "2005.09027", "submitter": "Pavel Levin", "authors": "Benjamin Gutelman and Pavel Levin", "title": "Efficient Image Gallery Representations at Scale Through Multi-Task\n  Learning", "comments": "Proceedings of the 43rd International ACM SIGIR Conference on\n  Research and Development in Information Retrieval", "journal-ref": null, "doi": "10.1145/3397271.3401433", "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image galleries provide a rich source of diverse information about a product\nwhich can be leveraged across many recommendation and retrieval applications.\nWe study the problem of building a universal image gallery encoder through\nmulti-task learning (MTL) approach and demonstrate that it is indeed a\npractical way to achieve generalizability of learned representations to new\ndownstream tasks. Additionally, we analyze the relative predictive performance\nof MTL-trained solutions against optimal and substantially more expensive\nsolutions, and find signals that MTL can be a useful mechanism to address\nsparsity in low-resource binary tasks.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 18:49:22 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 05:50:53 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2020 10:24:02 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Gutelman", "Benjamin", ""], ["Levin", "Pavel", ""]]}, {"id": "2005.09030", "submitter": "Shahaf Finder", "authors": "Shahaf E. Finder, Eran Treister, Oren Freifeld", "title": "Effective Learning of a GMRF Mixture Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a Gaussian Mixture Model (GMM) is hard when the number of parameters\nis too large given the amount of available data. As a remedy, we propose\nrestricting the GMM to a Gaussian Markov Random Field Mixture Model (GMRF-MM),\nas well as a new method for estimating the latter's sparse precision (i.e.,\ninverse covariance) matrices. When the sparsity pattern of each matrix is\nknown, we propose an efficient optimization method for the Maximum Likelihood\nEstimate (MLE) of that matrix. When it is unknown, we utilize the popular\nGraphical LASSO (GLASSO) to estimate that pattern. However, we show that even\nfor a single Gaussian, when GLASSO is tuned to successfully estimate the\nsparsity pattern, it does so at the price of a substantial bias of the values\nof the nonzero entries of the matrix, and we show that this problem only\nworsens in a mixture setting. To overcome this, we discard the non-zero values\nestimated by GLASSO, keep only its pattern estimate and use it within the\nproposed MLE method. This yields an effective two-step procedure that removes\nthe bias. We show that our \"debiasing\" approach outperforms GLASSO in both the\nsingle-GMRF and the GMRF-MM cases. We also show that when learning priors for\nimage patches, our method outperforms GLASSO even if we merely use an educated\nguess about the sparsity pattern, and that our GMRF-MM outperforms the baseline\nGMM on real and synthetic high-dimensional datasets. Our code is available at\n\\url{https://github.com/shahaffind/GMRF-MM}.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 19:00:14 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 07:59:19 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Finder", "Shahaf E.", ""], ["Treister", "Eran", ""], ["Freifeld", "Oren", ""]]}, {"id": "2005.09042", "submitter": "Ajith Suresh", "authors": "Arpita Patra and Ajith Suresh", "title": "BLAZE: Blazing Fast Privacy-Preserving Machine Learning", "comments": "The Network and Distributed System Security Symposium (NDSS) 2020", "journal-ref": null, "doi": "10.14722/ndss.2020.24202", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning tools have illustrated their potential in many significant\nsectors such as healthcare and finance, to aide in deriving useful inferences.\nThe sensitive and confidential nature of the data, in such sectors, raise\nnatural concerns for the privacy of data. This motivated the area of\nPrivacy-preserving Machine Learning (PPML) where privacy of the data is\nguaranteed. Typically, ML techniques require large computing power, which leads\nclients with limited infrastructure to rely on the method of Secure Outsourced\nComputation (SOC). In SOC setting, the computation is outsourced to a set of\nspecialized and powerful cloud servers and the service is availed on a\npay-per-use basis. In this work, we explore PPML techniques in the SOC setting\nfor widely used ML algorithms-- Linear Regression, Logistic Regression, and\nNeural Networks.\n  We propose BLAZE, a blazing fast PPML framework in the three server setting\ntolerating one malicious corruption over a ring (\\Z{\\ell}). BLAZE achieves the\nstronger security guarantee of fairness (all honest servers get the output\nwhenever the corrupt server obtains the same). Leveraging an input-independent\npreprocessing phase, BLAZE has a fast input-dependent online phase relying on\nefficient PPML primitives such as: (i) A dot product protocol for which the\ncommunication in the online phase is independent of the vector size, the first\nof its kind in the three server setting; (ii) A method for truncation that\nshuns evaluating expensive circuit for Ripple Carry Adders (RCA) and achieves a\nconstant round complexity. This improves over the truncation method of ABY3\n(Mohassel et al., CCS 2018) that uses RCA and consumes a round complexity that\nis of the order of the depth of RCA.\n  An extensive benchmarking of BLAZE for the aforementioned ML algorithms over\na 64-bit ring in both WAN and LAN settings shows massive improvements over\nABY3.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 19:18:22 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Patra", "Arpita", ""], ["Suresh", "Ajith", ""]]}, {"id": "2005.09047", "submitter": "Saeed Saremi", "authors": "Saeed Saremi", "title": "Learning and Inference in Imaginary Noise Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent developments in learning smoothed densities with empirical\nBayes, we study variational autoencoders with a decoder that is tailored for\nthe random variable $Y=X+N(0,\\sigma^2 I_d)$. A notion of smoothed variational\ninference emerges where the smoothing is implicitly enforced by the noise model\nof the decoder; \"implicit\", since during training the encoder only sees clean\nsamples. This is the concept of imaginary noise model, where the noise model\ndictates the functional form of the variational lower bound\n$\\mathcal{L}(\\sigma)$, but the noisy data are never seen during learning. The\nmodel is named $\\sigma$-VAE. We prove that all $\\sigma$-VAEs are equivalent to\neach other via a simple $\\beta$-VAE expansion: $\\mathcal{L}(\\sigma_2) \\equiv\n\\mathcal{L}(\\sigma_1,\\beta)$, where $\\beta=\\sigma_2^2/\\sigma_1^2$. We prove a\nsimilar result for the Laplace distribution in exponential families.\nEmpirically, we report an intriguing power law $\\mathcal{D}_{\\rm KL} \\sim\n\\sigma^{-\\nu}$ for the learned models and we study the inference in the\n$\\sigma$-VAE for unseen noisy data. The experiments were performed on MNIST,\nwhere we show that quite remarkably the model can make reasonable inferences on\nextremely noisy samples even though it has not seen any during training. The\nvanilla VAE completely breaks down in this regime. We finish with a hypothesis\n(the XYZ hypothesis) on the findings here.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 19:38:51 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 11:00:19 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 20:05:03 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Saremi", "Saeed", ""]]}, {"id": "2005.09048", "submitter": "Luis Scoccola", "authors": "Alexander Rolle, Luis Scoccola", "title": "Stable and consistent density-based clustering", "comments": "32 pages, 7 figures. v2: improves exposition, adds computational\n  examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a multiscale, consistent approach to density-based clustering that\nsatisfies stability theorems -- in both the input data and in the parameters --\nwhich hold without distributional assumptions. The stability in the input data\nis with respect to the Gromov--Hausdorff--Prokhorov distance on metric\nprobability spaces and interleaving distances between (multi-parameter)\nhierarchical clusterings we introduce. We prove stability results for standard\nsimplification procedures for hierarchical clusterings, which can be combined\nwith our approach to yield a stable flat clustering algorithm. We illustrate\nthe stability of the approach with computational examples. Our framework is\nbased on the concepts of persistence and interleaving distance from Topological\nData Analysis.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 19:45:04 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 17:38:01 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Rolle", "Alexander", ""], ["Scoccola", "Luis", ""]]}, {"id": "2005.09052", "submitter": "Padraig Cunningham", "authors": "Padraig Cunningham, Sarah Jane Delany", "title": "Underestimation Bias and Underfitting in Machine Learning", "comments": "12 pages, 7 figures, 3 tables", "journal-ref": "In: Heintz F., Milano M., O'Sullivan B. (eds) Trustworthy AI -\n  Integrating Learning, Optimization and Reasoning. TAILOR 2020. Lecture Notes\n  in Computer Science, vol 12641. Springer, Cham", "doi": "10.1007/978-3-030-73959-1_2", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often, what is termed algorithmic bias in machine learning will be due to\nhistoric bias in the training data. But sometimes the bias may be introduced\n(or at least exacerbated) by the algorithm itself. The ways in which algorithms\ncan actually accentuate bias has not received a lot of attention with\nresearchers focusing directly on methods to eliminate bias - no matter the\nsource. In this paper we report on initial research to understand the factors\nthat contribute to bias in classification algorithms. We believe this is\nimportant because underestimation bias is inextricably tied to regularization,\ni.e. measures to address overfitting can accentuate bias.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 20:01:56 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 11:53:07 GMT"}, {"version": "v3", "created": "Thu, 11 Feb 2021 09:41:48 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Cunningham", "Padraig", ""], ["Delany", "Sarah Jane", ""]]}, {"id": "2005.09056", "submitter": "Christina Kumler", "authors": "Christina Kumler-Bonfanti, Jebb Stewart, David Hall, Mark Govett", "title": "Tropical and Extratropical Cyclone Detection Using Deep Learning", "comments": "23 pages, 7 figures, 3 tables", "journal-ref": null, "doi": "10.1175/JAMC-D-20-0117.1", "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting valuable information from large sets of diverse meteorological\ndata is a time-intensive process. Machine learning methods can help improve\nboth speed and accuracy of this process. Specifically, deep learning image\nsegmentation models using the U-Net structure perform faster and can identify\nareas missed by more restrictive approaches, such as expert hand-labeling and a\npriori heuristic methods. This paper discusses four different state-of-the-art\nU-Net models designed for detection of tropical and extratropical cyclone\nRegions Of Interest (ROI) from two separate input sources: total precipitable\nwater output from the Global Forecasting System (GFS) model and water vapor\nradiance images from the Geostationary Operational Environmental Satellite\n(GOES). These models are referred to as IBTrACS-GFS, Heuristic-GFS,\nIBTrACS-GOES, and Heuristic-GOES. All four U-Nets are fast information\nextraction tools and perform with a ROI detection accuracy ranging from 80% to\n99%. These are additionally evaluated with the Dice and Tversky Intersection\nover Union (IoU) metrics, having Dice coefficient scores ranging from 0.51 to\n0.76 and Tversky coefficients ranging from 0.56 to 0.74. The extratropical\ncyclone U-Net model performed 3 times faster than the comparable heuristic\nmodel used to detect the same ROI. The U-Nets were specifically selected for\ntheir capabilities in detecting cyclone ROI beyond the scope of the training\nlabels. These machine learning models identified more ambiguous and active ROI\nmissed by the heuristic model and hand-labeling methods commonly used in\ngenerating real-time weather alerts, having a potentially direct impact on\npublic safety.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 20:09:20 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Kumler-Bonfanti", "Christina", ""], ["Stewart", "Jebb", ""], ["Hall", "David", ""], ["Govett", "Mark", ""]]}, {"id": "2005.09059", "submitter": "Taiyu Zhu", "authors": "Taiyu Zhu, Kezhi Li, Pau Herrero, Pantelis Georgiou", "title": "Basal Glucose Control in Type 1 Diabetes using Deep Reinforcement\n  Learning: An In Silico Validation", "comments": null, "journal-ref": "IEEE journal of biomedical and health informatics 2020", "doi": "10.1109/JBHI.2020.3014556", "report-no": null, "categories": "eess.SP cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People with Type 1 diabetes (T1D) require regular exogenous infusion of\ninsulin to maintain their blood glucose concentration in a therapeutically\nadequate target range. Although the artificial pancreas and continuous glucose\nmonitoring have been proven to be effective in achieving closed-loop control,\nsignificant challenges still remain due to the high complexity of glucose\ndynamics and limitations in the technology. In this work, we propose a novel\ndeep reinforcement learning model for single-hormone (insulin) and dual-hormone\n(insulin and glucagon) delivery. In particular, the delivery strategies are\ndeveloped by double Q-learning with dilated recurrent neural networks. For\ndesigning and testing purposes, the FDA-accepted UVA/Padova Type 1 simulator\nwas employed. First, we performed long-term generalized training to obtain a\npopulation model. Then, this model was personalized with a small data-set of\nsubject-specific data. In silico results show that the single and dual-hormone\ndelivery strategies achieve good glucose control when compared to a standard\nbasal-bolus therapy with low-glucose insulin suspension. Specifically, in the\nadult cohort (n=10), percentage time in target range [70, 180] mg/dL improved\nfrom 77.6% to 80.9% with single-hormone control, and to $85.6\\%$ with\ndual-hormone control. In the adolescent cohort (n=10), percentage time in\ntarget range improved from 55.5% to 65.9% with single-hormone control, and to\n78.8% with dual-hormone control. In all scenarios, a significant decrease in\nhypoglycemia was observed. These results show that the use of deep\nreinforcement learning is a viable approach for closed-loop glucose control in\nT1D.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 20:13:16 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Zhu", "Taiyu", ""], ["Li", "Kezhi", ""], ["Herrero", "Pau", ""], ["Georgiou", "Pantelis", ""]]}, {"id": "2005.09065", "submitter": "Shane Barratt", "authors": "Shane Barratt, Guillermo Angeris, Stephen Boyd", "title": "Optimal Representative Sample Weighting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of assigning weights to a set of samples or data\nrecords, with the goal of achieving a representative weighting, which happens\nwhen certain sample averages of the data are close to prescribed values. We\nframe the problem of finding representative sample weights as an optimization\nproblem, which in many cases is convex and can be efficiently solved. Our\nformulation includes as a special case the selection of a fixed number of the\nsamples, with equal weights, i.e., the problem of selecting a smaller\nrepresentative subset of the samples. While this problem is combinatorial and\nnot convex, heuristic methods based on convex optimization seem to perform very\nwell. We describe rsw, an open-source implementation of the ideas described in\nthis paper, and apply it to a skewed sample of the CDC BRFSS dataset.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 20:29:00 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Barratt", "Shane", ""], ["Angeris", "Guillermo", ""], ["Boyd", "Stephen", ""]]}, {"id": "2005.09069", "submitter": "Vivek Gupta", "authors": "Vivek Gupta, Ankit Saw, Pegah Nokhiz, Praneeth Netrapalli, Piyush Rai,\n  Partha Talukdar", "title": "P-SIF: Document Embeddings Using Partition Averaging", "comments": "15 Pages, 3 Figures, 13 Tables, AAAI 2020, Blog :\n  http://vivgupt.blogspot.com/2019/06/document-vector-estimation-using.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Simple weighted averaging of word vectors often yields effective\nrepresentations for sentences which outperform sophisticated seq2seq neural\nmodels in many tasks. While it is desirable to use the same method to represent\ndocuments as well, unfortunately, the effectiveness is lost when representing\nlong documents involving multiple sentences. One of the key reasons is that a\nlonger document is likely to contain words from many different topics; hence,\ncreating a single vector while ignoring all the topical structure is unlikely\nto yield an effective document representation. This problem is less acute in\nsingle sentences and other short text fragments where the presence of a single\ntopic is most likely. To alleviate this problem, we present P-SIF, a\npartitioned word averaging model to represent long documents. P-SIF retains the\nsimplicity of simple weighted word averaging while taking a document's topical\nstructure into account. In particular, P-SIF learns topic-specific vectors from\na document and finally concatenates them all to represent the overall document.\nWe provide theoretical justifications on the correctness of P-SIF. Through a\ncomprehensive set of experiments, we demonstrate P-SIF's effectiveness compared\nto simple weighted averaging and many other baselines.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 20:41:12 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Gupta", "Vivek", ""], ["Saw", "Ankit", ""], ["Nokhiz", "Pegah", ""], ["Netrapalli", "Praneeth", ""], ["Rai", "Piyush", ""], ["Talukdar", "Partha", ""]]}, {"id": "2005.09110", "submitter": "Alessandro Lameiras Koerich", "authors": "Voncarlos M. Araujo, Alceu S. Britto Jr., Luiz E. S. Oliveira and\n  Alessandro L. Koerich", "title": "Two-View Fine-grained Classification of Plant Species", "comments": "Submitted to Ecological Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic plant classification is a challenging problem due to the wide\nbiodiversity of the existing plant species in a fine-grained scenario. Powerful\ndeep learning architectures have been used to improve the classification\nperformance in such a fine-grained problem, but usually building models that\nare highly dependent on a large training dataset and which are not scalable. In\nthis paper, we propose a novel method based on a two-view leaf image\nrepresentation and a hierarchical classification strategy for fine-grained\nrecognition of plant species. It uses the botanical taxonomy as a basis for a\ncoarse-to-fine strategy applied to identify the plant genus and species. The\ntwo-view representation provides complementary global and local features of\nleaf images. A deep metric based on Siamese convolutional neural networks is\nused to reduce the dependence on a large number of training samples and make\nthe method scalable to new plant species. The experimental results on two\nchallenging fine-grained datasets of leaf images (i.e. LifeCLEF 2015 and\nLeafSnap) have shown the effectiveness of the proposed method, which achieved\nrecognition accuracy of 0.87 and 0.96 respectively.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 21:57:47 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Araujo", "Voncarlos M.", ""], ["Britto", "Alceu S.", "Jr."], ["Oliveira", "Luiz E. S.", ""], ["Koerich", "Alessandro L.", ""]]}, {"id": "2005.09112", "submitter": "Qingguo Wang", "authors": "Kimberly Glock, Charlie Napier, Andre Louie, Todd Gary, Joseph\n  Gigante, William Schaffner, Qingguo Wang", "title": "Measles Rash Identification Using Residual Deep Convolutional Neural\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measles is extremely contagious and is one of the leading causes of\nvaccine-preventable illness and death in developing countries, claiming more\nthan 100,000 lives each year. Measles was declared eliminated in the US in 2000\ndue to decades of successful vaccination for the measles. As a result, an\nincreasing number of US healthcare professionals and the public have never seen\nthe disease. Unfortunately, the Measles resurged in the US in 2019 with 1,282\nconfirmed cases. To assist in diagnosing measles, we collected more than 1300\nimages of a variety of skin conditions, with which we employed residual deep\nconvolutional neural network to distinguish measles rash from other skin\nconditions, in an aim to create a phone application in the future. On our image\ndataset, our model reaches a classification accuracy of 95.2%, sensitivity of\n81.7%, and specificity of 97.1%, indicating the model is effective in\nfacilitating an accurate detection of measles to help contain measles\noutbreaks.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 22:02:43 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 16:20:32 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 18:56:59 GMT"}, {"version": "v4", "created": "Tue, 11 Aug 2020 07:26:59 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Glock", "Kimberly", ""], ["Napier", "Charlie", ""], ["Louie", "Andre", ""], ["Gary", "Todd", ""], ["Gigante", "Joseph", ""], ["Schaffner", "William", ""], ["Wang", "Qingguo", ""]]}, {"id": "2005.09117", "submitter": "Avner May", "authors": "Simran Arora, Avner May, Jian Zhang, Christopher R\\'e", "title": "Contextual Embeddings: When Are They Worth It?", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the settings for which deep contextual embeddings (e.g., BERT) give\nlarge improvements in performance relative to classic pretrained embeddings\n(e.g., GloVe), and an even simpler baseline---random word embeddings---focusing\non the impact of the training set size and the linguistic properties of the\ntask. Surprisingly, we find that both of these simpler baselines can match\ncontextual embeddings on industry-scale data, and often perform within 5 to 10%\naccuracy (absolute) on benchmark tasks. Furthermore, we identify properties of\ndata for which contextual embeddings give particularly large gains: language\ncontaining complex structure, ambiguous word usage, and words unseen in\ntraining.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 22:20:17 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Arora", "Simran", ""], ["May", "Avner", ""], ["Zhang", "Jian", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2005.09123", "submitter": "Manuel Mager", "authors": "Manuel Mager, Ramon Fernandez Astudillo, Tahira Naseem, Md Arafat\n  Sultan, Young-Suk Lee, Radu Florian and Salim Roukos", "title": "GPT-too: A language-model-first approach for AMR-to-text generation", "comments": "Paper accepted to the Annual Meeting of the Association for\n  Computational Linguistics (ACL 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Meaning Representations (AMRs) are broad-coverage sentence-level semantic\ngraphs. Existing approaches to generating text from AMR have focused on\ntraining sequence-to-sequence or graph-to-sequence models on AMR annotated data\nonly. In this paper, we propose an alternative approach that combines a strong\npre-trained language model with cycle consistency-based re-scoring. Despite the\nsimplicity of the approach, our experimental results show these models\noutperform all previous techniques on the English LDC2017T10dataset, including\nthe recent use of transformer architectures. In addition to the standard\nevaluation metrics, we provide human evaluation experiments that further\nsubstantiate the strength of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 22:50:26 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 11:24:29 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Mager", "Manuel", ""], ["Astudillo", "Ramon Fernandez", ""], ["Naseem", "Tahira", ""], ["Sultan", "Md Arafat", ""], ["Lee", "Young-Suk", ""], ["Florian", "Radu", ""], ["Roukos", "Salim", ""]]}, {"id": "2005.09134", "submitter": "Linhai Ma", "authors": "Linhai Ma, Liang Liang", "title": "Improve robustness of DNN for ECG signal classification:a\n  noise-to-signal ratio perspective", "comments": "This paper is accepted at ICLR 2020 workshop on Artificial\n  Intelligence for Affordable Healthcare. 14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrocardiogram (ECG) is the most widely used diagnostic tool to monitor\nthe condition of the cardiovascular system. Deep neural networks (DNNs), have\nbeen developed in many research labs for automatic interpretation of ECG\nsignals to identify potential abnormalities in patient hearts. Studies have\nshown that given a sufficiently large amount of data, the classification\naccuracy of DNNs could reach human-expert cardiologist level. A DNN-based\nautomated ECG diagnostic system would be an affordable solution for patients in\ndeveloping countries where human-expert cardiologist are lacking. However,\ndespite of the excellent performance in classification accuracy, it has been\nshown that DNNs are highly vulnerable to adversarial attacks: subtle changes in\ninput of a DNN can lead to a wrong classification output with high confidence.\nThus, it is challenging and essential to improve adversarial robustness of DNNs\nfor ECG signal classification, a life-critical application. In this work, we\nproposed to improve DNN robustness from the perspective of noise-to-signal\nratio (NSR) and developed two methods to minimize NSR during training process.\nWe evaluated the proposed methods on PhysionNets MIT-BIH dataset, and the\nresults show that our proposed methods lead to an enhancement in robustness\nagainst PGD adversarial attack and SPSA attack, with a minimal change in\naccuracy on clean data.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 23:37:33 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 00:12:47 GMT"}, {"version": "v3", "created": "Thu, 15 Apr 2021 23:10:37 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Ma", "Linhai", ""], ["Liang", "Liang", ""]]}, {"id": "2005.09136", "submitter": "R\\'emi Le Priol", "authors": "R\\'emi Le Priol, Reza Babanezhad Harikandeh, Yoshua Bengio and Simon\n  Lacoste-Julien", "title": "An Analysis of the Adaptation Speed of Causal Models", "comments": "Published at AISTATS 2021. 10 pages main articles, 19 pages\n  supplement, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a collection of datasets generated by unknown interventions on an\nunknown structural causal model $G$. Recently, Bengio et al. (2020) conjectured\nthat among all candidate models, $G$ is the fastest to adapt from one dataset\nto another, along with promising experiments. Indeed, intuitively $G$ has less\nmechanisms to adapt, but this justification is incomplete. Our contribution is\na more thorough analysis of this hypothesis. We investigate the adaptation\nspeed of cause-effect SCMs. Using convergence rates from stochastic\noptimization, we justify that a relevant proxy for adaptation speed is distance\nin parameter space after intervention. Applying this proxy to categorical and\nnormal cause-effect models, we show two results. When the intervention is on\nthe cause variable, the SCM with the correct causal direction is advantaged by\na large factor. When the intervention is on the effect variable, we\ncharacterize the relative adaptation speed. Surprisingly, we find situations\nwhere the anticausal model is advantaged, falsifying the initial hypothesis.\nCode to reproduce experiments is available at\nhttps://github.com/remilepriol/causal-adaptation-speed\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 23:48:56 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 11:48:05 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Priol", "R\u00e9mi Le", ""], ["Harikandeh", "Reza Babanezhad", ""], ["Bengio", "Yoshua", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "2005.09147", "submitter": "Linhai Ma", "authors": "Linhai Ma, Liang Liang", "title": "Increasing-Margin Adversarial (IMA) Training to Improve Adversarial\n  Robustness of Neural Networks", "comments": "23 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network (CNN) has surpassed traditional methods for\nmed-ical image classification. However, CNN is vulnerable to adversarial\nattacks which may lead to disastrous consequences in medical applications.\nAlthough adversarial noises are usually generated by attack algorithms,\nwhite-noise-induced adversarial samples can exist, and therefore the threats\nare real. In this study, we propose a novel training method, named IMA, to\nimprove the robust-ness of CNN against adversarial noises. During training, the\nIMA method in-creases the margins of training samples in the input space, i.e.,\nmoving CNN de-cision boundaries far away from the training samples to improve\nrobustness. The IMA method is evaluated on four publicly available datasets\nunder strong 100-PGD white-box adversarial attacks, and the results show that\nthe proposed meth-od significantly improved CNN classification accuracy on\nnoisy data while keep-ing a relatively high accuracy on clean data. We hope our\napproach may facilitate the development of robust applications in medical\nfield.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 00:26:52 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 20:31:20 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 20:58:21 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Ma", "Linhai", ""], ["Liang", "Liang", ""]]}, {"id": "2005.09148", "submitter": "Rong Ou", "authors": "Rong Ou", "title": "Out-of-Core GPU Gradient Boosting", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPU-based algorithms have greatly accelerated many machine learning methods;\nhowever, GPU memory is typically smaller than main memory, limiting the size of\ntraining data. In this paper, we describe an out-of-core GPU gradient boosting\nalgorithm implemented in the XGBoost library. We show that much larger datasets\ncan fit on a given GPU, without degrading model accuracy or training time. To\nthe best of our knowledge, this is the first out-of-core GPU implementation of\ngradient boosting. Similar approaches can be applied to other machine learning\nalgorithms\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 00:41:00 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Ou", "Rong", ""]]}, {"id": "2005.09155", "submitter": "Gang Wang", "authors": "Alireza Sadeghi and Georgios B. Giannakis and Gang Wang and Fatemeh\n  Sheikholeslami", "title": "Reinforcement Learning for Caching with Space-Time Popularity Dynamics", "comments": "30 pages; 12 figs. arXiv admin note: text overlap with\n  arXiv:1708.06698, arXiv:1902.10301", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the tremendous growth of data traffic over wired and wireless networks\nalong with the increasing number of rich-media applications, caching is\nenvisioned to play a critical role in next-generation networks. To\nintelligently prefetch and store contents, a cache node should be able to learn\nwhat and when to cache. Considering the geographical and temporal content\npopularity dynamics, the limited available storage at cache nodes, as well as\nthe interactive in uence of caching decisions in networked caching settings,\ndeveloping effective caching policies is practically challenging. In response\nto these challenges, this chapter presents a versatile reinforcement learning\nbased approach for near-optimal caching policy design, in both single-node and\nnetwork caching settings under dynamic space-time popularities. The herein\npresented policies are complemented using a set of numerical tests, which\nshowcase the merits of the presented approach relative to several standard\ncaching policies.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 01:23:51 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Sadeghi", "Alireza", ""], ["Giannakis", "Georgios B.", ""], ["Wang", "Gang", ""], ["Sheikholeslami", "Fatemeh", ""]]}, {"id": "2005.09162", "submitter": "Shahabeddin Sotudian", "authors": "Mohammad Hossein Fazel Zarandi, Shahabeddin Sotudian, Oscar Castillo", "title": "A New Validity Index for Fuzzy-Possibilistic C-Means Clustering", "comments": "The following article has been accepted by Scientia Iranica", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In some complicated datasets, due to the presence of noisy data points and\noutliers, cluster validity indices can give conflicting results in determining\nthe optimal number of clusters. This paper presents a new validity index for\nfuzzy-possibilistic c-means clustering called Fuzzy-Possibilistic (FP) index,\nwhich works well in the presence of clusters that vary in shape and density.\nMoreover, FPCM like most of the clustering algorithms is susceptible to some\ninitial parameters. In this regard, in addition to the number of clusters, FPCM\nrequires a priori selection of the degree of fuzziness and the degree of\ntypicality. Therefore, we presented an efficient procedure for determining\ntheir optimal values. The proposed approach has been evaluated using several\nsynthetic and real-world datasets. Final computational results demonstrate the\ncapabilities and reliability of the proposed approach compared with several\nwell-known fuzzy validity indices in the literature. Furthermore, to clarify\nthe ability of the proposed method in real applications, the proposed method is\nimplemented in microarray gene expression data clustering and medical image\nsegmentation.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 01:48:13 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Zarandi", "Mohammad Hossein Fazel", ""], ["Sotudian", "Shahabeddin", ""], ["Castillo", "Oscar", ""]]}, {"id": "2005.09163", "submitter": "Yuang Liu", "authors": "Yuang Liu, Wei Zhang, Jun Wang", "title": "Learning from a Lightweight Teacher for Efficient Knowledge Distillation", "comments": "11 pages, 3 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Distillation (KD) is an effective framework for compressing deep\nlearning models, realized by a student-teacher paradigm requiring small student\nnetworks to mimic the soft target generated by well-trained teachers. However,\nthe teachers are commonly assumed to be complex and need to be trained on the\nsame datasets as students. This leads to a time-consuming training process. The\nrecent study shows vanilla KD plays a similar role as label smoothing and\ndevelops teacher-free KD, being efficient and mitigating the issue of learning\nfrom heavy teachers. But because teacher-free KD relies on manually-crafted\noutput distributions kept the same for all data instances belonging to the same\nclass, its flexibility and performance are relatively limited. To address the\nabove issues, this paper proposes en efficient knowledge distillation learning\nframework LW-KD, short for lightweight knowledge distillation. It firstly\ntrains a lightweight teacher network on a synthesized simple dataset, with an\nadjustable class number equal to that of a target dataset. The teacher then\ngenerates soft target whereby an enhanced KD loss could guide student learning,\nwhich is a combination of KD loss and adversarial loss for making student\noutput indistinguishable from the output of the teacher. Experiments on several\npublic datasets with different modalities demonstrate LWKD is effective and\nefficient, showing the rationality of its main design principles.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 01:54:15 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Liu", "Yuang", ""], ["Zhang", "Wei", ""], ["Wang", "Jun", ""]]}, {"id": "2005.09165", "submitter": "Minhyeok Lee", "authors": "Minhyeok Lee, Junhee Seok", "title": "Regularization Methods for Generative Adversarial Networks: An Overview\n  of Recent Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its short history, Generative Adversarial Network (GAN) has been\nextensively studied and used for various tasks, including its original purpose,\ni.e., synthetic sample generation. However, applying GAN to different data\ntypes with diverse neural network architectures has been hindered by its\nlimitation in training, where the model easily diverges. Such a notorious\ntraining of GANs is well known and has been addressed in numerous studies.\nConsequently, in order to make the training of GAN stable, numerous\nregularization methods have been proposed in recent years. This paper reviews\nthe regularization methods that have been recently introduced, most of which\nhave been published in the last three years. Specifically, we focus on general\nmethods that can be commonly used regardless of neural network architectures.\nTo explore the latest research trends in the regularization for GANs, the\nmethods are classified into several groups by their operation principles, and\nthe differences between the methods are analyzed. Furthermore, to provide\npractical knowledge of using these methods, we investigate popular methods that\nhave been frequently employed in state-of-the-art GANs. In addition, we discuss\nthe limitations in existing methods and propose future research directions.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 01:59:24 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Lee", "Minhyeok", ""], ["Seok", "Junhee", ""]]}, {"id": "2005.09170", "submitter": "Jeffrey Z. Pan", "authors": "Jeffrey Z. Pan, Nicholas Zufelt", "title": "On Intrinsic Dataset Properties for Adversarial Machine Learning", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have played a key role in a wide range of machine\nlearning applications. However, DNN classifiers are vulnerable to\nhuman-imperceptible adversarial perturbations, which can cause them to\nmisclassify inputs with high confidence. Thus, creating robust DNNs which can\ndefend against malicious examples is critical in applications where security\nplays a major role. In this paper, we study the effect of intrinsic dataset\nproperties on the performance of adversarial attack and defense methods,\ntesting on five popular image classification datasets - MNIST, Fashion-MNIST,\nCIFAR10/CIFAR100, and ImageNet. We find that input size and image contrast play\nkey roles in attack and defense success. Our discoveries highlight that dataset\ndesign and data preprocessing steps are important to boost the adversarial\nrobustness of DNNs. To our best knowledge, this is the first comprehensive work\nthat studies the effect of intrinsic dataset properties on adversarial machine\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 02:24:14 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Pan", "Jeffrey Z.", ""], ["Zufelt", "Nicholas", ""]]}, {"id": "2005.09175", "submitter": "Feng Qi", "authors": "Feng Qi, Guanjun Jiang", "title": "Human-like general language processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using language makes human beings surpass animals in wisdom. To let machines\nunderstand, learn, and use language flexibly, we propose a human-like general\nlanguage processing (HGLP) architecture, which contains sensorimotor,\nassociation, and cognitive systems. The HGLP network learns from easy to hard\nlike a child, understands word meaning by coactivating multimodal neurons,\ncomprehends and generates sentences by real-time constructing a virtual world\nmodel, and can express the whole thinking process verbally. HGLP rapidly\nlearned 10+ different tasks including object recognition, sentence\ncomprehension, imagination, attention control, query, inference, motion\njudgement, mixed arithmetic operation, digit tracing and writing, and\nhuman-like iterative thinking process guided by language. Language in the HGLP\nframework is not matching nor correlation statistics, but a script that can\ndescribe and control the imagination.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 02:44:55 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 08:08:02 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Qi", "Feng", ""], ["Jiang", "Guanjun", ""]]}, {"id": "2005.09194", "submitter": "Baocheng Zhu", "authors": "Shijun Wang, Baocheng Zhu, Lintao Ma, Yuan Qi", "title": "A Riemannian Primal-dual Algorithm Based on Proximal Operator and its\n  Application in Metric Learning", "comments": "8 pages, 2 figures, published as a conference paper in 2019\n  International Joint Conference on Neural Networks (IJCNN)", "journal-ref": null, "doi": "10.1109/IJCNN.2019.8852367", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we consider optimizing a smooth, convex, lower semicontinuous\nfunction in Riemannian space with constraints. To solve the problem, we first\nconvert it to a dual problem and then propose a general primal-dual algorithm\nto optimize the primal and dual variables iteratively. In each optimization\niteration, we employ a proximal operator to search optimal solution in the\nprimal space. We prove convergence of the proposed algorithm and show its\nnon-asymptotic convergence rate. By utilizing the proposed primal-dual\noptimization technique, we propose a novel metric learning algorithm which\nlearns an optimal feature transformation matrix in the Riemannian space of\npositive definite matrices. Preliminary experimental results on an optimal fund\nselection problem in fund of funds (FOF) management for quantitative investment\nshowed its efficacy.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 03:31:01 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Wang", "Shijun", ""], ["Zhu", "Baocheng", ""], ["Ma", "Lintao", ""], ["Qi", "Yuan", ""]]}, {"id": "2005.09195", "submitter": "Baocheng Zhu", "authors": "Shijun Wang, Baocheng Zhu, Chen Li, Mingzhe Wu, James Zhang, Wei Chu,\n  Yuan Qi", "title": "Riemannian Proximal Policy Optimization", "comments": "12 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, We propose a general Riemannian proximal optimization\nalgorithm with guaranteed convergence to solve Markov decision process (MDP)\nproblems. To model policy functions in MDP, we employ Gaussian mixture model\n(GMM) and formulate it as a nonconvex optimization problem in the Riemannian\nspace of positive semidefinite matrices. For two given policy functions, we\nalso provide its lower bound on policy improvement by using bounds derived from\nthe Wasserstein distance of GMMs. Preliminary experiments show the efficacy of\nour proposed Riemannian proximal policy optimization algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 03:37:59 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Wang", "Shijun", ""], ["Zhu", "Baocheng", ""], ["Li", "Chen", ""], ["Wu", "Mingzhe", ""], ["Zhang", "James", ""], ["Chu", "Wei", ""], ["Qi", "Yuan", ""]]}, {"id": "2005.09198", "submitter": "Ozgur Ozmen", "authors": "James Nutaro and Ozgur Ozmen", "title": "Quantifying the Uncertainty of Precision Estimates for Rule based Text\n  Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rule based classifiers that use the presence and absence of key sub-strings\nto make classification decisions have a natural mechanism for quantifying the\nuncertainty of their precision. For a binary classifier, the key insight is to\ntreat partitions of the sub-string set induced by the documents as Bernoulli\nrandom variables. The mean value of each random variable is an estimate of the\nclassifier's precision when presented with a document inducing that partition.\nThese means can be compared, using standard statistical tests, to a desired or\nexpected classifier precision. A set of binary classifiers can be combined into\na single, multi-label classifier by an application of the Dempster-Shafer\ntheory of evidence. The utility of this approach is demonstrated with a\nbenchmark problem.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 03:51:47 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Nutaro", "James", ""], ["Ozmen", "Ozgur", ""]]}, {"id": "2005.09207", "submitter": "Zhiyu Chen", "authors": "Zhiyu Chen, Mohamed Trabelsi, Jeff Heflin, Yinan Xu, Brian D. Davison", "title": "Table Search Using a Deep Contextualized Language Model", "comments": "Accepted at SIGIR 2020 (Long)", "journal-ref": null, "doi": "10.1145/3397271.3401044", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained contextualized language models such as BERT have achieved\nimpressive results on various natural language processing benchmarks.\nBenefiting from multiple pretraining tasks and large scale training corpora,\npretrained models can capture complex syntactic word relations. In this paper,\nwe use the deep contextualized language model BERT for the task of ad hoc table\nretrieval. We investigate how to encode table content considering the table\nstructure and input length limit of BERT. We also propose an approach that\nincorporates features from prior literature on table retrieval and jointly\ntrains them with BERT. In experiments on public datasets, we show that our best\napproach can outperform the previous state-of-the-art method and BERT baselines\nwith a large margin under different evaluation metrics.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 04:18:04 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 23:07:15 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Chen", "Zhiyu", ""], ["Trabelsi", "Mohamed", ""], ["Heflin", "Jeff", ""], ["Xu", "Yinan", ""], ["Davison", "Brian D.", ""]]}, {"id": "2005.09209", "submitter": "Bashir Rastegarpanah", "authors": "Bashir Rastegarpanah (1), Mark Crovella (1), Krishna P. Gummadi (2)\n  ((1) Boston University, (2) MPI-SWS)", "title": "Fair Inputs and Fair Outputs: The Incompatibility of Fairness in Privacy\n  and Accuracy", "comments": null, "journal-ref": null, "doi": "10.1145/3386392.3399568", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness concerns about algorithmic decision-making systems have been mainly\nfocused on the outputs (e.g., the accuracy of a classifier across individuals\nor groups). However, one may additionally be concerned with fairness in the\ninputs. In this paper, we propose and formulate two properties regarding the\ninputs of (features used by) a classifier. In particular, we claim that fair\nprivacy (whether individuals are all asked to reveal the same information) and\nneed-to-know (whether users are only asked for the minimal information required\nfor the task at hand) are desirable properties of a decision system. We explore\nthe interaction between these properties and fairness in the outputs (fair\nprediction accuracy). We show that for an optimal classifier these three\nproperties are in general incompatible, and we explain what common properties\nof data make them incompatible. Finally we provide an algorithm to verify if\nthe trade-off between the three properties exists in a given dataset, and use\nthe algorithm to show that this trade-off is common in real data.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 04:32:16 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 23:48:21 GMT"}, {"version": "v3", "created": "Sun, 24 May 2020 22:08:23 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Rastegarpanah", "Bashir", "", "Boston University"], ["Crovella", "Mark", "", "Boston University"], ["Gummadi", "Krishna P.", "", "MPI-SWS"]]}, {"id": "2005.09218", "submitter": "Jia-Fong Yeh", "authors": "Jia-Fong Yeh and Hsin-Ying Lee and Bing-Chen Tsai and Yi-Rong Chen and\n  Ping-Chia Huang and Winston H. Hsu", "title": "Large Margin Mechanism and Pseudo Query Set on Cross-Domain Few-Shot\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, few-shot learning problems have received a lot of attention.\nWhile methods in most previous works were trained and tested on datasets in one\nsingle domain, cross-domain few-shot learning is a brand-new branch of few-shot\nlearning problems, where models handle datasets in different domains between\ntraining and testing phases. In this paper, to solve the problem that the model\nis pre-trained (meta-trained) on a single dataset while fine-tuned on datasets\nin four different domains, including common objects, satellite images, and\nmedical images, we propose a novel large margin fine-tuning method (LMM-PQS),\nwhich generates pseudo query images from support images and fine-tunes the\nfeature extraction modules with a large margin mechanism inspired by methods in\nface recognition. According to the experiment results, LMM-PQS surpasses the\nbaseline models by a significant margin and demonstrates that our approach is\nrobust and can easily adapt pre-trained models to new domains with few data.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 05:28:35 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Yeh", "Jia-Fong", ""], ["Lee", "Hsin-Ying", ""], ["Tsai", "Bing-Chen", ""], ["Chen", "Yi-Rong", ""], ["Huang", "Ping-Chia", ""], ["Hsu", "Winston H.", ""]]}, {"id": "2005.09220", "submitter": "Pierre-Alexandre Kamienny Mr", "authors": "Pierre-Alexandre Kamienny, Kai Arulkumaran, Feryal Behbahani, Wendelin\n  Boehmer, Shimon Whiteson", "title": "Privileged Information Dropout in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using privileged information during training can improve the sample\nefficiency and performance of machine learning systems. This paradigm has been\napplied to reinforcement learning (RL), primarily in the form of distillation\nor auxiliary tasks, and less commonly in the form of augmenting the inputs of\nagents. In this work, we investigate Privileged Information Dropout (\\pid) for\nachieving the latter which can be applied equally to value-based and\npolicy-based RL algorithms. Within a simple partially-observed environment, we\ndemonstrate that \\pid outperforms alternatives for leveraging privileged\ninformation, including distillation and auxiliary tasks, and can successfully\nutilise different types of privileged information. Finally, we analyse its\neffect on the learned representations.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 05:32:33 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Kamienny", "Pierre-Alexandre", ""], ["Arulkumaran", "Kai", ""], ["Behbahani", "Feryal", ""], ["Boehmer", "Wendelin", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2005.09223", "submitter": "Zhixin Li", "authors": "Bo Xu, Xu Zhang, Zhixin Li, Matt Leotta, Shih-Fu Chang, Jie Shan", "title": "Deep Learning Guided Building Reconstruction from Satellite\n  Imagery-derived Point Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D urban reconstruction of buildings from remotely sensed imagery has drawn\nsignificant attention during the past two decades. While aerial imagery and\nLiDAR provide higher resolution, satellite imagery is cheaper and more\nefficient to acquire for large scale need. However, the high, orbital altitude\nof satellite observation brings intrinsic challenges, like unpredictable\natmospheric effect, multi view angles, significant radiometric differences due\nto the necessary multiple views, diverse land covers and urban structures in a\nscene, small base-height ratio or narrow field of view, all of which may\ndegrade 3D reconstruction quality. To address these major challenges, we\npresent a reliable and effective approach for building model reconstruction\nfrom the point clouds generated from multi-view satellite images. We utilize\nmultiple types of primitive shapes to fit the input point cloud. Specifically,\na deep-learning approach is adopted to distinguish the shape of building roofs\nin complex and yet noisy scenes. For points that belong to the same roof shape,\na multi-cue, hierarchical RANSAC approach is proposed for efficient and\nreliable segmenting and reconstructing the building point cloud. Experimental\nresults over four selected urban areas (0.34 to 2.04 sq km in size) demonstrate\nthe proposed method can generate detailed roof structures under noisy data\nenvironments. The average successful rate for building shape recognition is\n83.0%, while the overall completeness and correctness are over 70% with\nreference to ground truth created from airborne lidar. As the first effort to\naddress the public need of large scale city model generation, the development\nis deployed as open source software.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 05:38:06 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Xu", "Bo", ""], ["Zhang", "Xu", ""], ["Li", "Zhixin", ""], ["Leotta", "Matt", ""], ["Chang", "Shih-Fu", ""], ["Shan", "Jie", ""]]}, {"id": "2005.09226", "submitter": "Zhixin Li", "authors": "Zhixin Li, Wenyuan Zhang, Jie Shan", "title": "Holistic Parameteric Reconstruction of Building Models from Point Clouds", "comments": "Remote Sens. Spatial Inf. Sci., 2020", "journal-ref": null, "doi": "10.5194/isprs-archives-XLIII-B2-2020-689-2020", "report-no": null, "categories": "cs.CV cs.GR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building models are conventionally reconstructed by building roof points\nplanar segmentation and then using a topology graph to group the planes\ntogether. Roof edges and vertices are then mathematically represented by\nintersecting segmented planes. Technically, such solution is based on\nsequential local fitting, i.e., the entire data of one building are not\nsimultaneously participating in determining the building model. As a\nconsequence, the solution is lack of topological integrity and geometric rigor.\nFundamentally different from this traditional approach, we propose a holistic\nparametric reconstruction method which means taking into consideration the\nentire point clouds of one building simultaneously. In our work, building\nmodels are reconstructed from predefined parametric (roof) primitives. We first\nuse a well-designed deep neural network to segment and identify primitives in\nthe given building point clouds. A holistic optimization strategy is then\nintroduced to simultaneously determine the parameters of a segmented primitive.\nIn the last step, the optimal parameters are used to generate a watertight\nbuilding model in CityGML format. The airborne LiDAR dataset RoofN3D with\npredefined roof types is used for our test. It is shown that PointNet++ applied\nto the entire dataset can achieve an accuracy of 83% for primitive\nclassification. For a subset of 910 buildings in RoofN3D, the holistic approach\nis then used to determine the parameters of primitives and reconstruct the\nbuildings. The achieved overall quality of reconstruction is 0.08 meters for\npoint-surface-distance or 0.7 times RMSE of the input LiDAR points. The study\ndemonstrates the efficiency and capability of the proposed approach and its\npotential to handle large scale urban point clouds.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 05:42:23 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Li", "Zhixin", ""], ["Zhang", "Wenyuan", ""], ["Shan", "Jie", ""]]}, {"id": "2005.09229", "submitter": "Chong Peng", "authors": "Chong Peng, Zhilu Zhang, Zhao Kang, Chenglizhao Chen, Qiang Cheng", "title": "Two-Dimensional Semi-Nonnegative Matrix Factorization for Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new Semi-Nonnegative Matrix Factorization method\nfor 2-dimensional (2D) data, named TS-NMF. It overcomes the drawback of\nexisting methods that seriously damage the spatial information of the data by\nconverting 2D data to vectors in a preprocessing step. In particular,\nprojection matrices are sought under the guidance of building new data\nrepresentations, such that the spatial information is retained and projections\nare enhanced by the goal of clustering, which helps construct optimal\nprojection directions. Moreover, to exploit nonlinear structures of the data,\nmanifold is constructed in the projected subspace, which is adaptively updated\naccording to the projections and less afflicted with noise and outliers of the\ndata and thus more representative in the projected space. Hence, seeking\nprojections, building new data representations, and learning manifold are\nseamlessly integrated in a single model, which mutually enhance other and lead\nto a powerful data representation. Comprehensive experimental results verify\nthe effectiveness of TS-NMF in comparison with several state-of-the-art\nalgorithms, which suggests high potential of the proposed method for real world\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 05:54:14 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Peng", "Chong", ""], ["Zhang", "Zhilu", ""], ["Kang", "Zhao", ""], ["Chen", "Chenglizhao", ""], ["Cheng", "Qiang", ""]]}, {"id": "2005.09234", "submitter": "Kaori Suefusa", "authors": "Kaori Suefusa, Tomoya Nishida, Harsh Purohit, Ryo Tanabe, Takashi\n  Endo, and Yohei Kawaguchi", "title": "Anomalous sound detection based on interpolation deep neural network", "comments": "5 pages, 8 figures, published in ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the labor force decreases, the demand for labor-saving automatic anomalous\nsound detection technology that conducts maintenance of industrial equipment\nhas grown. Conventional approaches detect anomalies based on the reconstruction\nerrors of an autoencoder. However, when the target machine sound is\nnon-stationary, a reconstruction error tends to be large independent of an\nanomaly, and its variations increased because of the difficulty of predicting\nthe edge frames. To solve the issue, we propose an approach to anomalous\ndetection in which the model utilizes multiple frames of a spectrogram whose\ncenter frame is removed as an input, and it predicts an interpolation of the\nremoved frame as an output. Rather than predicting the edge frames, the\nproposed approach makes the reconstruction error consistent with the anomaly.\nExperimental results showed that the proposed approach achieved 27% improvement\nbased on the standard AUC score, especially against non-stationary machinery\nsounds.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 06:12:41 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Suefusa", "Kaori", ""], ["Nishida", "Tomoya", ""], ["Purohit", "Harsh", ""], ["Tanabe", "Ryo", ""], ["Endo", "Takashi", ""], ["Kawaguchi", "Yohei", ""]]}, {"id": "2005.09235", "submitter": "Guanyang Wang", "authors": "Guanyang Wang", "title": "On the Theoretical Properties of the Exchange Algorithm", "comments": "33 pages, 2 figures, typos fixed, include more examples, add\n  literature review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exchange algorithm is one of the most popular extensions of\nMetropolis-Hastings algorithm to sample from doubly-intractable distributions.\nHowever, theoretical exploration of exchange algorithm is very limited. For\nexample, natural questions like `Does exchange algorithm converge at a\ngeometric rate?' or `Does the exchange algorithm admit a Central Limit\nTheorem?' have not been answered. In this paper, we study the theoretical\nproperties of exchange algorithm, in terms of asymptotic variance and\nconvergence speed. We compare the exchange algorithm with the original\nMetropolis-Hastings algorithm and provide both necessary and sufficient\nconditions for geometric ergodicity of the exchange algorithm, which can be\napplied to various practical applications such as exponential random graph\nmodels and Ising models. A central limit theorem for the exchange algorithm is\nalso established. Meanwhile, a concrete example, involving the Binomial model\nwith conjugate and non-conjugate priors, is treated in detail with sharp\nconvergence rates. Our results justify the theoretical usefulness of the\nexchange algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 06:16:43 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 22:15:34 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 02:39:41 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Wang", "Guanyang", ""]]}, {"id": "2005.09237", "submitter": "Xm Zhang", "authors": "Lu Ma, Hua Huang, Pei Zhao, Tengrong Su", "title": "Acoustic Echo Cancellation by Combining Adaptive Digital Filter and\n  Recurrent Neural Network", "comments": "submitted to INTERSPEECH2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic Echo Cancellation (AEC) plays a key role in voice interaction. Due\nto the explicit mathematical principle and intelligent nature to accommodate\nconditions, adaptive filters with different types of implementations are always\nused for AEC, giving considerable performance. However, there would be some\nkinds of residual echo in the results, including linear residue introduced by\nmismatching between estimation and the reality and non-linear residue mostly\ncaused by non-linear components on the audio devices. The linear residue can be\nreduced with elaborate structure and methods, leaving the non-linear residue\nintractable for suppression. Though, some non-linear processing methods have\nalready be raised, they are complicated and inefficient for suppression, and\nwould bring damage to the speech audio. In this paper, a fusion scheme by\ncombining adaptive filter and neural network is proposed for AEC. The echo\ncould be reduced in a large scale by adaptive filtering, resulting in little\nresidual echo. Though it is much smaller than speech audio, it could also be\nperceived by human ear and would make communication annoy. The neural network\nis elaborately designed and trained for suppressing such residual echo.\nExperiments compared with prevailing methods are conducted, validating the\neffectiveness and superiority of the proposed combination scheme.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 06:25:52 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Ma", "Lu", ""], ["Huang", "Hua", ""], ["Zhao", "Pei", ""], ["Su", "Tengrong", ""]]}, {"id": "2005.09238", "submitter": "Lu Ma", "authors": "Lu Ma, Xin Zhao, Pei Zhao, Tengrong Su", "title": "A Lite Microphone Array Beamforming Scheme with Maximum Signal-to-Noise\n  Ratio Filter", "comments": "submitted to INTERSPEECH2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since space-domain information can be utilized, microphone array beamforming\nis often used to enhance the quality of the speech by suppressing directional\ndisturbance. However, with the increasing number of microphone, the complexity\nwould be increased. In this paper, a concise beamforming scheme using Maximum\nSignal-to-Noise Ratio (SNR) filter is proposed to reduce the beamforming\ncomplexity. The maximum SNR filter is implemented by using the estimated\ndirection-of-arrival (DOA) of the speech source localization (SSL) and the\nsolving method of independent vector analysis (IVA). Our experiments show that\nwhen compared with other widely-used algorithms, the proposed algorithm obtain\nhigher gain of signal-to-interference and noise ratio (SINR).\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 06:35:41 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Ma", "Lu", ""], ["Zhao", "Xin", ""], ["Zhao", "Pei", ""], ["Su", "Tengrong", ""]]}, {"id": "2005.09241", "submitter": "Damien Teney", "authors": "Damien Teney, Kushal Kafle, Robik Shrestha, Ehsan Abbasnejad,\n  Christopher Kanan, Anton van den Hengel", "title": "On the Value of Out-of-Distribution Testing: An Example of Goodhart's\n  Law", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Out-of-distribution (OOD) testing is increasingly popular for evaluating a\nmachine learning system's ability to generalize beyond the biases of a training\nset. OOD benchmarks are designed to present a different joint distribution of\ndata and labels between training and test time. VQA-CP has become the standard\nOOD benchmark for visual question answering, but we discovered three troubling\npractices in its current use. First, most published methods rely on explicit\nknowledge of the construction of the OOD splits. They often rely on\n``inverting'' the distribution of labels, e.g. answering mostly 'yes' when the\ncommon training answer is 'no'. Second, the OOD test set is used for model\nselection. Third, a model's in-domain performance is assessed after retraining\nit on in-domain splits (VQA v2) that exhibit a more balanced distribution of\nlabels. These three practices defeat the objective of evaluating\ngeneralization, and put into question the value of methods specifically\ndesigned for this dataset. We show that embarrassingly-simple methods,\nincluding one that generates answers at random, surpass the state of the art on\nsome question types. We provide short- and long-term solutions to avoid these\npitfalls and realize the benefits of OOD evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 06:45:50 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Teney", "Damien", ""], ["Kafle", "Kushal", ""], ["Shrestha", "Robik", ""], ["Abbasnejad", "Ehsan", ""], ["Kanan", "Christopher", ""], ["Hengel", "Anton van den", ""]]}, {"id": "2005.09242", "submitter": "Lu Ma", "authors": "Lu Ma, Haiping Zhang, Pei Zhao, Tengrong Su", "title": "Competitive Wakeup Scheme for Distributed Devices", "comments": "sumbitted to INTERSPEECH2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wakeup is the primary function in voice interaction which is the mainstream\nscheme in man-machine interaction (HMI) applications for smart home. All\ndevices will response if the same wake-up word is used for all devices. This\nwill bring chaos and reduce user quality of experience (QoE). The only way to\nsolve this problem is to make all the devices in the same wireless local area\nnetwork (WLAN) competing to wake-up based on the same scoring rule. The one\nclosest to the user would be selected for response. To this end, a competitive\nwakeup scheme is proposed in this paper with elaborately designed calibration\nmethod for receiving energy of microphones. Moreover, the user orientation is\nassisted to determine the optimal device. Experiments reveal the feasibility\nand validity of this scheme.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 06:46:02 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Ma", "Lu", ""], ["Zhang", "Haiping", ""], ["Zhao", "Pei", ""], ["Su", "Tengrong", ""]]}, {"id": "2005.09246", "submitter": "Rajeev Bhatt Ambati", "authors": "Rajeev Bhatt Ambati, Ahmed Ada Hanifi, Ramya Vunikili, Puneet Sharma,\n  and Oladimeji Farri", "title": "Assertion Detection in Multi-Label Clinical Text using Scope\n  Localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label sentences (text) in the clinical domain result from the rich\ndescription of scenarios during patient care. The state-of-theart methods for\nassertion detection mostly address this task in the setting of a single\nassertion label per sentence (text). In addition, few rules based and deep\nlearning methods perform negation/assertion scope detection on single-label\ntext. It is a significant challenge extending these methods to address\nmulti-label sentences without diminishing performance. Therefore, we developed\na convolutional neural network (CNN) architecture to localize multiple labels\nand their scopes in a single stage end-to-end fashion, and demonstrate that our\nmodel performs atleast 12% better than the state-of-the-art on multi-label\nclinical text.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 06:56:02 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Ambati", "Rajeev Bhatt", ""], ["Hanifi", "Ahmed Ada", ""], ["Vunikili", "Ramya", ""], ["Sharma", "Puneet", ""], ["Farri", "Oladimeji", ""]]}, {"id": "2005.09257", "submitter": "Jaikai Wang", "authors": "Aishan Liu, Jiakai Wang, Xianglong Liu, Bowen Cao, Chongzhi Zhang,\n  Hang Yu", "title": "Bias-based Universal Adversarial Patch Attack for Automatic Check-out", "comments": "This paper has been accepted on ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are inputs with imperceptible perturbations that easily\nmisleading deep neural networks(DNNs). Recently, adversarial patch, with noise\nconfined to a small and localized patch, has emerged for its easy feasibility\nin real-world scenarios. However, existing strategies failed to generate\nadversarial patches with strong generalization ability. In other words, the\nadversarial patches were input-specific and failed to attack images from all\nclasses, especially unseen ones during training. To address the problem, this\npaper proposes a bias-based framework to generate class-agnostic universal\nadversarial patches with strong generalization ability, which exploits both the\nperceptual and semantic bias of models. Regarding the perceptual bias, since\nDNNs are strongly biased towards textures, we exploit the hard examples which\nconvey strong model uncertainties and extract a textural patch prior from them\nby adopting the style similarities. The patch prior is more close to decision\nboundaries and would promote attacks. To further alleviate the heavy dependency\non large amounts of data in training universal attacks, we further exploit the\nsemantic bias. As the class-wise preference, prototypes are introduced and\npursued by maximizing the multi-class margin to help universal training. Taking\nAutomaticCheck-out (ACO) as the typical scenario, extensive experiments\nincluding white-box and black-box settings in both digital-world(RPC, the\nlargest ACO related dataset) and physical-world scenario(Taobao and JD, the\nworld' s largest online shopping platforms) are conducted. Experimental results\ndemonstrate that our proposed framework outperforms state-of-the-art\nadversarial patch attack methods.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 07:38:54 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 14:07:54 GMT"}, {"version": "v3", "created": "Mon, 3 Aug 2020 13:06:03 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Liu", "Aishan", ""], ["Wang", "Jiakai", ""], ["Liu", "Xianglong", ""], ["Cao", "Bowen", ""], ["Zhang", "Chongzhi", ""], ["Yu", "Hang", ""]]}, {"id": "2005.09260", "submitter": "Pavel Kral", "authors": "Ji\\v{r}\\'i Mart\\'inek, Christophe Cerisara, Pavel Kr\\'al and Ladislav\n  Lenc", "title": "Cross-lingual Approaches for Task-specific Dialogue Act Recognition", "comments": "Accepted for 17th International Conference on Artificial Intelligence\n  Applications and Innovations (AIAI 2021), 25-27 June", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper we exploit cross-lingual models to enable dialogue act\nrecognition for specific tasks with a small number of annotations. We design a\ntransfer learning approach for dialogue act recognition and validate it on two\ndifferent target languages and domains. We compute dialogue turn embeddings\nwith both a CNN and multi-head self-attention model and show that the best\nresults are obtained by combining all sources of transferred information. We\nfurther demonstrate that the proposed methods significantly outperform related\ncross-lingual DA recognition approaches.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 07:44:48 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 06:27:08 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Mart\u00ednek", "Ji\u0159\u00ed", ""], ["Cerisara", "Christophe", ""], ["Kr\u00e1l", "Pavel", ""], ["Lenc", "Ladislav", ""]]}, {"id": "2005.09261", "submitter": "Davoud Ataee Tarzanagh", "authors": "Parvin Nazari, Davoud Ataee Tarzanagh, George Michailidis", "title": "Adaptive First-and Zeroth-order Methods for Weakly Convex Stochastic\n  Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we design and analyze a new family of adaptive subgradient\nmethods for solving an important class of weakly convex (possibly nonsmooth)\nstochastic optimization problems. Adaptive methods that use exponential moving\naverages of past gradients to update search directions and learning rates have\nrecently attracted a lot of attention for solving optimization problems that\narise in machine learning. Nevertheless, their convergence analysis almost\nexclusively requires smoothness and/or convexity of the objective function. In\ncontrast, we establish non-asymptotic rates of convergence of first and\nzeroth-order adaptive methods and their proximal variants for a reasonably\nbroad class of nonsmooth \\& nonconvex optimization problems. Experimental\nresults indicate how the proposed algorithms empirically outperform stochastic\ngradient descent and its zeroth-order variant for solving such optimization\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 07:44:52 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 15:14:43 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Nazari", "Parvin", ""], ["Tarzanagh", "Davoud Ataee", ""], ["Michailidis", "George", ""]]}, {"id": "2005.09272", "submitter": "Lu Yu", "authors": "Lu Yu, Shichao Pei, Chuxu Zhang, Shangsong Liang, Xiao Bai, Nitesh\n  Chawla, Xiangliang Zhang", "title": "Addressing Class-Imbalance Problem in Personalized Ranking", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pairwise ranking models have been widely used to address recommendation\nproblems. The basic idea is to learn the rank of users' preferred items through\nseparating items into \\emph{positive} samples if user-item interactions exist,\nand \\emph{negative} samples otherwise. Due to the limited number of observable\ninteractions, pairwise ranking models face serious \\emph{class-imbalance}\nissues. Our theoretical analysis shows that current sampling-based methods\ncause the vertex-level imbalance problem, which makes the norm of learned item\nembeddings towards infinite after a certain training iterations, and\nconsequently results in vanishing gradient and affects the model inference\nresults. We thus propose an efficient \\emph{\\underline{Vi}tal\n\\underline{N}egative \\underline{S}ampler} (VINS) to alleviate the\nclass-imbalance issue for pairwise ranking model, in particular for deep\nlearning models optimized by gradient methods. The core of VINS is a bias\nsampler with reject probability that will tend to accept a negative candidate\nwith a larger degree weight than the given positive item. Evaluation results on\nseveral real datasets demonstrate that the proposed sampling method speeds up\nthe training procedure 30\\% to 50\\% for ranking models ranging from shallow to\ndeep, while maintaining and even improving the quality of ranking results in\ntop-N item recommendation.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 08:11:26 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 08:47:20 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Yu", "Lu", ""], ["Pei", "Shichao", ""], ["Zhang", "Chuxu", ""], ["Liang", "Shangsong", ""], ["Bai", "Xiao", ""], ["Chawla", "Nitesh", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "2005.09282", "submitter": "Bolaji Yusuf", "authors": "Bolaji Yusuf and Lucas Ondel", "title": "Bayesian Subspace HMM for the Zerospeech 2020 Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe our submission to the Zerospeech 2020 challenge,\nwhere the participants are required to discover latent representations from\nunannotated speech, and to use those representations to perform speech\nsynthesis, with synthesis quality used as a proxy metric for the unit quality.\nIn our system, we use the Bayesian Subspace Hidden Markov Model (SHMM) for unit\ndiscovery. The SHMM models each unit as an HMM whose parameters are constrained\nto lie in a low dimensional subspace of the total parameter space which is\ntrained to model phonetic variability. Our system compares favorably with the\nbaseline on the human-evaluated character error rate while maintaining\nsignificantly lower unit bitrate.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 08:28:38 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 12:24:11 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Yusuf", "Bolaji", ""], ["Ondel", "Lucas", ""]]}, {"id": "2005.09284", "submitter": "William Caicedo-Torres", "authors": "William Caicedo-Torres, Jairo Gutierrez", "title": "ISeeU2: Visually Interpretable ICU mortality prediction using deep\n  learning and free-text medical notes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Accurate mortality prediction allows Intensive Care Units (ICUs) to\nadequately benchmark clinical practice and identify patients with unexpected\noutcomes. Traditionally, simple statistical models have been used to assess\npatient death risk, many times with sub-optimal performance. On the other hand\ndeep learning holds promise to positively impact clinical practice by\nleveraging medical data to assist diagnosis and prediction, including mortality\nprediction. However, as the question of whether powerful Deep Learning models\nattend correlations backed by sound medical knowledge when generating\npredictions remains open, additional interpretability tools are needed to\nfoster trust and encourage the use of AI by clinicians. In this work we show a\nDeep Learning model trained on MIMIC-III to predict mortality using raw nursing\nnotes, together with visual explanations for word importance. Our model reaches\na ROC of 0.8629 (+/-0.0058), outperforming the traditional SAPS-II score and\nproviding enhanced interpretability when compared with similar Deep Learning\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 08:30:34 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Caicedo-Torres", "William", ""], ["Gutierrez", "Jairo", ""]]}, {"id": "2005.09294", "submitter": "Martin Kotuliak", "authors": "Martin Kotuliak, Sandro E. Schoenborn, Andrei Dan", "title": "Synthesizing Unrestricted False Positive Adversarial Objects Using\n  Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are data points misclassified by neural networks.\nOriginally, adversarial examples were limited to adding small perturbations to\na given image. Recent work introduced the generalized concept of unrestricted\nadversarial examples, without limits on the added perturbations. In this paper,\nwe introduce a new category of attacks that create unrestricted adversarial\nexamples for object detection. Our key idea is to generate adversarial objects\nthat are unrelated to the classes identified by the target object detector.\nDifferent from previous attacks, we use off-the-shelf Generative Adversarial\nNetworks (GAN), without requiring any further training or modification. Our\nmethod consists of searching over the latent normal space of the GAN for\nadversarial objects that are wrongly identified by the target object detector.\nWe evaluate this method on the commonly used Faster R-CNN ResNet-101, Inception\nv2 and SSD Mobilenet v1 object detectors using logo generative iWGAN-LC and\nSNGAN trained on CIFAR-10. The empirical results show that the generated\nadversarial objects are indistinguishable from non-adversarial objects\ngenerated by the GANs, transferable between the object detectors and robust in\nthe physical world. This is the first work to study unrestricted false positive\nadversarial examples for object detection.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 08:58:58 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Kotuliak", "Martin", ""], ["Schoenborn", "Sandro E.", ""], ["Dan", "Andrei", ""]]}, {"id": "2005.09296", "submitter": "Sungmin Kang", "authors": "Sungmin Kang (1), Robert Feldt (2), Shin Yoo (1) ((1) School of\n  Computing KAIST, (2) Chalmers University)", "title": "SINVAD: Search-based Image Space Navigation for DNN Image Classifier\n  Test Input Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The testing of Deep Neural Networks (DNNs) has become increasingly important\nas DNNs are widely adopted by safety critical systems. While many test adequacy\ncriteria have been suggested, automated test input generation for many types of\nDNNs remains a challenge because the raw input space is too large to randomly\nsample or to navigate and search for plausible inputs. Consequently, current\ntesting techniques for DNNs depend on small local perturbations to existing\ninputs, based on the metamorphic testing principle. We propose new ways to\nsearch not over the entire image space, but rather over a plausible input space\nthat resembles the true training distribution. This space is constructed using\nVariational Autoencoders (VAEs), and navigated through their latent vector\nspace. We show that this space helps efficiently produce test inputs that can\nreveal information about the robustness of DNNs when dealing with realistic\ntests, opening the field to meaningful exploration through the space of highly\nstructured images.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 09:06:21 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Kang", "Sungmin", ""], ["Feldt", "Robert", ""], ["Yoo", "Shin", ""]]}, {"id": "2005.09297", "submitter": "George Sterpu", "authors": "George Sterpu, Christian Saam, Naomi Harte", "title": "Should we hard-code the recurrence concept or learn it instead ?\n  Exploring the Transformer architecture for Audio-Visual Speech Recognition", "comments": "Submitted to INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The audio-visual speech fusion strategy AV Align has shown significant\nperformance improvements in audio-visual speech recognition (AVSR) on the\nchallenging LRS2 dataset. Performance improvements range between 7% and 30%\ndepending on the noise level when leveraging the visual modality of speech in\naddition to the auditory one. This work presents a variant of AV Align where\nthe recurrent Long Short-term Memory (LSTM) computation block is replaced by\nthe more recently proposed Transformer block. We compare the two methods,\ndiscussing in greater detail their strengths and weaknesses. We find that\nTransformers also learn cross-modal monotonic alignments, but suffer from the\nsame visual convergence problems as the LSTM model, calling for a deeper\ninvestigation into the dominant modality problem in machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 09:06:39 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Sterpu", "George", ""], ["Saam", "Christian", ""], ["Harte", "Naomi", ""]]}, {"id": "2005.09310", "submitter": "Yan Gao", "authors": "Yan Gao, Titouan Parcollet, Nicholas Lane", "title": "Distilling Knowledge from Ensembles of Acoustic Models for Joint\n  CTC-Attention End-to-End Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation has been widely used to compress existing deep\nlearning models while preserving the performance on a wide range of\napplications. In the specific context of Automatic Speech Recognition (ASR),\ndistillation from ensembles of acoustic models has recently shown promising\nresults in increasing recognition performance. In this paper, we propose an\nextension of multi-teacher distillation methods to joint CTC-attention\nend-to-end ASR systems. We also introduce three novel distillation strategies.\nThe core intuition behind them is to integrate the error rate metric to the\nteacher selection rather than solely focusing on the observed losses. In this\nway, we directly distill and optimize the student toward the relevant metric\nfor speech recognition. We evaluate these strategies under a selection of\ntraining procedures on different datasets (TIMIT, Librispeech, Common Voice)\nand various languages (English, French, Italian). In particular,\nstate-of-the-art error rates are reported on the Common Voice French, Italian\nand TIMIT datasets.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 09:24:54 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 04:17:07 GMT"}, {"version": "v3", "created": "Sun, 4 Jul 2021 02:15:21 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Gao", "Yan", ""], ["Parcollet", "Titouan", ""], ["Lane", "Nicholas", ""]]}, {"id": "2005.09319", "submitter": "Albert Zeyer", "authors": "Albert Zeyer, Andr\\'e Merboldt, Ralf Schl\\\"uter, Hermann Ney", "title": "A New Training Pipeline for an Improved Neural Transducer", "comments": "published at Interspeech 2020", "journal-ref": null, "doi": "10.21437/Interspeech.2020-1855", "report-no": null, "categories": "eess.AS cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The RNN transducer is a promising end-to-end model candidate. We compare the\noriginal training criterion with the full marginalization over all alignments,\nto the commonly used maximum approximation, which simplifies, improves and\nspeeds up our training. We also generalize from the original neural network\nmodel and study more powerful models, made possible due to the maximum\napproximation. We further generalize the output label topology to cover RNN-T,\nRNA and CTC. We perform several studies among all these aspects, including a\nstudy on the effect of external alignments. We find that the transducer model\ngeneralizes much better on longer sequences than the attention model. Our final\ntransducer model outperforms our attention model on Switchboard 300h by over 6%\nrelative WER.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 09:35:38 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 22:13:01 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Zeyer", "Albert", ""], ["Merboldt", "Andr\u00e9", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "2005.09336", "submitter": "Albert Zeyer", "authors": "Mohammad Zeineldeen, Albert Zeyer, Wei Zhou, Thomas Ng, Ralf\n  Schl\\\"uter, Hermann Ney", "title": "A systematic comparison of grapheme-based vs. phoneme-based label units\n  for encoder-decoder-attention models", "comments": "5 pages, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the rationale of end-to-end modeling, CTC, RNN-T or\nencoder-decoder-attention models for automatic speech recognition (ASR) use\ngraphemes or grapheme-based subword units based on e.g. byte-pair encoding\n(BPE). The mapping from pronunciation to spelling is learned completely from\ndata. In contrast to this, classical approaches to ASR employ secondary\nknowledge sources in the form of phoneme lists to define phonetic output labels\nand pronunciation lexica. In this work, we do a systematic comparison between\ngrapheme- and phoneme-based output labels for an encoder-decoder-attention ASR\nmodel. We investigate the use of single phonemes as well as BPE-based phoneme\ngroups as output labels of our model. To preserve a simplified and efficient\ndecoder design, we also extend the phoneme set by auxiliary units to be able to\ndistinguish homophones. Experiments performed on the Switchboard 300h and\nLibriSpeech benchmarks show that phoneme-based modeling is competitive to\ngrapheme-based encoder-decoder-attention modeling.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 09:54:17 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 22:05:17 GMT"}, {"version": "v3", "created": "Thu, 15 Apr 2021 16:59:10 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Zeineldeen", "Mohammad", ""], ["Zeyer", "Albert", ""], ["Zhou", "Wei", ""], ["Ng", "Thomas", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "2005.09343", "submitter": "Hong-Bin Liu", "authors": "Hong-Bin Liu, Ickjai Lee", "title": "Bridging the Gap Between Training and Inference for Spatio-Temporal\n  Forecasting", "comments": "ECAI 2020 Accepted, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatio-temporal sequence forecasting is one of the fundamental tasks in\nspatio-temporal data mining. It facilitates many real world applications such\nas precipitation nowcasting, citywide crowd flow prediction and air pollution\nforecasting. Recently, a few Seq2Seq based approaches have been proposed, but\none of the drawbacks of Seq2Seq models is that, small errors can accumulate\nquickly along the generated sequence at the inference stage due to the\ndifferent distributions of training and inference phase. That is because\nSeq2Seq models minimise single step errors only during training, however the\nentire sequence has to be generated during the inference phase which generates\na discrepancy between training and inference. In this work, we propose a novel\ncurriculum learning based strategy named Temporal Progressive Growing Sampling\nto effectively bridge the gap between training and inference for\nspatio-temporal sequence forecasting, by transforming the training process from\na fully-supervised manner which utilises all available previous ground-truth\nvalues to a less-supervised manner which replaces some of the ground-truth\ncontext with generated predictions. To do that we sample the target sequence\nfrom midway outputs from intermediate models trained with bigger timescales\nthrough a carefully designed decaying strategy. Experimental results\ndemonstrate that our proposed method better models long term dependencies and\noutperforms baseline approaches on two competitive datasets.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 10:14:43 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Liu", "Hong-Bin", ""], ["Lee", "Ickjai", ""]]}, {"id": "2005.09347", "submitter": "Yukuo Cen", "authors": "Yukuo Cen, Jianwei Zhang, Xu Zou, Chang Zhou, Hongxia Yang, Jie Tang", "title": "Controllable Multi-Interest Framework for Recommendation", "comments": "Accepted to KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural networks have been widely used in e-commerce recommender\nsystems, owing to the rapid development of deep learning. We formalize the\nrecommender system as a sequential recommendation problem, intending to predict\nthe next items that the user might be interacted with. Recent works usually\ngive an overall embedding from a user's behavior sequence. However, a unified\nuser embedding cannot reflect the user's multiple interests during a period. In\nthis paper, we propose a novel controllable multi-interest framework for the\nsequential recommendation, called ComiRec. Our multi-interest module captures\nmultiple interests from user behavior sequences, which can be exploited for\nretrieving candidate items from the large-scale item pool. These items are then\nfed into an aggregation module to obtain the overall recommendation. The\naggregation module leverages a controllable factor to balance the\nrecommendation accuracy and diversity. We conduct experiments for the\nsequential recommendation on two real-world datasets, Amazon and Taobao.\nExperimental results demonstrate that our framework achieves significant\nimprovements over state-of-the-art models. Our framework has also been\nsuccessfully deployed on the offline Alibaba distributed cloud platform.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 10:18:43 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 02:16:38 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Cen", "Yukuo", ""], ["Zhang", "Jianwei", ""], ["Zou", "Xu", ""], ["Zhou", "Chang", ""], ["Yang", "Hongxia", ""], ["Tang", "Jie", ""]]}, {"id": "2005.09363", "submitter": "Chizhou Liu", "authors": "Chizhou Liu, Yunzhen Feng, Ranran Wang, Bin Dong", "title": "Enhancing Certified Robustness via Smoothed Weighted Ensembling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized smoothing has achieved state-of-the-art certified robustness\nagainst $l_2$-norm adversarial attacks. However, it is not wholly resolved on\nhow to find the optimal base classifier for randomized smoothing. In this work,\nwe employ a Smoothed WEighted ENsembling (SWEEN) scheme to improve the\nperformance of randomized smoothed classifiers. We show the ensembling\ngenerality that SWEEN can help achieve optimal certified robustness.\nFurthermore, theoretical analysis proves that the optimal SWEEN model can be\nobtained from training under mild assumptions. We also develop an adaptive\nprediction algorithm to reduce the prediction and certification cost of SWEEN\nmodels. Extensive experiments show that SWEEN models outperform the upper\nenvelope of their corresponding candidate models by a large margin. Moreover,\nSWEEN models constructed using a few small models can achieve comparable\nperformance to a single large model with a notable reduction in training time.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 11:13:43 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 06:56:51 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2021 14:03:58 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Liu", "Chizhou", ""], ["Feng", "Yunzhen", ""], ["Wang", "Ranran", ""], ["Dong", "Bin", ""]]}, {"id": "2005.09372", "submitter": "Rituparna Sarkar", "authors": "Rituparna Sarkar, Suvadip Mukherjee, Elisabeth Labruy\\`ere and\n  Jean-Christophe Olivo-Marin", "title": "Learning to segment clustered amoeboid cells from brightfield microscopy\n  via multi-task learning with adaptive weight selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting and segmenting individual cells from microscopy images is critical\nto various life science applications. Traditional cell segmentation tools are\noften ill-suited for applications in brightfield microscopy due to poor\ncontrast and intensity heterogeneity, and only a small subset are applicable to\nsegment cells in a cluster. In this regard, we introduce a novel supervised\ntechnique for cell segmentation in a multi-task learning paradigm. A\ncombination of a multi-task loss, based on the region and cell boundary\ndetection, is employed for an improved prediction efficiency of the network.\nThe learning problem is posed in a novel min-max framework which enables\nadaptive estimation of the hyper-parameters in an automatic fashion. The region\nand cell boundary predictions are combined via morphological operations and\nactive contour model to segment individual cells.\n  The proposed methodology is particularly suited to segment touching cells\nfrom brightfield microscopy images without manual interventions.\nQuantitatively, we observe an overall Dice score of 0.93 on the validation set,\nwhich is an improvement of over 15.9% on a recent unsupervised method, and\noutperforms the popular supervised U-net algorithm by at least $5.8\\%$ on\naverage.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 11:31:53 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Sarkar", "Rituparna", ""], ["Mukherjee", "Suvadip", ""], ["Labruy\u00e8re", "Elisabeth", ""], ["Olivo-Marin", "Jean-Christophe", ""]]}, {"id": "2005.09377", "submitter": "EL-Hachemi Guerrout", "authors": "EL-Hachemi Guerrout, Ramdane Mahiou, Dominique Michelucci, Boukabene\n  Randa and Ouali Assia", "title": "hidden markov random fields and cuckoo search method for medical image\n  segmentation", "comments": "5 pages, 2 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Segmentation of medical images is an essential part in the process of\ndiagnostics. Physicians require an automatic, robust and valid results. Hidden\nMarkov Random Fields (HMRF) provide powerful model. This latter models the\nsegmentation problem as the minimization of an energy function. Cuckoo search\n(CS) algorithm is one of the recent nature-inspired meta-heuristic algorithms.\nIt has shown its efficiency in many engineering optimization problems. In this\npaper, we use three cuckoo search algorithm to achieve medical image\nsegmentation.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 11:54:03 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Guerrout", "EL-Hachemi", ""], ["Mahiou", "Ramdane", ""], ["Michelucci", "Dominique", ""], ["Randa", "Boukabene", ""], ["Assia", "Ouali", ""]]}, {"id": "2005.09389", "submitter": "Lukas Lange", "authors": "Lukas Lange, Heike Adel, Jannik Str\\\"otgen", "title": "On the Choice of Auxiliary Languages for Improved Sequence Tagging", "comments": "RepL4NLP at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work showed that embeddings from related languages can improve the\nperformance of sequence tagging, even for monolingual models. In this analysis\npaper, we investigate whether the best auxiliary language can be predicted\nbased on language distances and show that the most related language is not\nalways the best auxiliary language. Further, we show that attention-based\nmeta-embeddings can effectively combine pre-trained embeddings from different\nlanguages for sequence tagging and set new state-of-the-art results for\npart-of-speech tagging in five languages.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 12:32:20 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Lange", "Lukas", ""], ["Adel", "Heike", ""], ["Str\u00f6tgen", "Jannik", ""]]}, {"id": "2005.09391", "submitter": "Rahul Jashvantbhai Pandya Dr", "authors": "Raghu Vamshi Hemadri, Akshay Rayaluru, and Rahul Jashvantbhai Pandya", "title": "AEVB-Comm: An Intelligent CommunicationSystem based on AEVBs", "comments": "Paper is under review with IEEE Transactions on Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, applying Deep Learning (DL) techniques emerged as a common\npractice in the communication system, demonstrating promising results. The\npresent paper proposes a new Convolutional Neural Network (CNN) based\nVariational Autoencoder (VAE) communication system. The VAE (continuous latent\nspace) based communication systems confer unprecedented improvement in the\nsystem performance compared to AE (distributed latent space) and other\ntraditional methods. We have introduced an adjustable hyperparameter beta in\nthe proposed VAE, which is also known as beta-VAE, resulting in extremely\ndisentangled latent space representation. Furthermore, a higher-dimensional\nrepresentation of latent space is employed, such as 4n dimension instead of 2n,\nreducing the Block Error Rate (BLER). The proposed system can operate under\nAdditive Wide Gaussian Noise (AWGN) and Rayleigh fading channels. The CNN based\nVAE architecture performs the encoding and modulation at the transmitter,\nwhereas decoding and demodulation at the receiver. Finally, to prove that a\ncontinuous latent space-based system designated VAE performs better than the\nother, various simulation results supporting the same has been conferred under\nnormal and noisy conditions.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 12:36:37 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Hemadri", "Raghu Vamshi", ""], ["Rayaluru", "Akshay", ""], ["Pandya", "Rahul Jashvantbhai", ""]]}, {"id": "2005.09392", "submitter": "Lukas Lange", "authors": "Lukas Lange, Anastasiia Iurshina, Heike Adel, Jannik Str\\\"otgen", "title": "Adversarial Alignment of Multilingual Models for Extracting Temporal\n  Expressions from Text", "comments": "RepL4NLP at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although temporal tagging is still dominated by rule-based systems, there\nhave been recent attempts at neural temporal taggers. However, all of them\nfocus on monolingual settings. In this paper, we explore multilingual methods\nfor the extraction of temporal expressions from text and investigate\nadversarial training for aligning embedding spaces to one common space. With\nthis, we create a single multilingual model that can also be transferred to\nunseen languages and set the new state of the art in those cross-lingual\ntransfer experiments.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 12:37:04 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Lange", "Lukas", ""], ["Iurshina", "Anastasiia", ""], ["Adel", "Heike", ""], ["Str\u00f6tgen", "Jannik", ""]]}, {"id": "2005.09393", "submitter": "Filippo Fabiani", "authors": "Filippo Fabiani, Paul J. Goulart", "title": "The optimal transport paradigm enables data compression in data-driven\n  robust control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new data-enabled control technique for uncertain linear time-invariant\nsystems, recently conceived by Coulson et\\ al., builds upon the direct\noptimization of controllers over input/output pairs drawn from a large dataset.\nWe adopt an optimal transport-based method for compressing such large dataset\nto a smaller synthetic dataset of representative behaviours, aiming to\nalleviate the computational burden of controllers to be implemented online.\nSpecifically, the synthetic data are determined by minimizing the Wasserstein\ndistance between atomic distributions supported on both the original dataset\nand the compressed one. We show that a distributionally robust control law\ncomputed using the compressed data enjoys the same type of performance\nguarantees as the original dataset, at the price of enlarging the ambiguity set\nby an easily computable and well-behaved quantity. Numerical simulations\nconfirm that the control performance with the synthetic data is comparable to\nthe one obtained with the original data, but with significantly less\ncomputation required.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 12:38:20 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 22:43:15 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Fabiani", "Filippo", ""], ["Goulart", "Paul J.", ""]]}, {"id": "2005.09394", "submitter": "Hirofumi Inaguma", "authors": "Hirofumi Inaguma, Masato Mimura, Tatsuya Kawahara", "title": "Enhancing Monotonic Multihead Attention for Streaming ASR", "comments": "Accepted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a monotonic multihead attention (MMA) by extending hard\nmonotonic attention to Transformer-based automatic speech recognition (ASR) for\nonline streaming applications. For streaming inference, all monotonic attention\n(MA) heads should learn proper alignments because the next token is not\ngenerated until all heads detect the corresponding token boundaries. However,\nwe found not all MA heads learn alignments with a na\\\"ive implementation. To\nencourage every head to learn alignments properly, we propose HeadDrop\nregularization by masking out a part of heads stochastically during training.\nFurthermore, we propose to prune redundant heads to improve consensus among\nheads for boundary detection and prevent delayed token generation caused by\nsuch heads. Chunkwise attention on each MA head is extended to the multihead\ncounterpart. Finally, we propose head-synchronous beam search decoding to\nguarantee stable streaming inference.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 12:39:38 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 11:11:27 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 12:20:25 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Inaguma", "Hirofumi", ""], ["Mimura", "Masato", ""], ["Kawahara", "Tatsuya", ""]]}, {"id": "2005.09397", "submitter": "Lukas Lange", "authors": "Lukas Lange, Heike Adel, Jannik Str\\\"otgen", "title": "Closing the Gap: Joint De-Identification and Concept Extraction in the\n  Clinical Domain", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploiting natural language processing in the clinical domain requires\nde-identification, i.e., anonymization of personal information in texts.\nHowever, current research considers de-identification and downstream tasks,\nsuch as concept extraction, only in isolation and does not study the effects of\nde-identification on other tasks. In this paper, we close this gap by reporting\nconcept extraction performance on automatically anonymized data and\ninvestigating joint models for de-identification and concept extraction. In\nparticular, we propose a stacked model with restricted access to\nprivacy-sensitive information and a multitask model. We set the new state of\nthe art on benchmark datasets in English (96.1% F1 for de-identification and\n88.9% F1 for concept extraction) and Spanish (91.4% F1 for concept extraction).\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 12:44:41 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Lange", "Lukas", ""], ["Adel", "Heike", ""], ["Str\u00f6tgen", "Jannik", ""]]}, {"id": "2005.09424", "submitter": "Giuseppe Genovese", "authors": "Giuseppe Genovese", "title": "Minimax formula for the replica symmetric free energy of deep restricted\n  Boltzmann machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the free energy of a most used deep architecture for restricted\nBoltzmann machines, where the layers are disposed in series. Assuming\nindependent Gaussian distributed random weights, we show that the error term in\nthe so-called replica symmetric sum rule can be optimised as a saddle point.\nThis leads us to conjecture that in the replica symmetric approximation the\nfree energy is given by a min max formula, which parallels the one achieved for\ntwo-layer case.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 15:01:06 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Genovese", "Giuseppe", ""]]}, {"id": "2005.09428", "submitter": "Ding Liu", "authors": "Ding Liu, Zekun Yao, Quan Zhang", "title": "Quantum-Classical Machine learning by Hybrid Tensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor networks (TN) have found a wide use in machine learning, and in\nparticular, TN and deep learning bear striking similarities. In this work, we\npropose the quantum-classical hybrid tensor networks (HTN) which combine tensor\nnetworks with classical neural networks in a uniform deep learning framework to\novercome the limitations of regular tensor networks in machine learning. We\nfirst analyze the limitations of regular tensor networks in the applications of\nmachine learning involving the representation power and architecture\nscalability. We conclude that in fact the regular tensor networks are not\ncompetent to be the basic building blocks of deep learning. Then, we discuss\nthe performance of HTN which overcome all the deficiency of regular tensor\nnetworks for machine learning. In this sense, we are able to train HTN in the\ndeep learning way which is the standard combination of algorithms such as Back\nPropagation and Stochastic Gradient Descent. We finally provide two applicable\ncases to show the potential applications of HTN, including quantum states\nclassification and quantum-classical autoencoder. These cases also demonstrate\nthe great potentiality to design various HTN in deep learning way.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 10:20:35 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Liu", "Ding", ""], ["Yao", "Zekun", ""], ["Zhang", "Quan", ""]]}, {"id": "2005.09436", "submitter": "Siamak Parhizkari", "authors": "Siamak Parhizkari, Mohammad Bagher Menhaj", "title": "A cognitive based Intrusion detection system", "comments": "18 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion detection is one of the primary mechanisms to provide computer\nnetworks with security. With an increase in attacks and growing dependence on\nvarious fields such as medicine, commercial, and engineering to give services\nover a network, securing networks have become a significant issue. The purpose\nof Intrusion Detection Systems (IDS) is to make models which can recognize\nregular communications from abnormal ones and take necessary actions. Among\ndifferent methods in this field, Artificial Neural Networks (ANNs) have been\nwidely used. However, ANN-based IDS, has two main disadvantages: 1- Low\ndetection precision. 2- Weak detection stability. To overcome these issues,\nthis paper proposes a new approach based on Deep Neural Network (DNN. The\ngeneral mechanism of our model is as follows: first, some of the data in\ndataset is properly ranked, afterwards, dataset is normalized with Min-Max\nnormalizer to fit in the limited domain. Then dimensionality reduction is\napplied to decrease the amount of both useless dimensions and computational\ncost. After the preprocessing part, Mean-Shift clustering algorithm is the used\nto create different subsets and reduce the complexity of dataset. Based on each\nsubset, two models are trained by Support Vector Machine (SVM) and deep\nlearning method. Between two models for each subset, the model with a higher\naccuracy is chosen. This idea is inspired from philosophy of divide and\nconquer. Hence, the DNN can learn each subset quickly and robustly. Finally, to\nreduce the error from the previous step, an ANN model is trained to gain and\nuse the results in order to be able to predict the attacks. We can reach to\n95.4 percent of accuracy. Possessing a simple structure and less number of\ntunable parameters, the proposed model still has a grand generalization with a\nhigh level of accuracy in compared to other methods such as SVM, Bayes network,\nand STL.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 13:30:30 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Parhizkari", "Siamak", ""], ["Menhaj", "Mohammad Bagher", ""]]}, {"id": "2005.09448", "submitter": "Hans-J\\\"urgen Profitlich", "authors": "Daniel Sonntag, Fabrizio Nunnari, and Hans-J\\\"urgen Profitlich", "title": "The Skincare project, an interactive deep learning system for\n  differential diagnosis of malignant skin lesions. Technical Report", "comments": "20 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  A shortage of dermatologists causes long wait times for patients who seek\ndermatologic care. In addition, the diagnostic accuracy of general\npractitioners has been reported to be lower than the accuracy of artificial\nintelligence software. This article describes the Skincare project (H2020, EIT\nDigital). Contributions include enabling technology for clinical decision\nsupport based on interactive machine learning (IML), a reference architecture\ntowards a Digital European Healthcare Infrastructure (also cf. EIT MCPS),\ntechnical components for aggregating digitised patient information, and the\nintegration of decision support technology into clinical test-bed environments.\nHowever, the main contribution is a diagnostic and decision support system in\ndermatology for patients and doctors, an interactive deep learning system for\ndifferential diagnosis of malignant skin lesions. In this article, we describe\nits functionalities and the user interfaces to facilitate machine learning from\nhuman input. The baseline deep learning system, which delivers state-of-the-art\nresults and the potential to augment general practitioners and even\ndermatologists, was developed and validated using de-identified cases from a\ndermatology image data base (ISIC), which has about 20000 cases for development\nand validation, provided by board-certified dermatologists defining the\nreference standard for every case. ISIC allows for differential diagnosis, a\nranked list of eight diagnoses, that is used to plan treatments in the common\nsetting of diagnostic ambiguity. We give an overall description of the outcome\nof the Skincare project, and we focus on the steps to support communication and\ncoordination between humans and machine in IML. This is an integral part of the\ndevelopment of future cognitive assistants in the medical domain, and we\ndescribe the necessary intelligent user interfaces.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 13:51:17 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Sonntag", "Daniel", ""], ["Nunnari", "Fabrizio", ""], ["Profitlich", "Hans-J\u00fcrgen", ""]]}, {"id": "2005.09453", "submitter": "Zhenhui Ye", "authors": "Zhenhui Ye, Yining Chen, Guanghua Song, Bowei Yang, Shen Fan", "title": "Experience Augmentation: Boosting and Accelerating Off-Policy\n  Multi-Agent Reinforcement Learning", "comments": "10 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration of the high-dimensional state action space is one of the biggest\nchallenges in Reinforcement Learning (RL), especially in multi-agent domain. We\npresent a novel technique called Experience Augmentation, which enables a\ntime-efficient and boosted learning based on a fast, fair and thorough\nexploration to the environment. It can be combined with arbitrary off-policy\nMARL algorithms and is applicable to either homogeneous or heterogeneous\nenvironments. We demonstrate our approach by combining it with MADDPG and\nverifing the performance in two homogeneous and one heterogeneous environments.\nIn the best performing scenario, the MADDPG with experience augmentation\nreaches to the convergence reward of vanilla MADDPG with 1/4 realistic time,\nand its convergence beats the original model by a significant margin. Our\nablation studies show that experience augmentation is a crucial ingredient\nwhich accelerates the training process and boosts the convergence.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 13:57:11 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 02:12:08 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Ye", "Zhenhui", ""], ["Chen", "Yining", ""], ["Song", "Guanghua", ""], ["Yang", "Bowei", ""], ["Fan", "Shen", ""]]}, {"id": "2005.09463", "submitter": "Pramit Saha", "authors": "Pramit Saha, Sidney Fels", "title": "Learning Joint Articulatory-Acoustic Representations with Normalizing\n  Flows", "comments": "5 pages, 4 figures, accepted for publication in Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The articulatory geometric configurations of the vocal tract and the acoustic\nproperties of the resultant speech sound are considered to have a strong causal\nrelationship. This paper aims at finding a joint latent representation between\nthe articulatory and acoustic domain for vowel sounds via invertible neural\nnetwork models, while simultaneously preserving the respective domain-specific\nfeatures. Our model utilizes a convolutional autoencoder architecture and\nnormalizing flow-based models to allow both forward and inverse mappings in a\nsemi-supervised manner, between the mid-sagittal vocal tract geometry of a two\ndegrees-of-freedom articulatory synthesizer with 1D acoustic wave model and the\nMel-spectrogram representation of the synthesized speech sounds. Our approach\nachieves satisfactory performance in achieving both articulatory-to-acoustic as\nwell as acoustic-to-articulatory mapping, thereby demonstrating our success in\nachieving a joint encoding of both the domains.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 04:34:36 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 03:54:41 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Saha", "Pramit", ""], ["Fels", "Sidney", ""]]}, {"id": "2005.09476", "submitter": "Jixuan Zhi", "authors": "Jixuan Zhi and Jyh-Ming Lien", "title": "Learning to Herd Agents Amongst Obstacles: Training Robust Shepherding\n  Behaviors using Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic shepherding problem considers the control and navigation of a group\nof coherent agents (e.g., a flock of bird or a fleet of drones) through the\nmotion of an external robot, called shepherd. Machine learning based methods\nhave successfully solved this problem in an empty environment with no\nobstacles. Rule-based methods, on the other hand, can handle more complex\nscenarios in which environments are cluttered with obstacles and allow multiple\nshepherds to work collaboratively. However, these rule-based methods are\nfragile due to the difficulty in defining a comprehensive set of rules that can\nhandle all possible cases. To overcome these limitations, we propose the first\nknown learning-based method that can herd agents amongst obstacles. By using\ndeep reinforcement learning techniques combined with the probabilistic\nroadmaps, we train a shepherding model using noisy but controlled environmental\nand behavioral parameters. Our experimental results show that the proposed\nmethod is robust, namely, it is insensitive to the uncertainties originated\nfrom both environmental and behavioral models. Consequently, the proposed\nmethod has a higher success rate, shorter completion time and path length than\nthe rule-based behavioral methods have. These advantages are particularly\nprominent in more challenging scenarios involving more difficult groups and\nstrenuous passages.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 14:23:16 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Zhi", "Jixuan", ""], ["Lien", "Jyh-Ming", ""]]}, {"id": "2005.09485", "submitter": "Run-Qing Chen", "authors": "Wan-Lei Zhao, Run-Qing Chen, Hui Ye and Chong-Wah Ngo", "title": "k-sums: another side of k-means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the decades-old clustering method k-means is revisited. The\noriginal distortion minimization model of k-means is addressed by a pure\nstochastic minimization procedure. In each step of the iteration, one sample is\ntentatively reallocated from one cluster to another. It is moved to another\ncluster as long as the reallocation allows the sample to be closer to the new\ncentroid. This optimization procedure converges faster to a better local\nminimum over k-means and many of its variants. This fundamental modification\nover the k-means loop leads to the redefinition of a family of k-means\nvariants. Moreover, a new target function that minimizes the summation of\npairwise distances within clusters is presented. We show that it could be\nsolved under the same stochastic optimization procedure. This minimization\nprocedure built upon two minimization models outperforms k-means and its\nvariants considerably with different settings and on different datasets.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 14:36:12 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Zhao", "Wan-Lei", ""], ["Chen", "Run-Qing", ""], ["Ye", "Hui", ""], ["Ngo", "Chong-Wah", ""]]}, {"id": "2005.09503", "submitter": "Donald Reising", "authors": "Donald Reising, Joseph Cancelleri, T. Daniel Loveless, Farah Kandah,\n  and Anthony Skjellum", "title": "Pre-print: Radio Identity Verification-based IoT Security Using RF-DNA\n  Fingerprints and SVM", "comments": "14 pages, 23 figures and sub-figures, Submitted to the IEEE Internet\n  of Things Journal on May 19, 2020", "journal-ref": "IEEE Internet of Things Journal 2021", "doi": "10.1109/JIOT.2020.3045305", "report-no": null, "categories": "eess.SP cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is estimated that the number of IoT devices will reach 75 billion in the\nnext five years. Most of those currently, and to be deployed, lack sufficient\nsecurity to protect themselves and their networks from attack by malicious IoT\ndevices that masquerade as authorized devices to circumvent digital\nauthentication approaches. This work presents a PHY layer IoT authentication\napproach capable of addressing this critical security need through the use of\nfeature reduced Radio Frequency-Distinct Native Attributes (RF-DNA)\nfingerprints and Support Vector Machines (SVM). This work successfully\ndemonstrates 100%: (i) authorized ID verification across three trials of six\nrandomly chosen radios at signal-to-noise ratios greater than or equal to 6 dB,\nand (ii) rejection of all rogue radio ID spoofing attacks at signal-to-noise\nratios greater than or equal to 3 dB using RF-DNA fingerprints whose features\nare selected using the Relief-F algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 15:02:20 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Reising", "Donald", ""], ["Cancelleri", "Joseph", ""], ["Loveless", "T. Daniel", ""], ["Kandah", "Farah", ""], ["Skjellum", "Anthony", ""]]}, {"id": "2005.09512", "submitter": "Frederico Gadelha Guimaraes", "authors": "Leonardo Augusto Ferreira and Frederico Gadelha Guimar\\~aes and\n  Rodrigo Silva", "title": "Applying Genetic Programming to Improve Interpretability in Machine\n  Learning Models", "comments": "8 pages, 8 figures, submitted and accepted to 2020 IEEE Congress on\n  Evolutionary Computation (IEEE CEC 2020). Copyright 2020 IEEE. Personal use\n  of this material is permitted. Permission from IEEE must be obtained for all\n  other uses", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable Artificial Intelligence (or xAI) has become an important research\ntopic in the fields of Machine Learning and Deep Learning. In this paper, we\npropose a Genetic Programming (GP) based approach, named Genetic Programming\nExplainer (GPX), to the problem of explaining decisions computed by AI systems.\nThe method generates a noise set located in the neighborhood of the point of\ninterest, whose prediction should be explained, and fits a local explanation\nmodel for the analyzed sample. The tree structure generated by GPX provides a\ncomprehensible analytical, possibly non-linear, symbolic expression which\nreflects the local behavior of the complex model. We considered three machine\nlearning techniques that can be recognized as complex black-box models: Random\nForest, Deep Neural Network and Support Vector Machine in twenty data sets for\nregression and classifications problems. Our results indicate that the GPX is\nable to produce more accurate understanding of complex models than the state of\nthe art. The results validate the proposed approach as a novel way to deploy GP\nto improve interpretability.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 16:09:49 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Ferreira", "Leonardo Augusto", ""], ["Guimar\u00e3es", "Frederico Gadelha", ""], ["Silva", "Rodrigo", ""]]}, {"id": "2005.09525", "submitter": "Jacob Whitehill", "authors": "Anand Ramakrishnan and Brian Zylich and Erin Ottmar and Jennifer\n  LoCasale-Crouch and Jacob Whitehill", "title": "Toward Automated Classroom Observation: Multimodal Machine Learning to\n  Estimate CLASS Positive Climate and Negative Climate", "comments": "The authors discovered that the results are not reproducible", "journal-ref": "IEEE Transactions on Affective Computing, 2021", "doi": "10.1109/TAFFC.2021.3059209", "report-no": null, "categories": "cs.CV cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a multi-modal machine learning-based system, which we\ncall ACORN, to analyze videos of school classrooms for the Positive Climate\n(PC) and Negative Climate (NC) dimensions of the CLASS observation protocol\nthat is widely used in educational research. ACORN uses convolutional neural\nnetworks to analyze spectral audio features, the faces of teachers and\nstudents, and the pixels of each image frame, and then integrates this\ninformation over time using Temporal Convolutional Networks. The audiovisual\nACORN's PC and NC predictions have Pearson correlations of $0.55$ and $0.63$\nwith ground-truth scores provided by expert CLASS coders on the UVA Toddler\ndataset (cross-validation on $n=300$ 15-min video segments), and a purely\nauditory ACORN predicts PC and NC with correlations of $0.36$ and $0.41$ on the\nMET dataset (test set of $n=2000$ videos segments). These numbers are similar\nto inter-coder reliability of human coders. Finally, using Graph Convolutional\nNetworks we make early strides (AUC=$0.70$) toward predicting the specific\nmoments (45-90sec clips) when the PC is particularly weak/strong. Our findings\ninform the design of automatic classroom observation and also more general\nvideo activity recognition and summary recognition systems.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 15:36:32 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 23:02:07 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 15:24:49 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Ramakrishnan", "Anand", ""], ["Zylich", "Brian", ""], ["Ottmar", "Erin", ""], ["LoCasale-Crouch", "Jennifer", ""], ["Whitehill", "Jacob", ""]]}, {"id": "2005.09526", "submitter": "Jawar Singh Dr.", "authors": "Abhash Kumar, Jawar Singh, Sai Manohar Beeraka, and Bharat Gupta", "title": "In-memory Implementation of On-chip Trainable and Scalable ANN for AI/ML\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional von Neumann architecture based processors become inefficient in\nterms of energy and throughput as they involve separate processing and memory\nunits, also known as~\\textit{memory wall}. The memory wall problem is further\nexacerbated when massive parallelism and frequent data movement are required\nbetween processing and memory units for real-time implementation of artificial\nneural network (ANN) that enables many intelligent applications. One of the\nmost promising approach to address the memory wall problem is to carry out\ncomputations inside the memory core itself that enhances the memory bandwidth\nand energy efficiency for extensive computations. This paper presents an\nin-memory computing architecture for ANN enabling artificial intelligence (AI)\nand machine learning (ML) applications. The proposed architecture utilizes deep\nin-memory architecture based on standard six transistor (6T) static random\naccess memory (SRAM) core for the implementation of a multi-layered perceptron.\nOur novel on-chip training and inference in-memory architecture reduces energy\ncost and enhances throughput by simultaneously accessing the multiple rows of\nSRAM array per precharge cycle and eliminating the frequent access of data. The\nproposed architecture realizes backpropagation which is the keystone during the\nnetwork training using newly proposed different building blocks such as weight\nupdation, analog multiplication, error calculation, signed analog to digital\nconversion, and other necessary signal control units. The proposed architecture\nwas trained and tested on the IRIS dataset which exhibits $\\approx46\\times$\nmore energy efficient per MAC (multiply and accumulate) operation compared to\nearlier classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 15:36:39 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Kumar", "Abhash", ""], ["Singh", "Jawar", ""], ["Beeraka", "Sai Manohar", ""], ["Gupta", "Bharat", ""]]}, {"id": "2005.09530", "submitter": "Peter Karkus", "authors": "Peter Karkus, Anelia Angelova, Vincent Vanhoucke, Rico Jonschkowski", "title": "Differentiable Mapping Networks: Learning Structured Map Representations\n  for Sparse Visual Localization", "comments": "ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mapping and localization, preferably from a small number of observations, are\nfundamental tasks in robotics. We address these tasks by combining spatial\nstructure (differentiable mapping) and end-to-end learning in a novel neural\nnetwork architecture: the Differentiable Mapping Network (DMN). The DMN\nconstructs a spatially structured view-embedding map and uses it for subsequent\nvisual localization with a particle filter. Since the DMN architecture is\nend-to-end differentiable, we can jointly learn the map representation and\nlocalization using gradient descent. We apply the DMN to sparse visual\nlocalization, where a robot needs to localize in a new environment with respect\nto a small number of images from known viewpoints. We evaluate the DMN using\nsimulated environments and a challenging real-world Street View dataset. We\nfind that the DMN learns effective map representations for visual localization.\nThe benefit of spatial structure increases with larger environments, more\nviewpoints for mapping, and when training data is scarce. Project website:\nhttp://sites.google.com/view/differentiable-mapping\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 15:43:39 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Karkus", "Peter", ""], ["Angelova", "Anelia", ""], ["Vanhoucke", "Vincent", ""], ["Jonschkowski", "Rico", ""]]}, {"id": "2005.09561", "submitter": "Oliver Richter", "authors": "Oliver Richter and Roger Wattenhofer", "title": "Normalized Attention Without Probability Cage", "comments": "Preprint, work in progress. Feedback welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention architectures are widely used; they recently gained renewed\npopularity with Transformers yielding a streak of state of the art results.\nYet, the geometrical implications of softmax-attention remain largely\nunexplored. In this work we highlight the limitations of constraining attention\nweights to the probability simplex and the resulting convex hull of value\nvectors. We show that Transformers are sequence length dependent biased towards\ntoken isolation at initialization and contrast Transformers to simple max- and\nsum-pooling - two strong baselines rarely reported. We propose to replace the\nsoftmax in self-attention with normalization, yielding a hyperparameter and\ndata-bias robust, generally applicable architecture. We support our insights\nwith empirical results from more than 25,000 trained models. All results and\nimplementations are made available.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 16:26:34 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Richter", "Oliver", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "2005.09572", "submitter": "Yitan Zhu", "authors": "Yitan Zhu, Thomas Brettin, Yvonne A. Evrard, Alexander Partin,\n  Fangfang Xia, Maulik Shukla, Hyunseung Yoo, James H. Doroshow, Rick Stevens", "title": "Ensemble Transfer Learning for the Prediction of Anti-Cancer Drug\n  Response", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning has been shown to be effective in many applications in\nwhich training data for the target problem are limited but data for a related\n(source) problem are abundant. In this paper, we apply transfer learning to the\nprediction of anti-cancer drug response. Previous transfer learning studies for\ndrug response prediction focused on building models that predict the response\nof tumor cells to a specific drug treatment. We target the more challenging\ntask of building general prediction models that can make predictions for both\nnew tumor cells and new drugs. We apply the classic transfer learning framework\nthat trains a prediction model on the source dataset and refines it on the\ntarget dataset, and extends the framework through ensemble. The ensemble\ntransfer learning pipeline is implemented using LightGBM and two deep neural\nnetwork (DNN) models with different architectures. Uniquely, we investigate its\npower for three application settings including drug repurposing, precision\noncology, and new drug development, through different data partition schemes in\ncross-validation. We test the proposed ensemble transfer learning on benchmark\nin vitro drug screening datasets, taking one dataset as the source domain and\nanother dataset as the target domain. The analysis results demonstrate the\nbenefit of applying ensemble transfer learning for predicting anti-cancer drug\nresponse in all three applications with both LightGBM and DNN models. Compared\nbetween the different prediction models, a DNN model with two subnetworks for\nthe inputs of tumor features and drug features separately outperforms LightGBM\nand the other DNN model that concatenates tumor features and drug features for\ninput in the drug repurposing and precision oncology applications. In the more\nchallenging application of new drug development, LightGBM performs better than\nthe other two DNN models.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 20:29:48 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Zhu", "Yitan", ""], ["Brettin", "Thomas", ""], ["Evrard", "Yvonne A.", ""], ["Partin", "Alexander", ""], ["Xia", "Fangfang", ""], ["Shukla", "Maulik", ""], ["Yoo", "Hyunseung", ""], ["Doroshow", "James H.", ""], ["Stevens", "Rick", ""]]}, {"id": "2005.09595", "submitter": "Min Jae Song", "authors": "Joan Bruna, Oded Regev, Min Jae Song, and Yi Tang", "title": "Continuous LWE", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a continuous analogue of the Learning with Errors (LWE) problem,\nwhich we name CLWE. We give a polynomial-time quantum reduction from worst-case\nlattice problems to CLWE, showing that CLWE enjoys similar hardness guarantees\nto those of LWE. Alternatively, our result can also be seen as opening new\navenues of (quantum) attacks on lattice problems. Our work resolves an open\nproblem regarding the computational complexity of learning mixtures of\nGaussians without separability assumptions (Diakonikolas 2016, Moitra 2018). As\nan additional motivation, (a slight variant of) CLWE was considered in the\ncontext of robust machine learning (Diakonikolas et al.~FOCS 2017), where\nhardness in the statistical query (SQ) model was shown; our work addresses the\nopen question regarding its computational hardness (Bubeck et al.~ICML 2019).\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 17:16:12 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 20:55:35 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Bruna", "Joan", ""], ["Regev", "Oded", ""], ["Song", "Min Jae", ""], ["Tang", "Yi", ""]]}, {"id": "2005.09609", "submitter": "Mohammad Majdi", "authors": "Mohammad S. Majdi, Khalil N. Salman, Michael F. Morris, Nirav C.\n  Merchant, Jeffrey J. Rodriguez", "title": "Deep learning classification of chest x-ray images", "comments": "4 pages, 4 figures, 2 tables, conference , SSIAI 2020", "journal-ref": "2020 IEEE SSIAI, Albuquerque, NM, USA, 2020, pp. 116-119", "doi": "10.1109/SSIAI49293.2020.9094612", "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep learning based method for classification of commonly\noccurring pathologies in chest X-ray images. The vast number of publicly\navailable chest X-ray images provides the data necessary for successfully\nemploying deep learning methodologies to reduce the misdiagnosis of thoracic\ndiseases. We applied our method to the classification of two example\npathologies, pulmonary nodules and cardiomegaly, and we compared the\nperformance of our method to three existing methods. The results show an\nimprovement in AUC for detection of nodules and cardiomegaly compared to the\nexisting methods.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 17:29:33 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 19:42:03 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Majdi", "Mohammad S.", ""], ["Salman", "Khalil N.", ""], ["Morris", "Michael F.", ""], ["Merchant", "Nirav C.", ""], ["Rodriguez", "Jeffrey J.", ""]]}, {"id": "2005.09619", "submitter": "Andrew Ilyas", "authors": "Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras,\n  Jacob Steinhardt, Aleksander Madry", "title": "Identifying Statistical Bias in Dataset Replication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dataset replication is a useful tool for assessing whether improvements in\ntest accuracy on a specific benchmark correspond to improvements in models'\nability to generalize reliably. In this work, we present unintuitive yet\nsignificant ways in which standard approaches to dataset replication introduce\nstatistical bias, skewing the resulting observations. We study ImageNet-v2, a\nreplication of the ImageNet dataset on which models exhibit a significant\n(11-14%) drop in accuracy, even after controlling for a standard\nhuman-in-the-loop measure of data quality. We show that after correcting for\nthe identified statistical bias, only an estimated $3.6\\% \\pm 1.5\\%$ of the\noriginal $11.7\\% \\pm 1.0\\%$ accuracy drop remains unaccounted for. We conclude\nwith concrete recommendations for recognizing and avoiding bias in dataset\nreplication. Code for our study is publicly available at\nhttp://github.com/MadryLab/dataset-replication-analysis .\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 17:48:32 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 06:38:04 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Engstrom", "Logan", ""], ["Ilyas", "Andrew", ""], ["Santurkar", "Shibani", ""], ["Tsipras", "Dimitris", ""], ["Steinhardt", "Jacob", ""], ["Madry", "Aleksander", ""]]}, {"id": "2005.09624", "submitter": "Yueh-Hua Wu", "authors": "Yueh-Hua Wu, I-Hau Yeh, David Hu, Hong-Yuan Mark Liao", "title": "Batch-Augmented Multi-Agent Reinforcement Learning for Efficient Traffic\n  Signal Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this work is to provide a viable solution based on reinforcement\nlearning for traffic signal control problems. Although the state-of-the-art\nreinforcement learning approaches have yielded great success in a variety of\ndomains, directly applying it to alleviate traffic congestion can be\nchallenging, considering the requirement of high sample efficiency and how\ntraining data is gathered. In this work, we address several challenges that we\nencountered when we attempted to mitigate serious traffic congestion occurring\nin a metropolitan area. Specifically, we are required to provide a solution\nthat is able to (1) handle the traffic signal control when certain surveillance\ncameras that retrieve information for reinforcement learning are down, (2)\nlearn from batch data without a traffic simulator, and (3) make control\ndecisions without shared information across intersections. We present a\ntwo-stage framework to deal with the above-mentioned situations. The framework\ncan be decomposed into an Evolution Strategies approach that gives a fixed-time\ntraffic signal control schedule and a multi-agent off-policy reinforcement\nlearning that is capable of learning from batch data with the aid of three\nproposed components, bounded action, batch augmentation, and surrogate reward\nclipping. Our experiments show that the proposed framework reduces traffic\ncongestion by 36% in terms of waiting time compared with the currently used\nfixed-time traffic signal plan. Furthermore, the framework requires only 600\nqueries to a simulator to achieve the result.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 17:53:05 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Wu", "Yueh-Hua", ""], ["Yeh", "I-Hau", ""], ["Hu", "David", ""], ["Liao", "Hong-Yuan Mark", ""]]}, {"id": "2005.09627", "submitter": "Stanley Chan", "authors": "Abhiram Gnansambandam, Stanley H. Chan", "title": "One Size Fits All: Can We Train One Denoiser for All Noise Levels?", "comments": "Published in the 37th International Conference on Machine Learning\n  (ICML) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When training an estimator such as a neural network for tasks like image\ndenoising, it is often preferred to train one estimator and apply it to all\nnoise levels. The de facto training protocol to achieve this goal is to train\nthe estimator with noisy samples whose noise levels are uniformly distributed\nacross the range of interest. However, why should we allocate the samples\nuniformly? Can we have more training samples that are less noisy, and fewer\nsamples that are more noisy? What is the optimal distribution? How do we obtain\nsuch a distribution? The goal of this paper is to address this training sample\ndistribution problem from a minimax risk optimization perspective. We derive a\ndual ascent algorithm to determine the optimal sampling distribution of which\nthe convergence is guaranteed as long as the set of admissible estimators is\nclosed and convex. For estimators with non-convex admissible sets such as deep\nneural networks, our dual formulation converges to a solution of the convex\nrelaxation. We discuss how the algorithm can be implemented in practice. We\nevaluate the algorithm on linear estimators and deep networks.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 17:56:04 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 02:45:03 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 20:25:19 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Gnansambandam", "Abhiram", ""], ["Chan", "Stanley H.", ""]]}, {"id": "2005.09629", "submitter": "Daniel Park", "authors": "Daniel S. Park, Yu Zhang, Ye Jia, Wei Han, Chung-Cheng Chiu, Bo Li,\n  Yonghui Wu and Quoc V. Le", "title": "Improved Noisy Student Training for Automatic Speech Recognition", "comments": "5 pages, 5 figures, 4 tables; v2: minor revisions, reference added", "journal-ref": "Proc. Interspeech 2020, 2817-2821", "doi": "10.21437/Interspeech.2020-1470", "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a semi-supervised learning method known as \"noisy student training\"\nhas been shown to improve image classification performance of deep networks\nsignificantly. Noisy student training is an iterative self-training method that\nleverages augmentation to improve network performance. In this work, we adapt\nand improve noisy student training for automatic speech recognition, employing\n(adaptive) SpecAugment as the augmentation method. We find effective methods to\nfilter, balance and augment the data generated in between self-training\niterations. By doing so, we are able to obtain word error rates (WERs)\n4.2%/8.6% on the clean/noisy LibriSpeech test sets by only using the clean 100h\nsubset of LibriSpeech as the supervised set and the rest (860h) as the\nunlabeled set. Furthermore, we are able to achieve WERs 1.7%/3.4% on the\nclean/noisy LibriSpeech test sets by using the unlab-60k subset of LibriLight\nas the unlabeled set for LibriSpeech 960h. We are thus able to improve upon the\nprevious state-of-the-art clean/noisy test WERs achieved on LibriSpeech 100h\n(4.74%/12.20%) and LibriSpeech (1.9%/4.1%).\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 17:57:29 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 23:26:24 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Park", "Daniel S.", ""], ["Zhang", "Yu", ""], ["Jia", "Ye", ""], ["Han", "Wei", ""], ["Chiu", "Chung-Cheng", ""], ["Li", "Bo", ""], ["Wu", "Yonghui", ""], ["Le", "Quoc V.", ""]]}, {"id": "2005.09634", "submitter": "Andrew Loeb", "authors": "George S. Baggs, Paul Guerrier, Andrew Loeb, Jason C. Jones", "title": "Automated Copper Alloy Grain Size Evaluation Using a Deep-learning CNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cond-mat.mtrl-sci cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moog Inc. has automated the evaluation of copper (Cu) alloy grain size using\na deep-learning convolutional neural network (CNN). The proof-of-concept\nautomated image acquisition and batch-wise image processing offers the\npotential for significantly reduced labor, improved accuracy of grain\nevaluation, and decreased overall turnaround times for approving Cu alloy bar\nstock for use in flight critical aircraft hardware. A classification accuracy\nof 91.1% on individual sub-images of the Cu alloy coupons was achieved. Process\ndevelopment included minimizing the variation in acquired image color,\nbrightness, and resolution to create a dataset with 12300 sub-images, and then\noptimizing the CNN hyperparameters on this dataset using statistical design of\nexperiments (DoE).\n  Over the development of the automated Cu alloy grain size evaluation, a\ndegree of \"explainability\" in the artificial intelligence (XAI) output was\nrealized, based on the decomposition of the large raw images into many smaller\ndataset sub-images, through the ability to explain the CNN ensemble image\noutput via inspection of the classification results from the individual smaller\nsub-images.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:13:38 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Baggs", "George S.", ""], ["Guerrier", "Paul", ""], ["Loeb", "Andrew", ""], ["Jones", "Jason C.", ""]]}, {"id": "2005.09635", "submitter": "Yujun Shen", "authors": "Yujun Shen, Ceyuan Yang, Xiaoou Tang, Bolei Zhou", "title": "InterFaceGAN: Interpreting the Disentangled Face Representation Learned\n  by GANs", "comments": "Accepted by TPAMI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Generative Adversarial Networks (GANs) have made significant\nprogress in face synthesis, there lacks enough understanding of what GANs have\nlearned in the latent representation to map a random code to a photo-realistic\nimage. In this work, we propose a framework called InterFaceGAN to interpret\nthe disentangled face representation learned by the state-of-the-art GAN models\nand study the properties of the facial semantics encoded in the latent space.\nWe first find that GANs learn various semantics in some linear subspaces of the\nlatent space. After identifying these subspaces, we can realistically\nmanipulate the corresponding facial attributes without retraining the model. We\nthen conduct a detailed study on the correlation between different semantics\nand manage to better disentangle them via subspace projection, resulting in\nmore precise control of the attribute manipulation. Besides manipulating the\ngender, age, expression, and presence of eyeglasses, we can even alter the face\npose and fix the artifacts accidentally made by GANs. Furthermore, we perform\nan in-depth face identity analysis and a layer-wise analysis to evaluate the\nediting results quantitatively. Finally, we apply our approach to real face\nediting by employing GAN inversion approaches and explicitly training\nfeed-forward models based on the synthetic data established by InterFaceGAN.\nExtensive experimental results suggest that learning to synthesize faces\nspontaneously brings a disentangled and controllable face representation.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 18:01:22 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 08:36:47 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Shen", "Yujun", ""], ["Yang", "Ceyuan", ""], ["Tang", "Xiaoou", ""], ["Zhou", "Bolei", ""]]}, {"id": "2005.09638", "submitter": "Teeratorn Kadeethum", "authors": "Teeratorn Kadeethum, Thomas M J{\\o}rgensen, Hamidreza M Nick", "title": "Physics-informed Neural Networks for Solving Inverse Problems of\n  Nonlinear Biot's Equations: Batch Training", "comments": "arXiv admin note: text overlap with arXiv:2002.08235", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In biomedical engineering, earthquake prediction, and underground energy\nharvesting, it is crucial to indirectly estimate the physical properties of\nporous media since the direct measurement of those are usually\nimpractical/prohibitive. Here we apply the physics-informed neural networks to\nsolve the inverse problem with regard to the nonlinear Biot's equations.\nSpecifically, we consider batch training and explore the effect of different\nbatch sizes. The results show that training with small batch sizes, i.e., a few\nexamples per batch, provides better approximations (lower percentage error) of\nthe physical parameters than using large batches or the full batch. The\nincreased accuracy of the physical parameters, comes at the cost of longer\ntraining time. Specifically, we find the size should not be too small since a\nvery small batch size requires a very long training time without a\ncorresponding improvement in estimation accuracy. We find that a batch size of\n8 or 32 is a good compromise, which is also robust to additive noise in the\ndata. The learning rate also plays an important role and should be used as a\nhyperparameter.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 18:48:53 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Kadeethum", "Teeratorn", ""], ["J\u00f8rgensen", "Thomas M", ""], ["Nick", "Hamidreza M", ""]]}, {"id": "2005.09669", "submitter": "Sinho Chewi", "authors": "Sinho Chewi, Thibaut Le Gouic, Chen Lu, Tyler Maunu, Philippe\n  Rigollet, Austin J. Stromme", "title": "Exponential ergodicity of mirror-Langevin diffusions", "comments": "27 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the problem of sampling from ill-conditioned log-concave\ndistributions, we give a clean non-asymptotic convergence analysis of\nmirror-Langevin diffusions as introduced in Zhang et al. (2020). As a special\ncase of this framework, we propose a class of diffusions called Newton-Langevin\ndiffusions and prove that they converge to stationarity exponentially fast with\na rate which not only is dimension-free, but also has no dependence on the\ntarget distribution. We give an application of this result to the problem of\nsampling from the uniform distribution on a convex body using a strategy\ninspired by interior-point methods. Our general approach follows the recent\ntrend of linking sampling and optimization and highlights the role of the\nchi-squared divergence. In particular, it yields new results on the convergence\nof the vanilla Langevin diffusion in Wasserstein distance.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 18:00:52 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 22:39:02 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Chewi", "Sinho", ""], ["Gouic", "Thibaut Le", ""], ["Lu", "Chen", ""], ["Maunu", "Tyler", ""], ["Rigollet", "Philippe", ""], ["Stromme", "Austin J.", ""]]}, {"id": "2005.09683", "submitter": "Steffen Rendle", "authors": "Steffen Rendle, Walid Krichene, Li Zhang, John Anderson", "title": "Neural Collaborative Filtering vs. Matrix Factorization Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding based models have been the state of the art in collaborative\nfiltering for over a decade. Traditionally, the dot product or higher order\nequivalents have been used to combine two or more embeddings, e.g., most\nnotably in matrix factorization. In recent years, it was suggested to replace\nthe dot product with a learned similarity e.g. using a multilayer perceptron\n(MLP). This approach is often referred to as neural collaborative filtering\n(NCF). In this work, we revisit the experiments of the NCF paper that\npopularized learned similarities using MLPs. First, we show that with a proper\nhyperparameter selection, a simple dot product substantially outperforms the\nproposed learned similarities. Second, while a MLP can in theory approximate\nany function, we show that it is non-trivial to learn a dot product with an\nMLP. Finally, we discuss practical issues that arise when applying MLP based\nsimilarities and show that MLPs are too costly to use for item recommendation\nin production environments while dot products allow to apply very efficient\nretrieval algorithms. We conclude that MLPs should be used with care as\nembedding combiner and that dot products might be a better default choice.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 18:07:08 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 23:21:33 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Rendle", "Steffen", ""], ["Krichene", "Walid", ""], ["Zhang", "Li", ""], ["Anderson", "John", ""]]}, {"id": "2005.09687", "submitter": "Jesse Livezey", "authors": "Jesse A. Livezey and Joshua I. Glaser", "title": "Deep learning approaches for neural decoding: from CNNs to LSTMs and\n  spikes to fMRI", "comments": "22 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decoding behavior, perception, or cognitive state directly from neural\nsignals has applications in brain-computer interface research as well as\nimplications for systems neuroscience. In the last decade, deep learning has\nbecome the state-of-the-art method in many machine learning tasks ranging from\nspeech recognition to image segmentation. The success of deep networks in other\ndomains has led to a new wave of applications in neuroscience. In this article,\nwe review deep learning approaches to neural decoding. We describe the\narchitectures used for extracting useful features from neural recording\nmodalities ranging from spikes to EEG. Furthermore, we explore how deep\nlearning has been leveraged to predict common outputs including movement,\nspeech, and vision, with a focus on how pretrained deep networks can be\nincorporated as priors for complex decoding targets like acoustic speech or\nimages. Deep learning has been shown to be a useful tool for improving the\naccuracy and flexibility of neural decoding across a wide range of tasks, and\nwe point out areas for future scientific development.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 18:10:35 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Livezey", "Jesse A.", ""], ["Glaser", "Joshua I.", ""]]}, {"id": "2005.09727", "submitter": "Mohammad Ebrahimpour", "authors": "Mohammad K. Ebrahimpour, Jiayun Li, Yen-Yun Yu, Jackson L. Reese,\n  Azadeh Moghtaderi, Ming-Hsuan Yang, David C. Noelle", "title": "Ventral-Dorsal Neural Networks: Object Detection via Selective Attention", "comments": "in Proceedings of WACV. arXiv admin note: substantial text overlap\n  with arXiv:2005.07787", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Convolutional Neural Networks (CNNs) have been repeatedly proven to\nperform well on image classification tasks. Object detection methods, however,\nare still in need of significant improvements. In this paper, we propose a new\nframework called Ventral-Dorsal Networks (VDNets) which is inspired by the\nstructure of the human visual system. Roughly, the visual input signal is\nanalyzed along two separate neural streams, one in the temporal lobe and the\nother in the parietal lobe. The coarse functional distinction between these\nstreams is between object recognition -- the \"what\" of the signal -- and\nextracting location related information -- the \"where\" of the signal. The\nventral pathway from primary visual cortex, entering the temporal lobe, is\ndominated by \"what\" information, while the dorsal pathway, into the parietal\nlobe, is dominated by \"where\" information. Inspired by this structure, we\npropose the integration of a \"Ventral Network\" and a \"Dorsal Network\", which\nare complementary. Information about object identity can guide localization,\nand location information can guide attention to relevant image regions,\nimproving object recognition. This new dual network framework sharpens the\nfocus of object detection. Our experimental results reveal that the proposed\nmethod outperforms state-of-the-art object detection approaches on PASCAL VOC\n2007 by 8% (mAP) and PASCAL VOC 2012 by 3% (mAP). Moreover, a comparison of\ntechniques on Yearbook images displays substantial qualitative and quantitative\nbenefits of VDNet.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 23:57:36 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Ebrahimpour", "Mohammad K.", ""], ["Li", "Jiayun", ""], ["Yu", "Yen-Yun", ""], ["Reese", "Jackson L.", ""], ["Moghtaderi", "Azadeh", ""], ["Yang", "Ming-Hsuan", ""], ["Noelle", "David C.", ""]]}, {"id": "2005.09747", "submitter": "Rishikesh Ranade", "authors": "Rishikesh Ranade, Genong Li, Shaoping Li, Tarek Echekki", "title": "An Efficient Machine-Learning Approach for PDF Tabulation in Turbulent\n  Combustion Closure", "comments": null, "journal-ref": "Combustion Science and Technology, 1-20 (2019)", "doi": "10.1080/00102202.2019.1686702", "report-no": null, "categories": "cs.CE cs.LG physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probability density function (PDF) based turbulent combustion modelling is\nlimited by the need to store multi-dimensional PDF tables that can take up\nlarge amounts of memory. A significant saving in storage can be achieved by\nusing various machine-learning techniques that represent the thermo-chemical\nquantities of a PDF table using mathematical functions. These functions can be\ncomputationally more expensive than the existing interpolation methods used for\nthermo-chemical quantities. More importantly, the training time can amount to a\nconsiderable portion of the simulation time. In this work, we address these\nissues by introducing an adaptive training algorithm that relies on multi-layer\nperception (MLP) neural networks for regression and self-organizing maps (SOMs)\nfor clustering data to tabulate using different networks. The algorithm is\ndesigned to address both the multi-dimensionality of the PDF table as well as\nthe computational efficiency of the proposed algorithm. SOM clustering divides\nthe PDF table into several parts based on similarities in data. Each cluster of\ndata is trained using an MLP algorithm on simple network architectures to\ngenerate local functions for thermo-chemical quantities. The algorithm is\nvalidated for the so-called DLR-A turbulent jet diffusion flame using both RANS\nand LES simulations and the results of the PDF tabulation are compared to the\nstandard linear interpolation method. The comparison yields a very good\nagreement between the two tabulation techniques and establishes the MLP-SOM\napproach as a viable method for PDF tabulation.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 00:13:55 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Ranade", "Rishikesh", ""], ["Li", "Genong", ""], ["Li", "Shaoping", ""], ["Echekki", "Tarek", ""]]}, {"id": "2005.09752", "submitter": "Charu Sharma", "authors": "Charu Sharma, Jatin Chauhan, Manohar Kaul", "title": "Learning Representations using Spectral-Biased Random Walks on Graphs", "comments": "Accepted at IJCNN 2020: International Joint Conference on Neural\n  Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several state-of-the-art neural graph embedding methods are based on short\nrandom walks (stochastic processes) because of their ease of computation,\nsimplicity in capturing complex local graph properties, scalability, and\ninterpretibility. In this work, we are interested in studying how much a\nprobabilistic bias in this stochastic process affects the quality of the nodes\npicked by the process. In particular, our biased walk, with a certain\nprobability, favors movement towards nodes whose neighborhoods bear a\nstructural resemblance to the current node's neighborhood. We succinctly\ncapture this neighborhood as a probability measure based on the spectrum of the\nnode's neighborhood subgraph represented as a normalized laplacian matrix. We\npropose the use of a paragraph vector model with a novel Wasserstein\nregularization term. We empirically evaluate our approach against several\nstate-of-the-art node embedding techniques on a wide variety of real-world\ndatasets and demonstrate that our proposed method significantly improves upon\nexisting methods on both link prediction and node classification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 20:42:43 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 15:12:32 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Sharma", "Charu", ""], ["Chauhan", "Jatin", ""], ["Kaul", "Manohar", ""]]}, {"id": "2005.09756", "submitter": "Cal Peyser", "authors": "Cal Peyser, Tara N. Sainath, Golan Pundak", "title": "Improving Proper Noun Recognition in End-to-End ASR By Customization of\n  the MWER Loss Criterion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Proper nouns present a challenge for end-to-end (E2E) automatic speech\nrecognition (ASR) systems in that a particular name may appear only rarely\nduring training, and may have a pronunciation similar to that of a more common\nword. Unlike conventional ASR models, E2E systems lack an explicit\npronounciation model that can be specifically trained with proper noun\npronounciations and a language model that can be trained on a large text-only\ncorpus. Past work has addressed this issue by incorporating additional training\ndata or additional models. In this paper, we instead build on recent advances\nin minimum word error rate (MWER) training to develop two new loss criteria\nthat specifically emphasize proper noun recognition. Unlike past work on this\nproblem, this method requires no new data during training or external models\nduring inference. We see improvements ranging from 2% to 7% relative on several\nrelevant benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 21:10:50 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Peyser", "Cal", ""], ["Sainath", "Tara N.", ""], ["Pundak", "Golan", ""]]}, {"id": "2005.09766", "submitter": "Dufan Wu", "authors": "Dufan Wu, Hui Ren, Quanzheng Li", "title": "Self-supervised Dynamic CT Perfusion Image Denoising with Deep Neural\n  Networks", "comments": "13 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dynamic computed tomography perfusion (CTP) imaging is a promising approach\nfor acute ischemic stroke diagnosis and evaluation. Hemodynamic parametric maps\nof cerebral parenchyma are calculated from repeated CT scans of the first pass\nof iodinated contrast through the brain. It is necessary to reduce the dose of\nCTP for routine applications due to the high radiation exposure from the\nrepeated scans, where image denoising is necessary to achieve a reliable\ndiagnosis. In this paper, we proposed a self-supervised deep learning method\nfor CTP denoising, which did not require any high-dose reference images for\ntraining. The network was trained by mapping each frame of CTP to an estimation\nfrom its adjacent frames. Because the noise in the source and target was\nindependent, this approach could effectively remove the noise. Being free from\nhigh-dose training images granted the proposed method easier adaptation to\ndifferent scanning protocols. The method was validated on both simulation and a\npublic real dataset. The proposed method achieved improved image quality\ncompared to conventional denoising methods. On the real data, the proposed\nmethod also had improved spatial resolution and contrast-to-noise ratio\ncompared to supervised learning which was trained on the simulation data\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 21:44:07 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Wu", "Dufan", ""], ["Ren", "Hui", ""], ["Li", "Quanzheng", ""]]}, {"id": "2005.09787", "submitter": "Justin Doak", "authors": "Justin E. Doak, Michael R. Smith, Joey B. Ingram", "title": "Self-Updating Models with Error Remediation", "comments": "17 pages, 13 figures, published in the proceedings of the Artificial\n  Intelligence and Machine Learning for Multi-Domain Operations Applications II\n  conference in the SPIE Defense + Commercial Sensing, 2020 symposium", "journal-ref": "Proc. SPIE 11413, Artificial Intelligence and Machine Learning for\n  Multi-Domain Operations Applications II, 114131W (18 May 2020)", "doi": "10.1117/12.2563843", "report-no": "SAND No: SAND2020-5113 C", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many environments currently employ machine learning models for data\nprocessing and analytics that were built using a limited number of training\ndata points. Once deployed, the models are exposed to significant amounts of\npreviously-unseen data, not all of which is representative of the original,\nlimited training data. However, updating these deployed models can be difficult\ndue to logistical, bandwidth, time, hardware, and/or data sensitivity\nconstraints. We propose a framework, Self-Updating Models with Error\nRemediation (SUMER), in which a deployed model updates itself as new data\nbecomes available. SUMER uses techniques from semi-supervised learning and\nnoise remediation to iteratively retrain a deployed model using\nintelligently-chosen predictions from the model as the labels for new training\niterations. A key component of SUMER is the notion of error remediation as\nself-labeled data can be susceptible to the propagation of errors. We\ninvestigate the use of SUMER across various data sets and iterations. We find\nthat self-updating models (SUMs) generally perform better than models that do\nnot attempt to self-update when presented with additional previously-unseen\ndata. This performance gap is accentuated in cases where there is only limited\namounts of initial training data. We also find that the performance of SUMER is\ngenerally better than the performance of SUMs, demonstrating a benefit in\napplying error remediation. Consequently, SUMER can autonomously enhance the\noperational capabilities of existing data processing systems by intelligently\nupdating models in dynamic environments.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 23:09:38 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Doak", "Justin E.", ""], ["Smith", "Michael R.", ""], ["Ingram", "Joey B.", ""]]}, {"id": "2005.09801", "submitter": "Dehong Gao", "authors": "Dehong Gao, Linbo Jin, Ben Chen, Minghui Qiu, Peng Li, Yi Wei, Yi Hu\n  and Hao Wang", "title": "FashionBERT: Text and Image Matching with Adaptive Loss for Cross-modal\n  Retrieval", "comments": "10 pages, to be published in SIGIR20 Industry Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the text and image matching in cross-modal\nretrieval of the fashion industry. Different from the matching in the general\ndomain, the fashion matching is required to pay much more attention to the\nfine-grained information in the fashion images and texts. Pioneer approaches\ndetect the region of interests (i.e., RoIs) from images and use the RoI\nembeddings as image representations. In general, RoIs tend to represent the\n\"object-level\" information in the fashion images, while fashion texts are prone\nto describe more detailed information, e.g. styles, attributes. RoIs are thus\nnot fine-grained enough for fashion text and image matching. To this end, we\npropose FashionBERT, which leverages patches as image features. With the\npre-trained BERT model as the backbone network, FashionBERT learns high level\nrepresentations of texts and images. Meanwhile, we propose an adaptive loss to\ntrade off multitask learning in the FashionBERT modeling. Two tasks (i.e., text\nand image matching and cross-modal retrieval) are incorporated to evaluate\nFashionBERT. On the public dataset, experiments demonstrate FashionBERT\nachieves significant improvements in performances than the baseline and\nstate-of-the-art approaches. In practice, FashionBERT is applied in a concrete\ncross-modal retrieval application. We provide the detailed matching performance\nand inference efficiency analysis.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 00:41:00 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 05:56:10 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Gao", "Dehong", ""], ["Jin", "Linbo", ""], ["Chen", "Ben", ""], ["Qiu", "Minghui", ""], ["Li", "Peng", ""], ["Wei", "Yi", ""], ["Hu", "Yi", ""], ["Wang", "Hao", ""]]}, {"id": "2005.09807", "submitter": "Mansura Habiba Miss", "authors": "Mansura Habiba, Barak A. Pearlmutter", "title": "Neural Ordinary Differential Equation based Recurrent Neural Network\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural differential equations are a promising new member in the neural\nnetwork family. They show the potential of differential equations for time\nseries data analysis. In this paper, the strength of the ordinary differential\nequation (ODE) is explored with a new extension. The main goal of this work is\nto answer the following questions: (i)~can ODE be used to redefine the existing\nneural network model? (ii)~can Neural ODEs solve the irregular sampling rate\nchallenge of existing neural network models for a continuous time series, i.e.,\nlength and dynamic nature, (iii)~how to reduce the training and evaluation time\nof existing Neural ODE systems? This work leverages the mathematical foundation\nof ODEs to redesign traditional RNNs such as Long Short-Term Memory (LSTM) and\nGated Recurrent Unit (GRU). The main contribution of this paper is to\nillustrate the design of two new ODE-based RNN models (GRU-ODE model and\nLSTM-ODE) which can compute the hidden state and cell state at any point of\ntime using an ODE solver. These models reduce the computation overhead of\nhidden state and cell state by a vast amount. The performance evaluation of\nthese two new models for learning continuous time series with irregular\nsampling rate is then demonstrated. Experiments show that these new ODE based\nRNN models require less training time than Latent ODEs and conventional Neural\nODEs. They can achieve higher accuracy quickly, and the design of the neural\nnetwork is simpler than, previous neural ODE systems.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 01:02:29 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Habiba", "Mansura", ""], ["Pearlmutter", "Barak A.", ""]]}, {"id": "2005.09810", "submitter": "Kimon Fountoulakis", "authors": "Kimon Fountoulakis, Di Wang, Shenghao Yang", "title": "$p$-Norm Flow Diffusion for Local Graph Clustering", "comments": "28 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local graph clustering and the closely related seed set expansion problem are\nprimitives on graphs that are central to a wide range of analytic and learning\ntasks such as local clustering, community detection, nodes ranking and feature\ninference. Prior work on local graph clustering mostly falls into two\ncategories with numerical and combinatorial roots respectively. In this work,\nwe draw inspiration from both fields and propose a family of convex\noptimization formulations based on the idea of diffusion with p-norm network\nflow for $p\\in (1,\\infty)$. In the context of local clustering, we characterize\nthe optimal solutions for these optimization problems and show their usefulness\nin finding low conductance cuts around input seed set. In particular, we\nachieve quadratic approximation of conductance in the case of $p=2$ similar to\nthe Cheeger-type bounds of spectral methods, constant factor approximation when\n$p\\rightarrow\\infty$ similar to max-flow based methods, and a smooth transition\nfor general $p$ values in between. Thus, our optimization formulation can be\nviewed as bridging the numerical and combinatorial approaches, and we can\nachieve the best of both worlds in terms of speed and noise robustness. We show\nthat the proposed problem can be solved in strongly local running time for\n$p\\ge 2$ and conduct empirical evaluations on both synthetic and real-world\ngraphs to illustrate our approach compares favorably with existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 01:08:17 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 05:53:06 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 09:09:08 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Fountoulakis", "Kimon", ""], ["Wang", "Di", ""], ["Yang", "Shenghao", ""]]}, {"id": "2005.09814", "submitter": "Manan Tomar Mr.", "authors": "Manan Tomar, Lior Shani, Yonathan Efroni, Mohammad Ghavamzadeh", "title": "Mirror Descent Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mirror descent (MD), a well-known first-order method in constrained convex\noptimization, has recently been shown as an important tool to analyze\ntrust-region algorithms in reinforcement learning (RL). However, there remains\na considerable gap between such theoretically analyzed algorithms and the ones\nused in practice. Inspired by this, we propose an efficient RL algorithm,\ncalled {\\em mirror descent policy optimization} (MDPO). MDPO iteratively\nupdates the policy by {\\em approximately} solving a trust-region problem, whose\nobjective function consists of two terms: a linearization of the standard RL\nobjective and a proximity term that restricts two consecutive policies to be\nclose to each other. Each update performs this approximation by taking multiple\ngradient steps on this objective function. We derive {\\em on-policy} and {\\em\noff-policy} variants of MDPO, while emphasizing important design choices\nmotivated by the existing theory of MD in RL. We highlight the connections\nbetween on-policy MDPO and two popular trust-region RL algorithms: TRPO and\nPPO, and show that explicitly enforcing the trust-region constraint is in fact\n{\\em not} a necessity for high performance gains in TRPO. We then show how the\npopular soft actor-critic (SAC) algorithm can be derived by slight\nmodifications of off-policy MDPO. Overall, MDPO is derived from the MD\nprinciples, offers a unified approach to viewing a number of popular RL\nalgorithms, and performs better than or on-par with TRPO, PPO, and SAC in a\nnumber of continuous control tasks. Code is available at\n\\url{https://github.com/manantomar/Mirror-Descent-Policy-Optimization}.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 01:30:43 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 23:50:29 GMT"}, {"version": "v3", "created": "Sat, 31 Oct 2020 14:37:24 GMT"}, {"version": "v4", "created": "Fri, 19 Feb 2021 10:05:24 GMT"}, {"version": "v5", "created": "Mon, 7 Jun 2021 13:44:15 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Tomar", "Manan", ""], ["Shani", "Lior", ""], ["Efroni", "Yonathan", ""], ["Ghavamzadeh", "Mohammad", ""]]}, {"id": "2005.09834", "submitter": "Vikram Ramanarayanan", "authors": "Vikram Ramanarayanan and Matthew Mulholland and Debanjan Ghosh", "title": "Exploring Recurrent, Memory and Attention Based Architectures for\n  Scoring Interactional Aspects of Human-Machine Text Dialog", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important step towards enabling English language learners to improve their\nconversational speaking proficiency involves automated scoring of multiple\naspects of interactional competence and subsequent targeted feedback. This\npaper builds on previous work in this direction to investigate multiple neural\narchitectures -- recurrent, attention and memory based -- along with\nfeature-engineered models for the automated scoring of interactional and topic\ndevelopment aspects of text dialog data. We conducted experiments on a\nconversational database of text dialogs from human learners interacting with a\ncloud-based dialog system, which were triple-scored along multiple dimensions\nof conversational proficiency. We find that fusion of multiple architectures\nperforms competently on our automated scoring task relative to expert\ninter-rater agreements, with (i) hand-engineered features passed to a support\nvector learner and (ii) transformer-based architectures contributing most\nprominently to the fusion.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 03:23:00 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Ramanarayanan", "Vikram", ""], ["Mulholland", "Matthew", ""], ["Ghosh", "Debanjan", ""]]}, {"id": "2005.09841", "submitter": "Tom\\'a\\v{s} Koc\\'ak", "authors": "Tom\\'a\\v{s} Koc\\'ak, Aur\\'elien Garivier", "title": "Best Arm Identification in Spectral Bandits", "comments": "To be published in International Joint Conference on Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study best-arm identification with fixed confidence in bandit models with\ngraph smoothness constraint. We provide and analyze an efficient gradient\nascent algorithm to compute the sample complexity of this problem as a solution\nof a non-smooth max-min problem (providing in passing a simplified analysis for\nthe unconstrained case). Building on this algorithm, we propose an\nasymptotically optimal strategy. We furthermore illustrate by numerical\nexperiments both the strategy's efficiency and the impact of the smoothness\nconstraint on the sample complexity. Best Arm Identification (BAI) is an\nimportant challenge in many applications ranging from parameter tuning to\nclinical trials. It is now very well understood in vanilla bandit models, but\nreal-world problems typically involve some dependency between arms that\nrequires more involved models. Assuming a graph structure on the arms is an\nelegant practical way to encompass this phenomenon, but this had been done so\nfar only for regret minimization. Addressing BAI with graph constraints\ninvolves delicate optimization problems for which the present paper offers a\nsolution.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 04:12:04 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Koc\u00e1k", "Tom\u00e1\u0161", ""], ["Garivier", "Aur\u00e9lien", ""]]}, {"id": "2005.09856", "submitter": "Zixiao Shen", "authors": "Zixiao Shen, Xin Chen, Jonathan M. Garibaldi", "title": "A Novel Meta Learning Framework for Feature Selection using Data\n  Synthesis and Fuzzy Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel meta learning framework for feature selection\n(FS) based on fuzzy similarity. The proposed method aims to recommend the best\nFS method from four candidate FS methods for any given dataset. This is\nachieved by firstly constructing a large training data repository using data\nsynthesis. Six meta features that represent the characteristics of the training\ndataset are then extracted. The best FS method for each of the training\ndatasets is used as the meta label. Both the meta features and the\ncorresponding meta labels are subsequently used to train a classification model\nusing a fuzzy similarity measure based framework. Finally the trained model is\nused to recommend the most suitable FS method for a given unseen dataset. This\nproposed method was evaluated based on eight public datasets of real-world\napplications. It successfully recommended the best method for five datasets and\nthe second best method for one dataset, which outperformed any of the four\nindividual FS methods. Besides, the proposed method is computationally\nefficient for algorithm selection, leading to negligible additional time for\nthe feature selection process. Thus, the paper contributes a novel method for\neffectively recommending which feature selection method to use for any new\ngiven dataset.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 06:03:41 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 03:41:56 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Shen", "Zixiao", ""], ["Chen", "Xin", ""], ["Garibaldi", "Jonathan M.", ""]]}, {"id": "2005.09863", "submitter": "Chang Zhou", "authors": "Zhen Yang, Ming Ding, Chang Zhou, Hongxia Yang, Jingren Zhou and Jie\n  Tang", "title": "Understanding Negative Sampling in Graph Representation Learning", "comments": "KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning has been extensively studied in recent years.\nDespite its potential in generating continuous embeddings for various networks,\nboth the effectiveness and efficiency to infer high-quality representations\ntoward large corpus of nodes are still challenging. Sampling is a critical\npoint to achieve the performance goals. Prior arts usually focus on sampling\npositive node pairs, while the strategy for negative sampling is left\ninsufficiently explored. To bridge the gap, we systematically analyze the role\nof negative sampling from the perspectives of both objective and risk,\ntheoretically demonstrating that negative sampling is as important as positive\nsampling in determining the optimization objective and the resulted variance.\nTo the best of our knowledge, we are the first to derive the theory and\nquantify that the negative sampling distribution should be positively but\nsub-linearly correlated to their positive sampling distribution. With the\nguidance of the theory, we propose MCNS, approximating the positive\ndistribution with self-contrast approximation and accelerating negative\nsampling by Metropolis-Hastings. We evaluate our method on 5 datasets that\ncover extensive downstream graph learning tasks, including link prediction,\nnode classification and personalized recommendation, on a total of 19\nexperimental settings. These relatively comprehensive experimental results\ndemonstrate its robustness and superiorities.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 06:25:21 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 04:10:30 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Yang", "Zhen", ""], ["Ding", "Ming", ""], ["Zhou", "Chang", ""], ["Yang", "Hongxia", ""], ["Zhou", "Jingren", ""], ["Tang", "Jie", ""]]}, {"id": "2005.09867", "submitter": "Kim Phuc Tran", "authors": "Zhenglei He (GEMTEX), Kim Phuc Tran (GEMTEX), S\\'ebastien Thomassey\n  (GEMTEX), Xianyi Zeng (GEMTEX), Changhai Yi", "title": "A reinforcement learning based decision support system in textile\n  manufacturing process", "comments": null, "journal-ref": "15th International Conference on Intelligent Systems and Knowledge\n  Engineering (ISKE2020), Aug 2020, Cologne, Germany", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduced a reinforcement learning based decision support system\nin textile manufacturing process. A solution optimization problem of color\nfading ozonation is discussed and set up as a Markov Decision Process (MDP) in\nterms of tuple {S, A, P, R}. Q-learning is used to train an agent in the\ninteraction with the setup environment by accumulating the reward R. According\nto the application result, it is found that the proposed MDP model has well\nexpressed the optimization problem of textile manufacturing process discussed\nin this paper, therefore the use of reinforcement learning to support decision\nmaking in this sector is conducted and proven that is applicable with promising\nprospects.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 06:33:47 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["He", "Zhenglei", "", "GEMTEX"], ["Tran", "Kim Phuc", "", "GEMTEX"], ["Thomassey", "S\u00e9bastien", "", "GEMTEX"], ["Zeng", "Xianyi", "", "GEMTEX"], ["Yi", "Changhai", ""]]}, {"id": "2005.09874", "submitter": "Weizun Zhao", "authors": "Weizun Zhao (1), Lishuai Li (1), Sameer Alam (2), Yanjun Wang (3 and\n  4) ((1) Department of Systems Engineering and Engineering Management, City\n  University of Hong Kong, (2) School of Mechanical & Aerospace Engineering,\n  Nanyang Technological University, (3) College of Civil Aviation, Nanjing\n  University of Aeronautics and Astronautics, (4) Department of Aeronautics and\n  Astronautics, Massachusetts Institute of Technology)", "title": "An Incremental Clustering Method for Anomaly Detection in Flight Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety is a top priority for civil aviation. Data mining in digital Flight\nData Recorder (FDR) or Quick Access Recorder (QAR) data, commonly referred as\nblack box data on aircraft, has gained interest from researchers, airlines, and\naviation regulation agencies for safety management. New anomaly detection\nmethods based on supervised or unsupervised learning have been developed to\nmonitor pilot operations and detect any risks from onboard digital flight data\nrecorder data. However, all existing anomaly detection methods are offline\nlearning - the models are trained once using historical data and used for all\nfuture predictions. In practice, new QAR data are generated by every flight and\ncollected by airlines whenever a datalink is available. Offline methods cannot\nrespond to new data in time. Though these offline models can be updated by\nbeing re-trained after adding new data to the original training set, it is\ntime-consuming and computational costly to train a new model every time new\ndata come in. To address this problem, we propose a novel incremental anomaly\ndetection method to identify common patterns and detect outliers in flight\noperations from FDR data. The proposed method is based on Gaussian Mixture\nModel (GMM). An initial GMM cluster model is trained on historical offline\ndata. Then, it continuously adapts to new incoming data points via an\nexpectation-maximization (EM) algorithm. To track changes in flight operation\npatterns, only model parameters need to be saved, not the raw flight data. The\nproposed method was tested on two sets of simulation data. Comparable results\nwere found from the proposed online method and a classic offline model. A\nreal-world application of the proposed method is demonstrated using FDR data\nfrom daily operations of an airline. Results are presented and future\nchallenges of using online learning scheme for flight data analytics are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 06:58:25 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 02:18:12 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 10:30:28 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Zhao", "Weizun", "", "3 and\n  4"], ["Li", "Lishuai", "", "3 and\n  4"], ["Alam", "Sameer", "", "3 and\n  4"], ["Wang", "Yanjun", "", "3 and\n  4"]]}, {"id": "2005.09876", "submitter": "Matt Wand", "authors": "L. Maestrini and M.P. Wand", "title": "The Inverse G-Wishart Distribution and Variational Message Passing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message passing on a factor graph is a powerful paradigm for the coding of\napproximate inference algorithms for arbitrarily graphical large models. The\nnotion of a factor graph fragment allows for compartmentalization of algebra\nand computer code. We show that the Inverse G-Wishart family of distributions\nenables fundamental variational message passing factor graph fragments to be\nexpressed elegantly and succinctly. Such fragments arise in models for which\napproximate inference concerning covariance matrix or variance parameters is\nmade, and are ubiquitous in contemporary statistics and machine learning.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 06:59:48 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 06:57:56 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 06:35:47 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Maestrini", "L.", ""], ["Wand", "M. P.", ""]]}, {"id": "2005.09900", "submitter": "Deepak P", "authors": "Deepak P and Savitha Sam Abraham", "title": "Fair Outlier Detection", "comments": "In Proceedings of The 21th International Conference on Web\n  Information Systems Engineering (WISE 2020), Amsterdam and Leiden, The\n  Netherlands", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An outlier detection method may be considered fair over specified sensitive\nattributes if the results of outlier detection are not skewed towards\nparticular groups defined on such sensitive attributes. In this task, we\nconsider, for the first time to our best knowledge, the task of fair outlier\ndetection. In this work, we consider the task of fair outlier detection over\nmultiple multi-valued sensitive attributes (e.g., gender, race, religion,\nnationality, marital status etc.). We propose a fair outlier detection method,\nFairLOF, that is inspired by the popular LOF formulation for neighborhood-based\noutlier detection. We outline ways in which unfairness could be induced within\nLOF and develop three heuristic principles to enhance fairness, which form the\nbasis of the FairLOF method. Being a novel task, we develop an evaluation\nframework for fair outlier detection, and use that to benchmark FairLOF on\nquality and fairness of results. Through an extensive empirical evaluation over\nreal-world datasets, we illustrate that FairLOF is able to achieve significant\nimprovements in fairness at sometimes marginal degradations on result quality\nas measured against the fairness-agnostic LOF method.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 08:02:41 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 20:18:41 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["P", "Deepak", ""], ["Abraham", "Savitha Sam", ""]]}, {"id": "2005.09902", "submitter": "Harold Kiossou", "authors": "Nicolas Golenvaux, Pablo Gonzalez Alvarez, Harold Silv\\`ere Kiossou,\n  Pierre Schaus", "title": "An LSTM approach to Forecast Migration using Google Trends", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to model and forecast international migration as precisely as\npossible is crucial for policymaking. Recently Google Trends data in addition\nto other economic and demographic data have been shown to improve the\nforecasting quality of a gravity linear model for the one-year ahead\nforecasting. In this work, we replace the linear model with a long short-term\nmemory (LSTM) approach and compare it with two existing approaches: the linear\ngravity model and an artificial neural network (ANN) model. Our LSTM approach\ncombined with Google Trends data outperforms both these models on various\nmetrics in the task of forecasting the one-year ahead incoming international\nmigration to 35 Organization for Economic Co-operation and Development (OECD)\ncountries: for example the root mean square error (RMSE) and the mean average\nerror (MAE) have been divided by 5 and 4 on the test set. This positive result\ndemonstrates that machine learning techniques constitute a serious alternative\nover traditional approaches for studying migration mechanisms.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 08:07:42 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 13:54:24 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Golenvaux", "Nicolas", ""], ["Alvarez", "Pablo Gonzalez", ""], ["Kiossou", "Harold Silv\u00e8re", ""], ["Schaus", "Pierre", ""]]}, {"id": "2005.09903", "submitter": "Natalia Shepeleva", "authors": "Natalia Shepeleva, Werner Zellinger, Michal Lewandowski and Bernhard\n  Moser", "title": "ReLU Code Space: A Basis for Rating Network Quality Besides Accuracy", "comments": "in ICLR 2020 Workshop on Neural Architecture Search (NAS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new metric space of ReLU activation codes equipped with a\ntruncated Hamming distance which establishes an isometry between its elements\nand polyhedral bodies in the input space which have recently been shown to be\nstrongly related to safety, robustness, and confidence. This isometry allows\nthe efficient computation of adjacency relations between the polyhedral bodies.\nExperiments on MNIST and CIFAR-10 indicate that information besides accuracy\nmight be stored in the code space.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 08:10:28 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Shepeleva", "Natalia", ""], ["Zellinger", "Werner", ""], ["Lewandowski", "Michal", ""], ["Moser", "Bernhard", ""]]}, {"id": "2005.09904", "submitter": "Yongkweon Jeon", "authors": "Yongkweon Jeon, Baeseong Park, Se Jung Kwon, Byeongwook Kim, Jeongin\n  Yun, and Dongsoo Lee", "title": "BiQGEMM: Matrix Multiplication with Lookup Table For Binary-Coding-based\n  Quantized DNNs", "comments": "13 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of parameters in deep neural networks (DNNs) is rapidly increasing\nto support complicated tasks and to improve model accuracy. Correspondingly,\nthe amount of computations and required memory footprint increase as well.\nQuantization is an efficient method to address such concerns by compressing\nDNNs such that computations can be simplified while required storage footprint\nis significantly reduced. Unfortunately, commercial CPUs and GPUs do not fully\nsupport quantization because only fixed data transfers (such as 32 bits) are\nallowed. As a result, even if weights are quantized into a few bits, CPUs and\nGPUs cannot access multiple quantized weights without memory bandwidth waste.\nSuccess of quantization in practice, hence, relies on an efficient computation\nengine design, especially for matrix multiplication that is a basic computation\nengine in most DNNs. In this paper, we propose a novel matrix multiplication\nmethod, called BiQGEMM, dedicated to quantized DNNs. BiQGEMM can access\nmultiple quantized weights simultaneously in one instruction. In addition,\nBiQGEMM pre-computes intermediate results that are highly redundant when\nquantization leads to limited available computation space. Since pre-computed\nvalues are stored in lookup tables and reused, BiQGEMM achieves lower amount of\noverall computations. Our extensive experimental results show that BiQGEMM\npresents higher performance than conventional schemes when DNNs are quantized.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 08:15:33 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 05:43:28 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Jeon", "Yongkweon", ""], ["Park", "Baeseong", ""], ["Kwon", "Se Jung", ""], ["Kim", "Byeongwook", ""], ["Yun", "Jeongin", ""], ["Lee", "Dongsoo", ""]]}, {"id": "2005.09907", "submitter": "J. Emmanuel Johnson", "authors": "J. Emmanuel Johnson, Valero Laparra, Gustau Camps-Valls", "title": "Accounting for Input Noise in Gaussian Process Parameter Retrieval", "comments": null, "journal-ref": "IEEE Geoscience and Remote Sensing Letters ( Volume: 17 , Issue: 3\n  , March 2020 )", "doi": "10.1109/LGRS.2019.2921476", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) are a class of Kernel methods that have shown to be\nvery useful in geoscience and remote sensing applications for parameter\nretrieval, model inversion, and emulation. They are widely used because they\nare simple, flexible, and provide accurate estimates. GPs are based on a\nBayesian statistical framework which provides a posterior probability function\nfor each estimation. Therefore, besides the usual prediction (given in this\ncase by the mean function), GPs come equipped with the possibility to obtain a\npredictive variance (i.e., error bars, confidence intervals) for each\nprediction. Unfortunately, the GP formulation usually assumes that there is no\nnoise in the inputs, only in the observations. However, this is often not the\ncase in earth observation problems where an accurate assessment of the\nmeasuring instrument error is typically available, and where there is huge\ninterest in characterizing the error propagation through the processing\npipeline. In this letter, we demonstrate how one can account for input noise\nestimates using a GP model formulation which propagates the error terms using\nthe derivative of the predictive mean function. We analyze the resulting\npredictive variance term and show how they more accurately represent the model\nerror in a temperature prediction problem from infrared sounding data.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 08:23:48 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Johnson", "J. Emmanuel", ""], ["Laparra", "Valero", ""], ["Camps-Valls", "Gustau", ""]]}, {"id": "2005.09908", "submitter": "Chuan Xiao", "authors": "Yaoshu Wang, Chuan Xiao, Jianbin Qin, Rui Mao, Onizuka Makoto, Wei\n  Wang, Rui Zhang, Yoshiharu Ishikawa", "title": "Consistent and Flexible Selectivity Estimation for High-Dimensional Data", "comments": "Published at ACM SIGMOD Conference 2021", "journal-ref": null, "doi": "10.1145/3448016.3452772", "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selectivity estimation aims at estimating the number of database objects that\nsatisfy a selection criterion. Answering this problem accurately and\nefficiently is essential to many applications, such as density estimation,\noutlier detection, query optimization, and data integration. The estimation\nproblem is especially challenging for large-scale high-dimensional data due to\nthe curse of dimensionality, the large variance of selectivity across different\nqueries, and the need to make the estimator consistent (i.e., the selectivity\nis non-decreasing in the threshold). We propose a new deep learning-based model\nthat learns a query-dependent piecewise linear function as selectivity\nestimator, which is flexible to fit the selectivity curve of any distance\nfunction and query object, while guaranteeing that the output is non-decreasing\nin the threshold. To improve the accuracy for large datasets, we propose to\npartition the dataset into multiple disjoint subsets and build a local model on\neach of them. We perform experiments on real datasets and show that the\nproposed model consistently outperforms state-of-the-art models in accuracy in\nan efficient way and is useful for real applications.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 08:24:53 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 07:19:26 GMT"}, {"version": "v3", "created": "Sun, 7 Mar 2021 17:41:37 GMT"}, {"version": "v4", "created": "Thu, 27 May 2021 15:14:51 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Wang", "Yaoshu", ""], ["Xiao", "Chuan", ""], ["Qin", "Jianbin", ""], ["Mao", "Rui", ""], ["Makoto", "Onizuka", ""], ["Wang", "Wei", ""], ["Zhang", "Rui", ""], ["Ishikawa", "Yoshiharu", ""]]}, {"id": "2005.09910", "submitter": "Youngdoo Son", "authors": "Sungjae Lee, Youngdoo Son", "title": "Multitask Learning with Single Gradient Step Update for Task Balancing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitask learning is a methodology to boost generalization performance and\nalso reduce computational intensity and memory usage. However, learning\nmultiple tasks simultaneously can be more difficult than learning a single task\nbecause it can cause imbalance among tasks. To address the imbalance problem,\nwe propose an algorithm to balance between tasks at the gradient level by\napplying gradient-based meta-learning to multitask learning. The proposed\nmethod trains shared layers and task-specific layers separately so that the two\nlayers with different roles in a multitask network can be fitted to their own\npurposes. In particular, the shared layer that contains informative knowledge\nshared among tasks is trained by employing single gradient step update and\ninner/outer loop training to mitigate the imbalance problem at the gradient\nlevel. We apply the proposed method to various multitask computer vision\nproblems and achieve state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 08:34:20 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 12:29:42 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Lee", "Sungjae", ""], ["Son", "Youngdoo", ""]]}, {"id": "2005.09923", "submitter": "Shihua Zhang", "authors": "Kuo Gai and Shihua Zhang", "title": "Tessellated Wasserstein Auto-Encoders", "comments": "38 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-adversarial generative models such as variational auto-encoder (VAE),\nWasserstein auto-encoders with maximum mean discrepancy (WAE-MMD),\nsliced-Wasserstein auto-encoder (SWAE) are relatively easy to train and have\nless mode collapse compared to Wasserstein auto-encoder with generative\nadversarial network (WAE-GAN). However, they are not very accurate in\napproximating the target distribution in the latent space because they don't\nhave a discriminator to detect the minor difference between real and fake. To\nthis end, we develop a novel non-adversarial framework called Tessellated\nWasserstein Auto-encoders (TWAE) to tessellate the support of the target\ndistribution into a given number of regions by the centroidal Voronoi\ntessellation (CVT) technique and design batches of data according to the\ntessellation instead of random shuffling for accurate computation of\ndiscrepancy. Theoretically, we demonstrate that the error of estimate to the\ndiscrepancy decreases when the numbers of samples $n$ and regions $m$ of the\ntessellation become larger with rates of $\\mathcal{O}(\\frac{1}{\\sqrt{n}})$ and\n$\\mathcal{O}(\\frac{1}{\\sqrt{m}})$, respectively. Given fixed $n$ and $m$, a\nnecessary condition for the upper bound of measurement error to be minimized is\nthat the tessellation is the one determined by CVT. TWAE is very flexible to\ndifferent non-adversarial metrics and can substantially enhance their\ngenerative performance in terms of Fr\\'{e}chet inception distance (FID)\ncompared to VAE, WAE-MMD, SWAE. Moreover, numerical results indeed demonstrate\nthat TWAE is competitive to the adversarial model WAE-GAN, demonstrating its\npowerful generative ability.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 09:21:05 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 02:08:40 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Gai", "Kuo", ""], ["Zhang", "Shihua", ""]]}, {"id": "2005.09927", "submitter": "Alex Bewley", "authors": "Alex Bewley, Pei Sun, Thomas Mensink, Dragomir Anguelov, Cristian\n  Sminchisescu", "title": "Range Conditioned Dilated Convolutions for Scale Invariant 3D Object\n  Detection", "comments": "CoRL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a novel 3D object detection framework that processes\nLiDAR data directly on its native representation: range images. Benefiting from\nthe compactness of range images, 2D convolutions can efficiently process dense\nLiDAR data of a scene. To overcome scale sensitivity in this perspective view,\na novel range-conditioned dilation (RCD) layer is proposed to dynamically\nadjust a continuous dilation rate as a function of the measured range.\nFurthermore, localized soft range gating combined with a 3D box-refinement\nstage improves robustness in occluded areas, and produces overall more accurate\nbounding box predictions. On the public large-scale Waymo Open Dataset, our\nmethod sets a new baseline for range-based 3D detection, outperforming\nmultiview and voxel-based methods over all ranges with unparalleled performance\nat long range detection.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 09:24:43 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 08:06:26 GMT"}, {"version": "v3", "created": "Fri, 22 Jan 2021 14:52:57 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Bewley", "Alex", ""], ["Sun", "Pei", ""], ["Mensink", "Thomas", ""], ["Anguelov", "Dragomir", ""], ["Sminchisescu", "Cristian", ""]]}, {"id": "2005.09945", "submitter": "Youssef Achenchabe", "authors": "Youssef Achenchabe, Alexis Bondu, Antoine Cornu\\'ejols and Asma\n  Dachraoui", "title": "Early Classification of Time Series. Cost-based Optimization Criterion\n  and Algorithms", "comments": "Accepted for publication in Machine learning journal (MACH)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of applications require to recognize the class of an\nincoming time series as quickly as possible without unduly compromising the\naccuracy of the prediction. In this paper, we put forward a new optimization\ncriterion which takes into account both the cost of misclassification and the\ncost of delaying the decision. Based on this optimization criterion, we derived\na family of non-myopic algorithms which try to anticipate the expected future\ngain in information in balance with the cost of waiting. In one class of\nalgorithms, unsupervised-based, the expectations use the clustering of time\nseries, while in a second class, supervised-based, time series are grouped\naccording to the confidence level of the classifier used to label them.\nExtensive experiments carried out on real data sets using a large range of\ndelay cost functions show that the presented algorithms are able to\nsatisfactorily solving the earliness vs. accuracy trade-off, with the\nsupervised-based approaches faring better than the unsupervised-based ones. In\naddition, all these methods perform better in a wide variety of conditions than\na state of the art method based on a myopic strategy which is recognized as\nvery competitive.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 10:08:30 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 13:29:35 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Achenchabe", "Youssef", ""], ["Bondu", "Alexis", ""], ["Cornu\u00e9jols", "Antoine", ""], ["Dachraoui", "Asma", ""]]}, {"id": "2005.09946", "submitter": "Pierpaolo Basile", "authors": "Pierluigi Cassotti, Annalina Caputo, Marco Polignano, Pierpaolo Basile", "title": "GM-CTSC at SemEval-2020 Task 1: Gaussian Mixtures Cross Temporal\n  Similarity Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper describes the system proposed for the SemEval-2020 Task 1:\nUnsupervised Lexical Semantic Change Detection. We focused our approach on the\ndetection problem. Given the semantics of words captured by temporal word\nembeddings in different time periods, we investigate the use of unsupervised\nmethods to detect when the target word has gained or loosed senses. To this\nend, we defined a new algorithm based on Gaussian Mixture Models to cluster the\ntarget similarities computed over the two periods. We compared the proposed\napproach with a number of similarity-based thresholds. We found that, although\nthe performance of the detection methods varies across the word embedding\nalgorithms, the combination of Gaussian Mixture with Temporal Referencing\nresulted in our best system.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 10:14:01 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Cassotti", "Pierluigi", ""], ["Caputo", "Annalina", ""], ["Polignano", "Marco", ""], ["Basile", "Pierpaolo", ""]]}, {"id": "2005.09969", "submitter": "Ahmet M. Elbir", "authors": "Ahmet M. Elbir and Sinem Coleri", "title": "Federated Learning for Hybrid Beamforming in mm-Wave Massive MIMO", "comments": "Accepted in IEEE Communications Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning for hybrid beamforming has been extensively studied by using\ncentralized machine learning (CML) techniques, which require the training of a\nglobal model with a large dataset collected from the users. However, the\ntransmission of the whole dataset between the users and the base station (BS)\nis computationally prohibitive due to limited communication bandwidth and\nprivacy concerns. In this work, we introduce a federated learning (FL) based\nframework for hybrid beamforming, where the model training is performed at the\nBS by collecting only the gradients from the users. We design a convolutional\nneural network, in which the input is the channel data, yielding the analog\nbeamformers at the output. Via numerical simulations, FL is demonstrated to be\nmore tolerant to the imperfections and corruptions in the channel data as well\nas having less transmission overhead than CML.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 11:21:07 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 20:16:49 GMT"}, {"version": "v3", "created": "Sat, 22 Aug 2020 08:09:03 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Elbir", "Ahmet M.", ""], ["Coleri", "Sinem", ""]]}, {"id": "2005.09971", "submitter": "Paul Hofmann", "authors": "Paul Hofmann and Zaid Tashman", "title": "Hidden Markov Models and their Application for Predicting Failure Events", "comments": "Will be published in the proceedings of ICCS 2020;\n  @Booklet{EasyChair:3183, author = {Paul Hofmann and Zaid Tashman}, title =\n  {Hidden Markov Models and their Application for Predicting Failure Events},\n  howpublished = {EasyChair Preprint no. 3183}, year = {EasyChair, 2020}}", "journal-ref": null, "doi": "10.1007/978-3-030-50420-5_35", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how Markov mixed membership models (MMMM) can be used to predict the\ndegradation of assets. We model the degradation path of individual assets, to\npredict overall failure rates. Instead of a separate distribution for each\nhidden state, we use hierarchical mixtures of distributions in the exponential\nfamily. In our approach the observation distribution of the states is a finite\nmixture distribution of a small set of (simpler) distributions shared across\nall states. Using tied-mixture observation distributions offers several\nadvantages. The mixtures act as a regularization for typically very sparse\nproblems, and they reduce the computational effort for the learning algorithm\nsince there are fewer distributions to be found. Using shared mixtures enables\nsharing of statistical strength between the Markov states and thus transfer\nlearning. We determine for individual assets the trade-off between the risk of\nfailure and extended operating hours by combining a MMMM with a partially\nobservable Markov decision process (POMDP) to dynamically optimize the policy\nfor when and how to maintain the asset.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 11:30:16 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Hofmann", "Paul", ""], ["Tashman", "Zaid", ""]]}, {"id": "2005.09992", "submitter": "Pietro Rotondo", "authors": "Pietro Rotondo, Mauro Pastore, Marco Gherardi", "title": "Beyond the storage capacity: data driven satisfiability transition", "comments": "5 pages, 2 figures", "journal-ref": "Phys. Rev. Lett. 125, 120601 (2020)", "doi": "10.1103/PhysRevLett.125.120601", "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data structure has a dramatic impact on the properties of neural networks,\nyet its significance in the established theoretical frameworks is poorly\nunderstood. Here we compute the Vapnik-Chervonenkis entropy of a kernel machine\noperating on data grouped into equally labelled subsets. At variance with the\nunstructured scenario, entropy is non-monotonic in the size of the training\nset, and displays an additional critical point besides the storage capacity.\nRemarkably, the same behavior occurs in margin classifiers even with randomly\nlabelled data, as is elucidated by identifying the synaptic volume encoding the\ntransition. These findings reveal aspects of expressivity lying beyond the\ncondensed description provided by the storage capacity, and they indicate the\npath towards more realistic bounds for the generalization error of neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 12:25:38 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Rotondo", "Pietro", ""], ["Pastore", "Mauro", ""], ["Gherardi", "Marco", ""]]}, {"id": "2005.09997", "submitter": "Yu Wang", "authors": "Yu Wang, Fengjuan Gao, Linzhang Wang, Ke Wang", "title": "Learning Semantic Program Embeddings with Graph Interval Neural Network", "comments": "The abstract is simplified, for full abstract, please refer to the\n  paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning distributed representations of source code has been a challenging\ntask for machine learning models. Earlier works treated programs as text so\nthat natural language methods can be readily applied. Unfortunately, such\napproaches do not capitalize on the rich structural information possessed by\nsource code. Of late, Graph Neural Network (GNN) was proposed to learn\nembeddings of programs from their graph representations. Due to the homogeneous\nand expensive message-passing procedure, GNN can suffer from precision issues,\nespecially when dealing with programs rendered into large graphs. In this\npaper, we present a new graph neural architecture, called Graph Interval Neural\nNetwork (GINN), to tackle the weaknesses of the existing GNN. Unlike the\nstandard GNN, GINN generalizes from a curated graph representation obtained\nthrough an abstraction method designed to aid models to learn. In particular,\nGINN focuses exclusively on intervals for mining the feature representation of\na program, furthermore, GINN operates on a hierarchy of intervals for scaling\nthe learning to large graphs. We evaluate GINN for two popular downstream\napplications: variable misuse prediction and method name prediction. Results\nshow in both cases GINN outperforms the state-of-the-art models by a\ncomfortable margin. We have also created a neural bug detector based on GINN to\ncatch null pointer deference bugs in Java code. While learning from the same\n9,000 methods extracted from 64 projects, GINN-based bug detector significantly\noutperforms GNN-based bug detector on 13 unseen test projects. Next, we deploy\nour trained GINN-based bug detector and Facebook Infer to scan the codebase of\n20 highly starred projects on GitHub. Through our manual inspection, we confirm\n38 bugs out of 102 warnings raised by GINN-based bug detector compared to 34\nbugs out of 129 warnings for Facebook Infer.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 02:38:34 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 02:11:25 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Wang", "Yu", ""], ["Gao", "Fengjuan", ""], ["Wang", "Linzhang", ""], ["Wang", "Ke", ""]]}, {"id": "2005.10005", "submitter": "Raian Noufel Lefgoum", "authors": "Raian Noufel Lefgoum", "title": "Iterative Domain Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study a new approach in optimization that aims to search a\nlarge domain D where a given function takes large, small or specific values via\nan iterative optimization algorithm based on the gradient. We show that the\nobjective function used is not directly optimizable, however, we use a trick to\napproximate this objective by another one at each iteration to optimize it.\nThen we explore a use case of this algorithm in machine learning to find\ndomains where the models output large and small values with respect of some\nconstraints. Experiments demonstrate the efficiency of this algorithm on five\ncases with models trained on the titanic dataset.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 14:05:49 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Lefgoum", "Raian Noufel", ""]]}, {"id": "2005.10008", "submitter": "Priyadarshini Kumari", "authors": "Priyadarshini K, Ritesh Goru, Siddhartha Chaudhuri and Subhasis\n  Chaudhuri", "title": "Batch Decorrelation for Active Metric Learning", "comments": "Accepted to IJCAI-PRICAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an active learning strategy for training parametric models of\ndistance metrics, given triplet-based similarity assessments: object $x_i$ is\nmore similar to object $x_j$ than to $x_k$. In contrast to prior work on\nclass-based learning, where the fundamental goal is classification and any\nimplicit or explicit metric is binary, we focus on {\\em perceptual} metrics\nthat express the {\\em degree} of (dis)similarity between objects. We find that\nstandard active learning approaches degrade when annotations are requested for\n{\\em batches} of triplets at a time: our studies suggest that correlation among\ntriplets is responsible. In this work, we propose a novel method to {\\em\ndecorrelate} batches of triplets, that jointly balances informativeness and\ndiversity while decoupling the choice of heuristic for each criterion.\nExperiments indicate our method is general, adaptable, and outperforms the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 12:47:48 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 12:52:04 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["K", "Priyadarshini", ""], ["Goru", "Ritesh", ""], ["Chaudhuri", "Siddhartha", ""], ["Chaudhuri", "Subhasis", ""]]}, {"id": "2005.10018", "submitter": "Maciej Skorski", "authors": "Maciej Skorski", "title": "Revisiting Concentration of Missing Mass", "comments": "Added suplementary materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of \\emph{missing mass concentration}, developing a new\nmethod of estimating concentration of heterogenic sums, in spirit of celebrated\nRosenthal's inequality. As a result we slightly improve the state-of-art bounds\ndue to Ben-Hamou at al., and simplify the proofs.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 17:56:00 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 16:03:44 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 15:43:42 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Skorski", "Maciej", ""]]}, {"id": "2005.10026", "submitter": "Marc Etheve", "authors": "Marc Etheve and Zacharie Al\\`es and C\\^ome Bissuel and Olivier Juan\n  and Safia Kedad-Sidhoum", "title": "Reinforcement Learning for Variable Selection in a Branch and Bound\n  Algorithm", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-58942-4_12", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed integer linear programs are commonly solved by Branch and Bound\nalgorithms. A key factor of the efficiency of the most successful commercial\nsolvers is their fine-tuned heuristics. In this paper, we leverage patterns in\nreal-world instances to learn from scratch a new branching strategy optimised\nfor a given problem and compare it with a commercial solver. We propose FMSTS,\na novel Reinforcement Learning approach specifically designed for this task.\nThe strength of our method lies in the consistency between a local value\nfunction and a global metric of interest. In addition, we provide insights for\nadapting known RL techniques to the Branch and Bound setting, and present a new\nneural network architecture inspired from the literature. To our knowledge, it\nis the first time Reinforcement Learning has been used to fully optimise the\nbranching strategy. Computational experiments show that our method is\nappropriate and able to generalise well to new instances.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:15:48 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Etheve", "Marc", ""], ["Al\u00e8s", "Zacharie", ""], ["Bissuel", "C\u00f4me", ""], ["Juan", "Olivier", ""], ["Kedad-Sidhoum", "Safia", ""]]}, {"id": "2005.10034", "submitter": "Yixing Huang", "authors": "Yixing Huang, Alexander Preuhs, Michael Manhart, Guenter Lauritsch,\n  Andreas Maier", "title": "Data Consistent CT Reconstruction from Insufficient Data with Learned\n  Prior Images", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image reconstruction from insufficient data is common in computed tomography\n(CT), e.g., image reconstruction from truncated data, limited-angle data and\nsparse-view data. Deep learning has achieved impressive results in this field.\nHowever, the robustness of deep learning methods is still a concern for\nclinical applications due to the following two challenges: a) With limited\naccess to sufficient training data, a learned deep learning model may not\ngeneralize well to unseen data; b) Deep learning models are sensitive to noise.\nTherefore, the quality of images processed by neural networks only may be\ninadequate. In this work, we investigate the robustness of deep learning in CT\nimage reconstruction by showing false negative and false positive lesion cases.\nSince learning-based images with incorrect structures are likely not consistent\nwith measured projection data, we propose a data consistent reconstruction\n(DCR) method to improve their image quality, which combines the advantages of\ncompressed sensing and deep learning: First, a prior image is generated by deep\nlearning. Afterwards, unmeasured projection data are inpainted by forward\nprojection of the prior image. Finally, iterative reconstruction with\nreweighted total variation regularization is applied, integrating data\nconsistency for measured data and learned prior information for missing data.\nThe efficacy of the proposed method is demonstrated in cone-beam CT with\ntruncated data, limited-angle data and sparse-view data, respectively. For\nexample, for truncated data, DCR achieves a mean root-mean-square error of 24\nHU and a mean structure similarity index of 0.999 inside the field-of-view for\ndifferent patients in the noisy case, while the state-of-the-art U-Net method\nachieves 55 HU and 0.995 respectively for these two metrics.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:30:49 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Huang", "Yixing", ""], ["Preuhs", "Alexander", ""], ["Manhart", "Michael", ""], ["Lauritsch", "Guenter", ""], ["Maier", "Andreas", ""]]}, {"id": "2005.10036", "submitter": "Connor Coley", "authors": "Lior Hirschfeld, Kyle Swanson, Kevin Yang, Regina Barzilay, Connor W.\n  Coley", "title": "Uncertainty Quantification Using Neural Networks for Molecular Property\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty quantification (UQ) is an important component of molecular\nproperty prediction, particularly for drug discovery applications where model\npredictions direct experimental design and where unanticipated imprecision\nwastes valuable time and resources. The need for UQ is especially acute for\nneural models, which are becoming increasingly standard yet are challenging to\ninterpret. While several approaches to UQ have been proposed in the literature,\nthere is no clear consensus on the comparative performance of these models. In\nthis paper, we study this question in the context of regression tasks. We\nsystematically evaluate several methods on five benchmark datasets using\nmultiple complementary performance metrics. Our experiments show that none of\nthe methods we tested is unequivocally superior to all others, and none\nproduces a particularly reliable ranking of errors across multiple datasets.\nWhile we believe these results show that existing UQ methods are not sufficient\nfor all common use-cases and demonstrate the benefits of further research, we\nconclude with a practical recommendation as to which existing techniques seem\nto perform well relative to others.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:31:20 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Hirschfeld", "Lior", ""], ["Swanson", "Kyle", ""], ["Yang", "Kevin", ""], ["Barzilay", "Regina", ""], ["Coley", "Connor W.", ""]]}, {"id": "2005.10039", "submitter": "Hinrikus Wolf", "authors": "Tobias Schumacher, Hinrikus Wolf, Martin Ritzert, Florian Lemmerich,\n  Jan Bachmann, Florian Frantzen, Max Klabunde, Martin Grohe, Markus Strohmaier", "title": "The Effects of Randomness on the Stability of Node Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We systematically evaluate the (in-)stability of state-of-the-art node\nembedding algorithms due to randomness, i.e., the random variation of their\noutcomes given identical algorithms and graphs. We apply five node embeddings\nalgorithms---HOPE, LINE, node2vec, SDNE, and GraphSAGE---to synthetic and\nempirical graphs and assess their stability under randomness with respect to\n(i) the geometry of embedding spaces as well as (ii) their performance in\ndownstream tasks. We find significant instabilities in the geometry of\nembedding spaces independent of the centrality of a node. In the evaluation of\ndownstream tasks, we find that the accuracy of node classification seems to be\nunaffected by random seeding while the actual classification of nodes can vary\nsignificantly. This suggests that instability effects need to be taken into\naccount when working with node embeddings. Our work is relevant for researchers\nand engineers interested in the effectiveness, reliability, and reproducibility\nof node embedding approaches.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:36:09 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Schumacher", "Tobias", ""], ["Wolf", "Hinrikus", ""], ["Ritzert", "Martin", ""], ["Lemmerich", "Florian", ""], ["Bachmann", "Jan", ""], ["Frantzen", "Florian", ""], ["Klabunde", "Max", ""], ["Grohe", "Martin", ""], ["Strohmaier", "Markus", ""]]}, {"id": "2005.10040", "submitter": "Antoine Blanchard", "authors": "Antoine Blanchard and Themistoklis Sapsis", "title": "Informative Path Planning for Extreme Anomaly Detection in Environment\n  Exploration and Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An unmanned autonomous vehicle (UAV) is sent on a mission to explore and\nreconstruct an unknown environment from a series of measurements collected by\nBayesian optimization. The success of the mission is judged by the UAV's\nability to faithfully reconstruct any anomalous features present in the\nenvironment, with emphasis on the extremes (e.g., extreme topographic\ndepressions or abnormal chemical concentrations). We show that the criteria\ncommonly used for determining which locations the UAV should visit are\nill-suited for this task. We introduce a number of novel criteria that guide\nthe UAV towards regions of strong anomalies by leveraging previously collected\ninformation in a mathematically elegant and computationally tractable manner.\nWe demonstrate superiority of the proposed approach in several applications,\nincluding reconstruction of seafloor topography from real-world bathymetry\ndata, as well as tracking of dynamic anomalies. A particularly attractive\nproperty of our approach is its ability to overcome adversarial conditions,\nthat is, situations in which prior beliefs about the locations of the extremes\nare imprecise or erroneous.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:36:22 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 01:10:06 GMT"}, {"version": "v3", "created": "Wed, 7 Apr 2021 23:56:02 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Blanchard", "Antoine", ""], ["Sapsis", "Themistoklis", ""]]}, {"id": "2005.10045", "submitter": "Baris Kanber", "authors": "Baris Kanber", "title": "Sparse data to structured imageset transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning problems involving sparse datasets may benefit from the use\nof convolutional neural networks if the numbers of samples and features are\nvery large. Such datasets are increasingly more frequently encountered in a\nvariety of different domains. We convert such datasets to imagesets while\nattempting to give each image structure that is amenable for use with\nconvolutional neural networks. Experimental results on two publicly available,\nsparse datasets show that the approach can boost classification performance\ncompared to other methods, which may be attributed to the formation of visually\ndistinguishable shapes on the resultant images.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 20:36:59 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Kanber", "Baris", ""]]}, {"id": "2005.10048", "submitter": "Magdalena Biesialska", "authors": "Magdalena Biesialska, Bardia Rafieian, Marta R. Costa-juss\\`a", "title": "Enhancing Word Embeddings with Knowledge Extracted from Lexical\n  Resources", "comments": "Accepted to ACL 2020 SRW", "journal-ref": null, "doi": "10.18653/v1/2020.acl-srw.36", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present an effective method for semantic specialization of\nword vector representations. To this end, we use traditional word embeddings\nand apply specialization methods to better capture semantic relations between\nwords. In our approach, we leverage external knowledge from rich lexical\nresources such as BabelNet. We also show that our proposed post-specialization\nmethod based on an adversarial neural network with the Wasserstein distance\nallows to gain improvements over state-of-the-art methods on two tasks: word\nsimilarity and dialog state tracking.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:45:49 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Biesialska", "Magdalena", ""], ["Rafieian", "Bardia", ""], ["Costa-juss\u00e0", "Marta R.", ""]]}, {"id": "2005.10049", "submitter": "Wilfried Michel", "authors": "Wilfried Michel and Ralf Schl\\\"uter and Hermann Ney", "title": "Early Stage LM Integration Using Local and Global Log-Linear Combination", "comments": "Submitted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence models with an implicit alignment mechanism (e.g.\nattention) are closing the performance gap towards traditional hybrid hidden\nMarkov models (HMM) for the task of automatic speech recognition. One important\nfactor to improve word error rate in both cases is the use of an external\nlanguage model (LM) trained on large text-only corpora. Language model\nintegration is straightforward with the clear separation of acoustic model and\nlanguage model in classical HMM-based modeling. In contrast, multiple\nintegration schemes have been proposed for attention models. In this work, we\npresent a novel method for language model integration into implicit-alignment\nbased sequence-to-sequence models. Log-linear model combination of acoustic and\nlanguage model is performed with a per-token renormalization. This allows us to\ncompute the full normalization term efficiently both in training and in\ntesting. This is compared to a global renormalization scheme which is\nequivalent to applying shallow fusion in training. The proposed methods show\ngood improvements over standard model combination (shallow fusion) on our\nstate-of-the-art Librispeech system. Furthermore, the improvements are\npersistent even if the LM is exchanged for a more powerful one after training.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:49:55 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Michel", "Wilfried", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "2005.10050", "submitter": "Samaneh Abbasi Sureshjani", "authors": "Samaneh Abbasi-Sureshjani, Ralf Raumanns, Britt E. J. Michels, Gerard\n  Schouten, Veronika Cheplygina", "title": "Risk of Training Diagnostic Algorithms on Data with Demographic Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the critical challenges in machine learning applications is to have\nfair predictions. There are numerous recent examples in various domains that\nconvincingly show that algorithms trained with biased datasets can easily lead\nto erroneous or discriminatory conclusions. This is even more crucial in\nclinical applications where the predictive algorithms are designed mainly based\non a limited or given set of medical images and demographic variables such as\nage, sex and race are not taken into account. In this work, we conduct a survey\nof the MICCAI 2018 proceedings to investigate the common practice in medical\nimage analysis applications. Surprisingly, we found that papers focusing on\ndiagnosis rarely describe the demographics of the datasets used, and the\ndiagnosis is purely based on images. In order to highlight the importance of\nconsidering the demographics in diagnosis tasks, we used a publicly available\ndataset of skin lesions. We then demonstrate that a classifier with an overall\narea under the curve (AUC) of 0.83 has variable performance between 0.76 and\n0.91 on subgroups based on age and sex, even though the training set was\nrelatively balanced. Moreover, we show that it is possible to learn unbiased\nfeatures by explicitly using demographic variables in an adversarial training\nsetup, which leads to balanced scores per subgroups. Finally, we discuss the\nimplications of these results and provide recommendations for further research.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:51:01 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 11:33:59 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Abbasi-Sureshjani", "Samaneh", ""], ["Raumanns", "Ralf", ""], ["Michels", "Britt E. J.", ""], ["Schouten", "Gerard", ""], ["Cheplygina", "Veronika", ""]]}, {"id": "2005.10052", "submitter": "Raghavendra Selvan", "authors": "Raghavendra Selvan, Erik B. Dam, Nicki S. Detlefsen, Sofus Rischel,\n  Kaining Sheng, Mads Nielsen, Akshay Pai", "title": "Lung Segmentation from Chest X-rays using Variational Data Imputation", "comments": "Accepted to be presented at the first Workshop on the Art of Learning\n  with Missing Values (Artemiss) hosted by the 37th International Conference on\n  Machine Learning (ICML). Source code, training data and the trained models\n  are available here: https://github.com/raghavian/lungVAE/", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pulmonary opacification is the inflammation in the lungs caused by many\nrespiratory ailments, including the novel corona virus disease 2019 (COVID-19).\nChest X-rays (CXRs) with such opacifications render regions of lungs\nimperceptible, making it difficult to perform automated image analysis on them.\nIn this work, we focus on segmenting lungs from such abnormal CXRs as part of a\npipeline aimed at automated risk scoring of COVID-19 from CXRs. We treat the\nhigh opacity regions as missing data and present a modified CNN-based image\nsegmentation network that utilizes a deep generative model for data imputation.\nWe train this model on normal CXRs with extensive data augmentation and\ndemonstrate the usefulness of this model to extend to cases with extreme\nabnormalities.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:52:03 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 06:12:42 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Selvan", "Raghavendra", ""], ["Dam", "Erik B.", ""], ["Detlefsen", "Nicki S.", ""], ["Rischel", "Sofus", ""], ["Sheng", "Kaining", ""], ["Nielsen", "Mads", ""], ["Pai", "Akshay", ""]]}, {"id": "2005.10053", "submitter": "Rui Zhang", "authors": "Rui Zhang, Conrad Albrecht, Wei Zhang, Xiaodong Cui, Ulrich Finkler,\n  David Kung, Siyuan Lu", "title": "Map Generation from Large Scale Incomplete and Inaccurate Data Labels", "comments": "This paper is accepted by KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately and globally mapping human infrastructure is an important and\nchallenging task with applications in routing, regulation compliance\nmonitoring, and natural disaster response management etc.. In this paper we\npresent progress in developing an algorithmic pipeline and distributed compute\nsystem that automates the process of map creation using high resolution aerial\nimages. Unlike previous studies, most of which use datasets that are available\nonly in a few cities across the world, we utilizes publicly available imagery\nand map data, both of which cover the contiguous United States (CONUS). We\napproach the technical challenge of inaccurate and incomplete training data\nadopting state-of-the-art convolutional neural network architectures such as\nthe U-Net and the CycleGAN to incrementally generate maps with increasingly\nmore accurate and more complete labels of man-made infrastructure such as roads\nand houses. Since scaling the mapping task to CONUS calls for parallelization,\nwe then adopted an asynchronous distributed stochastic parallel gradient\ndescent training scheme to distribute the computational workload onto a cluster\nof GPUs with nearly linear speed-up.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:59:43 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Zhang", "Rui", ""], ["Albrecht", "Conrad", ""], ["Zhang", "Wei", ""], ["Cui", "Xiaodong", ""], ["Finkler", "Ulrich", ""], ["Kung", "David", ""], ["Lu", "Siyuan", ""]]}, {"id": "2005.10076", "submitter": "Mamikon Gulian", "authors": "Huaiqian You, Yue Yu, Nathaniel Trask, Mamikon Gulian, Marta D'Elia", "title": "Data-driven learning of robust nonlocal physics from high-fidelity\n  synthetic data", "comments": "32 pages, 10 figures, 3 tables", "journal-ref": null, "doi": "10.1016/j.cma.2020.113553", "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge to nonlocal models is the analytical complexity of deriving\nthem from first principles, and frequently their use is justified a posteriori.\nIn this work we extract nonlocal models from data, circumventing these\nchallenges and providing data-driven justification for the resulting model\nform. Extracting provably robust data-driven surrogates is a major challenge\nfor machine learning (ML) approaches, due to nonlinearities and lack of\nconvexity. Our scheme allows extraction of provably invertible nonlocal models\nwhose kernels may be partially negative. To achieve this, based on established\nnonlocal theory, we embed in our algorithm sufficient conditions on the\nnon-positive part of the kernel that guarantee well-posedness of the learnt\noperator. These conditions are imposed as inequality constraints and ensure\nthat models are robust, even in small-data regimes. We demonstrate this\nworkflow for a range of applications, including reproduction of manufactured\nnonlocal kernels; numerical homogenization of Darcy flow associated with a\nheterogeneous periodic microstructure; nonlocal approximation to high-order\nlocal transport phenomena; and approximation of globally supported fractional\ndiffusion operators by truncated kernels.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 22:53:14 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["You", "Huaiqian", ""], ["Yu", "Yue", ""], ["Trask", "Nathaniel", ""], ["Gulian", "Mamikon", ""], ["D'Elia", "Marta", ""]]}, {"id": "2005.10085", "submitter": "Tijs Slaats", "authors": "Christoffer Olling Back, Tijs Slaats, Thomas Troels Hildebrandt,\n  Morten Marquard", "title": "DisCoveR: Accurate & Efficient Discovery of Declarative Process Models", "comments": "Author's original version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Declarative process modeling formalisms - which capture high-level process\nconstraints - have seen growing interest, especially for modeling flexible\nprocesses. This paper presents DisCoveR, an extremely efficient and accurate\ndeclarative miner for learning Dynamic Condition Response (DCR) Graphs from\nevent logs. We precisely formalize the algorithm, describe a highly efficient\nbit vector implementation and rigorously evaluate performance against two other\ndeclarative miners, representing the state-of-the-art in Declare and DCR Graphs\nmining. DisCoveR outperforms each of these w.r.t. a binary classification task,\nachieving an average accuracy of 96.2% in the Process Discovery Contest 2019.\nDue to its linear time complexity, DisCoveR also achieves run-times 1-2 orders\nof magnitude below its declarative counterparts. Finally, we show how the miner\nhas been integrated in a state-of-the-art declarative process modeling\nframework as a model recommendation tool, discuss how discovery can play an\nintegral part of the modeling task and report on how the integration has\nimproved the modeling experience of end-users.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 14:48:33 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Back", "Christoffer Olling", ""], ["Slaats", "Tijs", ""], ["Hildebrandt", "Thomas Troels", ""], ["Marquard", "Morten", ""]]}, {"id": "2005.10087", "submitter": "Guillaume Ginolhac", "authors": "Florent Bouchard, Ammar Mian, Jialun Zhou, Salem Said, Guillaume\n  Ginolhac, and Yannick Berthoumieu", "title": "Riemannian geometry for Compound Gaussian distributions: application to\n  recursive change detection", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new Riemannian geometry for the Compound Gaussian distribution is proposed.\nIn particular, the Fisher information metric is obtained, along with\ncorresponding geodesics and distance function. This new geometry is applied on\na change detection problem on Multivariate Image Times Series: a recursive\napproach based on Riemannian optimization is developed. As shown on simulated\ndata, it allows to reach optimal performance while being computationally more\nefficient.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 14:51:09 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Bouchard", "Florent", ""], ["Mian", "Ammar", ""], ["Zhou", "Jialun", ""], ["Said", "Salem", ""], ["Ginolhac", "Guillaume", ""], ["Berthoumieu", "Yannick", ""]]}, {"id": "2005.10099", "submitter": "Yuhao Zhou", "authors": "Yuhao Zhou, Jiaxin Shi, Jun Zhu", "title": "Nonparametric Score Estimators", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the score, i.e., the gradient of log density function, from a set\nof samples generated by an unknown distribution is a fundamental task in\ninference and learning of probabilistic models that involve flexible yet\nintractable densities. Kernel estimators based on Stein's methods or score\nmatching have shown promise, however their theoretical properties and\nrelationships have not been fully-understood. We provide a unifying view of\nthese estimators under the framework of regularized nonparametric regression.\nIt allows us to analyse existing estimators and construct new ones with\ndesirable properties by choosing different hypothesis spaces and regularizers.\nA unified convergence analysis is provided for such estimators. Finally, we\npropose score estimators based on iterative regularization that enjoy\ncomputational benefits from curl-free kernels and fast convergence.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 15:01:03 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 06:41:58 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Zhou", "Yuhao", ""], ["Shi", "Jiaxin", ""], ["Zhu", "Jun", ""]]}, {"id": "2005.10110", "submitter": "Menghan Wang", "authors": "Menghan Wang, Yujie Lin, Guli Lin, Keping Yang, Xiao-ming Wu", "title": "M2GRL: A Multi-task Multi-view Graph Representation Learning Framework\n  for Web-scale Recommender Systems", "comments": "Accepted by KDD 2020 ads track as an oral paper. Code\n  address:https://github.com/99731/M2GRL", "journal-ref": null, "doi": "10.1145/3394486.3403284", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining graph representation learning with multi-view data (side\ninformation) for recommendation is a trend in industry. Most existing methods\ncan be categorized as \\emph{multi-view representation fusion}; they first build\none graph and then integrate multi-view data into a single compact\nrepresentation for each node in the graph. However, these methods are raising\nconcerns in both engineering and algorithm aspects: 1) multi-view data are\nabundant and informative in industry and may exceed the capacity of one single\nvector, and 2) inductive bias may be introduced as multi-view data are often\nfrom different distributions. In this paper, we use a \\emph{multi-view\nrepresentation alignment} approach to address this issue. Particularly, we\npropose a multi-task multi-view graph representation learning framework (M2GRL)\nto learn node representations from multi-view graphs for web-scale recommender\nsystems. M2GRL constructs one graph for each single-view data, learns multiple\nseparate representations from multiple graphs, and performs alignment to model\ncross-view relations. M2GRL chooses a multi-task learning paradigm to learn\nintra-view representations and cross-view relations jointly. Besides, M2GRL\napplies homoscedastic uncertainty to adaptively tune the loss weights of tasks\nduring training. We deploy M2GRL at Taobao and train it on 57 billion examples.\nAccording to offline metrics and online A/B tests, M2GRL significantly\noutperforms other state-of-the-art algorithms. Further exploration on diversity\nrecommendation in Taobao shows the effectiveness of utilizing multiple\nrepresentations produced by \\method{}, which we argue is a promising direction\nfor various industrial recommendation tasks of different focus.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 15:08:57 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 23:09:51 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 03:04:22 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Wang", "Menghan", ""], ["Lin", "Yujie", ""], ["Lin", "Guli", ""], ["Yang", "Keping", ""], ["Wu", "Xiao-ming", ""]]}, {"id": "2005.10111", "submitter": "Stephan Rabanser", "authors": "Stephan Rabanser, Tim Januschowski, Valentin Flunkert, David Salinas,\n  Jan Gasthaus", "title": "The Effectiveness of Discretization in Forecasting: An Empirical Study\n  on Neural Time Series Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series modeling techniques based on deep learning have seen many\nadvancements in recent years, especially in data-abundant settings and with the\ncentral aim of learning global models that can extract patterns across multiple\ntime series. While the crucial importance of appropriate data pre-processing\nand scaling has often been noted in prior work, most studies focus on improving\nmodel architectures. In this paper we empirically investigate the effect of\ndata input and output transformations on the predictive performance of several\nneural forecasting architectures. In particular, we investigate the\neffectiveness of several forms of data binning, i.e. converting real-valued\ntime series into categorical ones, when combined with feed-forward, recurrent\nneural networks, and convolution-based sequence models. In many non-forecasting\napplications where these models have been very successful, the model inputs and\noutputs are categorical (e.g. words from a fixed vocabulary in natural language\nprocessing applications or quantized pixel color intensities in computer\nvision). For forecasting applications, where the time series are typically\nreal-valued, various ad-hoc data transformations have been proposed, but have\nnot been systematically compared. To remedy this, we evaluate the forecasting\naccuracy of instances of the aforementioned model classes when combined with\ndifferent types of data scaling and binning. We find that binning almost always\nimproves performance (compared to using normalized real-valued inputs), but\nthat the particular type of binning chosen is of lesser importance.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 15:09:28 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Rabanser", "Stephan", ""], ["Januschowski", "Tim", ""], ["Flunkert", "Valentin", ""], ["Salinas", "David", ""], ["Gasthaus", "Jan", ""]]}, {"id": "2005.10114", "submitter": "Yuanfei Luo", "authors": "Yuanfei Luo, Hao Zhou, Weiwei Tu, Yuqiang Chen, Wenyuan Dai and Qiang\n  Yang", "title": "Network On Network for Tabular Data Classification in Real-world\n  Applications", "comments": null, "journal-ref": null, "doi": "10.1145/3397271.3401437", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tabular data is the most common data format adopted by our customers ranging\nfrom retail, finance to E-commerce, and tabular data classification plays an\nessential role to their businesses. In this paper, we present Network On\nNetwork (NON), a practical tabular data classification model based on deep\nneural network to provide accurate predictions. Various deep methods have been\nproposed and promising progress has been made. However, most of them use\noperations like neural network and factorization machines to fuse the\nembeddings of different features directly, and linearly combine the outputs of\nthose operations to get the final prediction. As a result, the intra-field\ninformation and the non-linear interactions between those operations (e.g.\nneural network and factorization machines) are ignored. Intra-field information\nis the information that features inside each field belong to the same field.\nNON is proposed to take full advantage of intra-field information and\nnon-linear interactions. It consists of three components: field-wise network at\nthe bottom to capture the intra-field information, across field network in the\nmiddle to choose suitable operations data-drivenly, and operation fusion\nnetwork on the top to fuse outputs of the chosen operations deeply. Extensive\nexperiments on six real-world datasets demonstrate NON can outperform the\nstate-of-the-art models significantly. Furthermore, both qualitative and\nquantitative study of the features in the embedding space show NON can capture\nintra-field information effectively.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 15:10:42 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 07:23:25 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Luo", "Yuanfei", ""], ["Zhou", "Hao", ""], ["Tu", "Weiwei", ""], ["Chen", "Yuqiang", ""], ["Dai", "Wenyuan", ""], ["Yang", "Qiang", ""]]}, {"id": "2005.10175", "submitter": "Shaofeng Zou", "authors": "Yue Wang and Shaofeng Zou", "title": "Finite-sample Analysis of Greedy-GQ with Linear Function Approximation\n  under Markovian Noise", "comments": "UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Greedy-GQ is an off-policy two timescale algorithm for optimal control in\nreinforcement learning. This paper develops the first finite-sample analysis\nfor the Greedy-GQ algorithm with linear function approximation under Markovian\nnoise. Our finite-sample analysis provides theoretical justification for\nchoosing stepsizes for this two timescale algorithm for faster convergence in\npractice, and suggests a trade-off between the convergence rate and the quality\nof the obtained policy. Our paper extends the finite-sample analyses of two\ntimescale reinforcement learning algorithms from policy evaluation to optimal\ncontrol, which is of more practical interest. Specifically, in contrast to\nexisting finite-sample analyses for two timescale methods, e.g., GTD, GTD2 and\nTDC, where their objective functions are convex, the objective function of the\nGreedy-GQ algorithm is non-convex. Moreover, the Greedy-GQ algorithm is also\nnot a linear two-timescale stochastic approximation algorithm. Our techniques\nin this paper provide a general framework for finite-sample analysis of\nnon-convex value-based reinforcement learning algorithms for optimal control.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 16:35:19 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Wang", "Yue", ""], ["Zou", "Shaofeng", ""]]}, {"id": "2005.10176", "submitter": "Tapajit Dey", "authors": "Tapajit Dey, Andrey Karnauch, Audris Mockus", "title": "Representation of Developer Expertise in Open Source Software", "comments": "Accepted in ICSE 2021 Main Technical Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Accurate representation of developer expertise has always been an\nimportant research problem. While a number of studies proposed novel methods of\nrepresenting expertise within individual projects, these methods are difficult\nto apply at an ecosystem level. However, with the focus of software development\nshifting from monolithic to modular, a method of representing developers'\nexpertise in the context of the entire OSS development becomes necessary when,\nfor example, a project tries to find new maintainers and look for developers\nwith relevant skills. Aim: We aim to address this knowledge gap by proposing\nand constructing the Skill Space where each API, developer, and project is\nrepresented and postulate how the topology of this space should reflect what\ndevelopers know (and projects need). Method: we use the World of Code\ninfrastructure to extract the complete set of APIs in the files changed by open\nsource developers and, based on that data, employ Doc2Vec embeddings for vector\nrepresentations of APIs, developers, and projects. We then evaluate if these\nembeddings reflect the postulated topology of the Skill Space by predicting\nwhat new APIs/projects developers use/join, and whether or not their pull\nrequests get accepted. We also check how the developers' representations in the\nSkill Space align with their self-reported API expertise. Result: Our results\nsuggest that the proposed embeddings in the Skill Space appear to satisfy the\npostulated topology and we hope that such representations may aid in the\nconstruction of signals that increase trust (and efficiency) of open source\necosystems at large and may aid investigations of other phenomena related to\ndeveloper proficiency and learning.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 16:36:07 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 13:20:30 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2021 11:43:45 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Dey", "Tapajit", ""], ["Karnauch", "Andrey", ""], ["Mockus", "Audris", ""]]}, {"id": "2005.10180", "submitter": "Joseph Y. Halpern", "authors": "Dalal Alrajeh, Hana Chockler, and Joseph Y. Halpern", "title": "Combining Experts' Causal Judgments", "comments": "A preliminary version of the paper appeared in \\emph{Proceedings of\n  the Thirty-Second AAAI Conference on Artificial Intelligence (AAAI-18)},\n  2018}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a policymaker who wants to decide which intervention to perform in\norder to change a currently undesirable situation. The policymaker has at her\ndisposal a team of experts, each with their own understanding of the causal\ndependencies between different factors contributing to the outcome. The\npolicymaker has varying degrees of confidence in the experts' opinions. She\nwants to combine their opinions in order to decide on the most effective\nintervention. We formally define the notion of an effective intervention, and\nthen consider how experts' causal judgments can be combined in order to\ndetermine the most effective intervention. We define a notion of two causal\nmodels being \\emph{compatible}, and show how compatible causal models can be\nmerged. We then use it as the basis for combining experts' causal judgments. We\nalso provide a definition of decomposition for causal models to cater for cases\nwhen models are incompatible. We illustrate our approach on a number of\nreal-life examples.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 16:41:07 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Alrajeh", "Dalal", ""], ["Chockler", "Hana", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "2005.10190", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu and Yuanzhi Li", "title": "Feature Purification: How Adversarial Training Performs Robust Deep\n  Learning", "comments": "v2 and V3 polish writing and experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the empirical success of using Adversarial Training to defend deep\nlearning models against adversarial perturbations, so far, it still remains\nrather unclear what the principles are behind the existence of adversarial\nperturbations, and what adversarial training does to the neural network to\nremove them.\n  In this paper, we present a principle that we call Feature Purification,\nwhere we show one of the causes of the existence of adversarial examples is the\naccumulation of certain small dense mixtures in the hidden weights during the\ntraining process of a neural network; and more importantly, one of the goals of\nadversarial training is to remove such mixtures to purify hidden weights. We\npresent both experiments on the CIFAR-10 dataset to illustrate this principle,\nand a theoretical result proving that for certain natural classification tasks,\ntraining a two-layer neural network with ReLU activation using randomly\ninitialized gradient descent indeed satisfies this principle.\n  Technically, we give, to the best of our knowledge, the first result proving\nthat the following two can hold simultaneously for training a neural network\nwith ReLU activation. (1) Training over the original data is indeed non-robust\nto small adversarial perturbations of some radius. (2) Adversarial training,\neven with an empirical perturbation algorithm such as FGM, can in fact be\nprovably robust against ANY perturbations of the same radius. Finally, we also\nprove a complexity lower bound, showing that low complexity models such as\nlinear classifiers, low-degree polynomials, or even the neural tangent kernel\nfor this network, CANNOT defend against perturbations of this same radius, no\nmatter what algorithms are used to train them.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 16:56:08 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 08:09:49 GMT"}, {"version": "v3", "created": "Sat, 3 Jul 2021 19:10:04 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""]]}, {"id": "2005.10200", "submitter": "Dat Quoc Nguyen", "authors": "Dat Quoc Nguyen, Thanh Vu and Anh Tuan Nguyen", "title": "BERTweet: A pre-trained language model for English Tweets", "comments": "In Proceedings of EMNLP 2020: System Demonstrations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present BERTweet, the first public large-scale pre-trained language model\nfor English Tweets. Our BERTweet, having the same architecture as BERT-base\n(Devlin et al., 2019), is trained using the RoBERTa pre-training procedure (Liu\net al., 2019). Experiments show that BERTweet outperforms strong baselines\nRoBERTa-base and XLM-R-base (Conneau et al., 2020), producing better\nperformance results than the previous state-of-the-art models on three Tweet\nNLP tasks: Part-of-speech tagging, Named-entity recognition and text\nclassification. We release BERTweet under the MIT License to facilitate future\nresearch and applications on Tweet data. Our BERTweet is available at\nhttps://github.com/VinAIResearch/BERTweet\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 17:05:57 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 10:00:24 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Nguyen", "Dat Quoc", ""], ["Vu", "Thanh", ""], ["Nguyen", "Anh Tuan", ""]]}, {"id": "2005.10203", "submitter": "Wei Jin", "authors": "Wei Jin, Yao Ma, Xiaorui Liu, Xianfeng Tang, Suhang Wang, Jiliang Tang", "title": "Graph Structure Learning for Robust Graph Neural Networks", "comments": "Accepted by KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are powerful tools in representation learning\nfor graphs. However, recent studies show that GNNs are vulnerable to\ncarefully-crafted perturbations, called adversarial attacks. Adversarial\nattacks can easily fool GNNs in making predictions for downstream tasks. The\nvulnerability to adversarial attacks has raised increasing concerns for\napplying GNNs in safety-critical applications. Therefore, developing robust\nalgorithms to defend adversarial attacks is of great significance. A natural\nidea to defend adversarial attacks is to clean the perturbed graph. It is\nevident that real-world graphs share some intrinsic properties. For example,\nmany real-world graphs are low-rank and sparse, and the features of two\nadjacent nodes tend to be similar. In fact, we find that adversarial attacks\nare likely to violate these graph properties. Therefore, in this paper, we\nexplore these properties to defend adversarial attacks on graphs. In\nparticular, we propose a general framework Pro-GNN, which can jointly learn a\nstructural graph and a robust graph neural network model from the perturbed\ngraph guided by these properties. Extensive experiments on real-world graphs\ndemonstrate that the proposed framework achieves significantly better\nperformance compared with the state-of-the-art defense methods, even when the\ngraph is heavily perturbed. We release the implementation of Pro-GNN to our\nDeepRobust repository for adversarial attacks and defenses (footnote:\nhttps://github.com/DSE-MSU/DeepRobust). The specific experimental settings to\nreproduce our results can be found in https://github.com/ChandlerBang/Pro-GNN.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 17:07:05 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 03:37:39 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 21:57:09 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Jin", "Wei", ""], ["Ma", "Yao", ""], ["Liu", "Xiaorui", ""], ["Tang", "Xianfeng", ""], ["Wang", "Suhang", ""], ["Tang", "Jiliang", ""]]}, {"id": "2005.10211", "submitter": "Benedict Wilkins", "authors": "Benedict Wilkins, Chris Watkins, Kostas Stathis", "title": "A Metric Learning Approach to Anomaly Detection in Video Games", "comments": "4 pages, 3 figures, Accepted in IEEE 2020 CONFERENCE ON GAMES (COG),\n  Dataset https://www.kaggle.com/benedictwilkinsai/atari-anomaly-dataset-aad ,\n  Code and pre-trained models https://github.com/BenedictWilkinsAI/S3N", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the aim of designing automated tools that assist in the video game\nquality assurance process, we frame the problem of identifying bugs in video\ngames as an anomaly detection (AD) problem. We develop State-State Siamese\nNetworks (S3N) as an efficient deep metric learning approach to AD in this\ncontext and explore how it may be used as part of an automated testing tool.\nFinally, we show by empirical evaluation on a series of Atari games, that S3N\nis able to learn a meaningful embedding, and consequently is able to identify\nvarious common types of video game bugs.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 17:23:21 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 13:27:00 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Wilkins", "Benedict", ""], ["Watkins", "Chris", ""], ["Stathis", "Kostas", ""]]}, {"id": "2005.10219", "submitter": "Jack Weston", "authors": "Abhishek Shivkumar, Jack Weston, Raphael Lenain, Emil Fristed", "title": "BlaBla: Linguistic Feature Extraction for Clinical Analysis in Multiple\n  Languages", "comments": "5 pages. 1 figure. Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce BlaBla, an open-source Python library for extracting linguistic\nfeatures with proven clinical relevance to neurological and psychiatric\ndiseases across many languages. BlaBla is a unifying framework for accelerating\nand simplifying clinical linguistic research. The library is built on\nstate-of-the-art NLP frameworks and supports multithreaded/GPU-enabled feature\nextraction via both native Python calls and a command line interface. We\ndescribe BlaBla's architecture and clinical validation of its features across\n12 diseases. We further demonstrate the application of BlaBla to a task\nvisualizing and classifying language disorders in three languages on real\nclinical data from the AphasiaBank dataset. We make the codebase freely\navailable to researchers with the hope of providing a consistent,\nwell-validated foundation for the next generation of clinical linguistic\nresearch.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 17:31:35 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Shivkumar", "Abhishek", ""], ["Weston", "Jack", ""], ["Lenain", "Raphael", ""], ["Fristed", "Emil", ""]]}, {"id": "2005.10220", "submitter": "Anush Sankaran", "authors": "Naveen Panwar, Tarun Tater, Anush Sankaran, Senthil Mani", "title": "Reducing Overlearning through Disentangled Representations by\n  Suppressing Unknown Tasks", "comments": "Added appendix with additional results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing deep learning approaches for learning visual features tend to\noverlearn and extract more information than what is required for the task at\nhand. From a privacy preservation perspective, the input visual information is\nnot protected from the model; enabling the model to become more intelligent\nthan it is trained to be. Current approaches for suppressing additional task\nlearning assume the presence of ground truth labels for the tasks to be\nsuppressed during training time. In this research, we propose a three-fold\nnovel contribution: (i) a model-agnostic solution for reducing model\noverlearning by suppressing all the unknown tasks, (ii) a novel metric to\nmeasure the trust score of a trained deep learning model, and (iii) a simulated\nbenchmark dataset, PreserveTask, having five different fundamental image\nclassification tasks to study the generalization nature of models. In the first\nset of experiments, we learn disentangled representations and suppress\noverlearning of five popular deep learning models: VGG16, VGG19, Inception-v1,\nMobileNet, and DenseNet on PreserverTask dataset. Additionally, we show results\nof our framework on color-MNIST dataset and practical applications of face\nattribute preservation in Diversity in Faces (DiF) and IMDB-Wiki dataset.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 17:31:44 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Panwar", "Naveen", ""], ["Tater", "Tarun", ""], ["Sankaran", "Anush", ""], ["Mani", "Senthil", ""]]}, {"id": "2005.10224", "submitter": "Nicholas H. Nelsen", "authors": "Nicholas H. Nelsen and Andrew M. Stuart", "title": "The Random Feature Model for Input-Output Maps between Banach Spaces", "comments": "To appear in SIAM Journal on Scientific Computing; 32 pages, 9\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Well known to the machine learning community, the random feature model is a\nparametric approximation to kernel interpolation or regression methods. It is\ntypically used to approximate functions mapping a finite-dimensional input\nspace to the real line. In this paper, we instead propose a methodology for use\nof the random feature model as a data-driven surrogate for operators that map\nan input Banach space to an output Banach space. Although the methodology is\nquite general, we consider operators defined by partial differential equations\n(PDEs); here, the inputs and outputs are themselves functions, with the input\nparameters being functions required to specify the problem, such as initial\ndata or coefficients, and the outputs being solutions of the problem. Upon\ndiscretization, the model inherits several desirable attributes from this\ninfinite-dimensional viewpoint, including mesh-invariant approximation error\nwith respect to the true PDE solution map and the capability to be trained at\none mesh resolution and then deployed at different mesh resolutions. We view\nthe random feature model as a non-intrusive data-driven emulator, provide a\nmathematical framework for its interpretation, and demonstrate its ability to\nefficiently and accurately approximate the nonlinear parameter-to-solution maps\nof two prototypical PDEs arising in physical science and engineering\napplications: viscous Burgers' equation and a variable coefficient elliptic\nequation.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 17:41:40 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 22:47:16 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Nelsen", "Nicholas H.", ""], ["Stuart", "Andrew M.", ""]]}, {"id": "2005.10227", "submitter": "Marcio Dorn", "authors": "Eduardo Avila, Marcio Dorn, Clarice Sampaio Alho, Alessandro Kahmann", "title": "Hemogram Data as a Tool for Decision-making in COVID-19 Management:\n  Applications to Resource Scarcity Scenarios", "comments": "14 pages, 5 figures, 2 tables, Tool Available at:\n  http://sbcb.inf.ufrgs.br/covid", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.OT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 pandemics has challenged emergency response systems worldwide, with\nwidespread reports of essential services breakdown and collapse of health care\nstructure. A critical element involves essential workforce management since\ncurrent protocols recommend release from duty for symptomatic individuals,\nincluding essential personnel. Testing capacity is also problematic in several\ncountries, where diagnosis demand outnumbers available local testing capacity.\nThis work describes a machine learning model derived from hemogram exam data\nperformed in symptomatic patients and how they can be used to predict qRT-PCR\ntest results. Methods: A Naive-Bayes model for machine learning is proposed for\nhandling different scarcity scenarios, including managing symptomatic essential\nworkforce and absence of diagnostic tests. Hemogram result data was used to\npredict qRT-PCR results in situations where the latter was not performed, or\nresults are not yet available. Adjusts in assumed prior probabilities allow\nfine-tuning of the model, according to actual prediction context. Proposed\nmodels can predict COVID-19 qRT-PCR results in symptomatic individuals with\nhigh accuracy, sensitivity and specificity. Data assessment can be performed in\nan individual or simultaneous basis, according to desired outcome. Based on\nhemogram data and background scarcity context, resource distribution is\nsignificantly optimized when model-based patient selection is observed,\ncompared to random choice. The model can help manage testing deficiency and\nother critical circumstances. Machine learning models can be derived from\nwidely available, quick, and inexpensive exam data in order to predict qRT-PCR\nresults used in COVID-19 diagnosis. These models can be used to assist\nstrategic decision-making in resource scarcity scenarios, including personnel\nshortage, lack of medical resources, and testing insufficiency.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 01:45:03 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Avila", "Eduardo", ""], ["Dorn", "Marcio", ""], ["Alho", "Clarice Sampaio", ""], ["Kahmann", "Alessandro", ""]]}, {"id": "2005.10242", "submitter": "Tongzhou Wang", "authors": "Tongzhou Wang, Phillip Isola", "title": "Understanding Contrastive Representation Learning through Alignment and\n  Uniformity on the Hypersphere", "comments": "International Conference on Machine Learning (ICML), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive representation learning has been outstandingly successful in\npractice. In this work, we identify two key properties related to the\ncontrastive loss: (1) alignment (closeness) of features from positive pairs,\nand (2) uniformity of the induced distribution of the (normalized) features on\nthe hypersphere. We prove that, asymptotically, the contrastive loss optimizes\nthese properties, and analyze their positive effects on downstream tasks.\nEmpirically, we introduce an optimizable metric to quantify each property.\nExtensive experiments on standard vision and language datasets confirm the\nstrong agreement between both metrics and downstream task performance.\nRemarkably, directly optimizing for these two metrics leads to representations\nwith comparable or better performance at downstream tasks than contrastive\nlearning.\n  Project Page: https://ssnl.github.io/hypersphere\n  Code: https://github.com/SsnL/align_uniform ,\nhttps://github.com/SsnL/moco_align_uniform\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 17:59:57 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 19:20:12 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 05:55:54 GMT"}, {"version": "v4", "created": "Mon, 1 Jun 2020 05:16:32 GMT"}, {"version": "v5", "created": "Wed, 17 Jun 2020 04:47:28 GMT"}, {"version": "v6", "created": "Mon, 24 Aug 2020 23:22:08 GMT"}, {"version": "v7", "created": "Sun, 1 Nov 2020 19:27:13 GMT"}, {"version": "v8", "created": "Sat, 7 Nov 2020 04:28:08 GMT"}, {"version": "v9", "created": "Tue, 10 Nov 2020 07:05:17 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Wang", "Tongzhou", ""], ["Isola", "Phillip", ""]]}, {"id": "2005.10243", "submitter": "Yonglong Tian", "authors": "Yonglong Tian, Chen Sun, Ben Poole, Dilip Krishnan, Cordelia Schmid,\n  Phillip Isola", "title": "What Makes for Good Views for Contrastive Learning?", "comments": "NeurIPS 2020. Project page: https://hobbitlong.github.io/InfoMin/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive learning between multiple views of the data has recently achieved\nstate of the art performance in the field of self-supervised representation\nlearning. Despite its success, the influence of different view choices has been\nless studied. In this paper, we use theoretical and empirical analysis to\nbetter understand the importance of view selection, and argue that we should\nreduce the mutual information (MI) between views while keeping task-relevant\ninformation intact. To verify this hypothesis, we devise unsupervised and\nsemi-supervised frameworks that learn effective views by aiming to reduce their\nMI. We also consider data augmentation as a way to reduce MI, and show that\nincreasing data augmentation indeed leads to decreasing MI and improves\ndownstream classification accuracy. As a by-product, we achieve a new\nstate-of-the-art accuracy on unsupervised pre-training for ImageNet\nclassification ($73\\%$ top-1 linear readout with a ResNet-50). In addition,\ntransferring our models to PASCAL VOC object detection and COCO instance\nsegmentation consistently outperforms supervised pre-training.\nCode:http://github.com/HobbitLong/PyContrast\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 17:59:57 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 18:59:33 GMT"}, {"version": "v3", "created": "Fri, 18 Dec 2020 10:01:34 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Tian", "Yonglong", ""], ["Sun", "Chen", ""], ["Poole", "Ben", ""], ["Krishnan", "Dilip", ""], ["Schmid", "Cordelia", ""], ["Isola", "Phillip", ""]]}, {"id": "2005.10247", "submitter": "Alexander Robey", "authors": "Alexander Robey, Hamed Hassani, George J. Pappas", "title": "Model-Based Robust Deep Learning: Generalizing to Natural,\n  Out-of-Distribution Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has resulted in major breakthroughs in many application\ndomains, the frameworks commonly used in deep learning remain fragile to\nartificially-crafted and imperceptible changes in the data. In response to this\nfragility, adversarial training has emerged as a principled approach for\nenhancing the robustness of deep learning with respect to norm-bounded\nperturbations. However, there are other sources of fragility for deep learning\nthat are arguably more common and less thoroughly studied. Indeed, natural\nvariation such as lighting or weather conditions can significantly degrade the\naccuracy of trained neural networks, proving that such natural variation\npresents a significant challenge for deep learning.\n  In this paper, we propose a paradigm shift from perturbation-based\nadversarial robustness toward model-based robust deep learning. Our objective\nis to provide general training algorithms that can be used to train deep neural\nnetworks to be robust against natural variation in data. Critical to our\nparadigm is first obtaining a model of natural variation which can be used to\nvary data over a range of natural conditions. Such models may be either known a\npriori or else learned from data. In the latter case, we show that deep\ngenerative models can be used to learn models of natural variation that are\nconsistent with realistic conditions. We then exploit such models in three\nnovel model-based robust training algorithms in order to enhance the robustness\nof deep learning with respect to the given model. Our extensive experiments\nshow that across a variety of naturally-occurring conditions and across various\ndatasets, deep neural networks trained with our model-based algorithms\nsignificantly outperform both standard deep learning algorithms as well as\nnorm-bounded robust deep learning algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 13:46:31 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 13:20:37 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Robey", "Alexander", ""], ["Hassani", "Hamed", ""], ["Pappas", "George J.", ""]]}, {"id": "2005.10284", "submitter": "Arash Rahnama", "authors": "Arash Rahnama and Andrew Tseng", "title": "An Adversarial Approach for Explaining the Predictions of Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models have been successfully applied to a wide range of\napplications including computer vision, natural language processing, and speech\nrecognition. A successful implementation of these models however, usually\nrelies on deep neural networks (DNNs) which are treated as opaque black-box\nsystems due to their incomprehensible complexity and intricate internal\nmechanism. In this work, we present a novel algorithm for explaining the\npredictions of a DNN using adversarial machine learning. Our approach\nidentifies the relative importance of input features in relation to the\npredictions based on the behavior of an adversarial attack on the DNN. Our\nalgorithm has the advantage of being fast, consistent, and easy to implement\nand interpret. We present our detailed analysis that demonstrates how the\nbehavior of an adversarial attack, given a DNN and a task, stays consistent for\nany input test data point proving the generality of our approach. Our analysis\nenables us to produce consistent and efficient explanations. We illustrate the\neffectiveness of our approach by conducting experiments using a variety of\nDNNs, tasks, and datasets. Finally, we compare our work with other well-known\ntechniques in the current literature.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 18:06:53 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 19:42:44 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 15:43:34 GMT"}, {"version": "v4", "created": "Mon, 28 Sep 2020 16:17:36 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Rahnama", "Arash", ""], ["Tseng", "Andrew", ""]]}, {"id": "2005.10294", "submitter": "Marko Stamenovic", "authors": "Marko Stamenovic", "title": "Towards Cover Song Detection with Siamese Convolutional Neural Networks", "comments": "Code available at\n  https://github.com/markostam/coversongs-dual-convnet", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, Stockholm, Sweden, PMLR 80, 2018", "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A cover song, by definition, is a new performance or recording of a\npreviously recorded, commercially released song. It may be by the original\nartist themselves or a different artist altogether and can vary from the\noriginal in unpredictable ways including key, arrangement, instrumentation,\ntimbre and more. In this work we propose a novel approach to learning audio\nrepresentations for the task of cover song detection. We train a neural\narchitecture on tens of thousands of cover-song audio clips and test it on a\nheld out set. We obtain a mean precision@1 of 65% over mini-batches, ten times\nbetter than random guessing. Our results indicate that Siamese network\nconfigurations show promise for approaching the cover song identification\nproblem.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 18:14:41 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Stamenovic", "Marko", ""]]}, {"id": "2005.10296", "submitter": "Ajith Suresh", "authors": "Nishat Koti, Mahak Pancholi, Arpita Patra, Ajith Suresh", "title": "SWIFT: Super-fast and Robust Privacy-Preserving Machine Learning", "comments": "This article is the full and extended version of an article to appear\n  in USENIX Security 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Performing machine learning (ML) computation on private data while\nmaintaining data privacy, aka Privacy-preserving Machine Learning~(PPML), is an\nemergent field of research. Recently, PPML has seen a visible shift towards the\nadoption of the Secure Outsourced Computation~(SOC) paradigm due to the heavy\ncomputation that it entails. In the SOC paradigm, computation is outsourced to\na set of powerful and specially equipped servers that provide service on a\npay-per-use basis. In this work, we propose SWIFT, a robust PPML framework for\na range of ML algorithms in SOC setting, that guarantees output delivery to the\nusers irrespective of any adversarial behaviour. Robustness, a highly desirable\nfeature, evokes user participation without the fear of denial of service.\n  At the heart of our framework lies a highly-efficient, maliciously-secure,\nthree-party computation (3PC) over rings that provides guaranteed output\ndelivery (GOD) in the honest-majority setting. To the best of our knowledge,\nSWIFT is the first robust and efficient PPML framework in the 3PC setting.\nSWIFT is as fast as (and is strictly better in some cases than) the best-known\n3PC framework BLAZE (Patra et al. NDSS'20), which only achieves fairness. We\nextend our 3PC framework for four parties (4PC). In this regime, SWIFT is as\nfast as the best known fair 4PC framework Trident (Chaudhari et al. NDSS'20)\nand twice faster than the best-known robust 4PC framework FLASH (Byali et al.\nPETS'20).\n  We demonstrate our framework's practical relevance by benchmarking popular ML\nalgorithms such as Logistic Regression and deep Neural Networks such as VGG16\nand LeNet, both over a 64-bit ring in a WAN setting. For deep NN, our results\ntestify to our claims that we provide improved security guarantee while\nincurring no additional overhead for 3PC and obtaining 2x improvement for 4PC.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 18:20:23 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 08:26:09 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2021 08:47:28 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Koti", "Nishat", ""], ["Pancholi", "Mahak", ""], ["Patra", "Arpita", ""], ["Suresh", "Ajith", ""]]}, {"id": "2005.10300", "submitter": "Kyle Crandall", "authors": "Kyle Crandall and Dustin Webb", "title": "Consensus Driven Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  As the complexity of our neural network models grow, so too do the data and\ncomputation requirements for successful training. One proposed solution to this\nproblem is training on a distributed network of computational devices, thus\ndistributing the computational and data storage loads. This strategy has\nalready seen some adoption by the likes of Google and other companies. In this\npaper we propose a new method of distributed, decentralized learning that\nallows a network of computation nodes to coordinate their training using\nasynchronous updates over an unreliable network while only having access to a\nlocal dataset. This is achieved by taking inspiration from Distributed\nAveraging Consensus algorithms to coordinate the various nodes. Sharing the\ninternal model instead of the training data allows the original raw data to\nremain with the computation node. The asynchronous nature and lack of\ncentralized coordination allows this paradigm to function with limited\ncommunication requirements. We demonstrate our method on the MNIST, Fashion\nMNIST, and CIFAR10 datasets. We show that our coordination method allows models\nto be learned on highly biased datasets, and in the presence of intermittent\ncommunication failure.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 18:24:19 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Crandall", "Kyle", ""], ["Webb", "Dustin", ""]]}, {"id": "2005.10321", "submitter": "Marko Stamenovic", "authors": "Marko Stamenovic, Jeibo Luo", "title": "Machine Identification of High Impact Research through Text and Image\n  Analysis", "comments": null, "journal-ref": "2017 IEEE Third International Conference on Multimedia Big Data\n  (BigMM)", "doi": "10.1109/BigMM.2017.63", "report-no": null, "categories": "cs.IR cs.DL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The volume of academic paper submissions and publications is growing at an\never increasing rate. While this flood of research promises progress in various\nfields, the sheer volume of output inherently increases the amount of noise. We\npresent a system to automatically separate papers with a high from those with a\nlow likelihood of gaining citations as a means to quickly find high impact,\nhigh quality research. Our system uses both a visual classifier, useful for\nsurmising a document's overall appearance, and a text classifier, for making\ncontent-informed decisions. Current work in the field focuses on small datasets\ncomposed of papers from individual conferences. Attempts to use similar\ntechniques on larger datasets generally only considers excerpts of the\ndocuments such as the abstract, potentially throwing away valuable data. We\nrectify these issues by providing a dataset composed of PDF documents and\ncitation counts spanning a decade of output within two separate academic\ndomains: computer science and medicine. This new dataset allows us to expand on\ncurrent work in the field by generalizing across time and academic domain.\nMoreover, we explore inter-domain prediction models - evaluating a classifier's\nperformance on a domain it was not trained on - to shed further insight on this\nimportant problem.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 19:12:24 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Stamenovic", "Marko", ""], ["Luo", "Jeibo", ""]]}, {"id": "2005.10322", "submitter": "Felice Antonio Merra", "authors": "Yashar Deldjoo and Tommaso Di Noia and Felice Antonio Merra", "title": "A survey on Adversarial Recommender Systems: from Attack/Defense\n  strategies to Generative Adversarial Networks", "comments": "37 pages, submitted to journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent-factor models (LFM) based on collaborative filtering (CF), such as\nmatrix factorization (MF) and deep CF methods, are widely used in modern\nrecommender systems (RS) due to their excellent performance and recommendation\naccuracy. However, success has been accompanied with a major new arising\nchallenge: many applications of machine learning (ML) are adversarial in\nnature. In recent years, it has been shown that these methods are vulnerable to\nadversarial examples, i.e., subtle but non-random perturbations designed to\nforce recommendation models to produce erroneous outputs.\n  The goal of this survey is two-fold: (i) to present recent advances on\nadversarial machine learning (AML) for the security of RS (i.e., attacking and\ndefense recommendation models), (ii) to show another successful application of\nAML in generative adversarial networks (GANs) for generative applications,\nthanks to their ability for learning (high-dimensional) data distributions. In\nthis survey, we provide an exhaustive literature review of 74 articles\npublished in major RS and ML journals and conferences. This review serves as a\nreference for the RS community, working on the security of RS or on generative\nmodels using GANs to improve their quality.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 19:17:11 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 10:48:34 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Deldjoo", "Yashar", ""], ["Di Noia", "Tommaso", ""], ["Merra", "Felice Antonio", ""]]}, {"id": "2005.10348", "submitter": "Hiram Ponce", "authors": "Jose Roberto Ayala-Solares, Hiram Ponce", "title": "Supervised learning with artificial hydrocarbon networks: an open source\n  implementation and its applications", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial hydrocarbon networks (AHN) is a novel supervised learning method\ninspired on the structure and the inner chemical mechanisms of organic\ncompounds. As any other cutting-edge algorithm, there are two challenges to be\nfaced: time-consuming for encoding and complications to connect with other\ntechnologies. Large and open source platforms have proved to be an alternative\nsolution to the latter challenges. In that sense, this paper aims to introduce\nthe ahnr package for R that implements AHN. It provides several functions to\ncreate, train, test and visualize AHN. It also includes conventional functions\nto easily interact with the trained models. For illustration purposes, it\npresents several examples about the applications of AHN in engineering, as well\nas, the way to use it. This package is intended to be very useful for\nscientists and applied researchers interested in machine learning and data\nmodeling. Package availability is in the Comprehensive R Archive Network.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 20:40:39 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Ayala-Solares", "Jose Roberto", ""], ["Ponce", "Hiram", ""]]}, {"id": "2005.10349", "submitter": "Benjamin Dutton", "authors": "Benjamin Dutton", "title": "Adversarial Canonical Correlation Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical Correlation Analysis (CCA) is a statistical technique used to\nextract common information from multiple data sources or views. It has been\nused in various representation learning problems, such as dimensionality\nreduction, word embedding, and clustering. Recent work has given CCA\nprobabilistic footing in a deep learning context and uses a variational lower\nbound for the data log likelihood to estimate model parameters. Alternatively,\nadversarial techniques have arisen in recent years as a powerful alternative to\nvariational Bayesian methods in autoencoders. In this work, we explore\nstraightforward adversarial alternatives to recent work in Deep Variational CCA\n(VCCA and VCCA-Private) we call ACCA and ACCA-Private and show how these\napproaches offer a stronger and more flexible way to match the approximate\nposteriors coming from encoders to much larger classes of priors than the VCCA\nand VCCA-Private models. This allows new priors for what constitutes a good\nrepresentation, such as disentangling underlying factors of variation, to be\nmore directly pursued. We offer further analysis on the multi-level\ndisentangling properties of VCCA-Private and ACCA-Private through the use of a\nnewly designed dataset we call Tangled MNIST. We also design a validation\ncriteria for these models that is theoretically grounded, task-agnostic, and\nworks well in practice. Lastly, we fill a minor research gap by deriving an\nadditional variational lower bound for VCCA that allows the representation to\nuse view-specific information from both input views.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 20:46:35 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 21:31:21 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Dutton", "Benjamin", ""]]}, {"id": "2005.10374", "submitter": "Jussi Leinonen", "authors": "Jussi Leinonen, Daniele Nerini, Alexis Berne", "title": "Stochastic Super-Resolution for Downscaling Time-Evolving Atmospheric\n  Fields with a Generative Adversarial Network", "comments": "Accepted for publication in IEEE Transactions in Geoscience and\n  Remote Sensing", "journal-ref": "IEEE Transactions on Geoscience and Remote Sensing, 2020", "doi": "10.1109/TGRS.2020.3032790", "report-no": null, "categories": "eess.IV cs.LG physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have been recently adopted for\nsuper-resolution, an application closely related to what is referred to as\n\"downscaling\" in the atmospheric sciences: improving the spatial resolution of\nlow-resolution images. The ability of conditional GANs to generate an ensemble\nof solutions for a given input lends itself naturally to stochastic\ndownscaling, but the stochastic nature of GANs is not usually considered in\nsuper-resolution applications. Here, we introduce a recurrent, stochastic\nsuper-resolution GAN that can generate ensembles of time-evolving\nhigh-resolution atmospheric fields for an input consisting of a low-resolution\nsequence of images of the same field. We test the GAN using two datasets, one\nconsisting of radar-measured precipitation from Switzerland, the other of cloud\noptical thickness derived from the Geostationary Earth Observing Satellite 16\n(GOES-16). We find that the GAN can generate realistic, temporally consistent\nsuper-resolution sequences for both datasets. The statistical properties of the\ngenerated ensemble are analyzed using rank statistics, a method adapted from\nensemble weather forecasting; these analyses indicate that the GAN produces\nclose to the correct amount of variability in its outputs. As the GAN generator\nis fully convolutional, it can be applied after training to input images larger\nthan the images used to train it. It is also able to generate time series much\nlonger than the training sequences, as demonstrated by applying the generator\nto a three-month dataset of the precipitation radar data. The source code to\nour GAN is available at https://github.com/jleinonen/downscaling-rnn-gan.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 22:06:52 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 13:45:17 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2020 14:41:17 GMT"}, {"version": "v4", "created": "Mon, 19 Oct 2020 14:28:34 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Leinonen", "Jussi", ""], ["Nerini", "Daniele", ""], ["Berne", "Alexis", ""]]}, {"id": "2005.10391", "submitter": "Caio Souza", "authors": "Caio Souza and Luiz Velho", "title": "Deep Reinforcement Learning for High Level Character Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the use of traditional animations, heuristic\nbehavior and reinforcement learning in the creation of intelligent characters\nfor computational media. The traditional animation and heuristic gives artistic\ncontrol over the behavior while the reinforcement learning adds generalization.\nThe use case presented is a dog character with a high-level controller in a 3D\nenvironment which is built around the desired behaviors to be learned, such as\nfetching an item. As the development of the environment is the key for\nlearning, further analysis is conducted of how to build those learning\nenvironments, the effects of environment and agent modeling choices, training\nprocedures and generalization of the learned behavior. This analysis builds\ninsight of the aforementioned factors and may serve as guide in the development\nof environments in general.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 23:32:19 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Souza", "Caio", ""], ["Velho", "Luiz", ""]]}, {"id": "2005.10400", "submitter": "Zhichao Jiang", "authors": "Kosuke Imai, Zhichao Jiang", "title": "Principal Fairness for Human and Algorithmic Decision-Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the concept of principal stratification from the causal inference\nliterature, we introduce a new notion of fairness, called principal fairness,\nfor human and algorithmic decision-making. The key idea is that one should not\ndiscriminate among individuals who would be similarly affected by the decision.\nUnlike the existing statistical definitions of fairness, principal fairness\nexplicitly accounts for the fact that individuals can be impacted by the\ndecision. We propose an axiomatic assumption that all groups are created equal.\nThis assumption is motivated by a belief that protected attributes such as race\nand gender should have no direct causal effects on potential outcomes. Under\nthis assumption, we show that principal fairness implies all three existing\nstatistical fairness criteria once we account for relevant covariates. This\nresult also highlights the essential role of conditioning covariates in\nresolving the previously recognized tradeoffs between the existing statistical\nfairness criteria. Finally, we discuss how to empirically choose conditioning\ncovariates and then evaluate the principal fairness of a particular decision.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 00:24:54 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 03:48:41 GMT"}, {"version": "v3", "created": "Fri, 25 Sep 2020 00:51:42 GMT"}, {"version": "v4", "created": "Thu, 14 Jan 2021 02:25:12 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Imai", "Kosuke", ""], ["Jiang", "Zhichao", ""]]}, {"id": "2005.10402", "submitter": "Fanglin Chen", "authors": "Fanglin Chen, Xiao Liu, Davide Proserpio, Isamar Troncoso, Feiyu Xiong", "title": "Studying Product Competition Using Representation Learning", "comments": "8 pages, to be published in SIGIR '20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studying competition and market structure at the product level instead of\nbrand level can provide firms with insights on cannibalization and product line\noptimization. However, it is computationally challenging to analyze\nproduct-level competition for the millions of products available on e-commerce\nplatforms. We introduce Product2Vec, a method based on the representation\nlearning algorithm Word2Vec, to study product-level competition, when the\nnumber of products is large. The proposed model takes shopping baskets as\ninputs and, for every product, generates a low-dimensional embedding that\npreserves important product information. In order for the product embeddings to\nbe useful for firm strategic decision making, we leverage economic theories and\ncausal inference to propose two modifications to Word2Vec. First of all, we\ncreate two measures, complementarity and exchangeability, that allow us to\ndetermine whether product pairs are complements or substitutes. Second, we\ncombine these vectors with random utility-based choice models to forecast\ndemand. To accurately estimate price elasticities, i.e., how demand responds to\nchanges in price, we modify Word2Vec by removing the influence of price from\nthe product vectors. We show that, compared with state-of-the-art models, our\napproach is faster, and can produce more accurate demand forecasts and price\nelasticities.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 00:36:13 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Chen", "Fanglin", ""], ["Liu", "Xiao", ""], ["Proserpio", "Davide", ""], ["Troncoso", "Isamar", ""], ["Xiong", "Feiyu", ""]]}, {"id": "2005.10406", "submitter": "Andrew Hard", "authors": "Andrew Hard, Kurt Partridge, Cameron Nguyen, Niranjan Subrahmanya,\n  Aishanee Shah, Pai Zhu, Ignacio Lopez Moreno, Rajiv Mathews", "title": "Training Keyword Spotting Models on Non-IID Data with Federated Learning", "comments": "Submitted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We demonstrate that a production-quality keyword-spotting model can be\ntrained on-device using federated learning and achieve comparable false accept\nand false reject rates to a centrally-trained model. To overcome the\nalgorithmic constraints associated with fitting on-device data (which are\ninherently non-independent and identically distributed), we conduct thorough\nempirical studies of optimization algorithms and hyperparameter configurations\nusing large-scale federated simulations. To overcome resource constraints, we\nreplace memory intensive MTR data augmentation with SpecAugment, which reduces\nthe false reject rate by 56%. Finally, to label examples (given the zero\nvisibility into on-device data), we explore teacher-student training.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 00:53:33 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 17:52:52 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Hard", "Andrew", ""], ["Partridge", "Kurt", ""], ["Nguyen", "Cameron", ""], ["Subrahmanya", "Niranjan", ""], ["Shah", "Aishanee", ""], ["Zhu", "Pai", ""], ["Moreno", "Ignacio Lopez", ""], ["Mathews", "Rajiv", ""]]}, {"id": "2005.10407", "submitter": "Van Tung Pham", "authors": "Zhiping Zeng, Van Tung Pham, Haihua Xu, Yerbolat Khassanov, Eng Siong\n  Chng, Chongjia Ni and Bin Ma", "title": "Leveraging Text Data Using Hybrid Transformer-LSTM Based End-to-End ASR\n  in Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study leveraging extra text data to improve low-resource\nend-to-end ASR under cross-lingual transfer learning setting. To this end, we\nextend our prior work [1], and propose a hybrid Transformer-LSTM based\narchitecture. This architecture not only takes advantage of the highly\neffective encoding capacity of the Transformer network but also benefits from\nextra text data due to the LSTM-based independent language model network. We\nconduct experiments on our in-house Malay corpus which contains limited labeled\ndata and a large amount of extra text. Results show that the proposed\narchitecture outperforms the previous LSTM-based architecture [1] by 24.2%\nrelative word error rate (WER) when both are trained using limited labeled\ndata. Starting from this, we obtain further 25.4% relative WER reduction by\ntransfer learning from another resource-rich language. Moreover, we obtain\nadditional 13.6% relative WER reduction by boosting the LSTM decoder of the\ntransferred model with the extra text data. Overall, our best model outperforms\nthe vanilla Transformer ASR by 11.9% relative WER. Last but not least, the\nproposed hybrid architecture offers much faster inference compared to both LSTM\nand Transformer architectures.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 00:56:42 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 09:35:42 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Zeng", "Zhiping", ""], ["Pham", "Van Tung", ""], ["Xu", "Haihua", ""], ["Khassanov", "Yerbolat", ""], ["Chng", "Eng Siong", ""], ["Ni", "Chongjia", ""], ["Ma", "Bin", ""]]}, {"id": "2005.10411", "submitter": "Zixuan Huang", "authors": "Zixuan Huang, Yin Li", "title": "Interpretable and Accurate Fine-grained Recognition via Region Grouping", "comments": "Accepted to CVPR 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an interpretable deep model for fine-grained visual recognition.\nAt the core of our method lies the integration of region-based part discovery\nand attribution within a deep neural network. Our model is trained using\nimage-level object labels, and provides an interpretation of its results via\nthe segmentation of object parts and the identification of their contributions\ntowards classification. To facilitate the learning of object parts without\ndirect supervision, we explore a simple prior of the occurrence of object\nparts. We demonstrate that this prior, when combined with our region-based part\ndiscovery and attribution, leads to an interpretable model that remains highly\naccurate. Our model is evaluated on major fine-grained recognition datasets,\nincluding CUB-200, CelebA and iNaturalist. Our results compare favorably to\nstate-of-the-art methods on classification tasks, and our method outperforms\nprevious approaches on the localization of object parts.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 01:18:26 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Huang", "Zixuan", ""], ["Li", "Yin", ""]]}, {"id": "2005.10416", "submitter": "Abdelrahman Abdallah", "authors": "Abdelrahman Abdallah, Mahmoud Kasem, Mohamed Hamada, and Shaymaa Sdeek", "title": "Automated Question Answer medical model based on Deep Learning\n  Technology", "comments": null, "journal-ref": "ICEMIS'20: Proceedings of the 6th International Conference on\n  Engineering & MIS 2020", "doi": "10.1145/3410352.3410744", "report-no": "13", "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence can now provide more solutions for different\nproblems, especially in the medical field. One of those problems the lack of\nanswers to any given medical/health-related question. The Internet is full of\nforums that allow people to ask some specific questions and get great answers\nfor them. Nevertheless, browsing these questions in order to locate one similar\nto your own, also finding a satisfactory answer is a difficult and\ntime-consuming task. This research will introduce a solution to this problem by\nautomating the process of generating qualified answers to these questions and\ncreating a kind of digital doctor. Furthermore, this research will train an\nend-to-end model using the framework of RNN and the encoder-decoder to generate\nsensible and useful answers to a small set of medical/health issues. The\nproposed model was trained and evaluated using data from various online\nservices, such as WebMD, HealthTap, eHealthForums, and iCliniq.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 01:40:01 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Abdallah", "Abdelrahman", ""], ["Kasem", "Mahmoud", ""], ["Hamada", "Mohamed", ""], ["Sdeek", "Shaymaa", ""]]}, {"id": "2005.10418", "submitter": "Liam Schramm", "authors": "Liam Schramm, Avishai Sintov, and Abdeslam Boularias", "title": "Learning to Transfer Dynamic Models of Underactuated Soft Robotic Hands", "comments": "ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning is a popular approach to bypassing data limitations in one\ndomain by leveraging data from another domain. This is especially useful in\nrobotics, as it allows practitioners to reduce data collection with physical\nrobots, which can be time-consuming and cause wear and tear. The most common\nway of doing this with neural networks is to take an existing neural network,\nand simply train it more with new data. However, we show that in some\nsituations this can lead to significantly worse performance than simply using\nthe transferred model without adaptation. We find that a major cause of these\nproblems is that models trained on small amounts of data can have chaotic or\ndivergent behavior in some regions. We derive an upper bound on the Lyapunov\nexponent of a trained transition model, and demonstrate two approaches that\nmake use of this insight. Both show significant improvement over traditional\nfine-tuning. Experiments performed on real underactuated soft robotic hands\nclearly demonstrate the capability to transfer a dynamic model from one hand to\nanother.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 01:46:59 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Schramm", "Liam", ""], ["Sintov", "Avishai", ""], ["Boularias", "Abdeslam", ""]]}, {"id": "2005.10419", "submitter": "Aditya Menon", "authors": "Aditya Krishna Menon, Ankit Singh Rawat, Sashank J. Reddi, Seungyeon\n  Kim, and Sanjiv Kumar", "title": "Why distillation helps: a statistical perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Knowledge distillation is a technique for improving the performance of a\nsimple \"student\" model by replacing its one-hot training labels with a\ndistribution over labels obtained from a complex \"teacher\" model. While this\nsimple approach has proven widely effective, a basic question remains\nunresolved: why does distillation help? In this paper, we present a statistical\nperspective on distillation which addresses this question, and provides a novel\nconnection to extreme multiclass retrieval techniques. Our core observation is\nthat the teacher seeks to estimate the underlying (Bayes) class-probability\nfunction. Building on this, we establish a fundamental bias-variance tradeoff\nin the student's objective: this quantifies how approximate knowledge of these\nclass-probabilities can significantly aid learning. Finally, we show how\ndistillation complements existing negative mining techniques for extreme\nmulticlass retrieval, and propose a unified objective which combines these\nideas.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 01:49:51 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Menon", "Aditya Krishna", ""], ["Rawat", "Ankit Singh", ""], ["Reddi", "Sashank J.", ""], ["Kim", "Seungyeon", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "2005.10430", "submitter": "Jungseock Joo", "authors": "Jungseock Joo, Kimmo K\\\"arkk\\\"ainen", "title": "Gender Slopes: Counterfactual Fairness for Computer Vision Models by\n  Attribute Manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated computer vision systems have been applied in many domains including\nsecurity, law enforcement, and personal devices, but recent reports suggest\nthat these systems may produce biased results, discriminating against people in\ncertain demographic groups. Diagnosing and understanding the underlying true\ncauses of model biases, however, are challenging tasks because modern computer\nvision systems rely on complex black-box models whose behaviors are hard to\ndecode. We propose to use an encoder-decoder network developed for image\nattribute manipulation to synthesize facial images varying in the dimensions of\ngender and race while keeping other signals intact. We use these synthesized\nimages to measure counterfactual fairness of commercial computer vision\nclassifiers by examining the degree to which these classifiers are affected by\ngender and racial cues controlled in the images, e.g., feminine faces may\nelicit higher scores for the concept of nurse and lower scores for STEM-related\nconcepts. We also report the skewed gender representations in an online search\nservice on profession-related keywords, which may explain the origin of the\nbiases encoded in the models.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 02:33:28 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Joo", "Jungseock", ""], ["K\u00e4rkk\u00e4inen", "Kimmo", ""]]}, {"id": "2005.10434", "submitter": "Yu Song", "authors": "Yu Song, Zilong Huang, Chuanyue Shen, Humphrey Shi, and David A Lange", "title": "Deep Learning-Based Automated Image Segmentation for Concrete\n  Petrographic Analysis", "comments": "Accepted as a journal publication by Cement & Concrete Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard petrography test method for measuring air voids in concrete\n(ASTM C457) requires a meticulous and long examination of sample phase\ncomposition under a stereomicroscope. The high expertise and specialized\nequipment discourage this test for routine concrete quality control. Though the\ntask can be alleviated with the aid of color-based image segmentation,\nadditional surface color treatment is required. Recently, deep learning\nalgorithms using convolutional neural networks (CNN) have achieved\nunprecedented segmentation performance on image testing benchmarks. In this\nstudy, we investigated the feasibility of using CNN to conduct concrete\nsegmentation without the use of color treatment. The CNN demonstrated a strong\npotential to process a wide range of concretes, including those not involved in\nmodel training. The experimental results showed that CNN outperforms the\ncolor-based segmentation by a considerable margin, and has comparable accuracy\nto human experts. Furthermore, the segmentation time is reduced to mere\nseconds.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 02:46:29 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 06:01:27 GMT"}, {"version": "v3", "created": "Thu, 28 May 2020 20:16:26 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Song", "Yu", ""], ["Huang", "Zilong", ""], ["Shen", "Chuanyue", ""], ["Shi", "Humphrey", ""], ["Lange", "David A", ""]]}, {"id": "2005.10439", "submitter": "Kelei He", "authors": "Kelei He, Chunfeng Lian, Bing Zhang, Xin Zhang, Xiaohuan Cao, Dong\n  Nie, Yang Gao, Junfeng Zhang, Dinggang Shen", "title": "HF-UNet: Learning Hierarchically Inter-Task Relevance in Multi-Task\n  U-Net for Accurate Prostate Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate segmentation of the prostate is a key step in external beam\nradiation therapy treatments. In this paper, we tackle the challenging task of\nprostate segmentation in CT images by a two-stage network with 1) the first\nstage to fast localize, and 2) the second stage to accurately segment the\nprostate. To precisely segment the prostate in the second stage, we formulate\nprostate segmentation into a multi-task learning framework, which includes a\nmain task to segment the prostate, and an auxiliary task to delineate the\nprostate boundary. Here, the second task is applied to provide additional\nguidance of unclear prostate boundary in CT images. Besides, the conventional\nmulti-task deep networks typically share most of the parameters (i.e., feature\nrepresentations) across all tasks, which may limit their data fitting ability,\nas the specificities of different tasks are inevitably ignored. By contrast, we\nsolve them by a hierarchically-fused U-Net structure, namely HF-UNet. The\nHF-UNet has two complementary branches for two tasks, with the novel proposed\nattention-based task consistency learning block to communicate at each level\nbetween the two decoding branches. Therefore, HF-UNet endows the ability to\nlearn hierarchically the shared representations for different tasks, and\npreserve the specificities of learned representations for different tasks\nsimultaneously. We did extensive evaluations of the proposed method on a large\nplanning CT image dataset, including images acquired from 339 patients. The\nexperimental results show HF-UNet outperforms the conventional multi-task\nnetwork architectures and the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 02:53:52 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 13:26:25 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["He", "Kelei", ""], ["Lian", "Chunfeng", ""], ["Zhang", "Bing", ""], ["Zhang", "Xin", ""], ["Cao", "Xiaohuan", ""], ["Nie", "Dong", ""], ["Gao", "Yang", ""], ["Zhang", "Junfeng", ""], ["Shen", "Dinggang", ""]]}, {"id": "2005.10441", "submitter": "Zexin Cai", "authors": "Zexin Cai, Yaogen Yang, Ming Li", "title": "Cross-lingual Multispeaker Text-to-Speech under Limited-Data Scenario", "comments": "in preparation for Neural Networks journal Special issue on Advances\n  in Deep Learning Based Speech Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling voices for multiple speakers and multiple languages in one\ntext-to-speech system has been a challenge for a long time. This paper presents\nan extension on Tacotron2 to achieve bilingual multispeaker speech synthesis\nwhen there are limited data for each language. We achieve cross-lingual\nsynthesis, including code-switching cases, between English and Mandarin for\nmonolingual speakers. The two languages share the same phonemic representations\nfor input, while the language attribute and the speaker identity are\nindependently controlled by language tokens and speaker embeddings,\nrespectively. In addition, we investigate the model's performance on the\ncross-lingual synthesis, with and without a bilingual dataset during training.\nWith the bilingual dataset, not only can the model generate high-fidelity\nspeech for all speakers concerning the language they speak, but also can\ngenerate accented, yet fluent and intelligible speech for monolingual speakers\nregarding non-native language. For example, the Mandarin speaker can speak\nEnglish fluently. Furthermore, the model trained with bilingual dataset is\nrobust for code-switching text-to-speech, as shown in our results and provided\nsamples.{https://caizexin.github.io/mlms-syn-samples/index.html}.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 03:03:34 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Cai", "Zexin", ""], ["Yang", "Yaogen", ""], ["Li", "Ming", ""]]}, {"id": "2005.10442", "submitter": "Naoto Sato", "authors": "Naoto Sato, Hironobu Kuruma, and Hideto Ogawa", "title": "Unsupposable Test-data Generation for Machine-learned Software", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As for software development by machine learning, a trained model is evaluated\nby using part of an existing dataset as test data. However, if data with\ncharacteristics that differ from the existing data is input, the model does not\nalways behave as expected. Accordingly, to confirm the behavior of the model\nmore strictly, it is necessary to create data that differs from the existing\ndata and test the model with that different data. The data to be tested\nincludes not only data that developers can suppose (supposable data) but also\ndata they cannot suppose (unsupposable data). To confirm the behavior of the\nmodel strictly, it is important to create as much unsupposable data as\npossible. In this study, therefore, a method called \"unsupposable test-data\ngeneration\" (UTG)---for giving suggestions for unsupposable data to model\ndevelopers and testers---is proposed. UTG uses a variational autoencoder (VAE)\nto generate unsupposable data. The unsupposable data is generated by acquiring\nlatent values with low occurrence probability in the prior distribution of the\nVAE and inputting the acquired latent values into the decoder. If unsupposable\ndata is included in the data generated by the decoder, the developer can\nrecognize new unsupposable features by referring to the data. On the basis of\nthose unsupposable features, the developer will be able to create other\nunsupposable data with the same features. The proposed UTG was applied to the\nMNIST dataset and the House Sales Price dataset. The results demonstrate the\nfeasibility of UTG.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 03:04:22 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Sato", "Naoto", ""], ["Kuruma", "Hironobu", ""], ["Ogawa", "Hideto", ""]]}, {"id": "2005.10451", "submitter": "Li Shen", "authors": "Yucong Shen, Li Shen, Hao-Zhi Huang, Xuan Wang, Wei Liu", "title": "CPOT: Channel Pruning via Optimal Transport", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep neural networks (DNNs) lead to tremendously growing\nnetwork parameters, making the deployments of DNNs on platforms with limited\nresources extremely difficult. Therefore, various pruning methods have been\ndeveloped to compress the deep network architectures and accelerate the\ninference process. Most of the existing channel pruning methods discard the\nless important filters according to well-designed filter ranking criteria.\nHowever, due to the limited interpretability of deep learning models, designing\nan appropriate ranking criterion to distinguish redundant filters is difficult.\nTo address such a challenging issue, we propose a new technique of Channel\nPruning via Optimal Transport, dubbed CPOT. Specifically, we locate the\nWasserstein barycenter for channels of each layer in the deep models, which is\nthe mean of a set of probability distributions under the optimal transport\nmetric. Then, we prune the redundant information located by Wasserstein\nbarycenters. At last, we empirically demonstrate that, for classification\ntasks, CPOT outperforms the state-of-the-art methods on pruning ResNet-20,\nResNet-32, ResNet-56, and ResNet-110. Furthermore, we show that the proposed\nCPOT technique is good at compressing the StarGAN models by pruning in the more\ndifficult case of image-to-image translation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 03:43:09 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Shen", "Yucong", ""], ["Shen", "Li", ""], ["Huang", "Hao-Zhi", ""], ["Wang", "Xuan", ""], ["Liu", "Wei", ""]]}, {"id": "2005.10473", "submitter": "Adit Krishnan", "authors": "Adit Krishnan, Mahashweta Das, Mangesh Bendre, Hao Yang, Hari Sundaram", "title": "Transfer Learning via Contextual Invariants for One-to-Many Cross-Domain\n  Recommendation", "comments": "SIGIR 2020", "journal-ref": null, "doi": "10.1145/3397271.3401078", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid proliferation of new users and items on the social web has\naggravated the gray-sheep user/long-tail item challenge in recommender systems.\nHistorically, cross-domain co-clustering methods have successfully leveraged\nshared users and items across dense and sparse domains to improve inference\nquality. However, they rely on shared rating data and cannot scale to multiple\nsparse target domains (i.e., the one-to-many transfer setting). This, combined\nwith the increasing adoption of neural recommender architectures, motivates us\nto develop scalable neural layer-transfer approaches for cross-domain learning.\nOur key intuition is to guide neural collaborative filtering with\ndomain-invariant components shared across the dense and sparse domains,\nimproving the user and item representations learned in the sparse domains. We\nleverage contextual invariances across domains to develop these shared modules,\nand demonstrate that with user-item interaction context, we can learn-to-learn\ninformative representation spaces even with sparse interaction data. We show\nthe effectiveness and scalability of our approach on two public datasets and a\nmassive transaction dataset from Visa, a global payments technology company\n(19% Item Recall, 3x faster vs. training separate models for each domain). Our\napproach is applicable to both implicit and explicit feedback settings.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 05:51:15 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Krishnan", "Adit", ""], ["Das", "Mahashweta", ""], ["Bendre", "Mangesh", ""], ["Yang", "Hao", ""], ["Sundaram", "Hari", ""]]}, {"id": "2005.10477", "submitter": "Shahin Boluki", "authors": "Siamak Zamani Dadaneh, Shahin Boluki, Mingzhang Yin, Mingyuan Zhou,\n  Xiaoning Qian", "title": "Pairwise Supervised Hashing with Bernoulli Variational Auto-Encoder and\n  Self-Control Gradient Estimator", "comments": "To appear in UAI 2020", "journal-ref": "Uncertainty in Artificial Intelligence Conference (UAI) 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic hashing has become a crucial component of fast similarity search in\nmany large-scale information retrieval systems, in particular, for text data.\nVariational auto-encoders (VAEs) with binary latent variables as hashing codes\nprovide state-of-the-art performance in terms of precision for document\nretrieval. We propose a pairwise loss function with discrete latent VAE to\nreward within-class similarity and between-class dissimilarity for supervised\nhashing. Instead of solving the optimization relying on existing biased\ngradient estimators, an unbiased low-variance gradient estimator is adopted to\noptimize the hashing function by evaluating the non-differentiable loss\nfunction over two correlated sets of binary hashing codes to control the\nvariance of gradient estimates. This new semantic hashing framework achieves\nsuperior performance compared to the state-of-the-arts, as demonstrated by our\ncomprehensive experiments.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 06:11:33 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Dadaneh", "Siamak Zamani", ""], ["Boluki", "Shahin", ""], ["Yin", "Mingzhang", ""], ["Zhou", "Mingyuan", ""], ["Qian", "Xiaoning", ""]]}, {"id": "2005.10480", "submitter": "Theekshana Dissanayake", "authors": "Theekshana Dissanayake, Tharindu Fernando, Simon Denman, Sridha\n  Sridharan, Houman Ghaemmaghami, Clinton Fookes", "title": "A Robust Interpretable Deep Learning Classifier for Heart Anomaly\n  Detection Without Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, abnormal heart sound classification is framed as a three-stage\nprocess. The first stage involves segmenting the phonocardiogram to detect\nfundamental heart sounds; after which features are extracted and classification\nis performed. Some researchers in the field argue the segmentation step is an\nunwanted computational burden, whereas others embrace it as a prior step to\nfeature extraction. When comparing accuracies achieved by studies that have\nsegmented heart sounds before analysis with those who have overlooked that\nstep, the question of whether to segment heart sounds before feature extraction\nis still open. In this study, we explicitly examine the importance of heart\nsound segmentation as a prior step for heart sound classification, and then\nseek to apply the obtained insights to propose a robust classifier for abnormal\nheart sound detection. Furthermore, recognizing the pressing need for\nexplainable Artificial Intelligence (AI) models in the medical domain, we also\nunveil hidden representations learned by the classifier using model\ninterpretation techniques. Experimental results demonstrate that the\nsegmentation plays an essential role in abnormal heart sound classification.\nOur new classifier is also shown to be robust, stable and most importantly,\nexplainable, with an accuracy of almost 100% on the widely used PhysioNet\ndataset.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 06:36:28 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 06:42:51 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Dissanayake", "Theekshana", ""], ["Fernando", "Tharindu", ""], ["Denman", "Simon", ""], ["Sridharan", "Sridha", ""], ["Ghaemmaghami", "Houman", ""], ["Fookes", "Clinton", ""]]}, {"id": "2005.10481", "submitter": "Maxim Berman", "authors": "Maxim Berman, Leonid Pishchulin, Ning Xu, Matthew B. Blaschko, Gerard\n  Medioni", "title": "AOWS: Adaptive and optimal network width search with latency constraints", "comments": "Accepted to CVPR 2020 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) approaches aim at automatically finding\nnovel CNN architectures that fit computational constraints while maintaining a\ngood performance on the target platform. We introduce a novel efficient\none-shot NAS approach to optimally search for channel numbers, given latency\nconstraints on a specific hardware. We first show that we can use a black-box\napproach to estimate a realistic latency model for a specific inference\nplatform, without the need for low-level access to the inference computation.\nThen, we design a pairwise MRF to score any channel configuration and use\ndynamic programming to efficiently decode the best performing configuration,\nyielding an optimal solution for the network width search. Finally, we propose\nan adaptive channel configuration sampling scheme to gradually specialize the\ntraining phase to the target computational constraints. Experiments on ImageNet\nclassification show that our approach can find networks fitting the resource\nconstraints on different target platforms while improving accuracy over the\nstate-of-the-art efficient networks.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 06:46:16 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Berman", "Maxim", ""], ["Pishchulin", "Leonid", ""], ["Xu", "Ning", ""], ["Blaschko", "Matthew B.", ""], ["Medioni", "Gerard", ""]]}, {"id": "2005.10483", "submitter": "Gherardo Varando", "authors": "Gherardo Varando and Niels Richard Hansen", "title": "Graphical continuous Lyapunov models", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The linear Lyapunov equation of a covariance matrix parametrizes the\nequilibrium covariance matrix of a stochastic process. This parametrization can\nbe interpreted as a new graphical model class, and we show how the model class\nbehaves under marginalization and introduce a method for structure learning via\n$\\ell_1$-penalized loss minimization. Our proposed method is demonstrated to\noutperform alternative structure learning algorithms in a simulation study, and\nwe illustrate its application for protein phosphorylation network\nreconstruction.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 06:50:27 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Varando", "Gherardo", ""], ["Hansen", "Niels Richard", ""]]}, {"id": "2005.10510", "submitter": "Junbum Cha", "authors": "Junbum Cha, Sanghyuk Chun, Gayoung Lee, Bado Lee, Seonghyeon Kim, and\n  Hwalsuk Lee", "title": "Few-shot Compositional Font Generation with Dual Memory", "comments": "ECCV 2020 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating a new font library is a very labor-intensive and time-consuming\njob for glyph-rich scripts. Despite the remarkable success of existing font\ngeneration methods, they have significant drawbacks; they require a large\nnumber of reference images to generate a new font set, or they fail to capture\ndetailed styles with only a few samples. In this paper, we focus on\ncompositional scripts, a widely used letter system in the world, where each\nglyph can be decomposed by several components. By utilizing the\ncompositionality of compositional scripts, we propose a novel font generation\nframework, named Dual Memory-augmented Font Generation Network (DM-Font), which\nenables us to generate a high-quality font library with only a few samples. We\nemploy memory components and global-context awareness in the generator to take\nadvantage of the compositionality. In the experiments on Korean-handwriting\nfonts and Thai-printing fonts, we observe that our method generates a\nsignificantly better quality of samples with faithful stylization compared to\nthe state-of-the-art generation methods quantitatively and qualitatively.\nSource code is available at https://github.com/clovaai/dmfont.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 08:13:40 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 11:47:52 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Cha", "Junbum", ""], ["Chun", "Sanghyuk", ""], ["Lee", "Gayoung", ""], ["Lee", "Bado", ""], ["Kim", "Seonghyeon", ""], ["Lee", "Hwalsuk", ""]]}, {"id": "2005.10516", "submitter": "David Charte", "authors": "David Charte, Francisco Charte, Mar\\'ia J. del Jesus, Francisco\n  Herrera", "title": "An analysis on the use of autoencoders for representation learning:\n  fundamentals, learning task case studies, explainability and challenges", "comments": null, "journal-ref": "Neurocomputing 404 (2020) 93-107", "doi": "10.1016/j.neucom.2020.04.057", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many machine learning tasks, learning a good representation of the data\ncan be the key to building a well-performant solution. This is because most\nlearning algorithms operate with the features in order to find models for the\ndata. For instance, classification performance can improve if the data is\nmapped to a space where classes are easily separated, and regression can be\nfacilitated by finding a manifold of data in the feature space. As a general\nrule, features are transformed by means of statistical methods such as\nprincipal component analysis, or manifold learning techniques such as Isomap or\nlocally linear embedding. From a plethora of representation learning methods,\none of the most versatile tools is the autoencoder. In this paper we aim to\ndemonstrate how to influence its learned representations to achieve the desired\nlearning behavior. To this end, we present a series of learning tasks: data\nembedding for visualization, image denoising, semantic hashing, detection of\nabnormal behaviors and instance generation. We model them from the\nrepresentation learning perspective, following the state of the art\nmethodologies in each field. A solution is proposed for each task employing\nautoencoders as the only learning method. The theoretical developments are put\ninto practice using a selection of datasets for the different problems and\nimplementing each solution, followed by a discussion of the results in each\ncase study and a brief explanation of other six learning applications. We also\nexplore the current challenges and approaches to explainability in the context\nof autoencoders. All of this helps conclude that, thanks to alterations in\ntheir structure as well as their objective function, autoencoders may be the\ncore of a possible solution to many problems which can be modeled as a\ntransformation of the feature space.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 08:41:57 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Charte", "David", ""], ["Charte", "Francisco", ""], ["del Jesus", "Mar\u00eda J.", ""], ["Herrera", "Francisco", ""]]}, {"id": "2005.10524", "submitter": "Gaurav Mittal", "authors": "Gaurav Mittal, Chang Liu, Nikolaos Karianakis, Victor Fragoso, Mei\n  Chen, Yun Fu", "title": "HyperSTAR: Task-Aware Hyperparameters for Deep Networks", "comments": "Published at CVPR 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks excel in solving visual recognition tasks, they\nrequire significant effort to find hyperparameters that make them work\noptimally. Hyperparameter Optimization (HPO) approaches have automated the\nprocess of finding good hyperparameters but they do not adapt to a given task\n(task-agnostic), making them computationally inefficient. To reduce HPO time,\nwe present HyperSTAR (System for Task Aware Hyperparameter Recommendation), a\ntask-aware method to warm-start HPO for deep neural networks. HyperSTAR ranks\nand recommends hyperparameters by predicting their performance conditioned on a\njoint dataset-hyperparameter space. It learns a dataset (task) representation\nalong with the performance predictor directly from raw images in an end-to-end\nfashion. The recommendations, when integrated with an existing HPO method, make\nit task-aware and significantly reduce the time to achieve optimal performance.\nWe conduct extensive experiments on 10 publicly available large-scale image\nclassification datasets over two different network architectures, validating\nthat HyperSTAR evaluates 50% less configurations to achieve the best\nperformance compared to existing methods. We further demonstrate that HyperSTAR\nmakes Hyperband (HB) task-aware, achieving the optimal accuracy in just 25% of\nthe budget required by both vanilla HB and Bayesian Optimized HB~(BOHB).\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 08:56:50 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Mittal", "Gaurav", ""], ["Liu", "Chang", ""], ["Karianakis", "Nikolaos", ""], ["Fragoso", "Victor", ""], ["Chen", "Mei", ""], ["Fu", "Yun", ""]]}, {"id": "2005.10531", "submitter": "Michael Biehl", "authors": "Michiel Straat, Fthi Abadi, Zhuoyun Kan, Christina G\\\"opfert, Barbara\n  Hammer, Michael Biehl", "title": "Supervised Learning in the Presence of Concept Drift: A modelling\n  framework", "comments": "17 pages in twocolumn", "journal-ref": "Neural Computing and Applications 2021", "doi": "10.1007/s00521-021-06035-1", "report-no": null, "categories": "cs.LG cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a modelling framework for the investigation of supervised learning\nin non-stationary environments. Specifically, we model two example types of\nlearning systems: prototype-based Learning Vector Quantization (LVQ) for\nclassification and shallow, layered neural networks for regression tasks. We\ninvestigate so-called student teacher scenarios in which the systems are\ntrained from a stream of high-dimensional, labeled data. Properties of the\ntarget task are considered to be non-stationary due to drift processes while\nthe training is performed. Different types of concept drift are studied, which\naffect the density of example inputs only, the target rule itself, or both. By\napplying methods from statistical physics, we develop a modelling framework for\nthe mathematical analysis of the training dynamics in non-stationary\nenvironments.\n  Our results show that standard LVQ algorithms are already suitable for the\ntraining in non-stationary environments to a certain extent. However, the\napplication of weight decay as an explicit mechanism of forgetting does not\nimprove the performance under the considered drift processes. Furthermore, we\ninvestigate gradient-based training of layered neural networks with sigmoidal\nactivation functions and compare with the use of rectified linear units (ReLU).\nOur findings show that the sensitivity to concept drift and the effectiveness\nof weight decay differs significantly between the two types of activation\nfunction.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 09:13:58 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 20:45:45 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Straat", "Michiel", ""], ["Abadi", "Fthi", ""], ["Kan", "Zhuoyun", ""], ["G\u00f6pfert", "Christina", ""], ["Hammer", "Barbara", ""], ["Biehl", "Michael", ""]]}, {"id": "2005.10544", "submitter": "John Cai", "authors": "John Cai, Sheng Mei Shen", "title": "Cross-Domain Few-Shot Learning with Meta Fine-Tuning", "comments": "CVPR 2020 Workshop on Visual Learning with Limited Labels (VL3)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we tackle the new Cross-Domain Few-Shot Learning benchmark\nproposed by the CVPR 2020 Challenge. To this end, we build upon\nstate-of-the-art methods in domain adaptation and few-shot learning to create a\nsystem that can be trained to perform both tasks. Inspired by the need to\ncreate models designed to be fine-tuned, we explore the integration of\ntransfer-learning (fine-tuning) with meta-learning algorithms, to train a\nnetwork that has specific layers that are designed to be adapted at a later\nfine-tuning stage. To do so, we modify the episodic training process to include\na first-order MAML-based meta-learning algorithm, and use a Graph Neural\nNetwork model as the subsequent meta-learning module. We find that our proposed\nmethod helps to boost accuracy significantly, especially when combined with\ndata augmentation. In our final results, we combine the novel method with the\nbaseline method in a simple ensemble, and achieve an average accuracy of 73.78%\non the benchmark. This is a 6.51% improvement over existing benchmarks that\nwere trained solely on miniImagenet.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 09:55:26 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 11:19:25 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 03:46:42 GMT"}, {"version": "v4", "created": "Tue, 25 Aug 2020 15:45:55 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Cai", "John", ""], ["Shen", "Sheng Mei", ""]]}, {"id": "2005.10549", "submitter": "Cheng Zhao", "authors": "Cheng Zhao, Chenliang Li, Rong Xiao, Hongbo Deng, Aixin Sun", "title": "CATN: Cross-Domain Recommendation for Cold-Start Users via Aspect\n  Transfer Network", "comments": "Accepted to SIGIR 2020", "journal-ref": null, "doi": "10.1145/3397271.3401169", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a large recommender system, the products (or items) could be in many\ndifferent categories or domains. Given two relevant domains (e.g., Book and\nMovie), users may have interactions with items in one domain but not in the\nother domain. To the latter, these users are considered as cold-start users.\nHow to effectively transfer users' preferences based on their interactions from\none domain to the other relevant domain, is the key issue in cross-domain\nrecommendation. Inspired by the advances made in review-based recommendation,\nwe propose to model user preference transfer at aspect-level derived from\nreviews. To this end, we propose a cross-domain recommendation framework via\naspect transfer network for cold-start users (named CATN). CATN is devised to\nextract multiple aspects for each user and each item from their review\ndocuments, and learn aspect correlations across domains with an attention\nmechanism. In addition, we further exploit auxiliary reviews from like-minded\nusers to enhance a user's aspect representations. Then, an end-to-end\noptimization framework is utilized to strengthen the robustness of our model.\nOn real-world datasets, the proposed CATN outperforms SOTA models significantly\nin terms of rating prediction accuracy. Further analysis shows that our model\nis able to reveal user aspect connections across domains at a fine level of\ngranularity, making the recommendation explainable.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 10:05:19 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 07:13:11 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Zhao", "Cheng", ""], ["Li", "Chenliang", ""], ["Xiao", "Rong", ""], ["Deng", "Hongbo", ""], ["Sun", "Aixin", ""]]}, {"id": "2005.10550", "submitter": "Renato Hermoza Aragon\\'es", "authors": "Renato Hermoza, Gabriel Maicas, Jacinto C. Nascimento and Gustavo\n  Carneiro", "title": "Region Proposals for Saliency Map Refinement for Weakly-supervised\n  Disease Localisation and Classification", "comments": "Early accept at MICCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deployment of automated systems to diagnose diseases from medical images\nis challenged by the requirement to localise the diagnosed diseases to justify\nor explain the classification decision. This requirement is hard to fulfil\nbecause most of the training sets available to develop these systems only\ncontain global annotations, making the localisation of diseases a weakly\nsupervised approach. The main methods designed for weakly supervised disease\nclassification and localisation rely on saliency or attention maps that are not\nspecifically trained for localisation, or on region proposals that can not be\nrefined to produce accurate detections. In this paper, we introduce a new model\nthat combines region proposal and saliency detection to overcome both\nlimitations for weakly supervised disease classification and localisation.\nUsing the ChestX-ray14 data set, we show that our proposed model establishes\nthe new state-of-the-art for weakly-supervised disease diagnosis and\nlocalisation.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 10:07:43 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 01:15:47 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Hermoza", "Renato", ""], ["Maicas", "Gabriel", ""], ["Nascimento", "Jacinto C.", ""], ["Carneiro", "Gustavo", ""]]}, {"id": "2005.10577", "submitter": "Filippo Vannella", "authors": "Filippo Vannella, Jaeseong Jeong, Alexandre Proutiere", "title": "Off-policy Learning for Remote Electrical Tilt Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the problem of Remote Electrical Tilt (RET) optimization using\noff-policy Contextual Multi-Armed-Bandit (CMAB) techniques. The goal in RET\noptimization is to control the orientation of the vertical tilt angle of the\nantenna to optimize Key Performance Indicators (KPIs) representing the Quality\nof Service (QoS) perceived by the users in cellular networks. Learning an\nimproved tilt update policy is hard. On the one hand, coming up with a new\npolicy in an online manner in a real network requires exploring tilt updates\nthat have never been used before, and is operationally too risky. On the other\nhand, devising this policy via simulations suffers from the\nsimulation-to-reality gap. In this paper, we circumvent these issues by\nlearning an improved policy in an offline manner using existing data collected\non real networks. We formulate the problem of devising such a policy using the\noff-policy CMAB framework. We propose CMAB learning algorithms to extract\noptimal tilt update policies from the data. We train and evaluate these\npolicies on real-world 4G Long Term Evolution (LTE) cellular network data. Our\npolicies show consistent improvements over the rule-based logging policy used\nto collect the data.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 11:30:31 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Vannella", "Filippo", ""], ["Jeong", "Jaeseong", ""], ["Proutiere", "Alexandre", ""]]}, {"id": "2005.10602", "submitter": "Ruiyang Ren", "authors": "Ruiyang Ren, Zhaoyang Liu, Yaliang Li, Wayne Xin Zhao, Hui Wang, Bolin\n  Ding, Ji-Rong Wen", "title": "Sequential Recommendation with Self-Attentive Multi-Adversarial Network", "comments": null, "journal-ref": null, "doi": "10.1145/3397271.3401111", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning has made significant progress in the task of\nsequential recommendation. Existing neural sequential recommenders typically\nadopt a generative way trained with Maximum Likelihood Estimation (MLE). When\ncontext information (called factor) is involved, it is difficult to analyze\nwhen and how each individual factor would affect the final recommendation\nperformance. For this purpose, we take a new perspective and introduce\nadversarial learning to sequential recommendation. In this paper, we present a\nMulti-Factor Generative Adversarial Network (MFGAN) for explicitly modeling the\neffect of context information on sequential recommendation. Specifically, our\nproposed MFGAN has two kinds of modules: a Transformer-based generator taking\nuser behavior sequences as input to recommend the possible next items, and\nmultiple factor-specific discriminators to evaluate the generated sub-sequence\nfrom the perspectives of different factors. To learn the parameters, we adopt\nthe classic policy gradient method, and utilize the reward signal of\ndiscriminators for guiding the learning of the generator. Our framework is\nflexible to incorporate multiple kinds of factor information, and is able to\ntrace how each factor contributes to the recommendation decision over time.\nExtensive experiments conducted on three real-world datasets demonstrate the\nsuperiority of our proposed model over the state-of-the-art methods, in terms\nof effectiveness and interpretability.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 12:28:59 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Ren", "Ruiyang", ""], ["Liu", "Zhaoyang", ""], ["Li", "Yaliang", ""], ["Zhao", "Wayne Xin", ""], ["Wang", "Hui", ""], ["Ding", "Bolin", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "2005.10614", "submitter": "Souvik Chakraborty", "authors": "Souvik Chakraborty", "title": "Transfer learning based multi-fidelity physics informed deep neural\n  network", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2020.109942", "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many systems in science and engineering, the governing differential\nequation is either not known or known in an approximate sense. Analyses and\ndesign of such systems are governed by data collected from the field and/or\nlaboratory experiments. This challenging scenario is further worsened when\ndata-collection is expensive and time-consuming. To address this issue, this\npaper presents a novel multi-fidelity physics informed deep neural network\n(MF-PIDNN). The framework proposed is particularly suitable when the physics of\nthe problem is known in an approximate sense (low-fidelity physics) and only a\nfew high-fidelity data are available. MF-PIDNN blends physics informed and\ndata-driven deep learning techniques by using the concept of transfer learning.\nThe approximate governing equation is first used to train a low-fidelity\nphysics informed deep neural network. This is followed by transfer learning\nwhere the low-fidelity model is updated by using the available high-fidelity\ndata. MF-PIDNN is able to encode useful information on the physics of the\nproblem from the {\\it approximate} governing differential equation and hence,\nprovides accurate prediction even in zones with no data. Additionally, no\nlow-fidelity data is required for training this model. Applicability and\nutility of MF-PIDNN are illustrated in solving four benchmark reliability\nanalysis problems. Case studies to illustrate interesting features of the\nproposed approach are also presented.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 13:57:48 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 05:17:32 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Chakraborty", "Souvik", ""]]}, {"id": "2005.10615", "submitter": "Rolf Jagerman", "authors": "Rolf Jagerman and Maarten de Rijke", "title": "Accelerated Convergence for Counterfactual Learning to Rank", "comments": "SIGIR 2020 full conference paper", "journal-ref": null, "doi": "10.1145/3397271.3401069", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual Learning to Rank (LTR) algorithms learn a ranking model from\nlogged user interactions, often collected using a production system. Employing\nsuch an offline learning approach has many benefits compared to an online one,\nbut it is challenging as user feedback often contains high levels of bias.\nUnbiased LTR uses Inverse Propensity Scoring (IPS) to enable unbiased learning\nfrom logged user interactions. One of the major difficulties in applying\nStochastic Gradient Descent (SGD) approaches to counterfactual learning\nproblems is the large variance introduced by the propensity weights. In this\npaper we show that the convergence rate of SGD approaches with IPS-weighted\ngradients suffers from the large variance introduced by the IPS weights:\nconvergence is slow, especially when there are large IPS weights. To overcome\nthis limitation, we propose a novel learning algorithm, called CounterSample,\nthat has provably better convergence than standard IPS-weighted gradient\ndescent methods. We prove that CounterSample converges faster and complement\nour theoretical findings with empirical results by performing extensive\nexperimentation in a number of biased LTR scenarios -- across optimizers, batch\nsizes, and different degrees of position bias.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 12:53:36 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Jagerman", "Rolf", ""], ["de Rijke", "Maarten", ""]]}, {"id": "2005.10619", "submitter": "Sindhu Padakandla", "authors": "Sindhu Padakandla", "title": "A Survey of Reinforcement Learning Algorithms for Dynamically Varying\n  Environments", "comments": null, "journal-ref": "ACM Computing Surveys 2021", "doi": "10.1145/3459991", "report-no": "Volume 54, Issue 6", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms find applications in inventory\ncontrol, recommender systems, vehicular traffic management, cloud computing and\nrobotics. The real-world complications of many tasks arising in these domains\nmakes them difficult to solve with the basic assumptions underlying classical\nRL algorithms. RL agents in these applications often need to react and adapt to\nchanging operating conditions. A significant part of research on single-agent\nRL techniques focuses on developing algorithms when the underlying assumption\nof stationary environment model is relaxed. This paper provides a survey of RL\nmethods developed for handling dynamically varying environment models. The goal\nof methods not limited by the stationarity assumption is to help autonomous\nagents adapt to varying operating conditions. This is possible either by\nminimizing the rewards lost during learning by RL agent or by finding a\nsuitable policy for the RL agent which leads to efficient operation of the\nunderlying system. A representative collection of these algorithms is discussed\nin detail in this work along with their categorization and their relative\nmerits and demerits. Additionally we also review works which are tailored to\napplication domains. Finally, we discuss future enhancements for this field.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 09:42:42 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Padakandla", "Sindhu", ""]]}, {"id": "2005.10622", "submitter": "Bin Wang", "authors": "Cong Fei, Bin Wang, Yuzheng Zhuang, Zongzhang Zhang, Jianye Hao,\n  Hongbo Zhang, Xuewu Ji and Wulong Liu", "title": "Triple-GAIL: A Multi-Modal Imitation Learning Framework with Generative\n  Adversarial Nets", "comments": "7 papges, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial imitation learning (GAIL) has shown promising results\nby taking advantage of generative adversarial nets, especially in the field of\nrobot learning. However, the requirement of isolated single modal\ndemonstrations limits the scalability of the approach to real world scenarios\nsuch as autonomous vehicles' demand for a proper understanding of human\ndrivers' behavior. In this paper, we propose a novel multi-modal GAIL\nframework, named Triple-GAIL, that is able to learn skill selection and\nimitation jointly from both expert demonstrations and continuously generated\nexperiences with data augmentation purpose by introducing an auxiliary skill\nselector. We provide theoretical guarantees on the convergence to optima for\nboth of the generator and the selector respectively. Experiments on real driver\ntrajectories and real-time strategy game datasets demonstrate that Triple-GAIL\ncan better fit multi-modal behaviors close to the demonstrators and outperforms\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 03:24:24 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 01:05:30 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Fei", "Cong", ""], ["Wang", "Bin", ""], ["Zhuang", "Yuzheng", ""], ["Zhang", "Zongzhang", ""], ["Hao", "Jianye", ""], ["Zhang", "Hongbo", ""], ["Ji", "Xuewu", ""], ["Liu", "Wulong", ""]]}, {"id": "2005.10624", "submitter": "Manish Raghavan", "authors": "Manish Raghavan, Aleksandrs Slivkins, Jennifer Wortman Vaughan, Zhiwei\n  Steven Wu", "title": "Greedy Algorithm almost Dominates in Smoothed Contextual Bandits", "comments": "Results in this paper, without any proofs, have been announced in an\n  extended abstract (Raghavan et al., 2018a), and fleshed out in the technical\n  report (Raghavan et al., 2018b [arXiv:1806.00543]). This manuscript covers a\n  subset of results from Raghavan et al. (2018a,b), focusing on the greedy\n  algorithm, and is streamlined accordingly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learning algorithms, widely used to power search and content\noptimization on the web, must balance exploration and exploitation, potentially\nsacrificing the experience of current users in order to gain information that\nwill lead to better decisions in the future. While necessary in the worst case,\nexplicit exploration has a number of disadvantages compared to the greedy\nalgorithm that always \"exploits\" by choosing an action that currently looks\noptimal. We ask under what conditions inherent diversity in the data makes\nexplicit exploration unnecessary. We build on a recent line of work on the\nsmoothed analysis of the greedy algorithm in the linear contextual bandits\nmodel. We improve on prior results to show that a greedy approach almost\nmatches the best possible Bayesian regret rate of any other algorithm on the\nsame problem instance whenever the diversity conditions hold, and that this\nregret is at most $\\tilde O(T^{1/3})$.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 18:11:40 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Raghavan", "Manish", ""], ["Slivkins", "Aleksandrs", ""], ["Vaughan", "Jennifer Wortman", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "2005.10627", "submitter": "Zhaofeng Wu", "authors": "Zhaofeng Wu, Ding Zhao, Qiao Liang, Jiahui Yu, Anmol Gulati, Ruoming\n  Pang", "title": "Dynamic Sparsity Neural Networks for Automatic Speech Recognition", "comments": "ICASSP 2021. (c) 2021 IEEE. Personal use of this material is\n  permitted. Permission from IEEE must be obtained for all other uses, in any\n  current or future media, including reprinting/republishing this material for\n  advertising or promotional purposes, creating new collective works, for\n  resale or redistribution to servers or lists, or reuse of any copyrighted\n  component of this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In automatic speech recognition (ASR), model pruning is a widely adopted\ntechnique that reduces model size and latency to deploy neural network models\non edge devices with resource constraints. However, multiple models with\ndifferent sparsity levels usually need to be separately trained and deployed to\nheterogeneous target hardware with different resource specifications and for\napplications that have various latency requirements. In this paper, we present\nDynamic Sparsity Neural Networks (DSNN) that, once trained, can instantly\nswitch to any predefined sparsity configuration at run-time. We demonstrate the\neffectiveness and flexibility of DSNN using experiments on internal production\ndatasets with Google Voice Search data, and show that the performance of a DSNN\nmodel is on par with that of individually trained single sparsity networks. Our\ntrained DSNN model, therefore, can greatly ease the training process and\nsimplify deployment in diverse scenarios with resource constraints.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 22:08:54 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 20:58:33 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 08:01:58 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Wu", "Zhaofeng", ""], ["Zhao", "Ding", ""], ["Liang", "Qiao", ""], ["Yu", "Jiahui", ""], ["Gulati", "Anmol", ""], ["Pang", "Ruoming", ""]]}, {"id": "2005.10629", "submitter": "Elie Azeraf", "authors": "Elie Azeraf, Emmanuel Monfrini, Emmanuel Vignon, Wojciech Pieczynski", "title": "Hidden Markov Chains, Entropic Forward-Backward, and Part-Of-Speech\n  Tagging", "comments": "5 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to take into account the characteristics - also called features -\nof observations is essential in Natural Language Processing (NLP) problems.\nHidden Markov Chain (HMC) model associated with classic Forward-Backward\nprobabilities cannot handle arbitrary features like prefixes or suffixes of any\nsize, except with an independence condition. For twenty years, this default has\nencouraged the development of other sequential models, starting with the\nMaximum Entropy Markov Model (MEMM), which elegantly integrates arbitrary\nfeatures. More generally, it led to neglect HMC for NLP. In this paper, we show\nthat the problem is not due to HMC itself, but to the way its restoration\nalgorithms are computed. We present a new way of computing HMC based\nrestorations using original Entropic Forward and Entropic Backward (EFB)\nprobabilities. Our method allows taking into account features in the HMC\nframework in the same way as in the MEMM framework. We illustrate the\nefficiency of HMC using EFB in Part-Of-Speech Tagging, showing its superiority\nover MEMM based restoration. We also specify, as a perspective, how HMCs with\nEFB might appear as an alternative to Recurrent Neural Networks to treat\nsequential data with a deep architecture.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 13:31:11 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Azeraf", "Elie", ""], ["Monfrini", "Emmanuel", ""], ["Vignon", "Emmanuel", ""], ["Pieczynski", "Wojciech", ""]]}, {"id": "2005.10630", "submitter": "Hilal Asi", "authors": "Hilal Asi, John C. Duchi", "title": "Near Instance-Optimality in Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop two notions of instance optimality in differential privacy,\ninspired by classical statistical theory: one by defining a local minimax risk\nand the other by considering unbiased mechanisms and analogizing the Cramer-Rao\nbound, and we show that the local modulus of continuity of the estimand of\ninterest completely determines these quantities. We also develop a\ncomplementary collection mechanisms, which we term the inverse sensitivity\nmechanisms, which are instance optimal (or nearly instance optimal) for a large\nclass of estimands. Moreover, these mechanisms uniformly outperform the smooth\nsensitivity framework on each instance for several function classes of\ninterest, including real-valued continuous functions. We carefully present two\ninstantiations of the mechanisms for median and robust regression estimation\nwith corresponding experiments.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 04:53:48 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Asi", "Hilal", ""], ["Duchi", "John C.", ""]]}, {"id": "2005.10632", "submitter": "Enrico Schiassi", "authors": "Enrico Schiassi, Carl Leake, Mario De Florio, Hunter Johnston, Roberto\n  Furfaro, Daniele Mortari", "title": "Extreme Theory of Functional Connections: A Physics-Informed Neural\n  Network Method for Solving Parametric Differential Equations", "comments": "28 pages, 12 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a novel, accurate, and robust physics-informed method\nfor solving problems involving parametric differential equations (DEs) called\nthe Extreme Theory of Functional Connections, or X-TFC. The proposed method is\na synergy of two recently developed frameworks for solving problems involving\nparametric DEs, 1) the Theory of Functional Connections, TFC, and the\nPhysics-Informed Neural Networks, PINN. Although this paper focuses on the\nsolution of exact problems involving parametric DEs (i.e. problems where the\nmodeling error is negligible) with known parameters, X-TFC can also be used for\ndata-driven solutions and data-driven discovery of parametric DEs. In the\nproposed method, the latent solution of the parametric DEs is approximated by a\nTFC constrained expression that uses a Neural Network (NN) as the\nfree-function. This approximate solution form always analytically satisfies the\nconstraints of the DE, while maintaining a NN with unconstrained parameters,\nlike the Deep-TFC method. X-TFC differs from PINN and Deep-TFC; whereas PINN\nand Deep-TFC use a deep-NN, X-TFC uses a single-layer NN, or more precisely, an\nExtreme Learning Machine, ELM. This choice is based on the properties of the\nELM algorithm. In order to numerically validate the method, it was tested over\na range of problems including the approximation of solutions to linear and\nnon-linear ordinary DEs (ODEs), systems of ODEs (SODEs), and partial DEs\n(PDEs). Furthermore, a few of these problems are of interest in physics and\nengineering such as the Classic Emden-Fowler equation, the Radiative Transfer\n(RT) equation, and the Heat-Transfer (HT) equation. The results show that X-TFC\nachieves high accuracy with low computational time and thus it is comparable\nwith the other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 22:51:04 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Schiassi", "Enrico", ""], ["Leake", "Carl", ""], ["De Florio", "Mario", ""], ["Johnston", "Hunter", ""], ["Furfaro", "Roberto", ""], ["Mortari", "Daniele", ""]]}, {"id": "2005.10636", "submitter": "Michihiro Yasunaga", "authors": "Michihiro Yasunaga, Percy Liang", "title": "Graph-based, Self-Supervised Program Repair from Diagnostic Feedback", "comments": "ICML 2020. Code & data available at\n  https://github.com/michiyasunaga/DrRepair", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning to repair programs from diagnostic\nfeedback (e.g., compiler error messages). Program repair is challenging for two\nreasons: First, it requires reasoning and tracking symbols across source code\nand diagnostic feedback. Second, labeled datasets available for program repair\nare relatively small. In this work, we propose novel solutions to these two\nchallenges. First, we introduce a program-feedback graph, which connects\nsymbols relevant to program repair in source code and diagnostic feedback, and\nthen apply a graph neural network on top to model the reasoning process.\nSecond, we present a self-supervised learning paradigm for program repair that\nleverages unlabeled programs available online to create a large amount of extra\nprogram repair examples, which we use to pre-train our models. We evaluate our\nproposed approach on two applications: correcting introductory programming\nassignments (DeepFix dataset) and correcting the outputs of program synthesis\n(SPoC dataset). Our final system, DrRepair, significantly outperforms prior\nwork, achieving 68.2% full repair rate on DeepFix (+22.9% over the prior best),\nand 48.4% synthesis success rate on SPoC (+3.7% over the prior best).\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 07:24:28 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 05:30:33 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Yasunaga", "Michihiro", ""], ["Liang", "Percy", ""]]}, {"id": "2005.10638", "submitter": "Alexandre Emerick", "authors": "Smith W. A. Canchumun, Jose D. B. Castro, J\\'ulia Potratz, Alexandre\n  A. Emerick and Marco Aurelio C. Pacheco", "title": "Recent Developments Combining Ensemble Smoother and Deep Generative\n  Networks for Facies History Matching", "comments": "46 pages, 26 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble smoothers are among the most successful and efficient techniques\ncurrently available for history matching. However, because these methods rely\non Gaussian assumptions, their performance is severely degraded when the prior\ngeology is described in terms of complex facies distributions. Inspired by the\nimpressive results obtained by deep generative networks in areas such as image\nand video generation, we started an investigation focused on the use of\nautoencoders networks to construct a continuous parameterization for facies\nmodels. In our previous publication, we combined a convolutional variational\nautoencoder (VAE) with the ensemble smoother with multiple data assimilation\n(ES-MDA) for history matching production data in models generated with\nmultiple-point geostatistics. Despite the good results reported in our previous\npublication, a major limitation of the designed parameterization is the fact\nthat it does not allow applying distance-based localization during the ensemble\nsmoother update, which limits its application in large-scale problems.\n  The present work is a continuation of this research project focusing in two\naspects: firstly, we benchmark seven different formulations, including VAE,\ngenerative adversarial network (GAN), Wasserstein GAN, variational\nauto-encoding GAN, principal component analysis (PCA) with cycle GAN, PCA with\ntransfer style network and VAE with style loss. These formulations are tested\nin a synthetic history matching problem with channelized facies. Secondly, we\npropose two strategies to allow the use of distance-based localization with the\ndeep learning parameterizations.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 21:32:42 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Canchumun", "Smith W. A.", ""], ["Castro", "Jose D. B.", ""], ["Potratz", "J\u00falia", ""], ["Emerick", "Alexandre A.", ""], ["Pacheco", "Marco Aurelio C.", ""]]}, {"id": "2005.10640", "submitter": "Jessica McBroom", "authors": "Jessica McBroom, Kalina Yacef and Irena Koprinska", "title": "DETECT: A Hierarchical Clustering Algorithm for Behavioural Trends in\n  Temporal Educational Data", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques for clustering student behaviour offer many opportunities to\nimprove educational outcomes by providing insight into student learning.\nHowever, one important aspect of student behaviour, namely its evolution over\ntime, can often be challenging to identify using existing methods. This is\nbecause the objective functions used by these methods do not explicitly aim to\nfind cluster trends in time, so these trends may not be clearly represented in\nthe results. This paper presents `DETECT' (Detection of Educational Trends\nElicited by Clustering Time-series data), a novel divisive hierarchical\nclustering algorithm that incorporates temporal information into its objective\nfunction to prioritise the detection of behavioural trends. The resulting\nclusters are similar in structure to a decision tree, with a hierarchy of\nclusters defined by decision rules on features. DETECT is easy to apply, highly\ncustomisable, applicable to a wide range of educational datasets and yields\neasily interpretable results. Through a case study of two online programming\ncourses (N>600), this paper demonstrates two example applications of DETECT: 1)\nto identify how cohort behaviour develops over time and 2) to identify student\nbehaviours that characterise exercises where many students give up.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 01:34:47 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["McBroom", "Jessica", ""], ["Yacef", "Kalina", ""], ["Koprinska", "Irena", ""]]}, {"id": "2005.10642", "submitter": "Tapas Si", "authors": "Jayri Bagchi and Tapas Si", "title": "Nonlinear Regression Analysis Using Multi-Verse Optimizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Regression analysis is an important machine learning task used for predictive\nanalytic in business, sports analysis, etc. In regression analysis,\noptimization algorithms play a significant role in search the coefficients in\nthe regression model. In this paper, nonlinear regression analysis using a\nrecently developed meta-heuristic Multi-Verse Optimizer (MVO) is proposed. The\nproposed method is applied to 10 well-known benchmark nonlinear regression\nproblems. A comparative study has been conducted with Particle Swarm Optimizer\n(PSO). The experimental results demonstrate that the proposed method\nstatistically outperforms PSO algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 15:03:52 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Bagchi", "Jayri", ""], ["Si", "Tapas", ""]]}, {"id": "2005.10644", "submitter": "Alun Stokes", "authors": "Alun Stokes, William Hum, Jonathan Zaslavsky", "title": "A Minimal-Input Multilayer Perceptron for Predicting Drug-Drug\n  Interactions Without Knowledge of Drug Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The necessity of predictive models in the drug discovery industry cannot be\nunderstated. With the sheer volume of potentially useful compounds that are\nconsidered for use, it is becoming increasingly computationally difficult to\ninvestigate the overlapping interactions between drugs. Understanding this is\nalso important to the layperson who needs to know what they can and cannot mix,\nespecially for those who use recreational drugs - which do not have the same\nrigorous warnings as prescription drugs. Without access to deterministic,\nexperimental results for every drug combination, other methods are necessary to\nbridge this knowledge gap. Ideally, such a method would require minimal inputs,\nhave high accuracy, and be computationally feasible. We have not come across a\nmodel that meets all these criteria. To this end, we propose a minimal-input\nmulti-layer perceptron that predicts the interactions between two drugs. This\nmodel has a great advantage of requiring no structural knowledge of the\nmolecules in question, and instead only uses experimentally accessible chemical\nand physical properties - 20 per compound in total. Using a set of known\ndrug-drug interactions, and associated properties of the drugs involved, we\ntrained our model on a dataset of about 650,000 entries. We report an accuracy\nof 0.968 on unseen samples of interactions between drugs on which the model was\ntrained, and an accuracy of 0.942 on unseen samples of interactions between\nunseen drugs. We believe this to be a promising and highly extensible model\nthat has potential for high generalized predictive accuracy with further\ntuning.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 17:15:19 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Stokes", "Alun", ""], ["Hum", "William", ""], ["Zaslavsky", "Jonathan", ""]]}, {"id": "2005.10663", "submitter": "Oran Gafni", "authors": "Oran Gafni, Lior Wolf", "title": "Wish You Were Here: Context-Aware Human Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for inserting objects, specifically humans, into\nexisting images, such that they blend in a photorealistic manner, while\nrespecting the semantic context of the scene. Our method involves three\nsubnetworks: the first generates the semantic map of the new person, given the\npose of the other persons in the scene and an optional bounding box\nspecification. The second network renders the pixels of the novel person and\nits blending mask, based on specifications in the form of multiple appearance\ncomponents. A third network refines the generated face in order to match those\nof the target person. Our experiments present convincing high-resolution\noutputs in this novel and challenging application domain. In addition, the\nthree networks are evaluated individually, demonstrating for example, state of\nthe art results in pose transfer benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 14:09:14 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Gafni", "Oran", ""], ["Wolf", "Lior", ""]]}, {"id": "2005.10674", "submitter": "Andrea Borghesi", "authors": "Michele Lombardi, Federico Baldo, Andrea Borghesi, Michela Milano", "title": "An Analysis of Regularized Approaches for Constrained Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization-based approaches for injecting constraints in Machine Learning\n(ML) were introduced to improve a predictive model via expert knowledge. We\ntackle the issue of finding the right balance between the loss (the accuracy of\nthe learner) and the regularization term (the degree of constraint\nsatisfaction). The key results of this paper is the formal demonstration that\nthis type of approach cannot guarantee to find all optimal solutions. In\nparticular, in the non-convex case there might be optima for the constrained\nproblem that do not correspond to any multiplier value.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 15:16:26 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Lombardi", "Michele", ""], ["Baldo", "Federico", ""], ["Borghesi", "Andrea", ""], ["Milano", "Michela", ""]]}, {"id": "2005.10686", "submitter": "Leixin Zhou", "authors": "Leixin Zhou, Wenxiang Deng, Xiaodong Wu", "title": "Unsupervised anomaly localization using VAE and beta-VAE", "comments": "arXiv admin note: substantial text overlap with arXiv:2002.03734 by\n  other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Variational Auto-Encoders (VAEs) have shown great potential in the\nunsupervised learning of data distributions. An VAE trained on normal images is\nexpected to only be able to reconstruct normal images, allowing the\nlocalization of anomalous pixels in an image via manipulating information\nwithin the VAE ELBO loss. The ELBO consists of KL divergence loss (image-wise)\nand reconstruction loss (pixel-wise). It is natural and straightforward to use\nthe later as the predictor. However, usually local anomaly added to a normal\nimage can deteriorate the whole reconstructed image, causing segmentation using\nonly naive pixel errors not accurate. Energy based projection was proposed to\nincrease the reconstruction accuracy of normal regions/pixels, which achieved\nthe state-of-the-art localization accuracy on simple natural images. Another\npossible predictors are ELBO and its components gradients with respect to each\npixels. Previous work claimed that KL gradient is a robust predictor. In this\npaper, we argue that the energy based projection in medical imaging is not as\nuseful as on natural images. Moreover, we observe that the robustness of KL\ngradient predictor totally depends on the setting of the VAE and dataset. We\nalso explored the effect of the weight of KL loss within beta-VAE and predictor\nensemble in anomaly localization.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 21:58:59 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Zhou", "Leixin", ""], ["Deng", "Wenxiang", ""], ["Wu", "Xiaodong", ""]]}, {"id": "2005.10687", "submitter": "Khalid Raza", "authors": "Nripendra Kumar Singh, Khalid Raza", "title": "Medical Image Generation using Generative Adversarial Networks", "comments": "19 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are unsupervised Deep Learning\napproach in the computer vision community which has gained significant\nattention from the last few years in identifying the internal structure of\nmultimodal medical imaging data. The adversarial network simultaneously\ngenerates realistic medical images and corresponding annotations, which proven\nto be useful in many cases such as image augmentation, image registration,\nmedical image generation, image reconstruction, and image-to-image translation.\nThese properties bring the attention of the researcher in the field of medical\nimage analysis and we are witness of rapid adaption in many novel and\ntraditional applications. This chapter provides state-of-the-art progress in\nGANs-based clinical application in medical image generation, and cross-modality\nsynthesis. The various framework of GANs which gained popularity in the\ninterpretation of medical images, such as Deep Convolutional GAN (DCGAN),\nLaplacian GAN (LAPGAN), pix2pix, CycleGAN, and unsupervised image-to-image\ntranslation model (UNIT), continue to improve their performance by\nincorporating additional hybrid architecture, has been discussed. Further, some\nof the recent applications of these frameworks for image reconstruction, and\nsynthesis, and future research directions in the area have been covered.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 20:31:57 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Singh", "Nripendra Kumar", ""], ["Raza", "Khalid", ""]]}, {"id": "2005.10691", "submitter": "Andrea Borghesi", "authors": "Andrea Borghesi, Federico Baldo, Michela Milano", "title": "Improving Deep Learning Models via Constraint-Based Domain Knowledge: a\n  Brief Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) models proved themselves to perform extremely well on a\nwide variety of learning tasks, as they can learn useful patterns from large\ndata sets. However, purely data-driven models might struggle when very\ndifficult functions need to be learned or when there is not enough available\ntraining data. Fortunately, in many domains prior information can be retrieved\nand used to boost the performance of DL models. This paper presents a first\nsurvey of the approaches devised to integrate domain knowledge, expressed in\nthe form of constraints, in DL learning models to improve their performance, in\nparticular targeting deep neural networks. We identify five (non-mutually\nexclusive) categories that encompass the main approaches to inject domain\nknowledge: 1) acting on the features space, 2) modifications to the hypothesis\nspace, 3) data augmentation, 4) regularization schemes, 5) constrained\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 15:34:09 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Borghesi", "Andrea", ""], ["Baldo", "Federico", ""], ["Milano", "Michela", ""]]}, {"id": "2005.10693", "submitter": "Mansura Habiba Miss", "authors": "Mansura Habiba, Barak A. Pearlmutter", "title": "Neural ODEs for Informative Missingness in Multivariate Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Informative missingness is unavoidable in the digital processing of\ncontinuous time series, where the value for one or more observations at\ndifferent time points are missing. Such missing observations are one of the\nmajor limitations of time series processing using deep learning. Practical\napplications, e.g., sensor data, healthcare, weather, generates data that is in\ntruth continuous in time, and informative missingness is a common phenomenon in\nthese datasets. These datasets often consist of multiple variables, and often\nthere are missing values for one or many of these variables. This\ncharacteristic makes time series prediction more challenging, and the impact of\nmissing input observations on the accuracy of the final output can be\nsignificant. A recent novel deep learning model called GRU-D is one early\nattempt to address informative missingness in time series data. On the other\nhand, a new family of neural networks called Neural ODEs (Ordinary Differential\nEquations) are natural and efficient for processing time series data which is\ncontinuous in time. In this paper, a deep learning model is proposed that\nleverages the effective imputation of GRU-D, and the temporal continuity of\nNeural ODEs. A time series classification task performed on the PhysioNet\ndataset demonstrates the performance of this architecture.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 00:28:30 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Habiba", "Mansura", ""], ["Pearlmutter", "Barak A.", ""]]}, {"id": "2005.10696", "submitter": "Hao Sun", "authors": "Hao Sun, Zhenghao Peng, Bo Dai, Jian Guo, Dahua Lin, Bolei Zhou", "title": "Novel Policy Seeking with Constrained Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In problem-solving, we humans can come up with multiple novel solutions to\nthe same problem. However, reinforcement learning algorithms can only produce a\nset of monotonous policies that maximize the cumulative reward but lack\ndiversity and novelty. In this work, we address the problem of generating novel\npolicies in reinforcement learning tasks. Instead of following the\nmulti-objective framework used in existing methods, we propose to rethink the\nproblem under a novel perspective of constrained optimization. We first\nintroduce a new metric to evaluate the difference between policies and then\ndesign two practical novel policy generation methods following the new\nperspective. The two proposed methods, namely the Constrained Task Novel\nBisector (CTNB) and the Interior Policy Differentiation (IPD), are derived from\nthe feasible direction method and the interior point method commonly known in\nthe constrained optimization literature. Experimental comparisons on the MuJoCo\ncontrol suite show our methods can achieve substantial improvement over\nprevious novelty-seeking methods in terms of both the novelty of policies and\ntheir performances in the primal task.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 14:39:14 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 07:18:38 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Sun", "Hao", ""], ["Peng", "Zhenghao", ""], ["Dai", "Bo", ""], ["Guo", "Jian", ""], ["Lin", "Dahua", ""], ["Zhou", "Bolei", ""]]}, {"id": "2005.10698", "submitter": "Robin Hirt", "authors": "Robin Hirt, Niklas K\\\"uhl, Yusuf Peker, Gerhard Satzger", "title": "How to Learn from Others: Transfer Machine Learning with Additive\n  Regression Models to Improve Sales Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a variety of business situations, the introduction or improvement of\nmachine learning approaches is impaired as these cannot draw on existing\nanalytical models. However, in many cases similar problems may have already\nbeen solved elsewhere-but the accumulated analytical knowledge cannot be tapped\nto solve a new problem, e.g., because of privacy barriers. For the particular\npurpose of sales forecasting for similar entities, we propose a transfer\nmachine learning approach based on additive regression models that lets new\nentities benefit from models of existing entities. We evaluate the approach on\na rich, multi-year dataset of multiple restaurant branches. We differentiate\nthe options to simply transfer models from one branch to another (\"zero shot\")\nor to transfer and adapt them. We analyze feasibility and performance against\nseveral forecasting benchmarks. The results show the potential of the approach\nto exploit the collectively available analytical knowledge. Thus, we contribute\nan approach that is generalizable beyond sales forecasting and the specific use\ncase in particular. In addition, we demonstrate its feasibility for a typical\nuse case as well as the potential for improving forecasting quality. These\nresults should inform academia, as they help to leverage knowledge across\nvarious entities, and have immediate practical application in industry.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 15:44:37 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Hirt", "Robin", ""], ["K\u00fchl", "Niklas", ""], ["Peker", "Yusuf", ""], ["Satzger", "Gerhard", ""]]}, {"id": "2005.10700", "submitter": "Hayden Helm", "authors": "Hayden S. Helm, Amitabh Basu, Avanti Athreya, Youngser Park, Joshua T.\n  Vogelstein, Michael Winding, Marta Zlatic, Albert Cardona, Patrick Bourke,\n  Jonathan Larson, Chris White, Carey E. Priebe", "title": "Learning to rank via combining representations", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to rank -- producing a ranked list of items specific to a query and\nwith respect to a set of supervisory items -- is a problem of general interest.\nThe setting we consider is one in which no analytic description of what\nconstitutes a good ranking is available. Instead, we have a collection of\nrepresentations and supervisory information consisting of a (target item,\ninteresting items set) pair. We demonstrate -- analytically, in simulation, and\nin real data examples -- that learning to rank via combining representations\nusing an integer linear program is effective when the supervision is as light\nas \"these few items are similar to your item of interest.\" While this\nnomination task is of general interest, for specificity we present our\nmethodology from the perspective of vertex nomination in graphs. The\nmethodology described herein is model agnostic.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 01:53:58 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 13:37:50 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Helm", "Hayden S.", ""], ["Basu", "Amitabh", ""], ["Athreya", "Avanti", ""], ["Park", "Youngser", ""], ["Vogelstein", "Joshua T.", ""], ["Winding", "Michael", ""], ["Zlatic", "Marta", ""], ["Cardona", "Albert", ""], ["Bourke", "Patrick", ""], ["Larson", "Jonathan", ""], ["White", "Chris", ""], ["Priebe", "Carey E.", ""]]}, {"id": "2005.10701", "submitter": "Alexandru Cristian Mara", "authors": "Alexandru Mara, Yoosof Mashayekhi, Jefrey Lijffijt, Tijl De Bie", "title": "CSNE: Conditional Signed Network Embedding", "comments": null, "journal-ref": null, "doi": "10.1145/3340531.3411959", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signed networks are mathematical structures that encode positive and negative\nrelations between entities such as friend/foe or trust/distrust. Recently,\nseveral papers studied the construction of useful low-dimensional\nrepresentations (embeddings) of these networks for the prediction of missing\nrelations or signs. Existing embedding methods for sign prediction generally\nenforce different notions of status or balance theories in their optimization\nfunction. These theories, however, are often inaccurate or incomplete, which\nnegatively impacts method performance.\n  In this context, we introduce conditional signed network embedding (CSNE).\nOur probabilistic approach models structural information about the signs in the\nnetwork separately from fine-grained detail. Structural information is\nrepresented in the form of a prior, while the embedding itself is used for\ncapturing fine-grained information. These components are then integrated in a\nrigorous manner. CSNE's accuracy depends on the existence of sufficiently\npowerful structural priors for modelling signed networks, currently unavailable\nin the literature. Thus, as a second main contribution, which we find to be\nhighly valuable in its own right, we also introduce a novel approach to\nconstruct priors based on the Maximum Entropy (MaxEnt) principle. These priors\ncan model the \\emph{polarity} of nodes (degree to which their links are\npositive) as well as signed \\emph{triangle counts} (a measure of the degree\nstructural balance holds to in a network).\n  Experiments on a variety of real-world networks confirm that CSNE outperforms\nthe state-of-the-art on the task of sign prediction. Moreover, the MaxEnt\npriors on their own, while less accurate than full CSNE, achieve accuracies\ncompetitive with the state-of-the-art at very limited computational cost, thus\nproviding an excellent runtime-accuracy trade-off in resource-constrained\nsituations.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 19:14:52 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 10:13:43 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Mara", "Alexandru", ""], ["Mashayekhi", "Yoosof", ""], ["Lijffijt", "Jefrey", ""], ["De Bie", "Tijl", ""]]}, {"id": "2005.10709", "submitter": "Yuan Wen", "authors": "Yuan Wen, Andrew Anderson, Valentin Radu, Michael F.P. O'Boyle, David\n  Gregg", "title": "TASO: Time and Space Optimization for Memory-Constrained DNN Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are used in many embedded applications,\nfrom industrial robotics and automation systems to biometric identification on\nmobile devices. State-of-the-art classification is typically achieved by large\nnetworks, which are prohibitively expensive to run on mobile and embedded\ndevices with tightly constrained memory and energy budgets. We propose an\napproach for ahead-of-time domain specific optimization of CNN models, based on\nan integer linear programming (ILP) for selecting primitive operations to\nimplement convolutional layers. We optimize the trade-off between execution\ntime and memory consumption by: 1) attempting to minimize execution time across\nthe whole network by selecting data layouts and primitive operations to\nimplement each layer; and 2) allocating an appropriate workspace that reflects\nthe upper bound of memory footprint per layer. These two optimization\nstrategies can be used to run any CNN on any platform with a C compiler. Our\nevaluation with a range of popular ImageNet neural architectures (GoogleNet,\nAlexNet, VGG, ResNet and SqueezeNet) on the ARM Cortex-A15 yields speedups of\n8x compared to a greedy algorithm based primitive selection, reduces memory\nrequirement by 2.2x while sacrificing only 15% of inference time compared to a\nsolver that considers inference time only. In addition, our optimization\napproach exposes a range of optimal points for different configurations across\nthe Pareto frontier of memory and latency trade-off, which can be used under\narbitrary system constraints.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 15:08:06 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Wen", "Yuan", ""], ["Anderson", "Andrew", ""], ["Radu", "Valentin", ""], ["O'Boyle", "Michael F. P.", ""], ["Gregg", "David", ""]]}, {"id": "2005.10716", "submitter": "Weixin Liang", "authors": "Weixin Liang, James Zou, Zhou Yu", "title": "Beyond User Self-Reported Likert Scale Ratings: A Comparison Model for\n  Automatic Dialog Evaluation", "comments": null, "journal-ref": "ACL 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open Domain dialog system evaluation is one of the most important challenges\nin dialog research. Existing automatic evaluation metrics, such as BLEU are\nmostly reference-based. They calculate the difference between the generated\nresponse and a limited number of available references. Likert-score based\nself-reported user rating is widely adopted by social conversational systems,\nsuch as Amazon Alexa Prize chatbots. However, self-reported user rating suffers\nfrom bias and variance among different users. To alleviate this problem, we\nformulate dialog evaluation as a comparison task. We also propose an automatic\nevaluation model CMADE (Comparison Model for Automatic Dialog Evaluation) that\nautomatically cleans self-reported user ratings as it trains on them.\nSpecifically, we first use a self-supervised method to learn better dialog\nfeature representation, and then use KNN and Shapley to remove confusing\nsamples. Our experiments show that CMADE achieves 89.2% accuracy in the dialog\ncomparison task.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 15:14:49 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 04:05:58 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Liang", "Weixin", ""], ["Zou", "James", ""], ["Yu", "Zhou", ""]]}, {"id": "2005.10743", "submitter": "Anru R. Zhang", "authors": "Yuetian Luo and Anru R. Zhang", "title": "Tensor Clustering with Planted Structures: Statistical Optimality and\n  Computational Limits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC cs.LG stat.ME stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper studies the statistical and computational limits of high-order\nclustering with planted structures. We focus on two clustering models, constant\nhigh-order clustering (CHC) and rank-one higher-order clustering (ROHC), and\nstudy the methods and theory for testing whether a cluster exists (detection)\nand identifying the support of cluster (recovery).\n  Specifically, we identify the sharp boundaries of signal-to-noise ratio for\nwhich CHC and ROHC detection/recovery are statistically possible. We also\ndevelop the tight computational thresholds: when the signal-to-noise ratio is\nbelow these thresholds, we prove that polynomial-time algorithms cannot solve\nthese problems under the computational hardness conjectures of hypergraphic\nplanted clique (HPC) detection and hypergraphic planted dense subgraph (HPDS)\nrecovery. We also propose polynomial-time tensor algorithms that achieve\nreliable detection and recovery when the signal-to-noise ratio is above these\nthresholds. Both sparsity and tensor structures yield the computational\nbarriers in high-order tensor clustering. The interplay between them results in\nsignificant differences between high-order tensor clustering and matrix\nclustering in literature in aspects of statistical and computational phase\ntransition diagrams, algorithmic approaches, hardness conjecture, and proof\ntechniques. To our best knowledge, we are the first to give a thorough\ncharacterization of the statistical and computational trade-off for such a\ndouble computational-barrier problem. Finally, we provide evidence for the\ncomputational hardness conjectures of HPC detection and HPDS recovery.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 15:53:44 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 01:57:19 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Luo", "Yuetian", ""], ["Zhang", "Anru R.", ""]]}, {"id": "2005.10745", "submitter": "Mohammed Yousefhussien", "authors": "Mohammed Yousefhussien, David J. Kelbe, and Carl Salvaggio", "title": "A Nearest Neighbor Network to Extract Digital Terrain Models from 3D\n  Point Clouds", "comments": "Preprint submitted to Science of Remote Sensing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When 3D-point clouds from overhead sensors are used as input to remote\nsensing data exploitation pipelines, a large amount of effort is devoted to\ndata preparation. Among the multiple stages of the preprocessing chain,\nestimating the Digital Terrain Model (DTM) model is considered to be of a high\nimportance; however, this remains a challenge, especially for raw point clouds\nderived from optical imagery. Current algorithms estimate the ground points\nusing either a set of geometrical rules that require tuning multiple parameters\nand human interaction, or cast the problem as a binary classification machine\nlearning task where ground and non-ground classes are found. In contrast, here\nwe present an algorithm that directly operates on 3D-point clouds and estimate\nthe underlying DTM for the scene using an end-to-end approach without the need\nto classify points into ground and non-ground cover types. Our model learns\nneighborhood information and seamlessly integrates this with point-wise and\nblock-wise global features. We validate our model using the ISPRS 3D Semantic\nLabeling Contest LiDAR data, as well as three scenes generated using dense\nstereo matching, representative of high-rise buildings, lower urban structures,\nand a dense old-city residential area. We compare our findings with two widely\nused software packages for DTM extraction, namely ENVI and LAStools. Our\npreliminary results show that the proposed method is able to achieve an overall\nMean Absolute Error of 11.5% compared to 29% and 16% for ENVI and LAStools.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 15:54:55 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 19:51:13 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Yousefhussien", "Mohammed", ""], ["Kelbe", "David J.", ""], ["Salvaggio", "Carl", ""]]}, {"id": "2005.10750", "submitter": "Yong Man Ro", "authors": "Byeong Cheon Kim, Jung Uk Kim, Hakmin Lee, Yong Man Ro", "title": "Revisiting Role of Autoencoders in Adversarial Settings", "comments": "Accepted at ICIP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To combat against adversarial attacks, autoencoder structure is widely used\nto perform denoising which is regarded as gradient masking. In this paper, we\nrevisit the role of autoencoders in adversarial settings. Through the\ncomprehensive experimental results and analysis, this paper presents the\ninherent property of adversarial robustness in the autoencoders. We also found\nthat autoencoders may use robust features that cause inherent adversarial\nrobustness. We believe that our discovery of the adversarial robustness of the\nautoencoders can provide clues to the future research and applications for\nadversarial defense.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 16:01:23 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Kim", "Byeong Cheon", ""], ["Kim", "Jung Uk", ""], ["Lee", "Hakmin", ""], ["Ro", "Yong Man", ""]]}, {"id": "2005.10757", "submitter": "Yong Man Ro", "authors": "Hakmin Lee, Hong Joo Lee, Seong Tae Kim, Yong Man Ro", "title": "Robust Ensemble Model Training via Random Layer Sampling Against\n  Adversarial Attack", "comments": "Accepted at BMVC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved substantial achievements in several\ncomputer vision areas, but have vulnerabilities that are often fooled by\nadversarial examples that are not recognized by humans. This is an important\nissue for security or medical applications. In this paper, we propose an\nensemble model training framework with random layer sampling to improve the\nrobustness of deep neural networks. In the proposed training framework, we\ngenerate various sampled model through the random layer sampling and update the\nweight of the sampled model. After the ensemble models are trained, it can hide\nthe gradient efficiently and avoid the gradient-based attack by the random\nlayer sampling method. To evaluate our proposed method, comprehensive and\ncomparative experiments have been conducted on three datasets. Experimental\nresults show that the proposed method improves the adversarial robustness.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 16:14:18 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 13:20:57 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Lee", "Hakmin", ""], ["Lee", "Hong Joo", ""], ["Kim", "Seong Tae", ""], ["Ro", "Yong Man", ""]]}, {"id": "2005.10761", "submitter": "Leighton Barnes", "authors": "Leighton Pate Barnes, Huseyin A. Inan, Berivan Isik, and Ayfer Ozgur", "title": "rTop-k: A Statistical Estimation Approach to Distributed SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large communication cost for exchanging gradients between different nodes\nsignificantly limits the scalability of distributed training for large-scale\nlearning models. Motivated by this observation, there has been significant\nrecent interest in techniques that reduce the communication cost of distributed\nStochastic Gradient Descent (SGD), with gradient sparsification techniques such\nas top-k and random-k shown to be particularly effective. The same observation\nhas also motivated a separate line of work in distributed statistical\nestimation theory focusing on the impact of communication constraints on the\nestimation efficiency of different statistical models. The primary goal of this\npaper is to connect these two research lines and demonstrate how statistical\nestimation models and their analysis can lead to new insights in the design of\ncommunication-efficient training techniques. We propose a simple statistical\nestimation model for the stochastic gradients which captures the sparsity and\nskewness of their distribution. The statistically optimal communication scheme\narising from the analysis of this model leads to a new sparsification technique\nfor SGD, which concatenates random-k and top-k, considered separately in the\nprior literature. We show through extensive experiments on both image and\nlanguage domains with CIFAR-10, ImageNet, and Penn Treebank datasets that the\nconcatenated application of these two sparsification methods consistently and\nsignificantly outperforms either method applied alone.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 16:27:46 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 21:26:06 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Barnes", "Leighton Pate", ""], ["Inan", "Huseyin A.", ""], ["Isik", "Berivan", ""], ["Ozgur", "Ayfer", ""]]}, {"id": "2005.10785", "submitter": "Eduard Gorbunov", "authors": "Eduard Gorbunov, Marina Danilova, Alexander Gasnikov", "title": "Stochastic Optimization with Heavy-Tailed Noise via Accelerated Gradient\n  Clipping", "comments": "NeurIPS 2020; 60 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new accelerated stochastic first-order method\ncalled clipped-SSTM for smooth convex stochastic optimization with heavy-tailed\ndistributed noise in stochastic gradients and derive the first high-probability\ncomplexity bounds for this method closing the gap in the theory of stochastic\noptimization with heavy-tailed noise. Our method is based on a special variant\nof accelerated Stochastic Gradient Descent (SGD) and clipping of stochastic\ngradients. We extend our method to the strongly convex case and prove new\ncomplexity bounds that outperform state-of-the-art results in this case.\nFinally, we extend our proof technique and derive the first non-trivial\nhigh-probability complexity bounds for SGD with clipping without light-tails\nassumption on the noise.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 17:05:27 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 11:00:08 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Gorbunov", "Eduard", ""], ["Danilova", "Marina", ""], ["Gasnikov", "Alexander", ""]]}, {"id": "2005.10791", "submitter": "Nihat Ay", "authors": "Nihat Ay", "title": "On the Locality of the Natural Gradient for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the natural gradient method for learning in deep Bayesian networks,\nincluding neural networks. There are two natural geometries associated with\nsuch learning systems consisting of visible and hidden units. One geometry is\nrelated to the full system, the other one to the visible sub-system. These two\ngeometries imply different natural gradients. In a first step, we demonstrate a\ngreat simplification of the natural gradient with respect to the first\ngeometry, due to locality properties of the Fisher information matrix. This\nsimplification does not directly translate to a corresponding simplification\nwith respect to the second geometry. We develop the theory for studying the\nrelation between the two versions of the natural gradient and outline a method\nfor the simplification of the natural gradient with respect to the second\ngeometry based on the first one. This method suggests to incorporate a\nrecognition model as an auxiliary model for the efficient application of the\nnatural gradient method in deep networks.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 17:17:03 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Ay", "Nihat", ""]]}, {"id": "2005.10804", "submitter": "Ruosong Wang", "authors": "Ruosong Wang, Ruslan Salakhutdinov, Lin F. Yang", "title": "Reinforcement Learning with General Value Function Approximation:\n  Provably Efficient Approach via Bounded Eluder Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value function approximation has demonstrated phenomenal empirical success in\nreinforcement learning (RL). Nevertheless, despite a handful of recent progress\non developing theory for RL with linear function approximation, the\nunderstanding of general function approximation schemes largely remains\nmissing. In this paper, we establish a provably efficient RL algorithm with\ngeneral value function approximation. We show that if the value functions admit\nan approximation with a function class $\\mathcal{F}$, our algorithm achieves a\nregret bound of $\\widetilde{O}(\\mathrm{poly}(dH)\\sqrt{T})$ where $d$ is a\ncomplexity measure of $\\mathcal{F}$ that depends on the eluder dimension [Russo\nand Van Roy, 2013] and log-covering numbers, $H$ is the planning horizon, and\n$T$ is the number interactions with the environment. Our theory generalizes\nrecent progress on RL with linear value function approximation and does not\nmake explicit assumptions on the model of the environment. Moreover, our\nalgorithm is model-free and provides a framework to justify the effectiveness\nof algorithms used in practice.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 17:36:09 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 18:59:13 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 17:49:05 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Wang", "Ruosong", ""], ["Salakhutdinov", "Ruslan", ""], ["Yang", "Lin F.", ""]]}, {"id": "2005.10807", "submitter": "Stephan Wojtowytsch", "authors": "Weinan E and Stephan Wojtowytsch", "title": "Kolmogorov Width Decay and Poor Approximators in Machine Learning:\n  Shallow Neural Networks, Random Feature Models and Neural Tangent Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a scale separation of Kolmogorov width type between subspaces of\na given Banach space under the condition that a sequence of linear maps\nconverges much faster on one of the subspaces. The general technique is then\napplied to show that reproducing kernel Hilbert spaces are poor\n$L^2$-approximators for the class of two-layer neural networks in high\ndimension, and that multi-layer networks with small path norm are poor\napproximators for certain Lipschitz functions, also in the $L^2$-topology.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 17:40:38 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 05:33:48 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["E", "Weinan", ""], ["Wojtowytsch", "Stephan", ""]]}, {"id": "2005.10815", "submitter": "Stephan Wojtowytsch", "authors": "Stephan Wojtowytsch and Weinan E", "title": "Can Shallow Neural Networks Beat the Curse of Dimensionality? A mean\n  field training perspective", "comments": "5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the gradient descent training of a two-layer neural network on\nempirical or population risk may not decrease population risk at an order\nfaster than $t^{-4/(d-2)}$ under mean field scaling. Thus gradient descent\ntraining for fitting reasonably smooth, but truly high-dimensional data may be\nsubject to the curse of dimensionality. We present numerical evidence that\ngradient descent training with general Lipschitz target functions becomes\nslower and slower as the dimension increases, but converges at approximately\nthe same rate in all dimensions when the target function lies in the natural\nfunction space for two-layer ReLU networks.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 17:50:15 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Wojtowytsch", "Stephan", ""], ["E", "Weinan", ""]]}, {"id": "2005.10817", "submitter": "Alexander Wein", "authors": "Matthias L\\\"offler, Alexander S. Wein, Afonso S. Bandeira", "title": "Computationally efficient sparse clustering", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study statistical and computational limits of clustering when the means of\nthe centres are sparse and their dimension is possibly much larger than the\nsample size. Our theoretical analysis focuses on the model $X_i = z_i \\theta +\n\\varepsilon_i, ~z_i \\in \\{-1,1\\}, ~\\varepsilon_i \\thicksim \\mathcal{N}(0,I)$,\nwhich has two clusters with centres $\\theta$ and $-\\theta$. We provide a finite\nsample analysis of a new sparse clustering algorithm based on sparse PCA and\nshow that it achieves the minimax optimal misclustering rate in the regime\n$\\|\\theta\\| \\rightarrow \\infty$.\n  Our results require the sparsity to grow slower than the square root of the\nsample size. Using a recent framework for computational lower bounds -- the\nlow-degree likelihood ratio -- we give evidence that this condition is\nnecessary for any polynomial-time clustering algorithm to succeed below the BBP\nthreshold. This complements existing evidence based on reductions and\nstatistical query lower bounds. Compared to these existing results, we cover a\nwider set of parameter regimes and give a more precise understanding of the\nruntime required and the misclustering error achievable. Our results imply that\na large class of tests based on low-degree polynomials fail to solve even the\nweak testing task.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 17:51:30 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 17:21:09 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 17:38:04 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["L\u00f6ffler", "Matthias", ""], ["Wein", "Alexander S.", ""], ["Bandeira", "Afonso S.", ""]]}, {"id": "2005.10831", "submitter": "Xiang Song Dr.", "authors": "Xiangxiang Zeng, Xiang Song, Tengfei Ma, Xiaoqin Pan, Yadi Zhou, Yuan\n  Hou, Zheng Zhang, George Karypis, and Feixiong Cheng", "title": "Repurpose Open Data to Discover Therapeutics for COVID-19 using Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been more than 850,000 confirmed cases and over 48,000 deaths from\nthe human coronavirus disease 2019 (COVID-19) pandemic, caused by novel severe\nacute respiratory syndrome coronavirus (SARS-CoV-2), in the United States\nalone. However, there are currently no proven effective medications against\nCOVID-19. Drug repurposing offers a promising way for the development of\nprevention and treatment strategies for COVID-19. This study reports an\nintegrative, network-based deep learning methodology to identify repurposable\ndrugs for COVID-19 (termed CoV-KGE). Specifically, we built a comprehensive\nknowledge graph that includes 15 million edges across 39 types of relationships\nconnecting drugs, diseases, genes, pathways, and expressions, from a large\nscientific corpus of 24 million PubMed publications. Using Amazon AWS computing\nresources, we identified 41 repurposable drugs (including indomethacin,\ntoremifene and niclosamide) whose therapeutic association with COVID-19 were\nvalidated by transcriptomic and proteomic data in SARS-CoV-2 infected human\ncells and data from ongoing clinical trials. While this study, by no means\nrecommends specific drugs, it demonstrates a powerful deep learning methodology\nto prioritize existing drugs for further investigation, which holds the\npotential of accelerating therapeutic development for COVID-19.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 16:02:29 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Zeng", "Xiangxiang", ""], ["Song", "Xiang", ""], ["Ma", "Tengfei", ""], ["Pan", "Xiaoqin", ""], ["Zhou", "Yadi", ""], ["Hou", "Yuan", ""], ["Zhang", "Zheng", ""], ["Karypis", "George", ""], ["Cheng", "Feixiong", ""]]}, {"id": "2005.10848", "submitter": "Surin Ahn", "authors": "Surin Ahn, Ayfer Ozgur and Mert Pilanci", "title": "Global Multiclass Classification and Dataset Construction via\n  Heterogeneous Local Experts", "comments": "27 pages, 8 figures, to be published in IEEE Journal on Selected\n  Areas in Information Theory (JSAIT) - Special Issue on Estimation and\n  Inference", "journal-ref": null, "doi": "10.1109/JSAIT.2020.3041804", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the domains of dataset construction and crowdsourcing, a notable challenge\nis to aggregate labels from a heterogeneous set of labelers, each of whom is\npotentially an expert in some subset of tasks (and less reliable in others). To\nreduce costs of hiring human labelers or training automated labeling systems,\nit is of interest to minimize the number of labelers while ensuring the\nreliability of the resulting dataset. We model this as the problem of\nperforming $K$-class classification using the predictions of smaller\nclassifiers, each trained on a subset of $[K]$, and derive bounds on the number\nof classifiers needed to accurately infer the true class of an unlabeled sample\nunder both adversarial and stochastic assumptions. By exploiting a connection\nto the classical set cover problem, we produce a near-optimal scheme for\ndesigning such configurations of classifiers which recovers the well known\none-vs.-one classification approach as a special case. Experiments with the\nMNIST and CIFAR-10 datasets demonstrate the favorable accuracy (compared to a\ncentralized classifier) of our aggregation scheme applied to classifiers\ntrained on subsets of the data. These results suggest a new way to\nautomatically label data or adapt an existing set of local classifiers to\nlarger-scale multiclass problems.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 18:07:42 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 04:34:43 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2021 23:34:36 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Ahn", "Surin", ""], ["Ozgur", "Ayfer", ""], ["Pilanci", "Mert", ""]]}, {"id": "2005.10851", "submitter": "Yinghan Long", "authors": "Yinghan Long, Indranil Chakraborty, Kaushik Roy", "title": "Conditionally Deep Hybrid Neural Networks Across Edge and Cloud", "comments": "6 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pervasiveness of \"Internet-of-Things\" in our daily life has led to a\nrecent surge in fog computing, encompassing a collaboration of cloud computing\nand edge intelligence. To that effect, deep learning has been a major driving\nforce towards enabling such intelligent systems. However, growing model sizes\nin deep learning pose a significant challenge towards deployment in\nresource-constrained edge devices. Moreover, in a distributed intelligence\nenvironment, efficient workload distribution is necessary between edge and\ncloud systems. To address these challenges, we propose a conditionally deep\nhybrid neural network for enabling AI-based fog computing. The proposed network\ncan be deployed in a distributed manner, consisting of quantized layers and\nearly exits at the edge and full-precision layers on the cloud. During\ninference, if an early exit has high confidence in the classification results,\nit would allow samples to exit at the edge, and the deeper layers on the cloud\nare activated conditionally, which can lead to improved energy efficiency and\ninference latency. We perform an extensive design space exploration with the\ngoal of minimizing energy consumption at the edge while achieving\nstate-of-the-art classification accuracies on image classification tasks. We\nshow that with binarized layers at the edge, the proposed conditional hybrid\nnetwork can process 65% of inferences at the edge, leading to 5.5x\ncomputational energy reduction with minimal accuracy degradation on CIFAR-10\ndataset. For the more complex dataset CIFAR-100, we observe that the proposed\nnetwork with 4-bit quantization at the edge achieves 52% early classification\nat the edge with 4.8x energy reduction. The analysis gives us insights on\ndesigning efficient hybrid networks which achieve significantly higher energy\nefficiency than full-precision networks for edge-cloud based distributed\nintelligence systems.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 18:18:43 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Long", "Yinghan", ""], ["Chakraborty", "Indranil", ""], ["Roy", "Kaushik", ""]]}, {"id": "2005.10856", "submitter": "Chao Zhou", "authors": "Chao Zhou", "title": "Hyperspectral Unmixing Network Inspired by Unfolding an Optimization\n  Problem", "comments": "mis-uploading. It is a paper still under construciton", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hyperspectral image (HSI) unmixing task is essentially an inverse\nproblem, which is commonly solved by optimization algorithms under a predefined\n(non-)linear mixture model. Although these optimization algorithms show\nimpressive performance, they are very computational demanding as they often\nrely on an iterative updating scheme. Recently, the rise of neural networks has\ninspired lots of learning based algorithms in unmixing literature. However,\nmost of them lack of interpretability and require a large training dataset. One\nnatural question then arises: can one leverage the model based algorithm and\nlearning based algorithm to achieve interpretable and fast algorithm for HSI\nunmixing problem? In this paper, we propose two novel network architectures,\nnamed U-ADMM-AENet and U-ADMM-BUNet, for abundance estimation and blind\nunmixing respectively, by combining the conventional optimization-model based\nunmixing method and the rising learning based unmixing method. We first\nconsider a linear mixture model with sparsity constraint, then we unfold\nAlternating Direction Method of Multipliers (ADMM) algorithm to construct the\nunmixing network structures. We also show that the unfolded structures can find\ncorresponding interpretations in machine learning literature, which further\ndemonstrates the effectiveness of proposed methods. Benefit from the\ninterpretation, the proposed networks can be initialized by incorporating prior\ninformation about the HSI data. Different from traditional unfolding networks,\nwe propose a new training strategy for proposed networks to better fit in the\nHSI applications. Extensive experiments show that the proposed methods can\nachieve much faster convergence and competitive performance even with very\nsmall size of training data, when compared with state-of-art algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 18:49:45 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 10:14:58 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Zhou", "Chao", ""]]}, {"id": "2005.10865", "submitter": "Benjamin Nye", "authors": "Benjamin E. Nye, Ani Nenkova, Iain J. Marshall, Byron C. Wallace", "title": "Trialstreamer: Mapping and Browsing Medical Evidence in Real-Time", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Trialstreamer, a living database of clinical trial reports. Here\nwe mainly describe the evidence extraction component; this extracts from\nbiomedical abstracts key pieces of information that clinicians need when\nappraising the literature, and also the relations between these. Specifically,\nthe system extracts descriptions of trial participants, the treatments compared\nin each arm (the interventions), and which outcomes were measured. The system\nthen attempts to infer which interventions were reported to work best by\ndetermining their relationship with identified trial outcome measures. In\naddition to summarizing individual trials, these extracted data elements allow\nautomatic synthesis of results across many trials on the same topic. We apply\nthe system at scale to all reports of randomized controlled trials indexed in\nMEDLINE, powering the automatic generation of evidence maps, which provide a\nglobal view of the efficacy of different interventions combining data from all\nrelevant clinical trials on a topic. We make all code and models freely\navailable alongside a demonstration of the web interface.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 19:32:04 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Nye", "Benjamin E.", ""], ["Nenkova", "Ani", ""], ["Marshall", "Iain J.", ""], ["Wallace", "Byron C.", ""]]}, {"id": "2005.10872", "submitter": "Carlos Florensa", "authors": "Michelle A. Lee, Carlos Florensa, Jonathan Tremblay, Nathan Ratliff,\n  Animesh Garg, Fabio Ramos, Dieter Fox", "title": "Guided Uncertainty-Aware Policy Optimization: Combining Learning and\n  Model-Based Strategies for Sample-Efficient Policy Learning", "comments": null, "journal-ref": "International Conference in Robotics and Automation 2020", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional robotic approaches rely on an accurate model of the environment,\na detailed description of how to perform the task, and a robust perception\nsystem to keep track of the current state. On the other hand, reinforcement\nlearning approaches can operate directly from raw sensory inputs with only a\nreward signal to describe the task, but are extremely sample-inefficient and\nbrittle. In this work, we combine the strengths of model-based methods with the\nflexibility of learning-based methods to obtain a general method that is able\nto overcome inaccuracies in the robotics perception/actuation pipeline, while\nrequiring minimal interactions with the environment. This is achieved by\nleveraging uncertainty estimates to divide the space in regions where the given\nmodel-based policy is reliable, and regions where it may have flaws or not be\nwell defined. In these uncertain regions, we show that a locally learned-policy\ncan be used directly with raw sensory inputs. We test our algorithm, Guided\nUncertainty-Aware Policy Optimization (GUAPO), on a real-world robot performing\npeg insertion. Videos are available at https://sites.google.com/view/guapo-rl\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 19:47:05 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 16:34:43 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Lee", "Michelle A.", ""], ["Florensa", "Carlos", ""], ["Tremblay", "Jonathan", ""], ["Ratliff", "Nathan", ""], ["Garg", "Animesh", ""], ["Ramos", "Fabio", ""], ["Fox", "Dieter", ""]]}, {"id": "2005.10876", "submitter": "Marco Toldo", "authors": "Marco Toldo, Andrea Maracani, Umberto Michieli and Pietro Zanuttigh", "title": "Unsupervised Domain Adaptation in Semantic Segmentation: a Review", "comments": "34 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to give an overview of the recent advancements in\nthe Unsupervised Domain Adaptation (UDA) of deep networks for semantic\nsegmentation. This task is attracting a wide interest, since semantic\nsegmentation models require a huge amount of labeled data and the lack of data\nfitting specific requirements is the main limitation in the deployment of these\ntechniques. This problem has been recently explored and has rapidly grown with\na large number of ad-hoc approaches. This motivates us to build a comprehensive\noverview of the proposed methodologies and to provide a clear categorization.\nIn this paper, we start by introducing the problem, its formulation and the\nvarious scenarios that can be considered. Then, we introduce the different\nlevels at which adaptation strategies may be applied: namely, at the input\n(image) level, at the internal features representation and at the output level.\nFurthermore, we present a detailed overview of the literature in the field,\ndividing previous methods based on the following (non mutually exclusive)\ncategories: adversarial learning, generative-based, analysis of the classifier\ndiscrepancies, self-teaching, entropy minimization, curriculum learning and\nmulti-task learning. Novel research directions are also briefly introduced to\ngive a hint of interesting open problems in the field. Finally, a comparison of\nthe performance of the various methods in the widely used autonomous driving\nscenario is presented.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 20:10:38 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Toldo", "Marco", ""], ["Maracani", "Andrea", ""], ["Michieli", "Umberto", ""], ["Zanuttigh", "Pietro", ""]]}, {"id": "2005.10879", "submitter": "Steven Smith", "authors": "Steven T. Smith, Edward K. Kao, Erika D. Mackin, Danelle C. Shah, Olga\n  Simek, Donald B. Rubin", "title": "Automatic Detection of Influential Actors in Disinformation Networks", "comments": "Proc. Natl. Acad. Sciences U.S.A. Vol. 118, No. 4, e2011216118", "journal-ref": null, "doi": "10.1073/pnas.2011216118", "report-no": null, "categories": "cs.SI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The weaponization of digital communications and social media to conduct\ndisinformation campaigns at immense scale, speed, and reach presents new\nchallenges to identify and counter hostile influence operations (IOs). This\npaper presents an end-to-end framework to automate detection of disinformation\nnarratives, networks, and influential actors. The framework integrates natural\nlanguage processing, machine learning, graph analytics, and a novel network\ncausal inference approach to quantify the impact of individual actors in\nspreading IO narratives. We demonstrate its capability on real-world hostile IO\ncampaigns with Twitter datasets collected during the 2017 French presidential\nelections, and known IO accounts disclosed by Twitter over a broad range of IO\ncampaigns (May 2007 to February 2020), over 50,000 accounts, 17 countries, and\ndifferent account types including both trolls and bots. Our system detects IO\naccounts with 96% precision, 79% recall, and 96% area-under-the-PR-curve, maps\nout salient network communities, and discovers high-impact accounts that escape\nthe lens of traditional impact statistics based on activity counts and network\ncentrality. Results are corroborated with independent sources of known IO\naccounts from U.S. Congressional reports, investigative journalism, and IO\ndatasets provided by Twitter.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 20:15:51 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 01:10:13 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2021 22:15:57 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Smith", "Steven T.", ""], ["Kao", "Edward K.", ""], ["Mackin", "Erika D.", ""], ["Shah", "Danelle C.", ""], ["Simek", "Olga", ""], ["Rubin", "Donald B.", ""]]}, {"id": "2005.10881", "submitter": "Bargav Jayaraman", "authors": "Bargav Jayaraman, Lingxiao Wang, Katherine Knipmeyer, Quanquan Gu,\n  David Evans", "title": "Revisiting Membership Inference Under Realistic Assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study membership inference in settings where some of the assumptions\ntypically used in previous research are relaxed. First, we consider skewed\npriors, to cover cases such as when only a small fraction of the candidate pool\ntargeted by the adversary are actually members and develop a PPV-based metric\nsuitable for this setting. This setting is more realistic than the balanced\nprior setting typically considered by researchers. Second, we consider\nadversaries that select inference thresholds according to their attack goals\nand develop a threshold selection procedure that improves inference attacks.\nSince previous inference attacks fail in imbalanced prior setting, we develop a\nnew inference attack based on the intuition that inputs corresponding to\ntraining set members will be near a local minimum in the loss function, and\nshow that an attack that combines this with thresholds on the per-instance loss\ncan achieve high PPV even in settings where other attacks appear to be\nineffective. Code for our experiments can be found here:\nhttps://github.com/bargavj/EvaluatingDPML.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 20:17:42 GMT"}, {"version": "v2", "created": "Sun, 21 Jun 2020 17:24:39 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 16:57:30 GMT"}, {"version": "v4", "created": "Sat, 3 Oct 2020 13:37:57 GMT"}, {"version": "v5", "created": "Wed, 13 Jan 2021 20:44:44 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Jayaraman", "Bargav", ""], ["Wang", "Lingxiao", ""], ["Knipmeyer", "Katherine", ""], ["Gu", "Quanquan", ""], ["Evans", "David", ""]]}, {"id": "2005.10884", "submitter": "Chong Xiang", "authors": "Chong Xiang, Arjun Nitin Bhagoji, Vikash Sehwag, Prateek Mittal", "title": "PatchGuard: A Provably Robust Defense against Adversarial Patches via\n  Small Receptive Fields and Masking", "comments": "USENIX Security Symposium 2021; extended technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Localized adversarial patches aim to induce misclassification in machine\nlearning models by arbitrarily modifying pixels within a restricted region of\nan image. Such attacks can be realized in the physical world by attaching the\nadversarial patch to the object to be misclassified, and defending against such\nattacks is an unsolved/open problem. In this paper, we propose a general\ndefense framework called PatchGuard that can achieve high provable robustness\nwhile maintaining high clean accuracy against localized adversarial patches.\nThe cornerstone of PatchGuard involves the use of CNNs with small receptive\nfields to impose a bound on the number of features corrupted by an adversarial\npatch. Given a bounded number of corrupted features, the problem of designing\nan adversarial patch defense reduces to that of designing a secure feature\naggregation mechanism. Towards this end, we present our robust masking defense\nthat robustly detects and masks corrupted features to recover the correct\nprediction. Notably, we can prove the robustness of our defense against any\nadversary within our threat model. Our extensive evaluation on ImageNet,\nImageNette (a 10-class subset of ImageNet), and CIFAR-10 datasets demonstrates\nthat our defense achieves state-of-the-art performance in terms of both\nprovable robust accuracy and clean accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 03:38:34 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 14:51:03 GMT"}, {"version": "v3", "created": "Sun, 2 Aug 2020 15:39:00 GMT"}, {"version": "v4", "created": "Sun, 18 Oct 2020 18:12:03 GMT"}, {"version": "v5", "created": "Wed, 31 Mar 2021 14:20:39 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Xiang", "Chong", ""], ["Bhagoji", "Arjun Nitin", ""], ["Sehwag", "Vikash", ""], ["Mittal", "Prateek", ""]]}, {"id": "2005.10902", "submitter": "Artur M Schweidtmann", "authors": "Artur M. Schweidtmann, Dominik Bongartz, Daniel Grothe, Tim\n  Kerkenhoff, Xiaopeng Lin, Jaromil Najman, Alexander Mitsos", "title": "Global Optimization of Gaussian processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes~(Kriging) are interpolating data-driven models that are\nfrequently applied in various disciplines. Often, Gaussian processes are\ntrained on datasets and are subsequently embedded as surrogate models in\noptimization problems. These optimization problems are nonconvex and global\noptimization is desired. However, previous literature observed computational\nburdens limiting deterministic global optimization to Gaussian processes\ntrained on few data points. We propose a reduced-space formulation for\ndeterministic global optimization with trained Gaussian processes embedded. For\noptimization, the branch-and-bound solver branches only on the degrees of\nfreedom and McCormick relaxations are propagated through explicit Gaussian\nprocess models. The approach also leads to significantly smaller and\ncomputationally cheaper subproblems for lower and upper bounding. To further\naccelerate convergence, we derive envelopes of common covariance functions for\nGPs and tight relaxations of acquisition functions used in Bayesian\noptimization including expected improvement, probability of improvement, and\nlower confidence bound. In total, we reduce computational time by orders of\nmagnitude compared to state-of-the-art methods, thus overcoming previous\ncomputational burdens. We demonstrate the performance and scaling of the\nproposed method and apply it to Bayesian optimization with global optimization\nof the acquisition function and chance-constrained programming. The Gaussian\nprocess models, acquisition functions, and training scripts are available\nopen-source within the \"MeLOn - Machine Learning Models for Optimization\"\ntoolbox~(https://git.rwth-aachen.de/avt.svt/public/MeLOn).\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 20:59:11 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Schweidtmann", "Artur M.", ""], ["Bongartz", "Dominik", ""], ["Grothe", "Daniel", ""], ["Kerkenhoff", "Tim", ""], ["Lin", "Xiaopeng", ""], ["Najman", "Jaromil", ""], ["Mitsos", "Alexander", ""]]}, {"id": "2005.10903", "submitter": "Peratham Wiriyathammabhum Mr.", "authors": "Peratham Wiriyathammabhum", "title": "SpotFast Networks with Memory Augmented Lateral Transformers for\n  Lipreading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel deep learning architecture for word-level\nlipreading. Previous works suggest a potential for incorporating a pretrained\ndeep 3D Convolutional Neural Networks as a front-end feature extractor. We\nintroduce a SpotFast networks, a variant of the state-of-the-art SlowFast\nnetworks for action recognition, which utilizes a temporal window as a spot\npathway and all frames as a fast pathway. We further incorporate memory\naugmented lateral transformers to learn sequential features for classification.\nWe evaluate the proposed model on the LRW dataset. The experiments show that\nour proposed model outperforms various state-of-the-art models and\nincorporating the memory augmented lateral transformers makes a 3.7%\nimprovement to the SpotFast networks.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 21:04:12 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Wiriyathammabhum", "Peratham", ""]]}, {"id": "2005.10912", "submitter": "Hadi Shafiee Dr.", "authors": "Prudhvi Thirumalaraju, Manoj Kumar Kanakasabapathy, Charles L Bormann,\n  Raghav Gupta, Rohan Pooniwala, Hemanth Kandula, Irene Souter, Irene\n  Dimitriadis, Hadi Shafiee", "title": "Evaluation of deep convolutional neural networks in classifying human\n  embryo images based on their morphological quality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A critical factor that influences the success of an in-vitro fertilization\n(IVF) procedure is the quality of the transferred embryo. Embryo morphology\nassessments, conventionally performed through manual microscopic analysis\nsuffer from disparities in practice, selection criteria, and subjectivity due\nto the experience of the embryologist. Convolutional neural networks (CNNs) are\npowerful, promising algorithms with significant potential for accurate\nclassifications across many object categories. Network architectures and\nhyper-parameters affect the efficiency of CNNs for any given task. Here, we\nevaluate multi-layered CNNs developed from scratch and popular deep-learning\narchitectures such as Inception v3, ResNET, Inception-ResNET-v2, and Xception\nin differentiating between embryos based on their morphological quality at 113\nhours post insemination (hpi). Xception performed the best in differentiating\nbetween the embryos based on their morphological quality.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 21:21:22 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Thirumalaraju", "Prudhvi", ""], ["Kanakasabapathy", "Manoj Kumar", ""], ["Bormann", "Charles L", ""], ["Gupta", "Raghav", ""], ["Pooniwala", "Rohan", ""], ["Kandula", "Hemanth", ""], ["Souter", "Irene", ""], ["Dimitriadis", "Irene", ""], ["Shafiee", "Hadi", ""]]}, {"id": "2005.10915", "submitter": "Sourya Dipta Das", "authors": "Sourya Dipta Das, Soumil Mandal", "title": "Team Neuro at SemEval-2020 Task 8: Multi-Modal Fine Grain Emotion\n  Classification of Memes using Multitask Learning", "comments": "Proceedings of the International Workshop on Semantic Evaluation\n  (SemEval)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we describe the system that we used for the memotion\nanalysis challenge, which is Task 8 of SemEval-2020. This challenge had three\nsubtasks where affect based sentiment classification of the memes was required\nalong with intensities. The system we proposed combines the three tasks into a\nsingle one by representing it as multi-label hierarchical classification\nproblem.Here,Multi-Task learning or Joint learning Procedure is used to train\nour model.We have used dual channels to extract text and image based features\nfrom separate Deep Neural Network Backbone and aggregate them to create task\nspecific features. These task specific aggregated feature vectors ware then\npassed on to smaller networks with dense layers, each one assigned for\npredicting one type of fine grain sentiment label. Our Proposed method show the\nsuperiority of this system in few tasks to other best models from the\nchallenge.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 21:29:44 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Das", "Sourya Dipta", ""], ["Mandal", "Soumil", ""]]}, {"id": "2005.10917", "submitter": "Shunsuke Kanda", "authors": "Shunsuke Kanda, Koh Takeuchi, Keisuke Fujii and Yasuo Tabei", "title": "Succinct Trit-array Trie for Scalable Trajectory Similarity Search", "comments": "Accepted by ACM SIGSPATIAL 2020 as a full paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive datasets of spatial trajectories representing the mobility of a\ndiversity of moving objects are ubiquitous in research and industry. Similarity\nsearch of a large collection of trajectories is indispensable for turning these\ndatasets into knowledge. Locality sensitive hashing (LSH) is a powerful\ntechnique for fast similarity searches. Recent methods employ LSH and attempt\nto realize an efficient similarity search of trajectories; however, those\nmethods are inefficient in terms of search time and memory when applied to\nmassive datasets. To address this problem, we present the trajectory-indexing\nsuccinct trit-array trie (tSTAT), which is a scalable method leveraging LSH for\ntrajectory similarity searches. tSTAT quickly performs the search on a tree\ndata structure called trie. We also present two novel techniques that enable to\ndramatically enhance the memory efficiency of tSTAT. One is a node reduction\ntechnique that substantially omits redundant trie nodes while maintaining the\ntime performance. The other is a space-efficient representation that leverages\nthe idea behind succinct data structures (i.e., a compressed data structure\nsupporting fast data operations). We experimentally test tSTAT on its ability\nto retrieve similar trajectories for a query from large collections of\ntrajectories and show that tSTAT performs superiorly in comparison to\nstate-of-the-art similarity search methods.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 21:42:30 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 21:01:47 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Kanda", "Shunsuke", ""], ["Takeuchi", "Koh", ""], ["Fujii", "Keisuke", ""], ["Tabei", "Yasuo", ""]]}, {"id": "2005.10918", "submitter": "Shenda Hong", "authors": "Cao Xiao, Trong Nghia Hoang, Shenda Hong, Tengfei Ma, Jimeng Sun", "title": "CHEER: Rich Model Helps Poor Model via Knowledge Infusion", "comments": "Published in TKDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There is a growing interest in applying deep learning (DL) to healthcare,\ndriven by the availability of data with multiple feature channels in rich-data\nenvironments (e.g., intensive care units). However, in many other practical\nsituations, we can only access data with much fewer feature channels in a\npoor-data environments (e.g., at home), which often results in predictive\nmodels with poor performance. How can we boost the performance of models\nlearned from such poor-data environment by leveraging knowledge extracted from\nexisting models trained using rich data in a related environment? To address\nthis question, we develop a knowledge infusion framework named CHEER that can\nsuccinctly summarize such rich model into transferable representations, which\ncan be incorporated into the poor model to improve its performance. The infused\nmodel is analyzed theoretically and evaluated empirically on several datasets.\nOur empirical results showed that CHEER outperformed baselines by 5.60% to\n46.80% in terms of the macro-F1 score on multiple physiological datasets.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 21:44:21 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Xiao", "Cao", ""], ["Hoang", "Trong Nghia", ""], ["Hong", "Shenda", ""], ["Ma", "Tengfei", ""], ["Sun", "Jimeng", ""]]}, {"id": "2005.10919", "submitter": "Rahul Mehta", "authors": "Rahul Mehta, Muge Karaman", "title": "Correlated Mixed Membership Modeling of Somatic Mutations", "comments": "To be published in IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies of cancer somatic mutation profiles seek to identify mutations\nfor targeted therapy in personalized medicine. Analysis of profiles, however,\nis not trivial, as each profile is heterogeneous and there are multiple\nconfounding factors that influence the cause-and-effect relationships between\ncancer genes such as cancer (sub)type, biological processes, total number of\nmutations, and non-linear mutation interactions. Moreover, cancer is\nbiologically redundant, i.e., distinct mutations can result in the alteration\nof similar biological processes, so it is important to identify all possible\ncombinatorial sets of mutations for effective patient treatment. To model this\nphenomena, we propose the correlated zero-inflated negative binomial process to\ninfer the inherent structure of somatic mutation profiles through latent\nrepresentations. This stochastic process takes into account different, yet\ncorrelated, co-occurring mutations using profile-specific negative binomial\ndispersion parameters that are mixed with a correlated beta-Bernoulli process\nand a probability parameter to model profile heterogeneity. These model\nparameters are inferred by iterative optimization via amortized and stochastic\nvariational inference using the Pan Cancer dataset from The Cancer Genomic\nArchive (TCGA). By examining the the latent space, we identify biologically\nrelevant correlations between somatic mutations.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 21:52:35 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Mehta", "Rahul", ""], ["Karaman", "Muge", ""]]}, {"id": "2005.10929", "submitter": "Viet Anh Trinh", "authors": "Viet Anh Trinh, Michael I Mandel", "title": "Large scale evaluation of importance maps in automatic speech\n  recognition", "comments": "submitted to INTERSPEECH 2020", "journal-ref": "Proceedings of Interspeech 2020", "doi": "10.21437/Interspeech.2020-2883", "report-no": null, "categories": "cs.SD cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a metric that we call the structured saliency\nbenchmark (SSBM) to evaluate importance maps computed for automatic speech\nrecognizers on individual utterances. These maps indicate time-frequency points\nof the utterance that are most important for correct recognition of a target\nword. Our evaluation technique is not only suitable for standard classification\ntasks, but is also appropriate for structured prediction tasks like\nsequence-to-sequence models. Additionally, we use this approach to perform a\nlarge scale comparison of the importance maps created by our previously\nintroduced technique using \"bubble noise\" to identify important points through\ncorrelation with a baseline approach based on smoothed speech energy and forced\nalignment. Our results show that the bubble analysis approach is better at\nidentifying important speech regions than this baseline on 100 sentences from\nthe AMI corpus.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 22:39:51 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Trinh", "Viet Anh", ""], ["Mandel", "Michael I", ""]]}, {"id": "2005.10940", "submitter": "Hao Tang", "authors": "Hao Tang, Hong Liu, Wei Xiao, Nicu Sebe", "title": "When Dictionary Learning Meets Deep Learning: Deep Dictionary Learning\n  and Coding Network for Image Recognition with Limited Data", "comments": "Accepted to TNNLS, an extended version of a paper published in\n  WACV2019. arXiv admin note: substantial text overlap with arXiv:1809.04185", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new Deep Dictionary Learning and Coding Network (DDLCN) for\nimage recognition tasks with limited data. The proposed DDLCN has most of the\nstandard deep learning layers (e.g., input/output, pooling, fully connected,\netc.), but the fundamental convolutional layers are replaced by our proposed\ncompound dictionary learning and coding layers. The dictionary learning learns\nan over-complete dictionary for input training data. At the deep coding layer,\na locality constraint is added to guarantee that the activated dictionary bases\nare close to each other. Then the activated dictionary atoms are assembled and\npassed to the compound dictionary learning and coding layers. In this way, the\nactivated atoms in the first layer can be represented by the deeper atoms in\nthe second dictionary. Intuitively, the second dictionary is designed to learn\nthe fine-grained components shared among the input dictionary atoms, thus a\nmore informative and discriminative low-level representation of the dictionary\natoms can be obtained. We empirically compare DDLCN with several leading\ndictionary learning methods and deep learning models. Experimental results on\nfive popular datasets show that DDLCN achieves competitive results compared\nwith state-of-the-art methods when the training data is limited. Code is\navailable at https://github.com/Ha0Tang/DDLCN.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 23:12:10 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Tang", "Hao", ""], ["Liu", "Hong", ""], ["Xiao", "Wei", ""], ["Sebe", "Nicu", ""]]}, {"id": "2005.10953", "submitter": "Xiaoxu Li", "authors": "Xiaoxu Li and Zhuo Sun and Jing-Hao Xue and Zhanyu Ma", "title": "A Concise Review of Recent Few-shot Meta-learning Methods", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot meta-learning has been recently reviving with expectations to mimic\nhumanity's fast adaption to new concepts based on prior knowledge. In this\nshort communication, we give a concise review on recent representative methods\nin few-shot meta-learning, which are categorized into four branches according\nto their technical characteristics. We conclude this review with some vital\ncurrent challenges and future prospects in few-shot meta-learning.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 00:39:14 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Li", "Xiaoxu", ""], ["Sun", "Zhuo", ""], ["Xue", "Jing-Hao", ""], ["Ma", "Zhanyu", ""]]}, {"id": "2005.10954", "submitter": "Mohammad Rami Koujan", "authors": "Mohammad Rami Koujan, Michail Christos Doukas, Anastasios Roussos,\n  Stefanos Zafeiriou", "title": "Head2Head: Video-based Neural Head Synthesis", "comments": "To be published in 15th IEEE International Conference on Automatic\n  Face and Gesture Recognition (FG 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel machine learning architecture for facial\nreenactment. In particular, contrary to the model-based approaches or recent\nframe-based methods that use Deep Convolutional Neural Networks (DCNNs) to\ngenerate individual frames, we propose a novel method that (a) exploits the\nspecial structure of facial motion (paying particular attention to mouth\nmotion) and (b) enforces temporal consistency. We demonstrate that the proposed\nmethod can transfer facial expressions, pose and gaze of a source actor to a\ntarget video in a photo-realistic fashion more accurately than state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 00:44:43 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Koujan", "Mohammad Rami", ""], ["Doukas", "Michail Christos", ""], ["Roussos", "Anastasios", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "2005.10956", "submitter": "Long Sha", "authors": "Tong Yang, Long Sha, Pengyu Hong", "title": "NagE: Non-Abelian Group Embedding for Knowledge Graphs", "comments": "work accepted the 29th ACM International Conference on Information\n  and Knowledge Management", "journal-ref": null, "doi": "10.1145/3340531.3411875", "report-no": null, "categories": "cs.AI cs.LG math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrated the existence of a group algebraic structure hidden in\nrelational knowledge embedding problems, which suggests that a group-based\nembedding framework is essential for designing embedding models. Our\ntheoretical analysis explores merely the intrinsic property of the embedding\nproblem itself hence is model-independent. Motivated by the theoretical\nanalysis, we have proposed a group theory-based knowledge graph embedding\nframework, in which relations are embedded as group elements, and entities are\nrepresented by vectors in group action spaces. We provide a generic recipe to\nconstruct embedding models associated with two instantiating examples: SO3E and\nSU2E, both of which apply a continuous non-Abelian group as the relation\nembedding. Empirical experiments using these two exampling models have shown\nstate-of-the-art results on benchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 00:54:45 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 21:25:20 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 14:44:44 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Yang", "Tong", ""], ["Sha", "Long", ""], ["Hong", "Pengyu", ""]]}, {"id": "2005.10960", "submitter": "Harini Suresh", "authors": "Harini Suresh, Natalie Lao, Ilaria Liccardi", "title": "Misplaced Trust: Measuring the Interference of Machine Learning in Human\n  Decision-Making", "comments": "10 pages", "journal-ref": "12th ACM Conference on Web Science, July 6-10, 2020, Southampton,\n  United Kingdom", "doi": "10.1145/3394231.3397922", "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ML decision-aid systems are increasingly common on the web, but their\nsuccessful integration relies on people trusting them appropriately: they\nshould use the system to fill in gaps in their ability, but recognize signals\nthat the system might be incorrect. We measured how people's trust in ML\nrecommendations differs by expertise and with more system information through a\ntask-based study of 175 adults. We used two tasks that are difficult for\nhumans: comparing large crowd sizes and identifying similar-looking animals.\nOur results provide three key insights: (1) People trust incorrect ML\nrecommendations for tasks that they perform correctly the majority of the time,\neven if they have high prior knowledge about ML or are given information\nindicating the system is not confident in its prediction; (2) Four different\ntypes of system information all increased people's trust in recommendations;\nand (3) Math and logic skills may be as important as ML for decision-makers\nworking with ML recommendations.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 01:22:58 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Suresh", "Harini", ""], ["Lao", "Natalie", ""], ["Liccardi", "Ilaria", ""]]}, {"id": "2005.10970", "submitter": "Kechen Qin", "authors": "Kechen Qin, Yu Wang, Cheng Li, Kalpa Gunaratna, Hongxia Jin, Virgil\n  Pavlu, Javed A. Aslam", "title": "A Complex KBQA System using Multiple Reasoning Paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop knowledge based question answering (KBQA) is a complex task for\nnatural language understanding. Many KBQA approaches have been proposed in\nrecent years, and most of them are trained based on labeled reasoning path.\nThis hinders the system's performance as many correct reasoning paths are not\nlabeled as ground truth, and thus they cannot be learned. In this paper, we\nintroduce an end-to-end KBQA system which can leverage multiple reasoning\npaths' information and only requires labeled answer as supervision. We conduct\nexperiments on several benchmark datasets containing both single-hop simple\nquestions as well as muti-hop complex questions, including WebQuestionSP\n(WQSP), ComplexWebQuestion-1.1 (CWQ), and PathQuestion-Large (PQL), and\ndemonstrate strong performance.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 02:35:42 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Qin", "Kechen", ""], ["Wang", "Yu", ""], ["Li", "Cheng", ""], ["Gunaratna", "Kalpa", ""], ["Jin", "Hongxia", ""], ["Pavlu", "Virgil", ""], ["Aslam", "Javed A.", ""]]}, {"id": "2005.10985", "submitter": "Seonwoo Lee", "authors": "SeonWoo Lee, HyeonTak Yu, HoJun Yang, JaeHeung Yang, GangMin Lim,\n  KyuSung Kim, ByeongKeun Choi, and JangWoo Kwon", "title": "Apply VGGNet-based deep learning model of vibration data for prediction\n  model of gravity acceleration equipment", "comments": "15 pages, 10 figures \"for associated publication of paper is as\n  follow: Journal of Mechanics in Medicine and Biology,\n  https://www.worldscientific.com/worldscinet/jmmb\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Hypergravity accelerators are a type of large machinery used for gravity\ntraining or medical research. A failure of such large equipment can be a\nserious problem in terms of safety or costs. This paper proposes a prediction\nmodel that can proactively prevent failures that may occur in a hypergravity\naccelerator. The method proposed in this paper was to convert vibration signals\nto spectograms and perform classification training using a deep learning model.\nAn experiment was conducted to evaluate the performance of the method proposed\nin this paper. A 4-channel accelerometer was attached to the bearing housing,\nwhich is a rotor, and time-amplitude data were obtained from the measured\nvalues by sampling. The data were converted to a two-dimensional spectrogram,\nand classification training was performed using a deep learning model for four\nconditions of the equipment: Unbalance, Misalignment, Shaft Rubbing, and\nNormal. The experimental results showed that the proposed method had a 99.5%\nF1-Score, which was up to 23% higher than the 76.25% for existing feature-based\nlearning models.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 03:36:06 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 02:49:31 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Lee", "SeonWoo", ""], ["Yu", "HyeonTak", ""], ["Yang", "HoJun", ""], ["Yang", "JaeHeung", ""], ["Lim", "GangMin", ""], ["Kim", "KyuSung", ""], ["Choi", "ByeongKeun", ""], ["Kwon", "JangWoo", ""]]}, {"id": "2005.10996", "submitter": "Garrett Wilson", "authors": "Garrett Wilson, Janardhan Rao Doppa, Diane J. Cook", "title": "Multi-Source Deep Domain Adaptation with Weak Supervision for\n  Time-Series Sensor Data", "comments": "Accepted at KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation (DA) offers a valuable means to reuse data and models for\nnew problem domains. However, robust techniques have not yet been considered\nfor time series data with varying amounts of data availability. In this paper,\nwe make three main contributions to fill this gap. First, we propose a novel\nConvolutional deep Domain Adaptation model for Time Series data (CoDATS) that\nsignificantly improves accuracy and training time over state-of-the-art DA\nstrategies on real-world sensor data benchmarks. By utilizing data from\nmultiple source domains, we increase the usefulness of CoDATS to further\nimprove accuracy over prior single-source methods, particularly on complex time\nseries datasets that have high variability between domains. Second, we propose\na novel Domain Adaptation with Weak Supervision (DA-WS) method by utilizing\nweak supervision in the form of target-domain label distributions, which may be\neasier to collect than additional data labels. Third, we perform comprehensive\nexperiments on diverse real-world datasets to evaluate the effectiveness of our\ndomain adaptation and weak supervision methods. Results show that CoDATS for\nsingle-source DA significantly improves over the state-of-the-art methods, and\nwe achieve additional improvements in accuracy using data from multiple source\ndomains and weakly supervised signals. Code is available at:\nhttps://github.com/floft/codats\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 04:16:58 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Wilson", "Garrett", ""], ["Doppa", "Janardhan Rao", ""], ["Cook", "Diane J.", ""]]}, {"id": "2005.11003", "submitter": "Jieli Zhou", "authors": "Jieli Zhou, Baoyu Jing, Zeya Wang", "title": "SODA: Detecting Covid-19 in Chest X-rays with Semi-supervised Open Set\n  Domain Adaptation", "comments": "BIOKDD 2020: 19th International Workshop on Data Mining in\n  Bioinformatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the shortage of COVID-19 viral testing kits and the long waiting time,\nradiology imaging is used to complement the screening process and triage\npatients into different risk levels. Deep learning based methods have taken an\nactive role in automatically detecting COVID-19 disease in chest x-ray images,\nas witnessed in many recent works in early 2020. Most of these works first\ntrain a Convolutional Neural Network (CNN) on an existing large-scale chest\nx-ray image dataset and then fine-tune it with a COVID-19 dataset at a much\nsmaller scale. However, direct transfer across datasets from different domains\nmay lead to poor performance for CNN due to two issues, the large domain shift\npresent in the biomedical imaging datasets and the extremely small scale of the\nCOVID-19 chest x-ray dataset. In an attempt to address these two important\nissues, we formulate the problem of COVID-19 chest x-ray image classification\nin a semi-supervised open set domain adaptation setting and propose a novel\ndomain adaptation method, Semi-supervised Open set Domain Adversarial network\n(SODA). SODA is able to align the data distributions across different domains\nin a general domain space and also in a common subspace of source and target\ndata. In our experiments, SODA achieves a leading classification performance\ncompared with recent state-of-the-art models in separating COVID-19 with common\npneumonia. We also present initial results showing that SODA can produce better\npathology localizations in the chest x-rays.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 04:58:28 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 05:17:57 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Zhou", "Jieli", ""], ["Jing", "Baoyu", ""], ["Wang", "Zeya", ""]]}, {"id": "2005.11007", "submitter": "Miran Kim", "authors": "Yeongjae Gil and Xiaoqian Jiang and Miran Kim and Junghye Lee", "title": "Secure and Differentially Private Bayesian Learning on Distributed Data", "comments": "18 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data integration and sharing maximally enhance the potential for novel and\nmeaningful discoveries. However, it is a non-trivial task as integrating data\nfrom multiple sources can put sensitive information of study participants at\nrisk. To address the privacy concern, we present a distributed Bayesian\nlearning approach via Preconditioned Stochastic Gradient Langevin Dynamics with\nRMSprop, which combines differential privacy and homomorphic encryption in a\nharmonious manner while protecting private information. We applied the proposed\nsecure and privacy-preserving distributed Bayesian learning approach to\nlogistic regression and survival analysis on distributed data, and demonstrated\nits feasibility in terms of prediction accuracy and time complexity, compared\nto the centralized approach.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 05:13:43 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Gil", "Yeongjae", ""], ["Jiang", "Xiaoqian", ""], ["Kim", "Miran", ""], ["Lee", "Junghye", ""]]}, {"id": "2005.11014", "submitter": "Ajay Chatterjee", "authors": "Ajay Chatterjee and Shubhashis Sengupta", "title": "Intent Mining from past conversations for conversational agent", "comments": "8 pages, 2 figures", "journal-ref": "Proceedings of the 28th International Conference on Computational\n  Linguistics, 2020", "doi": null, "report-no": "https://www.aclweb.org/anthology/2020.coling-main.366", "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Conversational systems are of primary interest in the AI community. Chatbots\nare increasingly being deployed to provide round-the-clock support and to\nincrease customer engagement. Many of the commercial bot building frameworks\nfollow a standard approach that requires one to build and train an intent model\nto recognize a user input. Intent models are trained in a supervised setting\nwith a collection of textual utterance and intent label pairs. Gathering a\nsubstantial and wide coverage of training data for different intent is a\nbottleneck in the bot building process. Moreover, the cost of labeling a\nhundred to thousands of conversations with intent is a time consuming and\nlaborious job. In this paper, we present an intent discovery framework that\ninvolves 4 primary steps: Extraction of textual utterances from a conversation\nusing a pre-trained domain agnostic Dialog Act Classifier (Data Extraction),\nautomatic clustering of similar user utterances (Clustering), manual annotation\nof clusters with an intent label (Labeling) and propagation of intent labels to\nthe utterances from the previous step, which are not mapped to any cluster\n(Label Propagation); to generate intent training data from raw conversations.\nWe have introduced a novel density-based clustering algorithm ITER-DBSCAN for\nunbalanced data clustering. Subject Matter Expert (Annotators with domain\nexpertise) manually looks into the clustered user utterances and provides an\nintent label for discovery. We conducted user studies to validate the\neffectiveness of the trained intent model generated in terms of coverage of\nintents, accuracy and time saving concerning manual annotation. Although the\nsystem is developed for building an intent model for the conversational system,\nthis framework can also be used for a short text clustering or as a labeling\nframework.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 05:29:13 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 04:45:07 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 07:44:22 GMT"}, {"version": "v4", "created": "Mon, 18 Jan 2021 13:45:27 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Chatterjee", "Ajay", ""], ["Sengupta", "Shubhashis", ""]]}, {"id": "2005.11017", "submitter": "Mengxi Wei", "authors": "Mengxi Wei, Yifan He, Qiong Zhang", "title": "Robust Layout-aware IE for Visually Rich Documents with Pre-trained\n  Language Models", "comments": "10 pages, to appear in SIGIR 2020 Industry Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many business documents processed in modern NLP and IR pipelines are visually\nrich: in addition to text, their semantics can also be captured by visual\ntraits such as layout, format, and fonts. We study the problem of information\nextraction from visually rich documents (VRDs) and present a model that\ncombines the power of large pre-trained language models and graph neural\nnetworks to efficiently encode both textual and visual information in business\ndocuments. We further introduce new fine-tuning objectives to improve in-domain\nunsupervised fine-tuning to better utilize large amount of unlabeled in-domain\ndata. We experiment on real world invoice and resume data sets and show that\nthe proposed method outperforms strong text-based RoBERTa baselines by 6.3%\nabsolute F1 on invoices and 4.7% absolute F1 on resumes. When evaluated in a\nfew-shot setting, our method requires up to 30x less annotation data than the\nbaseline to achieve the same level of performance at ~90% F1.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 06:04:50 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Wei", "Mengxi", ""], ["He", "Yifan", ""], ["Zhang", "Qiong", ""]]}, {"id": "2005.11018", "submitter": "Jingge Zhu", "authors": "Jingge Zhu", "title": "Semi-Supervised Learning: the Case When Unlabeled Data is Equally Useful", "comments": "accepted to UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning algorithms attempt to take advantage of relatively\ninexpensive unlabeled data to improve learning performance. In this work, we\nconsider statistical models where the data distributions can be characterized\nby continuous parameters. We show that under certain conditions on the\ndistribution, unlabeled data is equally useful as labeled date in terms of\nlearning rate. Specifically, let $n, m$ be the number of labeled and unlabeled\ndata, respectively. It is shown that the learning rate of semi-supervised\nlearning scales as $O(1/n)$ if $m\\sim n$, and scales as $O(1/n^{1+\\gamma})$ if\n$m\\sim n^{1+\\gamma}$ for some $\\gamma>0$, whereas the learning rate of\nsupervised learning scales as $O(1/n)$.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 06:05:00 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 06:53:36 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Zhu", "Jingge", ""]]}, {"id": "2005.11021", "submitter": "Moritz Schubotz", "authors": "Philipp Scharpf, Moritz Schubotz, Abdou Youssef, Felix Hamborg, Norman\n  Meuschke, Bela Gipp", "title": "Classification and Clustering of arXiv Documents, Sections, and\n  Abstracts, Comparing Encodings of Natural and Mathematical Language", "comments": null, "journal-ref": "Proceedings of the ACM/IEEE Joint Conference on Digital Libraries\n  JCDL 2020", "doi": "10.1145/3383583.3398529", "report-no": null, "categories": "cs.DL cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we show how selecting and combining encodings of natural and\nmathematical language affect classification and clustering of documents with\nmathematical content. We demonstrate this by using sets of documents, sections,\nand abstracts from the arXiv preprint server that are labeled by their subject\nclass (mathematics, computer science, physics, etc.) to compare different\nencodings of text and formulae and evaluate the performance and runtimes of\nselected classification and clustering algorithms. Our encodings achieve\nclassification accuracies up to $82.8\\%$ and cluster purities up to $69.4\\%$\n(number of clusters equals number of classes), and $99.9\\%$ (unspecified number\nof clusters) respectively. We observe a relatively low correlation between text\nand math similarity, which indicates the independence of text and formulae and\nmotivates treating them as separate features of a document. The classification\nand clustering can be employed, e.g., for document search and recommendation.\nFurthermore, we show that the computer outperforms a human expert when\nclassifying documents. Finally, we evaluate and discuss multi-label\nclassification and formula semantification.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 06:16:32 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Scharpf", "Philipp", ""], ["Schubotz", "Moritz", ""], ["Youssef", "Abdou", ""], ["Hamborg", "Felix", ""], ["Meuschke", "Norman", ""], ["Gipp", "Bela", ""]]}, {"id": "2005.11031", "submitter": "Giulia Cisotto", "authors": "Giulia Cisotto, Martina Capuzzo, Anna V. Guglielmi, Andrea Zanella", "title": "Feature selection for gesture recognition in Internet-of-Things for\n  healthcare", "comments": null, "journal-ref": "ICC 2020 - 2020 IEEE International Conference on Communications\n  (ICC)", "doi": "10.1109/ICC40277.2020.9149381", "report-no": null, "categories": "cs.CV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things is rapidly spreading across several fields, including\nhealthcare, posing relevant questions related to communication capabilities,\nenergy efficiency and sensors unobtrusiveness. Particularly, in the context of\nrecognition of gestures, e.g., grasping of different objects, brain and\nmuscular activity could be simultaneously recorded via EEG and EMG,\nrespectively, and analyzed to identify the gesture that is being accomplished,\nand the quality of its performance. This paper proposes a new algorithm that\naims (i) to robustly extract the most relevant features to classify different\ngrasping tasks, and (ii) to retain the natural meaning of the selected\nfeatures. This, in turn, gives the opportunity to simplify the recording setup\nto minimize the data traffic over the communication network, including\nInternet, and provide physiologically significant features for medical\ninterpretation. The algorithm robustness is ensured both by consensus\nclustering as a feature selection strategy, and by nested cross-validation\nscheme to evaluate its classification performance.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 06:54:53 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Cisotto", "Giulia", ""], ["Capuzzo", "Martina", ""], ["Guglielmi", "Anna V.", ""], ["Zanella", "Andrea", ""]]}, {"id": "2005.11035", "submitter": "Jangho Kim", "authors": "Jangho Kim, KiYoon Yoo, Nojun Kwak", "title": "Position-based Scaled Gradient for Model Quantization and Pruning", "comments": "Advances in Neural Information Processing Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the position-based scaled gradient (PSG) that scales the gradient\ndepending on the position of a weight vector to make it more\ncompression-friendly. First, we theoretically show that applying PSG to the\nstandard gradient descent (GD), which is called PSGD, is equivalent to the GD\nin the warped weight space, a space made by warping the original weight space\nvia an appropriately designed invertible function. Second, we empirically show\nthat PSG acting as a regularizer to a weight vector is favorable for model\ncompression domains such as quantization and pruning. PSG reduces the gap\nbetween the weight distributions of a full-precision model and its compressed\ncounterpart. This enables the versatile deployment of a model either as an\nuncompressed mode or as a compressed mode depending on the availability of\nresources. The experimental results on CIFAR-10/100 and ImageNet datasets show\nthe effectiveness of the proposed PSG in both domains of pruning and\nquantization even for extremely low bits. The code is released in Github.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 07:11:27 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 01:22:47 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 07:00:07 GMT"}, {"version": "v4", "created": "Wed, 11 Nov 2020 03:43:25 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Kim", "Jangho", ""], ["Yoo", "KiYoon", ""], ["Kwak", "Nojun", ""]]}, {"id": "2005.11041", "submitter": "Xovee Xu", "authors": "Fan Zhou, Xovee Xu, Goce Trajcevski, Kunpeng Zhang", "title": "A Survey of Information Cascade Analysis: Models, Predictions, and\n  Recent Advances", "comments": "Author version, with 43 pages, 9 figures, and 11 tables", "journal-ref": "ACM Computing Surveys (CSUR), 54(2), Article 27, Mar 2021, 36\n  pages", "doi": "10.1145/3433000", "report-no": null, "categories": "cs.SI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deluge of digital information in our daily life -- from user-generated\ncontent, such as microblogs and scientific papers, to online business, such as\nviral marketing and advertising -- offers unprecedented opportunities to\nexplore and exploit the trajectories and structures of the evolution of\ninformation cascades. Abundant research efforts, both academic and industrial,\nhave aimed to reach a better understanding of the mechanisms driving the spread\nof information and quantifying the outcome of information diffusion. This\narticle presents a comprehensive review and categorization of information\npopularity prediction methods, from feature engineering and stochastic\nprocesses, through graph representation, to deep learning-based approaches.\nSpecifically, we first formally define different types of information cascades\nand summarize the perspectives of existing studies. We then present a taxonomy\nthat categorizes existing works into the aforementioned three main groups as\nwell as the main subclasses in each group, and we systematically review\ncutting-edge research work. Finally, we summarize the pros and cons of existing\nresearch efforts and outline the open challenges and opportunities in this\nfield.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 07:39:48 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 04:46:20 GMT"}, {"version": "v3", "created": "Wed, 24 Mar 2021 03:33:58 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Zhou", "Fan", ""], ["Xu", "Xovee", ""], ["Trajcevski", "Goce", ""], ["Zhang", "Kunpeng", ""]]}, {"id": "2005.11045", "submitter": "Jerry Lonlac", "authors": "Micha\\\"el Chirmeni Boujike, Jerry Lonlac, Norbert Tsopze, Engelbert\n  Mephu Nguifo", "title": "Discovering Frequent Gradual Itemsets with Imprecise Data", "comments": "24 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The gradual patterns that model the complex co-variations of attributes of\nthe form \"The more/less X, The more/less Y\" play a crucial role in many real\nworld applications where the amount of numerical data to manage is important,\nthis is the biological data. Recently, these types of patterns have caught the\nattention of the data mining community, where several methods have been defined\nto automatically extract and manage these patterns from different data models.\nHowever, these methods are often faced the problem of managing the quantity of\nmined patterns, and in many practical applications, the calculation of all\nthese patterns can prove to be intractable for the user-defined frequency\nthreshold and the lack of focus leads to generating huge collections of\npatterns. Moreover another problem with the traditional approaches is that the\nconcept of gradualness is defined just as an increase or a decrease. Indeed, a\ngradualness is considered as soon as the values of the attribute on both\nobjects are different. As a result, numerous quantities of patterns extracted\nby traditional algorithms can be presented to the user although their\ngradualness is only a noise effect in the data. To address this issue, this\npaper suggests to introduce the gradualness thresholds from which to consider\nan increase or a decrease. In contrast to literature approaches, the proposed\napproach takes into account the distribution of attribute values, as well as\nthe user's preferences on the gradualness threshold and makes it possible to\nextract gradual patterns on certain databases where literature approaches fail\ndue to too large search space. Moreover, results from an experimental\nevaluation on real databases show that the proposed algorithm is scalable,\nefficient, and can eliminate numerous patterns that do not verify specific\ngradualness requirements to show a small set of patterns to the user.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 08:02:15 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Boujike", "Micha\u00ebl Chirmeni", ""], ["Lonlac", "Jerry", ""], ["Tsopze", "Norbert", ""], ["Nguifo", "Engelbert Mephu", ""]]}, {"id": "2005.11061", "submitter": "Kazuhiro Takemoto", "authors": "Hokuto Hirano, Kazuki Koga, Kazuhiro Takemoto", "title": "Vulnerability of deep neural networks for detecting COVID-19 cases from\n  chest X-ray images to universal adversarial attacks", "comments": "17 pages, 5 figures, 3 tables", "journal-ref": "PLoS ONE 5(12), e0243963 (2020)", "doi": "10.1371/journal.pone.0243963", "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under the epidemic of the novel coronavirus disease 2019 (COVID-19), chest\nX-ray computed tomography imaging is being used for effectively screening\nCOVID-19 patients. The development of computer-aided systems based on deep\nneural networks (DNNs) has been advanced, to rapidly and accurately detect\nCOVID-19 cases, because the need for expert radiologists, who are limited in\nnumber, forms a bottleneck for the screening. However, so far, the\nvulnerability of DNN-based systems has been poorly evaluated, although DNNs are\nvulnerable to a single perturbation, called universal adversarial perturbation\n(UAP), which can induce DNN failure in most classification tasks. Thus, we\nfocus on representative DNN models for detecting COVID-19 cases from chest\nX-ray images and evaluate their vulnerability to UAPs generated using simple\niterative algorithms. We consider nontargeted UAPs, which cause a task failure\nresulting in an input being assigned an incorrect label, and targeted UAPs,\nwhich cause the DNN to classify an input into a specific class. The results\ndemonstrate that the models are vulnerable to nontargeted and targeted UAPs,\neven in case of small UAPs. In particular, 2% norm of the UPAs to the average\nnorm of an image in the image dataset achieves >85% and >90% success rates for\nthe nontargeted and targeted attacks, respectively. Due to the nontargeted\nUAPs, the DNN models judge most chest X-ray images as COVID-19 cases. The\ntargeted UAPs make the DNN models classify most chest X-ray images into a given\ntarget class. The results indicate that careful consideration is required in\npractical applications of DNNs to COVID-19 diagnosis; in particular, they\nemphasize the need for strategies to address security concerns. As an example,\nwe show that iterative fine-tuning of the DNN models using UAPs improves the\nrobustness of the DNN models against UAPs.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 08:54:41 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Hirano", "Hokuto", ""], ["Koga", "Kazuki", ""], ["Takemoto", "Kazuhiro", ""]]}, {"id": "2005.11065", "submitter": "Wenjie Huang", "authors": "Wenjie Huang, Jing Jiang, Xiao Liu", "title": "Online Non-convex Learning for River Pollution Source Identification", "comments": "27 Pages, 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, novel gradient based online learning algorithms are developed\nto investigate an important environmental application: real-time river\npollution source identification, which aims at estimating the released mass,\nthe location and the released time of a river pollution source based on\ndownstream sensor data monitoring the pollution concentration. The problem can\nbe formulated as a non-convex loss minimization problem in statistical\nlearning, and our online algorithms have vectorized and adaptive step-sizes to\nensure high estimation accuracy on dimensions having different magnitudes. In\norder to avoid gradient-based method sticking into the saddle points of\nnon-convex loss, the \"escaping from saddle points\" module and multi-start\nversion of algorithms are derived to further improve the estimation accuracy by\nsearching for the global minimimals of the loss functions. It can be shown\ntheoretically and experimentally $O(N)$ local regret of the algorithms, and the\nhigh probability cumulative regret bound $O(N)$ under particular error bound\ncondition on loss functions. A real-life river pollution source identification\nexample shows superior performance of our algorithms than the existing methods\nin terms of estimating accuracy. The managerial insights for decision maker to\nuse the algorithm in reality are also provided.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 09:01:05 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Huang", "Wenjie", ""], ["Jiang", "Jing", ""], ["Liu", "Xiao", ""]]}, {"id": "2005.11067", "submitter": "Diego Antognini", "authors": "Diego Antognini and Claudiu Musat and Boi Faltings", "title": "Interacting with Explanations through Critiquing", "comments": "Accepted at IJCAI 2021. 15 pages, 10 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using personalized explanations to support recommendations has been shown to\nincrease trust and perceived quality. However, to actually obtain better\nrecommendations, there needs to be a means for users to modify the\nrecommendation criteria by interacting with the explanation. We present a novel\ntechnique using aspect markers that learns to generate personalized\nexplanations of recommendations from review texts, and we show that human users\nsignificantly prefer these explanations over those produced by state-of-the-art\ntechniques. Our work's most important innovation is that it allows users to\nreact to a recommendation by critiquing the textual explanation: removing\n(symmetrically adding) certain aspects they dislike or that are no longer\nrelevant (symmetrically that are of interest). The system updates its user\nmodel and the resulting recommendations according to the critique. This is\nbased on a novel unsupervised critiquing method for single- and multi-step\ncritiquing with textual explanations. Experiments on two real-world datasets\nshow that our system is the first to achieve good performance in adapting to\nthe preferences expressed in multi-step critiquing.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 09:03:06 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 09:07:21 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 10:32:26 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Antognini", "Diego", ""], ["Musat", "Claudiu", ""], ["Faltings", "Boi", ""]]}, {"id": "2005.11074", "submitter": "George Kyriakides", "authors": "George Kyriakides and Konstantinos Margaritis", "title": "An Introduction to Neural Architecture Search for Convolutional Networks", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) is a research field concerned with utilizing\noptimization algorithms to design optimal neural network architectures. There\nare many approaches concerning the architectural search spaces, optimization\nalgorithms, as well as candidate architecture evaluation methods. As the field\nis growing at a continuously increasing pace, it is difficult for a beginner to\ndiscern between major, as well as emerging directions the field has followed.\nIn this work, we provide an introduction to the basic concepts of NAS for\nconvolutional networks, along with the major advances in search spaces,\nalgorithms and evaluation techniques.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 09:33:22 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Kyriakides", "George", ""], ["Margaritis", "Konstantinos", ""]]}, {"id": "2005.11079", "submitter": "Wenzheng Feng", "authors": "Wenzheng Feng, Jie Zhang, Yuxiao Dong, Yu Han, Huanbo Luan, Qian Xu,\n  Qiang Yang, Evgeny Kharlamov, Jie Tang", "title": "Graph Random Neural Network for Semi-Supervised Learning on Graphs", "comments": "18 pages. Accepted by NeurIPS 2020. Final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of semi-supervised learning on graphs, for which graph\nneural networks (GNNs) have been extensively explored. However, most existing\nGNNs inherently suffer from the limitations of over-smoothing, non-robustness,\nand weak-generalization when labeled nodes are scarce. In this paper, we\npropose a simple yet effective framework---GRAPH RANDOM NEURAL NETWORKS\n(GRAND)---to address these issues. In GRAND, we first design a random\npropagation strategy to perform graph data augmentation. Then we leverage\nconsistency regularization to optimize the prediction consistency of unlabeled\nnodes across different data augmentations. Extensive experiments on graph\nbenchmark datasets suggest that GRAND significantly outperforms\nstate-of-the-art GNN baselines on semi-supervised node classification. Finally,\nwe show that GRAND mitigates the issues of over-smoothing and non-robustness,\nexhibiting better generalization behavior than existing GNNs. The source code\nof GRAND is publicly available at https://github.com/Grand20/grand.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 09:40:13 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 07:51:17 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 05:21:52 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Feng", "Wenzheng", ""], ["Zhang", "Jie", ""], ["Dong", "Yuxiao", ""], ["Han", "Yu", ""], ["Luan", "Huanbo", ""], ["Xu", "Qian", ""], ["Yang", "Qiang", ""], ["Kharlamov", "Evgeny", ""], ["Tang", "Jie", ""]]}, {"id": "2005.11081", "submitter": "Natalia Vesselinova", "authors": "Natalia Vesselinova, Rebecca Steinert, Daniel F. Perez-Ramirez, and\n  Magnus Boman", "title": "Learning Combinatorial Optimization on Graphs: A Survey with\n  Applications to Networking", "comments": "29 pages, 1 figure, open access journal publication", "journal-ref": "IEEE Access, vol. 8, 2020, pp. 120388--120416", "doi": "10.1109/ACCESS.2020.3004964", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches to solving combinatorial optimization problems on graphs\nsuffer from the need to engineer each problem algorithmically, with practical\nproblems recurring in many instances. The practical side of theoretical\ncomputer science, such as computational complexity, then needs to be addressed.\nRelevant developments in machine learning research on graphs are surveyed for\nthis purpose. We organize and compare the structures involved with learning to\nsolve combinatorial optimization problems, with a special eye on the\ntelecommunications domain and its continuous development of live and research\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 09:45:36 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 18:03:39 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Vesselinova", "Natalia", ""], ["Steinert", "Rebecca", ""], ["Perez-Ramirez", "Daniel F.", ""], ["Boman", "Magnus", ""]]}, {"id": "2005.11082", "submitter": "Maxime Chamberland", "authors": "Maxime Chamberland, Sila Genc, Erika P. Raven, Greg D. Parker, Adam\n  Cunningham, Joanne Doherty, Marianne van den Bree, Chantal M. W. Tax, Derek\n  K. Jones", "title": "Tractometry-based Anomaly Detection for Single-subject White Matter\n  Analysis", "comments": "Medical Imaging with Deep Learning (MIDL2020) Conference Short Paper", "journal-ref": "Medical Imaging with Deep Learning 2020", "doi": null, "report-no": "MIDL/2020/ExtendedAbstract/heX-Rk0TE0", "categories": "q-bio.QM cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  There is an urgent need for a paradigm shift from group-wise comparisons to\nindividual diagnosis in diffusion MRI (dMRI) to enable the analysis of rare\ncases and clinically-heterogeneous groups. Deep autoencoders have shown great\npotential to detect anomalies in neuroimaging data. We present a framework that\noperates on the manifold of white matter (WM) pathways to learn normative\nmicrostructural features, and discriminate those at genetic risk from controls\nin a paediatric population.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 09:50:22 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 18:59:34 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Chamberland", "Maxime", ""], ["Genc", "Sila", ""], ["Raven", "Erika P.", ""], ["Parker", "Greg D.", ""], ["Cunningham", "Adam", ""], ["Doherty", "Joanne", ""], ["Bree", "Marianne van den", ""], ["Tax", "Chantal M. W.", ""], ["Jones", "Derek K.", ""]]}, {"id": "2005.11084", "submitter": "Rana Hanocka", "authors": "Rana Hanocka, Gal Metzer, Raja Giryes, Daniel Cohen-Or", "title": "Point2Mesh: A Self-Prior for Deformable Meshes", "comments": "SIGGRAPH 2020; Project page:\n  https://ranahanocka.github.io/point2mesh/", "journal-ref": null, "doi": "10.1145/3386569.3392415", "report-no": null, "categories": "cs.GR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Point2Mesh, a technique for reconstructing a\nsurface mesh from an input point cloud. Instead of explicitly specifying a\nprior that encodes the expected shape properties, the prior is defined\nautomatically using the input point cloud, which we refer to as a self-prior.\nThe self-prior encapsulates reoccurring geometric repetitions from a single\nshape within the weights of a deep neural network. We optimize the network\nweights to deform an initial mesh to shrink-wrap a single input point cloud.\nThis explicitly considers the entire reconstructed shape, since shared local\nkernels are calculated to fit the overall object. The convolutional kernels are\noptimized globally across the entire shape, which inherently encourages\nlocal-scale geometric self-similarity across the shape surface. We show that\nshrink-wrapping a point cloud with a self-prior converges to a desirable\nsolution; compared to a prescribed smoothness prior, which often becomes\ntrapped in undesirable local minima. While the performance of traditional\nreconstruction approaches degrades in non-ideal conditions that are often\npresent in real world scanning, i.e., unoriented normals, noise and missing\n(low density) parts, Point2Mesh is robust to non-ideal conditions. We\ndemonstrate the performance of Point2Mesh on a large variety of shapes with\nvarying complexity.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 10:01:04 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Hanocka", "Rana", ""], ["Metzer", "Gal", ""], ["Giryes", "Raja", ""], ["Cohen-Or", "Daniel", ""]]}, {"id": "2005.11093", "submitter": "Yania Molina Souto", "authors": "Yania Molina Souto, Rafael Pereira, Roc\\'io Zorrilla, Anderson Chaves,\n  Brian Tsan, Florin Rusu, Eduardo Ogasawara, Artur Ziviani, Fabio Porto", "title": "DJEnsemble: On the Selection of a Disjoint Ensemble of Deep Learning\n  Black-Box Spatio-Temporal Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a cost-based approach for the automatic selection\nand allocation of a disjoint ensemble of black-box predictors to answer\npredictive spatio-temporal queries. Our approach is divided into two parts --\noffline and online. During the offline part, we preprocess the predictive\ndomain data -- transforming it into a regular grid -- and the black-box models\n-- computing their spatio-temporal learning function. In the online part, we\ncompute a DJEnsemble plan which minimizes a multivariate cost function based on\nestimates for the prediction error and the execution cost -- producing a model\nspatial allocation matrix -- and run the optimal ensemble plan. We conduct a\nset of extensive experiments that evaluate the DJEnsemble approach and\nhighlight its efficiency. We show that our cost model produces plans with\nperformance close to the actual best plan. When compared against the\ntraditional ensemble approach, DJEnsemble achieves up to $4X$ improvement in\nexecution time and almost $9X$ improvement in prediction accuracy. To the best\nof our knowledge, this is the first work to solve the problem of optimizing the\nallocation of black-box models to answer predictive spatio-temporal queries.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 10:37:16 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 15:36:51 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 15:56:46 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Souto", "Yania Molina", ""], ["Pereira", "Rafael", ""], ["Zorrilla", "Roc\u00edo", ""], ["Chaves", "Anderson", ""], ["Tsan", "Brian", ""], ["Rusu", "Florin", ""], ["Ogasawara", "Eduardo", ""], ["Ziviani", "Artur", ""], ["Porto", "Fabio", ""]]}, {"id": "2005.11098", "submitter": "Ziheng Duan", "authors": "Ziheng Duan, Daniel Montes, Yangsibo Huang, Dufan Wu, Javier M.\n  Romero, Ramon Gilberto Gonzalez, Quanzheng Li", "title": "Deep Learning Based Detection and Localization of Cerebal Aneurysms in\n  Computed Tomography Angiography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting cerebral aneurysms is an important clinical task of brain computed\ntomography angiography (CTA). However, human interpretation could be time\nconsuming due to the small size of some aneurysms. In this work, we proposed\nDeepBrain, a deep learning based cerebral aneurysm detection and localization\nalgorithm. The algorithm consisted of a 3D faster region-proposal convolution\nneural network for aneurysm detection and localization, and a 3D multi-scale\nfully convolutional neural network for false positive reduction. Furthermore, a\nnovel hierarchical non-maximum suppression algorithm was proposed to process\nthe detection results in 3D, which greatly reduced the time complexity by\neliminating unnecessary comparisons. DeepBrain was trained and tested on 550\nbrain CTA scans and achieved sensitivity of 93.3% with 0.3 false positives per\npatient on average.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 10:49:23 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Duan", "Ziheng", ""], ["Montes", "Daniel", ""], ["Huang", "Yangsibo", ""], ["Wu", "Dufan", ""], ["Romero", "Javier M.", ""], ["Gonzalez", "Ramon Gilberto", ""], ["Li", "Quanzheng", ""]]}, {"id": "2005.11100", "submitter": "Herv\\'e Chabanne", "authors": "Julien Bringer and Herv\\'e Chabanne and Linda Guiga", "title": "Premium Access to Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Networks (NNs) are today used for all our daily tasks; for instance,\nin mobile phones. We here want to show how to restrict their access to\nprivileged users. Our solution relies on a degraded implementation which can be\ncorrected thanks to a PIN. We explain how to select a few parameters in an NN\nso as to maximize the gap in the accuracy between the premium and the degraded\nmodes. We report experiments on an implementation of our proposal on a deep NN\nto prove its practicability.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 10:54:23 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Bringer", "Julien", ""], ["Chabanne", "Herv\u00e9", ""], ["Guiga", "Linda", ""]]}, {"id": "2005.11101", "submitter": "Javier Hernandez-Ortega", "authors": "Javier Hernandez-Ortega, Julian Fierrez, Aythami Morales, David Diaz", "title": "A Comparative Evaluation of Heart Rate Estimation Methods using Face\n  Videos", "comments": "Accepted in \"IEEE International Workshop on Medical Computing\n  (MediComp) 2020\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a comparative evaluation of methods for remote heart rate\nestimation using face videos, i.e., given a video sequence of the face as\ninput, methods to process it to obtain a robust estimation of the subjects\nheart rate at each moment. Four alternatives from the literature are tested,\nthree based in hand crafted approaches and one based on deep learning. The\nmethods are compared using RGB videos from the COHFACE database. Experiments\nshow that the learning-based method achieves much better accuracy than the hand\ncrafted ones. The low error rate achieved by the learning based model makes\npossible its application in real scenarios, e.g. in medical or sports\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 10:54:49 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Hernandez-Ortega", "Javier", ""], ["Fierrez", "Julian", ""], ["Morales", "Aythami", ""], ["Diaz", "David", ""]]}, {"id": "2005.11107", "submitter": "Kisung You", "authors": "Kisung You", "title": "Rdimtools: An R package for Dimension Reduction and Intrinsic Dimension\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering patterns of the complex high-dimensional data is a long-standing\nproblem. Dimension Reduction (DR) and Intrinsic Dimension Estimation (IDE) are\ntwo fundamental thematic programs that facilitate geometric understanding of\nthe data. We present Rdimtools - an R package that supports 133 DR and 17 IDE\nalgorithms whose extent makes multifaceted scrutiny of the data in one place\neasier. Rdimtools is distributed under the MIT license and is accessible from\nCRAN, GitHub, and its package website, all of which deliver instruction for\ninstallation, self-contained examples, and API documentation.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 11:06:43 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["You", "Kisung", ""]]}, {"id": "2005.11110", "submitter": "Jakob Lindinger", "authors": "Jakob Lindinger, David Reeb, Christoph Lippert, Barbara Rakitsch", "title": "Beyond the Mean-Field: Structured Deep Gaussian Processes Improve the\n  Predictive Uncertainties", "comments": "12 pages main text, 20 pages appendix. v2: changes due to NeurIPS\n  review process. Camera-ready version to be published at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Gaussian Processes learn probabilistic data representations for\nsupervised learning by cascading multiple Gaussian Processes. While this model\nfamily promises flexible predictive distributions, exact inference is not\ntractable. Approximate inference techniques trade off the ability to closely\nresemble the posterior distribution against speed of convergence and\ncomputational efficiency. We propose a novel Gaussian variational family that\nallows for retaining covariances between latent processes while achieving fast\nconvergence by marginalising out all global latent variables. After providing a\nproof of how this marginalisation can be done for general covariances, we\nrestrict them to the ones we empirically found to be most important in order to\nalso achieve computational efficiency. We provide an efficient implementation\nof our new approach and apply it to several benchmark datasets. It yields\nexcellent results and strikes a better balance between accuracy and calibrated\nuncertainty estimates than its state-of-the-art alternatives.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 11:10:59 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 13:53:00 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Lindinger", "Jakob", ""], ["Reeb", "David", ""], ["Lippert", "Christoph", ""], ["Rakitsch", "Barbara", ""]]}, {"id": "2005.11115", "submitter": "Ansgar Steland", "authors": "Ansgar Steland", "title": "Consistency of Extreme Learning Machines and Regression under\n  Non-Stationarity and Dependence for ML-Enhanced Moving Objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning by extreme learning machines resp. neural networks with\nrandom weights is studied under a non-stationary spatial-temporal sampling\ndesign which especially addresses settings where an autonomous object moving in\na non-stationary spatial environment collects and analyzes data. The stochastic\nmodel especially allows for spatial heterogeneity and weak dependence. As\nefficient and computationally cheap learning methods (unconstrained) least\nsquares, ridge regression and $\\ell_s$-penalized least squares (including the\nLASSO) are studied. Consistency and asymptotic normality of the least squares\nand ridge regression estimates as well as corresponding consistency results for\nthe $\\ell_s$-penalty are shown under weak conditions. The resuts also cover\nbounds for the sample squared predicition error.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 11:29:15 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 17:05:07 GMT"}, {"version": "v3", "created": "Fri, 18 Jun 2021 09:56:40 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Steland", "Ansgar", ""]]}, {"id": "2005.11138", "submitter": "Marko Stamenovic", "authors": "Igor Fedorov, Marko Stamenovic, Carl Jensen, Li-Chia Yang, Ari\n  Mandell, Yiming Gan, Matthew Mattina, Paul N. Whatmough", "title": "TinyLSTMs: Efficient Neural Speech Enhancement for Hearing Aids", "comments": "First four authors contributed equally. For audio samples, see\n  https://github.com/BoseCorp/efficient-neural-speech-enhancement", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern speech enhancement algorithms achieve remarkable noise suppression by\nmeans of large recurrent neural networks (RNNs). However, large RNNs limit\npractical deployment in hearing aid hardware (HW) form-factors, which are\nbattery powered and run on resource-constrained microcontroller units (MCUs)\nwith limited memory capacity and compute capability. In this work, we use model\ncompression techniques to bridge this gap. We define the constraints imposed on\nthe RNN by the HW and describe a method to satisfy them. Although model\ncompression techniques are an active area of research, we are the first to\ndemonstrate their efficacy for RNN speech enhancement, using pruning and\ninteger quantization of weights/activations. We also demonstrate state update\nskipping, which reduces the computational load. Finally, we conduct a\nperceptual evaluation of the compressed models to verify audio quality on human\nraters. Results show a reduction in model size and operations of 11.9$\\times$\nand 2.9$\\times$, respectively, over the baseline for compressed models, without\na statistical difference in listening preference and only exhibiting a loss of\n0.55dB SDR. Our model achieves a computational latency of 2.39ms, well within\nthe 10ms target and 351$\\times$ better than previous work.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 20:37:47 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Fedorov", "Igor", ""], ["Stamenovic", "Marko", ""], ["Jensen", "Carl", ""], ["Yang", "Li-Chia", ""], ["Mandell", "Ari", ""], ["Gan", "Yiming", ""], ["Mattina", "Matthew", ""], ["Whatmough", "Paul N.", ""]]}, {"id": "2005.11142", "submitter": "Haotian Liu", "authors": "Haotian Liu, Wenchuan Wu", "title": "Two-stage Deep Reinforcement Learning for Inverter-based Volt-VAR\n  Control in Active Distribution Networks", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based Vol/VAR optimization method is widely used to eliminate voltage\nviolations and reduce network losses. However, the parameters of active\ndistribution networks(ADNs) are not onsite identified, so significant errors\nmay be involved in the model and make the model-based method infeasible. To\ncope with this critical issue, we propose a novel two-stage deep reinforcement\nlearning (DRL) method to improve the voltage profile by regulating\ninverter-based energy resources, which consists of offline stage and online\nstage. In the offline stage, a highly efficient adversarial reinforcement\nlearning algorithm is developed to train an offline agent robust to the model\nmismatch. In the sequential online stage, we transfer the offline agent safely\nas the online agent to perform continuous learning and controlling online with\nsignificantly improved safety and efficiency. Numerical simulations on IEEE\ntest cases not only demonstrate that the proposed adversarial reinforcement\nlearning algorithm outperforms the state-of-art algorithm, but also show that\nour proposed two-stage method achieves much better performance than the\nexisting DRL based methods in the online application.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 08:02:13 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Liu", "Haotian", ""], ["Wu", "Wenchuan", ""]]}, {"id": "2005.11144", "submitter": "Saaketh Desai", "authors": "Saaketh Desai, Alejandro Strachan", "title": "Parsimonious neural networks learn interpretable physical laws", "comments": "18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is playing an increasing role in the physical sciences and\nsignificant progress has been made towards embedding domain knowledge into\nmodels. Less explored is its use to discover interpretable physical laws from\ndata. We propose parsimonious neural networks (PNNs) that combine neural\nnetworks with evolutionary optimization to find models that balance accuracy\nwith parsimony. The power and versatility of the approach is demonstrated by\ndeveloping models for classical mechanics and to predict the melting\ntemperature of materials from fundamental properties. In the first example, the\nresulting PNNs are easily interpretable as Newton's second law, expressed as a\nnon-trivial time integrator that exhibits time-reversibility and conserves\nenergy, where the parsimony is critical to extract underlying symmetries from\nthe data. In the second case, the PNNs not only find the celebrated Lindemann\nmelting law, but also new relationships that outperform it in the pareto sense\nof parsimony vs. accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 16:15:47 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 12:08:51 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 21:36:40 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Desai", "Saaketh", ""], ["Strachan", "Alejandro", ""]]}, {"id": "2005.11146", "submitter": "Tomasz Szydlo", "authors": "Tomasz Szydlo, Joanna Sendorek, Robert Brzoza-Woch, Mateusz Windak", "title": "Machine Learning in the Internet of Things for Industry 4.0", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Number of IoT devices is constantly increasing which results in greater\ncomplexity of computations and high data velocity. One of the approach to\nprocess sensor data is dataflow programming. It enables the development of\nreactive software with short processing and rapid response times, especially\nwhen moved to the edge of the network. This is especially important in systems\nthat utilize online machine learning algorithms to analyze ongoing processes\nsuch as those observed in Industry 4.0. In this paper, we show that\norganization of such systems depends on the entire processing stack, from the\nhardware layer all the way to the software layer, as well as on the required\nresponse times of the IoT system. We propose a flow processing stack for such\nsystems along with the organizational machine learning architectural patterns\nthat enable the possibility to spread the learning and inferencing on the edge\nand the cloud. In the paper, we analyse what latency is introduced by\ncommunication technologies used in the IoT for cloud connectivity and how they\ninfluence the response times of the system. Finally, we are providing\nrecommendations which machine learning patterns should be used in the IoT\nsystems depending on the application type.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 12:43:15 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Szydlo", "Tomasz", ""], ["Sendorek", "Joanna", ""], ["Brzoza-Woch", "Robert", ""], ["Windak", "Mateusz", ""]]}, {"id": "2005.11149", "submitter": "Hailan Ma", "authors": "Hailan Ma, Chang-Jiang Huang, Chunlin Chen, Daoyi Dong, Yuanlong Wang,\n  Re-Bing Wu, Guo-Yong Xiang", "title": "On compression rate of quantum autoencoders: Control design, numerical\n  and experimental realization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum autoencoders which aim at compressing quantum information in a\nlow-dimensional latent space lie in the heart of automatic data compression in\nthe field of quantum information. In this paper, we establish an upper bound of\nthe compression rate for a given quantum autoencoder and present a learning\ncontrol approach for training the autoencoder to achieve the maximal\ncompression rate. The upper bound of the compression rate is theoretically\nproven using eigen-decomposition and matrix differentiation, which is\ndetermined by the eigenvalues of the density matrix representation of the input\nstates. Numerical results on 2-qubit and 3-qubit systems are presented to\ndemonstrate how to train the quantum autoencoder to achieve the theoretically\nmaximal compression, and the training performance using different machine\nlearning algorithms is compared. Experimental results of a quantum autoencoder\nusing quantum optical systems are illustrated for compressing two 2-qubit\nstates into two 1-qubit states.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 12:44:16 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Ma", "Hailan", ""], ["Huang", "Chang-Jiang", ""], ["Chen", "Chunlin", ""], ["Dong", "Daoyi", ""], ["Wang", "Yuanlong", ""], ["Wu", "Re-Bing", ""], ["Xiang", "Guo-Yong", ""]]}, {"id": "2005.11184", "submitter": "Hemant Yadav", "authors": "Hemant Yadav, Sreyan Ghosh, Yi Yu, Rajiv Ratn Shah", "title": "End-to-end Named Entity Recognition from English Speech", "comments": "submitted to Interspeech-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition (NER) from text has been a widely studied problem\nand usually extracts semantic information from text. Until now, NER from speech\nis mostly studied in a two-step pipeline process that includes first applying\nan automatic speech recognition (ASR) system on an audio sample and then\npassing the predicted transcript to a NER tagger. In such cases, the error does\nnot propagate from one step to another as both the tasks are not optimized in\nan end-to-end (E2E) fashion. Recent studies confirm that integrated approaches\n(e.g., E2E ASR) outperform sequential ones (e.g., phoneme based ASR). In this\npaper, we introduce a first publicly available NER annotated dataset for\nEnglish speech and present an E2E approach, which jointly optimizes the ASR and\nNER tagger components. Experimental results show that the proposed E2E approach\noutperforms the classical two-step approach. We also discuss how NER from\nspeech can be used to handle out of vocabulary (OOV) words in an ASR system.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 13:39:14 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Yadav", "Hemant", ""], ["Ghosh", "Sreyan", ""], ["Yu", "Yi", ""], ["Shah", "Rajiv Ratn", ""]]}, {"id": "2005.11194", "submitter": "Charlie Kirkwood", "authors": "Charlie Kirkwood", "title": "Deep covariate-learning: optimising information extraction from terrain\n  texture for geostatistical modelling applications", "comments": "14 pages, 8 figures, submitted to journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Where data is available, it is desirable in geostatistical modelling to make\nuse of additional covariates, for example terrain data, in order to improve\nprediction accuracy in the modelling task. While elevation itself may be\nimportant, additional explanatory power for any given problem can be sought\n(but not necessarily found) by filtering digital elevation models to extract\nhigher-order derivatives such as slope angles, curvatures, and roughness. In\nessence, it would be beneficial to extract as much task-relevant information as\npossible from the elevation grid. However, given the complexities of the\nnatural world, chance dictates that the use of 'off-the-shelf' filters is\nunlikely to derive covariates that provide strong explanatory power to the\ntarget variable at hand, and any attempt to manually design informative\ncovariates is likely to be a trial-and-error process -- not optimal. In this\npaper we present a solution to this problem in the form of a deep learning\napproach to automatically deriving optimal task-specific terrain texture\ncovariates from a standard SRTM 90m gridded digital elevation model (DEM). For\nour target variables we use point-sampled geochemical data from the British\nGeological Survey: concentrations of potassium, calcium and arsenic in stream\nsediments. We find that our deep learning approach produces covariates for\ngeostatistical modelling that have surprisingly strong explanatory power on\ntheir own, with R-squared values around 0.6 for all three elements (with\narsenic on the log scale). These results are achieved without the neural\nnetwork being provided with easting, northing, or absolute elevation as inputs,\nand purely reflect the capacity of our deep neural network to extract\ntask-specific information from terrain texture. We hope that these results will\ninspire further investigation into the capabilities of deep learning within\ngeostatistical applications.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 14:00:28 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 11:19:48 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kirkwood", "Charlie", ""]]}, {"id": "2005.11212", "submitter": "Max Tegmark", "authors": "Silviu-Marian Udrescu (MIT), Max Tegmark (MIT)", "title": "Symbolic Pregression: Discovering Physical Laws from Distorted Video", "comments": "Expanded and improved physics discussion, additional method details.\n  9 pages, 7 figs", "journal-ref": "Phys. Rev. E 103, 043307 (2021)", "doi": "10.1103/PhysRevE.103.043307", "report-no": null, "categories": "cs.CV cs.AI cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for unsupervised learning of equations of motion for\nobjects in raw and optionally distorted unlabeled video. We first train an\nautoencoder that maps each video frame into a low-dimensional latent space\nwhere the laws of motion are as simple as possible, by minimizing a combination\nof non-linearity, acceleration and prediction error. Differential equations\ndescribing the motion are then discovered using Pareto-optimal symbolic\nregression. We find that our pre-regression (\"pregression\") step is able to\nrediscover Cartesian coordinates of unlabeled moving objects even when the\nvideo is distorted by a generalized lens. Using intuition from multidimensional\nknot-theory, we find that the pregression step is facilitated by first adding\nextra latent space dimensions to avoid topological problems during training and\nthen removing these extra dimensions via principal component analysis.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 18:00:52 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 17:52:02 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Udrescu", "Silviu-Marian", "", "MIT"], ["Tegmark", "Max", "", "MIT"]]}, {"id": "2005.11217", "submitter": "Prashnna Gyawali", "authors": "Prashnna Kumar Gyawali, Sandesh Ghimire, Pradeep Bajracharya, Zhiyuan\n  Li, Linwei Wang", "title": "Semi-supervised Medical Image Classification with Global Latent Mixing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computer-aided diagnosis via deep learning relies on large-scale annotated\ndata sets, which can be costly when involving expert knowledge. Semi-supervised\nlearning (SSL) mitigates this challenge by leveraging unlabeled data. One\neffective SSL approach is to regularize the local smoothness of neural\nfunctions via perturbations around single data points. In this work, we argue\nthat regularizing the global smoothness of neural functions by filling the void\nin between data points can further improve SSL. We present a novel SSL approach\nthat trains the neural network on linear mixing of labeled and unlabeled data,\nat both the input and latent space in order to regularize different portions of\nthe network. We evaluated the presented model on two distinct medical image\ndata sets for semi-supervised classification of thoracic disease and skin\nlesion, demonstrating its improved performance over SSL with local\nperturbations and SSL with global mixing but at the input space only. Our code\nis available at https://github.com/Prasanna1991/LatentMixing.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 14:49:13 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Gyawali", "Prashnna Kumar", ""], ["Ghimire", "Sandesh", ""], ["Bajracharya", "Pradeep", ""], ["Li", "Zhiyuan", ""], ["Wang", "Linwei", ""]]}, {"id": "2005.11235", "submitter": "Gautam Krishna", "authors": "Gautam Krishna, Co Tran, Mason Carnahan, Ahmed Tewfik", "title": "Predicting Video features from EEG and Vice versa", "comments": "under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore predicting facial or lip video features from\nelectroencephalography (EEG) features and predicting EEG features from recorded\nfacial or lip video frames using deep learning models. The subjects were asked\nto read out loud English sentences shown to them on a computer screen and their\nsimultaneous EEG signals and facial video frames were recorded. Our model was\nable to generate very broad characteristics of the facial or lip video frame\nfrom input EEG features. Our results demonstrate the first step towards\nsynthesizing high quality facial or lip video from recorded EEG features. We\ndemonstrate results for a data set consisting of seven subjects.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 20:04:38 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Krishna", "Gautam", ""], ["Tran", "Co", ""], ["Carnahan", "Mason", ""], ["Tewfik", "Ahmed", ""]]}, {"id": "2005.11246", "submitter": "Quentin Paletta", "authors": "Quentin Paletta, Joan Lasenby", "title": "Convolutional Neural Networks applied to sky images for short-term solar\n  irradiance forecasting", "comments": "4 pages, 7 figures, 1 table, accepted for European PV Solar Energy\n  Conference and Exhibition (EU-PVSEC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the advances in the field of solar energy, improvements of solar\nforecasting techniques, addressing the intermittent electricity production,\nremain essential for securing its future integration into a wider energy\nsupply. A promising approach to anticipate irradiance changes consists of\nmodeling the cloud cover dynamics from ground taken or satellite images. This\nwork presents preliminary results on the application of deep Convolutional\nNeural Networks for 2 to 20 min irradiance forecasting using hemispherical sky\nimages and exogenous variables. We evaluate the models on a set of irradiance\nmeasurements and corresponding sky images collected in Palaiseau (France) over\n8 months with a temporal resolution of 2 min. To outline the learning of neural\nnetworks in the context of short-term irradiance forecasting, we implemented\nvisualisation techniques revealing the types of patterns recognised by trained\nalgorithms in sky images. In addition, we show that training models with past\nsamples of the same day improves their forecast skill, relative to the smart\npersistence model based on the Mean Square Error, by around 10% on a 10 min\nahead prediction. These results emphasise the benefit of integrating previous\nsame-day data in short-term forecasting. This, in turn, can be achieved through\nmodel fine tuning or using recurrent units to facilitate the extraction of\nrelevant temporal features from past data.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 15:57:39 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Paletta", "Quentin", ""], ["Lasenby", "Joan", ""]]}, {"id": "2005.11248", "submitter": "Inkit Padhi", "authors": "Payel Das, Tom Sercu, Kahini Wadhawan, Inkit Padhi, Sebastian\n  Gehrmann, Flaviu Cipcigan, Vijil Chenthamarakshan, Hendrik Strobelt, Cicero\n  dos Santos, Pin-Yu Chen, Yi Yan Yang, Jeremy Tan, James Hedrick, Jason Crain,\n  Aleksandra Mojsilovic", "title": "Accelerating Antimicrobial Discovery with Controllable Deep Generative\n  Models and Molecular Dynamics", "comments": null, "journal-ref": "Nature Biomedical Engineering (2021)", "doi": "10.1038/s41551-021-00689-x", "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  De novo therapeutic design is challenged by a vast chemical repertoire and\nmultiple constraints, e.g., high broad-spectrum potency and low toxicity. We\npropose CLaSS (Controlled Latent attribute Space Sampling) - an efficient\ncomputational method for attribute-controlled generation of molecules, which\nleverages guidance from classifiers trained on an informative latent space of\nmolecules modeled using a deep generative autoencoder. We screen the generated\nmolecules for additional key attributes by using deep learning classifiers in\nconjunction with novel features derived from atomistic simulations. The\nproposed approach is demonstrated for designing non-toxic antimicrobial\npeptides (AMPs) with strong broad-spectrum potency, which are emerging drug\ncandidates for tackling antibiotic resistance. Synthesis and testing of only\ntwenty designed sequences identified two novel and minimalist AMPs with high\npotency against diverse Gram-positive and Gram-negative pathogens, including\none multidrug-resistant and one antibiotic-resistant K. pneumoniae, via\nmembrane pore formation. Both antimicrobials exhibit low in vitro and in vivo\ntoxicity and mitigate the onset of drug resistance. The proposed approach thus\npresents a viable path for faster and efficient discovery of potent and\nselective broad-spectrum antimicrobials.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 15:57:58 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 01:03:38 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Das", "Payel", ""], ["Sercu", "Tom", ""], ["Wadhawan", "Kahini", ""], ["Padhi", "Inkit", ""], ["Gehrmann", "Sebastian", ""], ["Cipcigan", "Flaviu", ""], ["Chenthamarakshan", "Vijil", ""], ["Strobelt", "Hendrik", ""], ["Santos", "Cicero dos", ""], ["Chen", "Pin-Yu", ""], ["Yang", "Yi Yan", ""], ["Tan", "Jeremy", ""], ["Hedrick", "James", ""], ["Crain", "Jason", ""], ["Mojsilovic", "Aleksandra", ""]]}, {"id": "2005.11251", "submitter": "Matthew England Dr", "authors": "Dorian Florescu and Matthew England", "title": "A machine learning based software pipeline to pick the variable ordering\n  for algorithms with polynomial inputs", "comments": "Accepted into Proc ICMS 2020", "journal-ref": "Mathematical Software (Proc. ICMS '20), pp. 302-322, (Lecture\n  Notes in Computer Science, 12097). Springer International Publishing, 2020", "doi": "10.1007/978-3-030-52200-1_30", "report-no": null, "categories": "cs.SC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the application of Machine Learning (ML) technology to\nimprove mathematical software. It may seem that the probabilistic nature of ML\ntools would invalidate the exact results prized by such software, however, the\nalgorithms which underpin the software often come with a range of choices which\nare good candidates for ML application. We refer to choices which have no\neffect on the mathematical correctness of the software, but do impact its\nperformance.\n  In the past we experimented with one such choice: the variable ordering to\nuse when building a Cylindrical Algebraic Decomposition (CAD). We used the\nPython library Scikit-Learn (sklearn) to experiment with different ML models,\nand developed new techniques for feature generation and hyper-parameter\nselection.\n  These techniques could easily be adapted for making decisions other than our\nimmediate application of CAD variable ordering. Hence in this paper we present\na software pipeline to use sklearn to pick the variable ordering for an\nalgorithm that acts on a polynomial system. The code described is freely\navailable online.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 16:00:04 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Florescu", "Dorian", ""], ["England", "Matthew", ""]]}, {"id": "2005.11257", "submitter": "Purushottam Kar", "authors": "Amit Chandak and Debojyoti Dey and Bhaskar Mukhoty and Purushottam Kar", "title": "Epidemiologically and Socio-economically Optimal Policies via Bayesian\n  Optimization", "comments": "Keywords: COVID-19, Optimal Policy, Lock-down, Epidemiology, Bayesian\n  Optimization Code available at https://github.com/purushottamkar/esop", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mass public quarantining, colloquially known as a lock-down, is a\nnon-pharmaceutical intervention to check spread of disease. This paper presents\nESOP (Epidemiologically and Socio-economically Optimal Policies), a novel\napplication of active machine learning techniques using Bayesian optimization,\nthat interacts with an epidemiological model to arrive at lock-down schedules\nthat optimally balance public health benefits and socio-economic downsides of\nreduced economic activity during lock-down periods. The utility of ESOP is\ndemonstrated using case studies with VIPER\n(Virus-Individual-Policy-EnviRonment), a stochastic agent-based simulator that\nthis paper also proposes. However, ESOP is flexible enough to interact with\narbitrary epidemiological simulators in a black-box manner, and produce\nschedules that involve multiple phases of lock-downs.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 16:11:33 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 03:44:27 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Chandak", "Amit", ""], ["Dey", "Debojyoti", ""], ["Mukhoty", "Bhaskar", ""], ["Kar", "Purushottam", ""]]}, {"id": "2005.11270", "submitter": "Yunzi Ding", "authors": "Yunzi Ding, Dmitriy Kunisky, Alexander S. Wein, Afonso S. Bandeira", "title": "The Average-Case Time Complexity of Certifying the Restricted Isometry\n  Property", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In compressed sensing, the restricted isometry property (RIP) on $M \\times N$\nsensing matrices (where $M < N$) guarantees efficient reconstruction of sparse\nvectors. A matrix has the $(s,\\delta)$-$\\mathsf{RIP}$ property if behaves as a\n$\\delta$-approximate isometry on $s$-sparse vectors. It is well known that an\n$M\\times N$ matrix with i.i.d. $\\mathcal{N}(0,1/M)$ entries is\n$(s,\\delta)$-$\\mathsf{RIP}$ with high probability as long as $s\\lesssim\n\\delta^2 M/\\log N$. On the other hand, most prior works aiming to\ndeterministically construct $(s,\\delta)$-$\\mathsf{RIP}$ matrices have failed\nwhen $s \\gg \\sqrt{M}$. An alternative way to find an RIP matrix could be to\ndraw a random gaussian matrix and certify that it is indeed RIP. However, there\nis evidence that this certification task is computationally hard when $s \\gg\n\\sqrt{M}$, both in the worst case and the average case.\n  In this paper, we investigate the exact average-case time complexity of\ncertifying the RIP property for $M\\times N$ matrices with i.i.d.\n$\\mathcal{N}(0,1/M)$ entries, in the \"possible but hard\" regime $\\sqrt{M} \\ll\ns\\lesssim M/\\log N$. Based on analysis of the low-degree likelihood ratio, we\ngive rigorous evidence that subexponential runtime $N^{\\tilde\\Omega(s^2/M)}$ is\nrequired, demonstrating a smooth tradeoff between the maximum tolerated\nsparsity and the required computational power. This lower bound is essentially\ntight, matching the runtime of an existing algorithm due to Koiran and Zouzias.\nOur hardness result allows $\\delta$ to take any constant value in $(0,1)$,\nwhich captures the relevant regime for compressed sensing. This improves upon\nthe existing average-case hardness result of Wang, Berthet, and Plan, which is\nlimited to $\\delta = o(1)$.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 16:55:01 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 15:44:33 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 16:00:12 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Ding", "Yunzi", ""], ["Kunisky", "Dmitriy", ""], ["Wein", "Alexander S.", ""], ["Bandeira", "Afonso S.", ""]]}, {"id": "2005.11275", "submitter": "Johannes Linder", "authors": "Johannes Linder and Georg Seelig", "title": "Fast differentiable DNA and protein sequence optimization for molecular\n  design", "comments": "All code available at http://www.github.com/johli/seqprop; Moved\n  example sequences from Suppl to new Figure 2, Added new benchmark comparison\n  to Section 4.3, Moved some technical comparisons to Suppl, Added new Methods\n  section", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Designing DNA and protein sequences with improved function has the potential\nto greatly accelerate synthetic biology. Machine learning models that\naccurately predict biological fitness from sequence are becoming a powerful\ntool for molecular design. Activation maximization offers a simple design\nstrategy for differentiable models: one-hot coded sequences are first\napproximated by a continuous representation which is then iteratively optimized\nwith respect to the predictor oracle by gradient ascent. While elegant, this\nmethod suffers from vanishing gradients and may cause predictor pathologies\nleading to poor convergence. Here, we build on a previously proposed\nstraight-through approximation method to optimize through discrete sequence\nsamples. By normalizing nucleotide logits across positions and introducing an\nadaptive entropy variable, we remove bottlenecks arising from overly large or\nskewed sampling parameters. The resulting algorithm, which we call Fast\nSeqProp, achieves up to 100-fold faster convergence compared to previous\nversions of activation maximization and finds improved fitness optima for many\napplications. We demonstrate Fast SeqProp by designing DNA and protein\nsequences for six deep learning predictors, including a protein structure\npredictor.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 17:03:55 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 22:44:01 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Linder", "Johannes", ""], ["Seelig", "Georg", ""]]}, {"id": "2005.11282", "submitter": "Ashish Khetan", "authors": "Ashish Khetan, Zohar Karnin", "title": "PruneNet: Channel Pruning via Global Importance", "comments": "12 pages, 3 figures, Published in ICLR 2020 NAS Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel pruning is one of the predominant approaches for accelerating deep\nneural networks. Most existing pruning methods either train from scratch with a\nsparsity inducing term such as group lasso, or prune redundant channels in a\npretrained network and then fine tune the network. Both strategies suffer from\nsome limitations: the use of group lasso is computationally expensive,\ndifficult to converge and often suffers from worse behavior due to the\nregularization bias. The methods that start with a pretrained network either\nprune channels uniformly across the layers or prune channels based on the basic\nstatistics of the network parameters. These approaches either ignore the fact\nthat some CNN layers are more redundant than others or fail to adequately\nidentify the level of redundancy in different layers. In this work, we\ninvestigate a simple-yet-effective method for pruning channels based on a\ncomputationally light-weight yet effective data driven optimization step that\ndiscovers the necessary width per layer. Experiments conducted on ILSVRC-$12$\nconfirm effectiveness of our approach. With non-uniform pruning across the\nlayers on ResNet-$50$, we are able to match the FLOP reduction of\nstate-of-the-art channel pruning results while achieving a $0.98\\%$ higher\naccuracy. Further, we show that our pruned ResNet-$50$ network outperforms\nResNet-$34$ and ResNet-$18$ networks, and that our pruned ResNet-$101$\noutperforms ResNet-$50$.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 17:09:56 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Khetan", "Ashish", ""], ["Karnin", "Zohar", ""]]}, {"id": "2005.11295", "submitter": "Dimitris Tsipras", "authors": "Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Andrew Ilyas,\n  Aleksander Madry", "title": "From ImageNet to Image Classification: Contextualizing Progress on\n  Benchmarks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building rich machine learning datasets in a scalable manner often\nnecessitates a crowd-sourced data collection pipeline. In this work, we use\nhuman studies to investigate the consequences of employing such a pipeline,\nfocusing on the popular ImageNet dataset. We study how specific design choices\nin the ImageNet creation process impact the fidelity of the resulting\ndataset---including the introduction of biases that state-of-the-art models\nexploit. Our analysis pinpoints how a noisy data collection pipeline can lead\nto a systematic misalignment between the resulting benchmark and the real-world\ntask it serves as a proxy for. Finally, our findings emphasize the need to\naugment our current model training and evaluation toolkit to take such\nmisalignments into account. To facilitate further research, we release our\nrefined ImageNet annotations at https://github.com/MadryLab/ImageNetMultiLabel.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 17:39:16 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Tsipras", "Dimitris", ""], ["Santurkar", "Shibani", ""], ["Engstrom", "Logan", ""], ["Ilyas", "Andrew", ""], ["Madry", "Aleksander", ""]]}, {"id": "2005.11300", "submitter": "Thomas Foster", "authors": "Thomas Foster, Chon Lok Lei, Martin Robinson, David Gavaghan, Ben\n  Lambert", "title": "Model Evidence with Fast Tree Based Quadrature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.MS stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High dimensional integration is essential to many areas of science, ranging\nfrom particle physics to Bayesian inference. Approximating these integrals is\nhard, due in part to the difficulty of locating and sampling from regions of\nthe integration domain that make significant contributions to the overall\nintegral. Here, we present a new algorithm called Tree Quadrature (TQ) that\nseparates this sampling problem from the problem of using those samples to\nproduce an approximation of the integral. TQ places no qualifications on how\nthe samples provided to it are obtained, allowing it to use state-of-the-art\nsampling algorithms that are largely ignored by existing integration\nalgorithms. Given a set of samples, TQ constructs a surrogate model of the\nintegrand in the form of a regression tree, with a structure optimised to\nmaximise integral precision. The tree divides the integration domain into\nsmaller containers, which are individually integrated and aggregated to\nestimate the overall integral. Any method can be used to integrate each\nindividual container, so existing integration methods, like Bayesian Monte\nCarlo, can be combined with TQ to boost their performance. On a set of\nbenchmark problems, we show that TQ provides accurate approximations to\nintegrals in up to 15 dimensions; and in dimensions 4 and above, it outperforms\nsimple Monte Carlo and the popular Vegas method.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 17:48:06 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Foster", "Thomas", ""], ["Lei", "Chon Lok", ""], ["Robinson", "Martin", ""], ["Gavaghan", "David", ""], ["Lambert", "Ben", ""]]}, {"id": "2005.11304", "submitter": "Dobrik Georgiev", "authors": "Dobrik Georgiev, Pietro Li\\`o", "title": "Neural Bipartite Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have found application for learning in the space\nof algorithms. However, the algorithms chosen by existing research (sorting,\nBreadth-First search, shortest path finding, etc.) usually align perfectly with\na standard GNN architecture. This report describes how neural execution is\napplied to a complex algorithm, such as finding maximum bipartite matching by\nreducing it to a flow problem and using Ford-Fulkerson to find the maximum\nflow. This is achieved via neural execution based only on features generated\nfrom a single GNN. The evaluation shows strongly generalising results with the\nnetwork achieving optimal matching almost 100% of the time.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 17:50:38 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 06:03:10 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 13:21:41 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Georgiev", "Dobrik", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "2005.11313", "submitter": "Param Raval", "authors": "Devshree Patel, Param Raval, Ratnam Parikh, Yesha Shastri", "title": "Comparative Study of Machine Learning Models and BERT on SQuAD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study aims to provide a comparative analysis of performance of certain\nmodels popular in machine learning and the BERT model on the Stanford Question\nAnswering Dataset (SQuAD). The analysis shows that the BERT model, which was\nonce state-of-the-art on SQuAD, gives higher accuracy in comparison to other\nmodels. However, BERT requires a greater execution time even when only 100\nsamples are used. This shows that with increasing accuracy more amount of time\nis invested in training the data. Whereas in case of preliminary machine\nlearning models, execution time for full data is lower but accuracy is\ncompromised.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 17:58:30 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Patel", "Devshree", ""], ["Raval", "Param", ""], ["Parikh", "Ratnam", ""], ["Shastri", "Yesha", ""]]}, {"id": "2005.11335", "submitter": "Arta Seify", "authors": "Arta Seify and Michael Buro", "title": "Single-Agent Optimization Through Policy Iteration Using Monte-Carlo\n  Tree Search", "comments": "Poster presentation at RL in Games Workshop, AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of Monte-Carlo Tree Search (MCTS) and deep reinforcement\nlearning is state-of-the-art in two-player perfect-information games. In this\npaper, we describe a search algorithm that uses a variant of MCTS which we\nenhanced by 1) a novel action value normalization mechanism for games with\npotentially unbounded rewards (which is the case in many optimization\nproblems), 2) defining a virtual loss function that enables effective search\nparallelization, and 3) a policy network, trained by generations of self-play,\nto guide the search. We gauge the effectiveness of our method in \"SameGame\"---a\npopular single-player test domain. Our experimental results indicate that our\nmethod outperforms baseline algorithms on several board sizes. Additionally, it\nis competitive with state-of-the-art search algorithms on a public set of\npositions.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 18:02:36 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Seify", "Arta", ""], ["Buro", "Michael", ""]]}, {"id": "2005.11347", "submitter": "Li Zhang", "authors": "Li Zhang, Han Wang, Lingxiao Li", "title": "SentPWNet: A Unified Sentence Pair Weighting Network for Task-specific\n  Sentence Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pair-based metric learning has been widely adopted to learn sentence\nembedding in many NLP tasks such as semantic text similarity due to its\nefficiency in computation. Most existing works employed a sequence encoder\nmodel and utilized limited sentence pairs with a pair-based loss to learn\ndiscriminating sentence representation. However, it is known that the sentence\nrepresentation can be biased when the sampled sentence pairs deviate from the\ntrue distribution of all sentence pairs. In this paper, our theoretical\nanalysis shows that existing works severely suffered from a good pair sampling\nand instance weighting strategy. Instead of one time pair selection and\nlearning on equal weighted pairs, we propose a unified locality weighting and\nlearning framework to learn task-specific sentence embedding. Our model,\nSentPWNet, exploits the neighboring spatial distribution of each sentence as\nlocality weight to indicate the informative level of sentence pair. Such weight\nis updated along with pair-loss optimization in each round, ensuring the model\nkeep learning the most informative sentence pairs. Extensive experiments on\nfour public available datasets and a self-collected place search benchmark with\n1.4 million places clearly demonstrate that our model consistently outperforms\nexisting sentence embedding methods with comparable efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 18:32:35 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Zhang", "Li", ""], ["Wang", "Han", ""], ["Li", "Lingxiao", ""]]}, {"id": "2005.11348", "submitter": "Dimitri Leandro De Oliveira Silva", "authors": "Dimitri Leandro de Oliveira Silva, Tito Spadini and Ricardo Suyama", "title": "Microphone Array Based Surveillance Audio Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The work assessed seven classical classifiers and two beamforming algorithms\nfor detecting surveillance sound events. The tests included the use of AWGN\nwith -10 dB to 30 dB SNR. Data Augmentation was also employed to improve\nalgorithms' performance. The results showed that the combination of SVM and\nDelay-and-Sum (DaS) scored the best accuracy (up to 86.0\\%), but had high\ncomputational cost ($\\approx $ 402 ms), mainly due to DaS. The use of SGD also\nseems to be a good alternative since it has achieved good accuracy either (up\nto 85.3\\%), but with quicker processing time ($\\approx$ 165 ms).\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 18:35:08 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Silva", "Dimitri Leandro de Oliveira", ""], ["Spadini", "Tito", ""], ["Suyama", "Ricardo", ""]]}, {"id": "2005.11353", "submitter": "Safa Onur Sahin", "authors": "S. Onur Sahin and Suleyman S. Kozat", "title": "A Tree Architecture of LSTM Networks for Sequential Regression with\n  Missing Data", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate regression for variable length sequential data containing\nmissing samples and introduce a novel tree architecture based on the Long\nShort-Term Memory (LSTM) networks. In our architecture, we employ a variable\nnumber of LSTM networks, which use only the existing inputs in the sequence, in\na tree-like architecture without any statistical assumptions or imputations on\nthe missing data, unlike all the previous approaches. In particular, we\nincorporate the missingness information by selecting a subset of these LSTM\nnetworks based on \"presence-pattern\" of a certain number of previous inputs.\nFrom the mixture of experts perspective, we train different LSTM networks as\nour experts for various missingness patterns and then combine their outputs to\ngenerate the final prediction. We also provide the computational complexity\nanalysis of the proposed architecture, which is in the same order of the\ncomplexity of the conventional LSTM architectures for the sequence length. Our\nmethod can be readily extended to similar structures such as GRUs, RNNs as\nremarked in the paper. In the experiments, we achieve significant performance\nimprovements with respect to the state-of-the-art methods for the well-known\nfinancial and real life datasets.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 18:57:47 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Sahin", "S. Onur", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "2005.11362", "submitter": "Drew Linsley", "authors": "Drew Linsley, Alekh Karkada Ashok, Lakshmi Narasimhan Govindarajan,\n  Rex Liu, and Thomas Serre", "title": "Stable and expressive recurrent vision models", "comments": "Published at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Primate vision depends on recurrent processing for reliable perception. A\ngrowing body of literature also suggests that recurrent connections improve the\nlearning efficiency and generalization of vision models on classic computer\nvision challenges. Why then, are current large-scale challenges dominated by\nfeedforward networks? We posit that the effectiveness of recurrent vision\nmodels is bottlenecked by the standard algorithm used for training them,\n\"back-propagation through time\" (BPTT), which has O(N) memory-complexity for\ntraining an N step model. Thus, recurrent vision model design is bounded by\nmemory constraints, forcing a choice between rivaling the enormous capacity of\nleading feedforward models or trying to compensate for this deficit through\ngranular and complex dynamics. Here, we develop a new learning algorithm,\n\"contractor recurrent back-propagation\" (C-RBP), which alleviates these issues\nby achieving constant O(1) memory-complexity with steps of recurrent\nprocessing. We demonstrate that recurrent vision models trained with C-RBP can\ndetect long-range spatial dependencies in a synthetic contour tracing task that\nBPTT-trained models cannot. We further show that recurrent vision models\ntrained with C-RBP to solve the large-scale Panoptic Segmentation MS-COCO\nchallenge outperform the leading feedforward approach, with fewer free\nparameters. C-RBP is a general-purpose learning algorithm for any application\nthat can benefit from expansive recurrent dynamics. Code and data are available\nat https://github.com/c-rbp.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 19:31:28 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 23:15:14 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Linsley", "Drew", ""], ["Ashok", "Alekh Karkada", ""], ["Govindarajan", "Lakshmi Narasimhan", ""], ["Liu", "Rex", ""], ["Serre", "Thomas", ""]]}, {"id": "2005.11371", "submitter": "Jixuan Wang", "authors": "Jixuan Wang, Xiong Xiao, Jian Wu, Ranjani Ramamurthy, Frank Rudzicz,\n  Michael Brudno", "title": "Speaker diarization with session-level speaker embedding refinement\n  using graph neural networks", "comments": "ICASSP 2020 (45th International Conference on Acoustics, Speech, and\n  Signal Processing)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep speaker embedding models have been commonly used as a building block for\nspeaker diarization systems; however, the speaker embedding model is usually\ntrained according to a global loss defined on the training data, which could be\nsub-optimal for distinguishing speakers locally in a specific meeting session.\nIn this work we present the first use of graph neural networks (GNNs) for the\nspeaker diarization problem, utilizing a GNN to refine speaker embeddings\nlocally using the structural information between speech segments inside each\nsession. The speaker embeddings extracted by a pre-trained model are remapped\ninto a new embedding space, in which the different speakers within a single\nsession are better separated. The model is trained for linkage prediction in a\nsupervised manner by minimizing the difference between the affinity matrix\nconstructed by the refined embeddings and the ground-truth adjacency matrix.\nSpectral clustering is then applied on top of the refined embeddings. We show\nthat the clustering performance of the refined speaker embeddings outperforms\nthe original embeddings significantly on both simulated and real meeting data,\nand our system achieves the state-of-the-art result on the NIST SRE 2000\nCALLHOME database.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 19:52:51 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Wang", "Jixuan", ""], ["Xiao", "Xiong", ""], ["Wu", "Jian", ""], ["Ramamurthy", "Ranjani", ""], ["Rudzicz", "Frank", ""], ["Brudno", "Michael", ""]]}, {"id": "2005.11387", "submitter": "Aydogan Ozcan", "authors": "Jingxi Li, Deniz Mengu, Nezih T. Yardimci, Yi Luo, Xurong Li, Muhammed\n  Veli, Yair Rivenson, Mona Jarrahi, Aydogan Ozcan", "title": "Spectrally-Encoded Single-Pixel Machine Vision Using Diffractive\n  Networks", "comments": "21 pages, 5 figures, 1 table", "journal-ref": "Science Advances (2021)", "doi": "10.1126/sciadv.abd7690", "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D engineering of matter has opened up new avenues for designing systems that\ncan perform various computational tasks through light-matter interaction. Here,\nwe demonstrate the design of optical networks in the form of multiple\ndiffractive layers that are trained using deep learning to transform and encode\nthe spatial information of objects into the power spectrum of the diffracted\nlight, which are used to perform optical classification of objects with a\nsingle-pixel spectroscopic detector. Using a time-domain spectroscopy setup\nwith a plasmonic nanoantenna-based detector, we experimentally validated this\nmachine vision framework at terahertz spectrum to optically classify the images\nof handwritten digits by detecting the spectral power of the diffracted light\nat ten distinct wavelengths, each representing one class/digit. We also report\nthe coupling of this spectral encoding achieved through a diffractive optical\nnetwork with a shallow electronic neural network, separately trained to\nreconstruct the images of handwritten digits based on solely the spectral\ninformation encoded in these ten distinct wavelengths within the diffracted\nlight. These reconstructed images demonstrate task-specific image decompression\nand can also be cycled back as new inputs to the same diffractive network to\nimprove its optical object classification. This unique machine vision framework\nmerges the power of deep learning with the spatial and spectral processing\ncapabilities of diffractive networks, and can also be extended to other\nspectral-domain measurement systems to enable new 3D imaging and sensing\nmodalities integrated with spectrally encoded classification tasks performed\nthrough diffractive optical networks.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 09:18:21 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 04:48:42 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Li", "Jingxi", ""], ["Mengu", "Deniz", ""], ["Yardimci", "Nezih T.", ""], ["Luo", "Yi", ""], ["Li", "Xurong", ""], ["Veli", "Muhammed", ""], ["Rivenson", "Yair", ""], ["Jarrahi", "Mona", ""], ["Ozcan", "Aydogan", ""]]}, {"id": "2005.11394", "submitter": "Sandeep Singh Sandha", "authors": "Sandeep Singh Sandha, Mohit Aggarwal, Igor Fedorov, Mani Srivastava", "title": "MANGO: A Python Library for Parallel Hyperparameter Tuning", "comments": "5 pages, 3 figures, ICASSP Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tuning hyperparameters for machine learning algorithms is a tedious task, one\nthat is typically done manually. To enable automated hyperparameter tuning,\nrecent works have started to use techniques based on Bayesian optimization.\nHowever, to practically enable automated tuning for large scale machine\nlearning training pipelines, significant gaps remain in existing libraries,\nincluding lack of abstractions, fault tolerance, and flexibility to support\nscheduling on any distributed computing framework. To address these challenges,\nwe present Mango, a Python library for parallel hyperparameter tuning. Mango\nenables the use of any distributed scheduling framework, implements intelligent\nparallel search strategies, and provides rich abstractions for defining complex\nhyperparameter search spaces that are compatible with scikit-learn. Mango is\ncomparable in performance to Hyperopt, another widely used library. Mango is\navailable open-source and is currently used in production at Arm Research to\nprovide state-of-art hyperparameter tuning capabilities.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 20:58:26 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Sandha", "Sandeep Singh", ""], ["Aggarwal", "Mohit", ""], ["Fedorov", "Igor", ""], ["Srivastava", "Mani", ""]]}, {"id": "2005.11401", "submitter": "Patrick Lewis", "authors": "Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir\n  Karpukhin, Naman Goyal, Heinrich K\\\"uttler, Mike Lewis, Wen-tau Yih, Tim\n  Rockt\\\"aschel, Sebastian Riedel, Douwe Kiela", "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks", "comments": "Accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large pre-trained language models have been shown to store factual knowledge\nin their parameters, and achieve state-of-the-art results when fine-tuned on\ndownstream NLP tasks. However, their ability to access and precisely manipulate\nknowledge is still limited, and hence on knowledge-intensive tasks, their\nperformance lags behind task-specific architectures. Additionally, providing\nprovenance for their decisions and updating their world knowledge remain open\nresearch problems. Pre-trained models with a differentiable access mechanism to\nexplicit non-parametric memory can overcome this issue, but have so far been\nonly investigated for extractive downstream tasks. We explore a general-purpose\nfine-tuning recipe for retrieval-augmented generation (RAG) -- models which\ncombine pre-trained parametric and non-parametric memory for language\ngeneration. We introduce RAG models where the parametric memory is a\npre-trained seq2seq model and the non-parametric memory is a dense vector index\nof Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG\nformulations, one which conditions on the same retrieved passages across the\nwhole generated sequence, the other can use different passages per token. We\nfine-tune and evaluate our models on a wide range of knowledge-intensive NLP\ntasks and set the state-of-the-art on three open domain QA tasks, outperforming\nparametric seq2seq models and task-specific retrieve-and-extract architectures.\nFor language generation tasks, we find that RAG models generate more specific,\ndiverse and factual language than a state-of-the-art parametric-only seq2seq\nbaseline.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 21:34:34 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 16:23:06 GMT"}, {"version": "v3", "created": "Mon, 29 Mar 2021 10:12:16 GMT"}, {"version": "v4", "created": "Mon, 12 Apr 2021 15:42:18 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Lewis", "Patrick", ""], ["Perez", "Ethan", ""], ["Piktus", "Aleksandra", ""], ["Petroni", "Fabio", ""], ["Karpukhin", "Vladimir", ""], ["Goyal", "Naman", ""], ["K\u00fcttler", "Heinrich", ""], ["Lewis", "Mike", ""], ["Yih", "Wen-tau", ""], ["Rockt\u00e4schel", "Tim", ""], ["Riedel", "Sebastian", ""], ["Kiela", "Douwe", ""]]}, {"id": "2005.11405", "submitter": "Nathaniel Roth", "authors": "Nat Roth, Justin Wagle", "title": "One of these (Few) Things is Not Like the Others", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To perform well, most deep learning based image classification systems\nrequire large amounts of data and computing resources. These constraints make\nit difficult to quickly personalize to individual users or train models outside\nof fairly powerful machines. To deal with these problems, there has been a\nlarge body of research into teaching machines to learn to classify images based\non only a handful of training examples, a field known as few-shot learning.\nFew-shot learning research traditionally makes the simplifying assumption that\nall images belong to one of a fixed number of previously seen groups. However,\nmany image datasets, such as a camera roll on a phone, will be noisy and\ncontain images that may not be relevant or fit into any clear group. We propose\na model which can both classify new images based on a small number of examples\nand recognize images which do not belong to any previously seen group. We adapt\nprevious few-shot learning work to include a simple mechanism for learning a\ncutoff that determines whether an image should be excluded or classified. We\nexamine how well our method performs in a realistic setting, benchmarking the\napproach on a noisy and ambiguous dataset of images. We evaluate performance\nover a spectrum of model architectures, including setups small enough to be run\non low powered devices, such as mobile phones or web browsers. We find that\nthis task of excluding irrelevant images poses significant extra difficulty\nbeyond that of the traditional few-shot task. We decompose the sources of this\nerror, and suggest future improvements that might alleviate this difficulty.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 21:49:35 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Roth", "Nat", ""], ["Wagle", "Justin", ""]]}, {"id": "2005.11408", "submitter": "Junzhe Zhu", "authors": "Junzhe Zhu, Mark Hasegawa-Johnson, Leda Sari", "title": "Identify Speakers in Cocktail Parties with End-to-End Attention", "comments": "Accepted by Interspeech 2020 for presentation;\n  https://github.com/JunzheJosephZhu/Identify-Speakers-in-Cocktail-Parties-with-E2E-Attention", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In scenarios where multiple speakers talk at the same time, it is important\nto be able to identify the talkers accurately. This paper presents an\nend-to-end system that integrates speech source extraction and speaker\nidentification, and proposes a new way to jointly optimize these two parts by\nmax-pooling the speaker predictions along the channel dimension. Residual\nattention permits us to learn spectrogram masks that are optimized for the\npurpose of speaker identification, while residual forward connections permit\ndilated convolution with a sufficiently large context window to guarantee\ncorrect streaming across syllable boundaries. End-to-end training results in a\nsystem that recognizes one speaker in a two-speaker broadcast speech mixture\nwith 99.9% accuracy and both speakers with 93.9% accuracy, and that recognizes\nall speakers in three-speaker scenarios with 81.2% accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 22:15:16 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2020 09:24:35 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Zhu", "Junzhe", ""], ["Hasegawa-Johnson", "Mark", ""], ["Sari", "Leda", ""]]}, {"id": "2005.11411", "submitter": "Raaz Dwivedi", "authors": "Nhat Ho, Koulik Khamaru, Raaz Dwivedi, Martin J. Wainwright, Michael\n  I. Jordan, Bin Yu", "title": "Instability, Computational Efficiency and Statistical Accuracy", "comments": "First three authors contributed equally (listed in random order). 57\n  pages, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many statistical estimators are defined as the fixed point of a\ndata-dependent operator, with estimators based on minimizing a cost function\nbeing an important special case. The limiting performance of such estimators\ndepends on the properties of the population-level operator in the idealized\nlimit of infinitely many samples. We develop a general framework that yields\nbounds on statistical accuracy based on the interplay between the deterministic\nconvergence rate of the algorithm at the population level, and its degree of\n(in)stability when applied to an empirical object based on $n$ samples. Using\nthis framework, we analyze both stable forms of gradient descent and some\nhigher-order and unstable algorithms, including Newton's method and its\ncubic-regularized variant, as well as the EM algorithm. We provide applications\nof our general results to several concrete classes of models, including\nGaussian mixture estimation, single-index models, and informative non-response\nmodels. We exhibit cases in which an unstable algorithm can achieve the same\nstatistical accuracy as a stable algorithm in exponentially fewer\nsteps---namely, with the number of iterations being reduced from polynomial to\nlogarithmic in sample size $n$.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 22:30:52 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Ho", "Nhat", ""], ["Khamaru", "Koulik", ""], ["Dwivedi", "Raaz", ""], ["Wainwright", "Martin J.", ""], ["Jordan", "Michael I.", ""], ["Yu", "Bin", ""]]}, {"id": "2005.11417", "submitter": "Rishabh Malhotra", "authors": "Rishabh Malhotra, Dhron Joshi, Ku Young Shin", "title": "Approaching Bio Cellular Classification for Malaria Infected Cells Using\n  Machine Learning and then Deep Learning to compare & analyze K-Nearest\n  Neighbours and Deep CNNs", "comments": "7 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malaria is a deadly disease which claims the lives of hundreds of thousands\nof people every year. Computational methods have been proven to be useful in\nthe medical industry by providing effective means of classification of\ndiagnostic imaging and disease identification. This paper examines different\nmachine learning methods in the context of classifying the presence of malaria\nin cell images. Numerous machine learning methods can be applied to the same\nproblem; the question of whether one machine learning method is better suited\nto a problem relies heavily on the problem itself and the implementation of a\nmodel. In particular, convolutional neural networks and k nearest neighbours\nare both analyzed and contrasted in regards to their application to classifying\nthe presence of malaria and each models empirical performance. Here, we\nimplement two models of classification; a convolutional neural network, and the\nk nearest neighbours algorithm. These two algorithms are compared based on\nvalidation accuracy. For our implementation, CNN (95%) performed 25% better\nthan kNN (75%).\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 23:02:36 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Malhotra", "Rishabh", ""], ["Joshi", "Dhron", ""], ["Shin", "Ku Young", ""]]}, {"id": "2005.11418", "submitter": "Xinwei Zhang", "authors": "Xinwei Zhang, Mingyi Hong, Sairaj Dhople, Wotao Yin and Yang Liu", "title": "FedPD: A Federated Learning Framework with Optimal Rates and Adaptivity\n  to Non-IID Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) has become a popular paradigm for learning from\ndistributed data. To effectively utilize data at different devices without\nmoving them to the cloud, algorithms such as the Federated Averaging (FedAvg)\nhave adopted a \"computation then aggregation\" (CTA) model, in which multiple\nlocal updates are performed using local data, before sending the local models\nto the cloud for aggregation.\n  However, these schemes typically require strong assumptions, such as the\nlocal data are identically independent distributed (i.i.d), or the size of the\nlocal gradients are bounded. In this paper, we first explicitly characterize\nthe behavior of the FedAvg algorithm, and show that without strong and\nunrealistic assumptions on the problem structure, the algorithm can behave\nerratically for non-convex problems (e.g., diverge to infinity). Aiming at\ndesigning FL algorithms that are provably fast and require as few assumptions\nas possible, we propose a new algorithm design strategy from the primal-dual\noptimization perspective. Our strategy yields a family of algorithms that take\nthe same CTA model as existing algorithms, but they can deal with the\nnon-convex objective, achieve the best possible optimization and communication\ncomplexity while being able to deal with both the full batch and mini-batch\nlocal computation models. Most importantly, the proposed algorithms are {\\it\ncommunication efficient}, in the sense that the communication pattern can be\nadaptive to the level of heterogeneity among the local data. To the best of our\nknowledge, this is the first algorithmic framework for FL that achieves all the\nabove properties.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 23:07:42 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 04:09:08 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 22:04:13 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Zhang", "Xinwei", ""], ["Hong", "Mingyi", ""], ["Dhople", "Sairaj", ""], ["Yin", "Wotao", ""], ["Liu", "Yang", ""]]}, {"id": "2005.11442", "submitter": "Sandeep Tata", "authors": "Abbas Kazerouni and Qi Zhao and Jing Xie and Sandeep Tata and Marc\n  Najork", "title": "Active Learning for Skewed Data Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a sequential active learning problem where, at each round, an agent\nselects a batch of unlabeled data points, queries their labels and updates a\nbinary classifier. While there exists a rich body of work on active learning in\nthis general form, in this paper, we focus on problems with two distinguishing\ncharacteristics: severe class imbalance (skew) and small amounts of initial\ntraining data. Both of these problems occur with surprising frequency in many\nweb applications. For instance, detecting offensive or sensitive content in\nonline communities (pornography, violence, and hate-speech) is receiving\nenormous attention from industry as well as research communities. Such problems\nhave both the characteristics we describe -- a vast majority of content is not\noffensive, so the number of positive examples for such content is orders of\nmagnitude smaller than the negative examples. Furthermore, there is usually\nonly a small amount of initial training data available when building\nmachine-learned models to solve such problems. To address both these issues, we\npropose a hybrid active learning algorithm (HAL) that balances exploiting the\nknowledge available through the currently labeled training examples with\nexploring the large amount of unlabeled data available. Through simulation\nresults, we show that HAL makes significantly better choices for what points to\nlabel when compared to strong baselines like margin-sampling. Classifiers\ntrained on the examples selected for labeling by HAL easily out-perform the\nbaselines on target metrics (like area under the precision-recall curve) given\nthe same budget for labeling examples. We believe HAL offers a simple,\nintuitive, and computationally tractable way to structure active learning for a\nwide range of machine learning applications.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 01:50:19 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Kazerouni", "Abbas", ""], ["Zhao", "Qi", ""], ["Xie", "Jing", ""], ["Tata", "Sandeep", ""], ["Najork", "Marc", ""]]}, {"id": "2005.11450", "submitter": "Alexander Lavin", "authors": "Bijan Haney and Alexander Lavin", "title": "Fine-Grain Few-Shot Vision via Domain Knowledge as Hyperspherical Priors", "comments": null, "journal-ref": "CVPR 2020 Workshop on Fine-Grained Visual Categorization", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prototypical networks have been shown to perform well at few-shot learning\ntasks in computer vision. Yet these networks struggle when classes are very\nsimilar to each other (fine-grain classification) and currently have no way of\ntaking into account prior knowledge (through the use of tabular data). Using a\nspherical latent space to encode prototypes, we can achieve few-shot fine-grain\nclassification by maximally separating the classes while incorporating domain\nknowledge as informative priors. We describe how to construct a hypersphere of\nprototypes that embed a-priori domain information, and demonstrate the\neffectiveness of the approach on challenging benchmark datasets for fine-grain\nclassification, with top results for one-shot classification and 5x speedups in\ntraining time.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 02:10:57 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Haney", "Bijan", ""], ["Lavin", "Alexander", ""]]}, {"id": "2005.11467", "submitter": "Tingting Liang", "authors": "Tingting Liang, Congying Xia, Yuyu Yin, Philip S. Yu", "title": "Joint Training Capsule Network for Cold Start Recommendation", "comments": "Accepted by SIGIR'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel neural network, joint training capsule network\n(JTCN), for the cold start recommendation task. We propose to mimic the\nhigh-level user preference other than the raw interaction history based on the\nside information for the fresh users. Specifically, an attentive capsule layer\nis proposed to aggregate high-level user preference from the low-level\ninteraction history via a dynamic routing-by-agreement mechanism. Moreover,\nJTCN jointly trains the loss for mimicking the user preference and the softmax\nloss for the recommendation together in an end-to-end manner. Experiments on\ntwo publicly available datasets demonstrate the effectiveness of the proposed\nmodel. JTCN improves other state-of-the-art methods at least 7.07% for\nCiteULike and 16.85% for Amazon in terms of Recall@100 in cold start\nrecommendation.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 04:27:38 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Liang", "Tingting", ""], ["Xia", "Congying", ""], ["Yin", "Yuyu", ""], ["Yu", "Philip S.", ""]]}, {"id": "2005.11470", "submitter": "Zhezhang Ding", "authors": "Donghao Xu, Zhezhang Ding, Xu He, Huijing Zhao, Mathieu Moze,\n  Fran\\c{c}ois Aioun, and Franck Guillemard", "title": "Learning from Naturalistic Driving Data for Human-like Autonomous\n  Highway Driving", "comments": "14 pages, 9 figures. Submitted to T.ITS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driving in a human-like manner is important for an autonomous vehicle to be a\nsmart and predictable traffic participant. To achieve this goal, parameters of\nthe motion planning module should be carefully tuned, which needs great effort\nand expert knowledge. In this study, a method of learning cost parameters of a\nmotion planner from naturalistic driving data is proposed. The learning is\nachieved by encouraging the selected trajectory to approximate the human\ndriving trajectory under the same traffic situation. The employed motion\nplanner follows a widely accepted methodology that first samples candidate\ntrajectories in the trajectory space, then select the one with minimal cost as\nthe planned trajectory. Moreover, in addition to traditional factors such as\ncomfort, efficiency and safety, the cost function is proposed to incorporate\nincentive of behavior decision like a human driver, so that both lane change\ndecision and motion planning are coupled into one framework. Two types of lane\nincentive cost -- heuristic and learning based -- are proposed and implemented.\nTo verify the validity of the proposed method, a data set is developed by using\nthe naturalistic trajectory data of human drivers collected on the motorways in\nBeijing, containing samples of lane changes to the left and right lanes, and\ncar followings. Experiments are conducted with respect to both lane change\ndecision and motion planning, and promising results are achieved.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 04:39:39 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Xu", "Donghao", ""], ["Ding", "Zhezhang", ""], ["He", "Xu", ""], ["Zhao", "Huijing", ""], ["Moze", "Mathieu", ""], ["Aioun", "Fran\u00e7ois", ""], ["Guillemard", "Franck", ""]]}, {"id": "2005.11478", "submitter": "Jiahong Wang", "authors": "Yuexin Zhang, Jiahong Wang", "title": "Short-term Load Forecasting Based on Hybrid Strategy Using Warm-start\n  Gradient Tree Boosting", "comments": "14 pages, 9 figures. The following article has been accepted by\n  Journal of Renewable and Sustainable Energy. After it is published, it will\n  be found at https://doi.org/10.1063/5.0015220", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep-learning-based hybrid strategy for short-term load forecasting is\npresented. The strategy proposes a novel tree-based ensemble method Warm-start\nGradient Tree Boosting (WGTB). Current strategies either ensemble submodels of\na single type, which fail to take advantage of the statistical strengths of\ndifferent inference models. Or they simply sum the outputs from completely\ndifferent inference models, which doesn't maximize the potential of ensemble.\nInspired by the bias-variance trade-off, WGTB is proposed and tailored to the\ngreat disparity among different inference models on accuracy, volatility and\nlinearity. The complete strategy integrates four different inference models of\ndifferent capacities. WGTB then ensembles their outputs by a warm-start and a\nhybrid of bagging and boosting, which lowers bias and variance concurrently. It\nis validated on two real datasets from State Grid Corporation of China of\nhourly resolution. The result demonstrates the effectiveness of the proposed\nstrategy that hybridizes the statistical strengths of both low-bias and\nlow-variance inference models.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 05:47:39 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 17:59:31 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Zhang", "Yuexin", ""], ["Wang", "Jiahong", ""]]}, {"id": "2005.11480", "submitter": "Ang Li", "authors": "Ang Li, Yixiao Duan, Huanrui Yang, Yiran Chen, Jianlei Yang", "title": "TIPRDC: Task-Independent Privacy-Respecting Data Crowdsourcing Framework\n  for Deep Learning with Anonymized Intermediate Representations", "comments": null, "journal-ref": null, "doi": "10.1145/3394486.3403125", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning partially benefits from the availability of\nvarious large-scale datasets. These datasets are often crowdsourced from\nindividual users and contain private information like gender, age, etc. The\nemerging privacy concerns from users on data sharing hinder the generation or\nuse of crowdsourcing datasets and lead to hunger of training data for new deep\nlearning applications. One na\\\"{\\i}ve solution is to pre-process the raw data\nto extract features at the user-side, and then only the extracted features will\nbe sent to the data collector. Unfortunately, attackers can still exploit these\nextracted features to train an adversary classifier to infer private\nattributes. Some prior arts leveraged game theory to protect private\nattributes. However, these defenses are designed for known primary learning\ntasks, the extracted features work poorly for unknown learning tasks. To tackle\nthe case where the learning task may be unknown or changing, we present TIPRDC,\na task-independent privacy-respecting data crowdsourcing framework with\nanonymized intermediate representation. The goal of this framework is to learn\na feature extractor that can hide the privacy information from the intermediate\nrepresentations; while maximally retaining the original information embedded in\nthe raw data for the data collector to accomplish unknown learning tasks. We\ndesign a hybrid training method to learn the anonymized intermediate\nrepresentation: (1) an adversarial training process for hiding private\ninformation from features; (2) maximally retain original information using a\nneural-network-based mutual information estimator.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 06:21:26 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 00:42:01 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 19:13:55 GMT"}, {"version": "v4", "created": "Fri, 5 Jun 2020 19:58:01 GMT"}, {"version": "v5", "created": "Fri, 12 Jun 2020 01:23:06 GMT"}, {"version": "v6", "created": "Mon, 24 Aug 2020 13:52:38 GMT"}, {"version": "v7", "created": "Tue, 25 Aug 2020 01:36:06 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Li", "Ang", ""], ["Duan", "Yixiao", ""], ["Yang", "Huanrui", ""], ["Chen", "Yiran", ""], ["Yang", "Jianlei", ""]]}, {"id": "2005.11498", "submitter": "Vaggelis Atlidakis", "authors": "Vaggelis Atlidakis, Roxana Geambasu, Patrice Godefroid, Marina\n  Polishchuk, Baishakhi Ray", "title": "Pythia: Grammar-Based Fuzzing of REST APIs with Coverage-guided Feedback\n  and Learning-based Mutations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Pythia, the first fuzzer that augments grammar-based\nfuzzing with coverage-guided feedback and a learning-based mutation strategy\nfor stateful REST API fuzzing. Pythia uses a statistical model to learn common\nusage patterns of a target REST API from structurally valid seed inputs. It\nthen generates learning-based mutations by injecting a small amount of noise\ndeviating from common usage patterns while still maintaining syntactic\nvalidity. Pythia's mutation strategy helps generate grammatically valid test\ncases and coverage-guided feedback helps prioritize the test cases that are\nmore likely to find bugs. We present experimental evaluation on three\nproduction-scale, open-source cloud services showing that Pythia outperforms\nprior approaches both in code coverage and new bugs found. Using Pythia, we\nfound 29 new bugs which we are in the process of reporting to the respective\nservice owners.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 09:17:41 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Atlidakis", "Vaggelis", ""], ["Geambasu", "Roxana", ""], ["Godefroid", "Patrice", ""], ["Polishchuk", "Marina", ""], ["Ray", "Baishakhi", ""]]}, {"id": "2005.11524", "submitter": "Muhammad E. H. Chowdhury", "authors": "Anas Tahir, Yazan Qiblawey, Amith Khandakar, Tawsifur Rahman, Uzair\n  Khurshid, Farayi Musharavati, M. T. Islam, Serkan Kiranyaz, Muhammad E. H.\n  Chowdhury", "title": "Deep Learning for Reliable Classification of COVID-19, MERS, and SARS\n  from Chest X-Ray Images", "comments": "10 Figures, 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel Coronavirus disease (COVID-19) is an extremely contagious and quickly\nspreading Coronavirus infestation. Severe Acute Respiratory Syndrome (SARS) and\nMiddle East Respiratory Syndrome (MERS), which outbreak in 2002 and 2011, and\nthe current COVID-19 pandemic are all from the same family of coronavirus. This\nwork aims to classify COVID-19, SARS, and MERS chest X-ray (CXR) images using\ndeep Convolutional Neural Networks (CNNs). A unique database was created,\nso-called QU-COVID-family, consisting of 423 COVID-19, 144 MERS, and 134 SARS\nCXR images. Besides, a robust COVID-19 recognition system was proposed to\nidentify lung regions using a CNN segmentation model (U-Net), and then classify\nthe segmented lung images as COVID-19, MERS, or SARS using a pre-trained CNN\nclassifier. Furthermore, the Score-CAM visualization method was utilized to\nvisualize classification output and understand the reasoning behind the\ndecision of deep CNNs. Several Deep Learning classifiers were trained and\ntested; four outperforming algorithms were reported. Original and preprocessed\nimages were used individually and all together as the input(s) to the networks.\nTwo recognition schemes were considered: plain CXR classification and segmented\nCXR classification. For plain CXRs, it was observed that InceptionV3\noutperforms other networks with a 3-channel scheme and achieves sensitivities\nof 99.5%, 93.1%, and 97% for classifying COVID-19, MERS, and SARS images,\nrespectively. In contrast, for segmented CXRs, InceptionV3 outperformed using\nthe original CXR dataset and achieved sensitivities of 96.94%, 79.68%, and\n90.26% for classifying COVID-19, MERS, and SARS images, respectively. All\nnetworks showed high COVID-19 detection sensitivity (>96%) with the segmented\nlung images. This indicates the unique radiographic signature of COVID-19 cases\nin the eyes of AI, which is often a challenging task for medical doctors.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 12:22:28 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 14:34:17 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 11:53:04 GMT"}, {"version": "v4", "created": "Mon, 8 Jun 2020 10:07:55 GMT"}, {"version": "v5", "created": "Thu, 18 Feb 2021 21:34:31 GMT"}, {"version": "v6", "created": "Tue, 1 Jun 2021 12:37:22 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Tahir", "Anas", ""], ["Qiblawey", "Yazan", ""], ["Khandakar", "Amith", ""], ["Rahman", "Tawsifur", ""], ["Khurshid", "Uzair", ""], ["Musharavati", "Farayi", ""], ["Islam", "M. T.", ""], ["Kiranyaz", "Serkan", ""], ["Chowdhury", "Muhammad E. H.", ""]]}, {"id": "2005.11546", "submitter": "Deepak Mittal", "authors": "VSR Veeravasarapu, Abhishek Goel, Deepak Mittal, Maneesh Singh", "title": "ProAlignNet : Unsupervised Learning for Progressively Aligning Noisy\n  Contours", "comments": "Accepted at CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contour shape alignment is a fundamental but challenging problem in computer\nvision, especially when the observations are partial, noisy, and largely\nmisaligned. Recent ConvNet-based architectures that were proposed to align\nimage structures tend to fail with contour representation of shapes, mostly due\nto the use of proximity-insensitive pixel-wise similarity measures as loss\nfunctions in their training processes. This work presents a novel ConvNet,\n\"ProAlignNet\" that accounts for large scale misalignments and complex\ntransformations between the contour shapes. It infers the warp parameters in a\nmulti-scale fashion with progressively increasing complex transformations over\nincreasing scales. It learns --without supervision-- to align contours,\nagnostic to noise and missing parts, by training with a novel loss function\nwhich is derived an upperbound of a proximity-sensitive and local\nshape-dependent similarity metric that uses classical Morphological Chamfer\nDistance Transform. We evaluate the reliability of these proposals on a\nsimulated MNIST noisy contours dataset via some basic sanity check experiments.\nNext, we demonstrate the effectiveness of the proposed models in two real-world\napplications of (i) aligning geo-parcel data to aerial image maps and (ii)\nrefining coarsely annotated segmentation labels. In both applications, the\nproposed models consistently perform superior to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 14:56:14 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Veeravasarapu", "VSR", ""], ["Goel", "Abhishek", ""], ["Mittal", "Deepak", ""], ["Singh", "Maneesh", ""]]}, {"id": "2005.11547", "submitter": "Tobias Christiani", "authors": "Tobias Christiani", "title": "DartMinHash: Fast Sketching for Weighted Sets", "comments": "See https://github.com/tobc/dartminhash for the code accompanying the\n  experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted minwise hashing is a standard dimensionality reduction technique\nwith applications to similarity search and large-scale kernel machines. We\nintroduce a simple algorithm that takes a weighted set $x \\in \\mathbb{R}_{\\geq\n0}^{d}$ and computes $k$ independent minhashes in expected time $O(k \\log k +\n\\Vert x \\Vert_{0}\\log( \\Vert x \\Vert_1 + 1/\\Vert x \\Vert_1))$, improving upon\nthe state-of-the-art BagMinHash algorithm (KDD '18) and representing the\nfastest weighted minhash algorithm for sparse data. Our experiments show\nrunning times that scale better with $k$ and $\\Vert x \\Vert_0$ compared to ICWS\n(ICDM '10) and BagMinhash, obtaining $10$x speedups in common use cases. Our\napproach also gives rise to a technique for computing fully independent\nlocality-sensitive hash values for $(L, K)$-parameterized approximate near\nneighbor search under weighted Jaccard similarity in optimal expected time\n$O(LK + \\Vert x \\Vert_0)$, improving on prior work even in the case of\nunweighted sets.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 14:59:25 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Christiani", "Tobias", ""]]}, {"id": "2005.11552", "submitter": "Long Chen", "authors": "Long Chen, Zhihua Liu, Lei Tong, Zheheng Jiang, Shengke Wang, Junyu\n  Dong, Huiyu Zhou", "title": "Underwater object detection using Invert Multi-Class Adaboost with deep\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning based methods have achieved promising\nperformance in standard object detection. However, these methods lack\nsufficient capabilities to handle underwater object detection due to these\nchallenges: (1) Objects in real applications are usually small and their images\nare blurry, and (2) images in the underwater datasets and real applications\naccompany heterogeneous noise. To address these two problems, we first propose\na novel neural network architecture, namely Sample-WeIghted hyPEr Network\n(SWIPENet), for small object detection. SWIPENet consists of high resolution\nand semantic rich Hyper Feature Maps which can significantly improve small\nobject detection accuracy. In addition, we propose a novel sample-weighted loss\nfunction which can model sample weights for SWIPENet, which uses a novel sample\nre-weighting algorithm, namely Invert Multi-Class Adaboost (IMA), to reduce the\ninfluence of noise on the proposed SWIPENet. Experiments on two underwater\nrobot picking contest datasets URPC2017 and URPC2018 show that the proposed\nSWIPENet+IMA framework achieves better performance in detection accuracy\nagainst several state-of-the-art object detection approaches.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 15:30:38 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Chen", "Long", ""], ["Liu", "Zhihua", ""], ["Tong", "Lei", ""], ["Jiang", "Zheheng", ""], ["Wang", "Shengke", ""], ["Dong", "Junyu", ""], ["Zhou", "Huiyu", ""]]}, {"id": "2005.11558", "submitter": "Vasileios Petridis", "authors": "Vasileios Petridis (Dept. of Electrical and Computer Engineering,\n  Aristotle University, Thessaloniki, Greece)", "title": "Invariant 3D Shape Recognition using Predictive Modular Neural Networks", "comments": "17 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper PREMONN (PREdictive MOdular Neural Networks) model/architecture\nis generalized to functions of two variables and to non-Euclidean spaces. It is\npresented in the context of 3D invariant shape recognition and texture\nrecognition. PREMONN uses local relation, it is modular and exhibits\nincremental learning. The recognition process can start at any point on a shape\nor texture, so a reference point is not needed. Its local relation\ncharacteristic enables it to recognize shape and texture even in presence of\nocclusion. The analysis is mainly mathematical. However, we present some\nexperimental results. The methods presented in this paper can be applied to\nmany problems such as gesture recognition, action recognition, dynamic texture\nrecognition etc.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 16:16:37 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Petridis", "Vasileios", "", "Dept. of Electrical and Computer Engineering,\n  Aristotle University, Thessaloniki, Greece"]]}, {"id": "2005.11560", "submitter": "Haoteng Tang", "authors": "Haoteng Tang, Guixiang Ma, Yurong Chen, Lei Guo, Wei Wang, Bo Zeng,\n  Liang Zhan", "title": "Adversarial Attack on Hierarchical Graph Pooling Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the emergence and development of graph neural\nnetworks (GNNs), which have been shown as a powerful approach for graph\nrepresentation learning in many tasks, such as node classification and graph\nclassification. The research on the robustness of these models has also started\nto attract attentions in the machine learning field. However, most of the\nexisting work in this area focus on the GNNs for node-level tasks, while little\nwork has been done to study the robustness of the GNNs for the graph\nclassification task. In this paper, we aim to explore the vulnerability of the\nHierarchical Graph Pooling (HGP) Neural Networks, which are advanced GNNs that\nperform very well in the graph classification in terms of prediction accuracy.\nWe propose an adversarial attack framework for this task. Specifically, we\ndesign a surrogate model that consists of convolutional and pooling operators\nto generate adversarial samples to fool the hierarchical GNN-based graph\nclassification models. We set the preserved nodes by the pooling operator as\nour attack targets, and then we perturb the attack targets slightly to fool the\npooling operator in hierarchical GNNs so that they will select the wrong nodes\nto preserve. We show the adversarial samples generated from multiple datasets\nby our surrogate model have enough transferability to attack current\nstate-of-art graph classification models. Furthermore, we conduct the robust\ntrain on the target models and demonstrate that the retrained graph\nclassification models are able to better defend against the attack from the\nadversarial samples. To the best of our knowledge, this is the first work on\nthe adversarial attack against hierarchical GNN-based graph classification\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 16:19:47 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Tang", "Haoteng", ""], ["Ma", "Guixiang", ""], ["Chen", "Yurong", ""], ["Guo", "Lei", ""], ["Wang", "Wei", ""], ["Zeng", "Bo", ""], ["Zhan", "Liang", ""]]}, {"id": "2005.11577", "submitter": "Nikesh Bajaj", "authors": "Nikesh Bajaj, Jes\\'us Requena Carri\\'on, Francesco Bellotti", "title": "PhyAAt: Physiology of Auditory Attention to Speech Dataset", "comments": "11 pages, 7 figures, For dataset and supporting resources, please see\n  https://phyaat.github.io", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Auditory attention to natural speech is a complex brain process. Its\nquantification from physiological signals can be valuable to improving and\nwidening the range of applications of current brain-computer-interface systems,\nhowever it remains a challenging task. In this article, we present a dataset of\nphysiological signals collected from an experiment on auditory attention to\nnatural speech. In this experiment, auditory stimuli consisting of\nreproductions of English sentences in different auditory conditions were\npresented to 25 non-native participants, who were asked to transcribe the\nsentences. During the experiment, 14 channel electroencephalogram, galvanic\nskin response, and photoplethysmogram signals were collected from each\nparticipant. Based on the number of correctly transcribed words, an attention\nscore was obtained for each auditory stimulus presented to subjects. A strong\ncorrelation ($p<<0.0001$) between the attention score and the auditory\nconditions was found. We also formulate four different predictive tasks\ninvolving the collected dataset and develop a feature extraction framework. The\nresults for each predictive task are obtained using a Support Vector Machine\nwith spectral features, and are better than chance level. The dataset has been\nmade publicly available for further research, along with a python library -\nphyaat to facilitate the preprocessing, modeling, and reproduction of the\nresults presented in this paper. The dataset and other resources are shared on\nwebpage - https://phyaat.github.io.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 17:55:18 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Bajaj", "Nikesh", ""], ["Carri\u00f3n", "Jes\u00fas Requena", ""], ["Bellotti", "Francesco", ""]]}, {"id": "2005.11593", "submitter": "Andrea Tirinzoni", "authors": "Andrea Tirinzoni, Alessandro Lazaric, Marcello Restelli", "title": "A Novel Confidence-Based Algorithm for Structured Bandits", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study finite-armed stochastic bandits where the rewards of each arm might\nbe correlated to those of other arms. We introduce a novel phased algorithm\nthat exploits the given structure to build confidence sets over the parameters\nof the true bandit problem and rapidly discard all sub-optimal arms. In\nparticular, unlike standard bandit algorithms with no structure, we show that\nthe number of times a suboptimal arm is selected may actually be reduced thanks\nto the information collected by pulling other arms. Furthermore, we show that,\nin some structures, the regret of an anytime extension of our algorithm is\nuniformly bounded over time. For these constant-regret structures, we also\nderive a matching lower bound. Finally, we demonstrate numerically that our\napproach better exploits certain structures than existing methods.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 19:52:44 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Tirinzoni", "Andrea", ""], ["Lazaric", "Alessandro", ""], ["Restelli", "Marcello", ""]]}, {"id": "2005.11599", "submitter": "Wennan Chang", "authors": "Wennan Chang, Xinyu Zhou, Yong Zang, Chi Zhang, Sha Cao", "title": "Component-wise Adaptive Trimming For Robust Mixture Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Parameter estimation of mixture regression model using the expectation\nmaximization (EM) algorithm is highly sensitive to outliers. Here we propose a\nfast and efficient robust mixture regression algorithm, called Component-wise\nAdaptive Trimming (CAT) method. We consider simultaneous outlier detection and\nrobust parameter estimation to minimize the effect of outlier contamination.\nRobust mixture regression has many important applications including in human\ncancer genomics data, where the population often displays strong heterogeneity\nadded by unwanted technological perturbations. Existing robust mixture\nregression methods suffer from outliers as they either conduct parameter\nestimation in the presence of outliers, or rely on prior knowledge of the level\nof outlier contamination. CAT was implemented in the framework of\nclassification expectation maximization, under which a natural definition of\noutliers could be derived. It implements a least trimmed squares (LTS) approach\nwithin each exclusive mixing component, where the robustness issue could be\ntransformed from the mixture case to simple linear regression case. The high\nbreakdown point of the LTS approach allows us to avoid the pre-specification of\ntrimming parameter. Compared with multiple existing algorithms, CAT is the most\ncompetitive one that can handle and adaptively trim off outliers as well as\nheavy tailed noise, in different scenarios of simulated data and real genomic\ndata. CAT has been implemented in an R package `RobMixReg' available in CRAN.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 20:59:16 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 05:02:57 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 15:54:18 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Chang", "Wennan", ""], ["Zhou", "Xinyu", ""], ["Zang", "Yong", ""], ["Zhang", "Chi", ""], ["Cao", "Sha", ""]]}, {"id": "2005.11603", "submitter": "Guruprasad Raghavan", "authors": "Guruprasad Raghavan, Jiayi Li, Matt Thomson", "title": "Geometric algorithms for predicting resilience and recovering damage in\n  neural networks", "comments": "10 pages and 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Biological neural networks have evolved to maintain performance despite\nsignificant circuit damage. To survive damage, biological network architectures\nhave both intrinsic resilience to component loss and also activate recovery\nprograms that adjust network weights through plasticity to stabilize\nperformance. Despite the importance of resilience in technology applications,\nthe resilience of artificial neural networks is poorly understood, and\nautonomous recovery algorithms have yet to be developed. In this paper, we\nestablish a mathematical framework to analyze the resilience of artificial\nneural networks through the lens of differential geometry. Our geometric\nlanguage provides natural algorithms that identify local vulnerabilities in\ntrained networks as well as recovery algorithms that dynamically adjust\nnetworks to compensate for damage. We reveal striking vulnerabilities in\ncommonly used image analysis networks, like MLP's and CNN's trained on MNIST\nand CIFAR10 respectively. We also uncover high-performance recovery paths that\nenable the same networks to dynamically re-adjust their parameters to\ncompensate for damage. Broadly, our work provides procedures that endow\nartificial systems with resilience and rapid-recovery routines to enhance their\nintegration with IoT devices as well as enable their deployment for critical\napplications.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 21:13:26 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 19:20:49 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Raghavan", "Guruprasad", ""], ["Li", "Jiayi", ""], ["Thomson", "Matt", ""]]}, {"id": "2005.11608", "submitter": "Sheriffo Ceesay", "authors": "Sheriffo Ceesay, Adam Barker, Yuhui Lin", "title": "Benchmarking and Performance Modelling of MapReduce Communication\n  Pattern", "comments": "8 pages, 10 figures", "journal-ref": "2019 IEEE International Conference on Cloud Computing Technology\n  and Science (CloudCom)", "doi": "10.1109/CloudCom.2019.00029", "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and predicting the performance of big data applications running\nin the cloud or on-premises could help minimise the overall cost of operations\nand provide opportunities in efforts to identify performance bottlenecks. The\ncomplexity of the low-level internals of big data frameworks and the ubiquity\nof application and workload configuration parameters makes it challenging and\nexpensive to come up with comprehensive performance modelling solutions.\n  In this paper, instead of focusing on a wide range of configurable\nparameters, we studied the low-level internals of the MapReduce communication\npattern and used a minimal set of performance drivers to develop a set of phase\nlevel parametric models for approximating the execution time of a given\napplication on a given cluster. Models can be used to infer the performance of\nunseen applications and approximate their performance when an arbitrary dataset\nis used as input. Our approach is validated by running empirical experiments in\ntwo setups. On average the error rate in both setups is plus or minus 10% from\nthe measured values.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 21:52:29 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Ceesay", "Sheriffo", ""], ["Barker", "Adam", ""], ["Lin", "Yuhui", ""]]}, {"id": "2005.11619", "submitter": "Himanshu Sharma", "authors": "Himanshu Sharma and Elise Jennings", "title": "Bayesian Neural Networks at Scale: A Performance Analysis and Pruning\n  Study", "comments": null, "journal-ref": "Journal of Super Computing (2020)", "doi": "10.1007/s11227-020-03401-z", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural Networks (BNNs) are a promising method of obtaining\nstatistical uncertainties for neural network predictions but with a higher\ncomputational overhead which can limit their practical usage. This work\nexplores the use of high performance computing with distributed training to\naddress the challenges of training BNNs at scale. We present a performance and\nscalability comparison of training the VGG-16 and Resnet-18 models on a\nCray-XC40 cluster. We demonstrate that network pruning can speed up inference\nwithout accuracy loss and provide an open source software package,\n{\\it{BPrune}} to automate this pruning. For certain models we find that pruning\nup to 80\\% of the network results in only a 7.0\\% loss in accuracy. With the\ndevelopment of new hardware accelerators for Deep Learning, BNNs are of\nconsiderable interest for benchmarking performance. This analysis of training a\nBNN at scale outlines the limitations and benefits compared to a conventional\nneural network.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 23:15:34 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 23:18:54 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Sharma", "Himanshu", ""], ["Jennings", "Elise", ""]]}, {"id": "2005.11622", "submitter": "Norman Tatro", "authors": "N. Joseph Tatro, Stefan C. Schonsheck, Rongjie Lai", "title": "Unsupervised Geometric Disentanglement for Surfaces via CFAN-VAE", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric disentanglement, the separation of latent codes for intrinsic (i.e.\nidentity) and extrinsic(i.e. pose) geometry, is a prominent task for generative\nmodels of non-Euclidean data such as 3D deformable models. It provides greater\ninterpretability of the latent space, and leads to more control in generation.\nThis work introduces a mesh feature, the conformal factor and normal feature\n(CFAN),for use in mesh convolutional autoencoders. We further propose CFAN-VAE,\na novel architecture that disentangles identity and pose using the CFAN\nfeature. Requiring no label information on the identity or pose during\ntraining, CFAN-VAE achieves geometric disentanglement in an unsupervisedway.\nOur comprehensive experiments, including reconstruction, interpolation,\ngeneration, and identity/pose transfer, demonstrate CFAN-VAE achieves\nstate-of-the-art performance on unsupervised geometric disentanglement. We also\nsuccessfully detect a level of geometric disentanglement in mesh convolutional\nautoencoders that encode xyz-coordinates directly by registering its latent\nspace to that of CFAN-VAE.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 23:28:10 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 01:50:38 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Tatro", "N. Joseph", ""], ["Schonsheck", "Stefan C.", ""], ["Lai", "Rongjie", ""]]}, {"id": "2005.11626", "submitter": "Xinchen Yan", "authors": "Kibok Lee, Zhuoyuan Chen, Xinchen Yan, Raquel Urtasun, Ersin Yumer", "title": "ShapeAdv: Generating Shape-Aware Adversarial 3D Point Clouds", "comments": "3D Point Clouds, Adversarial Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce ShapeAdv, a novel framework to study shape-aware adversarial\nperturbations that reflect the underlying shape variations (e.g., geometric\ndeformations and structural differences) in the 3D point cloud space. We\ndevelop shape-aware adversarial 3D point cloud attacks by leveraging the\nlearned latent space of a point cloud auto-encoder where the adversarial noise\nis applied in the latent space. Specifically, we propose three different\nvariants including an exemplar-based one by guiding the shape deformation with\nauxiliary data, such that the generated point cloud resembles the shape\nmorphing between objects in the same category. Different from prior works, the\nresulting adversarial 3D point clouds reflect the shape variations in the 3D\npoint cloud space while still being close to the original one. In addition,\nexperimental evaluations on the ModelNet40 benchmark demonstrate that our\nadversaries are more difficult to defend with existing point cloud defense\nmethods and exhibit a higher attack transferability across classifiers. Our\nshape-aware adversarial attacks are orthogonal to existing point cloud based\nattacks and shed light on the vulnerability of 3D deep neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 00:03:27 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Lee", "Kibok", ""], ["Chen", "Zhuoyuan", ""], ["Yan", "Xinchen", ""], ["Urtasun", "Raquel", ""], ["Yumer", "Ersin", ""]]}, {"id": "2005.11627", "submitter": "Zhiyong Cui", "authors": "Zhiyong Cui, Ruimin Ke, Ziyuan Pu, Yinhai Wang", "title": "Stacked Bidirectional and Unidirectional LSTM Recurrent Neural Network\n  for Forecasting Network-wide Traffic State with Missing Values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-term traffic forecasting based on deep learning methods, especially\nrecurrent neural networks (RNN), has received much attention in recent years.\nHowever, the potential of RNN-based models in traffic forecasting has not yet\nbeen fully exploited in terms of the predictive power of spatial-temporal data\nand the capability of handling missing data. In this paper, we focus on\nRNN-based models and attempt to reformulate the way to incorporate RNN and its\nvariants into traffic prediction models. A stacked bidirectional and\nunidirectional LSTM network architecture (SBU-LSTM) is proposed to assist the\ndesign of neural network structures for traffic state forecasting. As a key\ncomponent of the architecture, the bidirectional LSTM (BDLSM) is exploited to\ncapture the forward and backward temporal dependencies in spatiotemporal data.\nTo deal with missing values in spatial-temporal data, we also propose a data\nimputation mechanism in the LSTM structure (LSTM-I) by designing an imputation\nunit to infer missing values and assist traffic prediction. The bidirectional\nversion of LSTM-I is incorporated in the SBU-LSTM architecture. Two real-world\nnetwork-wide traffic state datasets are used to conduct experiments and\npublished to facilitate further traffic prediction research. The prediction\nperformance of multiple types of multi-layer LSTM or BDLSTM models is\nevaluated. Experimental results indicate that the proposed SBU-LSTM\narchitecture, especially the two-layer BDLSTM network, can achieve superior\nperformance for the network-wide traffic prediction in both accuracy and\nrobustness. Further, comprehensive comparison results show that the proposed\ndata imputation mechanism in the RNN-based models can achieve outstanding\nprediction performance when the model's input data contains different patterns\nof missing values.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 00:17:15 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Cui", "Zhiyong", ""], ["Ke", "Ruimin", ""], ["Pu", "Ziyuan", ""], ["Wang", "Yinhai", ""]]}, {"id": "2005.11630", "submitter": "Ang Li", "authors": "Ang Li, Chunpeng Wu, Yiran Chen, Bin Ni", "title": "MVStylizer: An Efficient Edge-Assisted Video Photorealistic Style\n  Transfer System for Mobile Phones", "comments": null, "journal-ref": null, "doi": "10.1145/3397166.3409140", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has made great progress in realizing neural style transfer of\nimages, which denotes transforming an image to a desired style. Many users\nstart to use their mobile phones to record their daily life, and then edit and\nshare the captured images and videos with other users. However, directly\napplying existing style transfer approaches on videos, i.e., transferring the\nstyle of a video frame by frame, requires an extremely large amount of\ncomputation resources. It is still technically unaffordable to perform style\ntransfer of videos on mobile phones. To address this challenge, we propose\nMVStylizer, an efficient edge-assisted photorealistic video style transfer\nsystem for mobile phones. Instead of performing stylization frame by frame,\nonly key frames in the original video are processed by a pre-trained deep\nneural network (DNN) on edge servers, while the rest of stylized intermediate\nframes are generated by our designed optical-flow-based frame interpolation\nalgorithm on mobile phones. A meta-smoothing module is also proposed to\nsimultaneously upscale a stylized frame to arbitrary resolution and remove\nstyle transfer related distortions in these upscaled frames. In addition, for\nthe sake of continuously enhancing the performance of the DNN model on the edge\nserver, we adopt a federated learning scheme to keep retraining each DNN model\non the edge server with collected data from mobile clients and syncing with a\nglobal DNN model on the cloud server. Such a scheme effectively leverages the\ndiversity of collected data from various mobile clients and efficiently\nimproves the system performance. Our experiments demonstrate that MVStylizer\ncan generate stylized videos with an even better visual quality compared to the\nstate-of-the-art method while achieving 75.5$\\times$ speedup for\n1920$\\times$1080 videos.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 00:54:27 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 19:16:08 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Li", "Ang", ""], ["Wu", "Chunpeng", ""], ["Chen", "Yiran", ""], ["Ni", "Bin", ""]]}, {"id": "2005.11633", "submitter": "Bojian Yin", "authors": "Bojian Yin, Federico Corradi, Sander M. Boht\\'e", "title": "Effective and Efficient Computation with Multiple-timescale Spiking\n  Recurrent Neural Networks", "comments": "11 pages,5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of brain-inspired neuromorphic computing as a paradigm for edge\nAI is motivating the search for high-performance and efficient spiking neural\nnetworks to run on this hardware. However, compared to classical neural\nnetworks in deep learning, current spiking neural networks lack competitive\nperformance in compelling areas. Here, for sequential and streaming tasks, we\ndemonstrate how a novel type of adaptive spiking recurrent neural network\n(SRNN) is able to achieve state-of-the-art performance compared to other\nspiking neural networks and almost reach or exceed the performance of classical\nrecurrent neural networks (RNNs) while exhibiting sparse activity. From this,\nwe calculate a $>$100x energy improvement for our SRNNs over classical RNNs on\nthe harder tasks. To achieve this, we model standard and adaptive\nmultiple-timescale spiking neurons as self-recurrent neural units, and leverage\nsurrogate gradients and auto-differentiation in the PyTorch Deep Learning\nframework to efficiently implement backpropagation-through-time, including\nlearning of the important spiking neuron parameters to adapt our spiking\nneurons to the tasks.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 01:04:53 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 14:12:49 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Yin", "Bojian", ""], ["Corradi", "Federico", ""], ["Boht\u00e9", "Sander M.", ""]]}, {"id": "2005.11638", "submitter": "Guofu Li", "authors": "Jinchao Huang, Guofu Li, Zhicong Yan, Fucai Luo, Shenghong Li", "title": "Joint learning of interpretation and distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extra trust brought by the model interpretation has made it an\nindispensable part of machine learning systems. But to explain a distilled\nmodel's prediction, one may either work with the student model itself, or turn\nto its teacher model. This leads to a more fundamental question: if a distilled\nmodel should give a similar prediction for a similar reason as its teacher\nmodel on the same input? This question becomes even more crucial when the two\nmodels have dramatically different structure, taking GBDT2NN for example. This\npaper conducts an empirical study on the new approach to explaining each\nprediction of GBDT2NN, and how imitating the explanation can further improve\nthe distillation process as an auxiliary learning task. Experiments on several\nbenchmarks show that the proposed methods achieve better performance on both\nexplanations and predictions.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 02:01:22 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Huang", "Jinchao", ""], ["Li", "Guofu", ""], ["Yan", "Zhicong", ""], ["Luo", "Fucai", ""], ["Li", "Shenghong", ""]]}, {"id": "2005.11640", "submitter": "Su Zhu", "authors": "Chen Liu, Su Zhu, Zijian Zhao, Ruisheng Cao, Lu Chen and Kai Yu", "title": "Jointly Encoding Word Confusion Network and Dialogue Context with BERT\n  for Spoken Language Understanding", "comments": "Accepted to INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken Language Understanding (SLU) converts hypotheses from automatic speech\nrecognizer (ASR) into structured semantic representations. ASR recognition\nerrors can severely degenerate the performance of the subsequent SLU module. To\naddress this issue, word confusion networks (WCNs) have been used to encode the\ninput for SLU, which contain richer information than 1-best or n-best\nhypotheses list. To further eliminate ambiguity, the last system act of\ndialogue context is also utilized as additional input. In this paper, a novel\nBERT based SLU model (WCN-BERT SLU) is proposed to encode WCNs and the dialogue\ncontext jointly. It can integrate both structural information and ASR posterior\nprobabilities of WCNs in the BERT architecture. Experiments on DSTC2, a\nbenchmark of SLU, show that the proposed method is effective and can outperform\nprevious state-of-the-art models significantly.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 02:26:13 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 13:24:06 GMT"}, {"version": "v3", "created": "Tue, 8 Sep 2020 02:45:43 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Liu", "Chen", ""], ["Zhu", "Su", ""], ["Zhao", "Zijian", ""], ["Cao", "Ruisheng", ""], ["Chen", "Lu", ""], ["Yu", "Kai", ""]]}, {"id": "2005.11650", "submitter": "Zonghan Wu", "authors": "Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, Xiaojun Chang,\n  Chengqi Zhang", "title": "Connecting the Dots: Multivariate Time Series Forecasting with Graph\n  Neural Networks", "comments": "Accepted by KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling multivariate time series has long been a subject that has attracted\nresearchers from a diverse range of fields including economics, finance, and\ntraffic. A basic assumption behind multivariate time series forecasting is that\nits variables depend on one another but, upon looking closely, it is fair to\nsay that existing methods fail to fully exploit latent spatial dependencies\nbetween pairs of variables. In recent years, meanwhile, graph neural networks\n(GNNs) have shown high capability in handling relational dependencies. GNNs\nrequire well-defined graph structures for information propagation which means\nthey cannot be applied directly for multivariate time series where the\ndependencies are not known in advance. In this paper, we propose a general\ngraph neural network framework designed specifically for multivariate time\nseries data. Our approach automatically extracts the uni-directed relations\namong variables through a graph learning module, into which external knowledge\nlike variable attributes can be easily integrated. A novel mix-hop propagation\nlayer and a dilated inception layer are further proposed to capture the spatial\nand temporal dependencies within the time series. The graph learning, graph\nconvolution, and temporal convolution modules are jointly learned in an\nend-to-end framework. Experimental results show that our proposed model\noutperforms the state-of-the-art baseline methods on 3 of 4 benchmark datasets\nand achieves on-par performance with other approaches on two traffic datasets\nwhich provide extra structural information.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 04:02:18 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Wu", "Zonghan", ""], ["Pan", "Shirui", ""], ["Long", "Guodong", ""], ["Jiang", "Jing", ""], ["Chang", "Xiaojun", ""], ["Zhang", "Chengqi", ""]]}, {"id": "2005.11651", "submitter": "Antonious Girgis Mamdouh", "authors": "Antonious M. Girgis, Deepesh Data, Kamalika Chaudhuri, Christina\n  Fragouli, and Suhas Diggavi", "title": "Successive Refinement of Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work examines a novel question: how much randomness is needed to achieve\nlocal differential privacy (LDP)? A motivating scenario is providing {\\em\nmultiple levels of privacy} to multiple analysts, either for distribution or\nfor heavy-hitter estimation, using the \\emph{same} (randomized) output. We call\nthis setting \\emph{successive refinement of privacy}, as it provides\nhierarchical access to the raw data with different privacy levels. For example,\nthe same randomized output could enable one analyst to reconstruct the input,\nwhile another can only estimate the distribution subject to LDP requirements.\nThis extends the classical Shannon (wiretap) security setting to local\ndifferential privacy. We provide (order-wise) tight characterizations of\nprivacy-utility-randomness trade-offs in several cases for distribution\nestimation, including the standard LDP setting under a randomness constraint.\nWe also provide a non-trivial privacy mechanism for multi-level privacy.\nFurthermore, we show that we cannot reuse random keys over time while\npreserving privacy of each user.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 04:16:01 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Girgis", "Antonious M.", ""], ["Data", "Deepesh", ""], ["Chaudhuri", "Kamalika", ""], ["Fragouli", "Christina", ""], ["Diggavi", "Suhas", ""]]}, {"id": "2005.11653", "submitter": "Fan Zhou", "authors": "Fan Zhou, Changjian Shui, Bincheng Huang, Boyu Wang and Brahim\n  Chaib-draa", "title": "Discriminative Active Learning for Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain Adaptation aiming to learn a transferable feature between different\nbut related domains has been well investigated and has shown excellent\nempirical performances. Previous works mainly focused on matching the marginal\nfeature distributions using the adversarial training methods while assuming the\nconditional relations between the source and target domain remained unchanged,\n$i.e.$, ignoring the conditional shift problem. However, recent works have\nshown that such a conditional shift problem exists and can hinder the\nadaptation process. To address this issue, we have to leverage labelled data\nfrom the target domain, but collecting labelled data can be quite expensive and\ntime-consuming. To this end, we introduce a discriminative active learning\napproach for domain adaptation to reduce the efforts of data annotation.\nSpecifically, we propose three-stage active adversarial training of neural\nnetworks: invariant feature space learning (first stage), uncertainty and\ndiversity criteria and their trade-off for query strategy (second stage) and\nre-training with queried target labels (third stage). Empirical comparisons\nwith existing domain adaptation methods using four benchmark datasets\ndemonstrate the effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 04:20:49 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Zhou", "Fan", ""], ["Shui", "Changjian", ""], ["Huang", "Bincheng", ""], ["Wang", "Boyu", ""], ["Chaib-draa", "Brahim", ""]]}, {"id": "2005.11665", "submitter": "Xiuyu Wu", "authors": "Xiuyu Wu, Nan Jiang and Yunfang Wu", "title": "A Question Type Driven and Copy Loss Enhanced Frameworkfor\n  Answer-Agnostic Neural Question Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The answer-agnostic question generation is a significant and challenging\ntask, which aims to automatically generate questions for a given sentence but\nwithout an answer. In this paper, we propose two new strategies to deal with\nthis task: question type prediction and copy loss mechanism. The question type\nmodule is to predict the types of questions that should be asked, which allows\nour model to generate multiple types of questions for the same source sentence.\nThe new copy loss enhances the original copy mechanism to make sure that every\nimportant word in the source sentence has been copied when generating\nquestions. Our integrated model outperforms the state-of-the-art approach in\nanswer-agnostic question generation, achieving a BLEU-4 score of 13.9 on SQuAD.\nHuman evaluation further validates the high quality of our generated questions.\nWe will make our code public available for further research.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 07:09:04 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Wu", "Xiuyu", ""], ["Jiang", "Nan", ""], ["Wu", "Yunfang", ""]]}, {"id": "2005.11670", "submitter": "Cristina Palmero", "authors": "Cristina Palmero, Oleg V. Komogortsev, Sachin S. Talathi", "title": "Benefits of temporal information for appearance-based gaze estimation", "comments": "In ACM Symposium on Eye Tracking Research & Applications (ETRA), 2020", "journal-ref": null, "doi": "10.1145/3379156.3391376", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art appearance-based gaze estimation methods, usually based on\ndeep learning techniques, mainly rely on static features. However, temporal\ntrace of eye gaze contains useful information for estimating a given gaze\npoint. For example, approaches leveraging sequential eye gaze information when\napplied to remote or low-resolution image scenarios with off-the-shelf cameras\nare showing promising results. The magnitude of contribution from temporal gaze\ntrace is yet unclear for higher resolution/frame rate imaging systems, in which\nmore detailed information about an eye is captured. In this paper, we\ninvestigate whether temporal sequences of eye images, captured using a\nhigh-resolution, high-frame rate head-mounted virtual reality system, can be\nleveraged to enhance the accuracy of an end-to-end appearance-based\ndeep-learning model for gaze estimation. Performance is compared against a\nstatic-only version of the model. Results demonstrate statistically-significant\nbenefits of temporal information, particularly for the vertical component of\ngaze.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 07:19:53 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Palmero", "Cristina", ""], ["Komogortsev", "Oleg V.", ""], ["Talathi", "Sachin S.", ""]]}, {"id": "2005.11671", "submitter": "Deqiang Li", "authors": "Deqiang Li, Qianmu Li, Yanfang Ye and Shouhuai Xu", "title": "SoK: Arms Race in Adversarial Malware Detection", "comments": "19 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malicious software (malware) is a major cyber threat that shall be tackled\nwith Machine Learning (ML) techniques because millions of new malware examples\nare injected into cyberspace on a daily basis. However, ML is known to be\nvulnerable to attacks known as adversarial examples. In this SoK paper, we\nsystematize the field of Adversarial Malware Detection (AMD) through the lens\nof a unified framework of assumptions, attacks, defenses and security\nproperties. This not only guides us to map attacks and defenses into some\npartial order structures, but also allows us to clearly describe the\nattack-defense arms race in the AMD context. In addition to manually drawing\ninsights, we also propose using ML to draw insights from the systematized\nrepresentation of the literature. Examples of the insights are: knowing the\ndefender's feature set is critical to the attacker's success; attack tactic (as\na core part of the threat model) largely determines what security property of a\nmalware detector can be broke; there is currently no silver bullet defense\nagainst evasion attacks or poisoning attacks; defense tactic largely determines\nwhat security properties can be achieved by a malware detector; knowing\nattacker's manipulation set is critical to defender's success; ML is an\neffective method for insights learning in SoK studies. These insights shed\nlight on future research directions.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 07:20:42 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 13:36:28 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Li", "Deqiang", ""], ["Li", "Qianmu", ""], ["Ye", "Yanfang", ""], ["Xu", "Shouhuai", ""]]}, {"id": "2005.11676", "submitter": "Andros Tjandra", "authors": "Andros Tjandra, Sakriani Sakti, Satoshi Nakamura", "title": "Transformer VQ-VAE for Unsupervised Unit Discovery and Speech Synthesis:\n  ZeroSpeech 2020 Challenge", "comments": "Submitted to INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we report our submitted system for the ZeroSpeech 2020\nchallenge on Track 2019. The main theme in this challenge is to build a speech\nsynthesizer without any textual information or phonetic labels. In order to\ntackle those challenges, we build a system that must address two major\ncomponents such as 1) given speech audio, extract subword units in an\nunsupervised way and 2) re-synthesize the audio from novel speakers. The system\nalso needs to balance the codebook performance between the ABX error rate and\nthe bitrate compression rate. Our main contribution here is we proposed\nTransformer-based VQ-VAE for unsupervised unit discovery and Transformer-based\ninverter for the speech synthesis given the extracted codebook. Additionally,\nwe also explored several regularization methods to improve performance even\nfurther.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 07:42:43 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Tjandra", "Andros", ""], ["Sakti", "Sakriani", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "2005.11679", "submitter": "Chichun Zhou", "authors": "Yang Liu, Hai-Long Tu, Chi-Chun Zhou, Yi Liua and Fu-Lin Zhang", "title": "Networks with pixels embedding: a method to improve noise resistance in\n  images classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the task of images classification, usually, the network is sensitive to\nnoises. For example, an image of cat with noises might be misclassified as an\nostrich. Conventionally, to overcome the problem of noises, one uses the\ntechnique of data enhancement, that is, to teach the network to distinguish\nnoises by adding more images with noises in the training dataset. In this work,\nwe provide a noise-resistance network in images classification by introducing a\ntechnique of pixels embedding. We test the network with pixels embedding, which\nis abbreviated as the network with PE, on the mnist database of handwritten\ndigits. It shows that the network with PE outperforms the conventional network\non images with noises. The technique of pixels embedding can be used in many\ntasks of images classification to improve noise resistance.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 07:55:08 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 09:02:01 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Liu", "Yang", ""], ["Tu", "Hai-Long", ""], ["Zhou", "Chi-Chun", ""], ["Liua", "Yi", ""], ["Zhang", "Fu-Lin", ""]]}, {"id": "2005.11687", "submitter": "Nikola Milo\\v{s}evi\\'c Dr", "authors": "Nikola Milosevic, Gangamma Kalappa, Hesam Dadafarin, Mahmoud Azimaee,\n  Goran Nenadic", "title": "MASK: A flexible framework to facilitate de-identification of clinical\n  texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Medical health records and clinical summaries contain a vast amount of\nimportant information in textual form that can help advancing research on\ntreatments, drugs and public health. However, the majority of these information\nis not shared because they contain private information about patients, their\nfamilies, or medical staff treating them. Regulations such as HIPPA in the US,\nPHIPPA in Canada and GDPR regulate the protection, processing and distribution\nof this information. In case this information is de-identified and personal\ninformation are replaced or redacted, they could be distributed to the research\ncommunity. In this paper, we present MASK, a software package that is designed\nto perform the de-identification task. The software is able to perform named\nentity recognition using some of the state-of-the-art techniques and then mask\nor redact recognized entities. The user is able to select named entity\nrecognition algorithm (currently implemented are two versions of CRF-based\ntechniques and BiLSTM-based neural network with pre-trained GLoVe and ELMo\nembedding) and masking algorithm (e.g. shift dates, replace names/locations,\ntotally redact entity).\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 08:53:00 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 20:09:00 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Milosevic", "Nikola", ""], ["Kalappa", "Gangamma", ""], ["Dadafarin", "Hesam", ""], ["Azimaee", "Mahmoud", ""], ["Nenadic", "Goran", ""]]}, {"id": "2005.11691", "submitter": "Jiexia Ye", "authors": "Jiexia Ye, Juanjuan Zhao, Kejiang Ye, Chengzhong Xu", "title": "How to Build a Graph-Based Deep Learning Architecture in Traffic Domain:\n  A Survey", "comments": "21pages, 11figures", "journal-ref": "IEEE Transactions on Intelligent Transportation Systems 2020", "doi": "10.1109/TITS.2020.3043250", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, various deep learning architectures have been proposed to\nsolve complex challenges (e.g. spatial dependency, temporal dependency) in\ntraffic domain, which have achieved satisfactory performance. These\narchitectures are composed of multiple deep learning techniques in order to\ntackle various challenges in traffic tasks. Traditionally, convolution neural\nnetworks (CNNs) are utilized to model spatial dependency by decomposing the\ntraffic network as grids. However, many traffic networks are graph-structured\nin nature. In order to utilize such spatial information fully, it's more\nappropriate to formulate traffic networks as graphs mathematically. Recently,\nvarious novel deep learning techniques have been developed to process graph\ndata, called graph neural networks (GNNs). More and more works combine GNNs\nwith other deep learning techniques to construct an architecture dealing with\nvarious challenges in a complex traffic task, where GNNs are responsible for\nextracting spatial correlations in traffic network. These graph-based\narchitectures have achieved state-of-the-art performance. To provide a\ncomprehensive and clear picture of such emerging trend, this survey carefully\nexamines various graph-based deep learning architectures in many traffic\napplications. We first give guidelines to formulate a traffic problem based on\ngraph and construct graphs from various kinds of traffic datasets. Then we\ndecompose these graph-based architectures to discuss their shared deep learning\ntechniques, clarifying the utilization of each technique in traffic tasks.\nWhat's more, we summarize some common traffic challenges and the corresponding\ngraph-based deep learning solutions to each challenge. Finally, we provide\nbenchmark datasets, open source codes and future research directions in this\nrapidly growing field.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 09:07:55 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 02:54:58 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 01:36:37 GMT"}, {"version": "v4", "created": "Thu, 4 Jun 2020 07:10:30 GMT"}, {"version": "v5", "created": "Sun, 7 Jun 2020 07:24:56 GMT"}, {"version": "v6", "created": "Sun, 11 Oct 2020 03:26:00 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Ye", "Jiexia", ""], ["Zhao", "Juanjuan", ""], ["Ye", "Kejiang", ""], ["Xu", "Chengzhong", ""]]}, {"id": "2005.11715", "submitter": "Neslihan Bayramoglu", "authors": "Neslihan Bayramoglu, Miika T. Nieminen and Simo Saarakkala", "title": "A Lightweight CNN and Joint Shape-Joint Space (JS2) Descriptor for\n  Radiological Osteoarthritis Detection", "comments": "MIUA2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knee osteoarthritis (OA) is very common progressive and degenerative\nmusculoskeletal disease worldwide creates a heavy burden on patients with\nreduced quality of life and also on society due to financial impact. Therefore,\nany attempt to reduce the burden of the disease could help both patients and\nsociety. In this study, we propose a fully automated novel method, based on\ncombination of joint shape and convolutional neural network (CNN) based bone\ntexture features, to distinguish between the knee radiographs with and without\nradiographic osteoarthritis. Moreover, we report the first attempt at\ndescribing the bone texture using CNN. Knee radiographs from Osteoarthritis\nInitiative (OAI) and Multicenter Osteoarthritis (MOST) studies were used in the\nexperiments. Our models were trained on 8953 knee radiographs from OAI and\nevaluated on 3445 knee radiographs from MOST. Our results demonstrate that\nfusing the proposed shape and texture parameters achieves the state-of-the art\nperformance in radiographic OA detection yielding area under the ROC curve\n(AUC) of 95.21%\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 10:48:38 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Bayramoglu", "Neslihan", ""], ["Nieminen", "Miika T.", ""], ["Saarakkala", "Simo", ""]]}, {"id": "2005.11716", "submitter": "Yaxin Shi", "authors": "Yaxin Shi, Yuangang Pan, Donna Xu and Ivor W. Tsang", "title": "Multi-view Alignment and Generation in CCA via Consistent Latent\n  Encoding", "comments": "37 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view alignment, achieving one-to-one correspondence of multi-view\ninputs, is critical in many real-world multi-view applications, especially for\ncross-view data analysis problems. Recently, an increasing number of works\nstudy this alignment problem with Canonical Correlation Analysis (CCA).\nHowever, existing CCA models are prone to misalign the multiple views due to\neither the neglect of uncertainty or the inconsistent encoding of the multiple\nviews. To tackle these two issues, this paper studies multi-view alignment from\nthe Bayesian perspective. Delving into the impairments of inconsistent\nencodings, we propose to recover correspondence of the multi-view inputs by\nmatching the marginalization of the joint distribution of multi-view random\nvariables under different forms of factorization. To realize our design, we\npresent Adversarial CCA (ACCA) which achieves consistent latent encodings by\nmatching the marginalized latent encodings through the adversarial training\nparadigm. Our analysis based on conditional mutual information reveals that\nACCA is flexible for handling implicit distributions. Extensive experiments on\ncorrelation analysis and cross-view generation under noisy input settings\ndemonstrate the superiority of our model.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 10:50:15 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Shi", "Yaxin", ""], ["Pan", "Yuangang", ""], ["Xu", "Donna", ""], ["Tsang", "Ivor W.", ""]]}, {"id": "2005.11720", "submitter": "Thibaut Le Gouic", "authors": "Thibaut Le Gouic and Jean-Michel Loubes and Philippe Rigollet", "title": "Projection to Fairness in Statistical Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of regression, we consider the fundamental question of making\nan estimator fair while preserving its prediction accuracy as much as possible.\nTo that end, we define its projection to fairness as its closest fair estimator\nin a sense that reflects prediction accuracy. Our methodology leverages tools\nfrom optimal transport to construct efficiently the projection to fairness of\nany given estimator as a simple post-processing step. Moreover, our approach\nprecisely quantifies the cost of fairness, measured in terms of prediction\naccuracy.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 11:20:07 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 09:16:22 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 17:46:21 GMT"}, {"version": "v4", "created": "Thu, 25 Jun 2020 17:02:18 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Gouic", "Thibaut Le", ""], ["Loubes", "Jean-Michel", ""], ["Rigollet", "Philippe", ""]]}, {"id": "2005.11730", "submitter": "Julian Skirzynski", "authors": "Julian Skirzy\\'nski, Frederic Becker and Falk Lieder", "title": "Automatic Discovery of Interpretable Planning Strategies", "comments": "Submitted to the Special Issue on Reinforcement Learning for Real\n  Life in Machine Learning Journal (2021). Code available at\n  https://github.com/RationalityEnhancement/InterpretableStrategyDiscovery", "journal-ref": null, "doi": "10.1007/s10994-021-05963-2", "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.HC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When making decisions, people often overlook critical information or are\noverly swayed by irrelevant information. A common approach to mitigate these\nbiases is to provide decision-makers, especially professionals such as medical\ndoctors, with decision aids, such as decision trees and flowcharts. Designing\neffective decision aids is a difficult problem. We propose that recently\ndeveloped reinforcement learning methods for discovering clever heuristics for\ngood decision-making can be partially leveraged to assist human experts in this\ndesign process. One of the biggest remaining obstacles to leveraging the\naforementioned methods is that the policies they learn are opaque to people. To\nsolve this problem, we introduce AI-Interpret: a general method for\ntransforming idiosyncratic policies into simple and interpretable descriptions.\nOur algorithm combines recent advances in imitation learning and program\ninduction with a new clustering method for identifying a large subset of\ndemonstrations that can be accurately described by a simple, high-performing\ndecision rule. We evaluate our new algorithm and employ it to translate\ninformation-acquisition policies discovered through metalevel reinforcement\nlearning. The results of large behavioral experiments showed that prividing the\ndecision rules generated by AI-Interpret as flowcharts significantly improved\npeople's planning strategies and decisions across three diferent classes of\nsequential decision problems. Moreover, another experiment revealed that this\napproach is significantly more effective than training people by giving them\nperformance feedback. Finally, a series of ablation studies confirmed that\nAI-Interpret is critical to the discovery of interpretable decision rules. We\nconclude that the methods and findings presented herein are an important step\ntowards leveraging automatic strategy discovery to improve human\ndecision-making.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 12:24:52 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 12:55:54 GMT"}, {"version": "v3", "created": "Sat, 10 Apr 2021 05:28:59 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Skirzy\u0144ski", "Julian", ""], ["Becker", "Frederic", ""], ["Lieder", "Falk", ""]]}, {"id": "2005.11736", "submitter": "Raghavendra Addanki", "authors": "Raghavendra Addanki, Shiva Prasad Kasiviswanathan, Andrew McGregor,\n  Cameron Musco", "title": "Efficient Intervention Design for Causal Discovery with Latents", "comments": "International Conference on Machine Learning 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider recovering a causal graph in presence of latent variables, where\nwe seek to minimize the cost of interventions used in the recovery process. We\nconsider two intervention cost models: (1) a linear cost model where the cost\nof an intervention on a subset of variables has a linear form, and (2) an\nidentity cost model where the cost of an intervention is the same, regardless\nof what variables it is on, i.e., the goal is just to minimize the number of\ninterventions. Under the linear cost model, we give an algorithm to identify\nthe ancestral relations of the underlying causal graph, achieving within a\n$2$-factor of the optimal intervention cost. This approximation factor can be\nimproved to $1+\\epsilon$ for any $\\epsilon > 0$ under some mild restrictions.\nUnder the identity cost model, we bound the number of interventions needed to\nrecover the entire causal graph, including the latent variables, using a\nparameterization of the causal graph through a special type of colliders. In\nparticular, we introduce the notion of $p$-colliders, that are colliders\nbetween pair of nodes arising from a specific type of conditioning in the\ncausal graph, and provide an upper bound on the number of interventions as a\nfunction of the maximum number of $p$-colliders between any two nodes in the\ncausal graph.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 12:53:48 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 16:53:18 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Addanki", "Raghavendra", ""], ["Kasiviswanathan", "Shiva Prasad", ""], ["McGregor", "Andrew", ""], ["Musco", "Cameron", ""]]}, {"id": "2005.11739", "submitter": "Mario Alberto Barrantes Quesada", "authors": "Mario Barrantes and Benedikt Herudek and Richard Wang", "title": "Adversarial NLI for Factual Correctness in Text Summarisation Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply the Adversarial NLI dataset to train the NLI model and show that the\nmodel has the potential to enhance factual correctness in abstract\nsummarization. We follow the work of Falke et al. (2019), which rank multiple\ngenerated summaries based on the entailment probabilities between an source\ndocument and summaries and select the summary that has the highest entailment\nprobability. The authors' earlier study concluded that current NLI models are\nnot sufficiently accurate for the ranking task. We show that the Transformer\nmodels fine-tuned on the new dataset achieve significantly higher accuracy and\nhave the potential of selecting a coherent summary.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 13:02:57 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Barrantes", "Mario", ""], ["Herudek", "Benedikt", ""], ["Wang", "Richard", ""]]}, {"id": "2005.11741", "submitter": "Virginia Aglietti", "authors": "Virginia Aglietti, Xiaoyu Lu, Andrei Paleyes, Javier Gonz\\'alez", "title": "Causal Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of globally optimizing a variable of interest\nthat is part of a causal model in which a sequence of interventions can be\nperformed. This problem arises in biology, operational research, communications\nand, more generally, in all fields where the goal is to optimize an output\nmetric of a system of interconnected nodes. Our approach combines ideas from\ncausal inference, uncertainty quantification and sequential decision making. In\nparticular, it generalizes Bayesian optimization, which treats the input\nvariables of the objective function as independent, to scenarios where causal\ninformation is available. We show how knowing the causal graph significantly\nimproves the ability to reason about optimal decision making strategies\ndecreasing the optimization cost while avoiding suboptimal solutions. We\npropose a new algorithm called Causal Bayesian Optimization (CBO). CBO\nautomatically balances two trade-offs: the classical exploration-exploitation\nand the new observation-intervention, which emerges when combining real\ninterventional data with the estimated intervention effects computed via\ndo-calculus. We demonstrate the practical benefits of this method in a\nsynthetic setting and in two real-world applications.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 13:20:50 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 10:57:50 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Aglietti", "Virginia", ""], ["Lu", "Xiaoyu", ""], ["Paleyes", "Andrei", ""], ["Gonz\u00e1lez", "Javier", ""]]}, {"id": "2005.11743", "submitter": "Paulina Pankowska", "authors": "Paulina Pankowska and Daniel L. Oberski", "title": "The effect of measurement error on clustering algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering consists of a popular set of techniques used to separate data into\ninteresting groups for further analysis. Many data sources on which clustering\nis performed are well-known to contain random and systematic measurement\nerrors. Such errors may adversely affect clustering. While several techniques\nhave been developed to deal with this problem, little is known about the\neffectiveness of these solutions. Moreover, no work to-date has examined the\neffect of systematic errors on clustering solutions.\n  In this paper, we perform a Monte Carlo study to investigate the sensitivity\nof two common clustering algorithms, GMMs with merging and DBSCAN, to random\nand systematic error. We find that measurement error is particularly\nproblematic when it is systematic and when it affects all variables in the\ndataset. For the conditions considered here, we also find that the\npartition-based GMM with merged components is less sensitive to measurement\nerror than the density-based DBSCAN procedure.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 13:36:30 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Pankowska", "Paulina", ""], ["Oberski", "Daniel L.", ""]]}, {"id": "2005.11753", "submitter": "Tianhao Wang", "authors": "Tianhao Wang, Joann Qiongna Chen, Zhikun Zhang, Dong Su, Yueqiang\n  Cheng, Zhou Li, Ninghui Li, Somesh Jha", "title": "Continuous Release of Data Streams under both Centralized and Local\n  Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of publishing a stream of real-valued\ndata satisfying differential privacy (DP). One major challenge is that the\nmaximal possible value can be quite large; thus it is necessary to estimate a\nthreshold so that numbers above it are truncated to reduce the amount of noise\nthat is required to all the data. The estimation must be done based on the data\nin a private fashion. We develop such a method that uses the Exponential\nMechanism with a quality function that approximates well the utility goal while\nmaintaining a low sensitivity. Given the threshold, we then propose a novel\nonline hierarchical method and several post-processing techniques.\n  Building on these ideas, we formalize the steps into a framework for private\npublishing of stream data. Our framework consists of three components: a\nthreshold optimizer that privately estimates the threshold, a perturber that\nadds calibrated noises to the stream, and a smoother that improves the result\nusing post-processing. Within our framework, we design an algorithm satisfying\nthe more stringent setting of DP called local DP (LDP). To our knowledge, this\nis the first LDP algorithm for publishing streaming data. Using four real-world\ndatasets, we demonstrate that our mechanism outperforms the state-of-the-art by\na factor of 6-10 orders of magnitude in terms of utility (measured by the mean\nsquared error of answering a random range query).\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 14:25:49 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Wang", "Tianhao", ""], ["Chen", "Joann Qiongna", ""], ["Zhang", "Zhikun", ""], ["Su", "Dong", ""], ["Cheng", "Yueqiang", ""], ["Li", "Zhou", ""], ["Li", "Ninghui", ""], ["Jha", "Somesh", ""]]}, {"id": "2005.11756", "submitter": "Geunhyeong Lee", "authors": "GeunHyeong Lee, Soo-Yong Shin", "title": "Reliability and Performance Assessment of Federated Learning on Clinical\n  Benchmark Data", "comments": "14 pages, 5 tables, 1 Supplementary Table, 2 Supplementary Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As deep learning have been applied in a clinical context, privacy concerns\nhave increased because of the collection and processing of a large amount of\npersonal data. Recently, federated learning (FL) has been suggested to protect\npersonal privacy because it does not centralize data during the training phase.\nIn this study, we assessed the reliability and performance of FL on benchmark\ndatasets including MNIST and MIMIC-III. In addition, we attempted to verify FL\non datasets that simulated a realistic clinical data distribution. We\nimplemented FL that uses a client and server architecture and tested client and\nserver FL on modified MNIST and MIMIC-III datasets. FL delivered reliable\nperformance on both imbalanced and extremely skewed distributions (i.e., the\ndifference of the number of patients and the characteristics of patients in\neach hospital). Therefore, FL can be suitable to protect privacy when applied\nto medical data.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 14:36:44 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Lee", "GeunHyeong", ""], ["Shin", "Soo-Yong", ""]]}, {"id": "2005.11757", "submitter": "Zhensu Sun", "authors": "Zhensu Sun, Yan Liu, Ziming Cheng, Chen Yang, Pengyu Che", "title": "Req2Lib: A Semantic Neural Model for Software Library Recommendation", "comments": "5 pages", "journal-ref": "2020 IEEE 27th International Conference on Software Analysis,\n  Evolution and Reengineering (SANER)", "doi": "10.1109/SANER48275.2020.9054865", "report-no": null, "categories": "cs.SE cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Third-party libraries are crucial to the development of software projects. To\nget suitable libraries, developers need to search through millions of libraries\nby filtering, evaluating, and comparing. The vast number of libraries places a\nbarrier for programmers to locate appropriate ones. To help developers,\nresearchers have proposed automated approaches to recommend libraries based on\nlibrary usage pattern. However, these prior studies can not sufficiently match\nuser requirements and suffer from cold-start problem. In this work, we would\nlike to make recommendations based on requirement descriptions to avoid these\nproblems. To this end, we propose a novel neural approach called Req2Lib which\nrecommends libraries given descriptions of the project requirement. We use a\nSequence-to-Sequence model to learn the library linked-usage information and\nsemantic information of requirement descriptions in natural language. Besides,\nwe apply a domain-specific pre-trained word2vec model for word embedding, which\nis trained over textual corpus from Stack Overflow posts. In the experiment, we\ntrain and evaluate the model with data from 5,625 java projects. Our\npreliminary evaluation demonstrates that Req2Lib can recommend libraries\naccurately.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 14:37:07 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Sun", "Zhensu", ""], ["Liu", "Yan", ""], ["Cheng", "Ziming", ""], ["Yang", "Chen", ""], ["Che", "Pengyu", ""]]}, {"id": "2005.11760", "submitter": "Chi-Chang Lee", "authors": "Chi-Chang Lee, Yu-Chen Lin, Hsuan-Tien Lin, Hsin-Min Wang, Yu Tsao", "title": "SERIL: Noise Adaptive Speech Enhancement using Regularization-based\n  Incremental Learning", "comments": "Accepted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous noise adaptation techniques have been proposed to fine-tune\ndeep-learning models in speech enhancement (SE) for mismatched noise\nenvironments. Nevertheless, adaptation to a new environment may lead to\ncatastrophic forgetting of the previously learned environments. The\ncatastrophic forgetting issue degrades the performance of SE in real-world\nembedded devices, which often revisit previous noise environments. The nature\nof embedded devices does not allow solving the issue with additional storage of\nall pre-trained models or earlier training data. In this paper, we propose a\nregularization-based incremental learning SE (SERIL) strategy, complementing\nexisting noise adaptation strategies without using additional storage. With a\nregularization constraint, the parameters are updated to the new noise\nenvironment while retaining the knowledge of the previous noise environments.\nThe experimental results show that, when faced with a new noise domain, the\nSERIL model outperforms the unadapted SE model. Meanwhile, compared with the\ncurrent adaptive technique based on fine-tuning, the SERIL model can reduce the\nforgetting of previous noise environments by 52%. The results verify that the\nSERIL model can effectively adjust itself to new noise environments while\novercoming the catastrophic forgetting issue. The results make SERIL a\nfavorable choice for real-world SE applications, where the noise environment\nchanges frequently.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 14:49:10 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 20:08:40 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Lee", "Chi-Chang", ""], ["Lin", "Yu-Chen", ""], ["Lin", "Hsuan-Tien", ""], ["Wang", "Hsin-Min", ""], ["Tsao", "Yu", ""]]}, {"id": "2005.11770", "submitter": "Junjie Liang", "authors": "Junjie Liang, Yanting Wu, Dongkuan Xu, Vasant Honavar", "title": "Longitudinal Deep Kernel Gaussian Process Regression", "comments": "Paper accepted by 35th AAAI Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes offer an attractive framework for predictive modeling from\nlongitudinal data, i.e., irregularly sampled, sparse observations from a set of\nindividuals over time. However, such methods have two key shortcomings: (i)\nThey rely on ad hoc heuristics or expensive trial and error to choose the\neffective kernels, and (ii) They fail to handle multilevel correlation\nstructure in the data. We introduce Longitudinal deep kernel Gaussian process\nregression (L-DKGPR), which to the best of our knowledge, is the only method to\novercome these limitations by fully automating the discovery of complex\nmultilevel correlation structure from longitudinal data. Specifically, L-DKGPR\neliminates the need for ad hoc heuristics or trial and error using a novel\nadaptation of deep kernel learning that combines the expressive power of deep\nneural networks with the flexibility of non-parametric kernel methods. L-DKGPR\neffectively learns the multilevel correlation with a novel addictive kernel\nthat simultaneously accommodates both time-varying and the time-invariant\neffects. We derive an efficient algorithm to train L-DKGPR using latent space\ninducing points and variational inference. Results of extensive experiments on\nseveral benchmark data sets demonstrate that L-DKGPR significantly outperforms\nthe state-of-the-art longitudinal data analysis (LDA) methods.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 15:10:48 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 19:18:23 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 14:21:33 GMT"}, {"version": "v4", "created": "Mon, 7 Dec 2020 20:44:53 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Liang", "Junjie", ""], ["Wu", "Yanting", ""], ["Xu", "Dongkuan", ""], ["Honavar", "Vasant", ""]]}, {"id": "2005.11772", "submitter": "Dawid Rymarczyk", "authors": "Bartosz Zieli\\'nski and Agnieszka Sroka-Oleksiak and Dawid Rymarczyk\n  and Adam Piekarczyk and Monika Brzychczy-W{\\l}och", "title": "Deep learning approach to describe and classify fungi microscopic images", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0234806", "report-no": "MIDL/2020/ExtendedAbstract/AEhp_Cqq-h", "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preliminary diagnosis of fungal infections can rely on microscopic\nexamination. However, in many cases, it does not allow unambiguous\nidentification of the species by microbiologist due to their visual similarity.\nTherefore, it is usually necessary to use additional biochemical tests. That\ninvolves additional costs and extends the identification process up to 10 days.\nSuch a delay in the implementation of targeted therapy may be grave in\nconsequence as the mortality rate for immunosuppressed patients is high. In\nthis paper, we apply a machine learning approach based on deep neural networks\nand Fisher Vector (advanced bag-of-words method) to classify microscopic images\nof various fungi species. Our approach has the potential to make the last stage\nof biochemical identification redundant, shortening the identification process\nby 2-3 days, and reducing the cost of the diagnosis.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 15:15:07 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Zieli\u0144ski", "Bartosz", ""], ["Sroka-Oleksiak", "Agnieszka", ""], ["Rymarczyk", "Dawid", ""], ["Piekarczyk", "Adam", ""], ["Brzychczy-W\u0142och", "Monika", ""]]}, {"id": "2005.11777", "submitter": "Murong Ma", "authors": "Murong Ma, Haiwei Wu, Xuyang Wang, Lin Yang, Junjie Wang and Ming Li", "title": "Acoustic Word Embedding System for Code-Switching Query-by-example\n  Spoken Term Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a deep convolutional neural network-based acoustic\nword embedding system on code-switching query by example spoken term detection.\nDifferent from previous configurations, we combine audio data in two languages\nfor training instead of only using one single language. We transform the\nacoustic features of keyword templates and searching content to\nfixed-dimensional vectors and calculate the distances between keyword segments\nand searching content segments obtained in a sliding manner. An auxiliary\nvariability-invariant loss is also applied to training data within the same\nword but different speakers. This strategy is used to prevent the extractor\nfrom encoding undesired speaker- or accent-related information into the\nacoustic word embeddings. Experimental results show that our proposed system\nproduces promising searching results in the code-switching test scenario. With\nthe increased number of templates and the employment of variability-invariant\nloss, the searching performance is further enhanced.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 15:27:56 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Ma", "Murong", ""], ["Wu", "Haiwei", ""], ["Wang", "Xuyang", ""], ["Yang", "Lin", ""], ["Wang", "Junjie", ""], ["Li", "Ming", ""]]}, {"id": "2005.11797", "submitter": "Pranav Poduval", "authors": "Pranav Poduval, Hrushikesh Loya, Amit Sethi", "title": "Functional Space Variational Inference for Uncertainty Estimation in\n  Computer Aided Diagnosis", "comments": "Meaningful priors on the functional space rather than the weight\n  space, result in well calibrated uncertainty estimates", "journal-ref": "Medical Imaging with Deep Learning 2020", "doi": null, "report-no": "MIDL/2020/ExtendedAbstract/eLL-c_Xc0B", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have revolutionized medical image analysis and disease\ndiagnosis. Despite their impressive performance, it is difficult to generate\nwell-calibrated probabilistic outputs for such networks, which makes them\nuninterpretable black boxes. Bayesian neural networks provide a principled\napproach for modelling uncertainty and increasing patient safety, but they have\na large computational overhead and provide limited improvement in calibration.\nIn this work, by taking skin lesion classification as an example task, we show\nthat by shifting Bayesian inference to the functional space we can craft\nmeaningful priors that give better calibrated uncertainty estimates at a much\nlower computational cost.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 16:42:11 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 16:47:06 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Poduval", "Pranav", ""], ["Loya", "Hrushikesh", ""], ["Sethi", "Amit", ""]]}, {"id": "2005.11810", "submitter": "Ulrich Viereck", "authors": "Ulrich Viereck, Kate Saenko, Robert Platt", "title": "Learning visual servo policies via planner cloning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning control policies for visual servoing in novel environments is an\nimportant problem. However, standard model-free policy learning methods are\nslow. This paper explores planner cloning: using behavior cloning to learn\npolicies that mimic the behavior of a full-state motion planner in simulation.\nWe propose Penalized Q Cloning (PQC), a new behavior cloning algorithm. We show\nthat it outperforms several baselines and ablations on some challenging\nproblems involving visual servoing in novel environments while avoiding\nobstacles. Finally, we demonstrate that these policies can be transferred\neffectively onto a real robotic platform, achieving approximately an 87%\nsuccess rate both in simulation and on a real robot.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 17:56:57 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Viereck", "Ulrich", ""], ["Saenko", "Kate", ""], ["Platt", "Robert", ""]]}, {"id": "2005.11811", "submitter": "Tuan-Duy Nguyen", "authors": "Tuan-Duy H. Nguyen, Huu-Nghia H. Nguyen, Hieu Dao", "title": "Recognizing Families through Images with Pretrained Encoder", "comments": "Will appear as part of RFIW2020 in the Proceedings of 2020\n  International Conference on Automatic Face and Gesture Recognition (IEEE\n  AMFG)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kinship verification and kinship retrieval are emerging tasks in computer\nvision. Kinship verification aims at determining whether two facial images are\nfrom related people or not, while kinship retrieval is the task of retrieving\npossible related facial images to a person from a gallery of images. They\nintroduce unique challenges because of the hidden relations and features that\ncarry inherent characteristics between the facial images. We employ 3 methods,\nFaceNet, Siamese VGG-Face, and a combination of FaceNet and VGG-Face models as\nfeature extractors, to achieve the 9th standing for kinship verification and\nthe 5th standing for kinship retrieval in the Recognizing Family in The Wild\n2020 competition. We then further experimented using StyleGAN2 as another\nencoder, with no improvement in the result.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 17:59:19 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Nguyen", "Tuan-Duy H.", ""], ["Nguyen", "Huu-Nghia H.", ""], ["Dao", "Hieu", ""]]}, {"id": "2005.11818", "submitter": "Steve Hanneke", "authors": "Olivier Bousquet, Steve Hanneke, Shay Moran, and Nikita Zhivotovskiy", "title": "Proper Learning, Helly Number, and an Optimal SVM Bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical PAC sample complexity bounds are stated for any Empirical Risk\nMinimizer (ERM) and contain an extra logarithmic factor $\\log(1/{\\epsilon})$\nwhich is known to be necessary for ERM in general. It has been recently shown\nby Hanneke (2016) that the optimal sample complexity of PAC learning for any VC\nclass C is achieved by a particular improper learning algorithm, which outputs\na specific majority-vote of hypotheses in C. This leaves the question of when\nthis bound can be achieved by proper learning algorithms, which are restricted\nto always output a hypothesis from C.\n  In this paper we aim to characterize the classes for which the optimal sample\ncomplexity can be achieved by a proper learning algorithm. We identify that\nthese classes can be characterized by the dual Helly number, which is a\ncombinatorial parameter that arises in discrete geometry and abstract\nconvexity. In particular, under general conditions on C, we show that the dual\nHelly number is bounded if and only if there is a proper learner that obtains\nthe optimal joint dependence on $\\epsilon$ and $\\delta$.\n  As further implications of our techniques we resolve a long-standing open\nproblem posed by Vapnik and Chervonenkis (1974) on the performance of the\nSupport Vector Machine by proving that the sample complexity of SVM in the\nrealizable case is $\\Theta((n/{\\epsilon})+(1/{\\epsilon})\\log(1/{\\delta}))$,\nwhere $n$ is the dimension. This gives the first optimal PAC bound for\nHalfspaces achieved by a proper learning algorithm, and moreover is\ncomputationally efficient.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 18:11:57 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Bousquet", "Olivier", ""], ["Hanneke", "Steve", ""], ["Moran", "Shay", ""], ["Zhivotovskiy", "Nikita", ""]]}, {"id": "2005.11853", "submitter": "Deepanshu Vasal", "authors": "Rajesh K Mishra, Deepanshu Vasal, and Sriram Vishwanath", "title": "Model-free Reinforcement Learning for Stochastic Stackelberg Security\n  Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a sequential stochastic Stackelberg game with two\nplayers, a leader and a follower. The follower has access to the state of the\nsystem while the leader does not. Assuming that the players act in their\nrespective best interests, the follower's strategy is to play the best response\nto the leader's strategy. In such a scenario, the leader has the advantage of\ncommitting to a policy which maximizes its own returns given the knowledge that\nthe follower is going to play the best response to its policy. Thus, both\nplayers converge to a pair of policies that form the Stackelberg equilibrium of\nthe game. Recently,~[1] provided a sequential decomposition algorithm to\ncompute the Stackelberg equilibrium for such games which allow for the\ncomputation of Markovian equilibrium policies in linear time as opposed to\ndouble exponential, as before. In this paper, we extend the idea to an MDP\nwhose dynamics are not known to the players, to propose an RL algorithm based\non Expected Sarsa that learns the Stackelberg equilibrium policy by simulating\na model of the MDP. We use particle filters to estimate the belief update for a\ncommon agent which computes the optimal policy based on the information which\nis common to both the players. We present a security game example to illustrate\nthe policy learned by our algorithm. by simulating a model of the MDP. We use\nparticle filters to estimate the belief update for a common agent which\ncomputes the optimal policy based on the information which is common to both\nthe players. We present a security game example to illustrate the policy\nlearned by our algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 22:34:20 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Mishra", "Rajesh K", ""], ["Vasal", "Deepanshu", ""], ["Vishwanath", "Sriram", ""]]}, {"id": "2005.11856", "submitter": "Joseph Paul Cohen", "authors": "Joseph Paul Cohen and Lan Dao and Paul Morrison and Karsten Roth and\n  Yoshua Bengio and Beiyi Shen and Almas Abbasi and Mahsa Hoshmand-Kochi and\n  Marzyeh Ghassemi and Haifang Li and Tim Q Duong", "title": "Predicting COVID-19 Pneumonia Severity on Chest X-ray with Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: The need to streamline patient management for COVID-19 has become\nmore pressing than ever. Chest X-rays provide a non-invasive (potentially\nbedside) tool to monitor the progression of the disease. In this study, we\npresent a severity score prediction model for COVID-19 pneumonia for frontal\nchest X-ray images. Such a tool can gauge severity of COVID-19 lung infections\n(and pneumonia in general) that can be used for escalation or de-escalation of\ncare as well as monitoring treatment efficacy, especially in the ICU.\n  Methods: Images from a public COVID-19 database were scored retrospectively\nby three blinded experts in terms of the extent of lung involvement as well as\nthe degree of opacity. A neural network model that was pre-trained on large\n(non-COVID-19) chest X-ray datasets is used to construct features for COVID-19\nimages which are predictive for our task.\n  Results: This study finds that training a regression model on a subset of the\noutputs from an this pre-trained chest X-ray model predicts our geographic\nextent score (range 0-8) with 1.14 mean absolute error (MAE) and our lung\nopacity score (range 0-6) with 0.78 MAE.\n  Conclusions: These results indicate that our model's ability to gauge\nseverity of COVID-19 lung infections could be used for escalation or\nde-escalation of care as well as monitoring treatment efficacy, especially in\nthe intensive care unit (ICU). A proper clinical trial is needed to evaluate\nefficacy. To enable this we make our code, labels, and data available online at\nhttps://github.com/mlmed/torchxrayvision/tree/master/scripts/covid-severity and\nhttps://github.com/ieee8023/covid-chestxray-dataset\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 23:13:16 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 16:40:48 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 17:09:53 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Cohen", "Joseph Paul", ""], ["Dao", "Lan", ""], ["Morrison", "Paul", ""], ["Roth", "Karsten", ""], ["Bengio", "Yoshua", ""], ["Shen", "Beiyi", ""], ["Abbasi", "Almas", ""], ["Hoshmand-Kochi", "Mahsa", ""], ["Ghassemi", "Marzyeh", ""], ["Li", "Haifang", ""], ["Duong", "Tim Q", ""]]}, {"id": "2005.11862", "submitter": "Venkatramani Balaji", "authors": "V. Balaji", "title": "Climbing down Charney's ladder: Machine Learning and the post-Dennard\n  era of computational climate science", "comments": "Accepted for publication in Phil Trans Roy Soc A", "journal-ref": null, "doi": "10.1098/rsta.2020.0085", "report-no": null, "categories": "physics.ao-ph cs.LG nlin.CD physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The advent of digital computing in the 1950s sparked a revolution in the\nscience of weather and climate. Meteorology, long based on extrapolating\npatterns in space and time, gave way to computational methods in a decade of\nadvances in numerical weather forecasting. Those same methods also gave rise to\ncomputational climate science, studying the behaviour of those same numerical\nequations over intervals much longer than weather events, and changes in\nexternal boundary conditions. Several subsequent decades of exponential growth\nin computational power have brought us to the present day, where models ever\ngrow in resolution and complexity, capable of mastery of many small-scale\nphenomena with global repercussions, and ever more intricate feedbacks in the\nEarth system.\n  The current juncture in computing, seven decades later, heralds an end to\nwhat is called Dennard scaling, the physics behind ever smaller computational\nunits and ever faster arithmetic. This is prompting a fundamental change in our\napproach to the simulation of weather and climate, potentially as revolutionary\nas that wrought by John von Neumann in the 1950s. One approach could return us\nto an earlier era of pattern recognition and extrapolation, this time aided by\ncomputational power. Another approach could lead us to insights that continue\nto be expressed in mathematical equations. In either approach, or any synthesis\nof those, it is clearly no longer the steady march of the last few decades,\ncontinuing to add detail to ever more elaborate models. In this prospectus, we\nattempt to show the outlines of how this may unfold in the coming decades, a\nnew harnessing of physical knowledge, computation, and data.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 23:46:09 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 16:19:20 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Balaji", "V.", ""]]}, {"id": "2005.11878", "submitter": "Yuanhan Hu", "authors": "Mert Gurbuzbalaban, Yuanhan Hu", "title": "Fractional moment-preserving initialization schemes for training deep\n  neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A traditional approach to initialization in deep neural networks (DNNs) is to\nsample the network weights randomly for preserving the variance of\npre-activations. On the other hand, several studies show that during the\ntraining process, the distribution of stochastic gradients can be heavy-tailed\nespecially for small batch sizes. In this case, weights and therefore\npre-activations can be modeled with a heavy-tailed distribution that has an\ninfinite variance but has a finite (non-integer) fractional moment of order $s$\nwith $s<2$. Motivated by this fact, we develop initialization schemes for fully\nconnected feed-forward networks that can provably preserve any given moment of\norder $s \\in (0, 2]$ over the layers for a class of activations including ReLU,\nLeaky ReLU, Randomized Leaky ReLU, and linear activations. These generalized\nschemes recover traditional initialization schemes in the limit $s \\to 2$ and\nserve as part of a principled theory for initialization. For all these schemes,\nwe show that the network output admits a finite almost sure limit as the number\nof layers grows, and the limit is heavy-tailed in some settings. This sheds\nfurther light into the origins of heavy tail during signal propagation in DNNs.\nWe prove that the logarithm of the norm of the network outputs, if properly\nscaled, will converge to a Gaussian distribution with an explicit mean and\nvariance we can compute depending on the activation used, the value of s chosen\nand the network width. We also prove that our initialization scheme avoids\nsmall network output values more frequently compared to traditional approaches.\nFurthermore, the proposed initialization strategy does not have an extra cost\nduring the training procedure. We show through numerical experiments that our\ninitialization can improve the training and test performance.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 01:10:01 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 02:39:19 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 17:25:23 GMT"}, {"version": "v4", "created": "Mon, 8 Jun 2020 20:00:48 GMT"}, {"version": "v5", "created": "Sat, 13 Feb 2021 15:23:47 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Gurbuzbalaban", "Mert", ""], ["Hu", "Yuanhan", ""]]}, {"id": "2005.11879", "submitter": "Zhou Fan", "authors": "Zhou Fan and Zhichao Wang", "title": "Spectra of the Conjugate Kernel and Neural Tangent Kernel for\n  linear-width neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the eigenvalue distributions of the Conjugate Kernel and Neural\nTangent Kernel associated to multi-layer feedforward neural networks. In an\nasymptotic regime where network width is increasing linearly in sample size,\nunder random initialization of the weights, and for input samples satisfying a\nnotion of approximate pairwise orthogonality, we show that the eigenvalue\ndistributions of the CK and NTK converge to deterministic limits. The limit for\nthe CK is described by iterating the Marcenko-Pastur map across the hidden\nlayers. The limit for the NTK is equivalent to that of a linear combination of\nthe CK matrices across layers, and may be described by recursive fixed-point\nequations that extend this Marcenko-Pastur map. We demonstrate the agreement of\nthese asymptotic predictions with the observed spectra for both synthetic and\nCIFAR-10 training data, and we perform a small simulation to investigate the\nevolutions of these spectra over training.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 01:11:49 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 17:46:17 GMT"}, {"version": "v3", "created": "Sat, 10 Oct 2020 16:47:46 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Fan", "Zhou", ""], ["Wang", "Zhichao", ""]]}, {"id": "2005.11885", "submitter": "Shimin Gong", "authors": "Jiaye Lin, Yuze Zou, Xiaoru Dong, Shimin Gong, Dinh Thai Hoang, Dusit\n  Niyato", "title": "Optimization-driven Deep Reinforcement Learning for Robust Beamforming\n  in IRS-assisted Wireless Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent reflecting surface (IRS) is a promising technology to assist\ndownlink information transmissions from a multi-antenna access point (AP) to a\nreceiver. In this paper, we minimize the AP's transmit power by a joint\noptimization of the AP's active beamforming and the IRS's passive beamforming.\nDue to uncertain channel conditions, we formulate a robust power minimization\nproblem subject to the receiver's signal-to-noise ratio (SNR) requirement and\nthe IRS's power budget constraint. We propose a deep reinforcement learning\n(DRL) approach that can adapt the beamforming strategies from past experiences.\nTo improve the learning performance, we derive a convex approximation as a\nlower bound on the robust problem, which is integrated into the DRL framework\nand thus promoting a novel optimization-driven deep deterministic policy\ngradient (DDPG) approach. In particular, when the DDPG algorithm generates a\npart of the action (e.g., passive beamforming), we can use the model-based\nconvex approximation to optimize the other part (e.g., active beamforming) of\nthe action more efficiently. Our simulation results demonstrate that the\noptimization-driven DDPG algorithm can improve both the learning rate and\nreward performance significantly compared to the conventional model-free DDPG\nalgorithm.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 01:42:55 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Lin", "Jiaye", ""], ["Zou", "Yuze", ""], ["Dong", "Xiaoru", ""], ["Gong", "Shimin", ""], ["Hoang", "Dinh Thai", ""], ["Niyato", "Dusit", ""]]}, {"id": "2005.11890", "submitter": "Ronan Perry", "authors": "Ronan Perry, Gavin Mischler, Richard Guo, Theodore Lee, Alexander\n  Chang, Arman Koul, Cameron Franz, Hugo Richard, Iain Carmichael, Pierre\n  Ablin, Alexandre Gramfort, Joshua T. Vogelstein", "title": "mvlearn: Multiview Machine Learning in Python", "comments": "6 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As data are generated more and more from multiple disparate sources,\nmultiview data sets, where each sample has features in distinct views, have\nballooned in recent years. However, no comprehensive package exists that\nenables non-specialists to use these methods easily. mvlearn is a Python\nlibrary which implements the leading multiview machine learning methods. Its\nsimple API closely follows that of scikit-learn for increased ease-of-use. The\npackage can be installed from Python Package Index (PyPI) and the conda package\nmanager and is released under the MIT open-source license. The documentation,\ndetailed examples, and all releases are available at\nhttps://mvlearn.github.io/.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 02:35:35 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 18:20:34 GMT"}, {"version": "v3", "created": "Fri, 4 Dec 2020 15:13:37 GMT"}, {"version": "v4", "created": "Tue, 25 May 2021 18:16:18 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Perry", "Ronan", ""], ["Mischler", "Gavin", ""], ["Guo", "Richard", ""], ["Lee", "Theodore", ""], ["Chang", "Alexander", ""], ["Koul", "Arman", ""], ["Franz", "Cameron", ""], ["Richard", "Hugo", ""], ["Carmichael", "Iain", ""], ["Ablin", "Pierre", ""], ["Gramfort", "Alexandre", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "2005.11903", "submitter": "Chaochao Chen", "authors": "Jun Zhou, Chaochao Chen, Longfei Zheng, Huiwen Wu, Jia Wu, Xiaolin\n  Zheng, Bingzhe Wu, Ziqi Liu, Li Wang", "title": "Vertically Federated Graph Neural Network for Privacy-Preserving Node\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Graph Neural Network (GNN) has achieved remarkable progresses in\nvarious real-world tasks on graph data, consisting of node features and the\nadjacent information between different nodes. High-performance GNN models\nalways depend on both rich features and complete edge information in graph.\nHowever, such information could possibly be isolated by different data holders\nin practice, which is the so-called data isolation problem. To solve this\nproblem, in this paper, we propose VFGNN, a federated GNN learning paradigm for\nprivacy-preserving node classification task under data vertically partitioned\nsetting, which can be generalized to existing GNN models. Specifically, we\nsplit the computation graph into two parts. We leave the private data (i.e.,\nfeatures, edges, and labels) related computations on data holders, and delegate\nthe rest of computations to a semi-honest server. We also propose to apply\ndifferential privacy to prevent potential information leakage from the server.\nWe conduct experiments on three benchmarks and the results demonstrate the\neffectiveness of VFGNN.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 03:12:18 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 08:13:06 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Zhou", "Jun", ""], ["Chen", "Chaochao", ""], ["Zheng", "Longfei", ""], ["Wu", "Huiwen", ""], ["Wu", "Jia", ""], ["Zheng", "Xiaolin", ""], ["Wu", "Bingzhe", ""], ["Liu", "Ziqi", ""], ["Wang", "Li", ""]]}, {"id": "2005.11904", "submitter": "Shangxi Wu", "authors": "Shangxi Wu and Jitao Sang and Kaiyuan Xu and Guanhua Zheng and\n  Changsheng Xu", "title": "Adaptive Adversarial Logits Pairing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples provide an opportunity as well as impose a challenge for\nunderstanding image classification systems. Based on the analysis of the\nadversarial training solution Adversarial Logits Pairing (ALP), we observed in\nthis work that: (1) The inference of adversarially robust model tends to rely\non fewer high-contribution features compared with vulnerable ones. (2) The\ntraining target of ALP doesn't fit well to a noticeable part of samples, where\nthe logits pairing loss is overemphasized and obstructs minimizing the\nclassification loss. Motivated by these observations, we design an Adaptive\nAdversarial Logits Pairing (AALP) solution by modifying the training process\nand training target of ALP. Specifically, AALP consists of an adaptive feature\noptimization module with Guided Dropout to systematically pursue fewer\nhigh-contribution features, and an adaptive sample weighting module by setting\nsample-specific training weights to balance between logits pairing loss and\nclassification loss. The proposed AALP solution demonstrates superior defense\nperformance on multiple datasets with extensive experiments.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 03:12:20 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 01:57:11 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Wu", "Shangxi", ""], ["Sang", "Jitao", ""], ["Xu", "Kaiyuan", ""], ["Zheng", "Guanhua", ""], ["Xu", "Changsheng", ""]]}, {"id": "2005.11914", "submitter": "Li Wang", "authors": "Hok Shing Wong, Li Wang, Raymond Chan, and Tieyong Zeng", "title": "Deep Tensor CCA for Multi-view Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Deep Tensor Canonical Correlation Analysis (DTCCA), a method to\nlearn complex nonlinear transformations of multiple views (more than two) of\ndata such that the resulting representations are linearly correlated in high\norder. The high-order correlation of given multiple views is modeled by\ncovariance tensor, which is different from most CCA formulations relying solely\non the pairwise correlations. Parameters of transformations of each view are\njointly learned by maximizing the high-order canonical correlation. To solve\nthe resulting problem, we reformulate it as the best sum of rank-1\napproximation, which can be efficiently solved by existing tensor decomposition\nmethod. DTCCA is a nonlinear extension of tensor CCA (TCCA) via deep networks.\nThe transformations of DTCCA are parametric functions, which are very different\nfrom implicit mapping in the form of kernel function. Comparing with kernel\nTCCA, DTCCA not only can deal with arbitrary dimensions of the input data, but\nalso does not need to maintain the training data for computing representations\nof any given data point. Hence, DTCCA as a unified model can efficiently\novercome the scalable issue of TCCA for either high-dimensional multi-view data\nor a large amount of views, and it also naturally extends TCCA for learning\nnonlinear representation. Extensive experiments on three multi-view data sets\ndemonstrate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 04:04:28 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Wong", "Hok Shing", ""], ["Wang", "Li", ""], ["Chan", "Raymond", ""], ["Zeng", "Tieyong", ""]]}, {"id": "2005.11930", "submitter": "Benjamin Lucas", "authors": "Benjamin Lucas, Charlotte Pelletier, Daniel Schmidt, Geoffrey I. Webb,\n  and Fran\\c{c}ois Petitjean", "title": "A Bayesian-inspired, deep learning-based, semi-supervised domain\n  adaptation technique for land cover mapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Land cover maps are a vital input variable to many types of environmental\nresearch and management. While they can be produced automatically by machine\nlearning techniques, these techniques require substantial training data to\nachieve high levels of accuracy, which are not always available. One technique\nresearchers use when labelled training data are scarce is domain adaptation\n(DA) -- where data from an alternate region, known as the source domain, are\nused to train a classifier and this model is adapted to map the study region,\nor target domain. The scenario we address in this paper is known as\nsemi-supervised DA, where some labelled samples are available in the target\ndomain. In this paper we present Sourcerer, a Bayesian-inspired, deep\nlearning-based, semi-supervised DA technique for producing land cover maps from\nSITS data. The technique takes a convolutional neural network trained on a\nsource domain and then trains further on the available target domain with a\nnovel regularizer applied to the model weights. The regularizer adjusts the\ndegree to which the model is modified to fit the target data, limiting the\ndegree of change when the target data are few in number and increasing it as\ntarget data quantity increases. Our experiments on Sentinel-2 time series\nimages compare Sourcerer with two state-of-the-art semi-supervised domain\nadaptation techniques and four baseline models. We show that on two different\nsource-target domain pairings Sourcerer outperforms all other methods for any\nquantity of labelled target data available. In fact, the results on the more\ndifficult target domain show that the starting accuracy of Sourcerer (when no\nlabelled target data are available), 74.2%, is greater than the next-best\nstate-of-the-art method trained on 20,000 labelled target instances.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 05:36:50 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 05:57:44 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Lucas", "Benjamin", ""], ["Pelletier", "Charlotte", ""], ["Schmidt", "Daniel", ""], ["Webb", "Geoffrey I.", ""], ["Petitjean", "Fran\u00e7ois", ""]]}, {"id": "2005.11932", "submitter": "Tuan-Duy Nguyen", "authors": "Tuan-Duy H. Nguyen and Huu-Nghia H. Nguyen", "title": "Towards a Robust WiFi-based Fall Detection with Adversarial Data\n  Augmentation", "comments": "Will appear in Proceedings of the 54th Annual Conference on\n  Information Sciences and Systems (CISS2020)", "journal-ref": "2020 54th Annual Conference on Information Sciences and Systems\n  (CISS), Princeton, NJ, USA, 2020, pp. 1-6", "doi": "10.1109/CISS48834.2020.1570617398", "report-no": null, "categories": "cs.HC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent WiFi-based fall detection systems have drawn much attention due to\ntheir advantages over other sensory systems. Various implementations have\nachieved impressive progress in performance, thanks to machine learning and\ndeep learning techniques. However, many of such high accuracy systems have low\nreliability as they fail to achieve robustness in unseen environments. To\naddress that, this paper investigates a method of generalization through\nadversarial data augmentation. Our results show a slight improvement in deep\nlearning-systems in unseen domains, though the performance is not significant.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 05:46:27 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Nguyen", "Tuan-Duy H.", ""], ["Nguyen", "Huu-Nghia H.", ""]]}, {"id": "2005.11949", "submitter": "Yunfei Yang", "authors": "Yunfei Yang, Zhen Li, Yang Wang", "title": "Approximation in shift-invariant spaces with deep ReLU neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the expressive power of deep ReLU neural networks for approximating\nfunctions in dilated shift-invariant spaces, which are widely used in signal\nprocessing, image processing, communications and so on. Approximation error\nbounds are estimated with respect to the width and depth of neural networks.\nThe network construction is based on the bit extraction and data-fitting\ncapacity of deep neural networks. As applications of our main results, the\napproximation rates of classical function spaces such as Sobolev spaces and\nBesov spaces are obtained. We also give lower bounds of the $L^p (1\\le p \\le\n\\infty)$ approximation error for Sobolev spaces, which show that our\nconstruction of neural network is asymptotically optimal up to a logarithmic\nfactor.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 07:23:47 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 08:47:13 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Yang", "Yunfei", ""], ["Li", "Zhen", ""], ["Wang", "Yang", ""]]}, {"id": "2005.11988", "submitter": "Pirmin Lemberger", "authors": "Pirmin Lemberger", "title": "Deep Learning Models for Automatic Summarization", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text summarization is an NLP task which aims to convert a textual document\ninto a shorter one while keeping as much meaning as possible. This pedagogical\narticle reviews a number of recent Deep Learning architectures that have helped\nto advance research in this field. We will discuss in particular applications\nof pointer networks, hierarchical Transformers and Reinforcement Learning. We\nassume basic knowledge of Seq2Seq architecture and Transformer networks within\nNLP.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 09:12:37 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Lemberger", "Pirmin", ""]]}, {"id": "2005.12005", "submitter": "O\\u{g}uzhan Karaahmeto\\u{g}lu", "authors": "Oguzhan Karaahmetoglu (1 and 2), Fatih Ilhan (1 and 2), Ismail Balaban\n  (2), Suleyman Serdar Kozat (1 and 2) ((1) Bilkent University, (2) DataBoss\n  A.S.)", "title": "Unsupervised Online Anomaly Detection On Irregularly Sampled Or Missing\n  Valued Time-Series Data Using LSTM Networks", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study anomaly detection and introduce an algorithm that processes variable\nlength, irregularly sampled sequences or sequences with missing values. Our\nalgorithm is fully unsupervised, however, can be readily extended to supervised\nor semisupervised cases when the anomaly labels are present as remarked\nthroughout the paper. Our approach uses the Long Short Term Memory (LSTM)\nnetworks in order to extract temporal features and find the most relevant\nfeature vectors for anomaly detection. We incorporate the sampling time\ninformation to our model by modulating the standard LSTM model with time\nmodulation gates. After obtaining the most relevant features from the LSTM, we\nlabel the sequences using a Support Vector Data Descriptor (SVDD) model. We\nintroduce a loss function and then jointly optimize the feature extraction and\nsequence processing mechanisms in an end-to-end manner. Through this joint\noptimization, the LSTM extracts the most relevant features for anomaly\ndetection later to be used in the SVDD, hence completely removes the need for\nfeature selection by expert knowledge. Furthermore, we provide a training\nalgorithm for the online setup, where we optimize our model parameters with\nindividual sequences as the new data arrives. Finally, on real-life datasets,\nwe show that our model significantly outperforms the standard approaches thanks\nto its combination of LSTM with SVDD and joint optimization.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 09:41:04 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Karaahmetoglu", "Oguzhan", "", "1 and 2"], ["Ilhan", "Fatih", "", "1 and 2"], ["Balaban", "Ismail", "", "1 and 2"], ["Kozat", "Suleyman Serdar", "", "1 and 2"]]}, {"id": "2005.12021", "submitter": "Yonghui Yang", "authors": "Le Wu, Yonghui Yang, Kun Zhang, Richang Hong, Yanjie Fu and Meng Wang", "title": "Joint Item Recommendation and Attribute Inference: An Adaptive Graph\n  Convolutional Network Approach", "comments": "Accepted by SIGIR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many recommender systems, users and items are associated with attributes,\nand users show preferences to items. The attribute information describes\nusers'(items') characteristics and has a wide range of applications, such as\nuser profiling, item annotation, and feature-enhanced recommendation. As\nannotating user (item) attributes is a labor intensive task, the attribute\nvalues are often incomplete with many missing attribute values. Therefore, item\nrecommendation and attribute inference have become two main tasks in these\nplatforms. Researchers have long converged that user (item) attributes and the\npreference behavior are highly correlated. Some researchers proposed to\nleverage one kind of data for the remaining task, and showed to improve\nperformance. Nevertheless, these models either neglected the incompleteness of\nuser (item) attributes or regarded the correlation of the two tasks with simple\nmodels, leading to suboptimal performance of these two tasks. To this end, in\nthis paper, we define these two tasks in an attributed user-item bipartite\ngraph, and propose an Adaptive Graph Convolutional Network (AGCN) approach for\njoint item recommendation and attribute inference. The key idea of AGCN is to\niteratively perform two parts: 1) Learning graph embedding parameters with\npreviously learned approximated attribute values to facilitate two tasks; 2)\nSending the approximated updated attribute values back to the attributed graph\nfor better graph embedding learning. Therefore, AGCN could adaptively adjust\nthe graph embedding learning parameters by incorporating both the given\nattributes and the estimated attribute values, in order to provide weakly\nsupervised information to refine the two tasks. Extensive experimental results\non three real-world datasets clearly show the effectiveness of the proposed\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 10:50:01 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Wu", "Le", ""], ["Yang", "Yonghui", ""], ["Zhang", "Kun", ""], ["Hong", "Richang", ""], ["Fu", "Yanjie", ""], ["Wang", "Meng", ""]]}, {"id": "2005.12022", "submitter": "Yizhou Luo", "authors": "Yizhou Luo and Kwan-Wu Chin", "title": "Learning to Charge RF-Energy Harvesting Devices in WiFi Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a solar-powered Access Point (AP) that is tasked\nwith supporting both non-energy harvesting or legacy data users such as\nlaptops, and devices with Radio Frequency (RF)-energy harvesting and sensing\ncapabilities. We propose two solutions that enable the AP to manage its\nharvested energy via transmit power control and also ensure devices perform\nsensing tasks frequently. Advantageously, our solutions are suitable for\ncurrent wireless networks and do not require perfect channel gain information\nor non-causal energy arrival at devices. The first solution uses a deep\nQ-network (DQN) whilst the second solution uses Model Predictive Control (MPC)\nto control the AP's transmit power. Our results show that our DQN and MPC\nsolutions improve energy efficiency and user satisfaction by respectively 16%\nto 35%, and 10% to 42% as compared to competing algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 10:55:24 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Luo", "Yizhou", ""], ["Chin", "Kwan-Wu", ""]]}, {"id": "2005.12055", "submitter": "Seyed Mostafa Kia", "authors": "Seyed Mostafa Kia, Hester Huijsdens, Richard Dinga, Thomas Wolfers,\n  Maarten Mennes, Ole A. Andreassen, Lars T. Westlye, Christian F. Beckmann,\n  Andre F. Marquand", "title": "Hierarchical Bayesian Regression for Multi-Site Normative Modeling of\n  Neuroimaging Data", "comments": "To be published in MICCAI 2020 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical neuroimaging has recently witnessed explosive growth in data\navailability which brings studying heterogeneity in clinical cohorts to the\nspotlight. Normative modeling is an emerging statistical tool for achieving\nthis objective. However, its application remains technically challenging due to\ndifficulties in properly dealing with nuisance variation, for example due to\nvariability in image acquisition devices. Here, in a fully probabilistic\nframework, we propose an application of hierarchical Bayesian regression (HBR)\nfor multi-site normative modeling. Our experimental results confirm the\nsuperiority of HBR in deriving more accurate normative ranges on large\nmulti-site neuroimaging data compared to widely used methods. This provides the\npossibility i) to learn the normative range of structural and functional brain\nmeasures on large multi-site data; ii) to recalibrate and reuse the learned\nmodel on local small data; therefore, HBR closes the technical loop for\napplying normative modeling as a medical tool for the diagnosis and prognosis\nof mental disorders.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 11:55:19 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Kia", "Seyed Mostafa", ""], ["Huijsdens", "Hester", ""], ["Dinga", "Richard", ""], ["Wolfers", "Thomas", ""], ["Mennes", "Maarten", ""], ["Andreassen", "Ole A.", ""], ["Westlye", "Lars T.", ""], ["Beckmann", "Christian F.", ""], ["Marquand", "Andre F.", ""]]}, {"id": "2005.12061", "submitter": "Kaiwen Zhou", "authors": "Kaiwen Zhou, Anthony Man-Cho So, James Cheng", "title": "Boosting First-Order Methods by Shifting Objective: New Schemes with\n  Faster Worst-Case Rates", "comments": "NeurIPS 2020, 29 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new methodology to design first-order methods for unconstrained\nstrongly convex problems. Specifically, instead of tackling the original\nobjective directly, we construct a shifted objective function that has the same\nminimizer as the original objective and encodes both the smoothness and strong\nconvexity of the original objective in an interpolation condition. We then\npropose an algorithmic template for tackling the shifted objective, which can\nexploit such a condition. Following this template, we derive several new\naccelerated schemes for problems that are equipped with various first-order\noracles and show that the interpolation condition allows us to vastly simplify\nand tighten the analysis of the derived methods. In particular, all the derived\nmethods have faster worst-case convergence rates than their existing\ncounterparts. Experiments on machine learning tasks are conducted to evaluate\nthe new methods.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 12:08:58 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 16:12:19 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Zhou", "Kaiwen", ""], ["So", "Anthony Man-Cho", ""], ["Cheng", "James", ""]]}, {"id": "2005.12062", "submitter": "Armin Lederer", "authors": "Armin Lederer, Alexandre Capone, Jonas Umlauft, Sandra Hirche", "title": "How Training Data Impacts Performance in Learning-based Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When first principle models cannot be derived due to the complexity of the\nreal system, data-driven methods allow us to build models from system\nobservations. As these models are employed in learning-based control, the\nquality of the data plays a crucial role for the performance of the resulting\ncontrol law. Nevertheless, there hardly exist measures for assessing training\ndata sets, and the impact of the distribution of the data on the closed-loop\nsystem properties is largely unknown. This paper derives - based on Gaussian\nprocess models - an analytical relationship between the density of the training\ndata and the control performance. We formulate a quality measure for the data\nset, which we refer to as $\\rho$-gap, and derive the ultimate bound for the\ntracking error under consideration of the model uncertainty. We show how the\n$\\rho$-gap can be applied to a feedback linearizing control law and provide\nnumerical illustrations for our approach.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 12:13:49 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Lederer", "Armin", ""], ["Capone", "Alexandre", ""], ["Umlauft", "Jonas", ""], ["Hirche", "Sandra", ""]]}, {"id": "2005.12069", "submitter": "Andreas Sedlmeier", "authors": "Andreas Sedlmeier and Robert M\\\"uller and Steffen Illium and Claudia\n  Linnhoff-Popien", "title": "Policy Entropy for Out-of-Distribution Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One critical prerequisite for the deployment of reinforcement learning\nsystems in the real world is the ability to reliably detect situations on which\nthe agent was not trained. Such situations could lead to potential safety risks\nwhen wrong predictions lead to the execution of harmful actions. In this work,\nwe propose PEOC, a new policy entropy based out-of-distribution classifier that\nreliably detects unencountered states in deep reinforcement learning. It is\nbased on using the entropy of an agent's policy as the classification score of\na one-class classifier. We evaluate our approach using a procedural environment\ngenerator. Results show that PEOC is highly competitive against\nstate-of-the-art one-class classification algorithms on the evaluated\nenvironments. Furthermore, we present a structured process for benchmarking\nout-of-distribution classification in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 12:18:20 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Sedlmeier", "Andreas", ""], ["M\u00fcller", "Robert", ""], ["Illium", "Steffen", ""], ["Linnhoff-Popien", "Claudia", ""]]}, {"id": "2005.12073", "submitter": "Matei Mancas", "authors": "Mancas Matei, Kong Phutphalla, Gosselin Bernard", "title": "Visual Attention: Deep Rare Features", "comments": "6 pages, double-colmun, accepted to IVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human visual system is modeled in engineering field providing\nfeature-engineered methods which detect contrasted/surprising/unusual data into\nimages. This data is \"interesting\" for humans and leads to numerous\napplications. Deep learning (DNNs) drastically improved the algorithms\nefficiency on the main benchmark datasets. However, DNN-based models are\ncounter-intuitive: surprising or unusual data is by definition difficult to\nlearn because of its low occurrence probability. In reality, DNNs models mainly\nlearn top-down features such as faces, text, people, or animals which usually\nattract human attention, but they have low efficiency in extracting surprising\nor unusual data in the images. In this paper, we propose a model called\nDeepRare2019 (DR) which uses the power of DNNs feature extraction and the\ngenericity of feature-engineered algorithms. DR 1) does not need any training,\n2) it takes less than a second per image on CPU only and 3) our tests on three\nvery different eye-tracking datasets show that DR is generic and is always in\nthe top-3 models on all datasets and metrics while no other model exhibits such\na regularity and genericity. DeepRare2019 code can be found at\nhttps://github.com/numediart/VisualAttention-RareFamily\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 12:28:08 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Matei", "Mancas", ""], ["Phutphalla", "Kong", ""], ["Bernard", "Gosselin", ""]]}, {"id": "2005.12099", "submitter": "Moritz Schubotz", "authors": "Moritz Schubotz and Philipp Scharpf and Olaf Teschke and Andreas\n  Kuehnemund and Corinna Breitinger and Bela Gipp", "title": "AutoMSC: Automatic Assignment of Mathematics Subject Classification\n  Labels", "comments": null, "journal-ref": "Intelligent Computer Mathematics - 13thInternational Conference,\n  {CICM} 2020, Bertinoro, Italy, July 26-31, 2020, Proceedings", "doi": "10.1007/978-3-030-53518-6_15", "report-no": null, "categories": "cs.DL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Authors of research papers in the fields of mathematics, and other math-heavy\ndisciplines commonly employ the Mathematics Subject Classification (MSC) scheme\nto search for relevant literature. The MSC is a hierarchical alphanumerical\nclassification scheme that allows librarians to specify one or multiple codes\nfor publications. Digital Libraries in Mathematics, as well as reviewing\nservices, such as zbMATH and Mathematical Reviews (MR) rely on these MSC labels\nin their workflows to organize the abstracting and reviewing process.\nEspecially, the coarse-grained classification determines the subject editor who\nis responsible for the actual reviewing process.\n  In this paper, we investigate the feasibility of automatically assigning a\ncoarse-grained primary classification using the MSC scheme, by regarding the\nproblem as a multi-class classification machine learning task. We find that our\nmethod achieves an (F_1)-score of over 77%, which is remarkably close to the\nagreement of zbMATH and MR ((F_1)-score of 81%). Moreover, we find that the\nmethod's confidence score allows for reducing the effort by 86% compared to the\nmanual coarse-grained classification effort while maintaining a precision of\n81% for automatically classified articles.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 13:26:45 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 07:12:34 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Schubotz", "Moritz", ""], ["Scharpf", "Philipp", ""], ["Teschke", "Olaf", ""], ["Kuehnemund", "Andreas", ""], ["Breitinger", "Corinna", ""], ["Gipp", "Bela", ""]]}, {"id": "2005.12108", "submitter": "Mohammed Sharafath Abdul Hameed", "authors": "Mohammed Sharafath Abdul Hameed (1), Gavneet Singh Chadha (1), Andreas\n  Schwung (1), and Steven X. Ding (2) ((1) South Westphalia University of\n  Applied Sciences, Germany (2) University of Duisburg-Essen, Germany)", "title": "Gradient Monitored Reinforcement Learning", "comments": "14 pages, 15 images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a novel neural network training approach for faster\nconvergence and better generalization abilities in deep reinforcement learning.\nParticularly, we focus on the enhancement of training and evaluation\nperformance in reinforcement learning algorithms by systematically reducing\ngradient's variance and thereby providing a more targeted learning process. The\nproposed method which we term as Gradient Monitoring(GM), is an approach to\nsteer the learning in the weight parameters of a neural network based on the\ndynamic development and feedback from the training process itself. We propose\ndifferent variants of the GM methodology which have been proven to increase the\nunderlying performance of the model. The one of the proposed variant, Momentum\nwith Gradient Monitoring (M-WGM), allows for a continuous adjustment of the\nquantum of back-propagated gradients in the network based on certain learning\nparameters. We further enhance the method with Adaptive Momentum with Gradient\nMonitoring (AM-WGM) method which allows for automatic adjustment between\nfocused learning of certain weights versus a more dispersed learning depending\non the feedback from the rewards collected. As a by-product, it also allows for\nautomatic derivation of the required deep network sizes during training as the\nalgorithm automatically freezes trained weights. The approach is applied to two\ndiscrete (Multi-Robot Co-ordination problem and Atari games) and one continuous\ncontrol task (MuJoCo) using Advantage Actor-Critic (A2C) and Proximal Policy\nOptimization (PPO) respectively. The results obtained particularly underline\nthe applicability and performance improvements of the methods in terms of\ngeneralization capability.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 13:45:47 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Hameed", "Mohammed Sharafath Abdul", ""], ["Chadha", "Gavneet Singh", ""], ["Schwung", "Andreas", ""], ["Ding", "Steven X.", ""]]}, {"id": "2005.12123", "submitter": "Makoto Yamada", "authors": "Mathis Petrovich and Chao Liang and Ryoma Sato and Yanbin Liu and\n  Yao-Hung Hubert Tsai and Linchao Zhu and Yi Yang and Ruslan Salakhutdinov and\n  Makoto Yamada", "title": "Feature Robust Optimal Transport for High-dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport is a machine learning problem with applications including\ndistribution comparison, feature selection, and generative adversarial\nnetworks. In this paper, we propose feature-robust optimal transport (FROT) for\nhigh-dimensional data, which solves high-dimensional OT problems using feature\nselection to avoid the curse of dimensionality. Specifically, we find a\ntransport plan with discriminative features. To this end, we formulate the FROT\nproblem as a min--max optimization problem. We then propose a convex\nformulation of the FROT problem and solve it using a Frank--Wolfe-based\noptimization algorithm, whereby the subproblem can be efficiently solved using\nthe Sinkhorn algorithm. Since FROT finds the transport plan from selected\nfeatures, it is robust to noise features. To show the effectiveness of FROT, we\npropose using the FROT algorithm for the layer selection problem in deep neural\nnetworks for semantic correspondence. By conducting synthetic and benchmark\nexperiments, we demonstrate that the proposed method can find a strong\ncorrespondence by determining important layers. We show that the FROT algorithm\nachieves state-of-the-art performance in real-world semantic correspondence\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 14:07:16 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 14:19:37 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 15:09:10 GMT"}, {"version": "v4", "created": "Tue, 29 Sep 2020 05:38:13 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Petrovich", "Mathis", ""], ["Liang", "Chao", ""], ["Sato", "Ryoma", ""], ["Liu", "Yanbin", ""], ["Tsai", "Yao-Hung Hubert", ""], ["Zhu", "Linchao", ""], ["Yang", "Yi", ""], ["Salakhutdinov", "Ruslan", ""], ["Yamada", "Makoto", ""]]}, {"id": "2005.12129", "submitter": "Matthew Davidow", "authors": "Matthew Davidow, David S. Matteson", "title": "Factor Analysis of Mixed Data for Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection aims to identify observations that deviate from the typical\npattern of data. Anomalous observations may correspond to financial fraud,\nhealth risks, or incorrectly measured data in practice. We show detecting\nanomalies in high-dimensional mixed data is enhanced through first embedding\nthe data then assessing an anomaly scoring scheme. We focus on unsupervised\ndetection and the continuous and categorical (mixed) variable case. We propose\na kurtosis-weighted Factor Analysis of Mixed Data for anomaly detection,\nFAMDAD, to obtain a continuous embedding for anomaly scoring. We illustrate\nthat anomalies are highly separable in the first and last few ordered\ndimensions of this space, and test various anomaly scoring experiments within\nthis subspace. Results are illustrated for both simulated and real datasets,\nand the proposed approach (FAMDAD) is highly accurate for high-dimensional\nmixed data throughout these diverse scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 14:13:10 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Davidow", "Matthew", ""], ["Matteson", "David S.", ""]]}, {"id": "2005.12137", "submitter": "Yipeng Hu", "authors": "Yipeng Hu, Joseph Jacob, Geoffrey JM Parker, David J Hawkes, John R\n  Hurst, Danail Stoyanov", "title": "The challenges of deploying artificial intelligence models in a rapidly\n  evolving pandemic", "comments": "Accepted in Nature Machine Intelligence", "journal-ref": null, "doi": "10.1038/s42256-020-0185-2", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic, caused by the severe acute respiratory syndrome\ncoronavirus 2, emerged into a world being rapidly transformed by artificial\nintelligence (AI) based on big data, computational power and neural networks.\nThe gaze of these networks has in recent years turned increasingly towards\napplications in healthcare. It was perhaps inevitable that COVID-19, a global\ndisease propagating health and economic devastation, should capture the\nattention and resources of the world's computer scientists in academia and\nindustry. The potential for AI to support the response to the pandemic has been\nproposed across a wide range of clinical and societal challenges, including\ndisease forecasting, surveillance and antiviral drug discovery. This is likely\nto continue as the impact of the pandemic unfolds on the world's people,\nindustries and economy but a surprising observation on the current pandemic has\nbeen the limited impact AI has had to date in the management of COVID-19. This\ncorrespondence focuses on exploring potential reasons behind the lack of\nsuccessful adoption of AI models developed for COVID-19 diagnosis and\nprognosis, in front-line healthcare services. We highlight the moving clinical\nneeds that models have had to address at different stages of the epidemic, and\nexplain the importance of translating models to reflect local healthcare\nenvironments. We argue that both basic and applied research are essential to\naccelerate the potential of AI models, and this is particularly so during a\nrapidly evolving pandemic. This perspective on the response to COVID-19, may\nprovide a glimpse into how the global scientific community should react to\ncombat future disease outbreaks more effectively.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 21:11:48 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Hu", "Yipeng", ""], ["Jacob", "Joseph", ""], ["Parker", "Geoffrey JM", ""], ["Hawkes", "David J", ""], ["Hurst", "John R", ""], ["Stoyanov", "Danail", ""]]}, {"id": "2005.12141", "submitter": "Manuel Dalcastagn\\'e", "authors": "Manuel Dalcastagn\\'e, Andrea Mariello, Roberto Battiti", "title": "Reactive Sample Size for Heuristic Search in Simulation-based\n  Optimization", "comments": "14 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In simulation-based optimization, the optimal setting of the input parameters\nof the objective function can be determined by heuristic optimization\ntechniques. However, when simulators model the stochasticity of real-world\nproblems, their output is a random variable and multiple evaluations of the\nobjective function are necessary to properly compare the expected performance\nof different parameter settings. This paper presents a novel reactive sample\nsize algorithm based on parametric tests and indifference-zone selection, which\ncan be used for improving the efficiency and robustness of heuristic\noptimization methods. The algorithm reactively decides, in an online manner,\nthe sample size to be used for each comparison during the optimization\naccording to observed statistical evidence. Tests employ benchmark functions\nextended with artificial levels of noise and a simulation-based optimization\ntool for hotel revenue management. Experimental results show that the reactive\nmethod can improve the efficiency and robustness of simulation-based\noptimization techniques.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 14:38:55 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Dalcastagn\u00e9", "Manuel", ""], ["Mariello", "Andrea", ""], ["Battiti", "Roberto", ""]]}, {"id": "2005.12147", "submitter": "Mayank Singh", "authors": "Mayank Kumar Singh, Sayan Banerjee, Shubhasis Chaudhuri", "title": "NENET: An Edge Learnable Network for Link Prediction in Scene Text", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Text detection in scenes based on deep neural networks have shown promising\nresults. Instead of using word bounding box regression, recent state-of-the-art\nmethods have started focusing on character bounding box and pixel-level\nprediction. This necessitates the need to link adjacent characters, which we\npropose in this paper using a novel Graph Neural Network (GNN) architecture\nthat allows us to learn both node and edge features as opposed to only the node\nfeatures under the typical GNN. The main advantage of using GNN for link\nprediction lies in its ability to connect characters which are spatially\nseparated and have an arbitrary orientation. We show our concept on the well\nknown SynthText dataset, achieving top results as compared to state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 14:47:16 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Singh", "Mayank Kumar", ""], ["Banerjee", "Sayan", ""], ["Chaudhuri", "Shubhasis", ""]]}, {"id": "2005.12150", "submitter": "Petar Radanliev", "authors": "Petar Radanliev, David De Roure, Kevin Page, Max Van Kleek, Omar\n  Santos, La Treall Maddox, Pete Burnap, Eirini Anthi, Carsten Maple", "title": "Design of a dynamic and self adapting system, supported with artificial\n  intelligence, machine learning and real time intelligence for predictive\n  cyber risk analytics in extreme environments, cyber risk in the colonisation\n  of Mars", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": "10.1007/s42797-021-00025-1", "report-no": null, "categories": "cs.CY cs.AI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multiple governmental agencies and private organisations have made\ncommitments for the colonisation of Mars. Such colonisation requires complex\nsystems and infrastructure that could be very costly to repair or replace in\ncases of cyber attacks. This paper surveys deep learning algorithms, IoT cyber\nsecurity and risk models, and established mathematical formulas to identify the\nbest approach for developing a dynamic and self adapting system for predictive\ncyber risk analytics supported with Artificial Intelligence and Machine\nLearning and real time intelligence in edge computing. The paper presents a new\nmathematical approach for integrating concepts for cognition engine design,\nedge computing and Artificial Intelligence and Machine Learning to automate\nanomaly detection. This engine instigates a step change by applying Artificial\nIntelligence and Machine Learning embedded at the edge of IoT networks, to\ndeliver safe and functional real time intelligence for predictive cyber risk\nanalytics. This will enhance capacities for risk analytics and assists in the\ncreation of a comprehensive and systematic understanding of the opportunities\nand threats that arise when edge computing nodes are deployed, and when\nArtificial Intelligence and Machine Learning technologies are migrated to the\nperiphery of the internet and into local IoT networks.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 15:42:45 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 20:36:26 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Radanliev", "Petar", ""], ["De Roure", "David", ""], ["Page", "Kevin", ""], ["Van Kleek", "Max", ""], ["Santos", "Omar", ""], ["Maddox", "La Treall", ""], ["Burnap", "Pete", ""], ["Anthi", "Eirini", ""], ["Maple", "Carsten", ""]]}, {"id": "2005.12154", "submitter": "Battista Biggio", "authors": "Fei Zhang, Patrick P.K. Chan, Battista Biggio, Daniel S. Yeung, Fabio\n  Roli", "title": "Adversarial Feature Selection against Evasion Attacks", "comments": null, "journal-ref": "IEEE Transactions on Cybernetics, vol. 46, no. 3, March 2016", "doi": "10.1109/TCYB.2015.2415032", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pattern recognition and machine learning techniques have been increasingly\nadopted in adversarial settings such as spam, intrusion and malware detection,\nalthough their security against well-crafted attacks that aim to evade\ndetection by manipulating data at test time has not yet been thoroughly\nassessed. While previous work has been mainly focused on devising\nadversary-aware classification algorithms to counter evasion attempts, only few\nauthors have considered the impact of using reduced feature sets on classifier\nsecurity against the same attacks. An interesting, preliminary result is that\nclassifier security to evasion may be even worsened by the application of\nfeature selection. In this paper, we provide a more detailed investigation of\nthis aspect, shedding some light on the security properties of feature\nselection against evasion attacks. Inspired by previous work on adversary-aware\nclassifiers, we propose a novel adversary-aware feature selection model that\ncan improve classifier security against evasion attacks, by incorporating\nspecific assumptions on the adversary's data manipulation strategy. We focus on\nan efficient, wrapper-based implementation of our approach, and experimentally\nvalidate its soundness on different application examples, including spam and\nmalware detection.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 15:05:51 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Zhang", "Fei", ""], ["Chan", "Patrick P. K.", ""], ["Biggio", "Battista", ""], ["Yeung", "Daniel S.", ""], ["Roli", "Fabio", ""]]}, {"id": "2005.12178", "submitter": "Alan Mazankiewicz", "authors": "Alan Mazankiewicz, Klemens B\\\"ohm, Mario Berg\\'es", "title": "Incremental Real-Time Personalization in Human Activity Recognition\n  Using Domain Adaptive Batch Normalization", "comments": "Updated version of the preprint from 05/2020 after going through\n  revision. The content (experiments, results, proposed method) has not\n  changed. The explanations changed. Certain sentences have been\n  added/removed/rephrased to be clearer. Removed Figure 3. Added Discussion\n  section. Renamed \"Description of Approach\" Section. Added a reference to\n  related work", "journal-ref": "Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 4, 4,\n  Article 144 (December 2020), 20 pages", "doi": "10.1145/3432230", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human Activity Recognition (HAR) from devices like smartphone accelerometers\nis a fundamental problem in ubiquitous computing. Machine learning based\nrecognition models often perform poorly when applied to new users that were not\npart of the training data. Previous work has addressed this challenge by\npersonalizing general recognition models to the unique motion pattern of a new\nuser in a static batch setting. They require target user data to be available\nupfront. The more challenging online setting has received less attention. No\nsamples from the target user are available in advance, but they arrive\nsequentially. Additionally, the motion pattern of users may change over time.\nThus, adapting to new and forgetting old information must be traded off.\nFinally, the target user should not have to do any work to use the recognition\nsystem by, say, labeling any activities. Our work addresses all of these\nchallenges by proposing an unsupervised online domain adaptation algorithm.\nBoth classification and personalization happen continuously and incrementally\nin real time. Our solution works by aligning the feature distributions of all\nsubjects, be they sources or the target, in hidden neural network layers. To\nthis end, we normalize the input of a layer with user-specific mean and\nvariance statistics. During training, these statistics are computed over\nuser-specific batches. In the online phase, they are estimated incrementally\nfor any new target user.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 15:49:10 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 14:13:48 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Mazankiewicz", "Alan", ""], ["B\u00f6hm", "Klemens", ""], ["Berg\u00e9s", "Mario", ""]]}, {"id": "2005.12181", "submitter": "Prashant Shenoy", "authors": "Menghong Feng, Noman Bashir, Prashant Shenoy, David Irwin, Beka\n  Kosanovic", "title": "SunDown: Model-driven Per-Panel Solar Anomaly Detection for Residential\n  Arrays", "comments": "13 pages, 13 figures. Extended version of a paper that will appear in\n  the Proceedings of the ACM SIGCAS Conference on Computing and Sustainable\n  Societies (COMPASS '20), June 2020, Ecuador", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been significant growth in both utility-scale and residential-scale\nsolar installations in recent years, driven by rapid technology improvements\nand falling prices. Unlike utility-scale solar farms that are professionally\nmanaged and maintained, smaller residential-scale installations often lack\nsensing and instrumentation for performance monitoring and fault detection. As\na result, faults may go undetected for long periods of time, resulting in\ngeneration and revenue losses for the homeowner. In this paper, we present\nSunDown, a sensorless approach designed to detect per-panel faults in\nresidential solar arrays. SunDown does not require any new sensors for its\nfault detection and instead uses a model-driven approach that leverages\ncorrelations between the power produced by adjacent panels to detect deviations\nfrom expected behavior. SunDown can handle concurrent faults in multiple panels\nand perform anomaly classification to determine probable causes. Using two\nyears of solar generation data from a real home and a manually generated\ndataset of multiple solar faults, we show that our approach has a MAPE of\n2.98\\% when predicting per-panel output. Our results also show that SunDown is\nable to detect and classify faults, including from snow cover, leaves and\ndebris, and electrical failures with 99.13% accuracy, and can detect multiple\nconcurrent faults with 97.2% accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 15:54:30 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Feng", "Menghong", ""], ["Bashir", "Noman", ""], ["Shenoy", "Prashant", ""], ["Irwin", "David", ""], ["Kosanovic", "Beka", ""]]}, {"id": "2005.12183", "submitter": "Filippo Masi", "authors": "Filippo Masi, Ioannis Stefanou, Paolo Vannucci, Victor Maffi-Berthier", "title": "Thermodynamics-based Artificial Neural Networks for constitutive\n  modeling", "comments": null, "journal-ref": "Journal of the Mechanics and Physics of Solids, 147, 104277 (2021)", "doi": "10.1016/j.jmps.2020.104277", "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning methods and, in particular, Artificial Neural Networks\n(ANNs) have demonstrated promising capabilities in material constitutive\nmodeling. One of the main drawbacks of such approaches is the lack of a\nrigorous frame based on the laws of physics. This may render physically\ninconsistent the predictions of a trained network, which can be even dangerous\nfor real applications.\n  Here we propose a new class of data-driven, physics-based, neural networks\nfor constitutive modeling of strain rate independent processes at the material\npoint level, which we define as Thermodynamics-based Artificial Neural Networks\n(TANNs). The two basic principles of thermodynamics are encoded in the\nnetwork's architecture by taking advantage of automatic differentiation to\ncompute the numerical derivatives of a network with respect to its inputs. In\nthis way, derivatives of the free-energy, the dissipation rate and their\nrelation with the stress and internal state variables are hardwired in the\nnetwork. Consequently, our network does not have to identify the underlying\npattern of thermodynamic laws during training, reducing the need of large\ndata-sets. Moreover the training is more efficient and robust, and the\npredictions more accurate. Finally and more important, the predictions remain\nthermodynamically consistent, even for unseen data. Based on these features,\nTANNs are a starting point for data-driven, physics-based constitutive modeling\nwith neural networks.\n  We demonstrate the wide applicability of TANNs for modeling elasto-plastic\nmaterials, with strain hardening and strain softening. Detailed comparisons\nshow that the predictions of TANNs outperform those of standard ANNs. TANNs '\narchitecture is general, enabling applications to materials with different or\nmore complex behavior, without any modification.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 15:56:34 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Masi", "Filippo", ""], ["Stefanou", "Ioannis", ""], ["Vannucci", "Paolo", ""], ["Maffi-Berthier", "Victor", ""]]}, {"id": "2005.12186", "submitter": "Philipp Behrendt", "authors": "Philipp Behrendt", "title": "Learnability of Timescale Graphical Event Models", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report tries to fill a gap in current literature on Timescale\nGraphical Event Models. I propose and evaluate different heuristics to\ndetermine hyper-parameters during the structure learning algorithm and refine\nan existing distance measure. A comprehensive benchmark on synthetic data will\nbe conducted allowing conclusions about the applicability of the different\nheuristics.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 15:57:22 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Behrendt", "Philipp", ""]]}, {"id": "2005.12187", "submitter": "Juri Opitz", "authors": "Juri Opitz", "title": "AMR Quality Rating with a Lightweight CNN", "comments": "AACL-IJCNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured semantic sentence representations such as Abstract Meaning\nRepresentations (AMRs) are potentially useful in various NLP tasks. However,\nthe quality of automatic parses can vary greatly and jeopardizes their\nusefulness. This can be mitigated by models that can accurately rate AMR\nquality in the absence of costly gold data, allowing us to inform downstream\nsystems about an incorporated parse's trustworthiness or select among different\ncandidate parses.\n  In this work, we propose to transfer the AMR graph to the domain of images.\nThis allows us to create a simple convolutional neural network (CNN) that\nimitates a human judge tasked with rating graph quality. Our experiments show\nthat the method can rate quality more accurately than strong baselines, in\nseveral quality dimensions. Moreover, the method proves to be efficient and\nreduces the incurred energy consumption.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 15:58:00 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 17:15:51 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Opitz", "Juri", ""]]}, {"id": "2005.12188", "submitter": "Mona Minakshi", "authors": "Mona Minakshi, Pratool Bharti, Willie B. McClinton III, Jamshidbek\n  Mirzakhalov, Ryan M. Carney, Sriram Chellappan", "title": "Automating the Surveillance of Mosquito Vectors from Trapped Specimens\n  Using Computer Vision Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among all animals, mosquitoes are responsible for the most deaths worldwide.\nInterestingly, not all types of mosquitoes spread diseases, but rather, a\nselect few alone are competent enough to do so. In the case of any disease\noutbreak, an important first step is surveillance of vectors (i.e., those\nmosquitoes capable of spreading diseases). To do this today, public health\nworkers lay several mosquito traps in the area of interest. Hundreds of\nmosquitoes will get trapped. Naturally, among these hundreds, taxonomists have\nto identify only the vectors to gauge their density. This process today is\nmanual, requires complex expertise/ training, and is based on visual inspection\nof each trapped specimen under a microscope. It is long, stressful and\nself-limiting. This paper presents an innovative solution to this problem. Our\ntechnique assumes the presence of an embedded camera (similar to those in\nsmart-phones) that can take pictures of trapped mosquitoes. Our techniques\nproposed here will then process these images to automatically classify the\ngenus and species type. Our CNN model based on Inception-ResNet V2 and Transfer\nLearning yielded an overall accuracy of 80% in classifying mosquitoes when\ntrained on 25,867 images of 250 trapped mosquito vector specimens captured via\nmany smart-phone cameras. In particular, the accuracy of our model in\nclassifying Aedes aegypti and Anopheles stephensi mosquitoes (both of which are\ndeadly vectors) is amongst the highest. We present important lessons learned\nand practical impact of our techniques towards the end of the paper.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 15:58:27 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 19:58:45 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Minakshi", "Mona", ""], ["Bharti", "Pratool", ""], ["McClinton", "Willie B.", "III"], ["Mirzakhalov", "Jamshidbek", ""], ["Carney", "Ryan M.", ""], ["Chellappan", "Sriram", ""]]}, {"id": "2005.12193", "submitter": "Hang Li", "authors": "Hang Li, Chen Ma, Wei Xu and Xue Liu", "title": "Feature Statistics Guided Efficient Filter Pruning", "comments": "To appear in Proceedings of IJCAI 2020 (copyright held by IJCAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building compact convolutional neural networks (CNNs) with reliable\nperformance is a critical but challenging task, especially when deploying them\nin real-world applications. As a common approach to reduce the size of CNNs,\npruning methods delete part of the CNN filters according to some metrics such\nas $l1$-norm. However, previous methods hardly leverage the information\nvariance in a single feature map and the similarity characteristics among\nfeature maps. In this paper, we propose a novel filter pruning method, which\nincorporates two kinds of feature map selections: diversity-aware selection\n(DFS) and similarity-aware selection (SFS). DFS aims to discover features with\nlow information diversity while SFS removes features that have high\nsimilarities with others. We conduct extensive empirical experiments with\nvarious CNN architectures on publicly available datasets. The experimental\nresults demonstrate that our model obtains up to 91.6% parameter decrease and\n83.7% FLOPs reduction with almost no accuracy loss.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 01:50:55 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Li", "Hang", ""], ["Ma", "Chen", ""], ["Xu", "Wei", ""], ["Liu", "Xue", ""]]}, {"id": "2005.12195", "submitter": "Christopher Kello", "authors": "Mohammad K. Ebrahimpour, Timothy Shea, Andreea Danielescu, David C.\n  Noelle, Christopher T. Kello", "title": "End-to-End Auditory Object Recognition via Inception Nucleus", "comments": "Published In proceedings of ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning approaches to auditory object recognition are traditionally\nbased on engineered features such as those derived from the spectrum or\ncepstrum. More recently, end-to-end classification systems in image and\nauditory recognition systems have been developed to learn features jointly with\nclassification and result in improved classification accuracy. In this paper,\nwe propose a novel end-to-end deep neural network to map the raw waveform\ninputs to sound class labels. Our network includes an \"inception nucleus\" that\noptimizes the size of convolutional filters on the fly that results in reducing\nengineering efforts dramatically. Classification results compared favorably\nagainst current state-of-the-art approaches, besting them by 10.4 percentage\npoints on the Urbansound8k dataset. Analyses of learned representations\nrevealed that filters in the earlier hidden layers learned wavelet-like\ntransforms to extract features that were informative for classification.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 16:08:41 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Ebrahimpour", "Mohammad K.", ""], ["Shea", "Timothy", ""], ["Danielescu", "Andreea", ""], ["Noelle", "David C.", ""], ["Kello", "Christopher T.", ""]]}, {"id": "2005.12206", "submitter": "Qingpeng Cai", "authors": "Jianxiong Wei, Anxiang Zeng, Yueqiu Wu, Peng Guo, Qingsong Hua,\n  Qingpeng Cai", "title": "Generator and Critic: A Deep Reinforcement Learning Approach for Slate\n  Re-ranking in E-commerce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The slate re-ranking problem considers the mutual influences between items to\nimprove user satisfaction in e-commerce, compared with the point-wise ranking.\nPrevious works either directly rank items by an end to end model, or rank items\nby a score function that trades-off the point-wise score and the diversity\nbetween items. However, there are two main existing challenges that are not\nwell studied: (1) the evaluation of the slate is hard due to the complex mutual\ninfluences between items of one slate; (2) even given the optimal evaluation,\nsearching the optimal slate is challenging as the action space is exponentially\nlarge. In this paper, we present a novel Generator and Critic slate re-ranking\napproach, where the Critic evaluates the slate and the Generator ranks the\nitems by the reinforcement learning approach. We propose a Full Slate Critic\n(FSC) model that considers the real impressed items and avoids the impressed\nbias of existing models. For the Generator, to tackle the problem of large\naction space, we propose a new exploration reinforcement learning algorithm,\ncalled PPO-Exploration. Experimental results show that the FSC model\nsignificantly outperforms the state of the art slate evaluation methods, and\nthe PPO-Exploration algorithm outperforms the existing reinforcement learning\nmethods substantially. The Generator and Critic approach improves both the\nslate efficiency(4% gmv and 5% number of orders) and diversity in live\nexperiments on one of the largest e-commerce websites in the world.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 16:24:01 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Wei", "Jianxiong", ""], ["Zeng", "Anxiang", ""], ["Wu", "Yueqiu", ""], ["Guo", "Peng", ""], ["Hua", "Qingsong", ""], ["Cai", "Qingpeng", ""]]}, {"id": "2005.12210", "submitter": "Noveen Sachdeva", "authors": "Noveen Sachdeva, Julian McAuley", "title": "How Useful are Reviews for Recommendation? A Critical Review and\n  Potential Improvements", "comments": "4 pages, 3 figures. Accepted for publication at SIGIR '20", "journal-ref": null, "doi": "10.1145/3397271.3401281", "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a growing body of work that seeks to improve recommender\nsystems through the use of review text. Generally, these papers argue that\nsince reviews 'explain' users' opinions, they ought to be useful to infer the\nunderlying dimensions that predict ratings or purchases. Schemes to incorporate\nreviews range from simple regularizers to neural network approaches. Our\ninitial findings reveal several discrepancies in reported results, partly due\nto (e.g.) copying results across papers despite changes in experimental\nsettings or data pre-processing. First, we attempt a comprehensive analysis to\nresolve these ambiguities. Further investigation calls for discussion on a much\nlarger problem about the \"importance\" of user reviews for recommendation.\nThrough a wide range of experiments, we observe several cases where\nstate-of-the-art methods fail to outperform existing baselines, especially as\nwe deviate from a few narrowly-defined settings where reviews are useful. We\nconclude by providing hypotheses for our observations, that seek to\ncharacterize under what conditions reviews are likely to be helpful. Through\nthis work, we aim to evaluate the direction in which the field is progressing\nand encourage robust empirical evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 16:30:05 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Sachdeva", "Noveen", ""], ["McAuley", "Julian", ""]]}, {"id": "2005.12230", "submitter": "Alptekin Temizel", "authors": "At{\\i}l \\.Ilerialkan, Alptekin Temizel, H\\\"useyin Hac{\\i}habibo\\u{g}lu", "title": "Speaker and Posture Classification using Instantaneous Intraspeech\n  Breathing Features", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic features extracted from speech are widely used in problems such as\nbiometric speaker identification and first-person activity detection. However,\nthe use of speech for such purposes raises privacy issues as the content is\naccessible to the processing party. In this work, we propose a method for\nspeaker and posture classification using intraspeech breathing sounds.\nInstantaneous magnitude features are extracted using the Hilbert-Huang\ntransform (HHT) and fed into a CNN-GRU network for classification of recordings\nfrom the open intraspeech breathing sound dataset, BreathBase, that we\ncollected for this study. Using intraspeech breathing sounds, 87% speaker\nclassification, and 98% posture classification accuracy were obtained.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 17:00:26 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["\u0130lerialkan", "At\u0131l", ""], ["Temizel", "Alptekin", ""], ["Hac\u0131habibo\u011flu", "H\u00fcseyin", ""]]}, {"id": "2005.12235", "submitter": "Sheng Zhou", "authors": "Xiufeng Huang, Sheng Zhou", "title": "Dynamic Compression Ratio Selection for Edge Inference Systems with Hard\n  Deadlines", "comments": "11 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implementing machine learning algorithms on Internet of things (IoT) devices\nhas become essential for emerging applications, such as autonomous driving,\nenvironment monitoring. But the limitations of computation capability and\nenergy consumption make it difficult to run complex machine learning algorithms\non IoT devices, especially when latency deadline exists. One solution is to\noffload the computation intensive tasks to the edge server. However, the\nwireless uploading of the raw data is time consuming and may lead to deadline\nviolation. To reduce the communication cost, lossy data compression can be\nexploited for inference tasks, but may bring more erroneous inference results.\nIn this paper, we propose a dynamic compression ratio selection scheme for edge\ninference system with hard deadlines. The key idea is to balance the tradeoff\nbetween communication cost and inference accuracy. By dynamically selecting the\noptimal compression ratio with the remaining deadline budgets for queued tasks,\nmore tasks can be timely completed with correct inference under limited\ncommunication resources. Furthermore, information augmentation that retransmits\nless compressed data of task with erroneous inference, is proposed to enhance\nthe accuracy performance. While it is often hard to know the correctness of\ninference, we use uncertainty to estimate the confidence of the inference, and\nbased on that, jointly optimize the information augmentation and compression\nratio selection. Lastly, considering the wireless transmission errors, we\nfurther design a retransmission scheme to reduce performance degradation due to\npacket losses. Simulation results show the performance of the proposed schemes\nunder different deadlines and task arrival rates.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 17:11:53 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Huang", "Xiufeng", ""], ["Zhou", "Sheng", ""]]}, {"id": "2005.12242", "submitter": "Paul Ferrand", "authors": "Paul Ferrand and Alexis Decurninge and Luis G. Ordo\\~nez and Maxime\n  Guillaud", "title": "Triplet-Based Wireless Channel Charting: Architecture and Experiments", "comments": "Accepted for publication in IEEE JSAC Series on Machine Learning for\n  Communications and Networks. A conference version was published in IEEE\n  Globecom 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel charting is a data-driven baseband processing technique consisting in\napplying self-supervised machine learning techniques to channel state\ninformation (CSI), with the objective of reducing the dimension of the data and\nextracting the fundamental parameters governing its distribution. We introduce\na novel channel charting approach based on triplets of samples. The proposed\nalgorithm learns a meaningful similarity metric between CSI samples on the\nbasis of proximity in their respective acquisition times, and simultaneously\nperforms dimensionality reduction. We present an extensive experimental\nvalidation of the proposed approach on data obtained from a commercial Massive\nMIMO system; in particular, we evaluate to which extent the obtained channel\nchart is similar to the user location information, although it is not\nsupervised by any geographical data. Finally, we propose and evaluate\nvariations in the channel charting process, including the partially supervised\ncase where some labels are available for part of the dataset.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 17:29:31 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 14:03:10 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Ferrand", "Paul", ""], ["Decurninge", "Alexis", ""], ["Ordo\u00f1ez", "Luis G.", ""], ["Guillaud", "Maxime", ""]]}, {"id": "2005.12244", "submitter": "Can Chen", "authors": "Can Chen, Amit Surana, Anthony Bloch, Indika Rajapakse", "title": "Controllability of Hypergraphs", "comments": "12 pages, 9 figures, 1 table, IEEE Transactions on Network Science\n  and Engineering, accepted to appear", "journal-ref": null, "doi": "10.1109/TNSE.2021.3068203", "report-no": null, "categories": "math.OC cs.LG cs.SI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a notion of controllability for hypergraphs via\ntensor algebra and polynomial control theory. Inspired by uniform hypergraphs,\nwe propose a new tensor-based multilinear dynamical system representation, and\nderive a Kalman-rank-like condition to determine the minimum number of control\nnodes (MCN) needed to achieve controllability of even uniform hypergraphs. We\npresent an efficient heuristic to obtain the MCN. MCN can be used as a measure\nof robustness, and we show that it is related to the hypergraph degree\ndistribution in simulated examples. Finally, we use MCN to examine robustness\nin real biological networks.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 17:33:32 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 16:34:24 GMT"}, {"version": "v3", "created": "Sat, 20 Mar 2021 18:29:53 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Chen", "Can", ""], ["Surana", "Amit", ""], ["Bloch", "Anthony", ""], ["Rajapakse", "Indika", ""]]}, {"id": "2005.12250", "submitter": "Dat Thanh Tran", "authors": "Dat Thanh Tran, Nikolaos Passalis, Anastasios Tefas, Moncef Gabbouj,\n  Alexandros Iosifidis", "title": "Attention-based Neural Bag-of-Features Learning for Sequence Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose 2D-Attention (2DA), a generic attention formulation\nfor sequence data, which acts as a complementary computation block that can\ndetect and focus on relevant sources of information for the given learning\nobjective. The proposed attention module is incorporated into the recently\nproposed Neural Bag of Feature (NBoF) model to enhance its learning capacity.\nSince 2DA acts as a plug-in layer, injecting it into different computation\nstages of the NBoF model results in different 2DA-NBoF architectures, each of\nwhich possesses a unique interpretation. We conducted extensive experiments in\nfinancial forecasting, audio analysis as well as medical diagnosis problems to\nbenchmark the proposed formulations in comparison with existing methods,\nincluding the widely used Gated Recurrent Units. Our empirical analysis shows\nthat the proposed attention formulations can not only improve performances of\nNBoF models but also make them resilient to noisy data.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 17:51:54 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Tran", "Dat Thanh", ""], ["Passalis", "Nikolaos", ""], ["Tefas", "Anastasios", ""], ["Gabbouj", "Moncef", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "2005.12254", "submitter": "Jaskirat Singh", "authors": "Jaskirat Singh and Liang Zheng", "title": "Dynamic Value Estimation for Single-Task Multi-Scene Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep reinforcement learning agents on environments with multiple\nlevels / scenes / conditions from the same task, has become essential for many\napplications aiming to achieve generalization and domain transfer from\nsimulation to the real world. While such a strategy is helpful with\ngeneralization, the use of multiple scenes significantly increases the variance\nof samples collected for policy gradient computations. Current methods continue\nto view this collection of scenes as a single Markov Decision Process (MDP)\nwith a common value function; however, we argue that it is better to treat the\ncollection as a single environment with multiple underlying MDPs. To this end,\nwe propose a dynamic value estimation (DVE) technique for these multiple-MDP\nenvironments, motivated by the clustering effect observed in the value function\ndistribution across different scenes. The resulting agent is able to learn a\nmore accurate and scene-specific value function estimate (and hence the\nadvantage function), leading to a lower sample variance. Our proposed approach\nis simple to accommodate with several existing implementations (like PPO, A3C)\nand results in consistent improvements for a range of ProcGen environments and\nthe AI2-THOR framework based visual navigation task.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 17:56:08 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Singh", "Jaskirat", ""], ["Zheng", "Liang", ""]]}, {"id": "2005.12256", "submitter": "Devendra Singh Chaplot", "authors": "Devendra Singh Chaplot, Ruslan Salakhutdinov, Abhinav Gupta, Saurabh\n  Gupta", "title": "Neural Topological SLAM for Visual Navigation", "comments": "Published in CVPR 2020. See the project webpage at\n  https://devendrachaplot.github.io/projects/Neural-Topological-SLAM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of image-goal navigation which involves\nnavigating to the location indicated by a goal image in a novel previously\nunseen environment. To tackle this problem, we design topological\nrepresentations for space that effectively leverage semantics and afford\napproximate geometric reasoning. At the heart of our representations are nodes\nwith associated semantic features, that are interconnected using coarse\ngeometric information. We describe supervised learning-based algorithms that\ncan build, maintain and use such representations under noisy actuation.\nExperimental study in visually and physically realistic simulation suggests\nthat our method builds effective representations that capture structural\nregularities and efficiently solve long-horizon navigation problems. We observe\na relative improvement of more than 50% over existing methods that study this\ntask.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 17:56:29 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 22:56:12 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Chaplot", "Devendra Singh", ""], ["Salakhutdinov", "Ruslan", ""], ["Gupta", "Abhinav", ""], ["Gupta", "Saurabh", ""]]}, {"id": "2005.12263", "submitter": "Chun-Na Li", "authors": "Xiang-Fei Yang, Yuan-Hai Shao, Chun-Na Li, Li-Ming Liu, Nai-Yang Deng", "title": "Principal Component Analysis Based on T$\\ell_1$-norm Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical principal component analysis (PCA) may suffer from the sensitivity\nto outliers and noise. Therefore PCA based on $\\ell_1$-norm and $\\ell_p$-norm\n($0 < p < 1$) have been studied. Among them, the ones based on $\\ell_p$-norm\nseem to be most interesting from the robustness point of view. However, their\nnumerical performance is not satisfactory. Note that, although T$\\ell_1$-norm\nis similar to $\\ell_p$-norm ($0 < p < 1$) in some sense, it has the stronger\nsuppression effect to outliers and better continuity. So PCA based on\nT$\\ell_1$-norm is proposed in this paper. Our numerical experiments have shown\nthat its performance is superior than PCA-$\\ell_p$ and $\\ell_p$SPCA as well as\nPCA, PCA-$\\ell_1$ obviously.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 04:28:45 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Yang", "Xiang-Fei", ""], ["Shao", "Yuan-Hai", ""], ["Li", "Chun-Na", ""], ["Liu", "Li-Ming", ""], ["Deng", "Nai-Yang", ""]]}, {"id": "2005.12267", "submitter": "Fadi Salo", "authors": "Fadi Salo, MohammadNoor Injadat, Ali Bou Nassif, Aleksander Essex", "title": "Data Mining with Big Data in Intrusion Detection Systems: A Systematic\n  Literature Review", "comments": "8 Pages, 5 Figures, to be appeared in the proceedings of the\n  International Symposium on Big Data Management and Analytics. April 25-26,\n  2019, Calgary, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cloud computing has become a powerful and indispensable technology for\ncomplex, high performance and scalable computation. The exponential expansion\nin the deployment of cloud technology has produced a massive amount of data\nfrom a variety of applications, resources and platforms. In turn, the rapid\nrate and volume of data creation has begun to pose significant challenges for\ndata management and security. The design and deployment of intrusion detection\nsystems (IDS) in the big data setting has, therefore, become a topic of\nimportance. In this paper, we conduct a systematic literature review (SLR) of\ndata mining techniques (DMT) used in IDS-based solutions through the period\n2013-2018. We employed criterion-based, purposive sampling identifying 32\narticles, which constitute the primary source of the present survey. After a\ncareful investigation of these articles, we identified 17 separate DMTs\ndeployed in an IDS context. This paper also presents the merits and\ndisadvantages of the various works of current research that implemented DMTs\nand distributed streaming frameworks (DSF) to detect and/or prevent malicious\nattacks in a big data environment.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 20:57:12 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Salo", "Fadi", ""], ["Injadat", "MohammadNoor", ""], ["Nassif", "Ali Bou", ""], ["Essex", "Aleksander", ""]]}, {"id": "2005.12270", "submitter": "Miad Zandavi Mr", "authors": "Seid Miad Zandavi, Taha Hossein Rashidi, Fatemeh Vafaee", "title": "Forecasting the Spread of Covid-19 Under Control Scenarios Using LSTM\n  and Dynamic Behavioral Models", "comments": "As requested by the dear moderator, to assess the statistical\n  significance of the reduction in RMSE in hybrid models compared to LSTM, each\n  module was evaluated 500 times after hype-parameter tuning, and the\n  corresponding RMSE distribution was used to estimate 95% confidence interval\n  (CI) and t-test p-values comparing significant differences between different\n  stages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To accurately predict the regional spread of Covid-19 infection, this study\nproposes a novel hybrid model which combines a Long short-term memory (LSTM)\nartificial recurrent neural network with dynamic behavioral models. Several\nfactors and control strategies affect the virus spread, and the uncertainty\narisen from confounding variables underlying the spread of the Covid-19\ninfection is substantial. The proposed model considers the effect of multiple\nfactors to enhance the accuracy in predicting the number of cases and deaths\nacross the top ten most-affected countries and Australia. The results show that\nthe proposed model closely replicates test data. It not only provides accurate\npredictions but also estimates the daily behavior of the system under\nuncertainty. The hybrid model outperforms the LSTM model accounting for limited\navailable data. The parameters of the hybrid models were optimized using a\ngenetic algorithm for each country to improve the prediction power while\nconsidering regional properties. Since the proposed model can accurately\npredict Covid-19 spread under consideration of containment policies, is capable\nof being used for policy assessment, planning and decision-making.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 10:43:55 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Zandavi", "Seid Miad", ""], ["Rashidi", "Taha Hossein", ""], ["Vafaee", "Fatemeh", ""]]}, {"id": "2005.12320", "submitter": "Wouter Van Gansbeke", "authors": "Wouter Van Gansbeke, Simon Vandenhende, Stamatios Georgoulis, Marc\n  Proesmans, Luc Van Gool", "title": "SCAN: Learning to Classify Images without Labels", "comments": "Accepted at ECCV 2020. Includes supplementary. Code and pretrained\n  models at https://github.com/wvangansbeke/Unsupervised-Classification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we automatically group images into semantically meaningful clusters when\nground-truth annotations are absent? The task of unsupervised image\nclassification remains an important, and open challenge in computer vision.\nSeveral recent approaches have tried to tackle this problem in an end-to-end\nfashion. In this paper, we deviate from recent works, and advocate a two-step\napproach where feature learning and clustering are decoupled. First, a\nself-supervised task from representation learning is employed to obtain\nsemantically meaningful features. Second, we use the obtained features as a\nprior in a learnable clustering approach. In doing so, we remove the ability\nfor cluster learning to depend on low-level features, which is present in\ncurrent end-to-end learning approaches. Experimental evaluation shows that we\noutperform state-of-the-art methods by large margins, in particular +26.6% on\nCIFAR10, +25.0% on CIFAR100-20 and +21.3% on STL10 in terms of classification\naccuracy. Furthermore, our method is the first to perform well on a large-scale\ndataset for image classification. In particular, we obtain promising results on\nImageNet, and outperform several semi-supervised learning methods in the\nlow-data regime without the use of any ground-truth annotations. The code is\nmade publicly available at\nhttps://github.com/wvangansbeke/Unsupervised-Classification.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 18:12:33 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 15:25:54 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Van Gansbeke", "Wouter", ""], ["Vandenhende", "Simon", ""], ["Georgoulis", "Stamatios", ""], ["Proesmans", "Marc", ""], ["Van Gool", "Luc", ""]]}, {"id": "2005.12326", "submitter": "Cong Wang", "authors": "Cong Wang, Yuanyuan Yang and Pengzhan Zhou", "title": "Towards Efficient Scheduling of Federated Mobile Devices under\n  Computational and Statistical Heterogeneity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Originated from distributed learning, federated learning enables\nprivacy-preserved collaboration on a new abstracted level by sharing the model\nparameters only. While the current research mainly focuses on optimizing\nlearning algorithms and minimizing communication overhead left by distributed\nlearning, there is still a considerable gap when it comes to the real\nimplementation on mobile devices. In this paper, we start with an empirical\nexperiment to demonstrate computation heterogeneity is a more pronounced\nbottleneck than communication on the current generation of battery-powered\nmobile devices, and the existing methods are haunted by mobile stragglers.\nFurther, non-identically distributed data across the mobile users makes the\nselection of participants critical to the accuracy and convergence. To tackle\nthe computational and statistical heterogeneity, we utilize data as a tuning\nknob and propose two efficient polynomial-time algorithms to schedule different\nworkloads on various mobile devices, when data is identically or\nnon-identically distributed. For identically distributed data, we combine\npartitioning and linear bottleneck assignment to achieve near-optimal training\ntime without accuracy loss. For non-identically distributed data, we convert it\ninto an average cost minimization problem and propose a greedy algorithm to\nfind a reasonable balance between computation time and accuracy. We also\nestablish an offline profiler to quantify the runtime behavior of different\ndevices, which serves as the input to the scheduling algorithms. We conduct\nextensive experiments on a mobile testbed with two datasets and up to 20\ndevices. Compared with the common benchmarks, the proposed algorithms achieve\n2-100x speedup epoch-wise, 2-7% accuracy gain and boost the convergence rate by\nmore than 100% on CIFAR10.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 18:21:51 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 18:12:30 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Wang", "Cong", ""], ["Yang", "Yuanyuan", ""], ["Zhou", "Pengzhan", ""]]}, {"id": "2005.12327", "submitter": "Bashar Awwad Shiekh Hasan", "authors": "Bashar Awwad Shiekh Hasan and Kate Kelly", "title": "Bayesian Stress Testing of Models in a Classification Hierarchy", "comments": "12 pages, 8 figures, conference paper accepted in WCCI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building a machine learning solution in real-life applications often involves\nthe decomposition of the problem into multiple models of various complexity.\nThis has advantages in terms of overall performance, better interpretability of\nthe outcomes, and easier model maintenance. In this work we propose a Bayesian\nframework to model the interaction amongst models in such a hierarchy. We show\nthat the framework can facilitate stress testing of the overall solution,\ngiving more confidence in its expected performance prior to active deployment.\nFinally, we test the proposed framework on a toy problem and financial fraud\ndetection dataset to demonstrate how it can be applied for any machine learning\nbased solution, regardless of the underlying modelling required.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 18:22:07 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Hasan", "Bashar Awwad Shiekh", ""], ["Kelly", "Kate", ""]]}, {"id": "2005.12339", "submitter": "Dan Roth", "authors": "Dan Roth", "title": "Incidental Supervision: Moving beyond Supervised Learning", "comments": "6 pages, 1 figure. Appeared in AAAI-17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning and Inference methods have become ubiquitous in our attempt\nto induce more abstract representations of natural language text, visual\nscenes, and other messy, naturally occurring data, and support decisions that\ndepend on it. However, learning models for these tasks is difficult partly\nbecause generating the necessary supervision signals for it is costly and does\nnot scale. This paper describes several learning paradigms that are designed to\nalleviate the supervision bottleneck. It will illustrate their benefit in the\ncontext of multiple problems, all pertaining to inducing various levels of\nsemantic representations from text.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 18:44:53 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Roth", "Dan", ""]]}, {"id": "2005.12359", "submitter": "Michael Moor", "authors": "Michael Moor, Max Horn, Christian Bock, Karsten Borgwardt, Bastian\n  Rieck", "title": "Path Imputation Strategies for Signature Models of Irregular Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The signature transform is a 'universal nonlinearity' on the space of\ncontinuous vector-valued paths, and has received attention for use in machine\nlearning on time series. However, real-world temporal data is typically\nobserved at discrete points in time, and must first be transformed into a\ncontinuous path before signature techniques can be applied. We make this step\nexplicit by characterising it as an imputation problem, and empirically assess\nthe impact of various imputation strategies when applying signature-based\nneural nets to irregular time series data. For one of these strategies,\nGaussian process (GP) adapters, we propose an extension~(GP-PoM) that makes\nuncertainty information directly available to the subsequent classifier while\nat the same time preventing costly Monte-Carlo (MC) sampling. In our\nexperiments, we find that the choice of imputation drastically affects shallow\nsignature models, whereas deeper architectures are more robust. Next, we\nobserve that uncertainty-aware predictions (based on GP-PoM or indicator\nimputations) are beneficial for predictive performance, even compared to the\nuncertainty-aware training of conventional GP adapters. In conclusion, we have\ndemonstrated that the path construction is indeed crucial for signature models\nand that our proposed strategy leads to competitive performance in general,\nwhile improving robustness of signature models in particular.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 19:31:21 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 13:05:35 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Moor", "Michael", ""], ["Horn", "Max", ""], ["Bock", "Christian", ""], ["Borgwardt", "Karsten", ""], ["Rieck", "Bastian", ""]]}, {"id": "2005.12368", "submitter": "Marija Stepanovi\\'c", "authors": "Andreas Kirkedal, Marija Stepanovi\\'c, Barbara Plank", "title": "FT Speech: Danish Parliament Speech Corpus", "comments": "Accepted at Interspeech 2020", "journal-ref": null, "doi": "10.21437/Interspeech.2020-3164", "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces FT Speech, a new speech corpus created from the\nrecorded meetings of the Danish Parliament, otherwise known as the Folketing\n(FT). The corpus contains over 1,800 hours of transcribed speech by a total of\n434 speakers. It is significantly larger in duration, vocabulary, and amount of\nspontaneous speech than the existing public speech corpora for Danish, which\nare largely limited to read-aloud and dictation data. We outline design\nconsiderations, including the preprocessing methods and the alignment\nprocedure. To evaluate the quality of the corpus, we train automatic speech\nrecognition systems on the new resource and compare them to the systems trained\non the Danish part of Spr\\r{a}kbanken, the largest public ASR corpus for Danish\nto date. Our baseline results show that we achieve a 14.01 WER on the new\ncorpus. A combination of FT Speech with in-domain language data provides\ncomparable results to models trained specifically on Spr\\r{a}kbanken, showing\nthat FT Speech transfers well to this data set. Interestingly, our results\ndemonstrate that the opposite is not the case. This shows that FT Speech\nprovides a valuable resource for promoting research on Danish ASR with more\nspontaneous speech.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 19:51:18 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 13:36:44 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Kirkedal", "Andreas", ""], ["Stepanovi\u0107", "Marija", ""], ["Plank", "Barbara", ""]]}, {"id": "2005.12379", "submitter": "Sumon Biswas", "authors": "Sumon Biswas and Hridesh Rajan", "title": "Do the Machine Learning Models on a Crowd Sourced Platform Exhibit Bias?\n  An Empirical Study on Model Fairness", "comments": "To be appeared in ESEC/FSE 2020", "journal-ref": "ESEC/FSE'2020: The 28th ACM Joint European Software Engineering\n  Conference and Symposium on the Foundations of Software Engineering,\n  Sacramento, California, United States, November 8-13, 2020", "doi": "10.1145/3368089.3409704", "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are increasingly being used in important\ndecision-making software such as approving bank loans, recommending criminal\nsentencing, hiring employees, and so on. It is important to ensure the fairness\nof these models so that no discrimination is made based on protected attribute\n(e.g., race, sex, age) while decision making. Algorithms have been developed to\nmeasure unfairness and mitigate them to a certain extent. In this paper, we\nhave focused on the empirical evaluation of fairness and mitigations on\nreal-world machine learning models. We have created a benchmark of 40 top-rated\nmodels from Kaggle used for 5 different tasks, and then using a comprehensive\nset of fairness metrics, evaluated their fairness. Then, we have applied 7\nmitigation techniques on these models and analyzed the fairness, mitigation\nresults, and impacts on performance. We have found that some model optimization\ntechniques result in inducing unfairness in the models. On the other hand,\nalthough there are some fairness control mechanisms in machine learning\nlibraries, they are not documented. The mitigation algorithm also exhibit\ncommon patterns such as mitigation in the post-processing is often costly (in\nterms of performance) and mitigation in the pre-processing stage is preferred\nin most cases. We have also presented different trade-off choices of fairness\nmitigation decisions. Our study suggests future research directions to reduce\nthe gap between theoretical fairness aware algorithms and the software\nengineering methods to leverage them in practice.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 23:35:53 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 17:27:44 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Biswas", "Sumon", ""], ["Rajan", "Hridesh", ""]]}, {"id": "2005.12386", "submitter": "Yiqi Wang", "authors": "Yiqi Wang, Yao Ma, Charu Aggarwal, Jiliang Tang", "title": "Non-IID Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph classification is an important task on graph-structured data with many\nreal-world applications. The goal of graph classification task is to train a\nclassifier using a set of training graphs. Recently, Graph Neural Networks\n(GNNs) have greatly advanced the task of graph classification. When building a\nGNN model for graph classification, the graphs in the training set are usually\nassumed to be identically distributed. However, in many real-world\napplications, graphs in the same dataset could have dramatically different\nstructures, which indicates that these graphs are likely non-identically\ndistributed. Therefore, in this paper, we aim to develop graph neural networks\nfor graphs that are not non-identically distributed. Specifically, we propose a\ngeneral non-IID graph neural network framework, i.e., Non-IID-GNN. Given a\ngraph, Non-IID-GNN can adapt any existing graph neural network model to\ngenerate a sample-specific model for this graph. Comprehensive experiments on\nvarious graph classification benchmarks demonstrate the effectiveness of the\nproposed framework. We will release the code of the proposed framework upon the\nacceptance of the paper.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 05:22:24 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Wang", "Yiqi", ""], ["Ma", "Yao", ""], ["Aggarwal", "Charu", ""], ["Tang", "Jiliang", ""]]}, {"id": "2005.12390", "submitter": "Constantinos Siettos", "authors": "Ioannis Gallos, Evangelos Galaris, Constantinos Siettos", "title": "Construction of embedded fMRI resting state functional connectivity\n  networks using manifold learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct embedded functional connectivity networks (FCN) from benchmark\nresting-state functional magnetic resonance imaging (rsfMRI) data acquired from\npatients with schizophrenia and healthy controls based on linear and nonlinear\nmanifold learning algorithms, namely, Multidimensional Scaling (MDS), Isometric\nFeature Mapping (ISOMAP) and Diffusion Maps. Furthermore, based on key global\ngraph-theoretical properties of the embedded FCN, we compare their\nclassification potential using machine learning techniques. We also assess the\nperformance of two metrics that are widely used for the construction of FCN\nfrom fMRI, namely the Euclidean distance and the lagged cross-correlation\nmetric. We show that the FCN constructed with Diffusion Maps and the lagged\ncross-correlation metric outperform the other combinations.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 20:39:29 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Gallos", "Ioannis", ""], ["Galaris", "Evangelos", ""], ["Siettos", "Constantinos", ""]]}, {"id": "2005.12394", "submitter": "Ye Hu", "authors": "Ye Hu, Mingzhe Chen, Walid Saad, H. Vincent Poor, and Shuguang Cui", "title": "Meta-Reinforcement Learning for Trajectory Design in Wireless UAV\n  Networks", "comments": "6 pages, Fig.4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the design of an optimal trajectory for an energy-constrained\ndrone operating in dynamic network environments is studied. In the considered\nmodel, a drone base station (DBS) is dispatched to provide uplink connectivity\nto ground users whose demand is dynamic and unpredictable. In this case, the\nDBS's trajectory must be adaptively adjusted to satisfy the dynamic user access\nrequests. To this end, a meta-learning algorithm is proposed in order to adapt\nthe DBS's trajectory when it encounters novel environments, by tuning a\nreinforcement learning (RL) solution. The meta-learning algorithm provides a\nsolution that adapts the DBS in novel environments quickly based on limited\nformer experiences. The meta-tuned RL is shown to yield a faster convergence to\nthe optimal coverage in unseen environments with a considerably low computation\ncomplexity, compared to the baseline policy gradient algorithm. Simulation\nresults show that, the proposed meta-learning solution yields a 25% improvement\nin the convergence speed, and about 10% improvement in the DBS' communication\nperformance, compared to a baseline policy gradient algorithm. Meanwhile, the\nprobability that the DBS serves over 50% of user requests increases about 27%,\ncompared to the baseline policy gradient algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 20:43:59 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Hu", "Ye", ""], ["Chen", "Mingzhe", ""], ["Saad", "Walid", ""], ["Poor", "H. Vincent", ""], ["Cui", "Shuguang", ""]]}, {"id": "2005.12401", "submitter": "Md Amimul Ehsan", "authors": "Md Amimul Ehsan, Amir Shahirinia, Nian Zhang, Timothy Oladunni", "title": "Wind Speed Prediction and Visualization Using Long Short-Term Memory\n  Networks (LSTM)", "comments": "10th International Conference on Information Science and Technology\n  (ICIST 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Climate change is one of the most concerning issues of this century. Emission\nfrom electric power generation is a crucial factor that drives the concern to\nthe next level. Renewable energy sources are widespread and available globally,\nhowever, one of the major challenges is to understand their characteristics in\na more informative way. This paper proposes the prediction of wind speed that\nsimplifies wind farm planning and feasibility study. Twelve artificial\nintelligence algorithms were used for wind speed prediction from collected\nmeteorological parameters. The model performances were compared to determine\nthe wind speed prediction accuracy. The results show a deep learning approach,\nlong short-term memory (LSTM) outperforms other models with the highest\naccuracy of 97.8%.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 17:51:13 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Ehsan", "Md Amimul", ""], ["Shahirinia", "Amir", ""], ["Zhang", "Nian", ""], ["Oladunni", "Timothy", ""]]}, {"id": "2005.12411", "submitter": "Manuel Mager", "authors": "Manuel Mager and Katharina Kann", "title": "The IMS-CUBoulder System for the SIGMORPHON 2020 Shared Task on\n  Unsupervised Morphological Paradigm Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we present the systems of the University of Stuttgart IMS and\nthe University of Colorado Boulder (IMS-CUBoulder) for SIGMORPHON 2020 Task 2\non unsupervised morphological paradigm completion (Kann et al., 2020). The task\nconsists of generating the morphological paradigms of a set of lemmas, given\nonly the lemmas themselves and unlabeled text. Our proposed system is a\nmodified version of the baseline introduced together with the task. In\nparticular, we experiment with substituting the inflection generation component\nwith an LSTM sequence-to-sequence model and an LSTM pointer-generator network.\nOur pointer-generator system obtains the best score of all seven submitted\nsystems on average over all languages, and outperforms the official baseline,\nwhich was best overall, on Bulgarian and Kannada.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 21:23:52 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Mager", "Manuel", ""], ["Kann", "Katharina", ""]]}, {"id": "2005.12415", "submitter": "Jason Sun", "authors": "Daqian Sun, Martin T. Wells", "title": "Robust Matrix Completion with Mixed Data Types", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the matrix completion problem of recovering a structured low rank\nmatrix with partially observed entries with mixed data types. Vast majority of\nthe solutions have proposed computationally feasible estimators with strong\nstatistical guarantees for the case where the underlying distribution of data\nin the matrix is continuous. A few recent approaches have extended using\nsimilar ideas these estimators to the case where the underlying distributions\nbelongs to the exponential family. Most of these approaches assume that there\nis only one underlying distribution and the low rank constraint is regularized\nby the matrix Schatten Norm. We propose a computationally feasible statistical\napproach with strong recovery guarantees along with an algorithmic framework\nsuited for parallelization to recover a low rank matrix with partially observed\nentries for mixed data types in one step. We also provide extensive simulation\nevidence that corroborate our theoretical results.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 21:35:10 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Sun", "Daqian", ""], ["Wells", "Martin T.", ""]]}, {"id": "2005.12418", "submitter": "Cristi\\'an Bravo", "authors": "Cristi\\'an Bravo and Mar\\'ia \\'Oskarsd\\'ottir", "title": "Evolution of Credit Risk Using a Personalized Pagerank Algorithm for\n  Multilayer Networks", "comments": "Conference camera-ready paper - accepted at KDD MLF 2020. 15 pages,\n  10 figures", "journal-ref": "Proceedings of the Third KDD Workshop on Machine Learning in\n  Finance, joint with 26th ACM SIGKDD Conference on Knowledge Discovery in\n  Databases (KDD MLF 2020). ACM, New York, NY, USA, 8 pages", "doi": null, "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel algorithm to study the evolution of credit\nrisk across complex multilayer networks. Pagerank-like algorithms allow for the\npropagation of an influence variable across single networks, and allow\nquantifying the risk single entities (nodes) are subject to given the\nconnection they have to other nodes in the network. Multilayer networks, on the\nother hand, are networks where subset of nodes can be associated to a unique\nset (layer), and where edges connect elements either intra or inter networks.\nOur personalized PageRank algorithm for multilayer networks allows for\nquantifying how credit risk evolves across time and propagates through these\nnetworks. By using bipartite networks in each layer, we can quantify the risk\nof various components, not only the loans. We test our method in an\nagricultural lending dataset, and our results show how default risk is a\nchallenging phenomenon that propagates and evolves through the network across\ntime.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 21:46:57 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 20:18:35 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Bravo", "Cristi\u00e1n", ""], ["\u00d3skarsd\u00f3ttir", "Mar\u00eda", ""]]}, {"id": "2005.12419", "submitter": "Takanori Fujiwara", "authors": "Takanori Fujiwara, Jian Zhao, Francine Chen, Yaoliang Yu, Kwan-Liu Ma", "title": "Interpretable Contrastive Learning for Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive learning (CL) is an emerging analysis approach that aims to\ndiscover unique patterns in one dataset relative to another. By applying this\napproach to network analysis, we can reveal unique characteristics in one\nnetwork by contrasting with another. For example, with networks of protein\ninteractions obtained from normal and cancer tissues, we can discover unique\ntypes of interactions in cancer tissues. However, existing CL methods cannot be\ndirectly applied to networks. To address this issue, we introduce a novel\napproach called contrastive network representation learning (cNRL). This\napproach embeds network nodes into a low-dimensional space that reveals the\nuniqueness of one network compared to another. Within this approach, we also\ndesign a method, named i-cNRL, that offers interpretability in the learned\nresults, allowing for understanding which specific patterns are found in one\nnetwork but not the other. We demonstrate the capability of i-cNRL with\nmultiple network models and real-world datasets. Furthermore, we provide\nquantitative and qualitative comparisons across i-cNRL and other potential cNRL\nalgorithm designs.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 21:46:59 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Fujiwara", "Takanori", ""], ["Zhao", "Jian", ""], ["Chen", "Francine", ""], ["Yu", "Yaoliang", ""], ["Ma", "Kwan-Liu", ""]]}, {"id": "2005.12420", "submitter": "Terence Broad", "authors": "Terence Broad, Frederic Fol Leymarie, Mick Grierson", "title": "Network Bending: Expressive Manipulation of Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce a new framework for manipulating and interacting with deep\ngenerative models that we call network bending. We present a comprehensive set\nof deterministic transformations that can be inserted as distinct layers into\nthe computational graph of a trained generative neural network and applied\nduring inference. In addition, we present a novel algorithm for analysing the\ndeep generative model and clustering features based on their spatial activation\nmaps. This allows features to be grouped together based on spatial similarity\nin an unsupervised fashion. This results in the meaningful manipulation of sets\nof features that correspond to the generation of a broad array of semantically\nsignificant features of the generated images. We outline this framework,\ndemonstrating our results on state-of-the-art deep generative models trained on\nseveral image datasets. We show how it allows for the direct manipulation of\nsemantically meaningful aspects of the generative process as well as allowing\nfor a broad range of expressive outcomes.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 21:48:45 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 15:06:56 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Broad", "Terence", ""], ["Leymarie", "Frederic Fol", ""], ["Grierson", "Mick", ""]]}, {"id": "2005.12433", "submitter": "Shuhan Yuan", "authors": "Shuhan Yuan and Xintao Wu", "title": "Deep Learning for Insider Threat Detection: Review, Challenges and\n  Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insider threats, as one type of the most challenging threats in cyberspace,\nusually cause significant loss to organizations. While the problem of insider\nthreat detection has been studied for a long time in both security and data\nmining communities, the traditional machine learning based detection\napproaches, which heavily rely on feature engineering, are hard to accurately\ncapture the behavior difference between insiders and normal users due to\nvarious challenges related to the characteristics of underlying data, such as\nhigh-dimensionality, complexity, heterogeneity, sparsity, lack of labeled\ninsider threats, and the subtle and adaptive nature of insider threats.\nAdvanced deep learning techniques provide a new paradigm to learn end-to-end\nmodels from complex data. In this brief survey, we first introduce one\ncommonly-used dataset for insider threat detection and review the recent\nliterature about deep learning for such research. The existing studies show\nthat compared with traditional machine learning algorithms, deep learning\nmodels can improve the performance of insider threat detection. However,\napplying deep learning to further advance the insider threat detection task\nstill faces several limitations, such as lack of labeled data, adaptive\nattacks. We then discuss such challenges and suggest future research directions\nthat have the potential to address challenges and further boost the performance\nof deep learning for insider threat detection.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 22:48:01 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Yuan", "Shuhan", ""], ["Wu", "Xintao", ""]]}, {"id": "2005.12442", "submitter": "Shashank Sonkar", "authors": "Shashank Sonkar, Andrew E. Waters, Andrew S. Lan, Phillip J. Grimaldi,\n  Richard G. Baraniuk", "title": "qDKT: Question-centric Deep Knowledge Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge tracing (KT) models, e.g., the deep knowledge tracing (DKT) model,\ntrack an individual learner's acquisition of skills over time by examining the\nlearner's performance on questions related to those skills. A practical\nlimitation in most existing KT models is that all questions nested under a\nparticular skill are treated as equivalent observations of a learner's ability,\nwhich is an inaccurate assumption in real-world educational scenarios. To\novercome this limitation we introduce qDKT, a variant of DKT that models every\nlearner's success probability on individual questions over time. First, qDKT\nincorporates graph Laplacian regularization to smooth predictions under each\nskill, which is particularly useful when the number of questions in the dataset\nis big. Second, qDKT uses an initialization scheme inspired by the fastText\nalgorithm, which has found success in a variety of language modeling tasks. Our\nexperiments on several real-world datasets show that qDKT achieves state-of-art\nperformance on predicting learner outcomes. Because of this, qDKT can serve as\na simple, yet tough-to-beat, baseline for new question-centric KT models.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 23:43:55 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Sonkar", "Shashank", ""], ["Waters", "Andrew E.", ""], ["Lan", "Andrew S.", ""], ["Grimaldi", "Phillip J.", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "2005.12444", "submitter": "Yuchuan Gou", "authors": "Yuchuan Gou, Qiancheng Wu, Minghao Li, Bo Gong, Mei Han", "title": "SegAttnGAN: Text to Image Generation with Segmentation Attention", "comments": "Accepted to the AI for Content Creation Workshop at CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel generative network (SegAttnGAN) that\nutilizes additional segmentation information for the text-to-image synthesis\ntask. As the segmentation data introduced to the model provides useful guidance\non the generator training, the proposed model can generate images with better\nrealism quality and higher quantitative measures compared with the previous\nstate-of-art methods. We achieved Inception Score of 4.84 on the CUB dataset\nand 3.52 on the Oxford-102 dataset. Besides, we tested the self-attention\nSegAttnGAN which uses generated segmentation data instead of masks from\ndatasets for attention and achieved similar high-quality results, suggesting\nthat our model can be adapted for the text-to-image synthesis task.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 23:56:41 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Gou", "Yuchuan", ""], ["Wu", "Qiancheng", ""], ["Li", "Minghao", ""], ["Gong", "Bo", ""], ["Han", "Mei", ""]]}, {"id": "2005.12458", "submitter": "Kunal Sharma", "authors": "Kunal Sharma, M. Cerezo, Lukasz Cincio, Patrick J. Coles", "title": "Trainability of Dissipative Perceptron-Based Quantum Neural Networks", "comments": "5 + 18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": "LA-UR-20-23484", "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several architectures have been proposed for quantum neural networks (QNNs),\nwith the goal of efficiently performing machine learning tasks on quantum data.\nRigorous scaling results are urgently needed for specific QNN constructions to\nunderstand which, if any, will be trainable at a large scale. Here, we analyze\nthe gradient scaling (and hence the trainability) for a recently proposed\narchitecture that we called dissipative QNNs (DQNNs), where the input qubits of\neach layer are discarded at the layer's output. We find that DQNNs can exhibit\nbarren plateaus, i.e., gradients that vanish exponentially in the number of\nqubits. Moreover, we provide quantitative bounds on the scaling of the gradient\nfor DQNNs under different conditions, such as different cost functions and\ncircuit depths, and show that trainability is not always guaranteed.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 00:59:09 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Sharma", "Kunal", ""], ["Cerezo", "M.", ""], ["Cincio", "Lukasz", ""], ["Coles", "Patrick J.", ""]]}, {"id": "2005.12476", "submitter": "Leslie Tiong", "authors": "Leslie Ching Ow Tiong, Jeongrae Kim, Sang Soo Han, Donghun Kim", "title": "Identification of Crystal Symmetry from Noisy Diffraction Patterns by A\n  Shape Analysis and Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robust and automated determination of crystal symmetry is of utmost\nimportance in material characterization and analysis. Recent studies have shown\nthat deep learning (DL) methods can effectively reveal the correlations between\nX-ray or electron-beam diffraction patterns and crystal symmetry. Despite their\npromise, most of these studies have been limited to identifying relatively few\nclasses into which a target material may be grouped. On the other hand, the\nDL-based identification of crystal symmetry suffers from a drastic drop in\naccuracy for problems involving classification into tens or hundreds of\nsymmetry classes (e.g., up to 230 space groups), severely limiting its\npractical usage. Here, we demonstrate that a combined approach of shaping\ndiffraction patterns and implementing them in a multistream DenseNet (MSDN)\nsubstantially improves the accuracy of classification. Even with an imbalanced\ndataset of 108,658 individual crystals sampled from 72 space groups, our model\nachieves 80.2% space group classification accuracy, outperforming conventional\nbenchmark models by 17-27 percentage points (%p). The enhancement can be\nlargely attributed to the pattern shaping strategy, through which the subtle\nchanges in patterns between symmetrically close crystal systems (e.g.,\nmonoclinic vs. orthorhombic or trigonal vs. hexagonal) are well differentiated.\nWe additionally find that the novel MSDN architecture is advantageous for\ncapturing patterns in a richer but less redundant manner relative to\nconventional convolutional neural networks. The newly proposed protocols in\nregard to both input descriptor processing and DL architecture enable accurate\nspace group classification and thus improve the practical usage of the DL\napproach in crystal symmetry identification.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 01:38:50 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Tiong", "Leslie Ching Ow", ""], ["Kim", "Jeongrae", ""], ["Han", "Sang Soo", ""], ["Kim", "Donghun", ""]]}, {"id": "2005.12483", "submitter": "Ernest Chan", "authors": "Xin Man and Ernest Chan", "title": "The best way to select features?", "comments": "8 pages, submitted to ACM International Conference on AI in Finance\n  (ICAIF-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection in machine learning is subject to the intrinsic randomness\nof the feature selection algorithms (for example, random permutations during\nMDA). Stability of selected features with respect to such randomness is\nessential to the human interpretability of a machine learning algorithm. We\nproposes a rank based stability metric called instability index to compare the\nstabilities of three feature selection algorithms MDA, LIME, and SHAP as\napplied to random forests. Typically, features are selected by averaging many\nrandom iterations of a selection algorithm. Though we find that the variability\nof the selected features does decrease as the number of iterations increases,\nit does not go to zero, and the features selected by the three algorithms do\nnot necessarily converge to the same set. We find LIME and SHAP to be more\nstable than MDA, and LIME is at least as stable as SHAP for the top ranked\nfeatures. Hence overall LIME is best suited for human interpretability.\nHowever, the selected set of features from all three algorithms significantly\nimproves various predictive metrics out of sample, and their predictive\nperformances do not differ significantly. Experiments were conducted on\nsynthetic datasets, two public benchmark datasets, and on proprietary data from\nan active investment strategy.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 02:20:40 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Man", "Xin", ""], ["Chan", "Ernest", ""]]}, {"id": "2005.12488", "submitter": "Takashi Mori", "authors": "Takashi Mori, Masahito Ueda", "title": "Is deeper better? It depends on locality of relevant features", "comments": "13+4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been recognized that a heavily overparameterized artificial neural\nnetwork exhibits surprisingly good generalization performance in various\nmachine-learning tasks. Recent theoretical studies have made attempts to unveil\nthe mystery of the overparameterization. In most of those previous works, the\noverparameterization is achieved by increasing the width of the network, while\nthe effect of increasing the depth has remained less well understood. In this\nwork, we investigate the effect of increasing the depth within an\noverparameterized regime. To gain an insight into the advantage of depth, we\nintroduce local and global labels as abstract but simple classification rules.\nIt turns out that the locality of the relevant feature for a given\nclassification rule plays a key role; our experimental results suggest that\ndeeper is better for local labels, whereas shallower is better for global\nlabels. We also compare the results of finite networks with those of the neural\ntangent kernel (NTK), which is equivalent to an infinitely wide network with a\nproper initialization and an infinitesimal learning rate. It is shown that the\nNTK does not correctly capture the depth dependence of the generalization\nperformance, which indicates the importance of the feature learning rather than\nthe lazy learning.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 02:44:18 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 12:22:50 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Mori", "Takashi", ""], ["Ueda", "Masahito", ""]]}, {"id": "2005.12496", "submitter": "Eric Zelikman", "authors": "Eric Zelikman, Christopher Healy, Sharon Zhou, Anand Avati", "title": "CRUDE: Calibrating Regression Uncertainty Distributions Empirically", "comments": "ICML 2020 Workshop on Uncertainty & Robustness in Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calibrated uncertainty estimates in machine learning are crucial to many\nfields such as autonomous vehicles, medicine, and weather and climate\nforecasting. While there is extensive literature on uncertainty calibration for\nclassification, the classification findings do not always translate to\nregression. As a result, modern models for predicting uncertainty in regression\nsettings typically produce uncalibrated and overconfident estimates. To address\nthese gaps, we present a calibration method for regression settings that does\nnot assume a particular uncertainty distribution over the error: Calibrating\nRegression Uncertainty Distributions Empirically (CRUDE). CRUDE makes the\nweaker assumption that error distributions have a constant arbitrary shape\nacross the output space, shifted by predicted mean and scaled by predicted\nstandard deviation. We detail a theoretical connection between CRUDE and\nconformal inference. Across an extensive set of regression tasks, CRUDE\ndemonstrates consistently sharper, better calibrated, and more accurate\nuncertainty estimates than state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 03:08:43 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 02:35:57 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 23:22:57 GMT"}, {"version": "v4", "created": "Sat, 4 Jul 2020 01:25:07 GMT"}, {"version": "v5", "created": "Wed, 14 Oct 2020 21:23:56 GMT"}, {"version": "v6", "created": "Mon, 15 Mar 2021 02:30:18 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Zelikman", "Eric", ""], ["Healy", "Christopher", ""], ["Zhou", "Sharon", ""], ["Avati", "Anand", ""]]}, {"id": "2005.12508", "submitter": "Joseph Campbell", "authors": "Joseph Campbell, Katsu Yamane", "title": "Learning Whole-Body Human-Robot Haptic Interaction in Social Contexts", "comments": "Accepted to ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a learning-from-demonstration (LfD) framework for\nteaching human-robot social interactions that involve whole-body haptic\ninteraction, i.e. direct human-robot contact over the full robot body. The\nperformance of existing LfD frameworks suffers in such interactions due to the\nhigh dimensionality and spatiotemporal sparsity of the demonstration data. We\nshow that by leveraging this sparsity, we can reduce the data dimensionality\nwithout incurring a significant accuracy penalty, and introduce three\nstrategies for doing so. By combining these techniques with an LfD framework\nfor learning multimodal human-robot interactions, we can model the\nspatiotemporal relationship between the tactile and kinesthetic information\nduring whole-body haptic interactions. Using a teleoperated bimanual robot\nequipped with 61 force sensors, we experimentally demonstrate that a model\ntrained with 121 sample hugs from 4 participants generalizes well to unseen\ninputs and human partners.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 03:44:09 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Campbell", "Joseph", ""], ["Yamane", "Katsu", ""]]}, {"id": "2005.12513", "submitter": "Fernanda Ribeiro", "authors": "Fernanda L. Ribeiro, Steffen Bollmann, Alexander M. Puckett", "title": "DeepRetinotopy: Predicting the Functional Organization of Human Visual\n  Cortex from Structural MRI Data using Geometric Deep Learning", "comments": null, "journal-ref": null, "doi": "10.1101/2020.02.11.934471", "report-no": "MIDL/2020/ExtendedAbstract/Nw_trRFjPE", "categories": "q-bio.NC cs.CV cs.LG q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Whether it be in a man-made machine or a biological system, form and function\nare often directly related. In the latter, however, this particular\nrelationship is often unclear due to the intricate nature of biology. Here we\ndeveloped a geometric deep learning model capable of exploiting the actual\nstructure of the cortex to learn the complex relationship between brain\nfunction and anatomy from structural and functional MRI data. Our model was not\nonly able to predict the functional organization of human visual cortex from\nanatomical properties alone, but it was also able to predict nuanced variations\nacross individuals.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 04:54:31 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Ribeiro", "Fernanda L.", ""], ["Bollmann", "Steffen", ""], ["Puckett", "Alexander M.", ""]]}, {"id": "2005.12516", "submitter": "Chang-You Tai", "authors": "Chang-You Tai, Meng-Ru Wu, Yun-Wei Chu, Shao-Yu Chu, Lun-Wei Ku", "title": "MVIN: Learning Multiview Items for Recommendation", "comments": null, "journal-ref": null, "doi": "10.1145/3397271.3401126", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers have begun to utilize heterogeneous knowledge graphs (KGs) as\nauxiliary information in recommendation systems to mitigate the cold start and\nsparsity issues. However, utilizing a graph neural network (GNN) to capture\ninformation in KG and further apply in RS is still problematic as it is unable\nto see each item's properties from multiple perspectives. To address these\nissues, we propose the multi-view item network (MVIN), a GNN-based\nrecommendation model which provides superior recommendations by describing\nitems from a unique mixed view from user and entity angles. MVIN learns item\nrepresentations from both the user view and the entity view. From the user\nview, user-oriented modules score and aggregate features to make\nrecommendations from a personalized perspective constructed according to KG\nentities which incorporates user click information. From the entity view, the\nmixing layer contrasts layer-wise GCN information to further obtain\ncomprehensive features from internal entity-entity interactions in the KG. We\nevaluate MVIN on three real-world datasets: MovieLens-1M (ML-1M), LFM-1b 2015\n(LFM-1b), and Amazon-Book (AZ-book). Results show that MVIN significantly\noutperforms state-of-the-art methods on these three datasets. In addition, from\nuser-view cases, we find that MVIN indeed captures entities that attract users.\nFigures further illustrate that mixing layers in a heterogeneous KG plays a\nvital role in neighborhood information aggregation.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 05:19:27 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Tai", "Chang-You", ""], ["Wu", "Meng-Ru", ""], ["Chu", "Yun-Wei", ""], ["Chu", "Shao-Yu", ""], ["Ku", "Lun-Wei", ""]]}, {"id": "2005.12518", "submitter": "Shilin Zhu", "authors": "Shilin Zhu", "title": "Survey: Machine Learning in Production Rendering", "comments": "This was the survey I did for my PhD research exam", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, machine learning-based approaches have had some great\nsuccess for rendering animated feature films. This survey summarizes several of\nthe most dramatic improvements in using deep neural networks over traditional\nrendering methods, such as better image quality and lower computational\noverhead. More specifically, this survey covers the fundamental principles of\nmachine learning and its applications, such as denoising, path guiding,\nrendering participating media, and other notoriously difficult light transport\nsituations. Some of these techniques have already been used in the latest\nreleased animations while others are still in the continuing development by\nresearchers in both academia and movie studios. Although learning-based\nrendering methods still have some open issues, they have already demonstrated\npromising performance in multiple parts of the rendering pipeline, and people\nare continuously making new attempts.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 05:23:32 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Zhu", "Shilin", ""]]}, {"id": "2005.12521", "submitter": "Ju-Hyung Lee", "authors": "Ju-Hyung Lee, Jihong Park, Mehdi Bennis, and Young-Chai Ko", "title": "Integrating LEO Satellite and UAV Relaying via Reinforcement Learning\n  for Non-Terrestrial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mega-constellation of low-earth orbit (LEO) satellites has the potential to\nenable long-range communication with low latency. Integrating this with\nburgeoning unmanned aerial vehicle (UAV) assisted non-terrestrial networks will\nbe a disruptive solution for beyond 5G systems provisioning large scale\nthree-dimensional connectivity. In this article, we study the problem of\nforwarding packets between two faraway ground terminals, through an LEO\nsatellite selected from an orbiting constellation and a mobile high-altitude\nplatform (HAP) such as a fixed-wing UAV. To maximize the end-to-end data rate,\nthe satellite association and HAP location should be optimized, which is\nchallenging due to a huge number of orbiting satellites and the resulting\ntime-varying network topology. We tackle this problem using deep reinforcement\nlearning (DRL) with a novel action dimension reduction technique. Simulation\nresults corroborate that our proposed method achieves up to 5.74x higher\naverage data rate compared to a direct communication baseline without SAT and\nHAP.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 05:39:27 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Lee", "Ju-Hyung", ""], ["Park", "Jihong", ""], ["Bennis", "Mehdi", ""], ["Ko", "Young-Chai", ""]]}, {"id": "2005.12531", "submitter": "Dongyang Dai", "authors": "Dongyang Dai, Li Chen, Yuping Wang, Mu Wang, Rui Xia, Xuchen Song,\n  Zhiyong Wu, Yuxuan Wang", "title": "Noise Robust TTS for Low Resource Speakers using Pre-trained Model and\n  Speech Enhancement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the popularity of deep neural network, speech synthesis task has\nachieved significant improvements based on the end-to-end encoder-decoder\nframework in the recent days. More and more applications relying on speech\nsynthesis technology have been widely used in our daily life. Robust speech\nsynthesis model depends on high quality and customized data which needs lots of\ncollecting efforts. It is worth investigating how to take advantage of\nlow-quality and low resource voice data which can be easily obtained from the\nInternet for usage of synthesizing personalized voice. In this paper, the\nproposed end-to-end speech synthesis model uses both speaker embedding and\nnoise representation as conditional inputs to model speaker and noise\ninformation respectively. Firstly, the speech synthesis model is pre-trained\nwith both multi-speaker clean data and noisy augmented data; then the\npre-trained model is adapted on noisy low-resource new speaker data; finally,\nby setting the clean speech condition, the model can synthesize the new\nspeaker's clean voice. Experimental results show that the speech generated by\nthe proposed approach has better subjective evaluation results than the method\ndirectly fine-tuning pre-trained multi-speaker speech synthesis model with\ndenoised new speaker data.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 06:14:06 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 11:36:56 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Dai", "Dongyang", ""], ["Chen", "Li", ""], ["Wang", "Yuping", ""], ["Wang", "Mu", ""], ["Xia", "Rui", ""], ["Song", "Xuchen", ""], ["Wu", "Zhiyong", ""], ["Wang", "Yuxuan", ""]]}, {"id": "2005.12551", "submitter": "Alexey Abramov", "authors": "Alexey Abramov, Christopher Bayer, Claudio Heller", "title": "Keep it Simple: Image Statistics Matching for Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying an object detector, which is neither trained nor fine-tuned on data\nclose to the final application, often leads to a substantial performance drop.\nIn order to overcome this problem, it is necessary to consider a shift between\nsource and target domains. Tackling the shift is known as Domain Adaptation\n(DA). In this work, we focus on unsupervised DA: maintaining the detection\naccuracy across different data distributions, when only unlabeled images are\navailable of the target domain. Recent state-of-the-art methods try to reduce\nthe domain gap using an adversarial training strategy which increases the\nperformance but at the same time the complexity of the training procedure. In\ncontrast, we look at the problem from a new perspective and keep it simple by\nsolely matching image statistics between source and target domain. We propose\nto align either color histograms or mean and covariance of the source images\ntowards the target domain. Hence, DA is accomplished without architectural\nadd-ons and additional hyper-parameters. The benefit of the approaches is\ndemonstrated by evaluating different domain shift scenarios on public data\nsets. In comparison to recent methods, we achieve state-of-the-art performance\nusing a much simpler procedure for the training. Additionally, we show that\napplying our techniques significantly reduces the amount of synthetic data\nneeded to learn a general model and thus increases the value of simulation.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 07:32:09 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Abramov", "Alexey", ""], ["Bayer", "Christopher", ""], ["Heller", "Claudio", ""]]}, {"id": "2005.12564", "submitter": "T. Konstantin Rusch", "authors": "Siddhartha Mishra, T. Konstantin Rusch", "title": "Enhancing accuracy of deep learning algorithms by training with\n  low-discrepancy sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep supervised learning algorithm based on low-discrepancy\nsequences as the training set. By a combination of theoretical arguments and\nextensive numerical experiments we demonstrate that the proposed algorithm\nsignificantly outperforms standard deep learning algorithms that are based on\nrandomly chosen training data, for problems in moderately high dimensions. The\nproposed algorithm provides an efficient method for building inexpensive\nsurrogates for many underlying maps in the context of scientific computing.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 08:14:00 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Mishra", "Siddhartha", ""], ["Rusch", "T. Konstantin", ""]]}, {"id": "2005.12565", "submitter": "Saadullah Amin", "authors": "Saadullah Amin, Katherine Ann Dunfield, Anna Vechkaeva and G\\\"unter\n  Neumann", "title": "A Data-driven Approach for Noise Reduction in Distantly Supervised\n  Biomedical Relation Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fact triples are a common form of structured knowledge used within the\nbiomedical domain. As the amount of unstructured scientific texts continues to\ngrow, manual annotation of these texts for the task of relation extraction\nbecomes increasingly expensive. Distant supervision offers a viable approach to\ncombat this by quickly producing large amounts of labeled, but considerably\nnoisy, data. We aim to reduce such noise by extending an entity-enriched\nrelation classification BERT model to the problem of multiple instance\nlearning, and defining a simple data encoding scheme that significantly reduces\nnoise, reaching state-of-the-art performance for distantly-supervised\nbiomedical relation extraction. Our approach further encodes knowledge about\nthe direction of relation triples, allowing for increased focus on relation\nlearning by reducing noise and alleviating the need for joint learning with\nknowledge graph completion.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 08:15:32 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Amin", "Saadullah", ""], ["Dunfield", "Katherine Ann", ""], ["Vechkaeva", "Anna", ""], ["Neumann", "G\u00fcnter", ""]]}, {"id": "2005.12579", "submitter": "Vanessa Volz", "authors": "Vanessa Volz and Niels Justesen and Sam Snodgrass and Sahar Asadi and\n  Sami Purmonen and Christoffer Holmg\\r{a}rd and Julian Togelius and Sebastian\n  Risi", "title": "Capturing Local and Global Patterns in Procedural Content Generation via\n  Machine Learning", "comments": "IEEE Conference on Games 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent procedural content generation via machine learning (PCGML) methods\nallow learning from existing content to produce similar content automatically.\nWhile these approaches are able to generate content for different games (e.g.\nSuper Mario Bros., DOOM, Zelda, and Kid Icarus), it is an open questions how\nwell these approaches can capture large-scale visual patterns such as symmetry.\nIn this paper, we propose match-three games as a domain to test PCGML\nalgorithms regarding their ability to generate suitable patterns. We\ndemonstrate that popular algorithm such as Generative Adversarial Networks\nstruggle in this domain and propose adaptations to improve their performance.\nIn particular we augment the neighborhood of a Markov Random Fields approach to\nnot only take local but also symmetric positional information into account. We\nconduct several empirical tests including a user study that show the\nimprovements achieved by the proposed modifications, and obtain promising\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 08:58:37 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Volz", "Vanessa", ""], ["Justesen", "Niels", ""], ["Snodgrass", "Sam", ""], ["Asadi", "Sahar", ""], ["Purmonen", "Sami", ""], ["Holmg\u00e5rd", "Christoffer", ""], ["Togelius", "Julian", ""], ["Risi", "Sebastian", ""]]}, {"id": "2005.12592", "submitter": "Kostiantyn Omelianchuk", "authors": "Kostiantyn Omelianchuk, Vitaliy Atrasevych, Artem Chernodub, Oleksandr\n  Skurzhanskyi", "title": "GECToR -- Grammatical Error Correction: Tag, Not Rewrite", "comments": "Accepted for publication in BEA workshop (15th Workshop on Innovative\n  Use of NLP for Building Educational Applications; co-located with ACL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a simple and efficient GEC sequence tagger using a\nTransformer encoder. Our system is pre-trained on synthetic data and then\nfine-tuned in two stages: first on errorful corpora, and second on a\ncombination of errorful and error-free parallel corpora. We design custom\ntoken-level transformations to map input tokens to target corrections. Our best\nsingle-model/ensemble GEC tagger achieves an $F_{0.5}$ of 65.3/66.5 on\nCoNLL-2014 (test) and $F_{0.5}$ of 72.4/73.6 on BEA-2019 (test). Its inference\nspeed is up to 10 times as fast as a Transformer-based seq2seq GEC system. The\ncode and trained models are publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 09:33:02 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 09:15:53 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Omelianchuk", "Kostiantyn", ""], ["Atrasevych", "Vitaliy", ""], ["Chernodub", "Artem", ""], ["Skurzhanskyi", "Oleksandr", ""]]}, {"id": "2005.12627", "submitter": "Morteza Haghir Chehreghani", "authors": "Fazeleh Sadat Hoseini, Morteza Haghir Chehreghani", "title": "Memory-Efficient Sampling for Minimax Distance Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimax distance measure extracts the underlying patterns and manifolds in an\nunsupervised manner. The existing methods require a quadratic memory with\nrespect to the number of objects. In this paper, we investigate efficient\nsampling schemes in order to reduce the memory requirement and provide a linear\nspace complexity. In particular, we propose a novel sampling technique that\nadapts well with Minimax distances. We evaluate the methods on real-world\ndatasets from different domains and analyze the results.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 11:00:34 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Hoseini", "Fazeleh Sadat", ""], ["Chehreghani", "Morteza Haghir", ""]]}, {"id": "2005.12632", "submitter": "Fabio Massimo Zennaro", "authors": "Fabio Massimo Zennaro and Laszlo Erdodi", "title": "Modeling Penetration Testing with Reinforcement Learning Using\n  Capture-the-Flag Challenges: Trade-offs between Model-free Learning and A\n  Priori Knowledge", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Penetration testing is a security exercise aimed at assessing the security of\na system by simulating attacks against it. So far, penetration testing has been\ncarried out mainly by trained human attackers and its success critically\ndepended on the available expertise. Automating this practice constitutes a\nnon-trivial problem, as the range of actions that a human expert may attempts\nagainst a system and the range of knowledge she relies on to take her decisions\nare hard to capture. In this paper, we focus our attention on simplified\npenetration testing problems expressed in the form of capture the flag hacking\nchallenges, and we analyze how model-free reinforcement learning algorithms may\nhelp to solve them. In modeling these capture the flag competitions as\nreinforcement learning problems we highlight that a specific challenge that\ncharacterize penetration testing is the problem of discovering the structure of\nthe problem at hand. We then show how this challenge may be eased by relying on\ndifferent forms of prior knowledge that may be provided to the agent. In this\nway we demonstrate how the feasibility of tackling penetration testing using\nreinforcement learning may rest on a careful trade-off between model-free and\nmodel-based algorithms. By using techniques to inject a priori knowledge, we\nshow it is possible to better direct the agent and restrict the space of its\nexploration problem, thus achieving solutions more efficiently.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 11:23:10 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 09:31:40 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Zennaro", "Fabio Massimo", ""], ["Erdodi", "Laszlo", ""]]}, {"id": "2005.12636", "submitter": "Zoltan Szabo", "authors": "Pierre-Cyril Aubin-Frankowski, Zoltan Szabo", "title": "Hard Shape-Constrained Kernel Machines", "comments": "camera-ready paper", "journal-ref": "Advances in Neural Information Processing Systems (NeurIPS-2020)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shape constraints (such as non-negativity, monotonicity, convexity) play a\ncentral role in a large number of applications, as they usually improve\nperformance for small sample size and help interpretability. However enforcing\nthese shape requirements in a hard fashion is an extremely challenging problem.\nClassically, this task is tackled (i) in a soft way (without out-of-sample\nguarantees), (ii) by specialized transformation of the variables on a\ncase-by-case basis, or (iii) by using highly restricted function classes, such\nas polynomials or polynomial splines. In this paper, we prove that hard affine\nshape constraints on function derivatives can be encoded in kernel machines\nwhich represent one of the most flexible and powerful tools in machine learning\nand statistics. Particularly, we present a tightened second-order cone\nconstrained reformulation, that can be readily implemented in convex solvers.\nWe prove performance guarantees on the solution, and demonstrate the efficiency\nof the approach in joint quantile regression with applications to economics and\nto the analysis of aircraft trajectories, among others.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 11:35:49 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 09:59:26 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Aubin-Frankowski", "Pierre-Cyril", ""], ["Szabo", "Zoltan", ""]]}, {"id": "2005.12647", "submitter": "Christian Truden", "authors": "Konstantin Posch, Christian Truden, Philipp Hungerl\\\"ander, J\\\"urgen\n  Pilz", "title": "A Bayesian Approach for Predicting Food and Beverage Sales in Staff\n  Canteens and Restaurants", "comments": null, "journal-ref": null, "doi": "10.1016/j.ijforecast.2021.06.001", "report-no": null, "categories": "stat.AP cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate demand forecasting is one of the key aspects for successfully\nmanaging restaurants and staff canteens. In particular, properly predicting\nfuture sales of menu items allows a precise ordering of food stock. From an\nenvironmental point of view, this ensures maintaining a low level of\npre-consumer food waste, while from the managerial point of view, this is\ncritical to guarantee the profitability of the restaurant. Hence, we are\ninterested in predicting future values of the daily sold quantities of given\nmenu items. The corresponding time series show multiple strong seasonalities,\ntrend changes, data gaps, and outliers. We propose a forecasting approach that\nis solely based on the data retrieved from Point of Sales systems and allows\nfor a straightforward human interpretation. Therefore, we propose two\ngeneralized additive models for predicting the future sales. In an extensive\nevaluation, we consider two data sets collected at a casual restaurant and a\nlarge staff canteen consisting of multiple time series, that cover a period of\n20 months, respectively. We show that the proposed models fit the features of\nthe considered restaurant data. Moreover, we compare the predictive performance\nof our method against the performance of other well-established forecasting\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 12:05:06 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 16:07:44 GMT"}, {"version": "v3", "created": "Mon, 10 May 2021 13:06:55 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Posch", "Konstantin", ""], ["Truden", "Christian", ""], ["Hungerl\u00e4nder", "Philipp", ""], ["Pilz", "J\u00fcrgen", ""]]}, {"id": "2005.12649", "submitter": "Alistair Letcher", "authors": "Alistair Letcher", "title": "On the Impossibility of Global Convergence in Multi-Loss Optimization", "comments": "26 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under mild regularity conditions, gradient-based methods converge globally to\na critical point in the single-loss setting. This is known to break down for\nvanilla gradient descent when moving to multi-loss optimization, but can we\nhope to build some algorithm with global guarantees? We negatively resolve this\nopen problem by proving that desirable convergence properties cannot\nsimultaneously hold for any algorithm. Our result has more to do with the\nexistence of games with no satisfactory outcomes, than with algorithms per se.\nMore explicitly we construct a two-player game with zero-sum interactions whose\nlosses are both coercive and analytic, but whose only simultaneous critical\npoint is a strict maximum. Any 'reasonable' algorithm, defined to avoid strict\nmaxima, will therefore fail to converge. This is fundamentally different from\nsingle losses, where coercivity implies existence of a global minimum.\nMoreover, we prove that a wide range of existing gradient-based methods almost\nsurely have bounded but non-convergent iterates in a constructed zero-sum game\nfor suitably small learning rates. It nonetheless remains an open question\nwhether such behavior can arise in high-dimensional games of interest to ML\npractitioners, such as GANs or multi-agent RL.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 12:11:18 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 12:49:09 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 09:14:59 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Letcher", "Alistair", ""]]}, {"id": "2005.12657", "submitter": "Xin Yao", "authors": "Xin Yao, Lifeng Sun", "title": "Continual Local Training for Better Initialization of Federated Models", "comments": "This paper has been accepted to 2020 IEEE International Conference on\n  Image Processing (ICIP 2020)", "journal-ref": null, "doi": "10.1109/ICIP40778.2020.9190968", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) refers to the learning paradigm that trains machine\nlearning models directly in the decentralized systems consisting of smart edge\ndevices without transmitting the raw data, which avoids the heavy communication\ncosts and privacy concerns. Given the typical heterogeneous data distributions\nin such situations, the popular FL algorithm \\emph{Federated Averaging}\n(FedAvg) suffers from weight divergence and thus cannot achieve a competitive\nperformance for the global model (denoted as the \\emph{initial performance} in\nFL) compared to centralized methods. In this paper, we propose the local\ncontinual training strategy to address this problem. Importance weights are\nevaluated on a small proxy dataset on the central server and then used to\nconstrain the local training. With this additional term, we alleviate the\nweight divergence and continually integrate the knowledge on different local\nclients into the global model, which ensures a better generalization ability.\nExperiments on various FL settings demonstrate that our method significantly\nimproves the initial performance of federated models with few extra\ncommunication costs.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 12:27:31 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Yao", "Xin", ""], ["Sun", "Lifeng", ""]]}, {"id": "2005.12661", "submitter": "Alessio Monti", "authors": "Alessio Monti, Alessia Bertugli, Simone Calderara, Rita Cucchiara", "title": "DAG-Net: Double Attentive Graph Neural Network for Trajectory\n  Forecasting", "comments": "Accepted at ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding human motion behaviour is a critical task for several possible\napplications like self-driving cars or social robots, and in general for all\nthose settings where an autonomous agent has to navigate inside a human-centric\nenvironment. This is non-trivial because human motion is inherently\nmulti-modal: given a history of human motion paths, there are many plausible\nways by which people could move in the future. Additionally, people activities\nare often driven by goals, e.g. reaching particular locations or interacting\nwith the environment. We address the aforementioned aspects by proposing a new\nrecurrent generative model that considers both single agents' future goals and\ninteractions between different agents. The model exploits a double\nattention-based graph neural network to collect information about the mutual\ninfluences among different agents and to integrate it with data about agents'\npossible future objectives. Our proposal is general enough to be applied to\ndifferent scenarios: the model achieves state-of-the-art results in both urban\nenvironments and also in sports applications.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 12:34:20 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 10:50:08 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Monti", "Alessio", ""], ["Bertugli", "Alessia", ""], ["Calderara", "Simone", ""], ["Cucchiara", "Rita", ""]]}, {"id": "2005.12662", "submitter": "Zihao Wang", "authors": "Zihao Wang, Clair Vandersteen, Thomas Demarcy, Dan Gnansia, Charles\n  Raffaelli, Nicolas Guevara, Herv\\'e Delingette", "title": "A Deep Learning based Fast Signed Distance Map Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": "MIDL/2020/ExtendedAbstract/b2N5ZuEouu", "categories": "cs.GR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signed distance map (SDM) is a common representation of surfaces in medical\nimage analysis and machine learning. The computational complexity of SDM for 3D\nparametric shapes is often a bottleneck in many applications, thus limiting\ntheir interest. In this paper, we propose a learning based SDM generation\nneural network which is demonstrated on a tridimensional cochlea shape model\nparameterized by 4 shape parameters. The proposed SDM Neural Network generates\na cochlea signed distance map depending on four input parameters and we show\nthat the deep learning approach leads to a 60 fold improvement in the time of\ncomputation compared to more classical SDM generation methods. Therefore, the\nproposed approach achieves a good trade-off between accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 12:36:19 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Wang", "Zihao", ""], ["Vandersteen", "Clair", ""], ["Demarcy", "Thomas", ""], ["Gnansia", "Dan", ""], ["Raffaelli", "Charles", ""], ["Guevara", "Nicolas", ""], ["Delingette", "Herv\u00e9", ""]]}, {"id": "2005.12668", "submitter": "Tom Hope", "authors": "Tom Hope, Jason Portenoy, Kishore Vasan, Jonathan Borchardt, Eric\n  Horvitz, Daniel S. Weld, Marti A. Hearst, Jevin West", "title": "SciSight: Combining faceted navigation and research group detection for\n  COVID-19 exploratory scientific search", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DL cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has sparked unprecedented mobilization of scientists,\ngenerating a deluge of papers that makes it hard for researchers to keep track\nand explore new directions. Search engines are designed for targeted queries,\nnot for discovery of connections across a corpus. In this paper, we present\nSciSight, a system for exploratory search of COVID-19 research integrating two\nkey capabilities: first, exploring associations between biomedical facets\nautomatically extracted from papers (e.g., genes, drugs, diseases, patient\noutcomes); second, combining textual and network information to search and\nvisualize groups of researchers and their ties. SciSight has so far served over\n$15K$ users with over $42K$ page views and $13\\%$ returns.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 08:56:21 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 03:05:32 GMT"}, {"version": "v3", "created": "Sun, 20 Sep 2020 15:43:20 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Hope", "Tom", ""], ["Portenoy", "Jason", ""], ["Vasan", "Kishore", ""], ["Borchardt", "Jonathan", ""], ["Horvitz", "Eric", ""], ["Weld", "Daniel S.", ""], ["Hearst", "Marti A.", ""], ["West", "Jevin", ""]]}, {"id": "2005.12690", "submitter": "Mengqi Ji", "authors": "Mengqi Ji, Jinzhi Zhang, Qionghai Dai, Lu Fang", "title": "SurfaceNet+: An End-to-end 3D Neural Network for Very Sparse Multi-view\n  Stereopsis", "comments": "Accepted by IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI), May 2020", "journal-ref": "2020, IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI)", "doi": "10.1109/TPAMI.2020.2996798", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view stereopsis (MVS) tries to recover the 3D model from 2D images. As\nthe observations become sparser, the significant 3D information loss makes the\nMVS problem more challenging. Instead of only focusing on densely sampled\nconditions, we investigate sparse-MVS with large baseline angles since the\nsparser sensation is more practical and more cost-efficient. By investigating\nvarious observation sparsities, we show that the classical depth-fusion\npipeline becomes powerless for the case with a larger baseline angle that\nworsens the photo-consistency check. As another line of the solution, we\npresent SurfaceNet+, a volumetric method to handle the 'incompleteness' and the\n'inaccuracy' problems induced by a very sparse MVS setup. Specifically, the\nformer problem is handled by a novel volume-wise view selection approach. It\nowns superiority in selecting valid views while discarding invalid occluded\nviews by considering the geometric prior. Furthermore, the latter problem is\nhandled via a multi-scale strategy that consequently refines the recovered\ngeometry around the region with the repeating pattern. The experiments\ndemonstrate the tremendous performance gap between SurfaceNet+ and\nstate-of-the-art methods in terms of precision and recall. Under the extreme\nsparse-MVS settings in two datasets, where existing methods can only return\nvery few points, SurfaceNet+ still works as well as in the dense MVS setting.\nThe benchmark and the implementation are publicly available at\nhttps://github.com/mjiUST/SurfaceNet-plus.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 13:13:02 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Ji", "Mengqi", ""], ["Zhang", "Jinzhi", ""], ["Dai", "Qionghai", ""], ["Fang", "Lu", ""]]}, {"id": "2005.12719", "submitter": "Sebastian Pina-Otey", "authors": "Sebastian Pina-Otey, Federico S\\'anchez, Thorsten Lux and Vicens\n  Gaitan", "title": "Exhaustive Neural Importance Sampling applied to Monte Carlo event\n  generation", "comments": "Published in Physical Review D 102, 013003 (2020). Appeared at the\n  ICML 2020 Workshop on Invertible Neural Networks, Normalizing Flows, and\n  Explicit Likelihood Models (INNF+ 2020)", "journal-ref": "Phys. Rev. D 102, 013003 (2020)", "doi": "10.1103/PhysRevD.102.013003", "report-no": null, "categories": "hep-ex cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generation of accurate neutrino-nucleus cross-section models needed for\nneutrino oscillation experiments require simultaneously the description of many\ndegrees of freedom and precise calculations to model nuclear responses. The\ndetailed calculation of complete models makes the Monte Carlo generators slow\nand impractical. We present Exhaustive Neural Importance Sampling (ENIS), a\nmethod based on normalizing flows to find a suitable proposal density for\nrejection sampling automatically and efficiently, and discuss how this\ntechnique solves common issues of the rejection algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 13:45:45 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 06:26:06 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Pina-Otey", "Sebastian", ""], ["S\u00e1nchez", "Federico", ""], ["Lux", "Thorsten", ""], ["Gaitan", "Vicens", ""]]}, {"id": "2005.12729", "submitter": "Andrew Ilyas", "authors": "Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras,\n  Firdaus Janoos, Larry Rudolph, Aleksander Madry", "title": "Implementation Matters in Deep Policy Gradients: A Case Study on PPO and\n  TRPO", "comments": "ICLR 2020 version. arXiv admin note: text overlap with\n  arXiv:1811.02553", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the roots of algorithmic progress in deep policy gradient algorithms\nthrough a case study on two popular algorithms: Proximal Policy Optimization\n(PPO) and Trust Region Policy Optimization (TRPO). Specifically, we investigate\nthe consequences of \"code-level optimizations:\" algorithm augmentations found\nonly in implementations or described as auxiliary details to the core\nalgorithm. Seemingly of secondary importance, such optimizations turn out to\nhave a major impact on agent behavior. Our results show that they (a) are\nresponsible for most of PPO's gain in cumulative reward over TRPO, and (b)\nfundamentally change how RL methods function. These insights show the\ndifficulty and importance of attributing performance gains in deep\nreinforcement learning. Code for reproducing our results is available at\nhttps://github.com/MadryLab/implementation-matters .\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 16:24:59 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Engstrom", "Logan", ""], ["Ilyas", "Andrew", ""], ["Santurkar", "Shibani", ""], ["Tsipras", "Dimitris", ""], ["Janoos", "Firdaus", ""], ["Rudolph", "Larry", ""], ["Madry", "Aleksander", ""]]}, {"id": "2005.12739", "submitter": "ByungSoo Ko", "authors": "Yang-Ho Ji, HeeJae Jun, Insik Kim, Jongtack Kim, Youngjoon Kim,\n  Byungsoo Ko, Hyong-Keun Kook, Jingeun Lee, Sangwon Lee, Sanghyuk Park", "title": "An Effective Pipeline for a Real-world Clothes Retrieval System", "comments": "2nd place solution on DeepFashion2 clothes retrieval challenge in\n  CVPR2020 workshop (CVFAD)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an effective pipeline for clothes retrieval system\nwhich has sturdiness on large-scale real-world fashion data. Our proposed\nmethod consists of three components: detection, retrieval, and post-processing.\nWe firstly conduct a detection task for precise retrieval on target clothes,\nthen retrieve the corresponding items with the metric learning-based model. To\nimprove the retrieval robustness against noise and misleading bounding boxes,\nwe apply post-processing methods such as weighted boxes fusion and feature\nconcatenation. With the proposed methodology, we achieved 2nd place in the\nDeepFashion2 Clothes Retrieval 2020 challenge.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 14:08:49 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Ji", "Yang-Ho", ""], ["Jun", "HeeJae", ""], ["Kim", "Insik", ""], ["Kim", "Jongtack", ""], ["Kim", "Youngjoon", ""], ["Ko", "Byungsoo", ""], ["Kook", "Hyong-Keun", ""], ["Lee", "Jingeun", ""], ["Lee", "Sangwon", ""], ["Park", "Sanghyuk", ""]]}, {"id": "2005.12741", "submitter": "Mengmi Zhang", "authors": "Mengmi Zhang, Gabriel Kreiman", "title": "What am I Searching for: Zero-shot Target Identity Inference in Visual\n  Search", "comments": "this was a mistaken new submission and a pointer to arXiv:1807.11926", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we infer intentions from a person's actions? As an example problem, here\nwe consider how to decipher what a person is searching for by decoding their\neye movement behavior. We conducted two psychophysics experiments where we\nmonitored eye movements while subjects searched for a target object. We defined\nthe fixations falling on \\textit{non-target} objects as \"error fixations\".\nUsing those error fixations, we developed a model (InferNet) to infer what the\ntarget was. InferNet uses a pre-trained convolutional neural network to extract\nfeatures from the error fixations and computes a similarity map between the\nerror fixations and all locations across the search image. The model\nconsolidates the similarity maps across layers and integrates these maps across\nall error fixations. InferNet successfully identifies the subject's goal and\noutperforms competitive null models, even without any object-specific training\non the inference task.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 04:53:32 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 19:49:41 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Zhang", "Mengmi", ""], ["Kreiman", "Gabriel", ""]]}, {"id": "2005.12742", "submitter": "Oliver Mey", "authors": "Oliver Mey, Willi Neudeck, Andr\\'e Schneider and Olaf Enge-Rosenblatt", "title": "Machine Learning-Based Unbalance Detection of a Rotating Shaft Using\n  Vibration Data", "comments": "Contribution at IEEE ETFA 2020 (25th International Conference on\n  Emerging Technologies and Factory Automation, Vienna)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fault detection at rotating machinery with the help of vibration sensors\noffers the possibility to detect damage to machines at an early stage and to\nprevent production downtimes by taking appropriate measures. The analysis of\nthe vibration data using methods of machine learning promises a significant\nreduction in the associated analysis effort and a further improvement in\ndiagnostic accuracy. Here we publish a dataset which is used as a basis for the\ndevelopment and evaluation of algorithms for unbalance detection. For this\npurpose, unbalances of various sizes were attached to a rotating shaft using a\n3D-printed holder. In a speed range from approx. 630 RPM to 2330 RPM, three\nsensors were used to record vibrations on the rotating shaft at a sampling rate\nof 4096 values per second. A development and an evaluation dataset are\navailable for each unbalance strength. Using the dataset recorded in this way,\nfully connected and convolutional neural networks, Hidden Markov Models and\nRandom Forest classifications on the basis of automatically extracted time\nseries features were tested. With a prediction accuracy of 98.6 % on the\nevaluation dataset, the best result could be achieved with a fully-connected\nneural network that receives the scaled FFT-transformed vibration data as\ninput.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 14:11:32 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 06:34:42 GMT"}, {"version": "v3", "created": "Fri, 31 Jul 2020 14:01:05 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Mey", "Oliver", ""], ["Neudeck", "Willi", ""], ["Schneider", "Andr\u00e9", ""], ["Enge-Rosenblatt", "Olaf", ""]]}, {"id": "2005.12743", "submitter": "Arushi Gupta", "authors": "Arushi Gupta", "title": "Inherent Noise in Gradient Based Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work has examined the ability of larger capacity neural networks to\ngeneralize better than smaller ones, even without explicit regularizers, by\nanalyzing gradient based algorithms such as GD and SGD. The presence of noise\nand its effect on robustness to parameter perturbations has been linked to\ngeneralization. We examine a property of GD and SGD, namely that instead of\niterating through all scalar weights in the network and updating them one by\none, GD (and SGD) updates all the parameters at the same time. As a result,\neach parameter $w^i$ calculates its partial derivative at the stale parameter\n$\\mathbf{w_t}$, but then suffers loss $\\hat{L}(\\mathbf{w_{t+1}})$. We show that\nthis causes noise to be introduced into the optimization. We find that this\nnoise penalizes models that are sensitive to perturbations in the weights. We\nfind that penalties are most pronounced for batches that are currently being\nused to update, and are higher for larger models.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 14:12:22 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Gupta", "Arushi", ""]]}, {"id": "2005.12766", "submitter": "Hongchao Fang", "authors": "Hongchao Fang, Sicheng Wang, Meng Zhou, Jiayuan Ding, Pengtao Xie", "title": "CERT: Contrastive Self-supervised Learning for Language Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained language models such as BERT, GPT have shown great effectiveness\nin language understanding. The auxiliary predictive tasks in existing\npretraining approaches are mostly defined on tokens, thus may not be able to\ncapture sentence-level semantics very well. To address this issue, we propose\nCERT: Contrastive self-supervised Encoder Representations from Transformers,\nwhich pretrains language representation models using contrastive\nself-supervised learning at the sentence level. CERT creates augmentations of\noriginal sentences using back-translation. Then it finetunes a pretrained\nlanguage encoder (e.g., BERT) by predicting whether two augmented sentences\noriginate from the same sentence. CERT is simple to use and can be flexibly\nplugged into any pretraining-finetuning NLP pipeline. We evaluate CERT on 11\nnatural language understanding tasks in the GLUE benchmark where CERT\noutperforms BERT on 7 tasks, achieves the same performance as BERT on 2 tasks,\nand performs worse than BERT on 2 tasks. On the averaged score of the 11 tasks,\nCERT outperforms BERT. The data and code are available at\nhttps://github.com/UCSD-AI4H/CERT\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 16:20:38 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 12:47:18 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Fang", "Hongchao", ""], ["Wang", "Sicheng", ""], ["Zhou", "Meng", ""], ["Ding", "Jiayuan", ""], ["Xie", "Pengtao", ""]]}, {"id": "2005.12770", "submitter": "Deepanway Ghosal", "authors": "Deepanway Ghosal, Maheshkumar H. Kolekar", "title": "Visual Interest Prediction with Attentive Multi-Task Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Visual interest & affect prediction is a very interesting area of research in\nthe area of computer vision. In this paper, we propose a transfer learning and\nattention mechanism based neural network model to predict visual interest &\naffective dimensions in digital photos. Learning the multi-dimensional affects\nis addressed through a multi-task learning framework. With various experiments\nwe show the effectiveness of the proposed approach. Evaluation of our model on\nthe benchmark dataset shows large improvement over current state-of-the-art\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 14:49:34 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 10:05:58 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Ghosal", "Deepanway", ""], ["Kolekar", "Maheshkumar H.", ""]]}, {"id": "2005.12781", "submitter": "Bingqing Yu", "authors": "Jacopo Tagliabue, Bingqing Yu, Marie Beaulieu", "title": "How to Grow a (Product) Tree: Personalized Category Suggestions for\n  eCommerce Type-Ahead", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an attempt to balance precision and recall in the search page, leading\ndigital shops have been effectively nudging users into select category facets\nas early as in the type-ahead suggestions. In this work, we present\nSessionPath, a novel neural network model that improves facet suggestions on\ntwo counts: first, the model is able to leverage session embeddings to provide\nscalable personalization; second, SessionPath predicts facets by explicitly\nproducing a probability distribution at each node in the taxonomy path. We\nbenchmark SessionPath on two partnering shops against count-based and neural\nmodels, and show how business requirements and model behavior can be combined\nin a principled way.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 15:03:16 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Tagliabue", "Jacopo", ""], ["Yu", "Bingqing", ""], ["Beaulieu", "Marie", ""]]}, {"id": "2005.12782", "submitter": "Herv\\'e Chabanne", "authors": "Herv\\'e Chabanne and Vincent Despiegel and Linda Guiga", "title": "A Protection against the Extraction of Neural Network Models", "comments": "Add Noisy Identity Parasitic layers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given oracle access to a Neural Network (NN), it is possible to extract its\nunderlying model. We here introduce a protection by adding parasitic layers\nwhich keep the underlying NN's predictions mostly unchanged while complexifying\nthe task of reverse-engineering. Our countermeasure relies on approximating a\nnoisy identity mapping with a Convolutional NN. We explain why the introduction\nof new parasitic layers complexifies the attacks. We report experiments\nregarding the performance and the accuracy of the protected NN.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 15:04:29 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 08:25:07 GMT"}, {"version": "v3", "created": "Fri, 31 Jul 2020 09:41:41 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Chabanne", "Herv\u00e9", ""], ["Despiegel", "Vincent", ""], ["Guiga", "Linda", ""]]}, {"id": "2005.12800", "submitter": "Eyke H\\\"ullermeier", "authors": "Eyke H\\\"ullermeier", "title": "Towards Analogy-Based Explanations in Machine Learning", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principles of analogical reasoning have recently been applied in the context\nof machine learning, for example to develop new methods for classification and\npreference learning. In this paper, we argue that, while analogical reasoning\nis certainly useful for constructing new learning algorithms with high\npredictive accuracy, is is arguably not less interesting from an\ninterpretability and explainability point of view. More specifically, we take\nthe view that an analogy-based approach is a viable alternative to existing\napproaches in the realm of explainable AI and interpretable machine learning,\nand that analogy-based explanations of the predictions produced by a machine\nlearning algorithm can complement similarity-based explanations in a meaningful\nway. To corroborate these claims, we outline the basic idea of an analogy-based\nexplanation and illustrate its potential usefulness by means of some examples.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 06:41:35 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2005.12801", "submitter": "Kiant\\'e Brantley", "authors": "Kiant\\'e Brantley, Amr Sharaf, Hal Daum\\'e III", "title": "Active Imitation Learning with Noisy Guidance", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning algorithms provide state-of-the-art results on many\nstructured prediction tasks by learning near-optimal search policies. Such\nalgorithms assume training-time access to an expert that can provide the\noptimal action at any queried state; unfortunately, the number of such queries\nis often prohibitive, frequently rendering these approaches impractical. To\ncombat this query complexity, we consider an active learning setting in which\nthe learning algorithm has additional access to a much cheaper noisy heuristic\nthat provides noisy guidance. Our algorithm, LEAQI, learns a difference\nclassifier that predicts when the expert is likely to disagree with the\nheuristic, and queries the expert only when necessary. We apply LEAQI to three\nsequence labeling tasks, demonstrating significantly fewer queries to the\nexpert and comparable (or better) accuracies over a passive approach.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 15:35:46 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Brantley", "Kiant\u00e9", ""], ["Sharaf", "Amr", ""], ["Daum\u00e9", "Hal", "III"]]}, {"id": "2005.12815", "submitter": "Diego Aghi", "authors": "Diego Aghi, Vittorio Mazzia, Marcello Chiaberge", "title": "Local Motion Planner for Autonomous Navigation in Vineyards with a RGB-D\n  Camera-Based Algorithm and Deep Learning Synergy", "comments": null, "journal-ref": null, "doi": "10.3390/machines8020027", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the advent of agriculture 3.0 and 4.0, researchers are increasingly\nfocusing on the development of innovative smart farming and precision\nagriculture technologies by introducing automation and robotics into the\nagricultural processes. Autonomous agricultural field machines have been\ngaining significant attention from farmers and industries to reduce costs,\nhuman workload, and required resources. Nevertheless, achieving sufficient\nautonomous navigation capabilities requires the simultaneous cooperation of\ndifferent processes; localization, mapping, and path planning are just some of\nthe steps that aim at providing to the machine the right set of skills to\noperate in semi-structured and unstructured environments. In this context, this\nstudy presents a low-cost local motion planner for autonomous navigation in\nvineyards based only on an RGB-D camera, low range hardware, and a dual layer\ncontrol algorithm. The first algorithm exploits the disparity map and its depth\nrepresentation to generate a proportional control for the robotic platform.\nConcurrently, a second back-up algorithm, based on representations learning and\nresilient to illumination variations, can take control of the machine in case\nof a momentaneous failure of the first block. Moreover, due to the double\nnature of the system, after initial training of the deep learning model with an\ninitial dataset, the strict synergy between the two algorithms opens the\npossibility of exploiting new automatically labeled data, coming from the\nfield, to extend the existing model knowledge. The machine learning algorithm\nhas been trained and tested, using transfer learning, with acquired images\nduring different field surveys in the North region of Italy and then optimized\nfor on-device inference with model pruning and quantization. Finally, the\noverall system has been validated with a customized robot platform in the\nrelevant environment.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 15:47:42 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Aghi", "Diego", ""], ["Mazzia", "Vittorio", ""], ["Chiaberge", "Marcello", ""]]}, {"id": "2005.12833", "submitter": "Laila Rasmy", "authors": "Laila Rasmy, Yang Xiang, Ziqian Xie, Cui Tao and Degui Zhi", "title": "Med-BERT: pre-trained contextualized embeddings on large-scale\n  structured electronic health records for disease prediction", "comments": "L.R., X.Y., and Z.X. share first authorship of this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) based predictive models from electronic health records\n(EHR) deliver impressive performance in many clinical tasks. Large training\ncohorts, however, are often required to achieve high accuracy, hindering the\nadoption of DL-based models in scenarios with limited training data size.\nRecently, bidirectional encoder representations from transformers (BERT) and\nrelated models have achieved tremendous successes in the natural language\nprocessing domain. The pre-training of BERT on a very large training corpus\ngenerates contextualized embeddings that can boost the performance of models\ntrained on smaller datasets. We propose Med-BERT, which adapts the BERT\nframework for pre-training contextualized embedding models on structured\ndiagnosis data from 28,490,650 patients EHR dataset. Fine-tuning experiments\nare conducted on two disease-prediction tasks: (1) prediction of heart failure\nin patients with diabetes and (2) prediction of pancreatic cancer from two\nclinical databases. Med-BERT substantially improves prediction accuracy,\nboosting the area under receiver operating characteristics curve (AUC) by\n2.02-7.12%. In particular, pre-trained Med-BERT substantially improves the\nperformance of tasks with very small fine-tuning training sets (300-500\nsamples) boosting the AUC by more than 20% or equivalent to the AUC of 10 times\nlarger training set. We believe that Med-BERT will benefit disease-prediction\nstudies with small local training datasets, reduce data collection expenses,\nand accelerate the pace of artificial intelligence aided healthcare.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 05:07:17 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Rasmy", "Laila", ""], ["Xiang", "Yang", ""], ["Xie", "Ziqian", ""], ["Tao", "Cui", ""], ["Zhi", "Degui", ""]]}, {"id": "2005.12838", "submitter": "Bo Li", "authors": "Bo Li, Marius de Groot, Rebecca M. E. Steketee, Rozanna Meijboom,\n  Marion Smits, Meike W. Vernooij, M. Arfan Ikram, Jiren Liu, Wiro J. Niessen,\n  Esther E. Bron", "title": "Neuro4Neuro: A neural network approach for neural tract segmentation\n  using large-scale population-based diffusion imaging", "comments": "Preprint to be published in NeuroImage", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subtle changes in white matter (WM) microstructure have been associated with\nnormal aging and neurodegeneration. To study these associations in more detail,\nit is highly important that the WM tracts can be accurately and reproducibly\ncharacterized from brain diffusion MRI. In addition, to enable analysis of WM\ntracts in large datasets and in clinical practice it is essential to have\nmethodology that is fast and easy to apply. This work therefore presents a new\napproach for WM tract segmentation: Neuro4Neuro, that is capable of direct\nextraction of WM tracts from diffusion tensor images using convolutional neural\nnetwork (CNN). This 3D end-to-end method is trained to segment 25 WM tracts in\naging individuals from a large population-based study (N=9752, 1.5T MRI). The\nproposed method showed good segmentation performance and high reproducibility,\ni.e., a high spatial agreement (Cohen's kappa, k = 0.72 ~ 0.83) and a low\nscan-rescan error in tract-specific diffusion measures (e.g., fractional\nanisotropy: error = 1% ~ 5%). The reproducibility of the proposed method was\nhigher than that of a tractography-based segmentation algorithm, while being\norders of magnitude faster (0.5s to segment one tract). In addition, we showed\nthat the method successfully generalizes to diffusion scans from an external\ndementia dataset (N=58, 3T MRI). In two proof-of-principle experiments, we\nassociated WM microstructure obtained using the proposed method with age in a\nnormal elderly population, and with disease subtypes in a dementia cohort. In\nconcordance with the literature, results showed a widespread reduction of\nmicrostructural organization with aging and substantial group-wise\nmicrostructure differences between dementia subtypes. In conclusion, we\npresented a highly reproducible and fast method for WM tract segmentation that\nhas the potential of being used in large-scale studies and clinical practice.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 16:14:31 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Li", "Bo", ""], ["de Groot", "Marius", ""], ["Steketee", "Rebecca M. E.", ""], ["Meijboom", "Rozanna", ""], ["Smits", "Marion", ""], ["Vernooij", "Meike W.", ""], ["Ikram", "M. Arfan", ""], ["Liu", "Jiren", ""], ["Niessen", "Wiro J.", ""], ["Bron", "Esther E.", ""]]}, {"id": "2005.12844", "submitter": "Sushrut Karmalkar", "authors": "Ilias Diakonikolas, Surbhi Goel, Sushrut Karmalkar, Adam R. Klivans,\n  Mahdi Soltanolkotabi", "title": "Approximation Schemes for ReLU Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the fundamental problem of ReLU regression, where the goal is to\noutput the best fitting ReLU with respect to square loss given access to draws\nfrom some unknown distribution. We give the first efficient, constant-factor\napproximation algorithm for this problem assuming the underlying distribution\nsatisfies some weak concentration and anti-concentration conditions (and\nincludes, for example, all log-concave distributions). This solves the main\nopen problem of Goel et al., who proved hardness results for any exact\nalgorithm for ReLU regression (up to an additive $\\epsilon$). Using more\nsophisticated techniques, we can improve our results and obtain a\npolynomial-time approximation scheme for any subgaussian distribution. Given\nthe aforementioned hardness results, these guarantees can not be substantially\nimproved.\n  Our main insight is a new characterization of surrogate losses for nonconvex\nactivations. While prior work had established the existence of convex\nsurrogates for monotone activations, we show that properties of the underlying\ndistribution actually induce strong convexity for the loss, allowing us to\nrelate the global minimum to the activation's Chow parameters.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 16:26:17 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 18:08:38 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Goel", "Surbhi", ""], ["Karmalkar", "Sushrut", ""], ["Klivans", "Adam R.", ""], ["Soltanolkotabi", "Mahdi", ""]]}, {"id": "2005.12855", "submitter": "Alexander Wong", "authors": "Alexander Wong, Zhong Qiu Lin, Linda Wang, Audrey G. Chung, Beiyi\n  Shen, Almas Abbasi, Mahsa Hoshmand-Kochi, and Timothy Q. Duong", "title": "COVID-Net S: Towards computer-aided severity assessment via training and\n  validation of deep neural networks for geographic extent and opacity extent\n  scoring of chest X-rays for SARS-CoV-2 lung disease severity", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: A critical step in effective care and treatment planning for\nsevere acute respiratory syndrome coronavirus 2 (SARS-CoV-2), the cause of the\nCOVID-19 pandemic, is the assessment of the severity of disease progression.\nChest x-rays (CXRs) are often used to assess SARS-CoV-2 severity, with two\nimportant assessment metrics being extent of lung involvement and degree of\nopacity. In this proof-of-concept study, we assess the feasibility of\ncomputer-aided scoring of CXRs of SARS-CoV-2 lung disease severity using a deep\nlearning system.\n  Materials and Methods: Data consisted of 396 CXRs from SARS-CoV-2 positive\npatient cases. Geographic extent and opacity extent were scored by two\nboard-certified expert chest radiologists (with 20+ years of experience) and a\n2nd-year radiology resident. The deep neural networks used in this study, which\nwe name COVID-Net S, are based on a COVID-Net network architecture. 100\nversions of the network were independently learned (50 to perform geographic\nextent scoring and 50 to perform opacity extent scoring) using random subsets\nof CXRs from the study, and we evaluated the networks using stratified Monte\nCarlo cross-validation experiments.\n  Findings: The COVID-Net S deep neural networks yielded R$^2$ of 0.664 $\\pm$\n0.032 and 0.635 $\\pm$ 0.044 between predicted scores and radiologist scores for\ngeographic extent and opacity extent, respectively, in stratified Monte Carlo\ncross-validation experiments. The best performing networks achieved R$^2$ of\n0.739 and 0.741 between predicted scores and radiologist scores for geographic\nextent and opacity extent, respectively.\n  Interpretation: The results are promising and suggest that the use of deep\nneural networks on CXRs could be an effective tool for computer-aided\nassessment of SARS-CoV-2 lung disease severity, although additional studies are\nneeded before adoption for routine clinical use.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 16:33:52 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 19:32:33 GMT"}, {"version": "v3", "created": "Sat, 22 Aug 2020 04:57:32 GMT"}, {"version": "v4", "created": "Fri, 16 Apr 2021 13:48:28 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Wong", "Alexander", ""], ["Lin", "Zhong Qiu", ""], ["Wang", "Linda", ""], ["Chung", "Audrey G.", ""], ["Shen", "Beiyi", ""], ["Abbasi", "Almas", ""], ["Hoshmand-Kochi", "Mahsa", ""], ["Duong", "Timothy Q.", ""]]}, {"id": "2005.12864", "submitter": "Giuseppe Canonaco", "authors": "Giuseppe Canonaco, Andrea Soprani, Manuel Roveri, Marcello Restelli", "title": "Time-Variant Variational Transfer for Value Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most of the transfer learning approaches to reinforcement learning (RL)\nthe distribution over the tasks is assumed to be stationary. Therefore, the\ntarget and source tasks are i.i.d. samples of the same distribution. In the\ncontext of this work, we consider the problem of transferring value functions\nthrough a variational method when the distribution that generates the tasks is\ntime-variant, proposing a solution that leverages this temporal structure\ninherent in the task generating process. Furthermore, by means of a\nfinite-sample analysis, the previously mentioned solution is theoretically\ncompared to its time-invariant version. Finally, we will provide an\nexperimental evaluation of the proposed technique with three distinct temporal\ndynamics in three different RL environments.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 16:52:26 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 13:13:12 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Canonaco", "Giuseppe", ""], ["Soprani", "Andrea", ""], ["Roveri", "Manuel", ""], ["Restelli", "Marcello", ""]]}, {"id": "2005.12890", "submitter": "Dominic Rose", "authors": "Dominic C. Rose, Jamie F. Mair and Juan P. Garrahan", "title": "A reinforcement learning approach to rare trajectory sampling", "comments": "55+6 pages, 7+1 figures", "journal-ref": "New J. Phys. (2020)", "doi": "10.1088/1367-2630/abd7bd", "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Very often when studying non-equilibrium systems one is interested in\nanalysing dynamical behaviour that occurs with very low probability, so called\nrare events. In practice, since rare events are by definition atypical, they\nare often difficult to access in a statistically significant way. What are\nrequired are strategies to \"make rare events typical\" so that they can be\ngenerated on demand. Here we present such a general approach to adaptively\nconstruct a dynamics that efficiently samples atypical events. We do so by\nexploiting the methods of reinforcement learning (RL), which refers to the set\nof machine learning techniques aimed at finding the optimal behaviour to\nmaximise a reward associated with the dynamics. We consider the general\nperspective of dynamical trajectory ensembles, whereby rare events are\ndescribed in terms of ensemble reweighting. By minimising the distance between\na reweighted ensemble and that of a suitably parametrised controlled dynamics\nwe arrive at a set of methods similar to those of RL to numerically approximate\nthe optimal dynamics that realises the rare behaviour of interest. As simple\nillustrations we consider in detail the problem of excursions of a random\nwalker, for the case of rare events with a finite time horizon; and the problem\nof a studying current statistics of a particle hopping in a ring geometry, for\nthe case of an infinite time horizon. We discuss natural extensions of the\nideas presented here, including to continuous-time Markov systems, first\npassage time problems and non-Markovian dynamics.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 17:29:01 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 16:03:45 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2020 15:14:23 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Rose", "Dominic C.", ""], ["Mair", "Jamie F.", ""], ["Garrahan", "Juan P.", ""]]}, {"id": "2005.12892", "submitter": "Munender Varshney Mr.", "authors": "Rajat, Munender Varshney, Pravendra Singh, Vinay P. Namboodiri", "title": "Minimizing Supervision in Multi-label Categorization", "comments": "Accepted in CVPR-W 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple categories of objects are present in most images. Treating this as a\nmulti-class classification is not justified. We treat this as a multi-label\nclassification problem. In this paper, we further aim to minimize the\nsupervision required for providing supervision in multi-label classification.\nSpecifically, we investigate an effective class of approaches that associate a\nweak localization with each category either in terms of the bounding box or\nsegmentation mask. Doing so improves the accuracy of multi-label\ncategorization. The approach we adopt is one of active learning, i.e.,\nincrementally selecting a set of samples that need supervision based on the\ncurrent model, obtaining supervision for these samples, retraining the model\nwith the additional set of supervised samples and proceeding again to select\nthe next set of samples. A crucial concern is the choice of the set of samples.\nIn doing so, we provide a novel insight, and no specific measure succeeds in\nobtaining a consistently improved selection criterion. We, therefore, provide a\nselection criterion that consistently improves the overall baseline criterion\nby choosing the top k set of samples for a varied set of criteria. Using this\ncriterion, we are able to show that we can retain more than 98% of the fully\nsupervised performance with just 20% of samples (and more than 96% using 10%)\nof the dataset on PASCAL VOC 2007 and 2012. Also, our proposed approach\nconsistently outperforms all other baseline metrics for all benchmark datasets\nand model combinations.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 17:35:47 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Rajat", "", ""], ["Varshney", "Munender", ""], ["Singh", "Pravendra", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "2005.12900", "submitter": "Yuxin Chen", "authors": "Gen Li, Yuting Wei, Yuejie Chi, Yuantao Gu, Yuxin Chen", "title": "Breaking the Sample Size Barrier in Model-Based Reinforcement Learning\n  with a Generative Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the sample efficiency of reinforcement learning in a\n$\\gamma$-discounted infinite-horizon Markov decision process (MDP) with state\nspace $\\mathcal{S}$ and action space $\\mathcal{A}$, assuming access to a\ngenerative model. Despite a number of prior work tackling this problem, a\ncomplete picture of the trade-offs between sample complexity and statistical\naccuracy is yet to be determined. In particular, prior results suffer from a\nsample size barrier, in the sense that their claimed statistical guarantees\nhold only when the sample size exceeds at least\n$\\frac{|\\mathcal{S}||\\mathcal{A}|}{(1-\\gamma)^2}$ (up to some log factor). The\ncurrent paper overcomes this barrier by certifying the minimax optimality of\nmodel-based reinforcement learning as soon as the sample size exceeds the order\nof $\\frac{|\\mathcal{S}||\\mathcal{A}|}{1-\\gamma}$ (modulo some log factor). More\nspecifically, a perturbed model-based planning algorithm provably finds an\n$\\varepsilon$-optimal policy with an order of $\\frac{|\\mathcal{S}||\\mathcal{A}|\n}{(1-\\gamma)^3\\varepsilon^2}\\log\\frac{|\\mathcal{S}||\\mathcal{A}|}{(1-\\gamma)\\varepsilon}$\nsamples for any $\\varepsilon \\in (0, \\frac{1}{1-\\gamma}]$. Along the way, we\nderive improved (instance-dependent) guarantees for model-based policy\nevaluation. To the best of our knowledge, this work provides the first\nminimax-optimal guarantee in a generative model that accommodates the entire\nrange of sample sizes (beyond which finding a meaningful policy is information\ntheoretically impossible).\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 17:53:18 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 17:50:39 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 02:02:42 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Li", "Gen", ""], ["Wei", "Yuting", ""], ["Chi", "Yuejie", ""], ["Gu", "Yuantao", ""], ["Chen", "Yuxin", ""]]}, {"id": "2005.12901", "submitter": "Cong Wang", "authors": "Cong Wang, Yanru Xiao, Xing Gao, Li Li, Jun Wang", "title": "A Framework for Behavioral Biometric Authentication using Deep Metric\n  Learning on Mobile Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile authentication using behavioral biometrics has been an active area of\nresearch. Existing research relies on building machine learning classifiers to\nrecognize an individual's unique patterns. However, these classifiers are not\npowerful enough to learn the discriminative features. When implemented on the\nmobile devices, they face new challenges from the behavioral dynamics, data\nprivacy and side-channel leaks. To address these challenges, we present a new\nframework to incorporate training on battery-powered mobile devices, so private\ndata never leaves the device and training can be flexibly scheduled to adapt\nthe behavioral patterns at runtime. We re-formulate the classification problem\ninto deep metric learning to improve the discriminative power and design an\neffective countermeasure to thwart side-channel leaks by embedding a noise\nsignature in the sensing signals without sacrificing too much usability. The\nexperiments demonstrate authentication accuracy over 95% on three public\ndatasets, a sheer 15% gain from multi-class classification with less data and\nrobustness against brute-force and side-channel attacks with 99% and 90%\nsuccess, respectively. We show the feasibility of training with mobile CPUs,\nwhere training 100 epochs takes less than 10 mins and can be boosted 3-5 times\nwith feature transfer. Finally, we profile memory, energy and computational\noverhead. Our results indicate that training consumes lower energy than\nwatching videos and slightly higher energy than playing games.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 17:56:20 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 16:39:08 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wang", "Cong", ""], ["Xiao", "Yanru", ""], ["Gao", "Xing", ""], ["Li", "Li", ""], ["Wang", "Jun", ""]]}, {"id": "2005.12914", "submitter": "Ziyu Xu", "authors": "Ziyu Xu, Chen Dan, Justin Khim, Pradeep Ravikumar", "title": "Class-Weighted Classification: Trade-offs and Robust Approaches", "comments": "28 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address imbalanced classification, the problem in which a label may have\nlow marginal probability relative to other labels, by weighting losses\naccording to the correct class. First, we examine the convergence rates of the\nexpected excess weighted risk of plug-in classifiers where the weighting for\nthe plug-in classifier and the risk may be different. This leads to irreducible\nerrors that do not converge to the weighted Bayes risk, which motivates our\nconsideration of robust risks. We define a robust risk that minimizes risk over\na set of weightings and show excess risk bounds for this problem. Finally, we\nshow that particular choices of the weighting set leads to a special instance\nof conditional value at risk (CVaR) from stochastic programming, which we call\nlabel conditional value at risk (LCVaR). Additionally, we generalize this\nweighting to derive a new robust risk problem that we call label heterogeneous\nconditional value at risk (LHCVaR). Finally, we empirically demonstrate the\nefficacy of LCVaR and LHCVaR on improving class conditional risks.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 16:45:13 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Xu", "Ziyu", ""], ["Dan", "Chen", ""], ["Khim", "Justin", ""], ["Ravikumar", "Pradeep", ""]]}, {"id": "2005.12964", "submitter": "Jianxin Ma", "authors": "Chang Zhou, Jianxin Ma, Jianwei Zhang, Jingren Zhou, Hongxia Yang", "title": "Contrastive Learning for Debiased Candidate Generation in Large-Scale\n  Recommender Systems", "comments": "Accepted by the 27th ACM SIGKDD Conference on Knowledge Discovery and\n  Data Mining (KDD 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep candidate generation (DCG) that narrows down the collection of relevant\nitems from billions to hundreds via representation learning has become\nprevalent in industrial recommender systems. Standard approaches approximate\nmaximum likelihood estimation (MLE) through sampling for better scalability and\naddress the problem of DCG in a way similar to language modeling. However, live\nrecommender systems face severe exposure bias and have a vocabulary several\norders of magnitude larger than that of natural language, implying that MLE\nwill preserve and even exacerbate the exposure bias in the long run in order to\nfaithfully fit the observed samples. In this paper, we theoretically prove that\na popular choice of contrastive loss is equivalent to reducing the exposure\nbias via inverse propensity weighting, which provides a new perspective for\nunderstanding the effectiveness of contrastive learning. Based on the\ntheoretical discovery, we design CLRec, a contrastive learning method to\nimprove DCG in terms of fairness, effectiveness and efficiency in recommender\nsystems with extremely large candidate size. We further improve upon CLRec and\npropose Multi-CLRec, for accurate multi-intention aware bias reduction. Our\nmethods have been successfully deployed in Taobao, where at least four-month\nonline A/B tests and offline analyses demonstrate its substantial improvements,\nincluding a dramatic reduction in the Matthew effect.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 08:15:23 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 17:46:41 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 09:21:25 GMT"}, {"version": "v4", "created": "Fri, 5 Jun 2020 17:15:04 GMT"}, {"version": "v5", "created": "Wed, 10 Jun 2020 14:32:52 GMT"}, {"version": "v6", "created": "Thu, 11 Jun 2020 12:29:48 GMT"}, {"version": "v7", "created": "Thu, 18 Feb 2021 07:41:38 GMT"}, {"version": "v8", "created": "Wed, 19 May 2021 08:14:17 GMT"}, {"version": "v9", "created": "Fri, 4 Jun 2021 16:34:46 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Zhou", "Chang", ""], ["Ma", "Jianxin", ""], ["Zhang", "Jianwei", ""], ["Zhou", "Jingren", ""], ["Yang", "Hongxia", ""]]}, {"id": "2005.12966", "submitter": "Zhiqiang Ma", "authors": "Zhiqiang Ma, Steven Pomerville, Mingyang Di, Armineh Nourbakhsh", "title": "SPot: A tool for identifying operating segments in financial tables", "comments": "This manuscript has been reviewed and accepted by SIGIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present SPot, an automated tool for detecting operating\nsegments and their related performance indicators from earnings reports. Due to\ntheir company-specific nature, operating segments cannot be detected using\ntaxonomy-based approaches. Instead, we train a Bidirectional RNN classifier\nthat can distinguish between common metrics such as \"revenue\" and\ncompany-specific metrics that are likely to be operating segments, such as\n\"iPhone\" or \"cloud services\". SPot surfaces the results in an interactive web\ninterface that allows users to trace and adjust performance metrics for each\noperating segment. This facilitates credit monitoring, enables them to perform\ncompetitive benchmarking more effectively, and can be used for trend analysis\nat company and sector levels.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 15:14:53 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Ma", "Zhiqiang", ""], ["Pomerville", "Steven", ""], ["Di", "Mingyang", ""], ["Nourbakhsh", "Armineh", ""]]}, {"id": "2005.12968", "submitter": "Benjamin Lansdell", "authors": "Benjamin Lansdell", "title": "Towards intervention-centric causal reasoning in learning agents", "comments": "11 page, 4 figures. Presented at ICLR 2020 workshop 'Causal learning\n  for decision making'", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interventions are central to causal learning and reasoning. Yet ultimately an\nintervention is an abstraction: an agent embedded in a physical environment\n(perhaps modeled as a Markov decision process) does not typically come equipped\nwith the notion of an intervention -- its action space is typically\nego-centric, without actions of the form `intervene on X'. Such a\ncorrespondence between ego-centric actions and interventions would be\nchallenging to hard-code. It would instead be better if an agent learnt which\nsequence of actions allow it to make targeted manipulations of the environment,\nand learnt corresponding representations that permitted learning from\nobservation. Here we show how a meta-learning approach can be used to perform\ncausal learning in this challenging setting, where the action-space is not a\nset of interventions and the observation space is a high-dimensional space with\na latent causal structure. A meta-reinforcement learning algorithm is used to\nlearn relationships that transfer on observational causal learning tasks. This\nwork shows how advances in deep reinforcement learning and meta-learning can\nprovide intervention-centric causal learning in high-dimensional environments\nwith a latent causal structure.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 18:53:04 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Lansdell", "Benjamin", ""]]}, {"id": "2005.12971", "submitter": "Chuan-Ju Wang", "authors": "Chuan-Ju Wang, Yu-Neng Chuang, Chih-Ming Chen, and Ming-Feng Tsai", "title": "Skewness Ranking Optimization for Personalized Recommendation", "comments": "Accepted by UAI'20. The first two authors contributed equally to this\n  work; author order was determined by seniority", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel optimization criterion that leverages\nfeatures of the skew normal distribution to better model the problem of\npersonalized recommendation. Specifically, the developed criterion borrows the\nconcept and the flexibility of the skew normal distribution, based on which\nthree hyperparameters are attached to the optimization criterion. Furthermore,\nfrom a theoretical point of view, we not only establish the relation between\nthe maximization of the proposed criterion and the shape parameter in the skew\nnormal distribution, but also provide the analogies and asymptotic analysis of\nthe proposed criterion to maximization of the area under the ROC curve.\nExperimental results conducted on a range of large-scale real-world datasets\nshow that our model significantly outperforms the state of the art and yields\nconsistently best performance on all tested datasets.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 00:59:22 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Wang", "Chuan-Ju", ""], ["Chuang", "Yu-Neng", ""], ["Chen", "Chih-Ming", ""], ["Tsai", "Ming-Feng", ""]]}, {"id": "2005.12974", "submitter": "Nasim Sonboli", "authors": "Nasim Sonboli, Farzad Eskandanian, Robin Burke, Weiwen Liu, Bamshad\n  Mobasher", "title": "Opportunistic Multi-aspect Fairness through Personalized Re-ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As recommender systems have become more widespread and moved into areas with\ngreater social impact, such as employment and housing, researchers have begun\nto seek ways to ensure fairness in the results that such systems produce. This\nwork has primarily focused on developing recommendation approaches in which\nfairness metrics are jointly optimized along with recommendation accuracy.\nHowever, the previous work had largely ignored how individual preferences may\nlimit the ability of an algorithm to produce fair recommendations. Furthermore,\nwith few exceptions, researchers have only considered scenarios in which\nfairness is measured relative to a single sensitive feature or attribute (such\nas race or gender). In this paper, we present a re-ranking approach to\nfairness-aware recommendation that learns individual preferences across\nmultiple fairness dimensions and uses them to enhance provider fairness in\nrecommendation results. Specifically, we show that our opportunistic and\nmetric-agnostic approach achieves a better trade-off between accuracy and\nfairness than prior re-ranking approaches and does so across multiple fairness\ndimensions.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 04:25:20 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Sonboli", "Nasim", ""], ["Eskandanian", "Farzad", ""], ["Burke", "Robin", ""], ["Liu", "Weiwen", ""], ["Mobasher", "Bamshad", ""]]}, {"id": "2005.12978", "submitter": "Simra Shahid", "authors": "Simra Shahid, Tanmay Singh, Yash Sharma, Kapil Sharma", "title": "Devising Malware Characterstics using Transformers", "comments": "5 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  With the increasing number of cybersecurity threats, it becomes more\ndifficult for researchers to skim through the security reports for malware\nanalysis. There is a need to be able to extract highly relevant sentences\nwithout having to read through the entire malware reports. In this paper, we\nare finding relevant malware behavior mentions from Advanced Persistent Threat\nReports. This main contribution is an opening attempt to Transformer the\napproach for malware behavior analysis.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 10:51:05 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Shahid", "Simra", ""], ["Singh", "Tanmay", ""], ["Sharma", "Yash", ""], ["Sharma", "Kapil", ""]]}, {"id": "2005.12979", "submitter": "Shijun Li", "authors": "Shijun Li, Wenqiang Lei, Qingyun Wu, Xiangnan He, Peng Jiang, Tat-Seng\n  Chua", "title": "Seamlessly Unifying Attributes and Items: Conversational Recommendation\n  for Cold-Start Users", "comments": "TOIS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Static recommendation methods like collaborative filtering suffer from the\ninherent limitation of performing real-time personalization for cold-start\nusers. Online recommendation, e.g., multi-armed bandit approach, addresses this\nlimitation by interactively exploring user preference online and pursuing the\nexploration-exploitation (EE) trade-off. However, existing bandit-based methods\nmodel recommendation actions homogeneously. Specifically, they only consider\nthe items as the arms, being incapable of handling the item attributes, which\nnaturally provide interpretable information of user's current demands and can\neffectively filter out undesired items. In this work, we consider the\nconversational recommendation for cold-start users, where a system can both ask\nthe attributes from and recommend items to a user interactively. This important\nscenario was studied in a recent work. However, it employs a hand-crafted\nfunction to decide when to ask attributes or make recommendations. Such\nseparate modeling of attributes and items makes the effectiveness of the system\nhighly rely on the choice of the hand-crafted function, thus introducing\nfragility to the system. To address this limitation, we seamlessly unify\nattributes and items in the same arm space and achieve their EE trade-offs\nautomatically using the framework of Thompson Sampling. Our Conversational\nThompson Sampling (ConTS) model holistically solves all questions in\nconversational recommendation by choosing the arm with the maximal reward to\nplay. Extensive experiments on three benchmark datasets show that ConTS\noutperforms the state-of-the-art methods Conversational UCB (ConUCB) and\nEstimation-Action-Reflection model in both metrics of success rate and average\nnumber of conversation turns.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 08:56:37 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 07:51:45 GMT"}, {"version": "v3", "created": "Wed, 30 Dec 2020 10:27:32 GMT"}, {"version": "v4", "created": "Tue, 8 Jun 2021 04:13:52 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Li", "Shijun", ""], ["Lei", "Wenqiang", ""], ["Wu", "Qingyun", ""], ["He", "Xiangnan", ""], ["Jiang", "Peng", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "2005.12981", "submitter": "Weinan Xu", "authors": "Weinan Xu, Hengxu He, Minshi Tan, Yunming Li, Jun Lang, Dongbai Guo", "title": "Deep Interest with Hierarchical Attention Network for Click-Through Rate\n  Prediction", "comments": "4 pages, SIGIR 2020 short paper accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Interest Network (DIN) is a state-of-the-art model which uses attention\nmechanism to capture user interests from historical behaviors. User interests\nintuitively follow a hierarchical pattern such that users generally show\ninterests from a higher-level then to a lower-level abstraction. Modeling such\nan interest hierarchy in an attention network can fundamentally improve the\nrepresentation of user behaviors. We, therefore, propose an improvement over\nDIN to model arbitrary interest hierarchy: Deep Interest with Hierarchical\nAttention Network (DHAN). In this model, a multi-dimensional hierarchical\nstructure is introduced on the first attention layer which attends to an\nindividual item, and the subsequent attention layers in the same dimension\nattend to higher-level hierarchy built on top of the lower corresponding\nlayers. To enable modeling of multiple dimensional hierarchies, an expanding\nmechanism is introduced to capture one to many hierarchies. This design enables\nDHAN to attend different importance to different hierarchical abstractions thus\ncan fully capture user interests at different dimensions (e.g. category, price,\nor brand).To validate our model, a simplified DHAN has applied to Click-Through\nRate (CTR) prediction and our experimental results on three public datasets\nwith two levels of the one-dimensional hierarchy only by category. It shows the\nsuperiority of DHAN with significant AUC uplift from 12% to 21% over DIN. DHAN\nis also compared with another state-of-the-art model Deep Interest Evolution\nNetwork (DIEN), which models temporal interest. The simplified DHAN also gets\nslight AUC uplift from 1.0% to 1.7% over DIEN. A potential future work can be a\ncombination of DHAN and DIEN to model both temporal and hierarchical interests.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 04:02:01 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Xu", "Weinan", ""], ["He", "Hengxu", ""], ["Tan", "Minshi", ""], ["Li", "Yunming", ""], ["Lang", "Jun", ""], ["Guo", "Dongbai", ""]]}, {"id": "2005.12982", "submitter": "Makbule Gulcin Ozsoy", "authors": "Makbule Gulcin Ozsoy", "title": "Utilizing FastText for Venue Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Venue recommendation systems model the past interactions (i.e., check-ins) of\nthe users and recommend venues. Traditional recommendation systems employ\ncollaborative filtering, content-based filtering or matrix factorization.\nRecently, vector space embedding and deep learning algorithms are also used for\nrecommendation. In this work, I propose a method for recommending top-k venues\nby utilizing the sequentiality feature of check-ins and a recent vector space\nembedding method, namely the FastText. Our proposed method; forms groups of\ncheck-ins, learns the vector space representations of the venues and utilizes\nthe learned embeddings to make venue recommendations. I measure the performance\nof the proposed method using a Foursquare check-in dataset.The results show\nthat the proposed method performs better than the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 14:57:12 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Ozsoy", "Makbule Gulcin", ""]]}, {"id": "2005.12987", "submitter": "Alessio Benavoli", "authors": "Alessio Benavoli and Dario Azzimonti and Dario Piga", "title": "Skew Gaussian Processes for Classification", "comments": "25 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) are distributions over functions, which provide a\nBayesian nonparametric approach to regression and classification. In spite of\ntheir success, GPs have limited use in some applications, for example, in some\ncases a symmetric distribution with respect to its mean is an unreasonable\nmodel. This implies, for instance, that the mean and the median coincide, while\nthe mean and median in an asymmetric (skewed) distribution can be different\nnumbers. In this paper, we propose Skew-Gaussian processes (SkewGPs) as a\nnon-parametric prior over functions. A SkewGP extends the multivariate Unified\nSkew-Normal distribution over finite dimensional vectors to a stochastic\nprocesses. The SkewGP class of distributions includes GPs and, therefore,\nSkewGPs inherit all good properties of GPs and increase their flexibility by\nallowing asymmetry in the probabilistic model. By exploiting the fact that\nSkewGP and probit likelihood are conjugate model, we derive closed form\nexpressions for the marginal likelihood and predictive distribution of this new\nnonparametric classifier. We verify empirically that the proposed SkewGP\nclassifier provides a better performance than a GP classifier based on either\nLaplace's method or Expectation Propagation.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 19:13:03 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Benavoli", "Alessio", ""], ["Azzimonti", "Dario", ""], ["Piga", "Dario", ""]]}, {"id": "2005.12991", "submitter": "Dawid Rymarczyk", "authors": "Dawid Rymarczyk and Adriana Borowa and Jacek Tabor and Bartosz\n  Zieli\\'nski", "title": "Kernel Self-Attention in Deep Multiple Instance Learning", "comments": "https://openaccess.thecvf.com/content/WACV2021/papers/Rymarczyk_Kernel_Self-Attention_for_Weakly-Supervised_Image_Classification_Using_Deep_Multiple_Instance_WACV_2021_paper.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Not all supervised learning problems are described by a pair of a fixed-size\ninput tensor and a label. In some cases, especially in medical image analysis,\na label corresponds to a bag of instances (e.g. image patches), and to classify\nsuch bag, aggregation of information from all of the instances is needed. There\nhave been several attempts to create a model working with a bag of instances,\nhowever, they are assuming that there are no dependencies within the bag and\nthe label is connected to at least one instance. In this work, we introduce\nSelf-Attention Attention-based MIL Pooling (SA-AbMILP) aggregation operation to\naccount for the dependencies between instances. We conduct several experiments\non MNIST, histological, microbiological, and retinal databases to show that\nSA-AbMILP performs better than other models. Additionally, we investigate\nkernel variations of Self-Attention and their influence on the results.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 14:59:13 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 12:36:50 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Rymarczyk", "Dawid", ""], ["Borowa", "Adriana", ""], ["Tabor", "Jacek", ""], ["Zieli\u0144ski", "Bartosz", ""]]}, {"id": "2005.13012", "submitter": "Eduardo C\\'esar Garrido-Merch\\'an", "authors": "Santiago Gonz\\'alez-Carvajal and Eduardo C. Garrido-Merch\\'an", "title": "Comparing BERT against traditional machine learning text classification", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The BERT model has arisen as a popular state-of-the-art machine learning\nmodel in the recent years that is able to cope with multiple NLP tasks such as\nsupervised text classification without human supervision. Its flexibility to\ncope with any type of corpus delivering great results has make this approach\nvery popular not only in academia but also in the industry. Although, there are\nlots of different approaches that have been used throughout the years with\nsuccess. In this work, we first present BERT and include a little review on\nclassical NLP approaches. Then, we empirically test with a suite of experiments\ndealing different scenarios the behaviour of BERT against the traditional\nTF-IDF vocabulary fed to machine learning algorithms. Our purpose of this work\nis to add empirical evidence to support or refuse the use of BERT as a default\non NLP tasks. Experiments show the superiority of BERT and its independence of\nfeatures of the NLP problem such as the language of the text adding empirical\nevidence to use BERT as a default technique to be used in NLP problems.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 20:14:39 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 15:48:52 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Gonz\u00e1lez-Carvajal", "Santiago", ""], ["Garrido-Merch\u00e1n", "Eduardo C.", ""]]}, {"id": "2005.13028", "submitter": "David K.E. Green", "authors": "David K. E. Green and Filip Rindler", "title": "Probabilistic solution of chaotic dynamical system inverse problems\n  using Bayesian Artificial Neural Networks", "comments": "36 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates the application of Bayesian Artificial Neural\nNetworks to Ordinary Differential Equation (ODE) inverse problems. We consider\nthe case of estimating an unknown chaotic dynamical system transition model\nfrom state observation data. Inverse problems for chaotic systems are\nnumerically challenging as small perturbations in model parameters can cause\nvery large changes in estimated forward trajectories. Bayesian Artificial\nNeural Networks can be used to simultaneously fit a model and estimate model\nparameter uncertainty. Knowledge of model parameter uncertainty can then be\nincorporated into the probabilistic estimates of the inferred system's forward\ntime evolution. The method is demonstrated numerically by analysing the chaotic\nSprott B system. Observations of the system are used to estimate a posterior\npredictive distribution over the weights of a parametric polynomial kernel\nArtificial Neural Network. It is shown that the proposed method is able to\nperform accurate time predictions. Further, the proposed method is able to\ncorrectly account for model uncertainties and provide useful prediction\nuncertainty bounds.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 20:35:02 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Green", "David K. E.", ""], ["Rindler", "Filip", ""]]}, {"id": "2005.13037", "submitter": "Naveen Sai Madiraju", "authors": "Naveen Madiraju, Homa Karimabadi", "title": "Instance Explainable Temporal Network For Multivariate Timeseries", "comments": "7 pages, 7 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep networks have been widely adopted, one of their shortcomings\nhas been their blackbox nature. One particularly difficult problem in machine\nlearning is multivariate time series (MVTS) classification. MVTS data arise in\nmany applications and are becoming ever more pervasive due to explosive growth\nof sensors and IoT devices. Here, we propose a novel network (IETNet) that\nidentifies the important channels in the classification decision for each\ninstance of inference. This feature also enables identification and removal of\nnon-predictive variables which would otherwise lead to overfit and/or\ninaccurate model. IETNet is an end-to-end network that combines temporal\nfeature extraction, variable selection, and joint variable interaction into a\nsingle learning framework. IETNet utilizes an 1D convolutions for temporal\nfeatures, a novel channel gate layer for variable-class assignment using an\nattention layer to perform cross channel reasoning and perform classification\nobjective. To gain insight into the learned temporal features and channels, we\nextract region of interest attention map along both time and channels. The\nviability of this network is demonstrated through a multivariate time series\ndata from N body simulations and spacecraft sensor data.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 20:55:24 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 22:56:10 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Madiraju", "Naveen", ""], ["Karimabadi", "Homa", ""]]}, {"id": "2005.13040", "submitter": "Rylan Perumal", "authors": "Rylan Perumal and Terence L van Zyl", "title": "Comparison of Recurrent Neural Network Architectures for Wildfire Spread\n  Modelling", "comments": null, "journal-ref": "2020 International SAUPEC/RobMech/PRASA Conference, Cape Town,\n  South Africa, 2020, pp. 1-6", "doi": "10.1109/SAUPEC/RobMech/PRASA48453.2020.9078028", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wildfire modelling is an attempt to reproduce fire behaviour. Through active\nfire analysis, it is possible to reproduce a dynamical process, such as\nwildfires, with limited duration time series data. Recurrent neural networks\n(RNNs) can model dynamic temporal behaviour due to their ability to remember\ntheir internal input. In this paper, we compare the Gated Recurrent Unit (GRU)\nand the Long Short-Term Memory (LSTM) network. We try to determine whether a\nwildfire continues to burn and given that it does, we aim to predict which one\nof the 8 cardinal directions the wildfire will spread in. Overall the GRU\nperforms better for longer time series than the LSTM. We have shown that\nalthough we are reasonable at predicting the direction in which the wildfire\nwill spread, we are not able to asses if the wildfire continues to burn due to\nthe lack of auxiliary data.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 20:58:22 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Perumal", "Rylan", ""], ["van Zyl", "Terence L", ""]]}, {"id": "2005.13053", "submitter": "Rihuan Ke", "authors": "Rihuan Ke, Aur\\'elie Bugeau, Nicolas Papadakis, Mark Kirkland, Peter\n  Schuetz, Carola-Bibiane Sch\\\"onlieb", "title": "Multi-task deep learning for image segmentation using recursive\n  approximation tasks", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2021.3062726", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully supervised deep neural networks for segmentation usually require a\nmassive amount of pixel-level labels which are manually expensive to create. In\nthis work, we develop a multi-task learning method to relax this constraint. We\nregard the segmentation problem as a sequence of approximation subproblems that\nare recursively defined and in increasing levels of approximation accuracy. The\nsubproblems are handled by a framework that consists of 1) a segmentation task\nthat learns from pixel-level ground truth segmentation masks of a small\nfraction of the images, 2) a recursive approximation task that conducts partial\nobject regions learning and data-driven mask evolution starting from partial\nmasks of each object instance, and 3) other problem oriented auxiliary tasks\nthat are trained with sparse annotations and promote the learning of dedicated\nfeatures. Most training images are only labeled by (rough) partial masks, which\ndo not contain exact object boundaries, rather than by their full segmentation\nmasks. During the training phase, the approximation task learns the statistics\nof these partial masks, and the partial regions are recursively increased\ntowards object boundaries aided by the learned information from the\nsegmentation task in a fully data-driven fashion. The network is trained on an\nextremely small amount of precisely segmented images and a large set of coarse\nlabels. Annotations can thus be obtained in a cheap way. We demonstrate the\nefficiency of our approach in three applications with microscopy images and\nultrasound images.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 21:35:26 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Ke", "Rihuan", ""], ["Bugeau", "Aur\u00e9lie", ""], ["Papadakis", "Nicolas", ""], ["Kirkland", "Mark", ""], ["Schuetz", "Peter", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""]]}, {"id": "2005.13078", "submitter": "Sakshi Arya", "authors": "Sakshi Arya and Yuhong Yang", "title": "To update or not to update? Delayed Nonparametric Bandits with\n  Randomized Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Delayed rewards problem in contextual bandits has been of interest in various\npractical settings. We study randomized allocation strategies and provide an\nunderstanding on how the exploration-exploitation tradeoff is affected by\ndelays in observing the rewards. In randomized strategies, the extent of\nexploration-exploitation is controlled by a user-determined exploration\nprobability sequence. In the presence of delayed rewards, one may choose\nbetween using the original exploration sequence that updates at every time\npoint or update the sequence only when a new reward is observed, leading to two\ncompeting strategies. In this work, we show that while both strategies may lead\nto strong consistency in allocation, the property holds for a wider scope of\nsituations for the latter. However, for finite sample performance, we\nillustrate that both strategies have their own advantages and disadvantages,\ndepending on the severity of the delay and underlying reward generating\nmechanisms.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 23:06:20 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Arya", "Sakshi", ""], ["Yang", "Yuhong", ""]]}, {"id": "2005.13085", "submitter": "Naoki Narisawa", "authors": "Naoki Narisawa, Nicolas Chauvet, Mikio Hasegawa and Makoto Naruse", "title": "Arm order recognition in multi-armed bandit problem with laser chaos\n  time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By exploiting ultrafast and irregular time series generated by lasers with\ndelayed feedback, we have previously demonstrated a scalable algorithm to solve\nmulti-armed bandit (MAB) problems utilizing the time-division multiplexing of\nlaser chaos time series. Although the algorithm detects the arm with the\nhighest reward expectation, the correct recognition of the order of arms in\nterms of reward expectations is not achievable. Here, we present an algorithm\nwhere the degree of exploration is adaptively controlled based on confidence\nintervals that represent the estimation accuracy of reward expectations. We\nhave demonstrated numerically that our approach did improve arm order\nrecognition accuracy significantly, along with reduced dependence on reward\nenvironments, and the total reward is almost maintained compared with\nconventional MAB methods. This study applies to sectors where the order\ninformation is critical, such as efficient allocation of resources in\ninformation and communications technology.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 23:43:54 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Narisawa", "Naoki", ""], ["Chauvet", "Nicolas", ""], ["Hasegawa", "Mikio", ""], ["Naruse", "Makoto", ""]]}, {"id": "2005.13092", "submitter": "Aditya Rawal", "authors": "Aditya Rawal, Joel Lehman, Felipe Petroski Such, Jeff Clune, Kenneth\n  O. Stanley", "title": "Synthetic Petri Dish: A Novel Surrogate Model for Rapid Architecture\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) explores a large space of architectural\nmotifs -- a compute-intensive process that often involves ground-truth\nevaluation of each motif by instantiating it within a large network, and\ntraining and evaluating the network with thousands of domain-specific data\nsamples. Inspired by how biological motifs such as cells are sometimes\nextracted from their natural environment and studied in an artificial Petri\ndish setting, this paper proposes the Synthetic Petri Dish model for evaluating\narchitectural motifs. In the Synthetic Petri Dish, architectural motifs are\ninstantiated in very small networks and evaluated using very few learned\nsynthetic data samples (to effectively approximate performance in the full\nproblem). The relative performance of motifs in the Synthetic Petri Dish can\nsubstitute for their ground-truth performance, thus accelerating the most\nexpensive step of NAS. Unlike other neural network-based prediction models that\nparse the structure of the motif to estimate its performance, the Synthetic\nPetri Dish predicts motif performance by training the actual motif in an\nartificial setting, thus deriving predictions from its true intrinsic\nproperties. Experiments in this paper demonstrate that the Synthetic Petri Dish\ncan therefore predict the performance of new motifs with significantly higher\naccuracy, especially when insufficient ground truth data is available. Our hope\nis that this work can inspire a new research direction in studying the\nperformance of extracted components of models in an alternative controlled\nsetting.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 00:12:06 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Rawal", "Aditya", ""], ["Lehman", "Joel", ""], ["Such", "Felipe Petroski", ""], ["Clune", "Jeff", ""], ["Stanley", "Kenneth O.", ""]]}, {"id": "2005.13097", "submitter": "Rasa Hosseinzadeh", "authors": "Murat A. Erdogdu, Rasa Hosseinzadeh", "title": "On the Convergence of Langevin Monte Carlo: The Interplay between Tail\n  Growth and Smoothness", "comments": "51 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study sampling from a target distribution ${\\nu_* = e^{-f}}$ using the\nunadjusted Langevin Monte Carlo (LMC) algorithm. For any potential function $f$\nwhose tails behave like ${\\|x\\|^\\alpha}$ for ${\\alpha \\in [1,2]}$, and has\n$\\beta$-H\\\"older continuous gradient, we prove that ${\\widetilde{\\mathcal{O}}\n\\Big(d^{\\frac{1}{\\beta}+\\frac{1+\\beta}{\\beta}(\\frac{2}{\\alpha} -\n\\boldsymbol{1}_{\\{\\alpha \\neq 1\\}})} \\epsilon^{-\\frac{1}{\\beta}}\\Big)}$ steps\nare sufficient to reach the $\\epsilon $-neighborhood of a $d$-dimensional\ntarget distribution $\\nu_*$ in KL-divergence. This convergence rate, in terms\nof $\\epsilon$ dependency, is not directly influenced by the tail growth rate\n$\\alpha$ of the potential function as long as its growth is at least linear,\nand it only relies on the order of smoothness $\\beta$. One notable consequence\nof this result is that for potentials with Lipschitz gradient, i.e. $\\beta=1$,\nour rate recovers the best known rate\n${\\widetilde{\\mathcal{O}}(d\\epsilon^{-1})}$ which was established for strongly\nconvex potentials in terms of $\\epsilon$ dependency, but we show that the same\nrate is achievable for a wider class of potentials that are degenerately convex\nat infinity. The growth rate $\\alpha$ starts to have an effect on the\nestablished rate in high dimensions where $d$ is large; furthermore, it\nrecovers the best-known dimension dependency when the tail growth of the\npotential is quadratic, i.e. ${\\alpha = 2}$, in the current setup. Our\nframework allows for finite perturbations, and any order of smoothness\n${\\beta\\in(0,1]}$; consequently, our results are applicable to a wide class of\nnon-convex potentials that are weakly smooth and exhibit at least linear tail\ngrowth.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 00:26:20 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Erdogdu", "Murat A.", ""], ["Hosseinzadeh", "Rasa", ""]]}, {"id": "2005.13099", "submitter": "Sahib Singh", "authors": "Sahib Singh, Harshvardhan Sikka, Sasikanth Kotti, Andrew Trask", "title": "Benchmarking Differentially Private Residual Networks for Medical\n  Imagery", "comments": "5 Pages, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we measure the effectiveness of $\\epsilon$-Differential Privacy\n(DP) when applied to medical imaging. We compare two robust differential\nprivacy mechanisms: Local-DP and DP-SGD and benchmark their performance when\nanalyzing medical imagery records. We analyze the trade-off between the model's\naccuracy and the level of privacy it guarantees, and also take a closer look to\nevaluate how useful these theoretical privacy guarantees actually prove to be\nin the real world medical setting.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 00:29:56 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 09:47:09 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 03:15:27 GMT"}, {"version": "v4", "created": "Sun, 19 Jul 2020 03:27:18 GMT"}, {"version": "v5", "created": "Sat, 5 Sep 2020 02:25:06 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Singh", "Sahib", ""], ["Sikka", "Harshvardhan", ""], ["Kotti", "Sasikanth", ""], ["Trask", "Andrew", ""]]}, {"id": "2005.13100", "submitter": "Marieme Ngom", "authors": "Marieme Ngom and Oana Marin", "title": "Fourier Neural Networks as Function Approximators and Differential\n  Equation Solvers", "comments": "22 pages, 10 figures Added figures to explain the initialization\n  strategy, fixed typos, updated abstract and modified title to make it more\n  self explanatory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Fourier neural network (FNN) that can be mapped directly to the\nFourier decomposition. The choice of activation and loss function yields\nresults that replicate a Fourier series expansion closely while preserving a\nstraightforward architecture with a single hidden layer. The simplicity of this\nnetwork architecture facilitates the integration with any other\nhigher-complexity networks, at a data pre- or postprocessing stage. We validate\nthis FNN on naturally periodic smooth functions and on piecewise continuous\nperiodic functions. We showcase the use of this FNN for modeling or solving\npartial differential equations with periodic boundary conditions. The main\nadvantages of the current approach are the validity of the solution outside the\ntraining region, interpretability of the trained model, and simplicity of use.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 00:30:58 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 19:56:18 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Ngom", "Marieme", ""], ["Marin", "Oana", ""]]}, {"id": "2005.13107", "submitter": "Zichao Wang", "authors": "Zichao Wang, Yi Gu, Andrew Lan, Richard Baraniuk", "title": "VarFA: A Variational Factor Analysis Framework For Efficient Bayesian\n  Learning Analytics", "comments": "edm 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose VarFA, a variational inference factor analysis framework that\nextends existing factor analysis models for educational data mining to\nefficiently output uncertainty estimation in the model's estimated factors.\nSuch uncertainty information is useful, for example, for an adaptive testing\nscenario, where additional tests can be administered if the model is not quite\ncertain about a students' skill level estimation. Traditional Bayesian\ninference methods that produce such uncertainty information are computationally\nexpensive and do not scale to large data sets. VarFA utilizes variational\ninference which makes it possible to efficiently perform Bayesian inference\neven on very large data sets. We use the sparse factor analysis model as a case\nstudy and demonstrate the efficacy of VarFA on both synthetic and real data\nsets. VarFA is also very general and can be applied to a wide array of factor\nanalysis models.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 01:03:07 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 20:46:06 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wang", "Zichao", ""], ["Gu", "Yi", ""], ["Lan", "Andrew", ""], ["Baraniuk", "Richard", ""]]}, {"id": "2005.13111", "submitter": "Lili Yu", "authors": "Kyle Swanson, Lili Yu, Tao Lei", "title": "Rationalizing Text Matching: Learning Sparse Alignments via Optimal\n  Transport", "comments": "To appear at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Selecting input features of top relevance has become a popular method for\nbuilding self-explaining models. In this work, we extend this selective\nrationalization approach to text matching, where the goal is to jointly select\nand align text pieces, such as tokens or sentences, as a justification for the\ndownstream prediction. Our approach employs optimal transport (OT) to find a\nminimal cost alignment between the inputs. However, directly applying OT often\nproduces dense and therefore uninterpretable alignments. To overcome this\nlimitation, we introduce novel constrained variants of the OT problem that\nresult in highly sparse alignments with controllable sparsity. Our model is\nend-to-end differentiable using the Sinkhorn algorithm for OT and can be\ntrained without any alignment annotations. We evaluate our model on the\nStackExchange, MultiNews, e-SNLI, and MultiRC datasets. Our model achieves very\nsparse rationale selections with high fidelity while preserving prediction\naccuracy compared to strong attention baseline models.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 01:20:49 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Swanson", "Kyle", ""], ["Yu", "Lili", ""], ["Lei", "Tao", ""]]}, {"id": "2005.13120", "submitter": "Shuyue Guan", "authors": "Shuyue Guan, Murray Loew, Hanseok Ko", "title": "Data Separability for Neural Network Classifiers and the Development of\n  a Separability Index", "comments": "11 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, the performance of a classifier depends on both the\nclassifier model and the dataset. For a specific neural network classifier, the\ntraining process varies with the training set used; some training data make\ntraining accuracy fast converged to high values, while some data may lead to\nslowly converged to lower accuracy. To quantify this phenomenon, we created the\nDistance-based Separability Index (DSI), which is independent of the classifier\nmodel, to measure the separability of datasets. In this paper, we consider the\nsituation where different classes of data are mixed together in the same\ndistribution is most difficult for classifiers to separate, and we show that\nthe DSI can indicate whether data belonging to different classes have similar\ndistributions. When comparing our proposed approach with several existing\nseparability/complexity measures using synthetic and real datasets, the results\nshow the DSI is an effective separability measure. We also discussed possible\napplications of the DSI in the fields of data science, machine learning, and\ndeep learning.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 01:49:19 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 03:23:17 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Guan", "Shuyue", ""], ["Loew", "Murray", ""], ["Ko", "Hanseok", ""]]}, {"id": "2005.13123", "submitter": "Matt DelVecchio", "authors": "Matthew DelVecchio, Bryse Flowers, William C. Headley", "title": "Effects of Forward Error Correction on Communications Aware Evasion\n  Attacks", "comments": null, "journal-ref": null, "doi": "10.1109/PIMRC48278.2020.9217343", "report-no": null, "categories": "eess.SP cs.CR cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown the impact of adversarial machine learning on deep\nneural networks (DNNs) developed for Radio Frequency Machine Learning (RFML)\napplications. While these attacks have been shown to be successful in\ndisrupting the performance of an eavesdropper, they fail to fully support the\nprimary goal of successful intended communication. To remedy this, a\ncommunications-aware attack framework was recently developed that allows for a\nmore effective balance between the opposing goals of evasion and intended\ncommunication through the novel use of a DNN to intelligently create the\nadversarial communication signal. Given the near ubiquitous usage of forward\nerror correction (FEC) coding in the majority of deployed systems to correct\nerrors that arise, incorporating FEC in this framework is a natural extension\nof this prior work and will allow for improved performance in more adverse\nenvironments. This work therefore provides contributions to the framework\nthrough improved loss functions and design considerations to incorporate\ninherent knowledge of the usage of FEC codes within the transmitted signal.\nPerformance analysis shows that FEC coding improves the communications aware\nadversarial attack even if no explicit knowledge of the coding scheme is\nassumed and allows for improved performance over the prior art in balancing the\nopposing goals of evasion and intended communications.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 01:58:26 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["DelVecchio", "Matthew", ""], ["Flowers", "Bryse", ""], ["Headley", "William C.", ""]]}, {"id": "2005.13124", "submitter": "Matt DelVecchio", "authors": "Matthew DelVecchio, Vanessa Arndorfer, William C. Headley", "title": "Investigating a Spectral Deception Loss Metric for Training Machine\n  Learning-based Evasion Attacks", "comments": null, "journal-ref": null, "doi": "10.1145/3395352.3402624", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial evasion attacks have been very successful in causing poor\nperformance in a wide variety of machine learning applications. One such\napplication is radio frequency spectrum sensing. While evasion attacks have\nproven particularly successful in this area, they have done so at the detriment\nof the signal's intended purpose. More specifically, for real-world\napplications of interest, the resulting perturbed signal that is transmitted to\nevade an eavesdropper must not deviate far from the original signal, less the\nintended information is destroyed. Recent work by the authors and others has\ndemonstrated an attack framework that allows for intelligent balancing between\nthese conflicting goals of evasion and communication. However, while these\nmethodologies consider creating adversarial signals that minimize\ncommunications degradation, they have been shown to do so at the expense of the\nspectral shape of the signal. This opens the adversarial signal up to defenses\nat the eavesdropper such as filtering, which could render the attack\nineffective. To remedy this, this work introduces a new spectral deception loss\nmetric that can be implemented during the training process to force the\nspectral shape to be more in-line with the original signal. As an initial proof\nof concept, a variety of methods are presented that provide a starting point\nfor this proposed loss. Through performance analysis, it is shown that these\ntechniques are effective in controlling the shape of the adversarial signal.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 02:02:03 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["DelVecchio", "Matthew", ""], ["Arndorfer", "Vanessa", ""], ["Headley", "William C.", ""]]}, {"id": "2005.13125", "submitter": "Kelechi Nwaike Mr.", "authors": "Kelechi Nwaike and Licheng Jiao", "title": "Counterfactual Detection meets Transfer Learning", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We can consider Counterfactuals as belonging in the domain of Discourse\nstructure and semantics, A core area in Natural Language Understanding and in\nthis paper, we introduce an approach to resolving counterfactual detection as\nwell as the indexing of the antecedents and consequents of Counterfactual\nstatements. While Transfer learning is already being applied to several NLP\ntasks, It has the characteristics to excel in a novel number of tasks. We show\nthat detecting Counterfactuals is a straightforward Binary Classification Task\nthat can be implemented with minimal adaptation on already existing model\nArchitectures, thanks to a well annotated training data set,and we introduce a\nnew end to end pipeline to process antecedents and consequents as an entity\nrecognition task, thus adapting them into Token Classification.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 02:02:57 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Nwaike", "Kelechi", ""], ["Jiao", "Licheng", ""]]}, {"id": "2005.13133", "submitter": "Deheng Qian", "authors": "Yanliang Zhu, Dongchun Ren, Mingyu Fan, Deheng Qian, Xin Li, Huaxia\n  Xia", "title": "Robust Trajectory Forecasting for Multiple Intelligent Agents in Dynamic\n  Scene", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trajectory forecasting, or trajectory prediction, of multiple interacting\nagents in dynamic scenes, is an important problem for many applications, such\nas robotic systems and autonomous driving. The problem is a great challenge\nbecause of the complex interactions among the agents and their interactions\nwith the surrounding scenes. In this paper, we present a novel method for the\nrobust trajectory forecasting of multiple intelligent agents in dynamic scenes.\nThe proposed method consists of three major interrelated components: an\ninteraction net for global spatiotemporal interactive feature extraction, an\nenvironment net for decoding dynamic scenes (i.e., the surrounding road\ntopology of an agent), and a prediction net that combines the spatiotemporal\nfeature, the scene feature, the past trajectories of agents and some random\nnoise for the robust trajectory prediction of agents. Experiments on\npedestrian-walking and vehicle-pedestrian heterogeneous datasets demonstrate\nthat the proposed method outperforms the state-of-the-art prediction methods in\nterms of prediction accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 02:32:55 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Zhu", "Yanliang", ""], ["Ren", "Dongchun", ""], ["Fan", "Mingyu", ""], ["Qian", "Deheng", ""], ["Li", "Xin", ""], ["Xia", "Huaxia", ""]]}, {"id": "2005.13135", "submitter": "Zhongpai Gao", "authors": "Zhongpai Gao, Guangtao Zhai, Junchi Yan, Xiaokang Yang", "title": "Permutation Matters: Anisotropic Convolutional Layer for Learning on\n  Point Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has witnessed a growing demand for efficient representation learning on\npoint clouds in many 3D computer vision applications. Behind the success story\nof convolutional neural networks (CNNs) is that the data (e.g., images) are\nEuclidean structured. However, point clouds are irregular and unordered.\nVarious point neural networks have been developed with isotropic filters or\nusing weighting matrices to overcome the structure inconsistency on point\nclouds. However, isotropic filters or weighting matrices limit the\nrepresentation power. In this paper, we propose a permutable anisotropic\nconvolutional operation (PAI-Conv) that calculates soft-permutation matrices\nfor each point using dot-product attention according to a set of evenly\ndistributed kernel points on a sphere's surface and performs shared anisotropic\nfilters. In fact, dot product with kernel points is by analogy with the\ndot-product with keys in Transformer as widely used in natural language\nprocessing (NLP). From this perspective, PAI-Conv can be regarded as the\ntransformer for point clouds, which is physically meaningful and is robust to\ncooperate with the efficient random point sampling method. Comprehensive\nexperiments on point clouds demonstrate that PAI-Conv produces competitive\nresults in classification and semantic segmentation tasks compared to\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 02:42:29 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 16:32:43 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Gao", "Zhongpai", ""], ["Zhai", "Guangtao", ""], ["Yan", "Junchi", ""], ["Yang", "Xiaokang", ""]]}, {"id": "2005.13139", "submitter": "Geoffrey Clark", "authors": "Geoffrey Clark, Joseph Campbell, Seyed Mostafa Rezayat Sorkhabadi,\n  Wenlong Zhang, Heni Ben Amor", "title": "Predictive Modeling of Periodic Behavior for Human-Robot Symbiotic\n  Walking", "comments": "Accepted to ICRA 2020. Accompanying video presentation:\n  https://www.youtube.com/watch?v=EjSVjueePyQ&t=1s", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose in this paper Periodic Interaction Primitives - a probabilistic\nframework that can be used to learn compact models of periodic behavior. Our\napproach extends existing formulations of Interaction Primitives to periodic\nmovement regimes, i.e., walking. We show that this model is particularly\nwell-suited for learning data-driven, customized models of human walking, which\ncan then be used for generating predictions over future states or for inferring\nlatent, biomechanical variables. We also demonstrate how the same framework can\nbe used to learn controllers for a robotic prosthesis using an imitation\nlearning approach. Results in experiments with human participants indicate that\nPeriodic Interaction Primitives efficiently generate predictions and ankle\nangle control signals for a robotic prosthetic ankle, with MAE of 2.21 degrees\nin 0.0008s per inference. Performance degrades gracefully in the presence of\nnoise or sensor fall outs. Compared to alternatives, this algorithm functions\n20 times faster and performed 4.5 times more accurately on test subjects.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 03:30:48 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Clark", "Geoffrey", ""], ["Campbell", "Joseph", ""], ["Sorkhabadi", "Seyed Mostafa Rezayat", ""], ["Zhang", "Wenlong", ""], ["Amor", "Heni Ben", ""]]}, {"id": "2005.13140", "submitter": "Shruti Jadon", "authors": "Shruti Jadon", "title": "SSM-Net for Plants Disease Identification in Low Data Regime", "comments": "5 pages, 7 Figures", "journal-ref": "Poster @CVPR workshop, Proceedings at IEEE / ITU International\n  Conference on Artificial Intelligence for Good 2020", "doi": "10.1109/AI4G50087.2020.9311073", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Plant disease detection is an essential factor in increasing agricultural\nproduction. Due to the difficulty of disease detection, farmers spray various\npesticides on their crops to protect them, causing great harm to crop growth\nand food standards. Deep learning can offer critical aid in detecting such\ndiseases. However, it is highly inconvenient to collect a large volume of data\non all forms of the diseases afflicting a specific plant species. In this\npaper, we propose a new metrics-based few-shot learning SSM net architecture,\nwhich consists of stacked siamese and matching network components to address\nthe problem of disease detection in low data regimes. We demonstrated our\nexperiments on two datasets: mini-leaves diseases and sugarcane diseases\ndataset. We have showcased that the SSM-Net approach can achieve better\ndecision boundaries with an accuracy of 92.7% on the mini-leaves dataset and\n94.3% on the sugarcane dataset. The accuracy increased by ~10% and ~5%\nrespectively, compared to the widely used VGG16 transfer learning approach.\nFurthermore, we attained F1 score of 0.90 using SSM Net on the sugarcane\ndataset and 0.91 on the mini-leaves dataset. Our code implementation is\navailable on Github: https://github.com/shruti-jadon/PlantsDiseaseDetection.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 03:43:38 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 05:52:17 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 22:02:02 GMT"}, {"version": "v4", "created": "Mon, 7 Sep 2020 20:16:31 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Jadon", "Shruti", ""]]}, {"id": "2005.13143", "submitter": "Muhammad Asif Rana", "authors": "Muhammad Asif Rana, Anqi Li, Dieter Fox, Byron Boots, Fabio Ramos,\n  Nathan Ratliff", "title": "Euclideanizing Flows: Diffeomorphic Reduction for Learning Stable\n  Dynamical Systems", "comments": "2nd Annual Conference on Learning for Dynamics and Control (L4DC)\n  2020 -- Revised Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic tasks often require motions with complex geometric structures. We\npresent an approach to learn such motions from a limited number of human\ndemonstrations by exploiting the regularity properties of human motions e.g.\nstability, smoothness, and boundedness. The complex motions are encoded as\nrollouts of a stable dynamical system, which, under a change of coordinates\ndefined by a diffeomorphism, is equivalent to a simple, hand-specified\ndynamical system. As an immediate result of using diffeomorphisms, the\nstability property of the hand-specified dynamical system directly carry over\nto the learned dynamical system. Inspired by recent works in density\nestimation, we propose to represent the diffeomorphism as a composition of\nsimple parameterized diffeomorphisms. Additional structure is imposed to\nprovide guarantees on the smoothness of the generated motions. The efficacy of\nthis approach is demonstrated through validation on an established benchmark as\nwell demonstrations collected on a real-world robotic system.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 03:51:57 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 17:28:20 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Rana", "Muhammad Asif", ""], ["Li", "Anqi", ""], ["Fox", "Dieter", ""], ["Boots", "Byron", ""], ["Ramos", "Fabio", ""], ["Ratliff", "Nathan", ""]]}, {"id": "2005.13149", "submitter": "Mike Wu", "authors": "Mike Wu, Chengxu Zhuang, Milan Mosse, Daniel Yamins, Noah Goodman", "title": "On Mutual Information in Contrastive Learning for Visual Representations", "comments": "8 pages content; 15 pages supplement with proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, several unsupervised, \"contrastive\" learning algorithms in\nvision have been shown to learn representations that perform remarkably well on\ntransfer tasks. We show that this family of algorithms maximizes a lower bound\non the mutual information between two or more \"views\" of an image where typical\nviews come from a composition of image augmentations. Our bound generalizes the\nInfoNCE objective to support negative sampling from a restricted region of\n\"difficult\" contrasts. We find that the choice of negative samples and views\nare critical to the success of these algorithms. Reformulating previous\nlearning objectives in terms of mutual information also simplifies and\nstabilizes them. In practice, our new objectives yield representations that\noutperform those learned with previous approaches for transfer to\nclassification, bounding box detection, instance segmentation, and keypoint\ndetection. % experiments show that choosing more difficult negative samples\nresults in a stronger representation, outperforming those learned with IR, LA,\nand CMC in classification, bounding box detection, instance segmentation, and\nkeypoint detection. The mutual information framework provides a unifying\ncomparison of approaches to contrastive learning and uncovers the choices that\nimpact representation learning.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 04:21:53 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 16:39:20 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Wu", "Mike", ""], ["Zhuang", "Chengxu", ""], ["Mosse", "Milan", ""], ["Yamins", "Daniel", ""], ["Goodman", "Noah", ""]]}, {"id": "2005.13163", "submitter": "Michael Bianco", "authors": "Michael J. Bianco, Sharon Gannot, and Peter Gerstoft", "title": "Semi-supervised source localization with deep generative modeling", "comments": "Published in proceedings of IEEE International Workshop on Machine\n  Learning for Signal Processing. arXiv admin note: substantial text overlap\n  with arXiv:2101.10636", "journal-ref": null, "doi": "10.1109/MLSP49062.2020.9231825", "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a semi-supervised localization approach based on deep generative\nmodeling with variational autoencoders (VAEs). Localization in reverberant\nenvironments remains a challenge, which machine learning (ML) has shown promise\nin addressing. Even with large data volumes, the number of labels available for\nsupervised learning in reverberant environments is usually small. We address\nthis issue by performing semi-supervised learning (SSL) with convolutional\nVAEs. The VAE is trained to generate the phase of relative transfer functions\n(RTFs), in parallel with a DOA classifier, on both labeled and unlabeled RTF\nsamples. The VAE-SSL approach is compared with SRP-PHAT and fully-supervised\nCNNs. We find that VAE-SSL can outperform both SRP-PHAT and CNN in\nlabel-limited scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 04:59:52 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 21:59:47 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2021 01:46:34 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Bianco", "Michael J.", ""], ["Gannot", "Sharon", ""], ["Gerstoft", "Peter", ""]]}, {"id": "2005.13166", "submitter": "Koorosh Aslansefat", "authors": "Koorosh Aslansefat, Ioannis Sorokos, Declan Whiting, Ramin Tavakoli\n  Kolagari, Yiannis Papadopoulos", "title": "SafeML: Safety Monitoring of Machine Learning Classifiers through\n  Statistical Difference Measure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Ensuring safety and explainability of machine learning (ML) is a topic of\nincreasing relevance as data-driven applications venture into safety-critical\napplication domains, traditionally committed to high safety standards that are\nnot satisfied with an exclusive testing approach of otherwise inaccessible\nblack-box systems. Especially the interaction between safety and security is a\ncentral challenge, as security violations can lead to compromised safety. The\ncontribution of this paper to addressing both safety and security within a\nsingle concept of protection applicable during the operation of ML systems is\nactive monitoring of the behaviour and the operational context of the\ndata-driven system based on distance measures of the Empirical Cumulative\nDistribution Function (ECDF). We investigate abstract datasets (XOR, Spiral,\nCircle) and current security-specific datasets for intrusion detection\n(CICIDS2017) of simulated network traffic, using distributional shift detection\nmeasures including the Kolmogorov-Smirnov, Kuiper, Anderson-Darling,\nWasserstein and mixed Wasserstein-Anderson-Darling measures. Our preliminary\nfindings indicate that the approach can provide a basis for detecting whether\nthe application context of an ML component is valid in the safety-security. Our\npreliminary code and results are available at\nhttps://github.com/ISorokos/SafeML.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 05:27:38 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Aslansefat", "Koorosh", ""], ["Sorokos", "Ioannis", ""], ["Whiting", "Declan", ""], ["Kolagari", "Ramin Tavakoli", ""], ["Papadopoulos", "Yiannis", ""]]}, {"id": "2005.13171", "submitter": "Yu Wang", "authors": "Yu Wang, JunPeng Bao, JianQiang Du, YongFeng Li", "title": "Precisely Predicting Acute Kidney Injury with Convolutional Neural\n  Network Based on Electronic Health Record Data", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The incidence of Acute Kidney Injury (AKI) commonly happens in the Intensive\nCare Unit (ICU) patients, especially in the adults, which is an independent\nrisk factor affecting short-term and long-term mortality. Though researchers in\nrecent years highlight the early prediction of AKI, the performance of existing\nmodels are not precise enough. The objective of this research is to precisely\npredict AKI by means of Convolutional Neural Network on Electronic Health\nRecord (EHR) data. The data sets used in this research are two public\nElectronic Health Record (EHR) databases: MIMIC-III and eICU database. In this\nstudy, we take several Convolutional Neural Network models to train and test\nour AKI predictor, which can precisely predict whether a certain patient will\nsuffer from AKI after admission in ICU according to the last measurements of\nthe 16 blood gas and demographic features. The research is based on Kidney\nDisease Improving Global Outcomes (KDIGO) criteria for AKI definition. Our work\ngreatly improves the AKI prediction precision, and the best AUROC is up to\n0.988 on MIMIC-III data set and 0.936 on eICU data set, both of which\noutperform the state-of-art predictors. And the dimension of the input vector\nused in this predictor is much fewer than that used in other existing\nresearches. Compared with the existing AKI predictors, the predictor in this\nwork greatly improves the precision of early prediction of AKI by using the\nConvolutional Neural Network architecture and a more concise input vector.\nEarly and precise prediction of AKI will bring much benefit to the decision of\ntreatment, so it is believed that our work is a very helpful clinical\napplication.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 05:39:42 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Wang", "Yu", ""], ["Bao", "JunPeng", ""], ["Du", "JianQiang", ""], ["Li", "YongFeng", ""]]}, {"id": "2005.13178", "submitter": "Pegah Salehi", "authors": "Pegah Salehi, Abdolah Chalechale, Maryam Taghizadeh", "title": "Generative Adversarial Networks (GANs): An Overview of Theoretical\n  Model, Evaluation Metrics, and Recent Developments", "comments": "Submitted to a journal in the computer vision field", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  One of the most significant challenges in statistical signal processing and\nmachine learning is how to obtain a generative model that can produce samples\nof large-scale data distribution, such as images and speeches. Generative\nAdversarial Network (GAN) is an effective method to address this problem. The\nGANs provide an appropriate way to learn deep representations without\nwidespread use of labeled training data. This approach has attracted the\nattention of many researchers in computer vision since it can generate a large\namount of data without precise modeling of the probability density function\n(PDF). In GANs, the generative model is estimated via a competitive process\nwhere the generator and discriminator networks are trained simultaneously. The\ngenerator learns to generate plausible data, and the discriminator learns to\ndistinguish fake data created by the generator from real data samples. Given\nthe rapid growth of GANs over the last few years and their application in\nvarious fields, it is necessary to investigate these networks accurately. In\nthis paper, after introducing the main concepts and the theory of GAN, two new\ndeep generative models are compared, the evaluation metrics utilized in the\nliterature and challenges of GANs are also explained. Moreover, the most\nremarkable GAN architectures are categorized and discussed. Finally, the\nessential applications in computer vision are examined.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 05:56:53 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Salehi", "Pegah", ""], ["Chalechale", "Abdolah", ""], ["Taghizadeh", "Maryam", ""]]}, {"id": "2005.13183", "submitter": "Yaming Yang", "authors": "Yaming Yang, Ziyu Guan, Jianxin Li, Wei Zhao, Jiangtao Cui, Quan Wang", "title": "Interpretable and Efficient Heterogeneous Graph Convolutional Network", "comments": "This paper has been submitted to IEEE TKDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Network (GCN) has achieved extraordinary success in\nlearning effective task-specific representations of nodes in graphs. However,\nregarding Heterogeneous Information Network (HIN), existing HIN-oriented GCN\nmethods still suffer from two deficiencies: (1) they cannot flexibly explore\nall possible meta-paths and extract the most useful ones for a target object,\nwhich hinders both effectiveness and interpretability; (2) they often need to\ngenerate intermediate meta-path based dense graphs, which leads to high\ncomputational complexity. To address the above issues, we propose an\ninterpretable and efficient Heterogeneous Graph Convolutional Network (ie-HGCN)\nto learn the representations of objects in HINs. It is designed as a\nhierarchical aggregation architecture, i.e., object-level aggregation first,\nfollowed by type-level aggregation. The novel architecture can automatically\nextract useful meta-paths for each object from all possible meta-paths (within\na length limit), which brings good model interpretability. It can also reduce\nthe computational cost by avoiding intermediate HIN transformation and\nneighborhood attention. We provide theoretical analysis about the proposed\nie-HGCN in terms of evaluating the usefulness of all possible meta-paths, its\nconnection to the spectral graph convolution on HINs, and its quasi-linear time\ncomplexity. Extensive experiments on three real network datasets demonstrate\nthe superiority of ie-HGCN over the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 06:06:00 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 03:15:13 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Yang", "Yaming", ""], ["Guan", "Ziyu", ""], ["Li", "Jianxin", ""], ["Zhao", "Wei", ""], ["Cui", "Jiangtao", ""], ["Wang", "Quan", ""]]}, {"id": "2005.13191", "submitter": "Paulito Palmes", "authors": "Paulito Palmes, Joern Ploennigs, Niall Brady", "title": "TSML (Time Series Machine Learnng)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Over the past years, the industrial sector has seen many innovations brought\nabout by automation. Inherent in this automation is the installation of sensor\nnetworks for status monitoring and data collection. One of the major challenges\nin these data-rich environments is how to extract and exploit information from\nthese large volume of data to detect anomalies, discover patterns to reduce\ndowntimes and manufacturing errors, reduce energy usage, predict\nfaults/failures, effective maintenance schedules, etc. To address these issues,\nwe developed TSML. Its technology is based on using the pipeline of lightweight\nfilters as building blocks to process huge amount of industrial time series\ndata in parallel.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 06:37:49 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Palmes", "Paulito", ""], ["Ploennigs", "Joern", ""], ["Brady", "Niall", ""]]}, {"id": "2005.13209", "submitter": "Shaked Brody", "authors": "Shaked Brody, Uri Alon and Eran Yahav", "title": "A Structural Model for Contextual Code Changes", "comments": "Accepted to OOPSLA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of predicting edit completions based on a learned\nmodel that was trained on past edits. Given a code snippet that is partially\nedited, our goal is to predict a completion of the edit for the rest of the\nsnippet. We refer to this task as the EditCompletion task and present a novel\napproach for tackling it. The main idea is to directly represent structural\nedits. This allows us to model the likelihood of the edit itself, rather than\nlearning the likelihood of the edited code. We represent an edit operation as a\npath in the program's Abstract Syntax Tree (AST), originating from the source\nof the edit to the target of the edit. Using this representation, we present a\npowerful and lightweight neural model for the EditCompletion task.\n  We conduct a thorough evaluation, comparing our approach to a variety of\nrepresentation and modeling approaches that are driven by multiple strong\nmodels such as LSTMs, Transformers, and neural CRFs. Our experiments show that\nour model achieves a 28% relative gain over state-of-the-art sequential models\nand 2x higher accuracy than syntactic models that learn to generate the edited\ncode, as opposed to modeling the edits directly.\n  Our code, dataset, and trained models are publicly available at\nhttps://github.com/tech-srl/c3po/ .\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 07:16:19 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 17:52:10 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Brody", "Shaked", ""], ["Alon", "Uri", ""], ["Yahav", "Eran", ""]]}, {"id": "2005.13232", "submitter": "Alireza Doostan", "authors": "Alexandre Cortiella, Kwang-Chun Park, and Alireza Doostan", "title": "Sparse Identification of Nonlinear Dynamical Systems via Reweighted\n  $\\ell_1$-regularized Least Squares", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2020.113620", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes an iterative sparse-regularized regression method to\nrecover governing equations of nonlinear dynamical systems from noisy state\nmeasurements. The method is inspired by the Sparse Identification of Nonlinear\nDynamics (SINDy) approach of {\\it [Brunton et al., PNAS, 113 (15) (2016)\n3932-3937]}, which relies on two main assumptions: the state variables are\nknown {\\it a priori} and the governing equations lend themselves to sparse,\nlinear expansions in a (nonlinear) basis of the state variables. The aim of\nthis work is to improve the accuracy and robustness of SINDy in the presence of\nstate measurement noise. To this end, a reweighted $\\ell_1$-regularized least\nsquares solver is developed, wherein the regularization parameter is selected\nfrom the corner point of a Pareto curve. The idea behind using weighted\n$\\ell_1$-norm for regularization -- instead of the standard $\\ell_1$-norm -- is\nto better promote sparsity in the recovery of the governing equations and, in\nturn, mitigate the effect of noise in the state variables. We also present a\nmethod to recover single physical constraints from state measurements. Through\nseveral examples of well-known nonlinear dynamical systems, we demonstrate\nempirically the accuracy and robustness of the reweighted $\\ell_1$-regularized\nleast squares strategy with respect to state measurement noise, thus\nillustrating its viability for a wide range of potential applications.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 08:30:15 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Cortiella", "Alexandre", ""], ["Park", "Kwang-Chun", ""], ["Doostan", "Alireza", ""]]}, {"id": "2005.13239", "submitter": "Tianhe Yu", "authors": "Tianhe Yu, Garrett Thomas, Lantao Yu, Stefano Ermon, James Zou, Sergey\n  Levine, Chelsea Finn, Tengyu Ma", "title": "MOPO: Model-based Offline Policy Optimization", "comments": "NeurIPS 2020. First two authors contributed equally. Last two authors\n  advised equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline reinforcement learning (RL) refers to the problem of learning\npolicies entirely from a large batch of previously collected data. This problem\nsetting offers the promise of utilizing such datasets to acquire policies\nwithout any costly or dangerous active exploration. However, it is also\nchallenging, due to the distributional shift between the offline training data\nand those states visited by the learned policy. Despite significant recent\nprogress, the most successful prior methods are model-free and constrain the\npolicy to the support of data, precluding generalization to unseen states. In\nthis paper, we first observe that an existing model-based RL algorithm already\nproduces significant gains in the offline setting compared to model-free\napproaches. However, standard model-based RL methods, designed for the online\nsetting, do not provide an explicit mechanism to avoid the offline setting's\ndistributional shift issue. Instead, we propose to modify the existing\nmodel-based RL methods by applying them with rewards artificially penalized by\nthe uncertainty of the dynamics. We theoretically show that the algorithm\nmaximizes a lower bound of the policy's return under the true MDP. We also\ncharacterize the trade-off between the gain and risk of leaving the support of\nthe batch data. Our algorithm, Model-based Offline Policy Optimization (MOPO),\noutperforms standard model-based RL algorithms and prior state-of-the-art\nmodel-free offline RL algorithms on existing offline RL benchmarks and two\nchallenging continuous control tasks that require generalizing from data\ncollected for a different task. The code is available at\nhttps://github.com/tianheyu927/mopo.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 08:46:41 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 06:01:54 GMT"}, {"version": "v3", "created": "Sun, 6 Sep 2020 23:25:56 GMT"}, {"version": "v4", "created": "Wed, 23 Sep 2020 07:08:58 GMT"}, {"version": "v5", "created": "Tue, 29 Sep 2020 23:49:26 GMT"}, {"version": "v6", "created": "Sun, 22 Nov 2020 07:04:17 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Yu", "Tianhe", ""], ["Thomas", "Garrett", ""], ["Yu", "Lantao", ""], ["Ermon", "Stefano", ""], ["Zou", "James", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""], ["Ma", "Tengyu", ""]]}, {"id": "2005.13243", "submitter": "Petr Hurtik", "authors": "Petr Hurtik, Vojtech Molek, Jan Hula, Marek Vajgl, Pavel Vlasanek,\n  Tomas Nejezchleba", "title": "Poly-YOLO: higher speed, more precise detection and instance\n  segmentation for YOLOv3", "comments": "18 pages, 15 figures, submitted to IEEE Transactions on Pattern\n  Analysis and Machine Intelligence (under review), Source code is available at\n  https://gitlab.com/irafm-ai/poly-yolo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new version of YOLO with better performance and extended with\ninstance segmentation called Poly-YOLO. Poly-YOLO builds on the original ideas\nof YOLOv3 and removes two of its weaknesses: a large amount of rewritten labels\nand inefficient distribution of anchors. Poly-YOLO reduces the issues by\naggregating features from a light SE-Darknet-53 backbone with a hypercolumn\ntechnique, using stairstep upsampling, and produces a single scale output with\nhigh resolution. In comparison with YOLOv3, Poly-YOLO has only 60% of its\ntrainable parameters but improves mAP by a relative 40%. We also present\nPoly-YOLO lite with fewer parameters and a lower output resolution. It has the\nsame precision as YOLOv3, but it is three times smaller and twice as fast, thus\nsuitable for embedded devices. Finally, Poly-YOLO performs instance\nsegmentation using bounding polygons. The network is trained to detect\nsize-independent polygons defined on a polar grid. Vertices of each polygon are\nbeing predicted with their confidence, and therefore Poly-YOLO produces\npolygons with a varying number of vertices.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 08:53:35 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 11:58:33 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Hurtik", "Petr", ""], ["Molek", "Vojtech", ""], ["Hula", "Jan", ""], ["Vajgl", "Marek", ""], ["Vlasanek", "Pavel", ""], ["Nejezchleba", "Tomas", ""]]}, {"id": "2005.13245", "submitter": "Jose M. Pe\\~na", "authors": "Jose M. Pe\\~na", "title": "On the Monotonicity of a Nondifferentially Mismeasured Binary Confounder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that we are interested in the average causal effect of a binary\ntreatment on an outcome when this relationship is confounded by a binary\nconfounder. Suppose that the confounder is unobserved but a nondifferential\nproxy of it is observed. We show that, under certain monotonicity assumption\nthat is empirically verifiable, adjusting for the proxy produces a measure of\nthe effect that is between the unadjusted and the true measures.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 09:07:07 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 07:35:40 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 12:07:23 GMT"}, {"version": "v4", "created": "Fri, 26 Jun 2020 08:48:17 GMT"}, {"version": "v5", "created": "Fri, 3 Jul 2020 09:39:26 GMT"}, {"version": "v6", "created": "Sun, 2 Aug 2020 20:24:29 GMT"}, {"version": "v7", "created": "Tue, 4 Aug 2020 14:07:42 GMT"}, {"version": "v8", "created": "Fri, 14 Aug 2020 18:38:40 GMT"}, {"version": "v9", "created": "Sun, 23 Aug 2020 07:45:49 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Pe\u00f1a", "Jose M.", ""]]}, {"id": "2005.13247", "submitter": "Shaohuai Shi", "authors": "Shaohuai Shi, Zhenheng Tang, Xiaowen Chu, Chengjian Liu, Wei Wang, Bo\n  Li", "title": "A Quantitative Survey of Communication Optimizations in Distributed Deep\n  Learning", "comments": "9 pages, 6 figures & tables. Code at:\n  https://github.com/HKBU-HPML/ddl-benchmarks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, large and complex deep learning (DL) models are increasingly\ntrained in a distributed manner across multiple worker machines, in which\nextensive communications between workers pose serious scaling problems. In this\narticle, we present a quantitative survey of communication optimization\ntechniques for data parallel distributed DL. We first identify the major\ncommunication challenges and classify the existing solutions into three levels,\nnamely the learning algorithm, the system architecture, and the network\ninfrastructure. We present the state-of-the-art communication optimization\ntechniques and conduct a comparative study of seven common lossless distributed\nDL methods on a 32-GPU cluster with 100Gbps InfiniBand (IB). We show that (1)\nthe DL models with low model intensity (such as BERT and BERT-Large) are\ndifficult to scale out even with the best available lossless algorithm over\n100Gbps IB; (2) the system architecture and scheduling algorithms have a\ncritical impact on the scaling property. We conclude the article with\ndiscussions on the open issues for further investigations.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 09:12:48 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 07:05:33 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Shi", "Shaohuai", ""], ["Tang", "Zhenheng", ""], ["Chu", "Xiaowen", ""], ["Liu", "Chengjian", ""], ["Wang", "Wei", ""], ["Li", "Bo", ""]]}, {"id": "2005.13249", "submitter": "Dani Kiyasseh", "authors": "Dani Kiyasseh, Tingting Zhu, David A. Clifton", "title": "CLOCS: Contrastive Learning of Cardiac Signals Across Space, Time, and\n  Patients", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The healthcare industry generates troves of unlabelled physiological data.\nThis data can be exploited via contrastive learning, a self-supervised\npre-training method that encourages representations of instances to be similar\nto one another. We propose a family of contrastive learning methods, CLOCS,\nthat encourages representations across space, time, \\textit{and} patients to be\nsimilar to one another. We show that CLOCS consistently outperforms the\nstate-of-the-art methods, BYOL and SimCLR, when performing a linear evaluation\nof, and fine-tuning on, downstream tasks. We also show that CLOCS achieves\nstrong generalization performance with only 25\\% of labelled training data.\nFurthermore, our training procedure naturally generates patient-specific\nrepresentations that can be used to quantify patient-similarity.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 09:25:41 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 17:46:42 GMT"}, {"version": "v3", "created": "Sun, 16 May 2021 13:12:14 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Kiyasseh", "Dani", ""], ["Zhu", "Tingting", ""], ["Clifton", "David A.", ""]]}, {"id": "2005.13263", "submitter": "Tanner Bohn", "authors": "Tanner Bohn, Charles X. Ling", "title": "Catching Attention with Automatic Pull Quote Selection", "comments": "Accepted to COLING-2020. 15 pages (~9 for content + refs + appendix),\n  6 figures, 5 tables (+ 5 appendix tables)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To advance understanding on how to engage readers, we advocate the novel task\nof automatic pull quote selection. Pull quotes are a component of articles\nspecifically designed to catch the attention of readers with spans of text\nselected from the article and given more salient presentation. This task\ndiffers from related tasks such as summarization and clickbait identification\nby several aspects. We establish a spectrum of baseline approaches to the task,\nranging from handcrafted features to a neural mixture-of-experts to cross-task\nmodels. By examining the contributions of individual features and embedding\ndimensions from these models, we uncover unexpected properties of pull quotes\nto help answer the important question of what engages readers. Human evaluation\nalso supports the uniqueness of this task and the suitability of our selection\nmodels. The benefits of exploring this problem further are clear: pull quotes\nincrease enjoyment and readability, shape reader perceptions, and facilitate\nlearning. Code to reproduce this work is available at\nhttps://github.com/tannerbohn/AutomaticPullQuoteSelection.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 09:59:34 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 02:49:35 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Bohn", "Tanner", ""], ["Ling", "Charles X.", ""]]}, {"id": "2005.13273", "submitter": "Chihiro Watanabe", "authors": "Chihiro Watanabe, Taiji Suzuki", "title": "Selective Inference for Latent Block Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model selection in latent block models has been a challenging but important\ntask in the field of statistics. Specifically, a major challenge is encountered\nwhen constructing a test on a block structure obtained by applying a specific\nclustering algorithm to a finite size matrix. In this case, it becomes crucial\nto consider the selective bias in the block structure, that is, the block\nstructure is selected from all the possible cluster memberships based on some\ncriterion by the clustering algorithm. To cope with this problem, this study\nprovides a selective inference method for latent block models. Specifically, we\nconstruct a statistical test on a set of row and column cluster memberships of\na latent block model, which is given by a squared residue minimization\nalgorithm. The proposed test, by its nature, includes and thus can also be used\nas the test on the set of row and column cluster numbers. We also propose an\napproximated version of the test based on simulated annealing to avoid\ncombinatorial explosion in searching the optimal block structure. The results\nshow that the proposed exact and approximated tests work effectively, compared\nto the naive test that did not take the selective bias into account.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 10:44:19 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 06:05:44 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 05:51:07 GMT"}, {"version": "v4", "created": "Sat, 8 May 2021 05:19:36 GMT"}, {"version": "v5", "created": "Sun, 6 Jun 2021 04:38:39 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Watanabe", "Chihiro", ""], ["Suzuki", "Taiji", ""]]}, {"id": "2005.13284", "submitter": "Pablo Jim\\'enez", "authors": "Alain Durmus, Pablo Jim\\'enez, \\'Eric Moulines, Salem Said, Hoi-To Wai", "title": "Convergence Analysis of Riemannian Stochastic Approximation Schemes", "comments": "41 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes the convergence for a large class of Riemannian\nstochastic approximation (SA) schemes, which aim at tackling stochastic\noptimization problems. In particular, the recursions we study use either the\nexponential map of the considered manifold (geodesic schemes) or more general\nretraction functions (retraction schemes) used as a proxy for the exponential\nmap. Such approximations are of great interest since they are low complexity\nalternatives to geodesic schemes. Under the assumption that the mean field of\nthe SA is correlated with the gradient of a smooth Lyapunov function (possibly\nnon-convex), we show that the above Riemannian SA schemes find an\n${\\mathcal{O}}(b_\\infty + \\log n / \\sqrt{n})$-stationary point (in expectation)\nwithin ${\\mathcal{O}}(n)$ iterations, where $b_\\infty \\geq 0$ is the asymptotic\nbias. Compared to previous works, the conditions we derive are considerably\nmilder. First, all our analysis are global as we do not assume iterates to be\na-priori bounded. Second, we study biased SA schemes. To be more specific, we\nconsider the case where the mean-field function can only be estimated up to a\nsmall bias, and/or the case in which the samples are drawn from a controlled\nMarkov chain. Third, the conditions on retractions required to ensure\nconvergence of the related SA schemes are weak and hold for well-known\nexamples. We illustrate our results on three machine learning problems.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 11:24:58 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 10:05:10 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 14:25:42 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Durmus", "Alain", ""], ["Jim\u00e9nez", "Pablo", ""], ["Moulines", "\u00c9ric", ""], ["Said", "Salem", ""], ["Wai", "Hoi-To", ""]]}, {"id": "2005.13285", "submitter": "Jannis Born", "authors": "Jannis Born, Matteo Manica, Joris Cadow, Greta Markert, Nil Adell\n  Mill, Modestas Filipavicius, Mar\\'ia Rodr\\'iguez Mart\\'inez", "title": "PaccMann$^{RL}$ on SARS-CoV-2: Designing antiviral candidates with\n  conditional generative models", "comments": "5 pages, 6 figures", "journal-ref": "ICML Workshop on Computational Biology 2020", "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the fast development of COVID-19 into a global pandemic, scientists\naround the globe are desperately searching for effective antiviral therapeutic\nagents. Bridging systems biology and drug discovery, we propose a deep learning\nframework for conditional de novo design of antiviral candidate drugs tailored\nagainst given protein targets. First, we train a multimodal ligand--protein\nbinding affinity model on predicting affinities of antiviral compounds to\ntarget proteins and couple this model with pharmacological toxicity predictors.\nExploiting this multi-objective as a reward function of a conditional molecular\ngenerator (consisting of two VAEs), we showcase a framework that navigates the\nchemical space toward regions with more antiviral molecules. Specifically, we\nexplore a challenging setting of generating ligands against unseen protein\ntargets by performing a leave-one-out-cross-validation on 41 SARS-CoV-2-related\ntarget proteins. Using deep RL, it is demonstrated that in 35 out of 41 cases,\nthe generation is biased towards sampling more binding ligands, with an average\nincrease of 83% comparing to an unbiased VAE. We present a case-study on a\npotential Envelope-protein inhibitor and perform a synthetic accessibility\nassessment of the best generated molecules is performed that resembles a viable\nroadmap towards a rapid in-vitro evaluation of potential SARS-CoV-2 inhibitors.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 11:30:15 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 16:52:25 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 14:44:02 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Born", "Jannis", ""], ["Manica", "Matteo", ""], ["Cadow", "Joris", ""], ["Markert", "Greta", ""], ["Mill", "Nil Adell", ""], ["Filipavicius", "Modestas", ""], ["Mart\u00ednez", "Mar\u00eda Rodr\u00edguez", ""]]}, {"id": "2005.13288", "submitter": "Jonas Wurst", "authors": "Jonas Wurst, Alberto Flores Fern\\'andez, Michael Botsch and Wolfgang\n  Utschick", "title": "An Entropy Based Outlier Score and its Application to Novelty Detection\n  for Road Infrastructure Images", "comments": "Copyright 2020 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": "2020 IEEE Intelligent Vehicles Symposium (IV)", "doi": "10.1109/IV47402.2020.9304733", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel unsupervised outlier score, which can be embedded into graph based\ndimensionality reduction techniques, is presented in this work. The score uses\nthe directed nearest neighbor graphs of those techniques. Hence, the same\nmeasure of similarity that is used to project the data into lower dimensions,\nis also utilized to determine the outlier score. The outlier score is realized\nthrough a weighted normalized entropy of the similarities. This score is\napplied to road infrastructure images. The aim is to identify newly observed\ninfrastructures given a pre-collected base dataset. Detecting unknown scenarios\nis a key for accelerated validation of autonomous vehicles. The results show\nthe high potential of the proposed technique. To validate the generalization\ncapabilities of the outlier score, it is additionally applied to various real\nworld datasets. The overall average performance in identifying outliers using\nthe proposed methods is higher compared to state-of-the-art methods. In order\nto generate the infrastructure images, an openDRIVE parsing and plotting tool\nfor Matlab is developed as part of this work. This tool and the implementation\nof the entropy based outlier score in combination with Uniform Manifold\nApproximation and Projection are made publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 11:34:42 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 08:40:47 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Wurst", "Jonas", ""], ["Fern\u00e1ndez", "Alberto Flores", ""], ["Botsch", "Michael", ""], ["Utschick", "Wolfgang", ""]]}, {"id": "2005.13291", "submitter": "Andrew Port", "authors": "Andrew Port, Chelhwon Kim, Mitesh Patel", "title": "Earballs: Neural Transmodal Translation", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CV cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As is expressed in the adage \"a picture is worth a thousand words\", when\nusing spoken language to communicate visual information, brevity can be a\nchallenge. This work describes a novel technique for leveraging machine learned\nfeature embeddings to translate visual (and other types of) information into a\nperceptual audio domain, allowing users to perceive this information using only\ntheir aural faculty. The system uses a pretrained image embedding network to\nextract visual features and embed them in a compact subset of Euclidean space\n-- this converts the images into feature vectors whose $L^2$ distances can be\nused as a meaningful measure of similarity. A generative adversarial network\n(GAN) is then used to find a distance preserving map from this metric space of\nfeature vectors into the metric space defined by a target audio dataset\nequipped with either the Euclidean metric or a mel-frequency cepstrum-based\npsychoacoustic distance metric. We demonstrate this technique by translating\nimages of faces into human speech-like audio. For both target audio metrics,\nthe GAN successfully found a metric preserving mapping, and in human subject\ntests, users were able to accurately classify audio translations of faces.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 11:41:48 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 20:48:18 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Port", "Andrew", ""], ["Kim", "Chelhwon", ""], ["Patel", "Mitesh", ""]]}, {"id": "2005.13293", "submitter": "Pascal Kerschke", "authors": "Moritz Seiler and Heike Trautmann and Pascal Kerschke", "title": "Enhancing Resilience of Deep Learning Networks by Means of Transferable\n  Adversaries", "comments": "This version has been accepted for publication at the International\n  Joint Conference on Neural Networks (IJCNN) 2020, which is part of the IEEE\n  World Congress on Computational Intelligence (IEEE WCCI) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks in general and deep learning networks in\nparticular established themselves as popular and powerful machine learning\nalgorithms. While the often tremendous sizes of these networks are beneficial\nwhen solving complex tasks, the tremendous number of parameters also causes\nsuch networks to be vulnerable to malicious behavior such as adversarial\nperturbations. These perturbations can change a model's classification\ndecision. Moreover, while single-step adversaries can easily be transferred\nfrom network to network, the transfer of more powerful multi-step adversaries\nhas - usually -- been rather difficult. In this work, we introduce a method for\ngenerating strong ad-versaries that can easily (and frequently) be transferred\nbetween different models. This method is then used to generate a large set of\nadversaries, based on which the effects of selected defense methods are\nexperimentally assessed. At last, we introduce a novel, simple, yet effective\napproach to enhance the resilience of neural networks against adversaries and\nbenchmark it against established defense methods. In contrast to the already\nexisting methods, our proposed defense approach is much more efficient as it\nonly requires a single additional forward-pass to achieve comparable\nperformance results.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 11:52:42 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Seiler", "Moritz", ""], ["Trautmann", "Heike", ""], ["Kerschke", "Pascal", ""]]}, {"id": "2005.13297", "submitter": "Hongwei Xie", "authors": "Hongwei Xie, Shuo Zhang, Huanghao Ding, Yafei Song, Baitao Shao,\n  Conggang Hu, Ling Cai and Mingyang Li", "title": "Accelerating Neural Network Inference by Overflow Aware Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inherent heavy computation of deep neural networks prevents their\nwidespread applications. A widely used method for accelerating model inference\nis quantization, by replacing the input operands of a network using fixed-point\nvalues. Then the majority of computation costs focus on the integer matrix\nmultiplication accumulation. In fact, high-bit accumulator leads to partially\nwasted computation and low-bit one typically suffers from numerical overflow.\nTo address this problem, we propose an overflow aware quantization method by\ndesigning trainable adaptive fixed-point representation, to optimize the number\nof bits for each input tensor while prohibiting numeric overflow during the\ncomputation. With the proposed method, we are able to fully utilize the\ncomputing power to minimize the quantization loss and obtain optimized\ninference performance. To verify the effectiveness of our method, we conduct\nimage classification, object detection, and semantic segmentation tasks on\nImageNet, Pascal VOC, and COCO datasets, respectively. Experimental results\ndemonstrate that the proposed method can achieve comparable performance with\nstate-of-the-art quantization methods while accelerating the inference process\nby about 2 times.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 11:56:22 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Xie", "Hongwei", ""], ["Zhang", "Shuo", ""], ["Ding", "Huanghao", ""], ["Song", "Yafei", ""], ["Shao", "Baitao", ""], ["Hu", "Conggang", ""], ["Cai", "Ling", ""], ["Li", "Mingyang", ""]]}, {"id": "2005.13299", "submitter": "Saad Shafiq", "authors": "Saad Shafiq, Atif Mashkoor, Christoph Mayr-Dorn, Alexander Egyed", "title": "Machine Learning for Software Engineering: A Systematic Mapping", "comments": "20 pages, 13 figures, under review in IST journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context: The software development industry is rapidly adopting machine\nlearning for transitioning modern day software systems towards highly\nintelligent and self-learning systems. However, the full potential of machine\nlearning for improving the software engineering life cycle itself is yet to be\ndiscovered, i.e., up to what extent machine learning can help reducing the\neffort/complexity of software engineering and improving the quality of\nresulting software systems. To date, no comprehensive study exists that\nexplores the current state-of-the-art on the adoption of machine learning\nacross software engineering life cycle stages. Objective: This article\naddresses the aforementioned problem and aims to present a state-of-the-art on\nthe growing number of uses of machine learning in software engineering. Method:\nWe conduct a systematic mapping study on applications of machine learning to\nsoftware engineering following the standard guidelines and principles of\nempirical software engineering. Results: This study introduces a machine\nlearning for software engineering (MLSE) taxonomy classifying the\nstate-of-the-art machine learning techniques according to their applicability\nto various software engineering life cycle stages. Overall, 227 articles were\nrigorously selected and analyzed as a result of this study. Conclusion: From\nthe selected articles, we explore a variety of aspects that should be helpful\nto academics and practitioners alike in understanding the potential of adopting\nmachine learning techniques during software engineering projects.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 11:56:56 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Shafiq", "Saad", ""], ["Mashkoor", "Atif", ""], ["Mayr-Dorn", "Christoph", ""], ["Egyed", "Alexander", ""]]}, {"id": "2005.13300", "submitter": "Wonryong Ryou", "authors": "Wonryong Ryou, Jiayu Chen, Mislav Balunovic, Gagandeep Singh, Andrei\n  Dan, Martin Vechev", "title": "Scalable Polyhedral Verification of Recurrent Neural Networks", "comments": "Published in CAV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a scalable and precise verifier for recurrent neural networks,\ncalled Prover based on two novel ideas: (i) a method to compute a set of\npolyhedral abstractions for the non-convex and nonlinear recurrent update\nfunctions by combining sampling, optimization, and Fermat's theorem, and (ii) a\ngradient descent based algorithm for abstraction refinement guided by the\ncertification problem that combines multiple abstractions for each neuron.\nUsing Prover, we present the first study of certifying a non-trivial use case\nof recurrent neural networks, namely speech classification. To achieve this, we\nadditionally develop custom abstractions for the non-linear speech\npreprocessing pipeline. Our evaluation shows that Prover successfully verifies\nseveral challenging recurrent models in computer vision, speech, and motion\nsensor data classification beyond the reach of prior work.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 11:57:01 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 09:56:18 GMT"}, {"version": "v3", "created": "Thu, 10 Jun 2021 21:49:38 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Ryou", "Wonryong", ""], ["Chen", "Jiayu", ""], ["Balunovic", "Mislav", ""], ["Singh", "Gagandeep", ""], ["Dan", "Andrei", ""], ["Vechev", "Martin", ""]]}, {"id": "2005.13303", "submitter": "Junqi Zhang", "authors": "Junqi Zhang, Bing Bai, Ye Lin, Jian Liang, Kun Bai, Fei Wang", "title": "General-Purpose User Embeddings based on Mobile App Usage", "comments": "To be published in the KDD2020 proceedings as a full paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we report our recent practice at Tencent for user modeling\nbased on mobile app usage. User behaviors on mobile app usage, including\nretention, installation, and uninstallation, can be a good indicator for both\nlong-term and short-term interests of users. For example, if a user installs\nSnapseed recently, she might have a growing interest in photographing. Such\ninformation is valuable for numerous downstream applications, including\nadvertising, recommendations, etc. Traditionally, user modeling from mobile app\nusage heavily relies on handcrafted feature engineering, which requires onerous\nhuman work for different downstream applications, and could be sub-optimal\nwithout domain experts. However, automatic user modeling based on mobile app\nusage faces unique challenges, including (1) retention, installation, and\nuninstallation are heterogeneous but need to be modeled collectively, (2) user\nbehaviors are distributed unevenly over time, and (3) many long-tailed apps\nsuffer from serious sparsity. In this paper, we present a tailored\nAutoEncoder-coupled Transformer Network (AETN), by which we overcome these\nchallenges and achieve the goals of reducing manual efforts and boosting\nperformance. We have deployed the model at Tencent, and both online/offline\nexperiments from multiple domains of downstream applications have demonstrated\nthe effectiveness of the output user embeddings.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 12:01:50 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Zhang", "Junqi", ""], ["Bai", "Bing", ""], ["Lin", "Ye", ""], ["Liang", "Jian", ""], ["Bai", "Kun", ""], ["Wang", "Fei", ""]]}, {"id": "2005.13326", "submitter": "Keyu An", "authors": "Keyu An, Hongyu Xiang, Zhijian Ou", "title": "CAT: A CTC-CRF based ASR Toolkit Bridging the Hybrid and the End-to-end\n  Approaches towards Data Efficiency and Low Latency", "comments": "Accepted into INTERSPEECH 2020. arXiv admin note: text overlap with\n  arXiv:1911.08747", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new open source toolkit for speech recognition,\nnamed CAT (CTC-CRF based ASR Toolkit). CAT inherits the data-efficiency of the\nhybrid approach and the simplicity of the E2E approach, providing a\nfull-fledged implementation of CTC-CRFs and complete training and testing\nscripts for a number of English and Chinese benchmarks. Experiments show CAT\nobtains state-of-the-art results, which are comparable to the fine-tuned hybrid\nmodels in Kaldi but with a much simpler training pipeline. Compared to existing\nnon-modularized E2E models, CAT performs better on limited-scale datasets,\ndemonstrating its data efficiency. Furthermore, we propose a new method called\ncontextualized soft forgetting, which enables CAT to do streaming ASR without\naccuracy degradation. We hope CAT, especially the CTC-CRF based framework and\nsoftware, will be of broad interest to the community, and can be further\nexplored and improved.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 12:41:21 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 02:00:08 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["An", "Keyu", ""], ["Xiang", "Hongyu", ""], ["Ou", "Zhijian", ""]]}, {"id": "2005.13352", "submitter": "Hexin Bai", "authors": "Hexin Bai, Peng Chu, Jeng-Yuan Tsai, Nathan Wilson, Xiaofeng Qian,\n  Qimin Yan, Haibin Ling", "title": "Graph Neural Network for Hamiltonian-Based Material Property Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Development of next-generation electronic devices for applications call for\nthe discovery of quantum materials hosting novel electronic, magnetic, and\ntopological properties. Traditional electronic structure methods require\nexpensive computation time and memory consumption, thus a fast and accurate\nprediction model is desired with increasing importance. Representing the\ninteractions among atomic orbitals in any material, a material Hamiltonian\nprovides all the essential elements that control the structure-property\ncorrelations in inorganic compounds. Effective learning of material Hamiltonian\nby developing machine learning methodologies therefore offers a transformative\napproach to accelerate the discovery and design of quantum materials. With this\nmotivation, we present and compare several different graph convolution networks\nthat are able to predict the band gap for inorganic materials. The models are\ndeveloped to incorporate two different features: the information of each\norbital itself and the interaction between each other. The information of each\norbital includes the name, relative coordinates with respect to the center of\nsuper cell and the atom number, while the interaction between orbitals are\nrepresented by the Hamiltonian matrix. The results show that our model can get\na promising prediction accuracy with cross-validation.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 13:32:10 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Bai", "Hexin", ""], ["Chu", "Peng", ""], ["Tsai", "Jeng-Yuan", ""], ["Wilson", "Nathan", ""], ["Qian", "Xiaofeng", ""], ["Yan", "Qimin", ""], ["Ling", "Haibin", ""]]}, {"id": "2005.13358", "submitter": "Jong-Hoon Ahn", "authors": "Jong-Hoon Ahn", "title": "Data-Driven Continuum Dynamics via Transport-Teleport Duality", "comments": "11 pages, 10 figures (Added references, Added figures, Reorganized\n  sections)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, machine learning methods have been widely used to study\nphysical systems that are challenging to solve with governing equations.\nPhysicists and engineers are framing the data-driven paradigm as an alternative\napproach to physical sciences. In this paradigm change, the deep learning\napproach is playing a pivotal role. However, most learning architectures do not\ninherently incorporate conservation laws in the form of continuity equations,\nand they require dense data to learn the dynamics of conserved quantities. In\nthis study, we introduce a clever mathematical transform to represent the\nclassical dynamics as a point-wise process of disappearance and reappearance of\na quantity, which dramatically reduces model complexity and training data for\nmachine learning of transport phenomena. We demonstrate that just a few\nobservational data and a simple learning model can be enough to learn the\ndynamics of real-world objects. The approach does not require the explicit use\nof governing equations and only depends on observation data. Because the\ncontinuity equation is a general equation that any conserved quantity should\nobey, the applicability may range from physical to social and medical sciences\nor any field where data are conserved quantities.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 13:39:09 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 20:58:22 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Ahn", "Jong-Hoon", ""]]}, {"id": "2005.13369", "submitter": "Francesco Zola", "authors": "Francesco Zola, Jan Lukas Bruse, Xabier Etxeberria Barrio, Mikel\n  Galar, Raul Orduna Urrutia", "title": "Generative Adversarial Networks for Bitcoin Data Augmentation", "comments": "8 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Bitcoin entity classification, results are strongly conditioned by the\nground-truth dataset, especially when applying supervised machine learning\napproaches. However, these ground-truth datasets are frequently affected by\nsignificant class imbalance as generally they contain much more information\nregarding legal services (Exchange, Gambling), than regarding services that may\nbe related to illicit activities (Mixer, Service). Class imbalance increases\nthe complexity of applying machine learning techniques and reduces the quality\nof classification results, especially for underrepresented, but critical\nclasses.\n  In this paper, we propose to address this problem by using Generative\nAdversarial Networks (GANs) for Bitcoin data augmentation as GANs recently have\nshown promising results in the domain of image classification. However, there\nis no \"one-fits-all\" GAN solution that works for every scenario. In fact,\nsetting GAN training parameters is non-trivial and heavily affects the quality\nof the generated synthetic data. We therefore evaluate how GAN parameters such\nas the optimization function, the size of the dataset and the chosen batch size\naffect GAN implementation for one underrepresented entity class (Mining Pool)\nand demonstrate how a \"good\" GAN configuration can be obtained that achieves\nhigh similarity between synthetically generated and real Bitcoin address data.\nTo the best of our knowledge, this is the first study presenting GANs as a\nvalid tool for generating synthetic address data for data augmentation in\nBitcoin entity classification.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 13:58:11 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Zola", "Francesco", ""], ["Bruse", "Jan Lukas", ""], ["Barrio", "Xabier Etxeberria", ""], ["Galar", "Mikel", ""], ["Urrutia", "Raul Orduna", ""]]}, {"id": "2005.13399", "submitter": "Lasha Abzianidze", "authors": "Lasha Abzianidze, Rik van Noord, Hessel Haagsma and Johan Bos", "title": "The First Shared Task on Discourse Representation Structure Parsing", "comments": "International Conference on Computational Semantics (IWCS)", "journal-ref": "Proceedings of the IWCS Shared Task on Semantic Parsing, IWCS,\n  SIGSEM, 2019, Association for Computational Linguistics", "doi": "10.18653/v1/W19-1201", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The paper presents the IWCS 2019 shared task on semantic parsing where the\ngoal is to produce Discourse Representation Structures (DRSs) for English\nsentences. DRSs originate from Discourse Representation Theory and represent\nscoped meaning representations that capture the semantics of negation, modals,\nquantification, and presupposition triggers. Additionally, concepts and\nevent-participants in DRSs are described with WordNet synsets and the thematic\nroles from VerbNet. To measure similarity between two DRSs, they are\nrepresented in a clausal form, i.e. as a set of tuples. Participant systems\nwere expected to produce DRSs in this clausal form. Taking into account the\nrich lexical information, explicit scope marking, a high number of shared\nvariables among clauses, and highly-constrained format of valid DRSs, all these\nmakes the DRS parsing a challenging NLP task. The results of the shared task\ndisplayed improvements over the existing state-of-the-art parser.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 14:52:21 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Abzianidze", "Lasha", ""], ["van Noord", "Rik", ""], ["Haagsma", "Hessel", ""], ["Bos", "Johan", ""]]}, {"id": "2005.13400", "submitter": "Byunghyun Ban", "authors": "Byunghyun Ban", "title": "Deep learning method to remove chemical, kinetic and electric artifacts\n  on ISEs", "comments": null, "journal-ref": "2020 International Conference on Information and Communication\n  Technology Convergence (ICTC)", "doi": "10.1109/ICTC49870.2020.9289083", "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest a deep learning based sensor signal processing method to remove\nchemical, kinetic and electrical artifacts from ion selective electrodes'\nmeasured values. An ISE is used to investigate the concentration of a specific\nion from aqueous solution, by measuring the Nernst potential along the glass\nmembrane. However, application of ISE on a mixture of multiple ion has some\nproblem. First problem is a chemical artifact which is called ion interference\neffect. Electrically charged particles interact with each other and flows\nthrough the glass membrane of different ISEs. Second problem is the kinetic\nartifact caused by the movement of the liquid. Water molecules collide with the\nglass membrane causing abnormal peak values of voltage. The last artifact is\nthe interference of ISEs. When multiple ISEs are dipped into same solution, one\nelectrode's signal emission interference voltage measurement of other\nelectrodes. Therefore, an ISE is recommended to be applied on single-ion\nsolution, without any other sensors applied at the same time. Deep learning\napproach can remove both 3 artifacts at the same time. The proposed method used\n5 layers of artificial neural networks to regress correct signal to remove\ncomplex artifacts with one-shot calculation. Its MAPE was less than 1.8% and R2\nof regression was 0.997. A randomly chosen value of AI-processed data has MAPE\nless than 5% (p-value 0.016).\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 12:48:32 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 00:26:41 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 07:56:16 GMT"}, {"version": "v4", "created": "Thu, 15 Oct 2020 07:16:45 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Ban", "Byunghyun", ""]]}, {"id": "2005.13407", "submitter": "Amir Feder", "authors": "Amir Feder, Nadav Oved, Uri Shalit, Roi Reichart", "title": "CausaLM: Causal Model Explanation Through Counterfactual Language Models", "comments": "Our code and data are available at:\n  https://amirfeder.github.io/CausaLM/ Accepted for publication in\n  Computational Linguistics journal", "journal-ref": null, "doi": "10.1162/coli_a_00404", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding predictions made by deep neural networks is notoriously\ndifficult, but also crucial to their dissemination. As all machine learning\nbased methods, they are as good as their training data, and can also capture\nunwanted biases. While there are tools that can help understand whether such\nbiases exist, they do not distinguish between correlation and causation, and\nmight be ill-suited for text-based models and for reasoning about high level\nlanguage concepts. A key problem of estimating the causal effect of a concept\nof interest on a given model is that this estimation requires the generation of\ncounterfactual examples, which is challenging with existing generation\ntechnology. To bridge that gap, we propose CausaLM, a framework for producing\ncausal model explanations using counterfactual language representation models.\nOur approach is based on fine-tuning of deep contextualized embedding models\nwith auxiliary adversarial tasks derived from the causal graph of the problem.\nConcretely, we show that by carefully choosing auxiliary adversarial\npre-training tasks, language representation models such as BERT can effectively\nlearn a counterfactual representation for a given concept of interest, and be\nused to estimate its true causal effect on model performance. A byproduct of\nour method is a language representation model that is unaffected by the tested\nconcept, which can be useful in mitigating unwanted bias ingrained in the data.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 15:06:35 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 06:59:21 GMT"}, {"version": "v3", "created": "Sun, 14 Jun 2020 21:06:43 GMT"}, {"version": "v4", "created": "Sun, 9 May 2021 12:34:18 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Feder", "Amir", ""], ["Oved", "Nadav", ""], ["Shalit", "Uri", ""], ["Reichart", "Roi", ""]]}, {"id": "2005.13420", "submitter": "Derek Onken", "authors": "Derek Onken and Lars Ruthotto", "title": "Discretize-Optimize vs. Optimize-Discretize for Time-Series Regression\n  and Continuous Normalizing Flows", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We compare the discretize-optimize (Disc-Opt) and optimize-discretize\n(Opt-Disc) approaches for time-series regression and continuous normalizing\nflows (CNFs) using neural ODEs. Neural ODEs are ordinary differential equations\n(ODEs) with neural network components. Training a neural ODE is an optimal\ncontrol problem where the weights are the controls and the hidden features are\nthe states. Every training iteration involves solving an ODE forward and\nanother backward in time, which can require large amounts of computation, time,\nand memory. Comparing the Opt-Disc and Disc-Opt approaches in image\nclassification tasks, Gholami et al. (2019) suggest that Disc-Opt is preferable\ndue to the guaranteed accuracy of gradients. In this paper, we extend the\ncomparison to neural ODEs for time-series regression and CNFs. Unlike in\nclassification, meaningful models in these tasks must also satisfy additional\nrequirements beyond accurate final-time output, e.g., the invertibility of the\nCNF. Through our numerical experiments, we demonstrate that with careful\nnumerical treatment, Disc-Opt methods can achieve similar performance as\nOpt-Disc at inference with drastically reduced training costs. Disc-Opt reduced\ncosts in six out of seven separate problems with training time reduction\nranging from 39% to 97%, and in one case, Disc-Opt reduced training from nine\ndays to less than one day.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 15:28:11 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 00:28:12 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Onken", "Derek", ""], ["Ruthotto", "Lars", ""]]}, {"id": "2005.13423", "submitter": "Sebastian Dorn", "authors": "Yunlei Tang, Sebastian Dorn and Chiragkumar Savani", "title": "Center3D: Center-based Monocular 3D Object Detection with Joint Depth\n  Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Localizing objects in 3D space and understanding their associated 3D\nproperties is challenging given only monocular RGB images. The situation is\ncompounded by the loss of depth information during perspective projection. We\npresent Center3D, a one-stage anchor-free approach, to efficiently estimate 3D\nlocation and depth using only monocular RGB images. By exploiting the\ndifference between 2D and 3D centers, we are able to estimate depth\nconsistently. Center3D uses a combination of classification and regression to\nunderstand the hidden depth information more robustly than each method alone.\nOur method employs two joint approaches: (1) LID: a classification-dominated\napproach with sequential Linear Increasing Discretization. (2) DepJoint: a\nregression-dominated approach with multiple Eigen's transformations for depth\nestimation. Evaluating on KITTI dataset for moderate objects, Center3D improved\nthe AP in BEV from $29.7\\%$ to $42.8\\%$, and the AP in 3D from $18.6\\%$ to\n$39.1\\%$. Compared with state-of-the-art detectors, Center3D has achieved the\nbest speed-accuracy trade-off in realtime monocular object detection.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 15:29:09 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Tang", "Yunlei", ""], ["Dorn", "Sebastian", ""], ["Savani", "Chiragkumar", ""]]}, {"id": "2005.13438", "submitter": "Hyeoncheol Cho", "authors": "Hyeoncheol Cho, Eok Kyun Lee, Insung S. Choi", "title": "InteractionNet: Modeling and Explaining of Noncovalent Protein-Ligand\n  Interactions with Noncovalent Graph Neural Network and Layer-Wise Relevance\n  Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expanding the scope of graph-based, deep-learning models to noncovalent\nprotein-ligand interactions has earned increasing attention in structure-based\ndrug design. Modeling the protein-ligand interactions with graph neural\nnetworks (GNNs) has experienced difficulties in the conversion of\nprotein-ligand complex structures into the graph representation and left\nquestions regarding whether the trained models properly learn the appropriate\nnoncovalent interactions. Here, we proposed a GNN architecture, denoted as\nInteractionNet, which learns two separated molecular graphs, being covalent and\nnoncovalent, through distinct convolution layers. We also analyzed the\nInteractionNet model with an explainability technique, i.e., layer-wise\nrelevance propagation, for examination of the chemical relevance of the model's\npredictions. Separation of the covalent and noncovalent convolutional steps\nmade it possible to evaluate the contribution of each step independently and\nanalyze the graph-building strategy for noncovalent interactions. We applied\nInteractionNet to the prediction of protein-ligand binding affinity and showed\nthat our model successfully predicted the noncovalent interactions in both\nperformance and relevance in chemical interpretation.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 12:46:44 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Cho", "Hyeoncheol", ""], ["Lee", "Eok Kyun", ""], ["Choi", "Insung S.", ""]]}, {"id": "2005.13449", "submitter": "Jun Ma", "authors": "Jun Ma", "title": "Segmentation Loss Odyssey", "comments": "Educational Materials\n  (https://miccai-sb.github.io/materials/Ma2019.pdf)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Loss functions are one of the crucial ingredients in deep learning-based\nmedical image segmentation methods. Many loss functions have been proposed in\nexisting literature, but are studied separately or only investigated with few\nother losses. In this paper, we present a systematic taxonomy to sort existing\nloss functions into four meaningful categories. This helps to reveal links and\nfundamental similarities between them. Moreover, we explore the relationship\nbetween the traditional region-based and the more recent boundary-based loss\nfunctions. The PyTorch implementations of these loss functions are publicly\navailable at \\url{https://github.com/JunMa11/SegLoss}.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 16:00:55 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Ma", "Jun", ""]]}, {"id": "2005.13458", "submitter": "Allen Wang", "authors": "Allen Wang, Xin Huang, Ashkan Jasour, and Brian Williams", "title": "Fast Risk Assessment for Autonomous Vehicles Using Learned Models of\n  Agent Futures", "comments": "To appear in Robotics: Science and Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents fast non-sampling based methods to assess the risk of\ntrajectories for autonomous vehicles when probabilistic predictions of other\nagents' futures are generated by deep neural networks (DNNs). The presented\nmethods address a wide range of representations for uncertain predictions\nincluding both Gaussian and non-Gaussian mixture models for predictions of both\nagent positions and controls. We show that the problem of risk assessment when\nGaussian mixture models (GMMs) of agent positions are learned can be solved\nrapidly to arbitrary levels of accuracy with existing numerical methods. To\naddress the problem of risk assessment for non-Gaussian mixture models of agent\nposition, we propose finding upper bounds on risk using Chebyshev's Inequality\nand sums-of-squares (SOS) programming; they are both of interest as the former\nis much faster while the latter can be arbitrarily tight. These approaches only\nrequire statistical moments of agent positions to determine upper bounds on\nrisk. To perform risk assessment when models are learned for agent controls as\nopposed to positions, we develop TreeRing, an algorithm analogous to tree\nsearch over the ring of polynomials that can be used to exactly propagate\nmoments of control distributions into position distributions through nonlinear\ndynamics. The presented methods are demonstrated on realistic predictions from\nDNNs trained on the Argoverse and CARLA datasets and are shown to be effective\nfor rapidly assessing the probability of low probability events.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 16:16:36 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 23:56:09 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Wang", "Allen", ""], ["Huang", "Xin", ""], ["Jasour", "Ashkan", ""], ["Williams", "Brian", ""]]}, {"id": "2005.13483", "submitter": "Pradeep Reddy Raamana", "authors": "Pradeep Reddy Raamana", "title": "Kernel methods library for pattern analysis and machine learning in\n  python", "comments": "6 pages, 3 code examples, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Kernel methods have proven to be powerful techniques for pattern analysis and\nmachine learning (ML) in a variety of domains. However, many of their original\nor advanced implementations remain in Matlab. With the incredible rise and\nadoption of Python in the ML and data science world, there is a clear need for\na well-defined library that enables not only the use of popular kernels, but\nalso allows easy definition of customized kernels to fine-tune them for diverse\napplications. The kernelmethods library fills that important void in the python\nML ecosystem in a domain-agnostic fashion, allowing the sample data type to be\nanything from numerical, categorical, graphs or a combination of them. In\naddition, this library provides a number of well-defined classes to make\nvarious kernel-based operations efficient (for large scale datasets), modular\n(for ease of domain adaptation), and inter-operable (across different\necosystems). The library is available at\nhttps://github.com/raamana/kernelmethods.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 16:44:42 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Raamana", "Pradeep Reddy", ""]]}, {"id": "2005.13485", "submitter": "Ruisheng Cao", "authors": "Ruisheng Cao, Su Zhu, Chenyu Yang, Chen Liu, Rao Ma, Yanbin Zhao, Lu\n  Chen and Kai Yu", "title": "Unsupervised Dual Paraphrasing for Two-stage Semantic Parsing", "comments": "accepted by ACL 2020 Long, 12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One daunting problem for semantic parsing is the scarcity of annotation.\nAiming to reduce nontrivial human labor, we propose a two-stage semantic\nparsing framework, where the first stage utilizes an unsupervised paraphrase\nmodel to convert an unlabeled natural language utterance into the canonical\nutterance. The downstream naive semantic parser accepts the intermediate output\nand returns the target logical form. Furthermore, the entire training process\nis split into two phases: pre-training and cycle learning. Three tailored\nself-supervised tasks are introduced throughout training to activate the\nunsupervised paraphrase model. Experimental results on benchmarks Overnight and\nGeoGranno demonstrate that our framework is effective and compatible with\nsupervised training.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 16:47:44 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 09:19:15 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 11:45:03 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Cao", "Ruisheng", ""], ["Zhu", "Su", ""], ["Yang", "Chenyu", ""], ["Liu", "Chen", ""], ["Ma", "Rao", ""], ["Zhao", "Yanbin", ""], ["Chen", "Lu", ""], ["Yu", "Kai", ""]]}, {"id": "2005.13510", "submitter": "Jeremy Georges-Filteau", "authors": "Jeremy Georges-Filteau, Elisa Cirillo", "title": "Synthetic Observational Health Data with GANs: from slow adoption to a\n  boom in medical research and ultimately digital twins?", "comments": "31 pages (10 in previous version), not including references and\n  glossary, 51 in total. Inclusion of a large number of recent publications and\n  expansion of the discussion accordingly", "journal-ref": null, "doi": "10.22541/au.158921777.79483839/v2", "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  After being collected for patient care, Observational Health Data (OHD) can\nfurther benefit patient well-being by sustaining the development of health\ninformatics and medical research. Vast potential is unexploited because of the\nfiercely private nature of patient-related data and regulations to protect it.\n  Generative Adversarial Networks (GANs) have recently emerged as a\ngroundbreaking way to learn generative models that produce realistic synthetic\ndata. They have revolutionized practices in multiple domains such as\nself-driving cars, fraud detection, digital twin simulations in industrial\nsectors, and medical imaging.\n  The digital twin concept could readily apply to modelling and quantifying\ndisease progression. In addition, GANs posses many capabilities relevant to\ncommon problems in healthcare: lack of data, class imbalance, rare diseases,\nand preserving privacy. Unlocking open access to privacy-preserving OHD could\nbe transformative for scientific research. In the midst of COVID-19, the\nhealthcare system is facing unprecedented challenges, many of which of are data\nrelated for the reasons stated above.\n  Considering these facts, publications concerning GAN applied to OHD seemed to\nbe severely lacking. To uncover the reasons for this slow adoption, we broadly\nreviewed the published literature on the subject. Our findings show that the\nproperties of OHD were initially challenging for the existing GAN algorithms\n(unlike medical imaging, for which state-of-the-art model were directly\ntransferable) and the evaluation synthetic data lacked clear metrics.\n  We find more publications on the subject than expected, starting slowly in\n2017, and since then at an increasing rate. The difficulties of OHD remain, and\nwe discuss issues relating to evaluation, consistency, benchmarking, data\nmodelling, and reproducibility.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 17:40:35 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 18:08:47 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2020 05:27:34 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Georges-Filteau", "Jeremy", ""], ["Cirillo", "Elisa", ""]]}, {"id": "2005.13521", "submitter": "Seokhyeon Park", "authors": "Seok-Hyeon Park, Ohyun Jo", "title": "Q-NAV: NAV Setting Method based on Reinforcement Learning in Underwater\n  Wireless Networks", "comments": "in Korean language", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The demand on the underwater communications is extremely increasing in\nsearching for underwater resources, marine expedition, or environmental\nresearches, yet there are many problems with the wireless communications\nbecause of the characteristics of the underwater environments. Especially, with\nthe underwater wireless networks, there happen inevitable delay time and\nspacial inequality due to the distances between the nodes. To solve these\nproblems, this paper suggests a new solution based on ALOHA-Q. The suggested\nmethod use random NAV value. and Environments take reward through\ncommunications success or fail. After then, The environments setting NAV value\nfrom reward. This model minimizes usage of energy and computing resources under\nthe underwater wireless networks, and learns and setting NAV values through\nintense learning. The results of the simulations show that NAV values can be\nenvironmentally adopted and select best value to the circumstances, so the\nproblems which are unnecessary delay times and spacial inequality can be\nsolved. Result of simulations, NAV time decreasing 17.5% compared with original\nNAV.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 14:15:33 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Park", "Seok-Hyeon", ""], ["Jo", "Ohyun", ""]]}, {"id": "2005.13522", "submitter": "Weiran Yao", "authors": "Weiran Yao, Sean Qian", "title": "Learning to Recommend Signal Plans under Incidents with Real-Time\n  Traffic Prediction", "comments": "To be published in Transportation Research Record (2020)", "journal-ref": null, "doi": "10.1177/0361198120917668", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main question to address in this paper is to recommend optimal signal\ntiming plans in real time under incidents by incorporating domain knowledge\ndeveloped with the traffic signal timing plans tuned for possible incidents,\nand learning from historical data of both traffic and implemented signals\ntiming. The effectiveness of traffic incident management is often limited by\nthe late response time and excessive workload of traffic operators. This paper\nproposes a novel decision-making framework that learns from both data and\ndomain knowledge to real-time recommend contingency signal plans that\naccommodate non-recurrent traffic, with the outputs from real-time traffic\nprediction at least 30 minutes in advance. Specifically, considering the rare\noccurrences of engagement of contingency signal plans for incidents, we propose\nto decompose the end-to-end recommendation task into two hierarchical models:\nreal-time traffic prediction and plan association. We learn the connections\nbetween the two models through metric learning, which reinforces partial-order\npreferences observed from historical signal engagement records. We demonstrate\nthe effectiveness of our approach by testing this framework on the traffic\nnetwork in Cranberry Township in 2019. Results show that our recommendation\nsystem has a precision score of 96.75% and recall of 87.5% on the testing plan,\nand make recommendation of an average of 22.5 minutes lead time ahead of Waze\nalerts. The results suggest that our framework is capable of giving traffic\noperators a significant time window to access the conditions and respond\nappropriately.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 01:30:29 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Yao", "Weiran", ""], ["Qian", "Sean", ""]]}, {"id": "2005.13523", "submitter": "Abdul Moeed", "authors": "Abdul Moeed", "title": "Emotion-robust EEG Classification for Motor Imagery", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developments in Brain Computer Interfaces (BCIs) are empowering those with\nsevere physical afflictions through their use in assistive systems. Common\nmethods of achieving this is via Motor Imagery (MI), which maps brain signals\nto code for certain commands. Electroencephalogram (EEG) is preferred for\nrecording brain signal data on account of it being non-invasive. Despite their\npotential utility, MI-BCI systems are yet confined to research labs. A major\ncause for this is lack of robustness of such systems. As hypothesized by two\nteams during Cybathlon 2016, a particular source of the system's vulnerability\nis the sharp change in the subject's state of emotional arousal. This work aims\ntowards making MI-BCI systems resilient to such emotional perturbations. To do\nso, subjects are exposed to high and low arousal-inducing virtual reality (VR)\nenvironments before recording EEG data. The advent of COVID-19 compelled us to\nmodify our methodology. Instead of training machine learning algorithms to\nclassify emotional arousal, we opt for classifying subjects that serve as proxy\nfor each state. Additionally, MI models are trained for each subject instead of\neach arousal state. As training subjects to use MI-BCI can be an arduous and\ntime-consuming process, reducing this variability and increasing robustness can\nconsiderably accelerate the acceptance and adoption of assistive technologies\npowered by BCI.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 17:31:07 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Moeed", "Abdul", ""]]}, {"id": "2005.13525", "submitter": "Mitch Hill", "authors": "Mitch Hill, Jonathan Mitchell, Song-Chun Zhu", "title": "Stochastic Security: Adversarial Defense Using Long-Run Dynamics of\n  Energy-Based Models", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vulnerability of deep networks to adversarial attacks is a central\nproblem for deep learning from the perspective of both cognition and security.\nThe current most successful defense method is to train a classifier using\nadversarial images created during learning. Another defense approach involves\ntransformation or purification of the original input to remove adversarial\nsignals before the image is classified. We focus on defending naturally-trained\nclassifiers using Markov Chain Monte Carlo (MCMC) sampling with an Energy-Based\nModel (EBM) for adversarial purification. In contrast to adversarial training,\nour approach is intended to secure pre-existing and highly vulnerable\nclassifiers.\n  The memoryless behavior of long-run MCMC sampling will eventually remove\nadversarial signals, while metastable behavior preserves consistent appearance\nof MCMC samples after many steps to allow accurate long-run prediction.\nBalancing these factors can lead to effective purification and robust\nclassification. We evaluate adversarial defense with an EBM using the strongest\nknown attacks against purification. Our contributions are 1) an improved method\nfor training EBM's with realistic long-run MCMC samples, 2) an\nExpectation-Over-Transformation (EOT) defense that resolves theoretical\nambiguities for stochastic defenses and from which the EOT attack naturally\nfollows, and 3) state-of-the-art adversarial defense for naturally-trained\nclassifiers and competitive defense compared to adversarially-trained\nclassifiers on Cifar-10, SVHN, and Cifar-100. Code and pre-trained models are\navailable at https://github.com/point0bar1/ebm-defense.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 17:53:36 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 19:39:26 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Hill", "Mitch", ""], ["Mitchell", "Jonathan", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2005.13530", "submitter": "Stephan Wojtowytsch", "authors": "Stephan Wojtowytsch", "title": "On the Convergence of Gradient Descent Training for Two-layer\n  ReLU-networks in the Mean Field Regime", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a necessary and sufficient condition for the convergence to\nminimum Bayes risk when training two-layer ReLU-networks by gradient descent in\nthe mean field regime with omni-directional initial parameter distribution.\nThis article extends recent results of Chizat and Bach to ReLU-activated\nnetworks and to the situation in which there are no parameters which exactly\nachieve MBR. The condition does not depend on the initalization of parameters\nand concerns only the weak convergence of the realization of the neural\nnetwork, not its parameter distribution.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 17:54:17 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Wojtowytsch", "Stephan", ""]]}, {"id": "2005.13535", "submitter": "Mohammad Rahaman", "authors": "Mohammad Saiedur Rahaman, Jonathan Liono, Yongli Ren, Jeffrey Chan,\n  Shaw Kudo, Tim Rawling and Flora D. Salim", "title": "An Ambient-Physical System to Infer Concentration in Open-plan Workplace", "comments": "12 pages, 14 figures", "journal-ref": null, "doi": "10.1109/JIOT.2020.2996219", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the core challenges in open-plan workspaces is to ensure a good level\nof concentration for the workers while performing their tasks. Hence, being\nable to infer concentration levels of workers will allow building designers,\nmanagers, and workers to estimate what effect different open-plan layouts will\nhave and to find an optimal one. In this research, we present an\nambient-physical system to investigate the concentration inference problem.\nSpecifically, we deploy a series of pervasive sensors to capture various\nambient and physical signals related to perceived concentration at work. The\npracticality of our system has been tested on two large open-plan workplaces\nwith different designs and layouts. The empirical results highlight promising\napplications of pervasive sensing in occupational concentration inference,\nwhich can be adopted to enhance the capabilities of modern workplaces.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 03:23:35 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Rahaman", "Mohammad Saiedur", ""], ["Liono", "Jonathan", ""], ["Ren", "Yongli", ""], ["Chan", "Jeffrey", ""], ["Kudo", "Shaw", ""], ["Rawling", "Tim", ""], ["Salim", "Flora D.", ""]]}, {"id": "2005.13575", "submitter": "Chundra Cathcart", "authors": "Chundra A. Cathcart, Florian Wandl", "title": "In search of isoglosses: continuous and discrete language embeddings in\n  Slavic historical phonology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the ability of neural network architectures to\neffectively learn diachronic phonological generalizations in a multilingual\nsetting. We employ models using three different types of language embedding\n(dense, sigmoid, and straight-through). We find that the Straight-Through model\noutperforms the other two in terms of accuracy, but the Sigmoid model's\nlanguage embeddings show the strongest agreement with the traditional\nsubgrouping of the Slavic languages. We find that the Straight-Through model\nhas learned coherent, semi-interpretable information about sound change, and\noutline directions for future research.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 18:10:46 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Cathcart", "Chundra A.", ""], ["Wandl", "Florian", ""]]}, {"id": "2005.13580", "submitter": "Patrick Esser", "authors": "Robin Rombach and Patrick Esser and Bj\\\"orn Ommer", "title": "Network-to-Network Translation with Conditional Invertible Neural\n  Networks", "comments": "NeurIPS 2020 (oral). Code at https://github.com/CompVis/net2net", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the ever-increasing computational costs of modern machine learning\nmodels, we need to find new ways to reuse such expert models and thus tap into\nthe resources that have been invested in their creation. Recent work suggests\nthat the power of these massive models is captured by the representations they\nlearn. Therefore, we seek a model that can relate between different existing\nrepresentations and propose to solve this task with a conditionally invertible\nnetwork. This network demonstrates its capability by (i) providing generic\ntransfer between diverse domains, (ii) enabling controlled content synthesis by\nallowing modification in other domains, and (iii) facilitating diagnosis of\nexisting representations by translating them into interpretable domains such as\nimages. Our domain transfer network can translate between fixed representations\nwithout having to learn or finetune them. This allows users to utilize various\nexisting domain-specific expert models from the literature that had been\ntrained with extensive computational resources. Experiments on diverse\nconditional image synthesis tasks, competitive image modification results and\nexperiments on image-to-image and text-to-image generation demonstrate the\ngeneric applicability of our approach. For example, we translate between BERT\nand BigGAN, state-of-the-art text and image models to provide text-to-image\ngeneration, which neither of both experts can perform on their own.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 18:14:22 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 20:34:36 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Rombach", "Robin", ""], ["Esser", "Patrick", ""], ["Ommer", "Bj\u00f6rn", ""]]}, {"id": "2005.13590", "submitter": "Haoxian Chen", "authors": "Han Lin, Haoxian Chen, Tianyi Zhang, Clement Laroche, and Krzysztof\n  Choromanski", "title": "Demystifying Orthogonal Monte Carlo and Beyond", "comments": "22 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Orthogonal Monte Carlo (OMC) is a very effective sampling algorithm imposing\nstructural geometric conditions (orthogonality) on samples for variance\nreduction. Due to its simplicity and superior performance as compared to its\nQuasi Monte Carlo counterparts, OMC is used in a wide spectrum of challenging\nmachine learning applications ranging from scalable kernel methods to\npredictive recurrent neural networks, generative models and reinforcement\nlearning. However theoretical understanding of the method remains very limited.\nIn this paper we shed new light on the theoretical principles behind OMC,\napplying theory of negatively dependent random variables to obtain several new\nconcentration results. We also propose a novel extensions of the method\nleveraging number theory techniques and particle algorithms, called\nNear-Orthogonal Monte Carlo (NOMC). We show that NOMC is the first algorithm\nconsistently outperforming OMC in applications ranging from kernel methods to\napproximating distances in probabilistic metric spaces.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 18:44:38 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Lin", "Han", ""], ["Chen", "Haoxian", ""], ["Zhang", "Tianyi", ""], ["Laroche", "Clement", ""], ["Choromanski", "Krzysztof", ""]]}, {"id": "2005.13596", "submitter": "Subhadeep Mukhopadhyay", "authors": "Subhadeep (DEEP) Mukhopadhyay and Kaijun Wang", "title": "Breiman's \"Two Cultures\" Revisited and Reconciled", "comments": "This paper celebrates the 70th anniversary of Statistical Machine\n  Learning--- how far we've come, and how far we have to go. Keywords:\n  Integrated statistical learning theory, Exploratory machine learning,\n  Uncertainty prediction machine, ML-powered modern applied statistics,\n  Information theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG econ.EM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a landmark paper published in 2001, Leo Breiman described the tense\nstandoff between two cultures of data modeling: parametric statistical and\nalgorithmic machine learning. The cultural division between these two\nstatistical learning frameworks has been growing at a steady pace in recent\nyears. What is the way forward? It has become blatantly obvious that this\nwidening gap between \"the two cultures\" cannot be averted unless we find a way\nto blend them into a coherent whole. This article presents a solution by\nestablishing a link between the two cultures. Through examples, we describe the\nchallenges and potential gains of this new integrated statistical thinking.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 19:02:56 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Subhadeep", "", "", "DEEP"], ["Mukhopadhyay", "", ""], ["Wang", "Kaijun", ""]]}, {"id": "2005.13605", "submitter": "Yurun Tian", "authors": "Yurun Tian, Vassileios Balntas, Tony Ng, Axel Barroso-Laguna, Yiannis\n  Demiris, Krystian Mikolajczyk", "title": "D2D: Keypoint Extraction with Describe to Detect Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel approach that exploits the information\nwithin the descriptor space to propose keypoint locations. Detect then\ndescribe, or detect and describe jointly are two typical strategies for\nextracting local descriptors. In contrast, we propose an approach that inverts\nthis process by first describing and then detecting the keypoint locations. %\nDescribe-to-Detect (D2D) leverages successful descriptor models without the\nneed for any additional training. Our method selects keypoints as salient\nlocations with high information content which is defined by the descriptors\nrather than some independent operators. We perform experiments on multiple\nbenchmarks including image matching, camera localisation, and 3D\nreconstruction. The results indicate that our method improves the matching\nperformance of various descriptors and that it generalises across methods and\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 19:27:46 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Tian", "Yurun", ""], ["Balntas", "Vassileios", ""], ["Ng", "Tony", ""], ["Barroso-Laguna", "Axel", ""], ["Demiris", "Yiannis", ""], ["Mikolajczyk", "Krystian", ""]]}, {"id": "2005.13607", "submitter": "Hehuan Ma", "authors": "Hehuan Ma, Yatao Bian, Yu Rong, Wenbing Huang, Tingyang Xu, Weiyang\n  Xie, Geyan Ye, Junzhou Huang", "title": "Multi-View Graph Neural Networks for Molecular Property Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The crux of molecular property prediction is to generate meaningful\nrepresentations of the molecules. One promising route is to exploit the\nmolecular graph structure through Graph Neural Networks (GNNs). It is well\nknown that both atoms and bonds significantly affect the chemical properties of\na molecule, so an expressive model shall be able to exploit both node (atom)\nand edge (bond) information simultaneously. Guided by this observation, we\npresent Multi-View Graph Neural Network (MV-GNN), a multi-view message passing\narchitecture to enable more accurate predictions of molecular properties. In\nMV-GNN, we introduce a shared self-attentive readout component and disagreement\nloss to stabilize the training process. This readout component also renders the\nwhole architecture interpretable. We further boost the expressive power of\nMV-GNN by proposing a cross-dependent message passing scheme that enhances\ninformation communication of the two views, which results in the MV-GNN^cross\nvariant. Lastly, we theoretically justify the expressiveness of the two\nproposed models in terms of distinguishing non-isomorphism graphs. Extensive\nexperiments demonstrate that MV-GNN models achieve remarkably superior\nperformance over the state-of-the-art models on a variety of challenging\nbenchmarks. Meanwhile, visualization results of the node importance are\nconsistent with prior knowledge, which confirms the interpretability power of\nMV-GNN models.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 04:46:07 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 08:57:04 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 06:09:52 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Ma", "Hehuan", ""], ["Bian", "Yatao", ""], ["Rong", "Yu", ""], ["Huang", "Wenbing", ""], ["Xu", "Tingyang", ""], ["Xie", "Weiyang", ""], ["Ye", "Geyan", ""], ["Huang", "Junzhou", ""]]}, {"id": "2005.13616", "submitter": "Barry-John Theobald", "authors": "Ahmed Hussen Abdelaziz and Barry-John Theobald and Paul Dixon and\n  Reinhard Knothe and Nicholas Apostoloff and Sachin Kajareker", "title": "Modality Dropout for Improved Performance-driven Talking Faces", "comments": "Pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our novel deep learning approach for driving animated faces using\nboth acoustic and visual information. In particular, speech-related facial\nmovements are generated using audiovisual information, and non-speech facial\nmovements are generated using only visual information. To ensure that our model\nexploits both modalities during training, batches are generated that contain\naudio-only, video-only, and audiovisual input features. The probability of\ndropping a modality allows control over the degree to which the model exploits\naudio and visual information during training. Our trained model runs in\nreal-time on resource limited hardware (e.g.\\ a smart phone), it is user\nagnostic, and it is not dependent on a potentially error-prone transcription of\nthe speech. We use subjective testing to demonstrate: 1) the improvement of\naudiovisual-driven animation over the equivalent video-only approach, and 2)\nthe improvement in the animation of speech-related facial movements after\nintroducing modality dropout. Before introducing dropout, viewers prefer\naudiovisual-driven animation in 51% of the test sequences compared with only\n18% for video-driven. After introducing dropout viewer preference for\naudiovisual-driven animation increases to 74%, but decreases to 8% for\nvideo-only.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 19:55:33 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Abdelaziz", "Ahmed Hussen", ""], ["Theobald", "Barry-John", ""], ["Dixon", "Paul", ""], ["Knothe", "Reinhard", ""], ["Apostoloff", "Nicholas", ""], ["Kajareker", "Sachin", ""]]}, {"id": "2005.13625", "submitter": "Justin Terry", "authors": "Justin K Terry, Nathaniel Grammel, Ananth Hari, Luis Santos, Benjamin\n  Black", "title": "Revisiting Parameter Sharing In Multi-Agent Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Nonstationarity\" is a fundamental problem in cooperative multi-agent\nreinforcement learning (MARL). It results from every agent's policy changing\nduring learning, while being part of the environment from the perspective of\nother agents. This causes information to inherently oscillate between agents\nduring learning, greatly slowing convergence. We use the MAILP model of\ninformation transfer during multi-agent learning to show that increasing\ncentralization during learning arbitrarily mitigates the slowing of convergence\ndue to nonstationarity. The most centralized case of learning is parameter\nsharing, an uncommonly used MARL method, specific to environments with\nhomogeneous agents. It bootstraps single-agent reinforcement learning (RL)\nmethods and learns an identical policy for each agent. We experimentally\nreplicate our theoretical result of increased learning centralization leading\nto better performance. We further apply parameter sharing to 8 more modern\nsingle-agent deep RL methods for the first time, achieving up to 44 times more\naverage reward in 16% as many episodes compared to previous parameter sharing\nexperiments. We finally give a formal proof of a set of methods that allow\nparameter sharing to serve in environments with heterogeneous agents.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 20:14:28 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 08:33:31 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 23:17:06 GMT"}, {"version": "v4", "created": "Fri, 24 Jul 2020 05:39:03 GMT"}, {"version": "v5", "created": "Wed, 11 Nov 2020 01:19:15 GMT"}, {"version": "v6", "created": "Thu, 25 Feb 2021 22:24:34 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Terry", "Justin K", ""], ["Grammel", "Nathaniel", ""], ["Hari", "Ananth", ""], ["Santos", "Luis", ""], ["Black", "Benjamin", ""]]}, {"id": "2005.13630", "submitter": "Johannes Schneider", "authors": "Johannes Schneider and Michalis Vlachos", "title": "Explaining Neural Networks by Decoding Layer Activations", "comments": null, "journal-ref": "Intelligent Data Analysis (IDA), 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a `CLAssifier-DECoder' architecture (\\emph{ClaDec}) which\nfacilitates the comprehension of the output of an arbitrary layer in a neural\nnetwork (NN). It uses a decoder to transform the non-interpretable\nrepresentation of the given layer to a representation that is more similar to\nthe domain a human is familiar with. In an image recognition problem, one can\nrecognize what information is represented by a layer by contrasting\nreconstructed images of \\emph{ClaDec} with those of a conventional\nauto-encoder(AE) serving as reference. We also extend \\emph{ClaDec} to allow\nthe trade-off between human interpretability and fidelity. We evaluate our\napproach for image classification using Convolutional NNs. We show that\nreconstructed visualizations using encodings from a classifier capture more\nrelevant information for classification than conventional AEs. Relevant code is\navailable at \\url{https://github.com/JohnTailor/ClaDec}\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 20:22:10 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 16:35:52 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 17:11:43 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Schneider", "Johannes", ""], ["Vlachos", "Michalis", ""]]}, {"id": "2005.13638", "submitter": "Sebastian Raschka", "authors": "Zhongjie Yu and Sebastian Raschka", "title": "Looking back to lower-level information in few-shot learning", "comments": "13 pages, 2 figures; fixed typographic errors and added journal ref", "journal-ref": "Information 2020, 11, 345", "doi": "10.3390/info11070345", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are capable of learning new concepts from small numbers of examples.\nIn contrast, supervised deep learning models usually lack the ability to\nextract reliable predictive rules from limited data scenarios when attempting\nto classify new examples. This challenging scenario is commonly known as\nfew-shot learning. Few-shot learning has garnered increased attention in recent\nyears due to its significance for many real-world problems. Recently, new\nmethods relying on meta-learning paradigms combined with graph-based\nstructures, which model the relationship between examples, have shown promising\nresults on a variety of few-shot classification tasks. However, existing work\non few-shot learning is only focused on the feature embeddings produced by the\nlast layer of the neural network. In this work, we propose the utilization of\nlower-level, supporting information, namely the feature embeddings of the\nhidden neural network layers, to improve classifier accuracy. Based on a\ngraph-based meta-learning framework, we develop a method called Looking-Back,\nwhere such lower-level information is used to construct additional graphs for\nlabel propagation in limited data settings. Our experiments on two popular\nfew-shot learning datasets, miniImageNet and tieredImageNet, show that our\nmethod can utilize the lower-level information in the network to improve\nstate-of-the-art classification performance.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 20:32:13 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 02:32:21 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Yu", "Zhongjie", ""], ["Raschka", "Sebastian", ""]]}, {"id": "2005.13643", "submitter": "Abdul Qayyum", "authors": "Abdul Qayyum, Alain Lalande, Thomas Decourselle, Thibaut Pommier,\n  Alexandre Cochet, Fabrice Meriaudeau", "title": "Segmentation of the Myocardium on Late-Gadolinium Enhanced MRI based on\n  2.5 D Residual Squeeze and Excitation Deep Learning Model", "comments": null, "journal-ref": null, "doi": null, "report-no": "MIDL/2020/ExtendedAbstract/4v2lR3Zvsw", "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Cardiac left ventricular (LV) segmentation from short-axis MRI acquired 10\nminutes after the injection of a contrast agent (LGE-MRI) is a necessary step\nin the processing allowing the identification and diagnosis of cardiac diseases\nsuch as myocardial infarction. However, this segmentation is challenging due to\nhigh variability across subjects and the potential lack of contrast between\nstructures. Then, the main objective of this work is to develop an accurate\nautomatic segmentation method based on deep learning models for the myocardial\nborders on LGE-MRI. To this end, 2.5 D residual neural network integrated with\na squeeze and excitation blocks in encoder side with specialized convolutional\nhas been proposed. Late fusion has been used to merge the output of the best\ntrained proposed models from a different set of hyperparameters. A total number\nof 320 exams (with a mean number of 6 slices per exam) were used for training\nand 28 exams used for testing. The performance analysis of the proposed\nensemble model in the basal and middle slices was similar as compared to\nintra-observer study and slightly lower at apical slices. The overall Dice\nscore was 82.01% by our proposed method as compared to Dice score of 83.22%\nobtained from the intra observer study. The proposed model could be used for\nthe automatic segmentation of myocardial border that is a very important step\nfor accurate quantification of no-reflow, myocardial infarction, myocarditis,\nand hypertrophic cardiomyopathy, among others.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 20:44:38 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Qayyum", "Abdul", ""], ["Lalande", "Alain", ""], ["Decourselle", "Thomas", ""], ["Pommier", "Thibaut", ""], ["Cochet", "Alexandre", ""], ["Meriaudeau", "Fabrice", ""]]}, {"id": "2005.13665", "submitter": "Zihao Zhang", "authors": "Zihao Zhang, Stefan Zohren, Stephen Roberts", "title": "Deep Learning for Portfolio Optimization", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": "10.3905/jfds.2020.1.042", "report-no": null, "categories": "q-fin.PM cs.LG q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We adopt deep learning models to directly optimise the portfolio Sharpe\nratio. The framework we present circumvents the requirements for forecasting\nexpected returns and allows us to directly optimise portfolio weights by\nupdating model parameters. Instead of selecting individual assets, we trade\nExchange-Traded Funds (ETFs) of market indices to form a portfolio. Indices of\ndifferent asset classes show robust correlations and trading them substantially\nreduces the spectrum of available assets to choose from. We compare our method\nwith a wide range of algorithms with results showing that our model obtains the\nbest performance over the testing period, from 2011 to the end of April 2020,\nincluding the financial instabilities of the first quarter of 2020. A\nsensitivity analysis is included to understand the relevance of input features\nand we further study the performance of our approach under different cost rates\nand different risk levels via volatility scaling.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 21:28:43 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 20:25:46 GMT"}, {"version": "v3", "created": "Sat, 23 Jan 2021 18:19:33 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Zhang", "Zihao", ""], ["Zohren", "Stefan", ""], ["Roberts", "Stephen", ""]]}, {"id": "2005.13685", "submitter": "Ameer Haj-Ali", "authors": "Ameer Haj-Ali, Hasan Genc, Qijing Huang, William Moses, John\n  Wawrzynek, Krste Asanovi\\'c, Ion Stoica", "title": "ProTuner: Tuning Programs with Monte Carlo Tree Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore applying the Monte Carlo Tree Search (MCTS) algorithm in a\nnotoriously difficult task: tuning programs for high-performance deep learning\nand image processing. We build our framework on top of Halide and show that\nMCTS can outperform the state-of-the-art beam-search algorithm. Unlike beam\nsearch, which is guided by greedy intermediate performance comparisons between\npartial and less meaningful schedules, MCTS compares complete schedules and\nlooks ahead before making any intermediate scheduling decision. We further\nexplore modifications to the standard MCTS algorithm as well as combining real\nexecution time measurements with the cost model. Our results show that MCTS can\noutperform beam search on a suite of 16 real benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 22:25:10 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Haj-Ali", "Ameer", ""], ["Genc", "Hasan", ""], ["Huang", "Qijing", ""], ["Moses", "William", ""], ["Wawrzynek", "John", ""], ["Asanovi\u0107", "Krste", ""], ["Stoica", "Ion", ""]]}, {"id": "2005.13695", "submitter": "Mohammed Ahmed", "authors": "Mohammed Ahmed, Hongbo Du, Alaa AlZoubi", "title": "An ENAS Based Approach for Constructing Deep Learning Models for Breast\n  Cancer Recognition from Ultrasound Images", "comments": "6 pages, 3 figures, Conference: Medical Imaging with Deep Learning\n  2020", "journal-ref": null, "doi": null, "report-no": "MIDL/2020/ExtendedAbstract/GxYt8XnZHM", "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Convolutional Neural Networks (CNN) provides an \"end-to-end\" solution\nfor image pattern recognition with impressive performance in many areas of\napplication including medical imaging. Most CNN models of high performance use\nhand-crafted network architectures that require expertise in CNNs to utilise\ntheir potentials. In this paper, we applied the Efficient Neural Architecture\nSearch (ENAS) method to find optimal CNN architectures for classifying breast\nlesions from ultrasound (US) images. Our empirical study with a dataset of 524\nUS images shows that the optimal models generated by using ENAS achieve an\naverage accuracy of 89.3%, surpassing other hand-crafted alternatives.\nFurthermore, the models are simpler in complexity and more efficient. Our study\ndemonstrates that the ENAS approach to CNN model design is a promising\ndirection for classifying ultrasound images of breast lesions.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 22:49:45 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Ahmed", "Mohammed", ""], ["Du", "Hongbo", ""], ["AlZoubi", "Alaa", ""]]}, {"id": "2005.13702", "submitter": "Shahbaz Rezaei", "authors": "Shahbaz Rezaei and Xin Liu", "title": "On the Difficulty of Membership Inference Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies propose membership inference (MI) attacks on deep models,\nwhere the goal is to infer if a sample has been used in the training process.\nDespite their apparent success, these studies only report accuracy, precision,\nand recall of the positive class (member class). Hence, the performance of\nthese attacks have not been clearly reported on negative class (non-member\nclass). In this paper, we show that the way the MI attack performance has been\nreported is often misleading because they suffer from high false positive rate\nor false alarm rate (FAR) that has not been reported. FAR shows how often the\nattack model mislabel non-training samples (non-member) as training (member)\nones. The high FAR makes MI attacks fundamentally impractical, which is\nparticularly more significant for tasks such as membership inference where the\nmajority of samples in reality belong to the negative (non-training) class.\nMoreover, we show that the current MI attack models can only identify the\nmembership of misclassified samples with mediocre accuracy at best, which only\nconstitute a very small portion of training samples.\n  We analyze several new features that have not been comprehensively explored\nfor membership inference before, including distance to the decision boundary\nand gradient norms, and conclude that deep models' responses are mostly similar\namong train and non-train samples. We conduct several experiments on image\nclassification tasks, including MNIST, CIFAR-10, CIFAR-100, and ImageNet, using\nvarious model architecture, including LeNet, AlexNet, ResNet, etc. We show that\nthe current state-of-the-art MI attacks cannot achieve high accuracy and low\nFAR at the same time, even when the attacker is given several advantages.\n  The source code is available at https://github.com/shrezaei/MI-Attack.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 23:09:17 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 00:18:48 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 20:17:22 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Rezaei", "Shahbaz", ""], ["Liu", "Xin", ""]]}, {"id": "2005.13706", "submitter": "Yifeng Zeng", "authors": "Bilian Chen, Biyang Ma, Yifeng Zeng, Langcai Cao, Jing Tang", "title": "Tensor Decomposition for Multi-agent Predictive State Representation", "comments": "20 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive state representation~(PSR) uses a vector of action-observation\nsequence to represent the system dynamics and subsequently predicts the\nprobability of future events. It is a concise knowledge representation that is\nwell studied in a single-agent planning problem domain. To the best of our\nknowledge, there is no existing work on using PSR to solve multi-agent planning\nproblems. Learning a multi-agent PSR model is quite difficult especially with\nthe increasing number of agents, not to mention the complexity of a problem\ndomain. In this paper, we resort to tensor techniques to tackle the challenging\ntask of multi-agent PSR model development problems. By first focusing on a\ntwo-agent setting, we construct the system dynamics matrix as a high order\ntensor for a PSR model, learn the prediction parameters and deduce state\nvectors directly through two different tensor decomposition methods\nrespectively, and derive the transition parameters via linear regression.\nSubsequently, we generalize the PSR learning approaches in a multi-agent\nsetting. Experimental results show that our methods can effectively solve\nmulti-agent PSR modelling problems in multiple problem domains.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 23:19:18 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Chen", "Bilian", ""], ["Ma", "Biyang", ""], ["Zeng", "Yifeng", ""], ["Cao", "Langcai", ""], ["Tang", "Jing", ""]]}, {"id": "2005.13712", "submitter": "Han Qiu", "authors": "Han Qiu, Yi Zeng, Qinkai Zheng, Tianwei Zhang, Meikang Qiu, Gerard\n  Memmi", "title": "Mitigating Advanced Adversarial Attacks with More Advanced Gradient\n  Obfuscation Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are well-known to be vulnerable to Adversarial\nExamples (AEs). A large amount of efforts have been spent to launch and heat\nthe arms race between the attackers and defenders. Recently, advanced\ngradient-based attack techniques were proposed (e.g., BPDA and EOT), which have\ndefeated a considerable number of existing defense methods. Up to today, there\nare still no satisfactory solutions that can effectively and efficiently defend\nagainst those attacks.\n  In this paper, we make a steady step towards mitigating those advanced\ngradient-based attacks with two major contributions. First, we perform an\nin-depth analysis about the root causes of those attacks, and propose four\nproperties that can break the fundamental assumptions of those attacks. Second,\nwe identify a set of operations that can meet those properties. By integrating\nthese operations, we design two preprocessing functions that can invalidate\nthese powerful attacks. Extensive evaluations indicate that our solutions can\neffectively mitigate all existing standard and advanced attack techniques, and\nbeat 11 state-of-the-art defense solutions published in top-tier conferences\nover the past 2 years. The defender can employ our solutions to constrain the\nattack success rate below 7% for the strongest attacks even the adversary has\nspent dozens of GPU hours.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 23:42:25 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Qiu", "Han", ""], ["Zeng", "Yi", ""], ["Zheng", "Qinkai", ""], ["Zhang", "Tianwei", ""], ["Qiu", "Meikang", ""], ["Memmi", "Gerard", ""]]}, {"id": "2005.13718", "submitter": "Asia Biega", "authors": "Asia J. Biega, Peter Potash, Hal Daum\\'e III, Fernando Diaz, Mich\\`ele\n  Finck", "title": "Operationalizing the Legal Principle of Data Minimization for\n  Personalization", "comments": "SIGIR 2020 paper: In Proc. of the 43rd International ACM SIGIR\n  Conference on Research and Development in Information Retrieval", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Article 5(1)(c) of the European Union's General Data Protection Regulation\n(GDPR) requires that \"personal data shall be [...] adequate, relevant, and\nlimited to what is necessary in relation to the purposes for which they are\nprocessed (`data minimisation')\". To date, the legal and computational\ndefinitions of `purpose limitation' and `data minimization' remain largely\nunclear. In particular, the interpretation of these principles is an open issue\nfor information access systems that optimize for user experience through\npersonalization and do not strictly require personal data collection for the\ndelivery of basic service.\n  In this paper, we identify a lack of a homogeneous interpretation of the data\nminimization principle and explore two operational definitions applicable in\nthe context of personalization. The focus of our empirical study in the domain\nof recommender systems is on providing foundational insights about the (i)\nfeasibility of different data minimization definitions, (ii) robustness of\ndifferent recommendation algorithms to minimization, and (iii) performance of\ndifferent minimization strategies.We find that the performance decrease\nincurred by data minimization might not be substantial, but that it might\ndisparately impact different users---a finding which has implications for the\nviability of different formal minimization definitions. Overall, our analysis\nuncovers the complexities of the data minimization problem in the context of\npersonalization and maps the remaining computational and regulatory challenges.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 00:43:06 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Biega", "Asia J.", ""], ["Potash", "Peter", ""], ["Daum\u00e9", "Hal", "III"], ["Diaz", "Fernando", ""], ["Finck", "Mich\u00e8le", ""]]}, {"id": "2005.13746", "submitter": "Yinan Wang", "authors": "Yinan Wang, Weihong \"Grace\" Guo, Xiaowei Yue", "title": "Tensor decomposition to Compress Convolutional Layers in Deep Learning", "comments": "35 pages, IISE Transactions", "journal-ref": null, "doi": "10.1080/24725854.2021.1894514", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature extraction for tensor data serves as an important step in many tasks\nsuch as anomaly detection, process monitoring, image classification, and\nquality control. Although many methods have been proposed for tensor feature\nextraction, there are still two challenges that need to be addressed: 1) how to\nreduce the computation cost for high dimensional and large volume tensor data;\n2) how to interpret the output features and evaluate their significance. {The\nmost recent methods in deep learning, such as Convolutional Neural Network\n(CNN), have shown outstanding performance in analyzing tensor data, but their\nwide adoption is still hindered by model complexity and lack of\ninterpretability. To fill this research gap, we propose to use CP-decomposition\nto approximately compress the convolutional layer (CPAC-Conv layer) in deep\nlearning. The contributions of our work could be summarized into three aspects:\n(1) we adapt CP-decomposition to compress convolutional kernels and derive the\nexpressions of both forward and backward propagations for our proposed\nCPAC-Conv layer; (2) compared with the original convolutional layer, the\nproposed CPAC-Conv layer can reduce the number of parameters without decaying\nprediction performance. It can combine with other layers to build novel deep\nNeural Networks; (3) the value of decomposed kernels indicates the significance\nof the corresponding feature map, which provides us with insights to guide\nfeature selection.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 02:35:48 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 01:53:10 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wang", "Yinan", ""], ["Guo", "Weihong \"Grace\"", ""], ["Yue", "Xiaowei", ""]]}, {"id": "2005.13748", "submitter": "Han Bao", "authors": "Han Bao, Clayton Scott, Masashi Sugiyama", "title": "Calibrated Surrogate Losses for Adversarially Robust Classification", "comments": "Corrigendum to the published version in COLT2020\n  (http://proceedings.mlr.press/v125/bao20a.html)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarially robust classification seeks a classifier that is insensitive to\nadversarial perturbations of test patterns. This problem is often formulated\nvia a minimax objective, where the target loss is the worst-case value of the\n0-1 loss subject to a bound on the size of perturbation. Recent work has\nproposed convex surrogates for the adversarial 0-1 loss, in an effort to make\noptimization more tractable. A primary question is that of consistency, that\nis, whether minimization of the surrogate risk implies minimization of the\nadversarial 0-1 risk. In this work, we analyze this question through the lens\nof calibration, which is a pointwise notion of consistency. We show that no\nconvex surrogate loss is calibrated with respect to the adversarial 0-1 loss\nwhen restricted to the class of linear models. We further introduce a class of\nnonconvex losses and offer necessary and sufficient conditions for losses in\nthis class to be calibrated. We also show that if the underlying distribution\nsatisfies Massart's noise condition, convex losses can also be calibrated in\nthe adversarial setting.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 02:40:42 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 09:56:30 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Bao", "Han", ""], ["Scott", "Clayton", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2005.13754", "submitter": "Petros Spachos", "authors": "Pai Chet Ng, Petros Spachos, Konstantinos Plataniotis", "title": "COVID-19 and Your Smartphone: BLE-based Smart Contact Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.HC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact tracing is of paramount importance when it comes to preventing the\nspreading of infectious diseases. Contact tracing is usually performed manually\nby authorized personnel. Manual contact tracing is an inefficient, error-prone,\ntime-consuming process of limited utility to the population at large as those\nin close contact with infected individuals are informed hours, if not days,\nlater. This paper introduces an alternative way to manual contact tracing. The\nproposed Smart Contact Tracing (SCT) system utilizes the smartphone's Bluetooth\nLow Energy (BLE) signals and machine learning classifier to accurately and\nquickly determined the contact profile. SCT's contribution is two-fold: a)\nclassification of the user's contact as high/low-risk using precise proximity\nsensing, and b) user anonymity using a privacy-preserving communications\nprotocol. SCT leverages BLE's non-connectable advertising feature to broadcast\na signature packet when the user is in the public space. Both broadcasted and\nobserved signatures are stored in the user's smartphone and they are only\nuploaded to a secure signature database when a user is confirmed by public\nhealth authorities to be infected. Using received signal strength (RSS) each\nsmartphone estimates its distance from other user's phones and issues real-time\nalerts when social distancing rules are violated. The paper includes extensive\nexperimentation utilizing real-life smartphone positions and a comparative\nevaluation of five machine learning classifiers. Reported results indicate that\na decision tree classifier outperforms other states of the art classification\nmethods in terms of accuracy. Lastly, to facilitate research in this area, and\nto contribute to the timely development of advanced solutions the entire data\nset of six experiments with about 123,000 data points is made publicly\navailable.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 02:56:17 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Ng", "Pai Chet", ""], ["Spachos", "Petros", ""], ["Plataniotis", "Konstantinos", ""]]}, {"id": "2005.13755", "submitter": "Paula Gordaliza", "authors": "Eustasio del Barrio, Paula Gordaliza, Jean-Michel Loubes", "title": "Review of Mathematical frameworks for Fairness in Machine Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:2001.07864,\n  arXiv:1911.04322, arXiv:1906.05082 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A review of the main fairness definitions and fair learning methodologies\nproposed in the literature over the last years is presented from a mathematical\npoint of view. Following our independence-based approach, we consider how to\nbuild fair algorithms and the consequences on the degradation of their\nperformance compared to the possibly unfair case. This corresponds to the price\nfor fairness given by the criteria $\\textit{statistical parity}$ or\n$\\textit{equality of odds}$. Novel results giving the expressions of the\noptimal fair classifier and the optimal fair predictor (under a linear\nregression gaussian model) in the sense of $\\textit{equality of odds}$ are\npresented.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 11:40:13 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["del Barrio", "Eustasio", ""], ["Gordaliza", "Paula", ""], ["Loubes", "Jean-Michel", ""]]}, {"id": "2005.13766", "submitter": "Risto Miikkulainen", "authors": "Risto Miikkulainen, Olivier Francon, Elliot Meyerson, Xin Qiu, Elisa\n  Canzani, and Babak Hodjat", "title": "From Prediction to Prescription: Evolutionary Optimization of\n  Non-Pharmaceutical Interventions in the COVID-19 Pandemic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several models have been developed to predict how the COVID-19 pandemic\nspreads, and how it could be contained with non-pharmaceutical interventions\n(NPIs) such as social distancing restrictions and school and business closures.\nThis paper demonstrates how evolutionary AI could be used to facilitate the\nnext step, i.e. determining most effective intervention strategies\nautomatically. Through evolutionary surrogate-assisted prescription (ESP), it\nis possible to generate a large number of candidate strategies and evaluate\nthem with predictive models. In principle, strategies can be customized for\ndifferent countries and locales, and balance the need to contain the pandemic\nand the need to minimize their economic impact. While still limited by\navailable data, early experiments suggest that workplace and school\nrestrictions are the most important and need to be designed carefully. It also\ndemonstrates that results of lifting restrictions can be unreliable, and\nsuggests creative ways in which restrictions can be implemented softly, e.g. by\nalternating them over time. As more data becomes available, the approach can be\nincreasingly useful in dealing with COVID-19 as well as possible future\npandemics.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 03:43:31 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 23:12:48 GMT"}, {"version": "v3", "created": "Sat, 1 Aug 2020 23:02:52 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Miikkulainen", "Risto", ""], ["Francon", "Olivier", ""], ["Meyerson", "Elliot", ""], ["Qiu", "Xin", ""], ["Canzani", "Elisa", ""], ["Hodjat", "Babak", ""]]}, {"id": "2005.13773", "submitter": "Martin P. Seybold", "authors": "Joachim Gudmundsson, Michael Horton, John Pfeifer, Martin P. Seybold", "title": "A Practical Index Structure Supporting Fr\\'echet Proximity Queries Among\n  Trajectories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a scalable approach for range and $k$ nearest neighbor queries\nunder computationally expensive metrics, like the continuous Fr\\'echet distance\non trajectory data. Based on clustering for metric indexes, we obtain a dynamic\ntree structure whose size is linear in the number of trajectories, regardless\nof the trajectory's individual sizes or the spatial dimension, which allows one\nto exploit low `intrinsic dimensionality' of data sets for effective search\nspace pruning.\n  Since the distance computation is expensive, generic metric indexing methods\nare rendered impractical. We present strategies that (i) improve on known upper\nand lower bound computations, (ii) build cluster trees without any or very few\ndistance calls, and (iii) search using bounds for metric pruning, interval\norderings for reduction, and randomized pivoting for reporting the final\nresults.\n  We analyze the efficiency and effectiveness of our methods with extensive\nexperiments on diverse synthetic and real-world data sets. The results show\nimprovement over state-of-the-art methods for exact queries, and even further\nspeed-ups are achieved for queries that may return approximate results.\nSurprisingly, the majority of exact nearest-neighbor queries on real data sets\nare answered without any distance computations.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 04:12:43 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Gudmundsson", "Joachim", ""], ["Horton", "Michael", ""], ["Pfeifer", "John", ""], ["Seybold", "Martin P.", ""]]}, {"id": "2005.13778", "submitter": "Parth Chadha", "authors": "Parth Chadha", "title": "Domain Knowledge Integration By Gradient Matching For Sample-Efficient\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free deep reinforcement learning (RL) agents can learn an effective\npolicy directly from repeated interactions with a black-box environment.\nHowever in practice, the algorithms often require large amounts of training\nexperience to learn and generalize well. In addition, classic model-free\nlearning ignores the domain information contained in the state transition\ntuples. Model-based RL, on the other hand, attempts to learn a model of the\nenvironment from experience and is substantially more sample efficient, but\nsuffers from significantly large asymptotic bias owing to the imperfect\ndynamics model. In this paper, we propose a gradient matching algorithm to\nimprove sample efficiency by utilizing target slope information from the\ndynamics predictor to aid the model-free learner. We demonstrate this by\npresenting a technique for matching the gradient information from the\nmodel-based learner with the model-free component in an abstract\nlow-dimensional space and validate the proposed technique through experimental\nresults that demonstrate the efficacy of this approach.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 05:02:47 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Chadha", "Parth", ""]]}, {"id": "2005.13787", "submitter": "Leyla Roohi", "authors": "Leyla Roohi, Benjamin I. P. Rubinstein and Vanessa Teague", "title": "Assessing Centrality Without Knowing Connections", "comments": "Full report of paper appearing in PAKDD2020", "journal-ref": "In: Advances in Knowledge Discovery and Data Mining. PAKDD 2020.\n  Lecture Notes in Computer Science, vol 12085. Springer, Cham, pages 152-163\n  (2020)", "doi": "10.1007/978-3-030-47436-2_12", "report-no": null, "categories": "cs.CR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the privacy-preserving computation of node influence in\ndistributed social networks, as measured by egocentric betweenness centrality\n(EBC). Motivated by modern communication networks spanning multiple providers,\nwe show for the first time how multiple mutually-distrusting parties can\nsuccessfully compute node EBC while revealing only differentially-private\ninformation about their internal network connections. A theoretical utility\nanalysis upper bounds a primary source of private EBC error---private release\nof ego networks---with high probability. Empirical results demonstrate\npractical applicability with a low 1.07 relative error achievable at strong\nprivacy budget $\\epsilon=0.1$ on a Facebook graph, and insignificant\nperformance degradation as the number of network provider parties grows.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 05:51:12 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Roohi", "Leyla", ""], ["Rubinstein", "Benjamin I. P.", ""], ["Teague", "Vanessa", ""]]}, {"id": "2005.13796", "submitter": "Zejiang Hou", "authors": "Zejiang Hou and Sun-Yuan Kung", "title": "A Feature-map Discriminant Perspective for Pruning Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network pruning has become the de facto tool to accelerate deep neural\nnetworks for mobile and edge applications. Recently, feature-map discriminant\nbased channel pruning has shown promising results, as it aligns well with the\nCNN objective of differentiating multiple classes and offers better\ninterpretability of the pruning decision. However, existing discriminant-based\nmethods are challenged by computation inefficiency, as there is a lack of\ntheoretical guidance on quantifying the feature-map discriminant power. In this\npaper, we present a new mathematical formulation to accurately and efficiently\nquantify the feature-map discriminativeness, which gives rise to a novel\ncriterion,Discriminant Information(DI). We analyze the theoretical property of\nDI, specifically the non-decreasing property, that makes DI a valid selection\ncriterion. DI-based pruning removes channels with minimum influence to DI\nvalue, as they contain little information regarding to the discriminant power.\nThe versatility of DI criterion also enables an intra-layer mixed precision\nquantization to further compress the network. Moreover, we propose a DI-based\ngreedy pruning algorithm and structure distillation technique to automatically\ndecide the pruned structure that satisfies certain resource budget, which is a\ncommon requirement in reality. Extensive experiments demonstratethe\neffectiveness of our method: our pruned ResNet50 on ImageNet achieves 44% FLOPs\nreduction without any Top-1 accuracy loss compared to unpruned model\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 06:25:22 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Hou", "Zejiang", ""], ["Kung", "Sun-Yuan", ""]]}, {"id": "2005.13797", "submitter": "Michael Shin", "authors": "Michael Shin, Eduardo Castillo, Irene Font Peradejordi, Shobhna\n  Jayaraman", "title": "3D human pose estimation with adaptive receptive fields and dilated\n  temporal convolutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this work, we demonstrate that receptive fields in 3D pose estimation can\nbe effectively specified using optical flow. We introduce adaptive receptive\nfields, a simple and effective method to aid receptive field selection in pose\nestimation models based on optical flow inference. We contrast the performance\nof a benchmark state-of-the-art model running on fixed receptive fields with\ntheir adaptive field counterparts. By using a reduced receptive field, our\nmodel can process slow-motion sequences (10x longer) 23% faster than the\nbenchmark model running at regular speed. The reduction in computational cost\nis achieved while producing a pose prediction accuracy to within 0.36% of the\nbenchmark model.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 06:25:41 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Shin", "Michael", ""], ["Castillo", "Eduardo", ""], ["Peradejordi", "Irene Font", ""], ["Jayaraman", "Shobhna", ""]]}, {"id": "2005.13799", "submitter": "Amitojdeep Singh", "authors": "Amitojdeep Singh, Sourya Sengupta, Vasudevan Lakshminarayanan", "title": "Explainable deep learning models in medical image analysis", "comments": "Preprint submitted to J.Imaging, MDPI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning methods have been very effective for a variety of medical\ndiagnostic tasks and has even beaten human experts on some of those. However,\nthe black-box nature of the algorithms has restricted clinical use. Recent\nexplainability studies aim to show the features that influence the decision of\na model the most. The majority of literature reviews of this area have focused\non taxonomy, ethics, and the need for explanations. A review of the current\napplications of explainable deep learning for different medical imaging tasks\nis presented here. The various approaches, challenges for clinical deployment,\nand the areas requiring further research are discussed here from a practical\nstandpoint of a deep learning researcher designing a system for the clinical\nend-users.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 06:31:05 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Singh", "Amitojdeep", ""], ["Sengupta", "Sourya", ""], ["Lakshminarayanan", "Vasudevan", ""]]}, {"id": "2005.13815", "submitter": "Nam Ho-Nguyen", "authors": "Nam Ho-Nguyen, Stephen J. Wright", "title": "Adversarial Classification via Distributional Robustness with\n  Wasserstein Ambiguity", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a model for adversarial classification based on distributionally\nrobust chance constraints. We show that under Wasserstein ambiguity, the model\naims to minimize the conditional value-at-risk of the distance to\nmisclassification, and we explore links to adversarial classification models\nproposed earlier and to maximum-margin classifiers. We also provide a\nreformulation of the distributionally robust model for linear classification,\nand show it is equivalent to minimizing a regularized ramp loss objective.\nNumerical experiments show that, despite the nonconvexity of this formulation,\nstandard descent methods appear to converge to the global minimizer for this\nproblem. Inspired by this observation, we show that, for a certain separable\ndistribution, the only stationary point of the regularized ramp loss\nminimization problem is the global minimizer.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 07:28:47 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 11:14:13 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Ho-Nguyen", "Nam", ""], ["Wright", "Stephen J.", ""]]}, {"id": "2005.13818", "submitter": "He Huang", "authors": "He Huang, Martin Pouls, Anne Meyer, and Markus Pauly", "title": "Travel Time Prediction using Tree-Based Ensembles", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-59747-4_27", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the task of predicting travel times between two\narbitrary points in an urban scenario. We view this problem from two temporal\nperspectives: long-term forecasting with a horizon of several days and\nshort-term forecasting with a horizon of one hour. Both of these perspectives\nare relevant for planning tasks in the context of urban mobility and\ntransportation services. We utilize tree-based ensemble methods that we train\nand evaluate on a dataset of taxi trip records from New York City. Through\nextensive data analysis, we identify relevant temporal and spatial features. We\nalso engineer additional features based on weather and routing data. The latter\nis obtained via a routing solver operating on the road network. The\ncomputational results show that the addition of this routing data can be\nbeneficial to the model performance. Moreover, employing different models for\nshort and long-term prediction is useful as short-term models are better suited\nto mirror current traffic conditions. In fact, we show that accurate short-term\npredictions may be obtained with only little training data.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 07:43:54 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Huang", "He", ""], ["Pouls", "Martin", ""], ["Meyer", "Anne", ""], ["Pauly", "Markus", ""]]}, {"id": "2005.13826", "submitter": "Weiran Huang", "authors": "Aoxue Li and Weiran Huang and Xu Lan and Jiashi Feng and Zhenguo Li\n  and Liwei Wang", "title": "Boosting Few-Shot Learning With Adaptive Margin Loss", "comments": "Accepted by CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning (FSL) has attracted increasing attention in recent years\nbut remains challenging, due to the intrinsic difficulty in learning to\ngeneralize from a few examples. This paper proposes an adaptive margin\nprinciple to improve the generalization ability of metric-based meta-learning\napproaches for few-shot learning problems. Specifically, we first develop a\nclass-relevant additive margin loss, where semantic similarity between each\npair of classes is considered to separate samples in the feature embedding\nspace from similar classes. Further, we incorporate the semantic context among\nall classes in a sampled training task and develop a task-relevant additive\nmargin loss to better distinguish samples from different classes. Our adaptive\nmargin method can be easily extended to a more realistic generalized FSL\nsetting. Extensive experiments demonstrate that the proposed method can boost\nthe performance of current metric-based meta-learning approaches, under both\nthe standard FSL and generalized FSL settings.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 07:58:41 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Li", "Aoxue", ""], ["Huang", "Weiran", ""], ["Lan", "Xu", ""], ["Feng", "Jiashi", ""], ["Li", "Zhenguo", ""], ["Wang", "Liwei", ""]]}, {"id": "2005.13835", "submitter": "Da Yi Wu", "authors": "Da-Yi Wu, Yi-Hsuan Yang", "title": "Speech-to-Singing Conversion based on Boundary Equilibrium GAN", "comments": "Accepted for publication at INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper investigates the use of generative adversarial network (GAN)-based\nmodels for converting the spectrogram of a speech signal into that of a singing\none, without reference to the phoneme sequence underlying the speech. This is\nachieved by viewing speech-to-singing conversion as a style transfer problem.\nSpecifically, given a speech input, and optionally the F0 contour of the target\nsinging, the proposed model generates as the output a singing signal with a\nprogressive-growing encoder/decoder architecture and boundary equilibrium GAN\nloss functions. Our quantitative and qualitative analysis show that the\nproposed model generates singing voices with much higher naturalness than an\nexisting non adversarially-trained baseline. For reproducibility, the code will\nbe publicly available at a GitHub repository upon paper publication.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 08:18:02 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 13:34:14 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 13:21:32 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Wu", "Da-Yi", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "2005.13837", "submitter": "Seanie Lee", "authors": "Dong Bok Lee, Seanie Lee, Woo Tae Jeong, Donghwan Kim, Sung Ju Hwang", "title": "Generating Diverse and Consistent QA pairs from Contexts with\n  Information-Maximizing Hierarchical Conditional VAEs", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the most crucial challenges in question answering (QA) is the scarcity\nof labeled data, since it is costly to obtain question-answer (QA) pairs for a\ntarget text domain with human annotation. An alternative approach to tackle the\nproblem is to use automatically generated QA pairs from either the problem\ncontext or from large amount of unstructured texts (e.g. Wikipedia). In this\nwork, we propose a hierarchical conditional variational autoencoder (HCVAE) for\ngenerating QA pairs given unstructured texts as contexts, while maximizing the\nmutual information between generated QA pairs to ensure their consistency. We\nvalidate our Information Maximizing Hierarchical Conditional Variational\nAutoEncoder (Info-HCVAE) on several benchmark datasets by evaluating the\nperformance of the QA model (BERT-base) using only the generated QA pairs\n(QA-based evaluation) or by using both the generated and human-labeled pairs\n(semi-supervised learning) for training, against state-of-the-art baseline\nmodels. The results show that our model obtains impressive performance gains\nover all baselines on both tasks, using only a fraction of data for training.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 08:26:06 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 01:02:24 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 07:58:35 GMT"}, {"version": "v4", "created": "Fri, 12 Jun 2020 06:58:33 GMT"}, {"version": "v5", "created": "Mon, 15 Jun 2020 02:55:11 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Lee", "Dong Bok", ""], ["Lee", "Seanie", ""], ["Jeong", "Woo Tae", ""], ["Kim", "Donghwan", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "2005.13857", "submitter": "Hartmut Surmann HaSu", "authors": "Hartmut Surmann, Christian Jestel, Robin Marchel, Franziska Musberg,\n  Houssem Elhadj and Mahbube Ardani", "title": "Deep Reinforcement learning for real autonomous mobile robot navigation\n  in indoor environments", "comments": "7 pages, report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep Reinforcement Learning has been successfully applied in various computer\ngames [8]. However, it is still rarely used in real-world applications,\nespecially for the navigation and continuous control of real mobile robots\n[13]. Previous approaches lack safety and robustness and/or need a structured\nenvironment. In this paper we present our proof of concept for autonomous\nself-learning robot navigation in an unknown environment for a real robot\nwithout a map or planner. The input for the robot is only the fused data from a\n2D laser scanner and a RGB-D camera as well as the orientation to the goal. The\nmap of the environment is unknown. The output actions of an Asynchronous\nAdvantage Actor-Critic network (GA3C) are the linear and angular velocities for\nthe robot. The navigator/controller network is pretrained in a high-speed,\nparallel, and self-implemented simulation environment to speed up the learning\nprocess and then deployed to the real robot. To avoid overfitting, we train\nrelatively small networks, and we add random Gaussian noise to the input laser\ndata. The sensor data fusion with the RGB-D camera allows the robot to navigate\nin real environments with real 3D obstacle avoidance and without the need to\nfit the environment to the sensory capabilities of the robot. To further\nincrease the robustness, we train on environments of varying difficulties and\nrun 32 training instances simultaneously. Video: supplementary File / YouTube,\nCode: GitHub\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 09:15:14 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Surmann", "Hartmut", ""], ["Jestel", "Christian", ""], ["Marchel", "Robin", ""], ["Musberg", "Franziska", ""], ["Elhadj", "Houssem", ""], ["Ardani", "Mahbube", ""]]}, {"id": "2005.13867", "submitter": "Mao Ye", "authors": "Chenpeng Zhang (1), Shuai Li (2), Mao Ye (1), Ce Zhu (2), Xue Li (3)\n  ((1) School of Computer Science and Engineering, University of Electronic\n  Science and Technology of China, (2) School of Information and Communication\n  Engineering, University of Electronic Science and Technology of China, (3)\n  School of Information Technology and Electronic Engineering, The University\n  of Queensland)", "title": "Learning Various Length Dependence by Dual Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are widely used as a memory model for\nsequence-related problems. Many variants of RNN have been proposed to solve the\ngradient problems of training RNNs and process long sequences. Although some\nclassical models have been proposed, capturing long-term dependence while\nresponding to short-term changes remains a challenge. To this problem, we\npropose a new model named Dual Recurrent Neural Networks (DuRNN). The DuRNN\nconsists of two parts to learn the short-term dependence and progressively\nlearn the long-term dependence. The first part is a recurrent neural network\nwith constrained full recurrent connections to deal with short-term dependence\nin sequence and generate short-term memory. Another part is a recurrent neural\nnetwork with independent recurrent connections which helps to learn long-term\ndependence and generate long-term memory. A selection mechanism is added\nbetween two parts to help the needed long-term information transfer to the\nindependent neurons. Multiple modules can be stacked to form a multi-layer\nmodel for better performance. Our contributions are: 1) a new recurrent model\ndeveloped based on the divide-and-conquer strategy to learn long and short-term\ndependence separately, and 2) a selection mechanism to enhance the separating\nand learning of different temporal scales of dependence. Both theoretical\nanalysis and extensive experiments are conducted to validate the performance of\nour model, and we also conduct simple visualization experiments and ablation\nanalyses for the model interpretability. Experimental results indicate that the\nproposed DuRNN model can handle not only very long sequences (over 5000 time\nsteps), but also short sequences very well. Compared with many state-of-the-art\nRNN models, our model has demonstrated efficient and better performance.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 09:30:01 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Zhang", "Chenpeng", ""], ["Li", "Shuai", ""], ["Ye", "Mao", ""], ["Zhu", "Ce", ""], ["Li", "Xue", ""]]}, {"id": "2005.13885", "submitter": "Gian Maria Marconi", "authors": "Gian Maria Marconi, Lorenzo Rosasco and Carlo Ciliberto", "title": "Hyperbolic Manifold Regression", "comments": "13 pages, 3 figures To be published in 23rd International Conference\n  on Artificial Intelligence and Statistics Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric representation learning has recently shown great promise in several\nmachine learning settings, ranging from relational learning to language\nprocessing and generative models. In this work, we consider the problem of\nperforming manifold-valued regression onto an hyperbolic space as an\nintermediate component for a number of relevant machine learning applications.\nIn particular, by formulating the problem of predicting nodes of a tree as a\nmanifold regression task in the hyperbolic space, we propose a novel\nperspective on two challenging tasks: 1) hierarchical classification via label\nembeddings and 2) taxonomy extension of hyperbolic representations. To address\nthe regression problem we consider previous methods as well as proposing two\nnovel approaches that are computationally more advantageous: a parametric deep\nlearning model that is informed by the geodesics of the target space and a\nnon-parametric kernel-method for which we also prove excess risk bounds. Our\nexperiments show that the strategy of leveraging the hyperbolic geometry is\npromising. In particular, in the taxonomy expansion setting, we find that the\nhyperbolic-based estimators significantly outperform methods performing\nregression in the ambient Euclidean space.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 10:16:30 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Marconi", "Gian Maria", ""], ["Rosasco", "Lorenzo", ""], ["Ciliberto", "Carlo", ""]]}, {"id": "2005.13899", "submitter": "Alexandr A. Kalinin", "authors": "Tatiana Gabruseva, Dmytro Poplavskiy, Alexandr A. Kalinin", "title": "Deep Learning for Automatic Pneumonia Detection", "comments": "to appear in CVPR 2020 Workshops proceedings", "journal-ref": "2020 IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition Workshops (CVPRW), Seattle, WA, USA, 2020, pp. 1436-1443", "doi": "10.1109/CVPRW50498.2020.00183", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pneumonia is the leading cause of death among young children and one of the\ntop mortality causes worldwide. The pneumonia detection is usually performed\nthrough examine of chest X-ray radiograph by highly-trained specialists. This\nprocess is tedious and often leads to a disagreement between radiologists.\nComputer-aided diagnosis systems showed the potential for improving diagnostic\naccuracy. In this work, we develop the computational approach for pneumonia\nregions detection based on single-shot detectors, squeeze-and-excitation deep\nconvolution neural networks, augmentations and multi-task learning. The\nproposed approach was evaluated in the context of the Radiological Society of\nNorth America Pneumonia Detection Challenge, achieving one of the best results\nin the challenge.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 10:54:34 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Gabruseva", "Tatiana", ""], ["Poplavskiy", "Dmytro", ""], ["Kalinin", "Alexandr A.", ""]]}, {"id": "2005.13904", "submitter": "Sebastian H\\\"onel", "authors": "Sebastian H\\\"onel, Morgan Ericsson, Welf L\\\"owe, Anna Wingkvist", "title": "Using Source Code Density to Improve the Accuracy of Automatic Commit\n  Classification into Maintenance Activities", "comments": "23 pages, to be published in The Journal of Systems and Software", "journal-ref": null, "doi": "10.1016/j.jss.2020.110673", "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Source code is changed for a reason, e.g., to adapt, correct, or adapt it.\nThis reason can provide valuable insight into the development process but is\nrarely explicitly documented when the change is committed to a source code\nrepository. Automatic commit classification uses features extracted from\ncommits to estimate this reason.\n  We introduce source code density, a measure of the net size of a commit, and\nshow how it improves the accuracy of automatic commit classification compared\nto previous size-based classifications. We also investigate how preceding\ngenerations of commits affect the class of a commit, and whether taking the\ncode density of previous commits into account can improve the accuracy further.\n  We achieve up to 89% accuracy and a Kappa of 0.82 for the cross-project\ncommit classification where the model is trained on one project and applied to\nother projects. Models trained on single projects yield accuracies of up to 93%\nwith a Kappa approaching 0.90. The accuracy of the automatic commit\nclassification has a direct impact on software (process) quality analyses that\nexploit the classification, so our improvements to the accuracy will also\nimprove the confidence in such analyses.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 11:05:39 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["H\u00f6nel", "Sebastian", ""], ["Ericsson", "Morgan", ""], ["L\u00f6we", "Welf", ""], ["Wingkvist", "Anna", ""]]}, {"id": "2005.13912", "submitter": "Rem-Sophia Mouradi", "authors": "Rem-Sophia Mouradi, C\\'edric Goeury, Olivier Thual, Fabrice Zaoui and\n  Pablo Tassi", "title": "Physically interpretable machine learning algorithm on multidimensional\n  non-linear fields", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2020.110074", "report-no": null, "categories": "physics.comp-ph cs.LG physics.data-an stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an ever-increasing interest for Machine Learning (ML) and a favorable data\ndevelopment context, we here propose an original methodology for data-based\nprediction of two-dimensional physical fields. Polynomial Chaos Expansion\n(PCE), widely used in the Uncertainty Quantification community (UQ), has long\nbeen employed as a robust representation for probabilistic input-to-output\nmapping. It has been recently tested in a pure ML context, and shown to be as\npowerful as classical ML techniques for point-wise prediction. Some advantages\nare inherent to the method, such as its explicitness and adaptability to small\ntraining sets, in addition to the associated probabilistic framework.\nSimultaneously, Dimensionality Reduction (DR) techniques are increasingly used\nfor pattern recognition and data compression and have gained interest due to\nimproved data quality. In this study, the interest of Proper Orthogonal\nDecomposition (POD) for the construction of a statistical predictive model is\ndemonstrated. Both POD and PCE have amply proved their worth in their\nrespective frameworks. The goal of the present paper was to combine them for a\nfield-measurement-based forecasting. The described steps are also useful to\nanalyze the data. Some challenging issues encountered when using\nmultidimensional field measurements are addressed, for example when dealing\nwith few data. The POD-PCE coupling methodology is presented, with particular\nfocus on input data characteristics and training-set choice. A simple\nmethodology for evaluating the importance of each physical parameter is\nproposed for the PCE model and extended to the POD-PCE coupling.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 11:26:06 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 19:54:49 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Mouradi", "Rem-Sophia", ""], ["Goeury", "C\u00e9dric", ""], ["Thual", "Olivier", ""], ["Zaoui", "Fabrice", ""], ["Tassi", "Pablo", ""]]}, {"id": "2005.13928", "submitter": "Carles Sanchez Ramos", "authors": "D. Gil, K. D\\'iaz-Chito, C. S\\'anchez, A. Hern\\'andez-Sabat\\'e", "title": "Early Screening of SARS-CoV-2 by Intelligent Analysis of X-Ray Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future SARS-CoV-2 virus outbreak COVID-XX might possibly occur during the\nnext years. However the pathology in humans is so recent that many clinical\naspects, like early detection of complications, side effects after recovery or\nearly screening, are currently unknown. In spite of the number of cases of\nCOVID-19, its rapid spread putting many sanitary systems in the edge of\ncollapse has hindered proper collection and analysis of the data related to\nCOVID-19 clinical aspects. We describe an interdisciplinary initiative that\nintegrates clinical research, with image diagnostics and the use of new\ntechnologies such as artificial intelligence and radiomics with the aim of\nclarifying some of SARS-CoV-2 open questions. The whole initiative addresses 3\nmain points: 1) collection of standardize data including images, clinical data\nand analytics; 2) COVID-19 screening for its early diagnosis at primary care\ncenters; 3) define radiomic signatures of COVID-19 evolution and associated\npathologies for the early treatment of complications. In particular, in this\npaper we present a general overview of the project, the experimental design and\nfirst results of X-ray COVID-19 detection using a classic approach based on HoG\nand feature selection. Our experiments include a comparison to some recent\nmethods for COVID-19 screening in X-Ray and an exploratory analysis of the\nfeasibility of X-Ray COVID-19 screening. Results show that classic approaches\ncan outperform deep-learning methods in this experimental setting, indicate the\nfeasibility of early COVID-19 screening and that non-COVID infiltration is the\ngroup of patients most similar to COVID-19 in terms of radiological description\nof X-ray. Therefore, an efficient COVID-19 screening should be complemented\nwith other clinical data to better discriminate these cases.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 11:46:31 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Gil", "D.", ""], ["D\u00edaz-Chito", "K.", ""], ["S\u00e1nchez", "C.", ""], ["Hern\u00e1ndez-Sabat\u00e9", "A.", ""]]}, {"id": "2005.13930", "submitter": "Benedikt Boenninghoff", "authors": "Benedikt Boenninghoff, Steffen Zeiler, Robert M. Nickel, Dorothea\n  Kolossa", "title": "Variational Autoencoder with Embedded Student-$t$ Mixture Model for\n  Authorship Attribution", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional computational authorship attribution describes a classification\ntask in a closed-set scenario. Given a finite set of candidate authors and\ncorresponding labeled texts, the objective is to determine which of the authors\nhas written another set of anonymous or disputed texts. In this work, we\npropose a probabilistic autoencoding framework to deal with this supervised\nclassification task. More precisely, we are extending a variational autoencoder\n(VAE) with embedded Gaussian mixture model to a Student-$t$ mixture model.\nAutoencoders have had tremendous success in learning latent representations.\nHowever, existing VAEs are currently still bound by limitations imposed by the\nassumed Gaussianity of the underlying probability distributions in the latent\nspace. In this work, we are extending the Gaussian model for the VAE to a\nStudent-$t$ model, which allows for an independent control of the \"heaviness\"\nof the respective tails of the implied probability densities. Experiments over\nan Amazon review dataset indicate superior performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 11:52:32 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Boenninghoff", "Benedikt", ""], ["Zeiler", "Steffen", ""], ["Nickel", "Robert M.", ""], ["Kolossa", "Dorothea", ""]]}, {"id": "2005.13934", "submitter": "Ronny Hug", "authors": "Ronny Hug, Stefan Becker, Wolfgang H\\\"ubner, Michael Arens", "title": "Quantifying the Complexity of Standard Benchmarking Datasets for\n  Long-Term Human Trajectory Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods to quantify the complexity of trajectory datasets are still a missing\npiece in benchmarking human trajectory prediction models. In order to gain a\nbetter understanding of the complexity of trajectory prediction tasks and\nfollowing the intuition, that more complex datasets contain more information,\nan approach for quantifying the amount of information contained in a dataset\nfrom a prototype-based dataset representation is proposed. The dataset\nrepresentation is obtained by first employing a non-trivial spatial sequence\nalignment, which enables a subsequent learning vector quantization (LVQ) stage.\nA large-scale complexity analysis is conducted on several human trajectory\nprediction benchmarking datasets, followed by a brief discussion on indications\nfor human trajectory prediction and benchmarking.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 12:00:41 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 12:20:58 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 12:47:53 GMT"}, {"version": "v4", "created": "Thu, 20 May 2021 08:17:40 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Hug", "Ronny", ""], ["Becker", "Stefan", ""], ["H\u00fcbner", "Wolfgang", ""], ["Arens", "Michael", ""]]}, {"id": "2005.13948", "submitter": "Patrick Kidger", "authors": "Patrick Kidger, James Morrill, Terry Lyons", "title": "Generalised Interpretable Shapelets for Irregular Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The shapelet transform is a form of feature extraction for time series, in\nwhich a time series is described by its similarity to each of a collection of\n`shapelets'. However it has previously suffered from a number of limitations,\nsuch as being limited to regularly-spaced fully-observed time series, and\nhaving to choose between efficient training and interpretability. Here, we\nextend the method to continuous time, and in doing so handle the general case\nof irregularly-sampled partially-observed multivariate time series.\nFurthermore, we show that a simple regularisation penalty may be used to train\nefficiently without sacrificing interpretability. The continuous-time\nformulation additionally allows for learning the length of each shapelet\n(previously a discrete object) in a differentiable manner. Finally, we\ndemonstrate that the measure of similarity between time series may be\ngeneralised to a learnt pseudometric. We validate our method by demonstrating\nits performance and interpretability on several datasets; for example we\ndiscover (purely from data) that the digits 5 and 6 may be distinguished by the\nchirality of their bottom loop, and that a kind of spectral gap exists in\nspoken audio classification.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 12:32:19 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 11:08:16 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Kidger", "Patrick", ""], ["Morrill", "James", ""], ["Lyons", "Terry", ""]]}, {"id": "2005.13953", "submitter": "Andriy Serdega", "authors": "Andriy Serdega, Dae-Shik Kim", "title": "VMI-VAE: Variational Mutual Information Maximization Framework for VAE\n  With Discrete and Continuous Priors", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.14254.95042", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoder is a scalable method for learning latent variable\nmodels of complex data. It employs a clear objective that can be easily\noptimized. However, it does not explicitly measure the quality of learned\nrepresentations. We propose a Variational Mutual Information Maximization\nFramework for VAE to address this issue. It provides an objective that\nmaximizes the mutual information between latent codes and observations. The\nobjective acts as a regularizer that forces VAE to not ignore the latent code\nand allows one to select particular components of it to be most informative\nwith respect to the observations. On top of that, the proposed framework\nprovides a way to evaluate mutual information between latent codes and\nobservations for a fixed VAE model.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 12:44:23 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Serdega", "Andriy", ""], ["Kim", "Dae-Shik", ""]]}, {"id": "2005.13971", "submitter": "Christian Oliva", "authors": "Christian Oliva and Luis F. Lago-Fern\\'andez", "title": "Separation of Memory and Processing in Dual Recurrent Neural Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.FL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a neural network architecture that stacks a recurrent layer and a\nfeedforward layer that is also connected to the input, and compare it to\nstandard Elman and LSTM architectures in terms of accuracy and\ninterpretability. When noise is introduced into the activation function of the\nrecurrent units, these neurons are forced into a binary activation regime that\nmakes the networks behave much as finite automata. The resulting models are\nsimpler, easier to interpret and get higher accuracy on different sample\nproblems, including the recognition of regular languages, the computation of\nadditions in different bases and the generation of arithmetic expressions.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 11:38:42 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Oliva", "Christian", ""], ["Lago-Fern\u00e1ndez", "Luis F.", ""]]}, {"id": "2005.13976", "submitter": "Madhur Behl", "authors": "Hyun Jae Cho, and Madhur Behl", "title": "Towards Automated Safety Coverage and Testing for Autonomous Vehicles\n  with Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The kind of closed-loop verification likely to be required for autonomous\nvehicle (AV) safety testing is beyond the reach of traditional test\nmethodologies and discrete verification. Validation puts the autonomous vehicle\nsystem to the test in scenarios or situations that the system would likely\nencounter in everyday driving after its release. These scenarios can either be\ncontrolled directly in a physical (closed-course proving ground) or virtual\n(simulation of predefined scenarios) environment, or they can arise\nspontaneously during operation in the real world (open-road testing or\nsimulation of randomly generated scenarios).\n  In AV testing, simulation serves primarily two purposes: to assist the\ndevelopment of a robust autonomous vehicle and to test and validate the AV\nbefore release. A challenge arises from the sheer number of scenario variations\nthat can be constructed from each of the above sources due to the high number\nof variables involved (most of which are continuous). Even with continuous\nvariables discretized, the possible number of combinations becomes practically\ninfeasible to test. To overcome this challenge we propose using reinforcement\nlearning (RL) to generate failure examples and unexpected traffic situations\nfor the AV software implementation. Although reinforcement learning algorithms\nhave achieved notable results in games and some robotic manipulations, this\ntechnique has not been widely scaled up to the more challenging real world\napplications like autonomous driving.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 19:00:38 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Cho", "Hyun Jae", ""], ["Behl", "Madhur", ""]]}, {"id": "2005.13977", "submitter": "Tiago Peixoto", "authors": "Tiago P. Peixoto", "title": "Revealing consensus and dissensus between network partitions", "comments": "28 pages, 16 figures", "journal-ref": "Phys. Rev. X 11, 021003 (2021)", "doi": "10.1103/PhysRevX.11.021003", "report-no": null, "categories": "physics.soc-ph cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Community detection methods attempt to divide a network into groups of nodes\nthat share similar properties, thus revealing its large-scale structure. A\nmajor challenge when employing such methods is that they are often degenerate,\ntypically yielding a complex landscape of competing answers. As an attempt to\nextract understanding from a population of alternative solutions, many methods\nexist to establish a consensus among them in the form of a single partition\n\"point estimate\" that summarizes the whole distribution. Here we show that it\nis in general not possible to obtain a consistent answer from such point\nestimates when the underlying distribution is too heterogeneous. As an\nalternative, we provide a comprehensive set of methods designed to characterize\nand summarize complex populations of partitions in a manner that captures not\nonly the existing consensus, but also the dissensus between elements of the\npopulation. Our approach is able to model mixed populations of partitions where\nmultiple consensuses can coexist, representing different competing hypotheses\nfor the network structure. We also show how our methods can be used to compare\npairs of partitions, how they can be generalized to hierarchical divisions, and\nbe used to perform statistical model selection between competing hypotheses.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 13:29:42 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 13:36:41 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 16:12:35 GMT"}, {"version": "v4", "created": "Fri, 8 Jan 2021 13:13:23 GMT"}, {"version": "v5", "created": "Wed, 21 Apr 2021 22:26:28 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Peixoto", "Tiago P.", ""]]}, {"id": "2005.13981", "submitter": "Chandan Karadagur Ananda Reddy", "authors": "Chandan K. A. Reddy, Vishak Gopal, Ross Cutler, Ebrahim Beyrami, Roger\n  Cheng, Harishchandra Dubey, Sergiy Matusevych, Robert Aichner, Ashkan Aazami,\n  Sebastian Braun, Puneet Rana, Sriram Srinivasan, Johannes Gehrke", "title": "The INTERSPEECH 2020 Deep Noise Suppression Challenge: Datasets,\n  Subjective Testing Framework, and Challenge Results", "comments": "Interspeech 2020. arXiv admin note: substantial text overlap with\n  arXiv:2001.08662", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The INTERSPEECH 2020 Deep Noise Suppression (DNS) Challenge is intended to\npromote collaborative research in real-time single-channel Speech Enhancement\naimed to maximize the subjective (perceptual) quality of the enhanced speech. A\ntypical approach to evaluate the noise suppression methods is to use objective\nmetrics on the test set obtained by splitting the original dataset. While the\nperformance is good on the synthetic test set, often the model performance\ndegrades significantly on real recordings. Also, most of the conventional\nobjective metrics do not correlate well with subjective tests and lab\nsubjective tests are not scalable for a large test set. In this challenge, we\nopen-sourced a large clean speech and noise corpus for training the noise\nsuppression models and a representative test set to real-world scenarios\nconsisting of both synthetic and real recordings. We also open-sourced an\nonline subjective test framework based on ITU-T P.808 for researchers to\nreliably test their developments. We evaluated the results using P.808 on a\nblind test set. The results and the key learnings from the challenge are\ndiscussed. The datasets and scripts can be found here for quick access\nhttps://github.com/microsoft/DNS-Challenge.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 23:48:37 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 18:04:15 GMT"}, {"version": "v3", "created": "Sun, 18 Oct 2020 04:36:21 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Reddy", "Chandan K. A.", ""], ["Gopal", "Vishak", ""], ["Cutler", "Ross", ""], ["Beyrami", "Ebrahim", ""], ["Cheng", "Roger", ""], ["Dubey", "Harishchandra", ""], ["Matusevych", "Sergiy", ""], ["Aichner", "Robert", ""], ["Aazami", "Ashkan", ""], ["Braun", "Sebastian", ""], ["Rana", "Puneet", ""], ["Srinivasan", "Sriram", ""], ["Gehrke", "Johannes", ""]]}, {"id": "2005.13983", "submitter": "Weixia Zhang", "authors": "Weixia Zhang and Kede Ma and Guangtao Zhai and Xiaokang Yang", "title": "Uncertainty-Aware Blind Image Quality Assessment in the Laboratory and\n  Wild", "comments": "Accepted to IEEE TIP. The implementations are available at\n  https://github.com/zwx8981/UNIQUE", "journal-ref": null, "doi": "10.1109/TIP.2021.3061932", "report-no": null, "categories": "cs.CV cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance of blind image quality assessment (BIQA) models has been\nsignificantly boosted by end-to-end optimization of feature engineering and\nquality regression. Nevertheless, due to the distributional shift between\nimages simulated in the laboratory and captured in the wild, models trained on\ndatabases with synthetic distortions remain particularly weak at handling\nrealistic distortions (and vice versa). To confront the\ncross-distortion-scenario challenge, we develop a \\textit{unified} BIQA model\nand an approach of training it for both synthetic and realistic distortions. We\nfirst sample pairs of images from individual IQA databases, and compute a\nprobability that the first image of each pair is of higher quality. We then\nemploy the fidelity loss to optimize a deep neural network for BIQA over a\nlarge number of such image pairs. We also explicitly enforce a hinge constraint\nto regularize uncertainty estimation during optimization. Extensive experiments\non six IQA databases show the promise of the learned method in blindly\nassessing image quality in the laboratory and wild. In addition, we demonstrate\nthe universality of the proposed training strategy by using it to improve\nexisting BIQA models.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 13:35:23 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 05:12:39 GMT"}, {"version": "v3", "created": "Wed, 10 Jun 2020 09:32:54 GMT"}, {"version": "v4", "created": "Tue, 7 Jul 2020 08:27:23 GMT"}, {"version": "v5", "created": "Mon, 22 Feb 2021 15:46:10 GMT"}, {"version": "v6", "created": "Tue, 23 Feb 2021 09:45:41 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Zhang", "Weixia", ""], ["Ma", "Kede", ""], ["Zhai", "Guangtao", ""], ["Yang", "Xiaokang", ""]]}, {"id": "2005.13985", "submitter": "Nikhel Gupta", "authors": "N. Gupta and C. L. Reichardt", "title": "Mass Estimation of Galaxy Clusters with Deep Learning II: CMB Cluster\n  Lensing", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.CO cs.LG gr-qc", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new application of deep learning to reconstruct the cosmic\nmicrowave background (CMB) temperature maps from the images of microwave sky,\nand to use these reconstructed maps to estimate the masses of galaxy clusters.\nWe use a feed-forward deep learning network, mResUNet, for both steps of the\nanalysis. The first deep learning model, mResUNet-I, is trained to reconstruct\nforeground and noise suppressed CMB maps from a set of simulated images of the\nmicrowave sky that include signals from the cosmic microwave background,\nastrophysical foregrounds like dusty and radio galaxies, instrumental noise as\nwell as the cluster's own thermal Sunyaev Zel'dovich signal. The second deep\nlearning model, mResUNet-II, is trained to estimate cluster masses from the\ngravitational lensing signature in the reconstructed foreground and noise\nsuppressed CMB maps. For SPTpol-like noise levels, the trained mResUNet-II\nmodel recovers the mass of a single galaxy cluster with a 1-$\\sigma$\nuncertainty $\\Delta M_{\\rm 200c}^{\\rm est}/M_{\\rm 200c}^{\\rm est} =$ 1.37 and\n0.51 for input cluster mass $M_{\\rm 200c}^{\\rm true}=10^{14}~\\rm M_{\\odot}$ and\n$8\\times 10^{14}~\\rm M_{\\odot}$, respectively. For input cluster mass $M_{\\rm\n200c}^{\\rm true}=3\\times 10^{14}~\\rm M_{\\odot}$, these uncertainties are a\nfactor of $1.4$ larger than would be achieved by a maximum likelihood estimator\n(MLE) on foreground-free maps with the input noise levels, but better by a\nfactor of $1.5$ than the MLE with foregrounds.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 13:39:49 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Gupta", "N.", ""], ["Reichardt", "C. L.", ""]]}, {"id": "2005.13992", "submitter": "Anahita Sanandaji", "authors": "Anahita Sanandaji, Saeed Ghanbartehrani, Zahra Mokhtari, Kimia Tajik", "title": "A Novel Ramp Metering Approach Based on Machine Learning and Historical\n  Data", "comments": "5 pages, 11 figures, 2 tables", "journal-ref": null, "doi": "10.3390/make2040021", "report-no": null, "categories": "eess.SY cs.LG cs.SY eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The random nature of traffic conditions on freeways can cause excessive\ncongestions and irregularities in the traffic flow. Ramp metering is a proven\neffective method to maintain freeway efficiency under various traffic\nconditions. Creating a reliable and practical ramp metering algorithm that\nconsiders both critical traffic measures and historical data is still a\nchallenging problem. In this study we use machine learning approaches to\ndevelop a novel real-time prediction model for ramp metering. We evaluate the\npotentials of our approach in providing promising results by comparing it with\na baseline traffic-responsive ramp metering algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 21:05:01 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Sanandaji", "Anahita", ""], ["Ghanbartehrani", "Saeed", ""], ["Mokhtari", "Zahra", ""], ["Tajik", "Kimia", ""]]}, {"id": "2005.13996", "submitter": "Yun Kuen Cheung", "authors": "Yun Kuen Cheung and Georgios Piliouras", "title": "Chaos, Extremism and Optimism: Volume Analysis of Learning in Games", "comments": "20 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present volume analyses of Multiplicative Weights Updates (MWU) and\nOptimistic Multiplicative Weights Updates (OMWU) in zero-sum as well as\ncoordination games. Such analyses provide new insights into these game\ndynamical systems, which seem hard to achieve via the classical techniques\nwithin Computer Science and Machine Learning.\n  The first step is to examine these dynamics not in their original space\n(simplex of actions) but in a dual space (aggregate payoff space of actions).\nThe second step is to explore how the volume of a set of initial conditions\nevolves over time when it is pushed forward according to the algorithm. This is\nreminiscent of approaches in Evolutionary Game Theory where replicator\ndynamics, the continuous-time analogue of MWU, is known to always preserve\nvolume in all games. Interestingly, when we examine discrete-time dynamics,\nboth the choice of the game and the choice of the algorithm play a critical\nrole. So whereas MWU expands volume in zero-sum games and is thus Lyapunov\nchaotic, we show that OMWU contracts volume, providing an alternative\nunderstanding for its known convergent behavior. However, we also prove a\nno-free-lunch type of theorem, in the sense that when examining coordination\ngames the roles are reversed: OMWU expands volume exponentially fast, whereas\nMWU contracts.\n  Using these tools, we prove two novel, rather negative properties of MWU in\nzero-sum games: (1) Extremism: even in games with unique fully mixed Nash\nequilibrium, the system recurrently gets stuck near pure-strategy profiles,\ndespite them being clearly unstable from game theoretic perspective. (2)\nUnavoidability: given any set of good points (with your own interpretation of\n\"good\"), the system cannot avoid bad points indefinitely.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 13:47:09 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Cheung", "Yun Kuen", ""], ["Piliouras", "Georgios", ""]]}, {"id": "2005.14001", "submitter": "Zhijian Ou", "authors": "Zhijian Ou, Yunfu Song", "title": "Joint Stochastic Approximation and Its Application to Learning Discrete\n  Latent Variable Models", "comments": "Accepted by UAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although with progress in introducing auxiliary amortized inference models,\nlearning discrete latent variable models is still challenging. In this paper,\nwe show that the annoying difficulty of obtaining reliable stochastic gradients\nfor the inference model and the drawback of indirectly optimizing the target\nlog-likelihood can be gracefully addressed in a new method based on stochastic\napproximation (SA) theory of the Robbins-Monro type. Specifically, we propose\nto directly maximize the target log-likelihood and simultaneously minimize the\ninclusive divergence between the posterior and the inference model. The\nresulting learning algorithm is called joint SA (JSA). To the best of our\nknowledge, JSA represents the first method that couples an SA version of the EM\n(expectation-maximization) algorithm (SAEM) with an adaptive MCMC procedure.\nExperiments on several benchmark generative modeling and structured prediction\ntasks show that JSA consistently outperforms recent competitive algorithms,\nwith faster convergence, better final likelihoods, and lower variance of\ngradient estimates.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 13:50:08 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Ou", "Zhijian", ""], ["Song", "Yunfu", ""]]}, {"id": "2005.14007", "submitter": "Ambedkar Dukkipati", "authors": "Sourabh Balgi and Ambedkar Dukkipati", "title": "Contradistinguisher: A Vapnik's Imperative to Unsupervised Domain\n  Adaptation", "comments": "18 pages. arXiv admin note: text overlap with arXiv:1909.03442", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A complex combination of simultaneous supervised-unsupervised learning is\nbelieved to be the key to humans performing tasks seamlessly across multiple\ndomains or tasks. This phenomenon of cross-domain learning has been very well\nstudied in domain adaptation literature. Recent domain adaptation works rely on\nan indirect way of first aligning the source and target domain distributions\nand then train a classifier on the labeled source domain to classify the target\ndomain. However, this approach has the main drawback that obtaining a\nnear-perfect alignment of the domains in itself might be difficult/impossible\n(e.g., language domains). To address this, we follow Vapnik's imperative of\nstatistical learning that states any desired problem should be solved in the\nmost direct way rather than solving a more general intermediate task and\npropose a direct approach to domain adaptation that does not require domain\nalignment. We propose a model referred Contradistinguisher that learns\ncontrastive features and whose objective is to jointly learn to\ncontradistinguish the unlabeled target domain in an unsupervised way and\nclassify in a supervised way on the source domain. We achieve the\nstate-of-the-art on Office-31 and VisDA-2017 datasets in both single-source and\nmulti-source settings. We also notice that the contradistinguish loss improves\nthe model performance by increasing the shape bias.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 19:54:38 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 06:36:05 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 11:55:34 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Balgi", "Sourabh", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "2005.14015", "submitter": "Purushottam Kar", "authors": "Darshak Chhatbar and Umair Z. Ahmed and Purushottam Kar", "title": "MACER: A Modular Framework for Accelerated Compilation Error Repair", "comments": "19 pages, 9 figures. A short version of this paper will appear at the\n  21st International Conference on Artificial Intelligence in Education (AIED).\n  Code for the MACER tool-chain is available at\n  https://github.com/purushottamkar/macer/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated compilation error repair, the problem of suggesting fixes to buggy\nprograms that fail to compile, has generated significant interest in recent\nyears. Apart from being a tool of general convenience, automated code repair\nhas significant pedagogical applications for novice programmers who find\ncompiler error messages cryptic and unhelpful. Existing approaches largely\nsolve this problem using a blackbox-application of a heavy-duty generative\nlearning technique, such as sequence-to-sequence prediction (TRACER) or\nreinforcement learning (RLAssist). Although convenient, such black-box\napplication of learning techniques makes existing approaches bulky in terms of\ntraining time, as well as inefficient at targeting specific error types.\n  We present MACER, a novel technique for accelerated error repair based on a\nmodular segregation of the repair process into repair identification and repair\napplication. MACER uses powerful yet inexpensive discriminative learning\ntechniques such as multi-label classifiers and rankers to first identify the\ntype of repair required and then apply the suggested repair.\n  Experiments indicate that the fine-grained approach adopted by MACER offers\nnot only superior error correction, but also much faster training and\nprediction. On a benchmark dataset of 4K buggy programs collected from actual\nstudent submissions, MACER outperforms existing methods by 20% at suggesting\nfixes for popular errors that exactly match the fix desired by the student.\nMACER is also competitive or better than existing methods at all error types --\nwhether popular or rare. MACER offers a training time speedup of 2x over TRACER\nand 800x over RLAssist, and a test time speedup of 2-4x over both.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 14:00:03 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Chhatbar", "Darshak", ""], ["Ahmed", "Umair Z.", ""], ["Kar", "Purushottam", ""]]}, {"id": "2005.14025", "submitter": "Jian Ma", "authors": "Jian Ma", "title": "copent: Estimating Copula Entropy and Transfer Entropy in R", "comments": "18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.IT cs.LG cs.MS math.IT stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical independence and conditional independence are two fundamental\nconcepts in statistics and machine learning. Copula Entropy is a mathematical\nconcept defined by Ma and Sun for multivariate statistical independence\nmeasuring and testing, and also proved to be closely related to conditional\nindependence (or transfer entropy). As the unified framework for measuring both\nindependence and causality, CE has been applied to solve several related\nstatistical or machine learning problems, including association discovery,\nstructure learning, variable selection, and causal discovery. The nonparametric\nmethods for estimating copula entropy and transfer entropy were also proposed\npreviously. This paper introduces copent, the R package which implements these\nproposed methods for estimating copula entropy and transfer entropy. The\nimplementation detail of the package is introduced. Three examples with\nsimulated data and real-world data on variable selection and causal discovery\nare also presented to demonstrate the usage of this package. The examples on\nvariable selection and causal discovery show the strong ability of copent on\ntesting (conditional) independence compared with the related packages. The\ncopent package is available on the Comprehensive R Archive Network (CRAN) and\nalso on GitHub at https://github.com/majianthu/copent.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 10:01:12 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 00:14:25 GMT"}, {"version": "v3", "created": "Sat, 27 Mar 2021 00:41:58 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Ma", "Jian", ""]]}, {"id": "2005.14028", "submitter": "Santhosh Rajamanickam", "authors": "Santhosh Rajamanickam, Pushkar Mishra, Helen Yannakoudakis, Ekaterina\n  Shutova", "title": "Joint Modelling of Emotion and Abusive Language Detection", "comments": "Proceedings of the 58th Annual Meeting of the Association for\n  Computational Linguistics, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of online communication platforms has been accompanied by some\nundesirable effects, such as the proliferation of aggressive and abusive\nbehaviour online. Aiming to tackle this problem, the natural language\nprocessing (NLP) community has experimented with a range of techniques for\nabuse detection. While achieving substantial success, these methods have so far\nonly focused on modelling the linguistic properties of the comments and the\nonline communities of users, disregarding the emotional state of the users and\nhow this might affect their language. The latter is, however, inextricably\nlinked to abusive behaviour. In this paper, we present the first joint model of\nemotion and abusive language detection, experimenting in a multi-task learning\nframework that allows one task to inform the other. Our results demonstrate\nthat incorporating affective features leads to significant improvements in\nabuse detection performance across datasets.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 14:08:40 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Rajamanickam", "Santhosh", ""], ["Mishra", "Pushkar", ""], ["Yannakoudakis", "Helen", ""], ["Shutova", "Ekaterina", ""]]}, {"id": "2005.14036", "submitter": "Kalliopi Basioti", "authors": "Kalliopi Basioti, George V. Moustakides", "title": "Image Restoration from Parametric Transformations using Generative\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When images are statistically described by a generative model we can use this\ninformation to develop optimum techniques for various image restoration\nproblems as inpainting, super-resolution, image coloring, generative model\ninversion, etc. With the help of the generative model it is possible to\nformulate, in a natural way, these restoration problems as Statistical\nestimation problems. Our approach, by combining maximum a-posteriori\nprobability with maximum likelihood estimation, is capable of restoring images\nthat are distorted by transformations even when the latter contain unknown\nparameters. The resulting optimization is completely defined with no parameters\nrequiring tuning. This must be compared with the current state of the art which\nrequires exact knowledge of the transformations and contains regularizer terms\nwith weights that must be properly defined. Finally, we must mention that we\nextend our method to accommodate mixtures of multiple images where each image\nis described by its own generative model and we are able of successfully\nseparating each participating image from a single mixture.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 01:14:40 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 12:09:41 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Basioti", "Kalliopi", ""], ["Moustakides", "George V.", ""]]}, {"id": "2005.14062", "submitter": "Anthony Gitter", "authors": "David Merrell, Anthony Gitter", "title": "Inferring Signaling Pathways with Probabilistic Programming", "comments": "15 pages, 10 figures; added Appendices C and D", "journal-ref": "Bioinformatics 36:Supplement_2 (2020) i822-i830", "doi": "10.1093/bioinformatics/btaa861", "report-no": null, "categories": "q-bio.MN cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cells regulate themselves via dizzyingly complex biochemical processes called\nsignaling pathways. These are usually depicted as a network, where nodes\nrepresent proteins and edges indicate their influence on each other. In order\nto understand diseases and therapies at the cellular level, it is crucial to\nhave an accurate understanding of the signaling pathways at work. Since\nsignaling pathways can be modified by disease, the ability to infer signaling\npathways from condition- or patient-specific data is highly valuable. A variety\nof techniques exist for inferring signaling pathways. We build on past works\nthat formulate signaling pathway inference as a Dynamic Bayesian Network\nstructure estimation problem on phosphoproteomic time course data. We take a\nBayesian approach, using Markov Chain Monte Carlo to estimate a posterior\ndistribution over possible Dynamic Bayesian Network structures. Our primary\ncontributions are (i) a novel proposal distribution that efficiently samples\nsparse graphs and (ii) the relaxation of common restrictive modeling\nassumptions. We implement our method, named Sparse Signaling Pathway Sampling,\nin Julia using the Gen probabilistic programming language. Probabilistic\nprogramming is a powerful methodology for building statistical models. The\nresulting code is modular, extensible, and legible. The Gen language, in\nparticular, allows us to customize our inference procedure for biological\ngraphs and ensure efficient sampling. We evaluate our algorithm on simulated\ndata and the HPN-DREAM pathway reconstruction challenge, comparing our\nperformance against a variety of baseline methods. Our results demonstrate the\nvast potential for probabilistic programming, and Gen specifically, for\nbiological network inference. Find the full codebase at\nhttps://github.com/gitter-lab/ssps\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 14:55:11 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 22:15:36 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Merrell", "David", ""], ["Gitter", "Anthony", ""]]}, {"id": "2005.14064", "submitter": "Jinglin Zhang", "authors": "Jinglin Zhang, Wenjun Xu, Hui Gao, Miao Pan, Zhu Han, and Ping Zhang", "title": "Codebook-Based Beam Tracking for Conformal ArrayEnabled UAV MmWave\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millimeter wave (mmWave) communications can potentially meet the high\ndata-rate requirements of unmanned aerial vehicle (UAV) networks. However, as\nthe prerequisite of mmWave communications, the narrow directional beam tracking\nis very challenging because of the three-dimensional (3D) mobility and attitude\nvariation of UAVs. Aiming to address the beam tracking difficulties, we propose\nto integrate the conformal array (CA) with the surface of each UAV, which\nenables the full spatial coverage and the agile beam tracking in highly dynamic\nUAV mmWave networks. More specifically, the key contributions of our work are\nthree-fold. 1) A new mmWave beam tracking framework is established for the\nCA-enabled UAV mmWave network. 2) A specialized hierarchical codebook is\nconstructed to drive the directional radiating element (DRE)-covered\ncylindrical conformal array (CCA), which contains both the angular beam pattern\nand the subarray pattern to fully utilize the potential of the CA. 3) A\ncodebook-based multiuser beam tracking scheme is proposed, where the Gaussian\nprocess machine learning enabled UAV position/attitude predication is developed\nto improve the beam tracking efficiency in conjunction with the tracking-error\naware adaptive beamwidth control. Simulation results validate the effectiveness\nof the proposed codebook-based beam tracking scheme in the CA-enabled UAV\nmmWave network, and demonstrate the advantages of CA over the conventional\nplanner array in terms of spectrum efficiency and outage probability in the\nhighly dynamic scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 14:57:23 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Zhang", "Jinglin", ""], ["Xu", "Wenjun", ""], ["Gao", "Hui", ""], ["Pan", "Miao", ""], ["Han", "Zhu", ""], ["Zhang", "Ping", ""]]}, {"id": "2005.14070", "submitter": "Muhammad Shah", "authors": "Muhammad A. Shah, Raphael Olivier and Bhiksha Raj", "title": "Exploiting Non-Linear Redundancy for Neural Model Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deploying deep learning models, comprising of non-linear combination of\nmillions, even billions, of parameters is challenging given the memory, power\nand compute constraints of the real world. This situation has led to research\ninto model compression techniques most of which rely on suboptimal heuristics\nand do not consider the parameter redundancies due to linear dependence between\nneuron activations in overparametrized networks. In this paper, we propose a\nnovel model compression approach based on exploitation of linear dependence,\nthat compresses networks by elimination of entire neurons and redistribution of\ntheir activations over other neurons in a manner that is provably lossless\nwhile training. We combine this approach with an annealing algorithm that may\nbe applied during training, or even on a trained model, and demonstrate, using\npopular datasets, that our method results in a reduction of up to 99\\% in\noverall network size with small loss in performance. Furthermore, we provide\ntheoretical results showing that in overparametrized, locally linear (ReLU)\nneural networks where redundant features exist, and with correct hyperparameter\nselection, our method is indeed able to capture and suppress those\ndependencies.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 15:13:21 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Shah", "Muhammad A.", ""], ["Olivier", "Raphael", ""], ["Raj", "Bhiksha", ""]]}, {"id": "2005.14073", "submitter": "Banghua Zhu", "authors": "Banghua Zhu, Jiantao Jiao and Jacob Steinhardt", "title": "Robust estimation via generalized quasi-gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore why many recently proposed robust estimation problems are\nefficiently solvable, even though the underlying optimization problems are\nnon-convex. We study the loss landscape of these robust estimation problems,\nand identify the existence of \"generalized quasi-gradients\". Whenever these\nquasi-gradients exist, a large family of low-regret algorithms are guaranteed\nto approximate the global minimum; this includes the commonly-used filtering\nalgorithm.\n  For robust mean estimation of distributions under bounded covariance, we show\nthat any first-order stationary point of the associated optimization problem is\nan {approximate global minimum} if and only if the corruption level $\\epsilon <\n1/3$. Consequently, any optimization algorithm that aproaches a stationary\npoint yields an efficient robust estimator with breakdown point $1/3$. With\ncareful initialization and step size, we improve this to $1/2$, which is\noptimal.\n  For other tasks, including linear regression and joint mean and covariance\nestimation, the loss landscape is more rugged: there are stationary points\narbitrarily far from the global minimum. Nevertheless, we show that generalized\nquasi-gradients exist and construct efficient algorithms. These algorithms are\nsimpler than previous ones in the literature, and for linear regression we\nimprove the estimation error from $O(\\sqrt{\\epsilon})$ to the optimal rate of\n$O(\\epsilon)$ for small $\\epsilon$ assuming certified hypercontractivity. For\nmean estimation with near-identity covariance, we show that a simple gradient\ndescent algorithm achieves breakdown point $1/3$ and iteration complexity\n$\\tilde{O}(d/\\epsilon^2)$.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 15:14:33 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Zhu", "Banghua", ""], ["Jiao", "Jiantao", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "2005.14080", "submitter": "Paolo Torroni", "authors": "Daniela Loreti and Marco Lippi and Paolo Torroni", "title": "Parallelizing Machine Learning as a Service for the End-User", "comments": null, "journal-ref": "Future Generation Computer Systems 105 (2020) 275-286", "doi": "10.1016/j.future.2019.11.042", "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As ML applications are becoming ever more pervasive, fully-trained systems\nare made increasingly available to a wide public, allowing end-users to submit\nqueries with their own data, and to efficiently retrieve results. With\nincreasingly sophisticated such services, a new challenge is how to scale up to\nevergrowing user bases. In this paper, we present a distributed architecture\nthat could be exploited to parallelize a typical ML system pipeline. We propose\na case study consisting of a text mining service and discuss how the method can\nbe generalized to many similar applications. We demonstrate the significance of\nthe computational gain boosted by the distributed architecture by way of an\nextensive experimental evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 15:22:50 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 09:13:36 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Loreti", "Daniela", ""], ["Lippi", "Marco", ""], ["Torroni", "Paolo", ""]]}, {"id": "2005.14090", "submitter": "Liam L.H. Lau", "authors": "Liam L.H. Lau and Denis Werth", "title": "ODEN: A Framework to Solve Ordinary Differential Equations using\n  Artificial Neural Networks", "comments": "10 pages, 7 figures. Prepared for submission to NeurIPS", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore in detail a method to solve ordinary differential equations using\nfeedforward neural networks. We prove a specific loss function, which does not\nrequire knowledge of the exact solution, to be a suitable standard metric to\nevaluate neural networks' performance. Neural networks are shown to be\nproficient at approximating continuous solutions within their training domains.\nWe illustrate neural networks' ability to outperform traditional standard\nnumerical techniques. Training is thoroughly examined and three universal\nphases are found: (i) a prior tangent adjustment, (ii) a curvature fitting, and\n(iii) a fine-tuning stage. The main limitation of the method is the nontrivial\ntask of finding the appropriate neural network architecture and the choice of\nneural network hyperparameters for efficient optimization. However, we observe\nan optimal architecture that matches the complexity of the differential\nequation. A user-friendly and adaptable open-source code (ODE$\\mathcal{N}$) is\nprovided on GitHub.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 15:34:10 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 10:06:43 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Lau", "Liam L. H.", ""], ["Werth", "Denis", ""]]}, {"id": "2005.14105", "submitter": "Christoph Hertrich", "authors": "Christoph Hertrich and Martin Skutella", "title": "Provably Good Solutions to the Knapsack Problem via Neural Networks of\n  Bounded Size", "comments": "A short version of this paper appears in the proceedings of AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DM cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of a satisfying and rigorous mathematical understanding of\nthe performance of neural networks is a major challenge in artificial\nintelligence. Against this background, we study the expressive power of neural\nnetworks through the example of the classical NP-hard Knapsack Problem. Our\nmain contribution is a class of recurrent neural networks (RNNs) with rectified\nlinear units that are iteratively applied to each item of a Knapsack instance\nand thereby compute optimal or provably good solution values. We show that an\nRNN of depth four and width depending quadratically on the profit of an optimum\nKnapsack solution is sufficient to find optimum Knapsack solutions. We also\nprove the following tradeoff between the size of an RNN and the quality of the\ncomputed Knapsack solution: for Knapsack instances consisting of $n$ items, an\nRNN of depth five and width $w$ computes a solution of value at least\n$1-\\mathcal{O}(n^2/\\sqrt{w})$ times the optimum solution value. Our results\nbuild upon a classical dynamic programming formulation of the Knapsack Problem\nas well as a careful rounding of profit values that are also at the core of the\nwell-known fully polynomial-time approximation scheme for the Knapsack Problem.\nA carefully conducted computational study qualitatively supports our\ntheoretical size bounds. Finally, we point out that our results can be\ngeneralized to many other combinatorial optimization problems that admit\ndynamic programming solution methods, such as various Shortest Path Problems,\nthe Longest Common Subsequence Problem, and the Traveling Salesperson Problem.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 15:55:37 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 10:26:12 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Hertrich", "Christoph", ""], ["Skutella", "Martin", ""]]}, {"id": "2005.14107", "submitter": "Mattias Heinrich", "authors": "Mattias P Heinrich and Lasse Hansen", "title": "Unsupervised learning of multimodal image registration using domain\n  adaptation with projected Earth Move's discrepancies", "comments": "Medical Imaging with Deep Learning (accepted short paper)\n  https://openreview.net/forum?id=wbZM-DcJB9", "journal-ref": null, "doi": null, "report-no": "MIDL/2020/ExtendedAbstract/wbZM-DcJB9", "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal image registration is a very challenging problem for deep learning\napproaches. Most current work focuses on either supervised learning that\nrequires labelled training scans and may yield models that bias towards\nannotated structures or unsupervised approaches that are based on hand-crafted\nsimilarity metrics and may therefore not outperform their classical non-trained\ncounterparts. We believe that unsupervised domain adaptation can be beneficial\nin overcoming the current limitations for multimodal registration, where good\nmetrics are hard to define. Domain adaptation has so far been mainly limited to\nclassification problems. We propose the first use of unsupervised domain\nadaptation for discrete multimodal registration. Based on a source domain for\nwhich quantised displacement labels are available as supervision, we transfer\nthe output distribution of the network to better resemble the target domain\n(other modality) using classifier discrepancies. To improve upon the sliced\nWasserstein metric for 2D histograms, we present a novel approximation that\nprojects predictions into 1D and computes the L1 distance of their cumulative\nsums. Our proof-of-concept demonstrates the applicability of domain transfer\nfrom mono- to multimodal (multi-contrast) 2D registration of canine MRI scans\nand improves the registration accuracy from 33% (using sliced Wasserstein) to\n44%.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 15:57:21 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Heinrich", "Mattias P", ""], ["Hansen", "Lasse", ""]]}, {"id": "2005.14113", "submitter": "Mohsen Minaei", "authors": "Mohsen Minaei, S Chandra Mouli, Mainack Mondal, Bruno Ribeiro, Aniket\n  Kate", "title": "Deceptive Deletions for Protecting Withdrawn Posts on Social Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over-sharing poorly-worded thoughts and personal information is prevalent on\nonline social platforms. In many of these cases, users regret posting such\ncontent. To retrospectively rectify these errors in users' sharing decisions,\nmost platforms offer (deletion) mechanisms to withdraw the content, and social\nmedia users often utilize them. Ironically and perhaps unfortunately, these\ndeletions make users more susceptible to privacy violations by malicious actors\nwho specifically hunt post deletions at large scale. The reason for such\nhunting is simple: deleting a post acts as a powerful signal that the post\nmight be damaging to its owner. Today, multiple archival services are already\nscanning social media for these deleted posts. Moreover, as we demonstrate in\nthis work, powerful machine learning models can detect damaging deletions at\nscale.\n  Towards restraining such a global adversary against users' right to be\nforgotten, we introduce Deceptive Deletion, a decoy mechanism that minimizes\nthe adversarial advantage. Our mechanism injects decoy deletions, hence\ncreating a two-player minmax game between an adversary that seeks to classify\ndamaging content among the deleted posts and a challenger that employs decoy\ndeletions to masquerade real damaging deletions. We formalize the Deceptive\nGame between the two players, determine conditions under which either the\nadversary or the challenger provably wins the game, and discuss the scenarios\nin-between these two extremes. We apply the Deceptive Deletion mechanism to a\nreal-world task on Twitter: hiding damaging tweet deletions. We show that a\npowerful global adversary can be beaten by a powerful challenger, raising the\nbar significantly and giving a glimmer of hope in the ability to be really\nforgotten on social platforms.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 16:08:33 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Minaei", "Mohsen", ""], ["Mouli", "S Chandra", ""], ["Mondal", "Mainack", ""], ["Ribeiro", "Bruno", ""], ["Kate", "Aniket", ""]]}, {"id": "2005.14117", "submitter": "Alessio Fagioli", "authors": "Danilo Avola, Luigi Cinque, Alessio Fagioli, Sebastiano Filetti,\n  Giorgio Grani, Emanuele Rodol\\`a", "title": "Knowledge-Driven Learning via Experts Consult for Thyroid Nodule\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-aided diagnosis (CAD) is becoming a prominent approach to assist\nclinicians spanning across multiple fields. These automated systems take\nadvantage of various computer vision (CV) procedures, as well as artificial\nintelligence (AI) techniques, so that a diagnosis of a given image (e.g.,\ncomputed tomography and ultrasound) can be formulated. Advances in both areas\n(CV and AI) are enabling ever increasing performances of CAD systems, which can\nultimately avoid performing invasive procedures such as fine-needle aspiration.\nIn this study, we focus on thyroid ultrasonography to present a novel\nknowledge-driven classification framework. The proposed system leverages cues\nprovided by an ensemble of experts, in order to guide the learning phase of a\ndensely connected convolutional network (DenseNet). The ensemble is composed by\nvarious networks pretrained on ImageNet, including AlexNet, ResNet, VGG, and\nothers, so that previously computed feature parameters could be used to create\nultrasonography domain experts via transfer learning, decreasing, moreover, the\nnumber of samples required for training. To validate the proposed method,\nextensive experiments were performed, providing detailed performances for both\nthe experts ensemble and the knowledge-driven DenseNet. The obtained results,\nshow how the the proposed system can become a great asset when formulating a\ndiagnosis, by leveraging previous knowledge derived from a consult.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 16:12:04 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Avola", "Danilo", ""], ["Cinque", "Luigi", ""], ["Fagioli", "Alessio", ""], ["Filetti", "Sebastiano", ""], ["Grani", "Giorgio", ""], ["Rodol\u00e0", "Emanuele", ""]]}, {"id": "2005.14124", "submitter": "Christopher M. Poskitt", "authors": "Yuqi Chen, Bohan Xuan, Christopher M. Poskitt, Jun Sun, Fan Zhang", "title": "Active Fuzzing for Testing and Securing Cyber-Physical Systems", "comments": "Accepted by the ACM SIGSOFT International Symposium on Software\n  Testing and Analysis (ISSTA 2020)", "journal-ref": "In Proc. ACM SIGSOFT International Symposium on Software Testing\n  and Analysis (ISSTA 2020), pages 14-26. ACM, 2020", "doi": "10.1145/3395363.3397376", "report-no": null, "categories": "cs.SE cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical systems (CPSs) in critical infrastructure face a pervasive\nthreat from attackers, motivating research into a variety of countermeasures\nfor securing them. Assessing the effectiveness of these countermeasures is\nchallenging, however, as realistic benchmarks of attacks are difficult to\nmanually construct, blindly testing is ineffective due to the enormous search\nspaces and resource requirements, and intelligent fuzzing approaches require\nimpractical amounts of data and network access. In this work, we propose active\nfuzzing, an automatic approach for finding test suites of packet-level CPS\nnetwork attacks, targeting scenarios in which attackers can observe sensors and\nmanipulate packets, but have no existing knowledge about the payload encodings.\nOur approach learns regression models for predicting sensor values that will\nresult from sampled network packets, and uses these predictions to guide a\nsearch for payload manipulations (i.e. bit flips) most likely to drive the CPS\ninto an unsafe state. Key to our solution is the use of online active learning,\nwhich iteratively updates the models by sampling payloads that are estimated to\nmaximally improve them. We evaluate the efficacy of active fuzzing by\nimplementing it for a water purification plant testbed, finding it can\nautomatically discover a test suite of flow, pressure, and over/underflow\nattacks, all with substantially less time, data, and network access than the\nmost comparable approach. Finally, we demonstrate that our prediction models\ncan also be utilised as countermeasures themselves, implementing them as\nanomaly detectors and early warning systems.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 16:19:50 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 08:15:48 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Chen", "Yuqi", ""], ["Xuan", "Bohan", ""], ["Poskitt", "Christopher M.", ""], ["Sun", "Jun", ""], ["Zhang", "Fan", ""]]}, {"id": "2005.14137", "submitter": "Huichen Li", "authors": "Huichen Li, Xiaojun Xu, Xiaolu Zhang, Shuang Yang, Bo Li", "title": "QEBA: Query-Efficient Boundary-Based Blackbox Attack", "comments": "Accepted by CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML), especially deep neural networks (DNNs) have been\nwidely used in various applications, including several safety-critical ones\n(e.g. autonomous driving). As a result, recent research about adversarial\nexamples has raised great concerns. Such adversarial attacks can be achieved by\nadding a small magnitude of perturbation to the input to mislead model\nprediction. While several whitebox attacks have demonstrated their\neffectiveness, which assume that the attackers have full access to the machine\nlearning models; blackbox attacks are more realistic in practice. In this\npaper, we propose a Query-Efficient Boundary-based blackbox Attack (QEBA) based\nonly on model's final prediction labels. We theoretically show why previous\nboundary-based attack with gradient estimation on the whole gradient space is\nnot efficient in terms of query numbers, and provide optimality analysis for\nour dimension reduction-based gradient estimation. On the other hand, we\nconducted extensive experiments on ImageNet and CelebA datasets to evaluate\nQEBA. We show that compared with the state-of-the-art blackbox attacks, QEBA is\nable to use a smaller number of queries to achieve a lower magnitude of\nperturbation with 100% attack success rate. We also show case studies of\nattacks on real-world APIs including MEGVII Face++ and Microsoft Azure.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 16:41:12 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Li", "Huichen", ""], ["Xu", "Xiaojun", ""], ["Zhang", "Xiaolu", ""], ["Yang", "Shuang", ""], ["Li", "Bo", ""]]}, {"id": "2005.14187", "submitter": "Hanrui Wang", "authors": "Hanrui Wang, Zhanghao Wu, Zhijian Liu, Han Cai, Ligeng Zhu, Chuang\n  Gan, Song Han", "title": "HAT: Hardware-Aware Transformers for Efficient Natural Language\n  Processing", "comments": "Accepted to ACL 2020. 14 pages, 12 figures. Code available at\n  http://github.com/mit-han-lab/hardware-aware-transformers.git", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers are ubiquitous in Natural Language Processing (NLP) tasks, but\nthey are difficult to be deployed on hardware due to the intensive computation.\nTo enable low-latency inference on resource-constrained hardware platforms, we\npropose to design Hardware-Aware Transformers (HAT) with neural architecture\nsearch. We first construct a large design space with $\\textit{arbitrary\nencoder-decoder attention}$ and $\\textit{heterogeneous layers}$. Then we train\na $\\textit{SuperTransformer}$ that covers all candidates in the design space,\nand efficiently produces many $\\textit{SubTransformers}$ with weight sharing.\nFinally, we perform an evolutionary search with a hardware latency constraint\nto find a specialized $\\textit{SubTransformer}$ dedicated to run fast on the\ntarget hardware. Extensive experiments on four machine translation tasks\ndemonstrate that HAT can discover efficient models for different hardware (CPU,\nGPU, IoT device). When running WMT'14 translation task on Raspberry Pi-4, HAT\ncan achieve $\\textbf{3}\\times$ speedup, $\\textbf{3.7}\\times$ smaller size over\nbaseline Transformer; $\\textbf{2.7}\\times$ speedup, $\\textbf{3.6}\\times$\nsmaller size over Evolved Transformer with $\\textbf{12,041}\\times$ less search\ncost and no performance loss. HAT code is\nhttps://github.com/mit-han-lab/hardware-aware-transformers.git\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 17:58:56 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Wang", "Hanrui", ""], ["Wu", "Zhanghao", ""], ["Liu", "Zhijian", ""], ["Cai", "Han", ""], ["Zhu", "Ligeng", ""], ["Gan", "Chuang", ""], ["Han", "Song", ""]]}, {"id": "2005.14213", "submitter": "Yien Xu", "authors": "Yifan Dai, Yien Xu, Aishwarya Ganesan, Ramnatthan Alagappan, Brian\n  Kroth, Andrea C. Arpaci-Dusseau, and Remzi H. Arpaci-Dusseau", "title": "From WiscKey to Bourbon: A Learned Index for Log-Structured Merge Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce BOURBON, a log-structured merge (LSM) tree that utilizes machine\nlearning to provide fast lookups. We base the design and implementation of\nBOURBON on empirically-grounded principles that we derive through careful\nanalysis of LSM design. BOURBON employs greedy piecewise linear regression to\nlearn key distributions, enabling fast lookup with minimal computation, and\napplies a cost-benefit strategy to decide when learning will be worthwhile.\nThrough a series of experiments on both synthetic and real-world datasets, we\nshow that BOURBON improves lookup performance by 1.23x-1.78x as compared to\nstate-of-the-art production LSMs.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 18:05:46 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 18:09:20 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Dai", "Yifan", ""], ["Xu", "Yien", ""], ["Ganesan", "Aishwarya", ""], ["Alagappan", "Ramnatthan", ""], ["Kroth", "Brian", ""], ["Arpaci-Dusseau", "Andrea C.", ""], ["Arpaci-Dusseau", "Remzi H.", ""]]}, {"id": "2005.14220", "submitter": "Arsham Mostaani", "authors": "Arsham Mostaani, Thang X. Vu, Symeon Chatzinotas, Bj\\\"orn Ottersten", "title": "Task-Based Information Compression for Multi-Agent Communication\n  Problems with Channel Rate Constraints", "comments": "13 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.MA cs.SY eess.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A collaborative task is assigned to a multiagent system (MAS) in which agents\nare allowed to communicate. The MAS runs over an underlying Markov decision\nprocess and its task is to maximize the averaged sum of discounted one-stage\nrewards. Although knowing the global state of the environment is necessary for\nthe optimal action selection of the MAS, agents are limited to individual\nobservations. The inter-agent communication can tackle the issue of local\nobservability, however, the limited rate of the inter-agent communication\nprevents the agent from acquiring the precise global state information. To\novercome this challenge, agents need to communicate their observations in a\ncompact way such that the MAS compromises the minimum possible sum of rewards.\nWe show that this problem is equivalent to a form of rate-distortion problem\nwhich we call the task-based information compression. We introduce a scheme for\ntask-based information compression titled State aggregation for information\ncompression (SAIC), for which a state aggregation algorithm is analytically\ndesigned. The SAIC is shown to be capable of achieving near-optimal performance\nin terms of the achieved sum of discounted rewards. The proposed algorithm is\napplied to a rendezvous problem and its performance is compared with several\nbenchmarks. Numerical experiments confirm the superiority of the proposed\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 18:29:21 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 14:27:26 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Mostaani", "Arsham", ""], ["Vu", "Thang X.", ""], ["Chatzinotas", "Symeon", ""], ["Ottersten", "Bj\u00f6rn", ""]]}, {"id": "2005.14228", "submitter": "Edwin Bedolla", "authors": "Edwin A. Bedolla-Montiel, Luis Carlos Padierna, Ram\\'on\n  Casta\\~neda-Priego", "title": "Machine Learning for Condensed Matter Physics", "comments": "48 pages, 2 figures, 300 references. Review paper. Major Revision", "journal-ref": "J. Phys.: Condens. Matter 33 (2021) 053001", "doi": "10.1088/1361-648X/abb895", "report-no": null, "categories": "physics.comp-ph cond-mat.dis-nn cond-mat.other cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Condensed Matter Physics (CMP) seeks to understand the microscopic\ninteractions of matter at the quantum and atomistic levels, and describes how\nthese interactions result in both mesoscopic and macroscopic properties. CMP\noverlaps with many other important branches of science, such as Chemistry,\nMaterials Science, Statistical Physics, and High-Performance Computing. With\nthe advancements in modern Machine Learning (ML) technology, a keen interest in\napplying these algorithms to further CMP research has created a compelling new\narea of research at the intersection of both fields. In this review, we aim to\nexplore the main areas within CMP, which have successfully applied ML\ntechniques to further research, such as the description and use of ML schemes\nfor potential energy surfaces, the characterization of topological phases of\nmatter in lattice systems, the prediction of phase transitions in off-lattice\nand atomistic simulations, the interpretation of ML theories with\nphysics-inspired frameworks and the enhancement of simulation methods with ML\nalgorithms. We also discuss in detail the main challenges and drawbacks of\nusing ML methods on CMP problems, as well as some perspectives for future\ndevelopments.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 18:44:55 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 04:24:08 GMT"}, {"version": "v3", "created": "Fri, 14 Aug 2020 01:03:43 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Bedolla-Montiel", "Edwin A.", ""], ["Padierna", "Luis Carlos", ""], ["Casta\u00f1eda-Priego", "Ram\u00f3n", ""]]}, {"id": "2005.14230", "submitter": "Nathaniel Bastian PhD", "authors": "Marc Chal\\'e, Nathaniel D. Bastian, Jeffery Weir", "title": "Algorithm Selection Framework for Cyber Attack Detection", "comments": "6 pages, 7 figures, 1 table, accepted to WiseML '20", "journal-ref": null, "doi": "10.1145/3395352.3402623", "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of cyber threats against both wired and wireless computer systems\nand other components of the Internet of Things continues to increase annually.\nIn this work, an algorithm selection framework is employed on the NSL-KDD data\nset and a novel paradigm of machine learning taxonomy is presented. The\nframework uses a combination of user input and meta-features to select the best\nalgorithm to detect cyber attacks on a network. Performance is compared between\na rule-of-thumb strategy and a meta-learning strategy. The framework removes\nthe conjecture of the common trial-and-error algorithm selection method. The\nframework recommends five algorithms from the taxonomy. Both strategies\nrecommend a high-performing algorithm, though not the best performing. The work\ndemonstrates the close connectedness between algorithm selection and the\ntaxonomy for which it is premised.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 18:49:29 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Chal\u00e9", "Marc", ""], ["Bastian", "Nathaniel D.", ""], ["Weir", "Jeffery", ""]]}, {"id": "2005.14253", "submitter": "Nicholas FitzGerald", "authors": "Thibault F\\'evry, Nicholas FitzGerald, Livio Baldini Soares, Tom\n  Kwiatkowski", "title": "Empirical Evaluation of Pretraining Strategies for Supervised Entity\n  Linking", "comments": "11 pages, 8 figures, appearing at AKBC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present an entity linking model which combines a Transformer\narchitecture with large scale pretraining from Wikipedia links. Our model\nachieves the state-of-the-art on two commonly used entity linking datasets:\n96.7% on CoNLL and 94.9% on TAC-KBP. We present detailed analyses to understand\nwhat design choices are important for entity linking, including choices of\nnegative entity candidates, Transformer architecture, and input perturbations.\nLastly, we present promising results on more challenging settings such as\nend-to-end entity linking and entity linking without in-domain training data.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 19:32:52 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["F\u00e9vry", "Thibault", ""], ["FitzGerald", "Nicholas", ""], ["Soares", "Livio Baldini", ""], ["Kwiatkowski", "Tom", ""]]}, {"id": "2005.14256", "submitter": "Zhou Shou", "authors": "Sha Yuan, Zhou Shao, Yu Zhang, Xingxing Wei, Tong Xiao, Yifan Wang,\n  Jie Tang", "title": "Attention: to Better Stand on the Shoulders of Giants", "comments": "arXiv admin note: text overlap with arXiv:1811.02117,\n  arXiv:1811.02129", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Science of science (SciSci) is an emerging discipline wherein science is used\nto study the structure and evolution of science itself using large data sets.\nThe increasing availability of digital data on scholarly outcomes offers\nunprecedented opportunities to explore SciSci. In the progress of science, the\npreviously discovered knowledge principally inspires new scientific ideas, and\ncitation is a reasonably good reflection of this cumulative nature of\nscientific research. The researches that choose potentially influential\nreferences will have a lead over the emerging publications. Although the peer\nreview process is the mainly reliable way of predicting a paper's future\nimpact, the ability to foresee the lasting impact based on citation records is\nincreasingly essential in the scientific impact analysis in the era of big\ndata. This paper develops an attention mechanism for the long-term scientific\nimpact prediction and validates the method based on a real large-scale citation\ndata set. The results break conventional thinking. Instead of accurately\nsimulating the original power-law distribution, emphasizing the limited\nattention can better stand on the shoulders of giants.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 00:25:51 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Yuan", "Sha", ""], ["Shao", "Zhou", ""], ["Zhang", "Yu", ""], ["Wei", "Xingxing", ""], ["Xiao", "Tong", ""], ["Wang", "Yifan", ""], ["Tang", "Jie", ""]]}, {"id": "2005.14257", "submitter": "Mohammadreza Iman", "authors": "Mohammadreza Iman, Amy Giuntini, Hamid Reza Arabnia, and Khaled\n  Rasheed", "title": "A Comparative Study of Machine Learning Models for Tabular Data Through\n  Challenge of Monitoring Parkinson's Disease Progression Using Voice\n  Recordings", "comments": "Accepted at \"HIMS'20 - The 6th Int'l Conf on Health Informatics and\n  Medical Systems\"; https://americancse.org/events/csce2020/conferences/hims20", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People with Parkinson's disease must be regularly monitored by their\nphysician to observe how the disease is progressing and potentially adjust\ntreatment plans to mitigate the symptoms. Monitoring the progression of the\ndisease through a voice recording captured by the patient at their own home can\nmake the process faster and less stressful. Using a dataset of voice recordings\nof 42 people with early-stage Parkinson's disease over a time span of 6 months,\nwe applied multiple machine learning techniques to find a correlation between\nthe voice recording and the patient's motor UPDRS score. We approached this\nproblem using a multitude of both regression and classification techniques.\nMuch of this paper is dedicated to mapping the voice data to motor UPDRS scores\nusing regression techniques in order to obtain a more precise value for unknown\ninstances. Through this comparative study of variant machine learning methods,\nwe realized some old machine learning methods like trees outperform cutting\nedge deep learning models on numerous tabular datasets.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 16:09:26 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Iman", "Mohammadreza", ""], ["Giuntini", "Amy", ""], ["Arabnia", "Hamid Reza", ""], ["Rasheed", "Khaled", ""]]}, {"id": "2005.14259", "submitter": "Alwyn Mathew", "authors": "Alwyn Mathew, Abhijit Roy, Jimson Mathew", "title": "Intelligent Residential Energy Management System using Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": "10.1109/JSYST.2020.2996547", "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rising demand for electricity and its essential nature in today's world\ncalls for intelligent home energy management (HEM) systems that can reduce\nenergy usage. This involves scheduling of loads from peak hours of the day when\nenergy consumption is at its highest to leaner off-peak periods of the day when\nenergy consumption is relatively lower thereby reducing the system's peak load\ndemand, which would consequently result in lesser energy bills, and improved\nload demand profile. This work introduces a novel way to develop a learning\nsystem that can learn from experience to shift loads from one time instance to\nanother and achieve the goal of minimizing the aggregate peak load. This paper\nproposes a Deep Reinforcement Learning (DRL) model for demand response where\nthe virtual agent learns the task like humans do. The agent gets feedback for\nevery action it takes in the environment; these feedbacks will drive the agent\nto learn about the environment and take much smarter steps later in its\nlearning stages. Our method outperformed the state of the art mixed integer\nlinear programming (MILP) for load peak reduction. The authors have also\ndesigned an agent to learn to minimize both consumers' electricity bills and\nutilities' system peak load demand simultaneously. The proposed model was\nanalyzed with loads from five different residential consumers; the proposed\nmethod increases the monthly savings of each consumer by reducing their\nelectricity bill drastically along with minimizing the peak load on the system\nwhen time shiftable loads are handled by the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 19:51:22 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Mathew", "Alwyn", ""], ["Roy", "Abhijit", ""], ["Mathew", "Jimson", ""]]}, {"id": "2005.14263", "submitter": "Jonne Pohjankukka Dr.", "authors": "Jonne Pohjankukka, Tapio Pahikkala, Paavo Nevalainen, Jukka Heikkonen", "title": "Estimating the Prediction Performance of Spatial Models via Spatial\n  k-Fold Cross Validation", "comments": "18 pages, 12 figures, 1 table", "journal-ref": "International Journal of Geographical Information Science, Volume\n  31, 2017, Issue 10, pages 2001-2019", "doi": "10.1080/13658816.2017.1346255", "report-no": null, "categories": "stat.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning one often assumes the data are independent when\nevaluating model performance. However, this rarely holds in practise.\nGeographic information data sets are an example where the data points have\nstronger dependencies among each other the closer they are geographically. This\nphenomenon known as spatial autocorrelation (SAC) causes the standard cross\nvalidation (CV) methods to produce optimistically biased prediction performance\nestimates for spatial models, which can result in increased costs and accidents\nin practical applications. To overcome this problem we propose a modified\nversion of the CV method called spatial k-fold cross validation (SKCV), which\nprovides a useful estimate for model prediction performance without optimistic\nbias due to SAC. We test SKCV with three real world cases involving open\nnatural data showing that the estimates produced by the ordinary CV are up to\n40% more optimistic than those of SKCV. Both regression and classification\ncases are considered in our experiments. In addition, we will show how the SKCV\nmethod can be applied as a criterion for selecting data sampling density for\nnew research area.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 19:55:18 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Pohjankukka", "Jonne", ""], ["Pahikkala", "Tapio", ""], ["Nevalainen", "Paavo", ""], ["Heikkonen", "Jukka", ""]]}, {"id": "2005.14284", "submitter": "Muhammad Naseer Bajwa", "authors": "Muhammad Naseer Bajwa, Muhammad Imran Malik, Shoaib Ahmed Siddiqui,\n  Andreas Dengel, Faisal Shafait, Wolfgang Neumeier, Sheraz Ahmed", "title": "Two-stage framework for optic disc localization and glaucoma\n  classification in retinal fundus images using deep learning", "comments": "16 Pages, 10 Figures", "journal-ref": "BMC medical informatics and decision making 19.1 (2019): 136", "doi": "10.1186/s12911-019-0842-8", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement of powerful image processing and machine learning\ntechniques, CAD has become ever more prevalent in all fields of medicine\nincluding ophthalmology. Since optic disc is the most important part of retinal\nfundus image for glaucoma detection, this paper proposes a two-stage framework\nthat first detects and localizes optic disc and then classifies it into healthy\nor glaucomatous. The first stage is based on RCNN and is responsible for\nlocalizing and extracting optic disc from a retinal fundus image while the\nsecond stage uses Deep CNN to classify the extracted disc into healthy or\nglaucomatous. In addition to the proposed solution, we also developed a\nrule-based semi-automatic ground truth generation method that provides\nnecessary annotations for training RCNN based model for automated disc\nlocalization. The proposed method is evaluated on seven publicly available\ndatasets for disc localization and on ORIGA dataset, which is the largest\npublicly available dataset for glaucoma classification. The results of\nautomatic localization mark new state-of-the-art on six datasets with accuracy\nreaching 100% on four of them. For glaucoma classification we achieved AUC\nequal to 0.874 which is 2.7% relative improvement over the state-of-the-art\nresults previously obtained for classification on ORIGA. Once trained on\ncarefully annotated data, Deep Learning based methods for optic disc detection\nand localization are not only robust, accurate and fully automated but also\neliminates the need for dataset-dependent heuristic algorithms. Our empirical\nevaluation of glaucoma classification on ORIGA reveals that reporting only AUC,\nfor datasets with class imbalance and without pre-defined train and test\nsplits, does not portray true picture of the classifier's performance and calls\nfor additional performance metrics to substantiate the results.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 20:40:19 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Bajwa", "Muhammad Naseer", ""], ["Malik", "Muhammad Imran", ""], ["Siddiqui", "Shoaib Ahmed", ""], ["Dengel", "Andreas", ""], ["Shafait", "Faisal", ""], ["Neumeier", "Wolfgang", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "2005.14308", "submitter": "Muhammad Naseer Bajwa", "authors": "Muhammad Naseer Bajwa, Yoshinobu Taniguchi, Muhammad Imran Malik,\n  Wolfgang Neumeier, Andreas Dengel, Sheraz Ahmed", "title": "Combining Fine- and Coarse-Grained Classifiers for Diabetic Retinopathy\n  Detection", "comments": "Pages 12, Figures 5", "journal-ref": null, "doi": "10.1007/978-3-030-39343-4_21", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual artefacts of early diabetic retinopathy in retinal fundus images are\nusually small in size, inconspicuous, and scattered all over retina. Detecting\ndiabetic retinopathy requires physicians to look at the whole image and fixate\non some specific regions to locate potential biomarkers of the disease.\nTherefore, getting inspiration from ophthalmologist, we propose to combine\ncoarse-grained classifiers that detect discriminating features from the whole\nimages, with a recent breed of fine-grained classifiers that discover and pay\nparticular attention to pathologically significant regions. To evaluate the\nperformance of this proposed ensemble, we used publicly available EyePACS and\nMessidor datasets. Extensive experimentation for binary, ternary and quaternary\nclassification shows that this ensemble largely outperforms individual image\nclassifiers as well as most of the published works in most training setups for\ndiabetic retinopathy detection. Furthermore, the performance of fine-grained\nclassifiers is found notably superior than coarse-grained image classifiers\nencouraging the development of task-oriented fine-grained classifiers modelled\nafter specialist ophthalmologists.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 21:37:36 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Bajwa", "Muhammad Naseer", ""], ["Taniguchi", "Yoshinobu", ""], ["Malik", "Muhammad Imran", ""], ["Neumeier", "Wolfgang", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "2005.14324", "submitter": "Pavel Jahoda", "authors": "Pavel Jahoda, Igor Drozdovskiy, Francesco Sauro, Leonardo Turchi,\n  Samuel Payler, and Loredana Bessone", "title": "Machine Learning for recognition of minerals from multispectral data", "comments": "11 pages", "journal-ref": null, "doi": "10.1039/D0AN01483D", "report-no": null, "categories": "cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) has found several applications in spectroscopy,\nincluding being used to recognise minerals and estimate elemental composition.\nIn this work, we present novel methods for automatic mineral identification\nbased on combining data from different spectroscopic methods. We evaluate\ncombining data from three spectroscopic methods: vibrational Raman scattering,\nreflective Visible-Near Infrared (VNIR), and Laser-Induced Breakdown\nSpectroscopy (LIBS). These methods were paired into Raman + VNIR, Raman + LIBS\nand VNIR + LIBS, and different methods of data fusion applied to each pair to\nclassify minerals. The methods presented here are shown to outperform the use\nof a single data source by a significant margin. Additionally, we present a\nDeep Learning algorithm for mineral classification from Raman spectra that\noutperforms previous state-of-the-art methods. Our approach was tested on\nvarious open access experimental Raman (RRUFF) and VNIR (USGS, Relab,\nECOSTRESS), as well as synthetic LIBS NIST spectral libraries. Our\ncross-validation tests show that multi-method spectroscopy paired with ML paves\nthe way towards rapid and accurate characterization of rocks and minerals.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 22:25:15 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Jahoda", "Pavel", ""], ["Drozdovskiy", "Igor", ""], ["Sauro", "Francesco", ""], ["Turchi", "Leonardo", ""], ["Payler", "Samuel", ""], ["Bessone", "Loredana", ""]]}, {"id": "2005.14330", "submitter": "Abdullah-Al-Zubaer Imran", "authors": "Abdullah-Al-Zubaer Imran, Chao Huang, Hui Tang, Wei Fan, Kenneth M.C.\n  Cheung, Michael To, Zhen Qian, Demetri Terzopoulos", "title": "Bipartite Distance for Shape-Aware Landmark Detection in Spinal X-Ray\n  Images", "comments": "Presented at Med-NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Scoliosis is a congenital disease that causes lateral curvature in the spine.\nIts assessment relies on the identification and localization of vertebrae in\nspinal X-ray images, conventionally via tedious and time-consuming manual\nradiographic procedures that are prone to subjectivity and observational\nvariability. Reliability can be improved through the automatic detection and\nlocalization of spinal landmarks. To guide a CNN in the learning of spinal\nshape while detecting landmarks in X-ray images, we propose a novel loss based\non a bipartite distance (BPD) measure, and show that it consistently improves\nlandmark detection performance.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 22:34:24 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Imran", "Abdullah-Al-Zubaer", ""], ["Huang", "Chao", ""], ["Tang", "Hui", ""], ["Fan", "Wei", ""], ["Cheung", "Kenneth M. C.", ""], ["To", "Michael", ""], ["Qian", "Zhen", ""], ["Terzopoulos", "Demetri", ""]]}, {"id": "2005.14346", "submitter": "Simge Kucukyavuz", "authors": "Simge Kucukyavuz, Ali Shojaie, Hasan Manzour, Linchuan Wei", "title": "Consistent Second-Order Conic Integer Programming for Learning Bayesian\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Networks (BNs) represent conditional probability relations among a\nset of random variables (nodes) in the form of a directed acyclic graph (DAG),\nand have found diverse applications in knowledge discovery. We study the\nproblem of learning the sparse DAG structure of a BN from continuous\nobservational data. The central problem can be modeled as a mixed-integer\nprogram with an objective function composed of a convex quadratic loss function\nand a regularization penalty subject to linear constraints. The optimal\nsolution to this mathematical program is known to have desirable statistical\nproperties under certain conditions. However, the state-of-the-art optimization\nsolvers are not able to obtain provably optimal solutions to the existing\nmathematical formulations for medium-size problems within reasonable\ncomputational times. To address this difficulty, we tackle the problem from\nboth computational and statistical perspectives. On the one hand, we propose a\nconcrete early stopping criterion to terminate the branch-and-bound process in\norder to obtain a near-optimal solution to the mixed-integer program, and\nestablish the consistency of this approximate solution. On the other hand, we\nimprove the existing formulations by replacing the linear \"big-$M$\" constraints\nthat represent the relationship between the continuous and binary indicator\nvariables with second-order conic constraints. Our numerical results\ndemonstrate the effectiveness of the proposed approaches.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 00:13:15 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 17:04:57 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kucukyavuz", "Simge", ""], ["Shojaie", "Ali", ""], ["Manzour", "Hasan", ""], ["Wei", "Linchuan", ""]]}, {"id": "2005.14359", "submitter": "Mao Ye", "authors": "Yan Min, Mao Ye, Liang Tian, Yulin Jian, Ce Zhu, Shangming Yang", "title": "Unsupervised Feature Selection via Multi-step Markov Transition\n  Probability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is a widely used dimension reduction technique to select\nfeature subsets because of its interpretability. Many methods have been\nproposed and achieved good results, in which the relationships between adjacent\ndata points are mainly concerned. But the possible associations between data\npairs that are may not adjacent are always neglected. Different from previous\nmethods, we propose a novel and very simple approach for unsupervised feature\nselection, named MMFS (Multi-step Markov transition probability for Feature\nSelection). The idea is using multi-step Markov transition probability to\ndescribe the relation between any data pair. Two ways from the positive and\nnegative viewpoints are employed respectively to keep the data structure after\nfeature selection. From the positive viewpoint, the maximum transition\nprobability that can be reached in a certain number of steps is used to\ndescribe the relation between two points. Then, the features which can keep the\ncompact data structure are selected. From the viewpoint of negative, the\nminimum transition probability that can be reached in a certain number of steps\nis used to describe the relation between two points. On the contrary, the\nfeatures that least maintain the loose data structure are selected. And the two\nways can also be combined. Thus three algorithms are proposed. Our main\ncontributions are a novel feature section approach which uses multi-step\ntransition probability to characterize the data structure, and three algorithms\nproposed from the positive and negative aspects for keeping data structure. The\nperformance of our approach is compared with the state-of-the-art methods on\neight real-world data sets, and the experimental results show that the proposed\nMMFS is effective in unsupervised feature selection.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 01:15:16 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Min", "Yan", ""], ["Ye", "Mao", ""], ["Tian", "Liang", ""], ["Jian", "Yulin", ""], ["Zhu", "Ce", ""], ["Yang", "Shangming", ""]]}, {"id": "2005.14381", "submitter": "Kiattikun Chobtham", "authors": "Kiattikun Chobtham, Anthony C. Constantinou", "title": "Bayesian network structure learning with causal effects in the presence\n  of latent variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent variables may lead to spurious relationships that can be\nmisinterpreted as causal relationships. In Bayesian Networks (BNs), this\nchallenge is known as learning under causal insufficiency. Structure learning\nalgorithms that assume causal insufficiency tend to reconstruct the ancestral\ngraph of a BN, where bi-directed edges represent confounding and directed edges\nrepresent direct or ancestral relationships. This paper describes a hybrid\nstructure learning algorithm, called CCHM, which combines the constraint-based\npart of cFCI with hill-climbing score-based learning. The score-based process\nincorporates Pearl s do-calculus to measure causal effects and orientate edges\nthat would otherwise remain undirected, under the assumption the BN is a linear\nStructure Equation Model where data follow a multivariate Gaussian\ndistribution. Experiments based on both randomised and well-known networks show\nthat CCHM improves the state-of-the-art in terms of reconstructing the true\nancestral graph.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 04:42:28 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 06:17:56 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Chobtham", "Kiattikun", ""], ["Constantinou", "Anthony C.", ""]]}, {"id": "2005.14401", "submitter": "Damian Bogunowicz", "authors": "Damian Bogunowicz, Aleksandr Rybnikov, Komal Vendidandi and Fedor\n  Chervinskii", "title": "Sim2Real for Peg-Hole Insertion with Eye-in-Hand Camera", "comments": "Published at ICRA 2020 ViTac workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though the peg-hole insertion is one of the well-studied problems in\nrobotics, it still remains a challenge for robots, especially when it comes to\nflexibility and the ability to generalize. Successful completion of the task\nrequires combining several modalities to cope with the complexity of the real\nworld. In our work, we focus on the visual aspect of the problem and employ the\nstrategy of learning an insertion task in a simulator. We use Deep\nReinforcement Learning to learn the policy end-to-end and then transfer the\nlearned model to the real robot, without any additional fine-tuning. We show\nthat the transferred policy, which only takes RGB-D and joint information\n(proprioception) can perform well on the real robot.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 05:58:54 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Bogunowicz", "Damian", ""], ["Rybnikov", "Aleksandr", ""], ["Vendidandi", "Komal", ""], ["Chervinskii", "Fedor", ""]]}, {"id": "2005.14408", "submitter": "Xiao Yang", "authors": "Deepak Muralidharan, Joel Ruben Antony Moniz, Sida Gao, Xiao Yang, Lin\n  Li, Justine Kao, Stephen Pulman, Atish Kothari, Ray Shen, Yinying Pan, Vivek\n  Kaul, Mubarak Seyed Ibrahim, Gang Xiang, Nan Dun, Yidan Zhou, Andy O, Yuan\n  Zhang, Pooja Chitkara, Xuan Wang, Alkesh Patel, Kushal Tayal, Roger Zheng,\n  Peter Grasch, Jason Williams", "title": "Noise-robust Named Entity Understanding for Virtual Assistants", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Understanding (NEU) plays an essential role in interactions\nbetween users and voice assistants, since successfully identifying entities and\ncorrectly linking them to their standard forms is crucial to understanding the\nuser's intent. NEU is a challenging task in voice assistants due to the\nambiguous nature of natural language and because noise introduced by speech\ntranscription and user errors occur frequently in spoken natural language\nqueries. In this paper, we propose an architecture with novel features that\njointly solves the recognition of named entities (a.k.a. Named Entity\nRecognition, or NER) and the resolution to their canonical forms (a.k.a. Entity\nLinking, or EL). We show that by combining NER and EL information in a joint\nreranking module, our proposed framework improves accuracy in both tasks. This\nimproved performance and the features that enable it, also lead to better\naccuracy in downstream tasks, such as domain classification and semantic\nparsing.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 06:14:53 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 20:32:55 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Muralidharan", "Deepak", ""], ["Moniz", "Joel Ruben Antony", ""], ["Gao", "Sida", ""], ["Yang", "Xiao", ""], ["Li", "Lin", ""], ["Kao", "Justine", ""], ["Pulman", "Stephen", ""], ["Kothari", "Atish", ""], ["Shen", "Ray", ""], ["Pan", "Yinying", ""], ["Kaul", "Vivek", ""], ["Ibrahim", "Mubarak Seyed", ""], ["Xiang", "Gang", ""], ["Dun", "Nan", ""], ["Zhou", "Yidan", ""], ["O", "Andy", ""], ["Zhang", "Yuan", ""], ["Chitkara", "Pooja", ""], ["Wang", "Xuan", ""], ["Patel", "Alkesh", ""], ["Tayal", "Kushal", ""], ["Zheng", "Roger", ""], ["Grasch", "Peter", ""], ["Williams", "Jason", ""]]}, {"id": "2005.14410", "submitter": "Niklas K\\\"uhl", "authors": "Lucia Schuler and Somaya Jamil and Niklas K\\\"uhl", "title": "AI-based Resource Allocation: Reinforcement Learning for Adaptive\n  Auto-scaling in Serverless Environments", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Serverless computing has emerged as a compelling new paradigm of cloud\ncomputing models in recent years. It promises the user services at large scale\nand low cost while eliminating the need for infrastructure management. On cloud\nprovider side, flexible resource management is required to meet fluctuating\ndemand. It can be enabled through automated provisioning and deprovisioning of\nresources. A common approach among both commercial and open source serverless\ncomputing platforms is workload-based auto-scaling, where a designated\nalgorithm scales instances according to the number of incoming requests. In the\nrecently evolving serverless framework Knative a request-based policy is\nproposed, where the algorithm scales resources by a configured maximum number\nof requests that can be processed in parallel per instance, the so-called\nconcurrency. As we show in a baseline experiment, this predefined concurrency\nlevel can strongly influence the performance of a serverless application.\nHowever, identifying the concurrency configuration that yields the highest\npossible quality of service is a challenging task due to various factors, e.g.\nvarying workload and complex infrastructure characteristics, influencing\nthroughput and latency. While there has been considerable research into\nintelligent techniques for optimizing auto-scaling for virtual machine\nprovisioning, this topic has not yet been discussed in the area of serverless\ncomputing. For this reason, we investigate the applicability of a reinforcement\nlearning approach, which has been proven on dynamic virtual machine\nprovisioning, to request-based auto-scaling in a serverless framework. Our\nresults show that within a limited number of iterations our proposed model\nlearns an effective scaling policy per workload, improving the performance\ncompared to the default auto-scaling configuration.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 06:18:39 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Schuler", "Lucia", ""], ["Jamil", "Somaya", ""], ["K\u00fchl", "Niklas", ""]]}, {"id": "2005.14415", "submitter": "Guangfeng Lin", "authors": "Guangfeng Lin, Ying Yang, Yindi Fan, Xiaobing Kang, Kaiyang Liao, and\n  Fan Zhao", "title": "High-order structure preserving graph neural network for few-shot\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Few-shot learning can find the latent structure information between the prior\nknowledge and the queried data by the similarity metric of meta-learning to\nconstruct the discriminative model for recognizing the new categories with the\nrare labeled samples. Most existing methods try to model the similarity\nrelationship of the samples in the intra tasks, and generalize the model to\nidentify the new categories. However, the relationship of samples between the\nseparated tasks is difficultly considered because of the different metric\ncriterion in the respective tasks. In contrast, the proposed high-order\nstructure preserving graph neural network(HOSP-GNN) can further explore the\nrich structure of the samples to predict the label of the queried data on graph\nthat enables the structure evolution to explicitly discriminate the categories\nby iteratively updating the high-order structure relationship (the relative\nmetric in multi-samples,instead of pairwise sample metric) with the manifold\nstructure constraints. HOSP-GNN can not only mine the high-order structure for\ncomplementing the relevance between samples that may be divided into the\ndifferent task in meta-learning, and but also generate the rule of the\nstructure updating by manifold constraint. Furthermore, HOSP-GNN doesn't need\nretrain the learning model for recognizing the new classes, and HOSP-GNN has\nthe well-generalizable high-order structure for model adaptability. Experiments\nshow that HOSP-GNN outperforms the state-of-the-art methods on supervised and\nsemi-supervised few-shot learning in three benchmark datasets that are\nminiImageNet, tieredImageNet and FC100.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 06:38:51 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Lin", "Guangfeng", ""], ["Yang", "Ying", ""], ["Fan", "Yindi", ""], ["Kang", "Xiaobing", ""], ["Liao", "Kaiyang", ""], ["Zhao", "Fan", ""]]}, {"id": "2005.14419", "submitter": "Paul Weng", "authors": "Olivier Buffet, Olivier Pietquin, Paul Weng", "title": "Reinforcement Learning", "comments": "Chapter in \"A Guided Tour of Artificial Intelligence Research\",\n  Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is a general framework for adaptive control,\nwhich has proven to be efficient in many domains, e.g., board games, video\ngames or autonomous vehicles. In such problems, an agent faces a sequential\ndecision-making problem where, at every time step, it observes its state,\nperforms an action, receives a reward and moves to a new state. An RL agent\nlearns by trial and error a good policy (or controller) based on observations\nand numeric reward feedback on the previously performed action. In this\nchapter, we present the basic framework of RL and recall the two main families\nof approaches that have been developed to learn a good policy. The first one,\nwhich is value-based, consists in estimating the value of an optimal policy,\nvalue from which a policy can be recovered, while the other, called policy\nsearch, directly works in a policy space. Actor-critic methods can be seen as a\npolicy search technique where the policy value that is learned guides the\npolicy improvement. Besides, we give an overview of some extensions of the\nstandard RL framework, notably when risk-averse behavior needs to be taken into\naccount or when rewards are not available or not known.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 06:53:29 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 05:19:26 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Buffet", "Olivier", ""], ["Pietquin", "Olivier", ""], ["Weng", "Paul", ""]]}, {"id": "2005.14424", "submitter": "Mao Ye", "authors": "Mao Ye, Chengyue Gong, Qiang Liu", "title": "SAFER: A Structure-free Approach for Certified Robustness to Adversarial\n  Word Substitutions", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art NLP models can often be fooled by human-unaware\ntransformations such as synonymous word substitution. For security reasons, it\nis of critical importance to develop models with certified robustness that can\nprovably guarantee that the prediction is can not be altered by any possible\nsynonymous word substitution. In this work, we propose a certified robust\nmethod based on a new randomized smoothing technique, which constructs a\nstochastic ensemble by applying random word substitutions on the input\nsentences, and leverage the statistical properties of the ensemble to provably\ncertify the robustness. Our method is simple and structure-free in that it only\nrequires the black-box queries of the model outputs, and hence can be applied\nto any pre-trained models (such as BERT) and any types of models (world-level\nor subword-level). Our method significantly outperforms recent state-of-the-art\nmethods for certified robustness on both IMDB and Amazon text classification\ntasks. To the best of our knowledge, we are the first work to achieve certified\nrobustness on large systems such as BERT with practically meaningful certified\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 07:15:19 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Ye", "Mao", ""], ["Gong", "Chengyue", ""], ["Liu", "Qiang", ""]]}, {"id": "2005.14425", "submitter": "Srinivas Kota Reddy", "authors": "Sahasrajit Sarmasarkar, Kota Srinivas Reddy, and Nikhil Karamchandani", "title": "Query complexity of heavy hitter estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DS cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of identifying the subset\n$\\mathcal{S}^{\\gamma}_{\\mathcal{P}}$ of elements in the support of an\nunderlying distribution $\\mathcal{P}$ whose probability value is larger than a\ngiven threshold $\\gamma$, by actively querying an oracle to gain information\nabout a sequence $X_1, X_2, \\ldots$ of $i.i.d.$ samples drawn from\n$\\mathcal{P}$. We consider two query models: $(a)$ each query is an index $i$\nand the oracle return the value $X_i$ and $(b)$ each query is a pair $(i,j)$\nand the oracle gives a binary answer confirming if $X_i = X_j$ or not. For each\nof these query models, we design sequential estimation algorithms which at each\nround, either decide what query to send to the oracle depending on the entire\nhistory of responses or decide to stop and output an estimate of\n$\\mathcal{S}^{\\gamma}_{\\mathcal{P}}$, which is required to be correct with some\npre-specified large probability. We provide upper bounds on the query\ncomplexity of the algorithms for any distribution $\\mathcal{P}$ and also derive\nlower bounds on the optimal query complexity under the two query models. We\nalso consider noisy versions of the two query models and propose robust\nestimators which can effectively counter the noise in the oracle responses.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 07:15:46 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 12:18:38 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Sarmasarkar", "Sahasrajit", ""], ["Reddy", "Kota Srinivas", ""], ["Karamchandani", "Nikhil", ""]]}, {"id": "2005.14426", "submitter": "Quanquan Gu", "authors": "Spencer Frei and Yuan Cao and Quanquan Gu", "title": "Agnostic Learning of a Single Neuron with Gradient Descent", "comments": "31 pages, 3 tables. This version improves the risk bound from\n  O(OPT^1/2) to O(OPT) for strictly increasing activation functions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning the best-fitting single neuron as\nmeasured by the expected square loss $\\mathbb{E}_{(x,y)\\sim\n\\mathcal{D}}[(\\sigma(w^\\top x)-y)^2]$ over some unknown joint distribution\n$\\mathcal{D}$ by using gradient descent to minimize the empirical risk induced\nby a set of i.i.d. samples $S\\sim \\mathcal{D}^n$. The activation function\n$\\sigma$ is an arbitrary Lipschitz and non-decreasing function, making the\noptimization problem nonconvex and nonsmooth in general, and covers typical\nneural network activation functions and inverse link functions in the\ngeneralized linear model setting. In the agnostic PAC learning setting, where\nno assumption on the relationship between the labels $y$ and the input $x$ is\nmade, if the optimal population risk is $\\mathsf{OPT}$, we show that gradient\ndescent achieves population risk $O(\\mathsf{OPT})+\\epsilon$ in polynomial time\nand sample complexity when $\\sigma$ is strictly increasing. For the ReLU\nactivation, our population risk guarantee is $O(\\mathsf{OPT}^{1/2})+\\epsilon$.\nWhen labels take the form $y = \\sigma(v^\\top x) + \\xi$ for zero-mean\nsub-Gaussian noise $\\xi$, we show that the population risk guarantees for\ngradient descent improve to $\\mathsf{OPT} + \\epsilon$. Our sample complexity\nand runtime guarantees are (almost) dimension independent, and when $\\sigma$ is\nstrictly increasing, require no distributional assumptions beyond boundedness.\nFor ReLU, we show the same results under a nondegeneracy assumption for the\nmarginal distribution of the input.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 07:20:35 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 17:43:43 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2020 17:19:08 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Frei", "Spencer", ""], ["Cao", "Yuan", ""], ["Gu", "Quanquan", ""]]}, {"id": "2005.14436", "submitter": "Duccio Fanelli", "authors": "Lorenzo Giambagli, Lorenzo Buffoni, Timoteo Carletti, Walter\n  Nocentini, Duccio Fanelli", "title": "Machine learning in spectral domain", "comments": null, "journal-ref": null, "doi": "10.1038/s41467-021-21481-0", "report-no": null, "categories": "cs.LG cond-mat.stat-mech eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are usually trained in the space of the nodes, by\nadjusting the weights of existing links via suitable optimization protocols. We\nhere propose a radically new approach which anchors the learning process to\nreciprocal space. Specifically, the training acts on the spectral domain and\nseeks to modify the eigenvalues and eigenvectors of transfer operators in\ndirect space. The proposed method is ductile and can be tailored to return\neither linear or non-linear classifiers. Adjusting the eigenvalues, when\nfreezing the eigenvectors entries, yields performances which are superior to\nthose attained with standard methods {\\it restricted} to a operate with an\nidentical number of free parameters. Tuning the eigenvalues correspond in fact\nto performing a global training of the neural network, a procedure which\npromotes (resp. inhibits) collective modes on which an effective information\nprocessing relies. This is at variance with the usual approach to learning\nwhich implements instead a local modulation of the weights associated to\npairwise links. Interestingly, spectral learning limited to the eigenvalues\nreturns a distribution of the predicted weights which is close to that obtained\nwhen training the neural network in direct space, with no restrictions on the\nparameters to be tuned. Based on the above, it is surmised that spectral\nlearning bound to the eigenvalues could be also employed for pre-training of\ndeep neural networks, in conjunction with conventional machine-learning\nschemes. Changing the eigenvectors to a different non-orthogonal basis alters\nthe topology of the network in direct space and thus allows to export the\nspectral learning strategy to other frameworks, as e.g. reservoir computing.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 07:55:37 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 16:13:09 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Giambagli", "Lorenzo", ""], ["Buffoni", "Lorenzo", ""], ["Carletti", "Timoteo", ""], ["Nocentini", "Walter", ""], ["Fanelli", "Duccio", ""]]}, {"id": "2005.14456", "submitter": "Yixing Xu", "authors": "Yunhe Wang, Yixing Xu, Dacheng Tao", "title": "DC-NAS: Divide-and-Conquer Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most applications demand high-performance deep neural architectures costing\nlimited resources. Neural architecture searching is a way of automatically\nexploring optimal deep neural networks in a given huge search space. However,\nall sub-networks are usually evaluated using the same criterion; that is, early\nstopping on a small proportion of the training dataset, which is an inaccurate\nand highly complex approach. In contrast to conventional methods, here we\npresent a divide-and-conquer (DC) approach to effectively and efficiently\nsearch deep neural architectures. Given an arbitrary search space, we first\nextract feature representations of all sub-networks according to changes in\nparameters or output features of each layer, and then calculate the similarity\nbetween two different sampled networks based on the representations. Then, a\nk-means clustering is conducted to aggregate similar architectures into the\nsame cluster, separately executing sub-network evaluation in each cluster. The\nbest architecture in each cluster is later merged to obtain the optimal neural\narchitecture. Experimental results conducted on several benchmarks illustrate\nthat DC-NAS can overcome the inaccurate evaluation problem, achieving a\n$75.1\\%$ top-1 accuracy on the ImageNet dataset, which is higher than that of\nstate-of-the-art methods using the same search space.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 09:02:16 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Wang", "Yunhe", ""], ["Xu", "Yixing", ""], ["Tao", "Dacheng", ""]]}, {"id": "2005.14458", "submitter": "Domagoj \\'Cevid MMath", "authors": "Domagoj \\'Cevid, Loris Michel, Jeffrey N\\\"af, Nicolai Meinshausen,\n  Peter B\\\"uhlmann", "title": "Distributional Random Forests: Heterogeneity Adjustment and Multivariate\n  Distributional Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Forests (Breiman, 2001) is a successful and widely used regression and\nclassification algorithm. Part of its appeal and reason for its versatility is\nits (implicit) construction of a kernel-type weighting function on training\ndata, which can also be used for targets other than the original mean\nestimation. We propose a novel forest construction for multivariate responses\nbased on their joint conditional distribution, independent of the estimation\ntarget and the data model. It uses a new splitting criterion based on the MMD\ndistributional metric, which is suitable for detecting heterogeneity in\nmultivariate distributions. The induced weights define an estimate of the full\nconditional distribution, which in turn can be used for arbitrary and\npotentially complicated targets of interest. The method is very versatile and\nconvenient to use, as we illustrate on a wide range of examples. The code is\navailable as Python and R packages drf.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 09:05:00 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 20:21:04 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["\u0106evid", "Domagoj", ""], ["Michel", "Loris", ""], ["N\u00e4f", "Jeffrey", ""], ["Meinshausen", "Nicolai", ""], ["B\u00fchlmann", "Peter", ""]]}, {"id": "2005.14501", "submitter": "Kevin Fauvel", "authors": "Kevin Fauvel, V\\'eronique Masson, \\'Elisa Fromont", "title": "A Performance-Explainability Framework to Benchmark Machine Learning\n  Methods: Application to Multivariate Time Series Classifiers", "comments": "In Proceedings of the IJCAI-PRICAI 2020 Workshop on Explainable\n  Artificial Intelligence. An example of this framework in use is available in\n  arXiv:2005.03645", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our research aims to propose a new performance-explainability analytical\nframework to assess and benchmark machine learning methods. The framework\ndetails a set of characteristics that systematize the\nperformance-explainability assessment of existing machine learning methods. In\norder to illustrate the use of the framework, we apply it to benchmark the\ncurrent state-of-the-art multivariate time series classifiers.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 11:08:31 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 10:49:05 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2020 06:45:12 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2020 10:44:26 GMT"}, {"version": "v5", "created": "Fri, 18 Dec 2020 17:29:31 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Fauvel", "Kevin", ""], ["Masson", "V\u00e9ronique", ""], ["Fromont", "\u00c9lisa", ""]]}, {"id": "2005.14502", "submitter": "Uzair Nadeem", "authors": "Uzair Nadeem, Mohammed Bennamoun, Roberto Togneri, Ferdous Sohel", "title": "Unconstrained Matching of 2D and 3D Descriptors for 6-DOF Pose\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel concept to directly match feature descriptors\nextracted from 2D images with feature descriptors extracted from 3D point\nclouds. We use this concept to directly localize images in a 3D point cloud. We\ngenerate a dataset of matching 2D and 3D points and their corresponding feature\ndescriptors, which is used to learn a Descriptor-Matcher classifier. To\nlocalize the pose of an image at test time, we extract keypoints and feature\ndescriptors from the query image. The trained Descriptor-Matcher is then used\nto match the features from the image and the point cloud. The locations of the\nmatched features are used in a robust pose estimation algorithm to predict the\nlocation and orientation of the query image. We carried out an extensive\nevaluation of the proposed method for indoor and outdoor scenarios and with\ndifferent types of point clouds to verify the feasibility of our approach.\nExperimental results demonstrate that direct matching of feature descriptors\nfrom images and point clouds is not only a viable idea but can also be reliably\nused to estimate the 6-DOF poses of query cameras in any type of 3D point cloud\nin an unconstrained manner with high precision.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 11:17:32 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Nadeem", "Uzair", ""], ["Bennamoun", "Mohammed", ""], ["Togneri", "Roberto", ""], ["Sohel", "Ferdous", ""]]}, {"id": "2005.14506", "submitter": "Philip Blagoveschensky", "authors": "Philip Blagoveschensky, Anh Huy Phan", "title": "Deep convolutional tensor network", "comments": "14 pages, 18 figures, to be published in the proceedings of NeurIPS\n  2020 Quantum tensor networks in machine learning workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks have achieved state of the art results in many areas,\nsupposedly due to parameter sharing, locality, and depth. Tensor networks (TNs)\nare linear algebraic representations of quantum many-body states based on their\nentanglement structure. TNs have found use in machine learning. We devise a\nnovel TN based model called Deep convolutional tensor network (DCTN) for image\nclassification, which has parameter sharing, locality, and depth. It is based\non the Entangled plaquette states (EPS) TN. We show how EPS can be implemented\nas a backpropagatable layer. We test DCTN on MNIST, FashionMNIST, and CIFAR10\ndatasets. A shallow DCTN performs well on MNIST and FashionMNIST and has a\nsmall parameter count. Unfortunately, depth increases overfitting and thus\ndecreases test accuracy. Also, DCTN of any depth performs badly on CIFAR10 due\nto overfitting. It is to be determined why. We discuss how the hyperparameters\nof DCTN affect its training and overfitting.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 11:36:52 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 21:25:00 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Blagoveschensky", "Philip", ""], ["Phan", "Anh Huy", ""]]}, {"id": "2005.14517", "submitter": "Zahid Iqbal", "authors": "Affan Idrees, Zahid Iqbal, Maria Ishfaq", "title": "An Efficient Indoor Navigation Technique To Find Optimal Route For\n  Blinds Using QR Codes", "comments": "IEEE 10th Conference on Industrial Electronics and Applications\n  (ICIEA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blind navigation is an accessibility application that enables blind to use an\nandroid Smartphone in an easy way for indoor navigation with instructions in\naudio form. We have proposed a prototype which is an indoor navigation\napplication for blinds that uses QR codes. It is developed for android Smart\nphones and does not require any additional hardware for navigation. It provides\nautomatic navigational assistance on pre-defined paths for blind. QR codes are\nplaced on the floor sections after specific distance that acts as an input for\ncurrent location detection and navigation. Whenever a QR code is scanned it\nprovides the user with the information of the current location and asks the\nuser to select the destination and then offers optimal and shortest path using\npath finding algorithms. During navigation whenever the deviation from the\nproposed path is detected it prompts the user and guides back to the right path\nby comparing the current path with the generated path. All of the instructions\nthroughout the application are provided in audio form to the user. The\ninterface of the application is well built for blinds which makes the smart\nphones user-friendly and useable for blind people. The user interacts with the\napplication through a specific set of user-friendly gestures for specific\ninputs and operations. At the end, we have performed comparison between\ndifferent state of art approaches and concluded that our approach is more user\nfriendly, cost effective and produced more accurate results.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 12:19:25 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Idrees", "Affan", ""], ["Iqbal", "Zahid", ""], ["Ishfaq", "Maria", ""]]}, {"id": "2005.14565", "submitter": "Cristiano Premebida", "authors": "G. Melotti, C. Premebida, J.J. Bird, D.R. Faria, N. Gon\\c{c}alves", "title": "Probabilistic Object Classification using CNN ML-MAP layers", "comments": "Accepted at the Workshop on Perception for Autonomous Driving (PAD),\n  European Conference on Computer Vision (ECCV) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks are currently the state-of-the-art for sensory perception in\nautonomous driving and robotics. However, deep models often generate\noverconfident predictions precluding proper probabilistic interpretation which\nwe argue is due to the nature of the SoftMax layer. To reduce the\noverconfidence without compromising the classification performance, we\nintroduce a CNN probabilistic approach based on distributions calculated in the\nnetwork's Logit layer. The approach enables Bayesian inference by means of ML\nand MAP layers. Experiments with calibrated and the proposed prediction layers\nare carried out on object classification using data from the KITTI database.\nResults are reported for camera ($RGB$) and LiDAR (range-view) modalities,\nwhere the new approach shows promising performance compared to SoftMax.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 13:34:15 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 11:37:53 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Melotti", "G.", ""], ["Premebida", "C.", ""], ["Bird", "J. J.", ""], ["Faria", "D. R.", ""], ["Gon\u00e7alves", "N.", ""]]}, {"id": "2005.14601", "submitter": "Jingfan Chen", "authors": "Jingfan Chen, Guanghui Zhu, Chunfeng Yuan, Yihua Huang", "title": "Semi-supervised Embedding Learning for High-dimensional Bayesian\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is a broadly applied methodology to optimize the\nexpensive black-box function. Despite its success, it still faces the challenge\nfrom the high-dimensional search space. To alleviate this problem, we propose a\nnovel Bayesian optimization framework (termed SILBO), which finds a\nlow-dimensional space to perform Bayesian optimization iteratively through\nsemi-supervised dimension reduction. SILBO incorporates both labeled points and\nunlabeled points acquired from the acquisition function to guide the embedding\nspace learning. To accelerate the learning procedure, we present a randomized\nmethod for generating the projection matrix. Furthermore, to map from the\nlow-dimensional space to the high-dimensional original space, we propose two\nmapping strategies: $\\text{SILBO}_{FZ}$ and $\\text{SILBO}_{FX}$ according to\nthe evaluation overhead of the objective function. Experimental results on both\nsynthetic function and hyperparameter optimization tasks demonstrate that SILBO\noutperforms the existing state-of-the-art high-dimensional Bayesian\noptimization methods.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 14:37:12 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 11:48:16 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 05:36:39 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Chen", "Jingfan", ""], ["Zhu", "Guanghui", ""], ["Yuan", "Chunfeng", ""], ["Huang", "Yihua", ""]]}, {"id": "2005.14605", "submitter": "Alexander Borisenko", "authors": "Oleksandr Borysenko and Maksym Byshkin", "title": "CoolMomentum: A Method for Stochastic Optimization by Langevin Dynamics\n  with Simulated Annealing", "comments": "9 pages, 2 figures", "journal-ref": "Borysenko, O., Byshkin, M. CoolMomentum: a method for stochastic\n  optimization by Langevin dynamics with simulated annealing. Sci Rep 11, 10705\n  (2021)", "doi": "10.1038/s41598-021-90144-3", "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning applications require global optimization of non-convex\nobjective functions, which have multiple local minima. The same problem is\noften found in physical simulations and may be resolved by the methods of\nLangevin dynamics with Simulated Annealing, which is a well-established\napproach for minimization of many-particle potentials. This analogy provides\nuseful insights for non-convex stochastic optimization in machine learning.\nHere we find that integration of the discretized Langevin equation gives a\ncoordinate updating rule equivalent to the famous Momentum optimization\nalgorithm. As a main result, we show that a gradual decrease of the momentum\ncoefficient from the initial value close to unity until zero is equivalent to\napplication of Simulated Annealing or slow cooling, in physical terms. Making\nuse of this novel approach, we propose CoolMomentum -- a new stochastic\noptimization method. Applying Coolmomentum to optimization of Resnet-20 on\nCifar-10 dataset and Efficientnet-B0 on Imagenet, we demonstrate that it is\nable to achieve high accuracies.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 14:44:24 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 15:26:37 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Borysenko", "Oleksandr", ""], ["Byshkin", "Maksym", ""]]}, {"id": "2005.14611", "submitter": "Lea Sch\\\"onherr", "authors": "Sina D\\\"aubener, Lea Sch\\\"onherr, Asja Fischer, Dorothea Kolossa", "title": "Detecting Adversarial Examples for Speech Recognition via Uncertainty\n  Quantification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CR cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems and also, specifically, automatic speech recognition\n(ASR) systems are vulnerable against adversarial attacks, where an attacker\nmaliciously changes the input. In the case of ASR systems, the most interesting\ncases are targeted attacks, in which an attacker aims to force the system into\nrecognizing given target transcriptions in an arbitrary audio sample. The\nincreasing number of sophisticated, quasi imperceptible attacks raises the\nquestion of countermeasures. In this paper, we focus on hybrid ASR systems and\ncompare four acoustic models regarding their ability to indicate uncertainty\nunder attack: a feed-forward neural network and three neural networks\nspecifically designed for uncertainty quantification, namely a Bayesian neural\nnetwork, Monte Carlo dropout, and a deep ensemble. We employ uncertainty\nmeasures of the acoustic model to construct a simple one-class classification\nmodel for assessing whether inputs are benign or adversarial. Based on this\napproach, we are able to detect adversarial examples with an area under the\nreceiving operator curve score of more than 0.99. The neural networks for\nuncertainty quantification simultaneously diminish the vulnerability to the\nattack, which is reflected in a lower recognition accuracy of the malicious\ntarget text in comparison to a standard hybrid ASR system.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 19:31:02 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 16:37:01 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["D\u00e4ubener", "Sina", ""], ["Sch\u00f6nherr", "Lea", ""], ["Fischer", "Asja", ""], ["Kolossa", "Dorothea", ""]]}, {"id": "2005.14612", "submitter": "Zhengyang Wang", "authors": "Meng Liu, Zhengyang Wang, Shuiwang Ji", "title": "Non-Local Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern graph neural networks (GNNs) learn node embeddings through multilayer\nlocal aggregation and achieve great success in applications on assortative\ngraphs. However, tasks on disassortative graphs usually require non-local\naggregation. In this work, we propose a simple yet effective non-local\naggregation framework with an efficient attention-guided sorting for GNNs.\nBased on it, we develop various non-local GNNs. We perform thorough experiments\nto analyze disassortative graph datasets and evaluate our non-local GNNs.\nExperimental results demonstrate that our non-local GNNs significantly\noutperform previous state-of-the-art methods on six benchmark datasets of\ndisassortative graphs, in terms of both model performance and efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 14:50:27 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Liu", "Meng", ""], ["Wang", "Zhengyang", ""], ["Ji", "Shuiwang", ""]]}, {"id": "2005.14617", "submitter": "Manuel Roehrl", "authors": "Manuel A. Roehrl, Thomas A. Runkler, Veronika Brandtstetter, Michel\n  Tokic, Stefan Obermayer", "title": "Modeling System Dynamics with Physics-Informed Neural Networks Based on\n  Lagrangian Mechanics", "comments": "Accepted for publication at the 21st IFAC World Congress 2020", "journal-ref": null, "doi": "10.1016/j.ifacol.2020.12.2182", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Identifying accurate dynamic models is required for the simulation and\ncontrol of various technical systems. In many important real-world\napplications, however, the two main modeling approaches often fail to meet\nrequirements: first principles methods suffer from high bias, whereas\ndata-driven modeling tends to have high variance. Additionally, purely\ndata-based models often require large amounts of data and are often difficult\nto interpret. In this paper, we present physics-informed neural ordinary\ndifferential equations (PINODE), a hybrid model that combines the two modeling\ntechniques to overcome the aforementioned problems. This new approach directly\nincorporates the equations of motion originating from the Lagrange Mechanics\ninto a deep neural network structure. Thus, we can integrate prior physics\nknowledge where it is available and use function approximation--e. g., neural\nnetworks--where it is not. The method is tested with a forward model of a\nreal-world physical system with large uncertainties. The resulting model is\naccurate and data-efficient while ensuring physical plausibility. With this, we\ndemonstrate a method that beneficially merges physical insight with real data.\nOur findings are of interest for model-based control and system identification\nof mechanical systems.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 15:10:43 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Roehrl", "Manuel A.", ""], ["Runkler", "Thomas A.", ""], ["Brandtstetter", "Veronika", ""], ["Tokic", "Michel", ""], ["Obermayer", "Stefan", ""]]}, {"id": "2005.14621", "submitter": "Ibrahim Alabdulmohsin", "authors": "Ibrahim Alabdulmohsin", "title": "Fair Classification via Unconstrained Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving the Bayes optimal binary classification rule subject to group\nfairness constraints is known to be reducible, in some cases, to learning a\ngroup-wise thresholding rule over the Bayes regressor. In this paper, we extend\nthis result by proving that, in a broader setting, the Bayes optimal fair\nlearning rule remains a group-wise thresholding rule over the Bayes regressor\nbut with a (possible) randomization at the thresholds. This provides a stronger\njustification to the post-processing approach in fair classification, in which\n(1) a predictor is learned first, after which (2) its output is adjusted to\nremove bias. We show how the post-processing rule in this two-stage approach\ncan be learned quite efficiently by solving an unconstrained optimization\nproblem. The proposed algorithm can be applied to any black-box machine\nlearning model, such as deep neural networks, random forests and support vector\nmachines. In addition, it can accommodate many fairness criteria that have been\npreviously proposed in the literature, such as equalized odds and statistical\nparity. We prove that the algorithm is Bayes consistent and motivate it,\nfurthermore, via an impossibility result that quantifies the tradeoff between\naccuracy and fairness across multiple demographic groups. Finally, we conclude\nby validating the algorithm on the Adult benchmark dataset.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 11:29:05 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Alabdulmohsin", "Ibrahim", ""]]}, {"id": "2005.14627", "submitter": "Md Gulzar Hussain", "authors": "Md Gulzar Hussain, Md Rashidul Hasan, Mahmuda Rahman, Joy Protim, and\n  Sakib Al Hasan", "title": "Detection of Bangla Fake News using MNB and SVM Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fake news has been coming into sight in significant numbers for numerous\nbusiness and political reasons and has become frequent in the online world.\nPeople can get contaminated easily by these fake news for its fabricated words\nwhich have enormous effects on the offline community. Thus, interest in\nresearch in this area has risen. Significant research has been conducted on the\ndetection of fake news from English texts and other languages but a few in\nBangla Language. Our work reflects the experimental analysis on the detection\nof Bangla fake news from social media as this field still requires much focus.\nIn this research work, we have used two supervised machine learning algorithms,\nMultinomial Naive Bayes (MNB) and Support Vector Machine (SVM) classifiers to\ndetect Bangla fake news with CountVectorizer and Term Frequency - Inverse\nDocument Frequency Vectorizer as feature extraction. Our proposed framework\ndetects fake news depending on the polarity of the corresponding article.\nFinally, our analysis shows SVM with the linear kernel with an accuracy of\n96.64% outperform MNB with an accuracy of 93.32%.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 15:38:54 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Hussain", "Md Gulzar", ""], ["Hasan", "Md Rashidul", ""], ["Rahman", "Mahmuda", ""], ["Protim", "Joy", ""], ["Hasan", "Sakib Al", ""]]}, {"id": "2005.14635", "submitter": "David Aparicio", "authors": "Joana Lorenz, Maria In\\^es Silva, David Apar\\'icio, Jo\\~ao Tiago\n  Ascens\\~ao, Pedro Bizarro", "title": "Machine learning methods to detect money laundering in the Bitcoin\n  blockchain in the presence of label scarcity", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every year, criminals launder billions of dollars acquired from serious\nfelonies (e.g., terrorism, drug smuggling, or human trafficking) harming\ncountless people and economies. Cryptocurrencies, in particular, have developed\nas a haven for money laundering activity. Machine Learning can be used to\ndetect these illicit patterns. However, labels are so scarce that traditional\nsupervised algorithms are inapplicable. Here, we address money laundering\ndetection assuming minimal access to labels. First, we show that existing\nstate-of-the-art solutions using unsupervised anomaly detection methods are\ninadequate to detect the illicit patterns in a real Bitcoin transaction\ndataset. Then, we show that our proposed active learning solution is capable of\nmatching the performance of a fully supervised baseline by using just 5\\% of\nthe labels. This solution mimics a typical real-life situation in which a\nlimited number of labels can be acquired through manual annotation by experts.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 15:52:48 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Lorenz", "Joana", ""], ["Silva", "Maria In\u00eas", ""], ["Apar\u00edcio", "David", ""], ["Ascens\u00e3o", "Jo\u00e3o Tiago", ""], ["Bizarro", "Pedro", ""]]}, {"id": "2005.14658", "submitter": "Cristi\\'an Bravo", "authors": "Luisa Roa, Alejandro Correa-Bahnsen, Gabriel Suarez, Fernando\n  Cort\\'es-Tejada, Mar\\'ia A. Luque and Cristi\\'an Bravo", "title": "Super-App Behavioral Patterns in Credit Risk Models: Financial,\n  Statistical and Regulatory Implications", "comments": "Accepted - v2. 25 pages", "journal-ref": "Expert Systems with Applications: 114486 (2020)", "doi": "10.1016/j.eswa.2020.114486", "report-no": null, "categories": "q-fin.GN cs.CY cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper we present the impact of alternative data that originates from\nan app-based marketplace, in contrast to traditional bureau data, upon credit\nscoring models. These alternative data sources have shown themselves to be\nimmensely powerful in predicting borrower behavior in segments traditionally\nunderserved by banks and financial institutions. Our results, validated across\ntwo countries, show that these new sources of data are particularly useful for\npredicting financial behavior in low-wealth and young individuals, who are also\nthe most likely to engage with alternative lenders. Furthermore, using the\nTreeSHAP method for Stochastic Gradient Boosting interpretation, our results\nalso revealed interesting non-linear trends in the variables originating from\nthe app, which would not normally be available to traditional banks. Our\nresults represent an opportunity for technology companies to disrupt\ntraditional banking by correctly identifying alternative data sources and\nhandling this new information properly. At the same time alternative data must\nbe carefully validated to overcome regulatory hurdles across diverse\njurisdictions.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 01:32:03 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 18:51:22 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Roa", "Luisa", ""], ["Correa-Bahnsen", "Alejandro", ""], ["Suarez", "Gabriel", ""], ["Cort\u00e9s-Tejada", "Fernando", ""], ["Luque", "Mar\u00eda A.", ""], ["Bravo", "Cristi\u00e1n", ""]]}, {"id": "2005.14664", "submitter": "Josef Urban", "authors": "Josef Urban and Jan Jakub\\r{u}v", "title": "First Neural Conjecturing Datasets and Experiments", "comments": "Accepted to CICM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.NE cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe several datasets and first experiments with creating conjectures\nby neural methods. The datasets are based on the Mizar Mathematical Library\nprocessed in several forms and the problems extracted from it by the MPTP\nsystem and proved by the E prover using the ENIGMA guidance. The conjecturing\nexperiments use the Transformer architecture and in particular its GPT-2\nimplementation.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 16:46:25 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Urban", "Josef", ""], ["Jakub\u016fv", "Jan", ""]]}, {"id": "2005.14670", "submitter": "Florian Ziel", "authors": "Florian Ziel", "title": "The energy distance for ensemble and scenario reduction", "comments": "Accepted for publication in Philosophical Transactions A", "journal-ref": null, "doi": "10.1098/rsta.2019.0431", "report-no": null, "categories": "stat.ML cs.LG math.OC q-fin.RM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scenario reduction techniques are widely applied for solving sophisticated\ndynamic and stochastic programs, especially in energy and power systems, but\nalso used in probabilistic forecasting, clustering and estimating generative\nadversarial networks (GANs). We propose a new method for ensemble and scenario\nreduction based on the energy distance which is a special case of the maximum\nmean discrepancy (MMD). We discuss the choice of energy distance in detail,\nespecially in comparison to the popular Wasserstein distance which is\ndominating the scenario reduction literature. The energy distance is a metric\nbetween probability measures that allows for powerful tests for equality of\narbitrary multivariate distributions or independence. Thanks to the latter, it\nis a suitable candidate for ensemble and scenario reduction problems. The\ntheoretical properties and considered examples indicate clearly that the\nreduced scenario sets tend to exhibit better statistical properties for the\nenergy distance than a corresponding reduction with respect to the Wasserstein\ndistance. We show applications to a Bernoulli random walk and two real data\nbased examples for electricity demand profiles and day-ahead electricity\nprices.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 16:52:23 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 18:46:10 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Ziel", "Florian", ""]]}, {"id": "2005.14679", "submitter": "Roberto Calandra", "authors": "Mike Lambeta and Po-Wei Chou and Stephen Tian and Brian Yang and\n  Benjamin Maloon and Victoria Rose Most and Dave Stroud and Raymond Santos and\n  Ahmad Byagowi and Gregg Kammerer and Dinesh Jayaraman and Roberto Calandra", "title": "DIGIT: A Novel Design for a Low-Cost Compact High-Resolution Tactile\n  Sensor with Application to In-Hand Manipulation", "comments": "8 pages, published in the IEEE Robotics and Automation Letters (RA-L)", "journal-ref": null, "doi": "10.1109/LRA.2020.2977257", "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite decades of research, general purpose in-hand manipulation remains one\nof the unsolved challenges of robotics. One of the contributing factors that\nlimit current robotic manipulation systems is the difficulty of precisely\nsensing contact forces -- sensing and reasoning about contact forces are\ncrucial to accurately control interactions with the environment. As a step\ntowards enabling better robotic manipulation, we introduce DIGIT, an\ninexpensive, compact, and high-resolution tactile sensor geared towards in-hand\nmanipulation. DIGIT improves upon past vision-based tactile sensors by\nminiaturizing the form factor to be mountable on multi-fingered hands, and by\nproviding several design improvements that result in an easier, more repeatable\nmanufacturing process, and enhanced reliability. We demonstrate the\ncapabilities of the DIGIT sensor by training deep neural network model-based\ncontrollers to manipulate glass marbles in-hand with a multi-finger robotic\nhand. To provide the robotic community access to reliable and low-cost tactile\nsensors, we open-source the DIGIT design at https://digit.ml/.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 17:07:54 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Lambeta", "Mike", ""], ["Chou", "Po-Wei", ""], ["Tian", "Stephen", ""], ["Yang", "Brian", ""], ["Maloon", "Benjamin", ""], ["Most", "Victoria Rose", ""], ["Stroud", "Dave", ""], ["Santos", "Raymond", ""], ["Byagowi", "Ahmad", ""], ["Kammerer", "Gregg", ""], ["Jayaraman", "Dinesh", ""], ["Calandra", "Roberto", ""]]}, {"id": "2005.14683", "submitter": "Christoph Martin", "authors": "Christoph Martin, Meike Riebeling", "title": "A Process for the Evaluation of Node Embedding Methods in the Context of\n  Node Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Node embedding methods find latent lower-dimensional representations which\nare used as features in machine learning models. In the last few years, these\nmethods have become extremely popular as a replacement for manual feature\nengineering. Since authors use various approaches for the evaluation of node\nembedding methods, existing studies can rarely be efficiently and accurately\ncompared. We address this issue by developing a process for a fair and\nobjective evaluation of node embedding procedures w.r.t. node classification.\nThis process supports researchers and practitioners to compare new and existing\nmethods in a reproducible way. We apply this process to four popular node\nembedding methods and make valuable observations. With an appropriate\ncombination of hyperparameters, good performance can be achieved even with\nembeddings of lower dimensions, which is positive for the run times of the\ndownstream machine learning task and the embedding algorithm. Multiple\nhyperparameter combinations yield similar performance. Thus, no extensive,\ntime-consuming search is required to achieve reasonable performance in most\ncases.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 17:20:19 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Martin", "Christoph", ""], ["Riebeling", "Meike", ""]]}, {"id": "2005.14695", "submitter": "Micha Pfeiffer", "authors": "Micha Pfeiffer, Carina Riediger, Stefan Leger, Jens-Peter K\\\"uhn,\n  Danilo Seppelt, Ralf-Thorsten Hoffmann, J\\\"urgen Weitz and Stefanie Speidel", "title": "Non-Rigid Volume to Surface Registration using a Data-Driven\n  Biomechanical Model", "comments": "Provisionally accepted for MICCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.GR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Non-rigid registration is a key component in soft-tissue navigation. We focus\non laparoscopic liver surgery, where we register the organ model obtained from\na preoperative CT scan to the intraoperative partial organ surface,\nreconstructed from the laparoscopic video. This is a challenging task due to\nsparse and noisy intraoperative data, real-time requirements and many unknowns\n- such as tissue properties and boundary conditions. Furthermore, establishing\ncorrespondences between pre- and intraoperative data can be extremely difficult\nsince the liver usually lacks distinct surface features and the used imaging\nmodalities suffer from very different types of noise. In this work, we train a\nconvolutional neural network to perform both the search for surface\ncorrespondences as well as the non-rigid registration in one step. The network\nis trained on physically accurate biomechanical simulations of randomly\ngenerated, deforming organ-like structures. This enables the network to\nimmediately generalize to a new patient organ without the need to re-train. We\nadd various amounts of noise to the intraoperative surfaces during training,\nmaking the network robust to noisy intraoperative data. During inference, the\nnetwork outputs the displacement field which matches the preoperative volume to\nthe partial intraoperative surface. In multiple experiments, we show that the\nnetwork translates well to real data while maintaining a high inference speed.\nOur code is made available online.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 17:35:23 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Pfeiffer", "Micha", ""], ["Riediger", "Carina", ""], ["Leger", "Stefan", ""], ["K\u00fchn", "Jens-Peter", ""], ["Seppelt", "Danilo", ""], ["Hoffmann", "Ralf-Thorsten", ""], ["Weitz", "J\u00fcrgen", ""], ["Speidel", "Stefanie", ""]]}, {"id": "2005.14707", "submitter": "Charles Jin", "authors": "Charles Jin, Martin Rinard", "title": "Learning From Context-Agnostic Synthetic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach for synthesizing training data given only a single\nexample of each class. Rather than learn over a large but fixed dataset of\nexamples, we generate our entire training set using only the synthetic examples\nprovided. The goal is to learn a classifier that generalizes to a non-synthetic\ndomain without pretraining or fine-tuning on any real world data. We evaluate\nour approach by training neural networks for two standard benchmarks for\nreal-world image classification: on the GTSRB traffic sign recognition\nbenchmark, we achieve 96% test accuracy using only one clean example of each\nsign on a blank background; on the MNIST handwritten digit benchmark, we\nachieve 90% test accuracy using a single example of each digit taken from a\ncomputer font. Our performance is competitive with state-of-the-art results\nfrom the few-shot learning and domain transfer literature, while using\nsignificantly less data.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 17:53:25 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 22:50:20 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Jin", "Charles", ""], ["Rinard", "Martin", ""]]}, {"id": "2005.14708", "submitter": "Prasanna Sanjay Raut", "authors": "Prasanna Sanjay Raut, Omid Sadeghi and Maryam Fazel", "title": "Online DR-Submodular Maximization with Stochastic Cumulative Constraints", "comments": "To appear in proceedings of AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider online continuous DR-submodular maximization with\nlinear stochastic long-term constraints. Compared to the prior work on online\nsubmodular maximization, our setting introduces the extra complication of\nstochastic linear constraint functions that are i.i.d. generated at each round.\nTo be precise, at step $t\\in\\{1,\\dots,T\\}$, a DR-submodular utility function\n$f_t(\\cdot)$ and a constraint vector $p_t$, i.i.d. generated from an unknown\ndistribution with mean $p$, are revealed after committing to an action $x_t$\nand we aim to maximize the overall utility while the expected cumulative\nresource consumption $\\sum_{t=1}^T \\langle p,x_t\\rangle$ is below a fixed\nbudget $B_T$. Stochastic long-term constraints arise naturally in applications\nwhere there is a limited budget or resource available and resource consumption\nat each step is governed by stochastically time-varying environments. We\npropose the Online Lagrangian Frank-Wolfe (OLFW) algorithm to solve this class\nof online problems. We analyze the performance of the OLFW algorithm and we\nobtain sub-linear regret bounds as well as sub-linear cumulative constraint\nviolation bounds, both in expectation and with high probability.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 17:55:42 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 02:02:50 GMT"}, {"version": "v3", "created": "Fri, 21 May 2021 14:45:10 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Raut", "Prasanna Sanjay", ""], ["Sadeghi", "Omid", ""], ["Fazel", "Maryam", ""]]}, {"id": "2005.14717", "submitter": "Lydia Zakynthinou", "authors": "Anamay Chaturvedi, Huy Nguyen, Lydia Zakynthinou", "title": "Differentially Private Decomposable Submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of differentially private constrained maximization of\ndecomposable submodular functions. A submodular function is decomposable if it\ntakes the form of a sum of submodular functions. The special case of maximizing\na monotone, decomposable submodular function under cardinality constraints is\nknown as the Combinatorial Public Projects (CPP) problem [Papadimitriou et al.,\n2008]. Previous work by Gupta et al. [2010] gave a differentially private\nalgorithm for the CPP problem. We extend this work by designing differentially\nprivate algorithms for both monotone and non-monotone decomposable submodular\nmaximization under general matroid constraints, with competitive utility\nguarantees. We complement our theoretical bounds with experiments demonstrating\nempirical performance, which improves over the differentially private\nalgorithms for the general case of submodular maximization and is close to the\nperformance of non-private algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 17:59:46 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Chaturvedi", "Anamay", ""], ["Nguyen", "Huy", ""], ["Zakynthinou", "Lydia", ""]]}]