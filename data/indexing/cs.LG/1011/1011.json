[{"id": "1011.0041", "submitter": "Byron Boots", "authors": "Byron Boots and Geoffrey J. Gordon", "title": "Predictive State Temporal Difference Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach to value function approximation which combines\nlinear temporal difference reinforcement learning with subspace identification.\nIn practical applications, reinforcement learning (RL) is complicated by the\nfact that state is either high-dimensional or partially observable. Therefore,\nRL methods are designed to work with features of state rather than state\nitself, and the success or failure of learning is often determined by the\nsuitability of the selected features. By comparison, subspace identification\n(SSID) methods are designed to select a feature set which preserves as much\ninformation as possible about state. In this paper we connect the two\napproaches, looking at the problem of reinforcement learning with a large set\nof features, each of which may only be marginally useful for value function\napproximation. We introduce a new algorithm for this situation, called\nPredictive State Temporal Difference (PSTD) learning. As in SSID for predictive\nstate representations, PSTD finds a linear compression operator that projects a\nlarge set of features down to a small set that preserves the maximum amount of\npredictive information. As in RL, PSTD then uses a Bellman recursion to\nestimate a value function. We discuss the connection between PSTD and prior\napproaches in RL and SSID. We prove that PSTD is statistically consistent,\nperform several experiments that illustrate its properties, and demonstrate its\npotential on a difficult optimal stopping problem.\n", "versions": [{"version": "v1", "created": "Sat, 30 Oct 2010 03:09:11 GMT"}, {"version": "v2", "created": "Tue, 18 Jan 2011 02:04:12 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Boots", "Byron", ""], ["Gordon", "Geoffrey J.", ""]]}, {"id": "1011.0097", "submitter": "Shiqian Ma", "authors": "Katya Scheinberg, Shiqian Ma, Donald Goldfarb", "title": "Sparse Inverse Covariance Selection via Alternating Linearization\n  Methods", "comments": null, "journal-ref": "NIPS 2010", "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian graphical models are of great interest in statistical learning.\nBecause the conditional independencies between different nodes correspond to\nzero entries in the inverse covariance matrix of the Gaussian distribution, one\ncan learn the structure of the graph by estimating a sparse inverse covariance\nmatrix from sample data, by solving a convex maximum likelihood problem with an\n$\\ell_1$-regularization term. In this paper, we propose a first-order method\nbased on an alternating linearization technique that exploits the problem's\nspecial structure; in particular, the subproblems solved in each iteration have\nclosed-form solutions. Moreover, our algorithm obtains an $\\epsilon$-optimal\nsolution in $O(1/\\epsilon)$ iterations. Numerical experiments on both synthetic\nand real data from gene association networks show that a practical version of\nthis algorithm outperforms other competitive algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 30 Oct 2010 18:30:43 GMT"}], "update_date": "2010-11-02", "authors_parsed": [["Scheinberg", "Katya", ""], ["Ma", "Shiqian", ""], ["Goldfarb", "Donald", ""]]}, {"id": "1011.0350", "submitter": "Laszlo Juracz", "authors": "Laszlo Juracz", "title": "Developing courses with HoloRena, a framework for scenario- and game\n  based e-learning environments", "comments": "18 pages", "journal-ref": "International Journal of Software Engineering & Applications\n  (IJSEA), October 2010, Volume 1, Number 4", "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  However utilizing rich, interactive solutions can make learning more\neffective and attractive, scenario- and game-based educational resources on the\nweb are not widely used. Creating these applications is a complex, expensive\nand challenging process. Development frameworks and authoring tools hardly\nsupport reusable components, teamwork and learning management\nsystem-independent courseware architecture. In this article we initiate the\nconcept of a low-level, thick-client solution addressing these problems. With\nsome example applications we try to demonstrate, how a framework, based on this\nconcept can be useful for developing scenario- and game-based e-learning\nenvironments.\n", "versions": [{"version": "v1", "created": "Mon, 1 Nov 2010 15:40:31 GMT"}], "update_date": "2010-11-02", "authors_parsed": [["Juracz", "Laszlo", ""]]}, {"id": "1011.0415", "submitter": "Morteza Ibrahimi", "authors": "Jos\\'e Bento, Morteza Ibrahimi, and Andrea Montanari", "title": "Learning Networks of Stochastic Differential Equations", "comments": "This publication is to appear in NIPS 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cond-mat.stat-mech cs.IT cs.LG math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider linear models for stochastic dynamics. To any such model can be\nassociated a network (namely a directed graph) describing which degrees of\nfreedom interact under the dynamics. We tackle the problem of learning such a\nnetwork from observation of the system trajectory over a time interval $T$.\n  We analyze the $\\ell_1$-regularized least squares algorithm and, in the\nsetting in which the underlying network is sparse, we prove performance\nguarantees that are \\emph{uniform in the sampling rate} as long as this is\nsufficiently high. This result substantiates the notion of a well defined `time\ncomplexity' for the network inference problem.\n", "versions": [{"version": "v1", "created": "Mon, 1 Nov 2010 19:09:57 GMT"}], "update_date": "2011-03-01", "authors_parsed": [["Bento", "Jos\u00e9", ""], ["Ibrahimi", "Morteza", ""], ["Montanari", "Andrea", ""]]}, {"id": "1011.0450", "submitter": "Vassilis Kekatos", "authors": "Vassilis Kekatos and Georgios B. Giannakis", "title": "From Sparse Signals to Sparse Residuals for Robust Sensing", "comments": "Under review for publication in the IEEE Transactions on Signal\n  Processing (revised version)", "journal-ref": null, "doi": "10.1109/TSP.2011.2141661", "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key challenges in sensor networks is the extraction of information\nby fusing data from a multitude of distinct, but possibly unreliable sensors.\nRecovering information from the maximum number of dependable sensors while\nspecifying the unreliable ones is critical for robust sensing. This sensing\ntask is formulated here as that of finding the maximum number of feasible\nsubsystems of linear equations, and proved to be NP-hard. Useful links are\nestablished with compressive sampling, which aims at recovering vectors that\nare sparse. In contrast, the signals here are not sparse, but give rise to\nsparse residuals. Capitalizing on this form of sparsity, four sensing schemes\nwith complementary strengths are developed. The first scheme is a convex\nrelaxation of the original problem expressed as a second-order cone program\n(SOCP). It is shown that when the involved sensing matrices are Gaussian and\nthe reliable measurements are sufficiently many, the SOCP can recover the\noptimal solution with overwhelming probability. The second scheme is obtained\nby replacing the initial objective function with a concave one. The third and\nfourth schemes are tailored for noisy sensor data. The noisy case is cast as a\ncombinatorial problem that is subsequently surrogated by a (weighted) SOCP.\nInterestingly, the derived cost functions fall into the framework of robust\nmultivariate linear regression, while an efficient block-coordinate descent\nalgorithm is developed for their minimization. The robust sensing capabilities\nof all schemes are verified by simulated tests.\n", "versions": [{"version": "v1", "created": "Mon, 1 Nov 2010 20:59:12 GMT"}, {"version": "v2", "created": "Sun, 27 Mar 2011 20:05:18 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Kekatos", "Vassilis", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1011.0472", "submitter": "Xinhua Zhang", "authors": "Xinhua Zhang and Ankan Saha and S.V.N. Vishwanathan", "title": "Regularized Risk Minimization by Nesterov's Accelerated Gradient\n  Methods: Algorithmic Extensions and Empirical Studies", "comments": "28 pages. Supplementary material for NIPS 2010 paper \"Lower Bounds on\n  Rate of Convergence of Cutting Plane Methods\" by the same authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nesterov's accelerated gradient methods (AGM) have been successfully applied\nin many machine learning areas. However, their empirical performance on\ntraining max-margin models has been inferior to existing specialized solvers.\nIn this paper, we first extend AGM to strongly convex and composite objective\nfunctions with Bregman style prox-functions. Our unifying framework covers both\nthe $\\infty$-memory and 1-memory styles of AGM, tunes the Lipschiz constant\nadaptively, and bounds the duality gap. Then we demonstrate various ways to\napply this framework of methods to a wide range of machine learning problems.\nEmphasis will be given on their rate of convergence and how to efficiently\ncompute the gradient and optimize the models. The experimental results show\nthat with our extensions AGM outperforms state-of-the-art solvers on max-margin\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 1 Nov 2010 23:41:35 GMT"}], "update_date": "2010-11-03", "authors_parsed": [["Zhang", "Xinhua", ""], ["Saha", "Ankan", ""], ["Vishwanathan", "S. V. N.", ""]]}, {"id": "1011.0686", "submitter": "Stephane Ross", "authors": "Stephane Ross, Geoffrey J. Gordon, J. Andrew Bagnell", "title": "A Reduction of Imitation Learning and Structured Prediction to No-Regret\n  Online Learning", "comments": "Appearing in the 14th International Conference on Artificial\n  Intelligence and Statistics (AISTATS 2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential prediction problems such as imitation learning, where future\nobservations depend on previous predictions (actions), violate the common\ni.i.d. assumptions made in statistical learning. This leads to poor performance\nin theory and often in practice. Some recent approaches provide stronger\nguarantees in this setting, but remain somewhat unsatisfactory as they train\neither non-stationary or stochastic policies and require a large number of\niterations. In this paper, we propose a new iterative algorithm, which trains a\nstationary deterministic policy, that can be seen as a no regret algorithm in\nan online learning setting. We show that any such no regret algorithm, combined\nwith additional reduction assumptions, must find a policy with good performance\nunder the distribution of observations it induces in such sequential settings.\nWe demonstrate that this new approach outperforms previous approaches on two\nchallenging imitation learning problems and a benchmark sequence labeling\nproblem.\n", "versions": [{"version": "v1", "created": "Tue, 2 Nov 2010 17:55:55 GMT"}, {"version": "v2", "created": "Wed, 3 Nov 2010 15:59:19 GMT"}, {"version": "v3", "created": "Wed, 16 Mar 2011 18:51:21 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Ross", "Stephane", ""], ["Gordon", "Geoffrey J.", ""], ["Bagnell", "J. Andrew", ""]]}, {"id": "1011.1161", "submitter": "Kamesh Munagala", "authors": "Sudipto Guha and Kamesh Munagala and Martin Pal", "title": "Multiarmed Bandit Problems with Delayed Feedback", "comments": "The results and presentation in this paper are subsumed by the\n  article \"Approximation algorithms for Bayesian multi-armed bandit problems\"\n  arXiv:1306.3525", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we initiate the study of optimization of bandit type problems\nin scenarios where the feedback of a play is not immediately known. This arises\nnaturally in allocation problems which have been studied extensively in the\nliterature, albeit in the absence of delays in the feedback. We study this\nproblem in the Bayesian setting. In presence of delays, no solution with\nprovable guarantees is known to exist with sub-exponential running time.\n  We show that bandit problems with delayed feedback that arise in allocation\nsettings can be forced to have significant structure, with a slight loss in\noptimality. This structure gives us the ability to reason about the\nrelationship of single arm policies to the entangled optimum policy, and\neventually leads to a O(1) approximation for a significantly general class of\npriors. The structural insights we develop are of key interest and carry over\nto the setting where the feedback of an action is available instantaneously,\nand we improve all previous results in this setting as well.\n", "versions": [{"version": "v1", "created": "Thu, 4 Nov 2010 14:00:41 GMT"}, {"version": "v2", "created": "Tue, 12 Jul 2011 13:53:42 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2013 15:10:04 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Guha", "Sudipto", ""], ["Munagala", "Kamesh", ""], ["Pal", "Martin", ""]]}, {"id": "1011.1296", "submitter": "Jonathan Ullman", "authors": "Anupam Gupta, Moritz Hardt, Aaron Roth, Jonathan Ullman", "title": "Privately Releasing Conjunctions and the Statistical Query Barrier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we would like to know all answers to a set of statistical queries C\non a data set up to small error, but we can only access the data itself using\nstatistical queries. A trivial solution is to exhaustively ask all queries in\nC. Can we do any better?\n  + We show that the number of statistical queries necessary and sufficient for\nthis task is---up to polynomial factors---equal to the agnostic learning\ncomplexity of C in Kearns' statistical query (SQ) model. This gives a complete\nanswer to the question when running time is not a concern.\n  + We then show that the problem can be solved efficiently (allowing arbitrary\nerror on a small fraction of queries) whenever the answers to C can be\ndescribed by a submodular function. This includes many natural concept classes,\nsuch as graph cuts and Boolean disjunctions and conjunctions.\n  While interesting from a learning theoretic point of view, our main\napplications are in privacy-preserving data analysis:\n  Here, our second result leads to the first algorithm that efficiently\nreleases differentially private answers to of all Boolean conjunctions with 1%\naverage error. This presents significant progress on a key open problem in\nprivacy-preserving data analysis.\n  Our first result on the other hand gives unconditional lower bounds on any\ndifferentially private algorithm that admits a (potentially\nnon-privacy-preserving) implementation using only statistical queries. Not only\nour algorithms, but also most known private algorithms can be implemented using\nonly statistical queries, and hence are constrained by these lower bounds. Our\nresult therefore isolates the complexity of agnostic learning in the SQ-model\nas a new barrier in the design of differentially private algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 4 Nov 2010 23:59:08 GMT"}, {"version": "v2", "created": "Sun, 14 Nov 2010 15:36:08 GMT"}, {"version": "v3", "created": "Wed, 15 Dec 2010 00:31:57 GMT"}, {"version": "v4", "created": "Thu, 27 Oct 2011 16:50:37 GMT"}], "update_date": "2011-10-28", "authors_parsed": [["Gupta", "Anupam", ""], ["Hardt", "Moritz", ""], ["Roth", "Aaron", ""], ["Ullman", "Jonathan", ""]]}, {"id": "1011.1518", "submitter": "Daniel Hsu", "authors": "Daniel Hsu, Sham M. Kakade, Tong Zhang", "title": "Robust Matrix Decomposition with Outliers", "comments": "Corrected comparisons to previous work of Candes et al (2009)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose a given observation matrix can be decomposed as the sum of a low-rank\nmatrix and a sparse matrix (outliers), and the goal is to recover these\nindividual components from the observed sum. Such additive decompositions have\napplications in a variety of numerical problems including system\nidentification, latent variable graphical modeling, and principal components\nanalysis. We study conditions under which recovering such a decomposition is\npossible via a combination of $\\ell_1$ norm and trace norm minimization. We are\nspecifically interested in the question of how many outliers are allowed so\nthat convex programming can still achieve accurate recovery, and we obtain\nstronger recovery guarantees than previous studies. Moreover, we do not assume\nthat the spatial pattern of outliers is random, which stands in contrast to\nrelated analyses under such assumptions via matrix completion.\n", "versions": [{"version": "v1", "created": "Fri, 5 Nov 2010 21:43:02 GMT"}, {"version": "v2", "created": "Fri, 12 Nov 2010 22:07:12 GMT"}, {"version": "v3", "created": "Sat, 4 Dec 2010 01:44:01 GMT"}], "update_date": "2010-12-07", "authors_parsed": [["Hsu", "Daniel", ""], ["Kakade", "Sham M.", ""], ["Zhang", "Tong", ""]]}, {"id": "1011.1576", "submitter": "Nikos Karampatziakis", "authors": "Nikos Karampatziakis and John Langford", "title": "Online Importance Weight Aware Updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An importance weight quantifies the relative importance of one example over\nanother, coming up in applications of boosting, asymmetric classification\ncosts, reductions, and active learning. The standard approach for dealing with\nimportance weights in gradient descent is via multiplication of the gradient.\nWe first demonstrate the problems of this approach when importance weights are\nlarge, and argue in favor of more sophisticated ways for dealing with them. We\nthen develop an approach which enjoys an invariance property: that updating\ntwice with importance weight $h$ is equivalent to updating once with importance\nweight $2h$. For many important losses this has a closed form update which\nsatisfies standard regret guarantees when all examples have $h=1$. We also\nbriefly discuss two other reasonable approaches for handling large importance\nweights. Empirically, these approaches yield substantially superior prediction\nwith similar computational performance while reducing the sensitivity of the\nalgorithm to the exact setting of the learning rate. We apply these to online\nactive learning yielding an extraordinarily fast active learning algorithm that\nworks even in the presence of adversarial noise.\n", "versions": [{"version": "v1", "created": "Sat, 6 Nov 2010 18:40:15 GMT"}, {"version": "v2", "created": "Tue, 11 Jan 2011 09:41:03 GMT"}, {"version": "v3", "created": "Tue, 22 Mar 2011 06:14:55 GMT"}, {"version": "v4", "created": "Sat, 18 Jun 2011 20:15:10 GMT"}], "update_date": "2011-06-21", "authors_parsed": [["Karampatziakis", "Nikos", ""], ["Langford", "John", ""]]}, {"id": "1011.1716", "submitter": "Anil Hirani", "authors": "Anil N. Hirani, Kaushik Kalyanaraman, Seth Watts", "title": "Least Squares Ranking on Graphs", "comments": "Added missing references, comparison of linear solvers overhauled,\n  conclusion section added, some new figures added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of alternatives to be ranked, and some pairwise comparison data,\nranking is a least squares computation on a graph. The vertices are the\nalternatives, and the edge values comprise the comparison data. The basic idea\nis very simple and old: come up with values on vertices such that their\ndifferences match the given edge data. Since an exact match will usually be\nimpossible, one settles for matching in a least squares sense. This formulation\nwas first described by Leake in 1976 for rankingfootball teams and appears as\nan example in Professor Gilbert Strang's classic linear algebra textbook. If\none is willing to look into the residual a little further, then the problem\nreally comes alive, as shown effectively by the remarkable recent paper of\nJiang et al. With or without this twist, the humble least squares problem on\ngraphs has far-reaching connections with many current areas ofresearch. These\nconnections are to theoretical computer science (spectral graph theory, and\nmultilevel methods for graph Laplacian systems); numerical analysis (algebraic\nmultigrid, and finite element exterior calculus); other mathematics (Hodge\ndecomposition, and random clique complexes); and applications (arbitrage, and\nranking of sports teams). Not all of these connections are explored in this\npaper, but many are. The underlying ideas are easy to explain, requiring only\nthe four fundamental subspaces from elementary linear algebra. One of our aims\nis to explain these basic ideas and connections, to get researchers in many\nfields interested in this topic. Another aim is to use our numerical\nexperiments for guidance on selecting methods and exposing the need for further\ndevelopment.\n", "versions": [{"version": "v1", "created": "Mon, 8 Nov 2010 06:41:43 GMT"}, {"version": "v2", "created": "Mon, 6 Jun 2011 19:57:07 GMT"}, {"version": "v3", "created": "Mon, 5 Sep 2011 18:19:20 GMT"}, {"version": "v4", "created": "Tue, 6 Sep 2011 14:08:48 GMT"}], "update_date": "2011-09-07", "authors_parsed": [["Hirani", "Anil N.", ""], ["Kalyanaraman", "Kaushik", ""], ["Watts", "Seth", ""]]}, {"id": "1011.1936", "submitter": "Jacob Abernethy", "authors": "Jacob Abernethy, Peter L. Bartlett, Elad Hazan", "title": "Blackwell Approachability and Low-Regret Learning are Equivalent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the celebrated Blackwell Approachability Theorem for two-player\ngames with vector payoffs. We show that Blackwell's result is equivalent, via\nefficient reductions, to the existence of \"no-regret\" algorithms for Online\nLinear Optimization. Indeed, we show that any algorithm for one such problem\ncan be efficiently converted into an algorithm for the other. We provide a\nuseful application of this reduction: the first efficient algorithm for\ncalibrated forecasting.\n", "versions": [{"version": "v1", "created": "Mon, 8 Nov 2010 22:41:14 GMT"}], "update_date": "2010-11-10", "authors_parsed": [["Abernethy", "Jacob", ""], ["Bartlett", "Peter L.", ""], ["Hazan", "Elad", ""]]}, {"id": "1011.2512", "submitter": "Ali Akbar Kiaei Khoshroudbari", "authors": "Ali Akbar Kiaei, Saeed Bagheri Shouraki, Seyed Hossein Khasteh,\n  Mahmoud Khademi, and Alireza Ghatreh Samani", "title": "Extended Active Learning Method", "comments": "18 pages, 26 figures, 2 tables, submitted to the control engineering\n  practice of Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active Learning Method (ALM) is a soft computing method which is used for\nmodeling and control, based on fuzzy logic. Although ALM has shown that it acts\nwell in dynamic environments, its operators cannot support it very well in\ncomplex situations due to losing data. Thus ALM can find better membership\nfunctions if more appropriate operators be chosen for it. This paper\nsubstituted two new operators instead of ALM original ones; which consequently\nrenewed finding membership functions in a way superior to conventional ALM.\nThis new method is called Extended Active Learning Method (EALM).\n", "versions": [{"version": "v1", "created": "Wed, 10 Nov 2010 21:44:26 GMT"}, {"version": "v2", "created": "Mon, 17 Jan 2011 19:09:02 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Kiaei", "Ali Akbar", ""], ["Shouraki", "Saeed Bagheri", ""], ["Khasteh", "Seyed Hossein", ""], ["Khademi", "Mahmoud", ""], ["Samani", "Alireza Ghatreh", ""]]}, {"id": "1011.2624", "submitter": "Marcela Svarc", "authors": "Ricardo Fraiman, Badih Ghattas and Marcela Svarc", "title": "Clustering using Unsupervised Binary Trees: CUBT", "comments": "This paper has been withdrawn by the author due to an involuntary\n  double submission to the arxiv", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We herein introduce a new method of interpretable clustering that uses\nunsupervised binary trees. It is a three-stage procedure, the first stage of\nwhich entails a series of recursive binary splits to reduce the heterogeneity\nof the data within the new subsamples. During the second stage (pruning),\nconsideration is given to whether adjacent nodes can be aggregated. Finally,\nduring the third stage (joining), similar clusters are joined together, even if\nthey do not share the same parent originally. Consistency results are obtained,\nand the procedure is used on simulated and real data sets.\n", "versions": [{"version": "v1", "created": "Thu, 11 Nov 2010 12:12:56 GMT"}, {"version": "v2", "created": "Thu, 27 Oct 2011 14:00:46 GMT"}], "update_date": "2011-10-28", "authors_parsed": [["Fraiman", "Ricardo", ""], ["Ghattas", "Badih", ""], ["Svarc", "Marcela", ""]]}, {"id": "1011.3090", "submitter": "Ryota Tomioka", "authors": "Ryota Tomioka, Taiji Suzuki", "title": "Regularization Strategies and Empirical Bayesian Learning for MKL", "comments": "19pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple kernel learning (MKL), structured sparsity, and multi-task learning\nhave recently received considerable attention. In this paper, we show how\ndifferent MKL algorithms can be understood as applications of either\nregularization on the kernel weights or block-norm-based regularization, which\nis more common in structured sparsity and multi-task learning. We show that\nthese two regularization strategies can be systematically mapped to each other\nthrough a concave conjugate operation. When the kernel-weight-based regularizer\nis separable into components, we can naturally consider a generative\nprobabilistic model behind MKL. Based on this model, we propose learning\nalgorithms for the kernel weights through the maximization of marginal\nlikelihood. We show through numerical experiments that $\\ell_2$-norm MKL and\nElastic-net MKL achieve comparable accuracy to uniform kernel combination.\nAlthough uniform kernel combination might be preferable from its simplicity,\n$\\ell_2$-norm MKL and Elastic-net MKL can learn the usefulness of the\ninformation sources represented as kernels. In particular, Elastic-net MKL\nachieves sparsity in the kernel weights.\n", "versions": [{"version": "v1", "created": "Sat, 13 Nov 2010 02:40:14 GMT"}, {"version": "v2", "created": "Wed, 2 Mar 2011 08:19:07 GMT"}], "update_date": "2011-03-03", "authors_parsed": [["Tomioka", "Ryota", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1011.3168", "submitter": "Alexander Rakhlin", "authors": "Alexander Rakhlin, Karthik Sridharan, Ambuj Tewari", "title": "Online Learning: Beyond Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online learnability of a wide class of problems, extending the\nresults of (Rakhlin, Sridharan, Tewari, 2010) to general notions of performance\nmeasure well beyond external regret. Our framework simultaneously captures such\nwell-known notions as internal and general Phi-regret, learning with\nnon-additive global cost functions, Blackwell's approachability, calibration of\nforecasters, adaptive regret, and more. We show that learnability in all these\nsituations is due to control of the same three quantities: a martingale\nconvergence term, a term describing the ability to perform well if future is\nknown, and a generalization of sequential Rademacher complexity, studied in\n(Rakhlin, Sridharan, Tewari, 2010). Since we directly study complexity of the\nproblem instead of focusing on efficient algorithms, we are able to improve and\nextend many known results which have been previously derived via an algorithmic\nconstruction.\n", "versions": [{"version": "v1", "created": "Sun, 14 Nov 2010 00:17:02 GMT"}, {"version": "v2", "created": "Thu, 24 Mar 2011 15:45:21 GMT"}], "update_date": "2011-03-25", "authors_parsed": [["Rakhlin", "Alexander", ""], ["Sridharan", "Karthik", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1011.3557", "submitter": "Kristina Lerman", "authors": "Anon Plangprasopchok, Kristina Lerman, Lise Getoor", "title": "A Probabilistic Approach for Learning Folksonomies from Structured Data", "comments": "In Proceedings of the 4th ACM Web Search and Data Mining Conference\n  (WSDM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning structured representations has emerged as an important problem in\nmany domains, including document and Web data mining, bioinformatics, and image\nanalysis. One approach to learning complex structures is to integrate many\nsmaller, incomplete and noisy structure fragments. In this work, we present an\nunsupervised probabilistic approach that extends affinity propagation to\ncombine the small ontological fragments into a collection of integrated,\nconsistent, and larger folksonomies. This is a challenging task because the\nmethod must aggregate similar structures while avoiding structural\ninconsistencies and handling noise. We validate the approach on a real-world\nsocial media dataset, comprised of shallow personal hierarchies specified by\nmany individual users, collected from the photosharing website Flickr. Our\nempirical results show that our proposed approach is able to construct deeper\nand denser structures, compared to an approach using only the standard affinity\npropagation algorithm. Additionally, the approach yields better overall\nintegration quality than a state-of-the-art approach based on incremental\nrelational clustering.\n", "versions": [{"version": "v1", "created": "Tue, 16 Nov 2010 00:46:31 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Plangprasopchok", "Anon", ""], ["Lerman", "Kristina", ""], ["Getoor", "Lise", ""]]}, {"id": "1011.3728", "submitter": "Curzio Basso", "authors": "Curzio Basso and Matteo Santoro and Alessandro Verri and Silvia Villa", "title": "PADDLE: Proximal Algorithm for Dual Dictionaries LEarning", "comments": null, "journal-ref": null, "doi": null, "report-no": "DISI-TR-2010-06", "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, considerable research efforts have been devoted to the design of\nmethods to learn from data overcomplete dictionaries for sparse coding.\nHowever, learned dictionaries require the solution of an optimization problem\nfor coding new data. In order to overcome this drawback, we propose an\nalgorithm aimed at learning both a dictionary and its dual: a linear mapping\ndirectly performing the coding. By leveraging on proximal methods, our\nalgorithm jointly minimizes the reconstruction error of the dictionary and the\ncoding error of its dual; the sparsity of the representation is induced by an\n$\\ell_1$-based penalty on its coefficients. The results obtained on synthetic\ndata and real images show that the algorithm is capable of recovering the\nexpected dictionaries. Furthermore, on a benchmark dataset, we show that the\nimage features obtained from the dual matrix yield state-of-the-art\nclassification performance while being much less computational intensive.\n", "versions": [{"version": "v1", "created": "Tue, 16 Nov 2010 15:31:25 GMT"}], "update_date": "2010-11-17", "authors_parsed": [["Basso", "Curzio", ""], ["Santoro", "Matteo", ""], ["Verri", "Alessandro", ""], ["Villa", "Silvia", ""]]}, {"id": "1011.4104", "submitter": "Andri Mirzal", "authors": "Andri Mirzal", "title": "Clustering and Latent Semantic Indexing Aspects of the Singular Value\n  Decomposition", "comments": "38 pages, submitted to Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper discusses clustering and latent semantic indexing (LSI) aspects of\nthe singular value decomposition (SVD). The purpose of this paper is twofold.\nThe first is to give an explanation on how and why the singular vectors can be\nused in clustering. And the second is to show that the two seemingly unrelated\nSVD aspects actually originate from the same source: related vertices tend to\nbe more clustered in the graph representation of lower rank approximate matrix\nusing the SVD than in the original semantic graph. Accordingly, the SVD can\nimprove retrieval performance of an information retrieval system since queries\nmade to the approximate matrix can retrieve more relevant documents and filter\nout more irrelevant documents than the same queries made to the original\nmatrix. By utilizing this fact, we will devise an LSI algorithm that mimicks\nSVD capability in clustering related vertices. Convergence analysis shows that\nthe algorithm is convergent and produces a unique solution for each input.\nExperimental results using some standard datasets in LSI research show that\nretrieval performances of the algorithm are comparable to the SVD's. In\naddition, the algorithm is more practical and easier to use because there is no\nneed to determine decomposition rank which is crucial in driving retrieval\nperformance of the SVD.\n", "versions": [{"version": "v1", "created": "Wed, 17 Nov 2010 23:39:12 GMT"}, {"version": "v2", "created": "Wed, 9 Mar 2011 18:56:56 GMT"}, {"version": "v3", "created": "Wed, 17 Oct 2012 08:41:06 GMT"}, {"version": "v4", "created": "Fri, 16 Nov 2012 04:26:29 GMT"}], "update_date": "2012-11-19", "authors_parsed": [["Mirzal", "Andri", ""]]}, {"id": "1011.4748", "submitter": "Yi Gai", "authors": "Yi Gai, Bhaskar Krishnamachari and Rahul Jain", "title": "Combinatorial Network Optimization with Unknown Variables: Multi-Armed\n  Bandits with Linear Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the classic multi-armed bandits problem, the goal is to have a policy for\ndynamically operating arms that each yield stochastic rewards with unknown\nmeans. The key metric of interest is regret, defined as the gap between the\nexpected total reward accumulated by an omniscient player that knows the reward\nmeans for each arm, and the expected total reward accumulated by the given\npolicy. The policies presented in prior work have storage, computation and\nregret all growing linearly with the number of arms, which is not scalable when\nthe number of arms is large. We consider in this work a broad class of\nmulti-armed bandits with dependent arms that yield rewards as a linear\ncombination of a set of unknown parameters. For this general framework, we\npresent efficient policies that are shown to achieve regret that grows\nlogarithmically with time, and polynomially in the number of unknown parameters\n(even though the number of dependent arms may grow exponentially). Furthermore,\nthese policies only require storage that grows linearly in the number of\nunknown parameters. We show that this generalization is broadly applicable and\nuseful for many interesting tasks in networks that can be formulated as\ntractable combinatorial optimization problems with linear objective functions,\nsuch as maximum weight matching, shortest path, and minimum spanning tree\ncomputations.\n", "versions": [{"version": "v1", "created": "Mon, 22 Nov 2010 08:40:35 GMT"}], "update_date": "2010-11-23", "authors_parsed": [["Gai", "Yi", ""], ["Krishnamachari", "Bhaskar", ""], ["Jain", "Rahul", ""]]}, {"id": "1011.4752", "submitter": "Yi Gai", "authors": "Wenhan Dai, Yi Gai, Bhaskar Krishnamachari, Qing Zhao", "title": "The Non-Bayesian Restless Multi-Armed Bandit: a Case of Near-Logarithmic\n  Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the classic Bayesian restless multi-armed bandit (RMAB) problem, there are\n$N$ arms, with rewards on all arms evolving at each time as Markov chains with\nknown parameters. A player seeks to activate $K \\geq 1$ arms at each time in\norder to maximize the expected total reward obtained over multiple plays. RMAB\nis a challenging problem that is known to be PSPACE-hard in general. We\nconsider in this work the even harder non-Bayesian RMAB, in which the\nparameters of the Markov chain are assumed to be unknown \\emph{a priori}. We\ndevelop an original approach to this problem that is applicable when the\ncorresponding Bayesian problem has the structure that, depending on the known\nparameter values, the optimal solution is one of a prescribed finite set of\npolicies. In such settings, we propose to learn the optimal policy for the\nnon-Bayesian RMAB by employing a suitable meta-policy which treats each policy\nfrom this finite set as an arm in a different non-Bayesian multi-armed bandit\nproblem for which a single-arm selection policy is optimal. We demonstrate this\napproach by developing a novel sensing policy for opportunistic spectrum access\nover unknown dynamic channels. We prove that our policy achieves\nnear-logarithmic regret (the difference in expected reward compared to a\nmodel-aware genie), which leads to the same average reward that can be achieved\nby the optimal policy under a known model. This is the first such result in the\nliterature for a non-Bayesian RMAB.\n", "versions": [{"version": "v1", "created": "Mon, 22 Nov 2010 09:07:55 GMT"}], "update_date": "2010-11-23", "authors_parsed": [["Dai", "Wenhan", ""], ["Gai", "Yi", ""], ["Krishnamachari", "Bhaskar", ""], ["Zhao", "Qing", ""]]}, {"id": "1011.4969", "submitter": "Keqin Liu", "authors": "Haoyang Liu, Keqin Liu, Qing Zhao", "title": "Learning in A Changing World: Restless Multi-Armed Bandit with Unknown\n  Dynamics", "comments": "33 pages, 5 figures, submitted to IEEE Transactions on Information\n  Theory, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the restless multi-armed bandit (RMAB) problem with unknown\ndynamics in which a player chooses M out of N arms to play at each time. The\nreward state of each arm transits according to an unknown Markovian rule when\nit is played and evolves according to an arbitrary unknown random process when\nit is passive. The performance of an arm selection policy is measured by\nregret, defined as the reward loss with respect to the case where the player\nknows which M arms are the most rewarding and always plays the M best arms. We\nconstruct a policy with an interleaving exploration and exploitation epoch\nstructure that achieves a regret with logarithmic order when arbitrary (but\nnontrivial) bounds on certain system parameters are known. When no knowledge\nabout the system is available, we show that the proposed policy achieves a\nregret arbitrarily close to the logarithmic order. We further extend the\nproblem to a decentralized setting where multiple distributed players share the\narms without information exchange. Under both an exogenous restless model and\nan endogenous restless model, we show that a decentralized extension of the\nproposed policy preserves the logarithmic regret order as in the centralized\nsetting. The results apply to adaptive learning in various dynamic systems and\ncommunication networks, as well as financial investment.\n", "versions": [{"version": "v1", "created": "Mon, 22 Nov 2010 22:39:47 GMT"}, {"version": "v2", "created": "Mon, 26 Dec 2011 03:42:59 GMT"}], "update_date": "2011-12-30", "authors_parsed": [["Liu", "Haoyang", ""], ["Liu", "Keqin", ""], ["Zhao", "Qing", ""]]}, {"id": "1011.5053", "submitter": "Sivan Sabato", "authors": "Sivan Sabato, Nathan Srebro, Naftali Tishby", "title": "Tight Sample Complexity of Large-Margin Learning", "comments": "Appearing in Neural Information Processing Systems (NIPS) 2010; This\n  is the full version, including appendix with proofs; Also with some\n  corrections", "journal-ref": "Advances in Neural Information Processing Systems 23 (NIPS),\n  2038-2046, 2010", "doi": null, "report-no": null, "categories": "cs.LG math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain a tight distribution-specific characterization of the sample\ncomplexity of large-margin classification with L_2 regularization: We introduce\nthe \\gamma-adapted-dimension, which is a simple function of the spectrum of a\ndistribution's covariance matrix, and show distribution-specific upper and\nlower bounds on the sample complexity, both governed by the\n\\gamma-adapted-dimension of the source distribution. We conclude that this new\nquantity tightly characterizes the true sample complexity of large-margin\nclassification. The bounds hold for a rich family of sub-Gaussian\ndistributions.\n", "versions": [{"version": "v1", "created": "Tue, 23 Nov 2010 10:44:21 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2012 16:40:03 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Sabato", "Sivan", ""], ["Srebro", "Nathan", ""], ["Tishby", "Naftali", ""]]}, {"id": "1011.5270", "submitter": "Facundo Memoli", "authors": "Gunnar Carlsson and Facundo Memoli", "title": "Classifying Clustering Schemes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many clustering schemes are defined by optimizing an objective function\ndefined on the partitions of the underlying set of a finite metric space. In\nthis paper, we construct a framework for studying what happens when we instead\nimpose various structural conditions on the clustering schemes, under the\ngeneral heading of functoriality. Functoriality refers to the idea that one\nshould be able to compare the results of clustering algorithms as one varies\nthe data set, for example by adding points or by applying functions to it. We\nshow that within this framework, one can prove a theorems analogous to one of\nJ. Kleinberg, in which for example one obtains an existence and uniqueness\ntheorem instead of a non-existence result.\n  We obtain a full classification of all clustering schemes satisfying a\ncondition we refer to as excisiveness. The classification can be changed by\nvarying the notion of maps of finite metric spaces. The conditions occur\nnaturally when one considers clustering as the statistical version of the\ngeometric notion of connected components. By varying the degree of\nfunctoriality that one requires from the schemes it is possible to construct\nricher families of clustering schemes that exhibit sensitivity to density.\n", "versions": [{"version": "v1", "created": "Wed, 24 Nov 2010 01:51:00 GMT"}, {"version": "v2", "created": "Mon, 29 Nov 2010 22:11:55 GMT"}], "update_date": "2010-12-01", "authors_parsed": [["Carlsson", "Gunnar", ""], ["Memoli", "Facundo", ""]]}, {"id": "1011.5395", "submitter": "Daniel Vainsencher", "authors": "Daniel Vainsencher, Shie Mannor, Alfred M. Bruckstein", "title": "The Sample Complexity of Dictionary Learning", "comments": null, "journal-ref": null, "doi": "10.1016/j.specom.2013.01.005", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large set of signals can sometimes be described sparsely using a\ndictionary, that is, every element can be represented as a linear combination\nof few elements from the dictionary. Algorithms for various signal processing\napplications, including classification, denoising and signal separation, learn\na dictionary from a set of signals to be represented. Can we expect that the\nrepresentation found by such a dictionary for a previously unseen example from\nthe same source will have L_2 error of the same magnitude as those for the\ngiven examples? We assume signals are generated from a fixed distribution, and\nstudy this questions from a statistical learning theory perspective.\n  We develop generalization bounds on the quality of the learned dictionary for\ntwo types of constraints on the coefficient selection, as measured by the\nexpected L_2 error in representation when the dictionary is used. For the case\nof l_1 regularized coefficient selection we provide a generalization bound of\nthe order of O(sqrt(np log(m lambda)/m)), where n is the dimension, p is the\nnumber of elements in the dictionary, lambda is a bound on the l_1 norm of the\ncoefficient vector and m is the number of samples, which complements existing\nresults. For the case of representing a new signal as a combination of at most\nk dictionary elements, we provide a bound of the order O(sqrt(np log(m k)/m))\nunder an assumption on the level of orthogonality of the dictionary (low Babel\nfunction). We further show that this assumption holds for most dictionaries in\nhigh dimensions in a strong probabilistic sense. Our results further yield fast\nrates of order 1/m as opposed to 1/sqrt(m) using localized Rademacher\ncomplexity. We provide similar results in a general setting using kernels with\nweak smoothness requirements.\n", "versions": [{"version": "v1", "created": "Wed, 24 Nov 2010 15:18:42 GMT"}], "update_date": "2013-02-06", "authors_parsed": [["Vainsencher", "Daniel", ""], ["Mannor", "Shie", ""], ["Bruckstein", "Alfred M.", ""]]}, {"id": "1011.5668", "submitter": "Alexey Chernov", "authors": "Alexey Chernov", "title": "On Theorem 2.3 in \"Prediction, Learning, and Games\" by Cesa-Bianchi and\n  Lugosi", "comments": "3 pages; excerpt from arXiv:1005.1918, simplified and rewritten using\n  the notation of the monograph by Cesa-Bianchi and Lugosi", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The note presents a modified proof of a loss bound for the exponentially\nweighted average forecaster with time-varying potential. The regret term of the\nalgorithm is upper-bounded by sqrt{n ln(N)} (uniformly in n), where N is the\nnumber of experts and n is the number of steps.\n", "versions": [{"version": "v1", "created": "Thu, 25 Nov 2010 18:52:30 GMT"}], "update_date": "2010-11-29", "authors_parsed": [["Chernov", "Alexey", ""]]}, {"id": "1011.6086", "submitter": "Lucas Theis", "authors": "Lucas Theis, Sebastian Gerwinn, Fabian Sinz and Matthias Bethge", "title": "In All Likelihood, Deep Belief Is Not Enough", "comments": null, "journal-ref": "Journal of Machine Learning Research 12, 3071-3096, 2011", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical models of natural stimuli provide an important tool for\nresearchers in the fields of machine learning and computational neuroscience. A\ncanonical way to quantitatively assess and compare the performance of\nstatistical models is given by the likelihood. One class of statistical models\nwhich has recently gained increasing popularity and has been applied to a\nvariety of complex data are deep belief networks. Analyses of these models,\nhowever, have been typically limited to qualitative analyses based on samples\ndue to the computationally intractable nature of the model likelihood.\nMotivated by these circumstances, the present article provides a consistent\nestimator for the likelihood that is both computationally tractable and simple\nto apply in practice. Using this estimator, a deep belief network which has\nbeen suggested for the modeling of natural image patches is quantitatively\ninvestigated and compared to other models of natural image patches. Contrary to\nearlier claims based on qualitative results, the results presented in this\narticle provide evidence that the model under investigation is not a\nparticularly good model for natural images\n", "versions": [{"version": "v1", "created": "Sun, 28 Nov 2010 20:54:58 GMT"}], "update_date": "2012-09-17", "authors_parsed": [["Theis", "Lucas", ""], ["Gerwinn", "Sebastian", ""], ["Sinz", "Fabian", ""], ["Bethge", "Matthias", ""]]}, {"id": "1011.6224", "submitter": "Markward Britsch", "authors": "Markward Britsch (1), Nikolai Gagunashvili (2), Michael Schmelling (1)\n  ((1) Max-Planck-Institut f\\\"ur Kernphysik, (2) University of Akureyri)", "title": "Classifying extremely imbalanced data sets", "comments": null, "journal-ref": "PoS ACAT2010:047,2010", "doi": null, "report-no": null, "categories": "physics.data-an cs.LG hep-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imbalanced data sets containing much more background than signal instances\nare very common in particle physics, and will also be characteristic for the\nupcoming analyses of LHC data. Following up the work presented at ACAT 2008, we\nuse the multivariate technique presented there (a rule growing algorithm with\nthe meta-methods bagging and instance weighting) on much more imbalanced data\nsets, especially a selection of D0 decays without the use of particle\nidentification. It turns out that the quality of the result strongly depends on\nthe number of background instances used for training. We discuss methods to\nexploit this in order to improve the results significantly, and how to handle\nand reduce the size of large training sets without loss of result quality in\ngeneral. We will also comment on how to take into account statistical\nfluctuation in receiver operation characteristic curves (ROC) for comparing\nclassifier methods.\n", "versions": [{"version": "v1", "created": "Mon, 29 Nov 2010 13:34:02 GMT"}], "update_date": "2011-08-11", "authors_parsed": [["Britsch", "Markward", "", "Max-Planck-Institut f\u00fcr Kernphysik"], ["Gagunashvili", "Nikolai", "", "University of Akureyri"], ["Schmelling", "Michael", "", "Max-Planck-Institut f\u00fcr Kernphysik"]]}]