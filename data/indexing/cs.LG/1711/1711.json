[{"id": "1711.00001", "submitter": "Haoze Wu", "authors": "Haoze Wu, Yangyu Zhou", "title": "Gene Ontology (GO) Prediction using Machine Learning Methods", "comments": "The results in this paper result from a biased test set, and is\n  therefore not reliable", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We applied machine learning to predict whether a gene is involved in axon\nregeneration. We extracted 31 features from different databases and trained\nfive machine learning models. Our optimal model, a Random Forest Classifier\nwith 50 submodels, yielded a test score of 85.71%, which is 4.1% higher than\nthe baseline score. We concluded that our models have some predictive\ncapability. Similar methodology and features could be applied to predict other\nGene Ontology (GO) terms.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 19:02:13 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 16:47:43 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Wu", "Haoze", ""], ["Zhou", "Yangyu", ""]]}, {"id": "1711.00002", "submitter": "Hanzhang Hu", "authors": "Hanzhang Hu, Debadeepta Dey, Allison Del Giorno, Martial Hebert, J.\n  Andrew Bagnell", "title": "Log-DenseNet: How to Sparsify a DenseNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skip connections are increasingly utilized by deep neural networks to improve\naccuracy and cost-efficiency. In particular, the recent DenseNet is efficient\nin computation and parameters, and achieves state-of-the-art predictions by\ndirectly connecting each feature layer to all previous ones. However,\nDenseNet's extreme connectivity pattern may hinder its scalability to high\ndepths, and in applications like fully convolutional networks, full DenseNet\nconnections are prohibitively expensive. This work first experimentally shows\nthat one key advantage of skip connections is to have short distances among\nfeature layers during backpropagation. Specifically, using a fixed number of\nskip connections, the connection patterns with shorter backpropagation distance\namong layers have more accurate predictions. Following this insight, we propose\na connection template, Log-DenseNet, which, in comparison to DenseNet, only\nslightly increases the backpropagation distances among layers from 1 to ($1 +\n\\log_2 L$), but uses only $L\\log_2 L$ total connections instead of $O(L^2)$.\nHence, Log-DenseNets are easier than DenseNets to implement and to scale. We\ndemonstrate the effectiveness of our design principle by showing better\nperformance than DenseNets on tabula rasa semantic segmentation, and\ncompetitive results on visual recognition.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 22:01:08 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Hu", "Hanzhang", ""], ["Dey", "Debadeepta", ""], ["Del Giorno", "Allison", ""], ["Hebert", "Martial", ""], ["Bagnell", "J. Andrew", ""]]}, {"id": "1711.00004", "submitter": "Fei Wang", "authors": "Fei Wang, Xiaofeng Gao, Guihai Chen, Jun Ye", "title": "Accelerate RNN-based Training with Importance Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Importance sampling (IS) as an elegant and efficient variance reduction (VR)\ntechnique for the acceleration of stochastic optimization problems has\nattracted many researches recently. Unlike commonly adopted stochastic uniform\nsampling in stochastic optimizations, IS-integrated algorithms sample training\ndata at each iteration with respect to a weighted sampling probability\ndistribution $P$, which is constructed according to the precomputed importance\nfactors. Previous experimental results show that IS has achieved remarkable\nprogresses in the acceleration of training convergence. Unfortunately, the\ncalculation of the sampling probability distribution $P$ causes a major\nlimitation of IS: it requires the input data to be well-structured, i.e., the\nfeature vector is properly defined. Consequently, recurrent neural networks\n(RNN) as a popular learning algorithm is not able to enjoy the benefits of IS\ndue to the fact that its raw input data, i.e., the training sequences, are\noften unstructured which makes calculation of $P$ impossible. In considering of\nthe the popularity of RNN-based learning applications and their relative long\ntraining time, we are interested in accelerating them through IS. This paper\npropose a novel Fast-Importance-Mining algorithm to calculate the importance\nfactor for unstructured data which makes the application of IS in RNN-based\napplications possible. Our experimental evaluation on popular open-source\nRNN-based learning applications validate the effectiveness of IS in improving\nthe convergence rate of RNNs.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 13:09:17 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Wang", "Fei", ""], ["Gao", "Xiaofeng", ""], ["Chen", "Guihai", ""], ["Ye", "Jun", ""]]}, {"id": "1711.00048", "submitter": "Daniel Stoller", "authors": "Daniel Stoller, Sebastian Ewert, Simon Dixon", "title": "Adversarial Semi-Supervised Audio Source Separation applied to Singing\n  Voice Extraction", "comments": "5 pages, 2 figures, 1 table. Final version of manuscript accepted for\n  2018 IEEE International Conference on Acoustics, Speech and Signal Processing\n  (ICASSP). Implementation available at\n  https://github.com/f90/AdversarialAudioSeparation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state of the art in music source separation employs neural networks\ntrained in a supervised fashion on multi-track databases to estimate the\nsources from a given mixture. With only few datasets available, often extensive\ndata augmentation is used to combat overfitting. Mixing random tracks, however,\ncan even reduce separation performance as instruments in real music are\nstrongly correlated. The key concept in our approach is that source estimates\nof an optimal separator should be indistinguishable from real source signals.\nBased on this idea, we drive the separator towards outputs deemed as realistic\nby discriminator networks that are trained to tell apart real from separator\nsamples. This way, we can also use unpaired source and mixture recordings\nwithout the drawbacks of creating unrealistic music mixtures. Our framework is\nwidely applicable as it does not assume a specific network architecture or\nnumber of sources. To our knowledge, this is the first adoption of adversarial\ntraining for music source separation. In a prototype experiment for singing\nvoice separation, separation performance increases with our approach compared\nto purely supervised training.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 18:35:45 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 16:13:45 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Stoller", "Daniel", ""], ["Ewert", "Sebastian", ""], ["Dixon", "Simon", ""]]}, {"id": "1711.00049", "submitter": "Xiang Li", "authors": "Zhe Guo, Xiang Li, Heng Huang, Ning Guo, Quanzheng Li", "title": "Medical Image Segmentation Based on Multi-Modal Convolutional Neural\n  Network: Study on Image Fusion Schemes", "comments": "Zhe Guo and Xiang Li contribute equally to this work", "journal-ref": "2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI\n  2018), Washington, DC, 2018, pp. 903-907", "doi": "10.1109/ISBI.2018.8363717", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image analysis using more than one modality (i.e. multi-modal) has been\nincreasingly applied in the field of biomedical imaging. One of the challenges\nin performing the multimodal analysis is that there exist multiple schemes for\nfusing the information from different modalities, where such schemes are\napplication-dependent and lack a unified framework to guide their designs. In\nthis work we firstly propose a conceptual architecture for the image fusion\nschemes in supervised biomedical image analysis: fusing at the feature level,\nfusing at the classifier level, and fusing at the decision-making level.\nFurther, motivated by the recent success in applying deep learning for natural\nimage analysis, we implement the three image fusion schemes above based on the\nConvolutional Neural Network (CNN) with varied structures, and combined into a\nsingle framework. The proposed image segmentation framework is capable of\nanalyzing the multi-modality images using different fusing schemes\nsimultaneously. The framework is applied to detect the presence of soft tissue\nsarcoma from the combination of Magnetic Resonance Imaging (MRI), Computed\nTomography (CT) and Positron Emission Tomography (PET) images. It is found from\nthe results that while all the fusion schemes outperform the single-modality\nschemes, fusing at the feature level can generally achieve the best performance\nin terms of both accuracy and computational cost, but also suffers from the\ndecreased robustness in the presence of large errors in any image modalities.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 18:37:28 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 16:02:28 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Guo", "Zhe", ""], ["Li", "Xiang", ""], ["Huang", "Heng", ""], ["Guo", "Ning", ""], ["Li", "Quanzheng", ""]]}, {"id": "1711.00064", "submitter": "Chandler Zuo", "authors": "Chandler Zuo", "title": "Calibration for Stratified Classification Models", "comments": "14 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classification problems, sampling bias between training data and testing\ndata is critical to the ranking performance of classification scores. Such bias\ncan be both unintentionally introduced by data collection and intentionally\nintroduced by the algorithm, such as under-sampling or weighting techniques\napplied to imbalanced data. When such sampling bias exists, using the raw\nclassification score to rank observations in the testing data can lead to\nsuboptimal results. In this paper, I investigate the optimal calibration\nstrategy in general settings, and develop a practical solution for one specific\nsampling bias case, where the sampling bias is introduced by stratified\nsampling. The optimal solution is developed by analytically solving the problem\nof optimizing the ROC curve. For practical data, I propose a ranking algorithm\nfor general classification models with stratified data. Numerical experiments\ndemonstrate that the proposed algorithm effectively addresses the stratified\nsampling bias issue. Interestingly, the proposed method shows its potential\napplicability in two other machine learning areas: unsupervised learning and\nmodel ensembling, which can be future research topics.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 19:23:57 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Zuo", "Chandler", ""]]}, {"id": "1711.00066", "submitter": "Konrad Zolna", "authors": "Konrad Zolna, Devansh Arpit, Dendi Suhubdy, Yoshua Bengio", "title": "Fraternal Dropout", "comments": "Accepted to ICLR 2018. Extended appendix. Added official GitHub code\n  for replication: https://github.com/kondiz/fraternal-dropout . Added\n  references. Corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are important class of architectures among\nneural networks useful for language modeling and sequential prediction.\nHowever, optimizing RNNs is known to be harder compared to feed-forward neural\nnetworks. A number of techniques have been proposed in literature to address\nthis problem. In this paper we propose a simple technique called fraternal\ndropout that takes advantage of dropout to achieve this goal. Specifically, we\npropose to train two identical copies of an RNN (that share parameters) with\ndifferent dropout masks while minimizing the difference between their\n(pre-softmax) predictions. In this way our regularization encourages the\nrepresentations of RNNs to be invariant to dropout mask, thus being robust. We\nshow that our regularization term is upper bounded by the expectation-linear\ndropout objective which has been shown to address the gap due to the difference\nbetween the train and inference phases of dropout. We evaluate our model and\nachieve state-of-the-art results in sequence modeling tasks on two benchmark\ndatasets - Penn Treebank and Wikitext-2. We also show that our approach leads\nto performance improvement by a significant margin in image captioning\n(Microsoft COCO) and semi-supervised (CIFAR-10) tasks.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 19:32:45 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 16:40:34 GMT"}, {"version": "v3", "created": "Wed, 31 Jan 2018 00:12:47 GMT"}, {"version": "v4", "created": "Wed, 28 Mar 2018 15:50:58 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Zolna", "Konrad", ""], ["Arpit", "Devansh", ""], ["Suhubdy", "Dendi", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1711.00073", "submitter": "Qi Yu", "authors": "Rose Yu, Stephan Zheng, Anima Anandkumar, Yisong Yue", "title": "Long-term Forecasting using Higher Order Tensor RNNs", "comments": "24 pages including appendix, updated JMLR version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Higher-Order Tensor RNN (HOT-RNN), a novel family of neural\nsequence architectures for multivariate forecasting in environments with\nnonlinear dynamics. Long-term forecasting in such systems is highly\nchallenging, since there exist long-term temporal dependencies, higher-order\ncorrelations and sensitivity to error propagation. Our proposed recurrent\narchitecture addresses these issues by learning the nonlinear dynamics directly\nusing higher-order moments and higher-order state transition functions.\nFurthermore, we decompose the higher-order structure using the tensor-train\ndecomposition to reduce the number of parameters while preserving the model\nperformance. We theoretically establish the approximation guarantees and the\nvariance bound for HOT-RNN for general sequence inputs. We also demonstrate 5%\n~ 12% improvements for long-term prediction over general RNN and LSTM\narchitectures on a range of simulated environments with nonlinear dynamics, as\nwell on real-world time series data.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 19:44:41 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2018 20:45:20 GMT"}, {"version": "v3", "created": "Sat, 24 Aug 2019 00:15:47 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Yu", "Rose", ""], ["Zheng", "Stephan", ""], ["Anandkumar", "Anima", ""], ["Yue", "Yisong", ""]]}, {"id": "1711.00107", "submitter": "James Goldfarb", "authors": "James W Goldfarb", "title": "Separation of Water and Fat Magnetic Resonance Imaging Signals Using\n  Deep Learning with Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: A new method for magnetic resonance (MR) imaging water-fat\nseparation using a convolutional neural network (ConvNet) and deep learning\n(DL) is presented. Feasibility of the method with complex and magnitude images\nis demonstrated with a series of patient studies and accuracy of predicted\nquantitative values is analyzed.\n  Methods: Water-fat separation of 1200 gradient-echo acquisitions from 90\nimaging sessions (normal, acute and chronic myocardial infarction) was\nperformed using a conventional model based method with modeling of R2* and\noff-resonance and a multi-peak fat spectrum. A U-Net convolutional neural\nnetwork for calculation of water-only, fat-only, R2* and off-resonance images\nwas trained with 900 gradient-echo Multiple and single-echo complex and\nmagnitude input data algorithms were studied and compared to conventional\nextended echo modeling.\n  Results: The U-Net ConvNet was easily trained and provided water-fat\nseparation results visually comparable to conventional methods. Myocardial fat\ndeposition in chronic myocardial infarction and intramyocardial hemorrhage in\nacute myocardial infarction were well visualized in the DL results. Predicted\nvalues for R2*, off-resonance, water and fat signal intensities were well\ncorrelated with conventional model based water fat separation (R2>=0.97,\np<0.001). DL images had a 14% higher signal-to-noise ratio (p<0.001) when\ncompared to the conventional method.\n  Conclusion: Deep learning utilizing ConvNets is a feasible method for MR\nwater-fat separationimaging with complex, magnitude and single echo image data.\nA trained U-Net can be efficiently used for MR water-fat separation, providing\nresults comparable to conventional model based methods.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 17:36:36 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Goldfarb", "James W", ""]]}, {"id": "1711.00108", "submitter": "Elliot Meyerson", "authors": "Elliot Meyerson and Risto Miikkulainen", "title": "Beyond Shared Hierarchies: Deep Multitask Learning through Soft Layer\n  Ordering", "comments": "14 pages (main paper: 10 pages). Published as a conference paper at\n  ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing deep multitask learning (MTL) approaches align layers shared between\ntasks in a parallel ordering. Such an organization significantly constricts the\ntypes of shared structure that can be learned. The necessity of parallel\nordering for deep MTL is first tested by comparing it with permuted ordering of\nshared layers. The results indicate that a flexible ordering can enable more\neffective sharing, thus motivating the development of a soft ordering approach,\nwhich learns how shared layers are applied in different ways for different\ntasks. Deep MTL with soft ordering outperforms parallel ordering methods across\na series of domains. These results suggest that the power of deep MTL comes\nfrom learning highly general building blocks that can be assembled to meet the\ndemands of each task.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 20:55:06 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 02:05:34 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Meyerson", "Elliot", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "1711.00123", "submitter": "Will Grathwohl", "authors": "Will Grathwohl, Dami Choi, Yuhuai Wu, Geoffrey Roeder, David Duvenaud", "title": "Backpropagation through the Void: Optimizing control variates for\n  black-box gradient estimation", "comments": "Published at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based optimization is the foundation of deep learning and\nreinforcement learning. Even when the mechanism being optimized is unknown or\nnot differentiable, optimization using high-variance or biased gradient\nestimates is still often the best strategy. We introduce a general framework\nfor learning low-variance, unbiased gradient estimators for black-box functions\nof random variables. Our method uses gradients of a neural network trained\njointly with model parameters or policies, and is applicable in both discrete\nand continuous settings. We demonstrate this framework for training discrete\nlatent-variable models. We also give an unbiased, action-conditional extension\nof the advantage actor-critic reinforcement learning algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 21:58:13 GMT"}, {"version": "v2", "created": "Wed, 8 Nov 2017 23:11:31 GMT"}, {"version": "v3", "created": "Fri, 23 Feb 2018 22:36:22 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Grathwohl", "Will", ""], ["Choi", "Dami", ""], ["Wu", "Yuhuai", ""], ["Roeder", "Geoffrey", ""], ["Duvenaud", "David", ""]]}, {"id": "1711.00126", "submitter": "Abolfazl Hashemi", "authors": "Abolfazl Hashemi and Haris Vikalo", "title": "Accelerated Sparse Subspace Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art algorithms for sparse subspace clustering perform spectral\nclustering on a similarity matrix typically obtained by representing each data\npoint as a sparse combination of other points using either basis pursuit (BP)\nor orthogonal matching pursuit (OMP). BP-based methods are often prohibitive in\npractice while the performance of OMP-based schemes are unsatisfactory,\nespecially in settings where data points are highly similar. In this paper, we\npropose a novel algorithm that exploits an accelerated variant of orthogonal\nleast-squares to efficiently find the underlying subspaces. We show that under\ncertain conditions the proposed algorithm returns a subspace-preserving\nsolution. Simulation results illustrate that the proposed method compares\nfavorably with BP-based method in terms of running time while being\nsignificantly more accurate than OMP-based schemes.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 22:05:47 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Hashemi", "Abolfazl", ""], ["Vikalo", "Haris", ""]]}, {"id": "1711.00137", "submitter": "Jacob Schreiber", "authors": "Jacob Schreiber", "title": "Pomegranate: fast and flexible probabilistic modeling in python", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present pomegranate, an open source machine learning package for\nprobabilistic modeling in Python. Probabilistic modeling encompasses a wide\nrange of methods that explicitly describe uncertainty using probability\ndistributions. Three widely used probabilistic models implemented in\npomegranate are general mixture models, hidden Markov models, and Bayesian\nnetworks. A primary focus of pomegranate is to abstract away the complexities\nof training models from their definition. This allows users to focus on\nspecifying the correct model for their application instead of being limited by\ntheir understanding of the underlying algorithms. An aspect of this focus\ninvolves the collection of additive sufficient statistics from data sets as a\nstrategy for training models. This approach trivially enables many useful\nlearning strategies, such as out-of-core learning, minibatch learning, and\nsemi-supervised learning, without requiring the user to consider how to\npartition data or modify the algorithms to handle these tasks themselves.\npomegranate is written in Cython to speed up calculations and releases the\nglobal interpreter lock to allow for built-in multithreaded parallelism, making\nit competitive with---or outperform---other implementations of similar\nalgorithms. This paper presents an overview of the design choices in\npomegranate, and how they have enabled complex features to be supported by\nsimple code.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 22:53:20 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 23:43:16 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Schreiber", "Jacob", ""]]}, {"id": "1711.00141", "submitter": "Haoyang Zeng", "authors": "Constantinos Daskalakis, Andrew Ilyas, Vasilis Syrgkanis, Haoyang Zeng", "title": "Training GANs with Optimism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the issue of limit cycling behavior in training Generative\nAdversarial Networks and propose the use of Optimistic Mirror Decent (OMD) for\ntraining Wasserstein GANs. Recent theoretical results have shown that\noptimistic mirror decent (OMD) can enjoy faster regret rates in the context of\nzero-sum games. WGANs is exactly a context of solving a zero-sum game with\nsimultaneous no-regret dynamics. Moreover, we show that optimistic mirror\ndecent addresses the limit cycling problem in training WGANs. We formally show\nthat in the case of bi-linear zero-sum games the last iterate of OMD dynamics\nconverges to an equilibrium, in contrast to GD dynamics which are bound to\ncycle. We also portray the huge qualitative difference between GD and OMD\ndynamics with toy examples, even when GD is modified with many adaptations\nproposed in the recent literature, such as gradient penalty or momentum. We\napply OMD WGAN training to a bioinformatics problem of generating DNA\nsequences. We observe that models trained with OMD achieve consistently smaller\nKL divergence with respect to the true underlying distribution, than models\ntrained with GD variants. Finally, we introduce a new algorithm, Optimistic\nAdam, which is an optimistic variant of Adam. We apply it to WGAN training on\nCIFAR10 and observe improved performance in terms of inception score as\ncompared to Adam.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 23:09:08 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 16:33:55 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Ilyas", "Andrew", ""], ["Syrgkanis", "Vasilis", ""], ["Zeng", "Haoyang", ""]]}, {"id": "1711.00142", "submitter": "Abolfazl Hashemi", "authors": "Abolfazl Hashemi, Rasoul Shafipour, Haris Vikalo, and Gonzalo Mateos", "title": "Sampling and Reconstruction of Graph Signals via Weak Submodularity and\n  Semidefinite Relaxation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of sampling a bandlimited graph signal in the presence\nof noise, where the objective is to select a node subset of prescribed\ncardinality that minimizes the signal reconstruction mean squared error (MSE).\nTo that end, we formulate the task at hand as the minimization of MSE subject\nto binary constraints, and approximate the resulting NP-hard problem via\nsemidefinite programming (SDP) relaxation. Moreover, we provide an alternative\nformulation based on maximizing a monotone weak submodular function and propose\na randomized-greedy algorithm to find a sub-optimal subset. We then derive a\nworst-case performance guarantee on the MSE returned by the randomized greedy\nalgorithm for general non-stationary graph signals. The efficacy of the\nproposed methods is illustrated through numerical simulations on synthetic and\nreal-world graphs. Notably, the randomized greedy algorithm yields an\norder-of-magnitude speedup over state-of-the-art greedy sampling schemes, while\nincurring only a marginal MSE performance loss.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 23:29:25 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Hashemi", "Abolfazl", ""], ["Shafipour", "Rasoul", ""], ["Vikalo", "Haris", ""], ["Mateos", "Gonzalo", ""]]}, {"id": "1711.00146", "submitter": "Miquel Mart\\'i I Rabad\\'an", "authors": "Miquel Mart\\'i and Atsuto Maki", "title": "A multitask deep learning model for real-time deployment in embedded\n  systems", "comments": "2 pages, 5 figures. Poster presentation at Swedish Symposium on Deep\n  Learning SSDL2017, Stockholm, Sweden. June 20-21, 2017", "journal-ref": "Swedish Symposium on Deep Learning 2017", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach to Multitask Learning (MTL) to make deep learning\nmodels faster and lighter for applications in which multiple tasks need to be\nsolved simultaneously, which is particularly useful in embedded, real-time\nsystems. We develop a multitask model for both Object Detection and Semantic\nSegmentation and analyze the challenges that appear during its training. Our\nmultitask network is 1.6x faster, lighter and uses less memory than deploying\nthe single-task models in parallel. We conclude that MTL has the potential to\ngive superior performance in exchange of a more complex training process that\nintroduces challenges not present in single-task models.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 23:59:23 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Mart\u00ed", "Miquel", ""], ["Maki", "Atsuto", ""]]}, {"id": "1711.00165", "submitter": "Yasaman Bahri", "authors": "Jaehoon Lee, Yasaman Bahri, Roman Novak, Samuel S. Schoenholz, Jeffrey\n  Pennington, Jascha Sohl-Dickstein", "title": "Deep Neural Networks as Gaussian Processes", "comments": "Published version in ICLR 2018. 10 pages + appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has long been known that a single-layer fully-connected neural network\nwith an i.i.d. prior over its parameters is equivalent to a Gaussian process\n(GP), in the limit of infinite network width. This correspondence enables exact\nBayesian inference for infinite width neural networks on regression tasks by\nmeans of evaluating the corresponding GP. Recently, kernel functions which\nmimic multi-layer random neural networks have been developed, but only outside\nof a Bayesian framework. As such, previous work has not identified that these\nkernels can be used as covariance functions for GPs and allow fully Bayesian\nprediction with a deep neural network.\n  In this work, we derive the exact equivalence between infinitely wide deep\nnetworks and GPs. We further develop a computationally efficient pipeline to\ncompute the covariance function for these GPs. We then use the resulting GPs to\nperform Bayesian inference for wide deep neural networks on MNIST and CIFAR-10.\nWe observe that trained neural network accuracy approaches that of the\ncorresponding GP with increasing layer width, and that the GP uncertainty is\nstrongly correlated with trained network prediction error. We further find that\ntest performance increases as finite-width trained networks are made wider and\nmore similar to a GP, and thus that GP predictions typically outperform those\nof finite-width networks. Finally we connect the performance of these GPs to\nthe recent theory of signal propagation in random neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 02:13:25 GMT"}, {"version": "v2", "created": "Wed, 17 Jan 2018 02:50:16 GMT"}, {"version": "v3", "created": "Sat, 3 Mar 2018 00:45:00 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Lee", "Jaehoon", ""], ["Bahri", "Yasaman", ""], ["Novak", "Roman", ""], ["Schoenholz", "Samuel S.", ""], ["Pennington", "Jeffrey", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1711.00215", "submitter": "Bert Moons", "authors": "Bert Moons, Koen Goetschalckx, Nick Van Berckelaer, Marian Verhelst", "title": "Minimum Energy Quantized Neural Networks", "comments": "preprint for work presented at the 51st Asilomar Conference on\n  Signals, Systems and Computers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work targets the automated minimum-energy optimization of Quantized\nNeural Networks (QNNs) - networks using low precision weights and activations.\nThese networks are trained from scratch at an arbitrary fixed point precision.\nAt iso-accuracy, QNNs using fewer bits require deeper and wider network\narchitectures than networks using higher precision operators, while they\nrequire less complex arithmetic and less bits per weights. This fundamental\ntrade-off is analyzed and quantified to find the minimum energy QNN for any\nbenchmark and hence optimize energy-efficiency. To this end, the energy\nconsumption of inference is modeled for a generic hardware platform. This\nallows drawing several conclusions across different benchmarks. First, energy\nconsumption varies orders of magnitude at iso-accuracy depending on the number\nof bits used in the QNN. Second, in a typical system, BinaryNets or int4\nimplementations lead to the minimum energy solution, outperforming int8\nnetworks up to 2-10x at iso-accuracy. All code used for QNN training is\navailable from https://github.com/BertMoons.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 05:50:19 GMT"}, {"version": "v2", "created": "Thu, 23 Nov 2017 09:37:02 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Moons", "Bert", ""], ["Goetschalckx", "Koen", ""], ["Van Berckelaer", "Nick", ""], ["Verhelst", "Marian", ""]]}, {"id": "1711.00221", "submitter": "Haibin Yu", "authors": "Haibin Yu, Trong Nghia Hoang, Kian Hsiang Low, Patrick Jaillet", "title": "Stochastic Variational Inference for Bayesian Sparse Gaussian Process\n  Regression", "comments": "To appear in Proceedings of the International Joint Conference on\n  Neural Networks 2019 (IJCNN'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel variational inference framework for deriving a\nfamily of Bayesian sparse Gaussian process regression (SGPR) models whose\napproximations are variationally optimal with respect to the full-rank GPR\nmodel enriched with various corresponding correlation structures of the\nobservation noises. Our variational Bayesian SGPR (VBSGPR) models jointly treat\nboth the distributions of the inducing variables and hyperparameters as\nvariational parameters, which enables the decomposability of the variational\nlower bound that in turn can be exploited for stochastic optimization. Such a\nstochastic optimization involves iteratively following the stochastic gradient\nof the variational lower bound to improve its estimates of the optimal\nvariational distributions of the inducing variables and hyperparameters (and\nhence the predictive distribution) of our VBSGPR models and is guaranteed to\nachieve asymptotic convergence to them. We show that the stochastic gradient is\nan unbiased estimator of the exact gradient and can be computed in constant\ntime per iteration, hence achieving scalability to big data. We empirically\nevaluate the performance of our proposed framework on two real-world, massive\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 06:30:03 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 00:06:02 GMT"}, {"version": "v3", "created": "Fri, 22 Mar 2019 06:46:30 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Yu", "Haibin", ""], ["Hoang", "Trong Nghia", ""], ["Low", "Kian Hsiang", ""], ["Jaillet", "Patrick", ""]]}, {"id": "1711.00239", "submitter": "Chenping Hou", "authors": "Chenping Hou, Ling-Li Zeng, Dewen Hu", "title": "Secure Classification With Augmented Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the evolution of data collection ways, it is possible to produce\nabundant data described by multiple feature sets. Previous studies show that\nincluding more features does not necessarily bring positive effect. How to\nprevent the augmented features worsening classification performance is crucial\nbut rarely studied. In this paper, we study this challenging problem by\nproposing a secure classification approach, whose accuracy is never degenerated\nwhen exploiting augmented features. We propose two ways to achieve the security\nof our method named as SEcure Classification (SEC). Firstly, to leverage\naugmented features, we learn various types of classifiers and adapt them by\nemploying a specially designed robust loss. It provides various candidate\nclassifiers to meet the following assumption of security operation. Secondly,\nwe integrate all candidate classifiers by approximately maximizing the\nperformance improvement. Under a mild assumption, the integrated classifier has\ntheoretical security guarantee. Several new optimization methods have been\ndeveloped to accommodate the problems with proved convergence. Besides\nevaluating SEC on 16 data sets, we also apply SEC in the application of\ndiagnostic classification of schizophrenia since it has vast application\npotentiality. Experimental results demonstrate the effectiveness of SEC in both\ntackling security problem and discriminating schizophrenic patients from\nhealthy controls.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 07:57:54 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Hou", "Chenping", ""], ["Zeng", "Ling-Li", ""], ["Hu", "Dewen", ""]]}, {"id": "1711.00244", "submitter": "Anamitra R. Choudhury", "authors": "Dharma Teja Vooturi, Saurabh Goyal, Anamitra R. Choudhury, Yogish\n  Sabharwal, Ashish Verma", "title": "Efficient Inferencing of Compressed Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large number of weights in deep neural networks makes the models difficult to\nbe deployed in low memory environments such as, mobile phones, IOT edge devices\nas well as \"inferencing as a service\" environments on cloud. Prior work has\nconsidered reduction in the size of the models, through compression techniques\nlike pruning, quantization, Huffman encoding etc. However, efficient\ninferencing using the compressed models has received little attention,\nspecially with the Huffman encoding in place. In this paper, we propose\nefficient parallel algorithms for inferencing of single image and batches,\nunder various memory constraints. Our experimental results show that our\napproach of using variable batch size for inferencing achieves 15-25\\%\nperformance improvement in the inference throughput for AlexNet, while\nmaintaining memory and latency constraints.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 08:16:40 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Vooturi", "Dharma Teja", ""], ["Goyal", "Saurabh", ""], ["Choudhury", "Anamitra R.", ""], ["Sabharwal", "Yogish", ""], ["Verma", "Ashish", ""]]}, {"id": "1711.00258", "submitter": "Yucen Luo", "authors": "Yucen Luo, Jun Zhu, Mengxi Li, Yong Ren, Bo Zhang", "title": "Smooth Neighbors on Teacher Graphs for Semi-supervised Learning", "comments": "Accept as Spotlight in Computer Vision and Pattern Recognition 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed self-ensembling methods have achieved promising results\nin deep semi-supervised learning, which penalize inconsistent predictions of\nunlabeled data under different perturbations. However, they only consider\nadding perturbations to each single data point, while ignoring the connections\nbetween data samples. In this paper, we propose a novel method, called Smooth\nNeighbors on Teacher Graphs (SNTG). In SNTG, a graph is constructed based on\nthe predictions of the teacher model, i.e., the implicit self-ensemble of\nmodels. Then the graph serves as a similarity measure with respect to which the\nrepresentations of \"similar\" neighboring points are learned to be smooth on the\nlow-dimensional manifold. We achieve state-of-the-art results on\nsemi-supervised learning benchmarks. The error rates are 9.89%, 3.99% for\nCIFAR-10 with 4000 labels, SVHN with 500 labels, respectively. In particular,\nthe improvements are significant when the labels are fewer. For the\nnon-augmented MNIST with only 20 labels, the error rate is reduced from\nprevious 4.81% to 1.36%. Our method also shows robustness to noisy labels.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 09:10:07 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 14:53:05 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Luo", "Yucen", ""], ["Zhu", "Jun", ""], ["Li", "Mengxi", ""], ["Ren", "Yong", ""], ["Zhang", "Bo", ""]]}, {"id": "1711.00267", "submitter": "Wenbin Li", "authors": "Wenbin Li, Jeannette Bohg, Mario Fritz", "title": "Acquiring Target Stacking Skills by Goal-Parameterized Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding physical phenomena is a key component of human intelligence and\nenables physical interaction with previously unseen environments. In this\npaper, we study how an artificial agent can autonomously acquire this intuition\nthrough interaction with the environment. We created a synthetic block stacking\nenvironment with physics simulation in which the agent can learn a policy\nend-to-end through trial and error. Thereby, we bypass to explicitly model\nphysical knowledge within the policy. We are specifically interested in tasks\nthat require the agent to reach a given goal state that may be different for\nevery new trial. To this end, we propose a deep reinforcement learning\nframework that learns policies which are parametrized by a goal. We validated\nthe model on a toy example navigating in a grid world with different target\npositions and in a block stacking task with different target structures of the\nfinal tower. In contrast to prior work, our policies show better generalization\nacross different goals.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 10:04:29 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 11:38:17 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Li", "Wenbin", ""], ["Bohg", "Jeannette", ""], ["Fritz", "Mario", ""]]}, {"id": "1711.00313", "submitter": "Mostafa Dehghani", "authors": "Mostafa Dehghani, Aliaksei Severyn, Sascha Rothe, Jaap Kamps", "title": "Avoiding Your Teacher's Mistakes: Training Neural Networks with\n  Controlled Weak Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks requires massive amounts of training data, but\nfor many tasks only limited labeled data is available. This makes weak\nsupervision attractive, using weak or noisy signals like the output of\nheuristic methods or user click-through data for training. In a semi-supervised\nsetting, we can use a large set of data with weak labels to pretrain a neural\nnetwork and then fine-tune the parameters with a small amount of data with true\nlabels. This feels intuitively sub-optimal as these two independent stages\nleave the model unaware about the varying label quality. What if we could\nsomehow inform the model about the label quality? In this paper, we propose a\nsemi-supervised learning method where we train two neural networks in a\nmulti-task fashion: a \"target network\" and a \"confidence network\". The target\nnetwork is optimized to perform a given task and is trained using a large set\nof unlabeled data that are weakly annotated. We propose to weight the gradient\nupdates to the target network using the scores provided by the second\nconfidence network, which is trained on a small amount of supervised data. Thus\nwe avoid that the weight updates computed from noisy labels harm the quality of\nthe target network model. We evaluate our learning strategy on two different\ntasks: document ranking and sentiment classification. The results demonstrate\nthat our approach not only enhances the performance compared to the baselines\nbut also speeds up the learning process from weak labels.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 12:38:59 GMT"}, {"version": "v2", "created": "Thu, 7 Dec 2017 14:30:18 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Dehghani", "Mostafa", ""], ["Severyn", "Aliaksei", ""], ["Rothe", "Sascha", ""], ["Kamps", "Jaap", ""]]}, {"id": "1711.00342", "submitter": "Lester Mackey", "authors": "Lester Mackey, Vasilis Syrgkanis, Ilias Zadik", "title": "Orthogonal Machine Learning: Power and Limitations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Double machine learning provides $\\sqrt{n}$-consistent estimates of\nparameters of interest even when high-dimensional or nonparametric nuisance\nparameters are estimated at an $n^{-1/4}$ rate. The key is to employ\nNeyman-orthogonal moment equations which are first-order insensitive to\nperturbations in the nuisance parameters. We show that the $n^{-1/4}$\nrequirement can be improved to $n^{-1/(2k+2)}$ by employing a $k$-th order\nnotion of orthogonality that grants robustness to more complex or\nhigher-dimensional nuisance parameters. In the partially linear regression\nsetting popular in causal inference, we show that we can construct second-order\northogonal moments if and only if the treatment residual is not normally\ndistributed. Our proof relies on Stein's lemma and may be of independent\ninterest. We conclude by demonstrating the robustness benefits of an explicit\ndoubly-orthogonal estimation procedure for treatment effect.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 13:42:54 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 22:49:28 GMT"}, {"version": "v3", "created": "Thu, 21 Dec 2017 03:16:15 GMT"}, {"version": "v4", "created": "Tue, 12 Jun 2018 02:25:49 GMT"}, {"version": "v5", "created": "Sat, 16 Jun 2018 05:07:05 GMT"}, {"version": "v6", "created": "Wed, 1 Aug 2018 18:40:19 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Mackey", "Lester", ""], ["Syrgkanis", "Vasilis", ""], ["Zadik", "Ilias", ""]]}, {"id": "1711.00350", "submitter": "Brenden Lake", "authors": "Brenden M. Lake and Marco Baroni", "title": "Generalization without systematicity: On the compositional skills of\n  sequence-to-sequence recurrent networks", "comments": "Published at the 35th International Conference on Machine Learning\n  (ICML 2018)", "journal-ref": "Lake, B. M. and Baroni, M. (2018). Generalization without\n  systematicity: On the compositional skills of sequence-to-sequence recurrent\n  networks. International Conference on Machine Learning (ICML)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can understand and produce new utterances effortlessly, thanks to\ntheir compositional skills. Once a person learns the meaning of a new verb\n\"dax,\" he or she can immediately understand the meaning of \"dax twice\" or \"sing\nand dax.\" In this paper, we introduce the SCAN domain, consisting of a set of\nsimple compositional navigation commands paired with the corresponding action\nsequences. We then test the zero-shot generalization capabilities of a variety\nof recurrent neural networks (RNNs) trained on SCAN with sequence-to-sequence\nmethods. We find that RNNs can make successful zero-shot generalizations when\nthe differences between training and test commands are small, so that they can\napply \"mix-and-match\" strategies to solve the task. However, when\ngeneralization requires systematic compositional skills (as in the \"dax\"\nexample above), RNNs fail spectacularly. We conclude with a proof-of-concept\nexperiment in neural machine translation, suggesting that lack of systematicity\nmight be partially responsible for neural networks' notorious training data\nthirst.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 01:50:02 GMT"}, {"version": "v2", "created": "Sun, 11 Feb 2018 21:55:39 GMT"}, {"version": "v3", "created": "Wed, 6 Jun 2018 20:52:51 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Lake", "Brenden M.", ""], ["Baroni", "Marco", ""]]}, {"id": "1711.00355", "submitter": "Daniyal Amir Awan", "authors": "Daniyal Amir Awan, Renato L.G. Cavalcante, Masahiro Yukawa, Slawomir\n  Stanczak", "title": "Detection for 5G-NOMA: An Online Adaptive Machine Learning Approach", "comments": "Accepted at ICC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-orthogonal multiple access (NOMA) has emerged as a promising radio access\ntechnique for enabling the performance enhancements promised by the\nfifth-generation (5G) networks in terms of connectivity, low latency, and high\nspectrum efficiency. In the NOMA uplink, successive interference cancellation\n(SIC) based detection with device clustering has been suggested. In the case of\nmultiple receive antennas, SIC can be combined with the minimum mean-squared\nerror (MMSE) beamforming. However, there exists a tradeoff between the NOMA\ncluster size and the incurred SIC error. Larger clusters lead to larger errors\nbut they are desirable from the spectrum efficiency and connectivity point of\nview. We propose a novel online learning based detection for the NOMA uplink.\nIn particular, we design an online adaptive filter in the sum space of linear\nand Gaussian reproducing kernel Hilbert spaces (RKHSs). Such a sum space design\nis robust against variations of a dynamic wireless network that can deteriorate\nthe performance of a purely nonlinear adaptive filter. We demonstrate by\nsimulations that the proposed method outperforms the MMSE-SIC based detection\nfor large cluster sizes.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 14:09:58 GMT"}, {"version": "v2", "created": "Thu, 11 Jan 2018 18:55:59 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Awan", "Daniyal Amir", ""], ["Cavalcante", "Renato L. G.", ""], ["Yukawa", "Masahiro", ""], ["Stanczak", "Slawomir", ""]]}, {"id": "1711.00366", "submitter": "Lantian Li Mr.", "authors": "Lantian Li, Zhiyuan Tang, Dong Wang, Thomas Fang Zheng", "title": "Full-info Training for Deep Speaker Feature Learning", "comments": "Accepted by ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent studies, it has shown that speaker patterns can be learned from\nvery short speech segments (e.g., 0.3 seconds) by a carefully designed\nconvolutional & time-delay deep neural network (CT-DNN) model. By enforcing the\nmodel to discriminate the speakers in the training data, frame-level speaker\nfeatures can be derived from the last hidden layer. In spite of its good\nperformance, a potential problem of the present model is that it involves a\nparametric classifier, i.e., the last affine layer, which may consume some\ndiscriminative knowledge, thus leading to `information leak' for the feature\nlearning. This paper presents a full-info training approach that discards the\nparametric classifier and enforces all the discriminative knowledge learned by\nthe feature net. Our experiments on the Fisher database demonstrate that this\nnew training scheme can produce more coherent features, leading to consistent\nand notable performance improvement on the speaker verification task.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 12:44:23 GMT"}, {"version": "v2", "created": "Sun, 25 Feb 2018 05:42:01 GMT"}, {"version": "v3", "created": "Tue, 27 Feb 2018 09:57:22 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Li", "Lantian", ""], ["Tang", "Zhiyuan", ""], ["Wang", "Dong", ""], ["Zheng", "Thomas Fang", ""]]}, {"id": "1711.00388", "submitter": "Lunjia Hu", "authors": "Avrim Blum, Lunjia Hu", "title": "Active Tolerant Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we give the first algorithms for tolerant testing of nontrivial\nclasses in the active model: estimating the distance of a target function to a\nhypothesis class C with respect to some arbitrary distribution D, using only a\nsmall number of label queries to a polynomial-sized pool of unlabeled examples\ndrawn from D. Specifically, we show that for the class D of unions of d\nintervals on the line, we can estimate the error rate of the best hypothesis in\nthe class to an additive error epsilon from only $O(\\frac{1}{\\epsilon^6}\\log\n\\frac{1}{\\epsilon})$ label queries to an unlabeled pool of size\n$O(\\frac{d}{\\epsilon^2}\\log \\frac{1}{\\epsilon})$. The key point here is the\nnumber of labels needed is independent of the VC-dimension of the class. This\nextends the work of Balcan et al. [2012] who solved the non-tolerant testing\nproblem for this class (distinguishing the zero-error case from the case that\nthe best hypothesis in the class has error greater than epsilon).\n  We also consider the related problem of estimating the performance of a given\nlearning algorithm A in this setting. That is, given a large pool of unlabeled\nexamples drawn from distribution D, can we, from only a few label queries,\nestimate how well A would perform if the entire dataset were labeled? We focus\non k-Nearest Neighbor style algorithms, and also show how our results can be\napplied to the problem of hyperparameter tuning (selecting the best value of k\nfor the given learning problem).\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 15:20:13 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Blum", "Avrim", ""], ["Hu", "Lunjia", ""]]}, {"id": "1711.00400", "submitter": "Richard Combes", "authors": "Richard Combes, Stefan Magureanu and Alexandre Proutiere", "title": "Minimal Exploration in Structured Stochastic Bandits", "comments": "13 pages, NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces and addresses a wide class of stochastic bandit\nproblems where the function mapping the arm to the corresponding reward\nexhibits some known structural properties. Most existing structures (e.g.\nlinear, Lipschitz, unimodal, combinatorial, dueling, ...) are covered by our\nframework. We derive an asymptotic instance-specific regret lower bound for\nthese problems, and develop OSSB, an algorithm whose regret matches this\nfundamental limit. OSSB is not based on the classical principle of \"optimism in\nthe face of uncertainty\" or on Thompson sampling, and rather aims at matching\nthe minimal exploration rates of sub-optimal arms as characterized in the\nderivation of the regret lower bound. We illustrate the efficiency of OSSB\nusing numerical experiments in the case of the linear bandit problem and show\nthat OSSB outperforms existing algorithms, including Thompson sampling.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 15:40:26 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Combes", "Richard", ""], ["Magureanu", "Stefan", ""], ["Proutiere", "Alexandre", ""]]}, {"id": "1711.00436", "submitter": "Hanxiao Liu", "authors": "Hanxiao Liu, Karen Simonyan, Oriol Vinyals, Chrisantha Fernando, Koray\n  Kavukcuoglu", "title": "Hierarchical Representations for Efficient Architecture Search", "comments": "Accepted as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore efficient neural architecture search methods and show that a\nsimple yet powerful evolutionary algorithm can discover new architectures with\nexcellent performance. Our approach combines a novel hierarchical genetic\nrepresentation scheme that imitates the modularized design pattern commonly\nadopted by human experts, and an expressive search space that supports complex\ntopologies. Our algorithm efficiently discovers architectures that outperform a\nlarge number of manually designed models for image classification, obtaining\ntop-1 error of 3.6% on CIFAR-10 and 20.3% when transferred to ImageNet, which\nis competitive with the best existing neural architecture search approaches. We\nalso present results using random search, achieving 0.3% less top-1 accuracy on\nCIFAR-10 and 0.1% less on ImageNet whilst reducing the search time from 36\nhours down to 1 hour.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 16:46:27 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 22:31:30 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Liu", "Hanxiao", ""], ["Simonyan", "Karen", ""], ["Vinyals", "Oriol", ""], ["Fernando", "Chrisantha", ""], ["Kavukcuoglu", "Koray", ""]]}, {"id": "1711.00439", "submitter": "Shashanka Ubaru", "authors": "Shashanka Ubaru and Yousef Saad", "title": "Sampling and multilevel coarsening algorithms for fast matrix\n  approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses matrix approximation problems for matrices that are\nlarge, sparse and/or that are representations of large graphs. To tackle these\nproblems, we consider algorithms that are based primarily on coarsening\ntechniques, possibly combined with random sampling. A multilevel coarsening\ntechnique is proposed which utilizes a hypergraph associated with the data\nmatrix and a graph coarsening strategy based on column matching. Theoretical\nresults are established that characterize the quality of the dimension\nreduction achieved by a coarsening step, when a proper column matching strategy\nis employed. We consider a number of standard applications of this technique as\nwell as a few new ones. Among the standard applications we first consider the\nproblem of computing the partial SVD for which a combination of sampling and\ncoarsening yields significantly improved SVD results relative to sampling\nalone. We also consider the Column subset selection problem, a popular low rank\napproximation method used in data related applications, and show how multilevel\ncoarsening can be adapted for this problem. Similarly, we consider the problem\nof graph sparsification and show how coarsening techniques can be employed to\nsolve it. Numerical experiments illustrate the performances of the methods in\nvarious applications.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 16:57:51 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 18:06:41 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Ubaru", "Shashanka", ""], ["Saad", "Yousef", ""]]}, {"id": "1711.00449", "submitter": "Angus Galloway", "authors": "Angus Galloway, Graham W. Taylor, Medhat Moussa", "title": "Attacking Binarized Neural Networks", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks with low-precision weights and activations offer compelling\nefficiency advantages over their full-precision equivalents. The two most\nfrequently discussed benefits of quantization are reduced memory consumption,\nand a faster forward pass when implemented with efficient bitwise operations.\nWe propose a third benefit of very low-precision neural networks: improved\nrobustness against some adversarial attacks, and in the worst case, performance\nthat is on par with full-precision models. We focus on the very low-precision\ncase where weights and activations are both quantized to $\\pm$1, and note that\nstochastically quantizing weights in just one layer can sharply reduce the\nimpact of iterative attacks. We observe that non-scaled binary neural networks\nexhibit a similar effect to the original defensive distillation procedure that\nled to gradient masking, and a false notion of security. We address this by\nconducting both black-box and white-box experiments with binary models that do\nnot artificially mask gradients.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 17:28:26 GMT"}, {"version": "v2", "created": "Wed, 31 Jan 2018 17:03:31 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Galloway", "Angus", ""], ["Taylor", "Graham W.", ""], ["Moussa", "Medhat", ""]]}, {"id": "1711.00455", "submitter": "Rudy Bunel", "authors": "Rudy Bunel, Ilker Turkaslan, Philip H.S. Torr, Pushmeet Kohli, M.\n  Pawan Kumar", "title": "A Unified View of Piecewise Linear Neural Network Verification", "comments": "Updated version of \"Piecewise Linear Neural Network verification: A\n  comparative study\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of Deep Learning and its potential use in many safety-critical\napplications has motivated research on formal verification of Neural Network\n(NN) models. Despite the reputation of learned NN models to behave as black\nboxes and the theoretical hardness of proving their properties, researchers\nhave been successful in verifying some classes of models by exploiting their\npiecewise linear structure and taking insights from formal methods such as\nSatisifiability Modulo Theory. These methods are however still far from scaling\nto realistic neural networks. To facilitate progress on this crucial area, we\nmake two key contributions. First, we present a unified framework that\nencompasses previous methods. This analysis results in the identification of\nnew methods that combine the strengths of multiple existing approaches,\naccomplishing a speedup of two orders of magnitude compared to the previous\nstate of the art. Second, we propose a new data set of benchmarks which\nincludes a collection of previously released testcases. We use the benchmark to\nprovide the first experimental comparison of existing algorithms and identify\nthe factors impacting the hardness of verification problems.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 17:42:12 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 09:58:39 GMT"}, {"version": "v3", "created": "Tue, 22 May 2018 10:37:06 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Bunel", "Rudy", ""], ["Turkaslan", "Ilker", ""], ["Torr", "Philip H. S.", ""], ["Kohli", "Pushmeet", ""], ["Kumar", "M. Pawan", ""]]}, {"id": "1711.00464", "submitter": "Alexander Alemi", "authors": "Alexander A. Alemi, Ben Poole, Ian Fischer, Joshua V. Dillon, Rif A.\n  Saurous, Kevin Murphy", "title": "Fixing a Broken ELBO", "comments": "21 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in unsupervised representation learning has focused on learning\ndeep directed latent-variable models. Fitting these models by maximizing the\nmarginal likelihood or evidence is typically intractable, thus a common\napproximation is to maximize the evidence lower bound (ELBO) instead. However,\nmaximum likelihood training (whether exact or approximate) does not necessarily\nresult in a good latent representation, as we demonstrate both theoretically\nand empirically. In particular, we derive variational lower and upper bounds on\nthe mutual information between the input and the latent variable, and use these\nbounds to derive a rate-distortion curve that characterizes the tradeoff\nbetween compression and reconstruction accuracy. Using this framework, we\ndemonstrate that there is a family of models with identical ELBO, but different\nquantitative and qualitative characteristics. Our framework also suggests a\nsimple new method to ensure that latent variable models with powerful\nstochastic decoders do not ignore their latent code.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 17:58:43 GMT"}, {"version": "v2", "created": "Fri, 5 Jan 2018 19:34:58 GMT"}, {"version": "v3", "created": "Tue, 13 Feb 2018 20:54:38 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Alemi", "Alexander A.", ""], ["Poole", "Ben", ""], ["Fischer", "Ian", ""], ["Dillon", "Joshua V.", ""], ["Saurous", "Rif A.", ""], ["Murphy", "Kevin", ""]]}, {"id": "1711.00489", "submitter": "Samuel L. Smith", "authors": "Samuel L. Smith, Pieter-Jan Kindermans, Chris Ying and Quoc V. Le", "title": "Don't Decay the Learning Rate, Increase the Batch Size", "comments": "11 pages, 8 figures. Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common practice to decay the learning rate. Here we show one can\nusually obtain the same learning curve on both training and test sets by\ninstead increasing the batch size during training. This procedure is successful\nfor stochastic gradient descent (SGD), SGD with momentum, Nesterov momentum,\nand Adam. It reaches equivalent test accuracies after the same number of\ntraining epochs, but with fewer parameter updates, leading to greater\nparallelism and shorter training times. We can further reduce the number of\nparameter updates by increasing the learning rate $\\epsilon$ and scaling the\nbatch size $B \\propto \\epsilon$. Finally, one can increase the momentum\ncoefficient $m$ and scale $B \\propto 1/(1-m)$, although this tends to slightly\nreduce the test accuracy. Crucially, our techniques allow us to repurpose\nexisting training schedules for large batch training with no hyper-parameter\ntuning. We train ResNet-50 on ImageNet to $76.1\\%$ validation accuracy in under\n30 minutes.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 18:04:31 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 00:16:12 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Smith", "Samuel L.", ""], ["Kindermans", "Pieter-Jan", ""], ["Ying", "Chris", ""], ["Le", "Quoc V.", ""]]}, {"id": "1711.00501", "submitter": "Tengyu Ma", "authors": "Rong Ge, Jason D. Lee, Tengyu Ma", "title": "Learning One-hidden-layer Neural Networks with Landscape Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a one-hidden-layer neural network: we\nassume the input $x\\in \\mathbb{R}^d$ is from Gaussian distribution and the\nlabel $y = a^\\top \\sigma(Bx) + \\xi$, where $a$ is a nonnegative vector in\n$\\mathbb{R}^m$ with $m\\le d$, $B\\in \\mathbb{R}^{m\\times d}$ is a full-rank\nweight matrix, and $\\xi$ is a noise vector. We first give an analytic formula\nfor the population risk of the standard squared loss and demonstrate that it\nimplicitly attempts to decompose a sequence of low-rank tensors simultaneously.\n  Inspired by the formula, we design a non-convex objective function $G(\\cdot)$\nwhose landscape is guaranteed to have the following properties: 1. All local\nminima of $G$ are also global minima.\n  2. All global minima of $G$ correspond to the ground truth parameters.\n  3. The value and gradient of $G$ can be estimated using samples.\n  With these properties, stochastic gradient descent on $G$ provably converges\nto the global minimum and learn the ground-truth parameters. We also prove\nfinite sample complexity result and validate the results by simulations.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 18:27:42 GMT"}, {"version": "v2", "created": "Fri, 3 Nov 2017 00:19:35 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Ge", "Rong", ""], ["Lee", "Jason D.", ""], ["Ma", "Tengyu", ""]]}, {"id": "1711.00541", "submitter": "Yi Luo", "authors": "Yi Luo, Nima Mesgarani", "title": "TasNet: time-domain audio separation network for real-time,\n  single-channel speech separation", "comments": "Camera ready version for ICASSP 2018, Calgary, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM cs.NE eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Robust speech processing in multi-talker environments requires effective\nspeech separation. Recent deep learning systems have made significant progress\ntoward solving this problem, yet it remains challenging particularly in\nreal-time, short latency applications. Most methods attempt to construct a mask\nfor each source in time-frequency representation of the mixture signal which is\nnot necessarily an optimal representation for speech separation. In addition,\ntime-frequency decomposition results in inherent problems such as\nphase/magnitude decoupling and long time window which is required to achieve\nsufficient frequency resolution. We propose Time-domain Audio Separation\nNetwork (TasNet) to overcome these limitations. We directly model the signal in\nthe time-domain using an encoder-decoder framework and perform the source\nseparation on nonnegative encoder outputs. This method removes the frequency\ndecomposition step and reduces the separation problem to estimation of source\nmasks on encoder outputs which is then synthesized by the decoder. Our system\noutperforms the current state-of-the-art causal and noncausal speech separation\nalgorithms, reduces the computational cost of speech separation, and\nsignificantly reduces the minimum required latency of the output. This makes\nTasNet suitable for applications where low-power, real-time implementation is\ndesirable such as in hearable and telecommunication devices.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 21:19:22 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2018 02:25:29 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Luo", "Yi", ""], ["Mesgarani", "Nima", ""]]}, {"id": "1711.00614", "submitter": "Daehyung Park", "authors": "Daehyung Park, Yuuna Hoshi, Charles C. Kemp", "title": "A Multimodal Anomaly Detector for Robot-Assisted Feeding Using an\n  LSTM-based Variational Autoencoder", "comments": "8 pages, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of anomalous executions is valuable for reducing potential\nhazards in assistive manipulation. Multimodal sensory signals can be helpful\nfor detecting a wide range of anomalies. However, the fusion of\nhigh-dimensional and heterogeneous modalities is a challenging problem. We\nintroduce a long short-term memory based variational autoencoder (LSTM-VAE)\nthat fuses signals and reconstructs their expected distribution. We also\nintroduce an LSTM-VAE-based detector using a reconstruction-based anomaly score\nand a state-based threshold. For evaluations with 1,555 robot-assisted feeding\nexecutions including 12 representative types of anomalies, our detector had a\nhigher area under the receiver operating characteristic curve (AUC) of 0.8710\nthan 5 other baseline detectors from the literature. We also show the\nmultimodal fusion through the LSTM-VAE is effective by comparing our detector\nwith 17 raw sensory signals versus 4 hand-engineered features.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 04:50:54 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Park", "Daehyung", ""], ["Hoshi", "Yuuna", ""], ["Kemp", "Charles C.", ""]]}, {"id": "1711.00629", "submitter": "Xin Zhang", "authors": "Xin Zhang, Weixuan Kou, Eric I-Chao Chang, He Gao, Yubo Fan and Yan Xu", "title": "Sleep Stage Classification Based on Multi-level Feature Learning and\n  Recurrent Neural Networks via Wearable Device", "comments": "11 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a practical approach for automatic sleep stage\nclassification based on a multi-level feature learning framework and Recurrent\nNeural Network (RNN) classifier using heart rate and wrist actigraphy derived\nfrom a wearable device. The feature learning framework is designed to extract\nlow- and mid-level features. Low-level features capture temporal and frequency\ndomain properties and mid-level features learn compositions and structural\ninformation of signals. Since sleep staging is a sequential problem with\nlong-term dependencies, we take advantage of RNNs with Bidirectional Long\nShort-Term Memory (BLSTM) architectures for sequence data learning. To simulate\nthe actual situation of daily sleep, experiments are conducted with a resting\ngroup in which sleep is recorded in resting state, and a comprehensive group in\nwhich both resting sleep and non-resting sleep are included.We evaluate the\nalgorithm based on an eight-fold cross validation to classify five sleep stages\n(W, N1, N2, N3, and REM). The proposed algorithm achieves weighted precision,\nrecall and F1 score of 58.0%, 60.3%, and 58.2% in the resting group and 58.5%,\n61.1%, and 58.5% in the comprehensive group, respectively. Various comparison\nexperiments demonstrate the effectiveness of feature learning and BLSTM. We\nfurther explore the influence of depth and width of RNNs on performance. Our\nmethod is specially proposed for wearable devices and is expected to be\napplicable for long-term sleep monitoring at home. Without using too much prior\ndomain knowledge, our method has the potential to generalize sleep disorder\ndetection.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 06:28:45 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Zhang", "Xin", ""], ["Kou", "Weixuan", ""], ["Chang", "Eric I-Chao", ""], ["Gao", "He", ""], ["Fan", "Yubo", ""], ["Xu", "Yan", ""]]}, {"id": "1711.00658", "submitter": "Lei Han", "authors": "Lei Han, Yiheng Huang and Tong Zhang", "title": "Candidates vs. Noises Estimation for Large Multi-Class Classification\n  Problem", "comments": "Published in ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method for multi-class classification problems, where\nthe number of classes K is large. The method, referred to as Candidates vs.\nNoises Estimation (CANE), selects a small subset of candidate classes and\nsamples the remaining classes. We show that CANE is always consistent and\ncomputationally efficient. Moreover, the resulting estimator has low\nstatistical variance approaching that of the maximum likelihood estimator, when\nthe observed label belongs to the selected candidates with high probability. In\npractice, we use a tree structure with leaves as classes to promote fast beam\nsearch for candidate selection. We further apply the CANE method to estimate\nword probabilities in learning large neural language models. Extensive\nexperimental results show that CANE achieves better prediction accuracy over\nthe Noise-Contrastive Estimation (NCE), its variants and a number of the\nstate-of-the-art tree classifiers, while it gains significant speedup compared\nto standard O(K) methods.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 09:23:11 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 04:16:06 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Han", "Lei", ""], ["Huang", "Yiheng", ""], ["Zhang", "Tong", ""]]}, {"id": "1711.00659", "submitter": "Alain Rakotomamonjy", "authors": "Rafael Will M de Araujo (USP), Roberto Hirata (USP), Alain\n  Rakotomamonjy (LITIS)", "title": "Concave losses for robust dictionary learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional dictionary learning methods are based on quadratic convex loss\nfunction and thus are sensitive to outliers. In this paper, we propose a\ngeneric framework for robust dictionary learning based on concave losses. We\nprovide results on composition of concave functions, notably regarding\nsuper-gradient computations, that are key for developing generic dictionary\nlearning algorithms applicable to smooth and non-smooth losses. In order to\nimprove identification of outliers, we introduce an initialization heuristic\nbased on undercomplete dictionary learning. Experimental results using\nsynthetic and real data demonstrate that our method is able to better detect\noutliers, is capable of generating better dictionaries, outperforming\nstate-of-the-art methods such as K-SVD and LC-KSVD.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 09:27:58 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["de Araujo", "Rafael Will M", "", "USP"], ["Hirata", "Roberto", "", "USP"], ["Rakotomamonjy", "Alain", "", "LITIS"]]}, {"id": "1711.00695", "submitter": "Iliyan Zarov", "authors": "Laura Douglas, Iliyan Zarov, Konstantinos Gourgoulias, Chris Lucas,\n  Chris Hart, Adam Baker, Maneesh Sahani, Yura Perov, Saurabh Johri", "title": "A Universal Marginalizer for Amortized Inference in Generative Models", "comments": "Submitted to the NIPS 2017 Workshop on Advances in Approximate\n  Bayesian Inference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of inference in a causal generative model where the\nset of available observations differs between data instances. We show how\ncombining samples drawn from the graphical model with an appropriate masking\nfunction makes it possible to train a single neural network to approximate all\nthe corresponding conditional marginal distributions and thus amortize the cost\nof inference. We further demonstrate that the efficiency of importance sampling\nmay be improved by basing proposals on the output of the neural network. We\nalso outline how the same network can be used to generate samples from an\napproximate joint posterior via a chain decomposition of the graph.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 11:40:09 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Douglas", "Laura", ""], ["Zarov", "Iliyan", ""], ["Gourgoulias", "Konstantinos", ""], ["Lucas", "Chris", ""], ["Hart", "Chris", ""], ["Baker", "Adam", ""], ["Sahani", "Maneesh", ""], ["Perov", "Yura", ""], ["Johri", "Saurabh", ""]]}, {"id": "1711.00726", "submitter": "Tu  Nguyen", "authors": "Tu Ngoc Nguyen", "title": "A Comprehensive Low and High-level Feature Analysis for Early Rumor\n  Detection on Twitter", "comments": "CIKM 2017 Workshop on Interpretable Data Mining - Bridging the Gap\n  between Shallow and Deep Models (IDM 2017). arXiv admin note: substantial\n  text overlap with arXiv:1709.04402", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work have done a good job in modeling rumors and detecting them over\nmicroblog streams. However, the performance of their automatic approaches are\nnot relatively high when looking early in the diffusion. A first intuition is\nthat, at early stage, most of the aggregated rumor features (e.g., propagation\nfeatures) are not mature and distinctive enough. The objective of rumor\ndebunking in microblogs, however, are to detect these misinformation as early\nas possible. In this work, we leverage neural models in learning the hidden\nrepresentations of individual rumor-related tweets at the very beginning of a\nrumor. Our extensive experiments show that the resulting signal improves our\nclassification performance over time, significantly within the first 10 hours.\nTo deepen the understanding of these low and high-level features in\ncontributing to the model performance over time, we conduct an extensive study\non a wide range of high impact rumor features for the 48 hours range. The end\nmodel that engages these features are shown to be competitive, reaches over 90%\naccuracy and out-performs strong baselines in our carefully cured dataset.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 15:49:47 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 00:44:22 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Nguyen", "Tu Ngoc", ""]]}, {"id": "1711.00727", "submitter": "Wei Lyu", "authors": "Wei Lyu, Zhaoyang Zhang, Chunxu Jiao, Kangjian Qin, and Huazi Zhang", "title": "Performance Evaluation of Channel Decoding With Deep Neural Networks", "comments": "6 pages, 11 figures, Latex; typos corrected; IEEE ICC 2018 to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the demand of high data rate and low latency in fifth generation (5G),\ndeep neural network decoder (NND) has become a promising candidate due to its\ncapability of one-shot decoding and parallel computing. In this paper, three\ntypes of NND, i.e., multi-layer perceptron (MLP), convolution neural network\n(CNN) and recurrent neural network (RNN), are proposed with the same parameter\nmagnitude. The performance of these deep neural networks are evaluated through\nextensive simulation. Numerical results show that RNN has the best decoding\nperformance, yet at the price of the highest computational overhead. Moreover,\nwe find there exists a saturation length for each type of neural network, which\nis caused by their restricted learning abilities.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 10:21:02 GMT"}, {"version": "v2", "created": "Wed, 31 Jan 2018 08:43:37 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Lyu", "Wei", ""], ["Zhang", "Zhaoyang", ""], ["Jiao", "Chunxu", ""], ["Qin", "Kangjian", ""], ["Zhang", "Huazi", ""]]}, {"id": "1711.00740", "submitter": "Miltiadis Allamanis", "authors": "Miltiadis Allamanis, Marc Brockschmidt, Mahmoud Khademi", "title": "Learning to Represent Programs with Graphs", "comments": "Published in ICLR 2018. arXiv admin note: text overlap with\n  arXiv:1705.07867", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning tasks on source code (i.e., formal languages) have been considered\nrecently, but most work has tried to transfer natural language methods and does\nnot capitalize on the unique opportunities offered by code's known syntax. For\nexample, long-range dependencies induced by using the same variable or function\nin distant locations are often not considered. We propose to use graphs to\nrepresent both the syntactic and semantic structure of code and use graph-based\ndeep learning methods to learn to reason over program structures.\n  In this work, we present how to construct graphs from source code and how to\nscale Gated Graph Neural Networks training to such large graphs. We evaluate\nour method on two tasks: VarNaming, in which a network attempts to predict the\nname of a variable given its usage, and VarMisuse, in which the network learns\nto reason about selecting the correct variable that should be used at a given\nprogram location. Our comparison to methods that use less structured program\nrepresentations shows the advantages of modeling known structure, and suggests\nthat our models learn to infer meaningful names and to solve the VarMisuse task\nin many cases. Additionally, our testing showed that VarMisuse identifies a\nnumber of bugs in mature open-source projects.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 09:48:06 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 11:59:03 GMT"}, {"version": "v3", "created": "Fri, 4 May 2018 20:30:53 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Allamanis", "Miltiadis", ""], ["Brockschmidt", "Marc", ""], ["Khademi", "Mahmoud", ""]]}, {"id": "1711.00753", "submitter": "Kristin Branson", "authors": "Mayank Kabra and Kristin Branson", "title": "Network-size independent covering number bounds for deep networks", "comments": "We found a possible error in our analysis. We are re-evaluating, and\n  may resubmit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a covering number bound for deep learning networks that is\nindependent of the size of the network. The key for the simple analysis is that\nfor linear classifiers, rotating the data doesn't affect the covering number.\nThus, we can ignore the rotation part of each layer's linear transformation,\nand get the covering number bound by concentrating on the scaling part.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 14:18:19 GMT"}, {"version": "v2", "created": "Wed, 8 Nov 2017 19:00:05 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Kabra", "Mayank", ""], ["Branson", "Kristin", ""]]}, {"id": "1711.00765", "submitter": "Barak Sober", "authors": "Barak Sober, Yariv Aizenbud, David Levin", "title": "Approximation of Functions over Manifolds: A Moving Least-Squares\n  Approach", "comments": "arXiv admin note: text overlap with arXiv:1606.07104", "journal-ref": null, "doi": "10.1016/j.cam.2020.113140", "report-no": null, "categories": "stat.ML cs.CG cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for approximating a function defined over a\n$d$-dimensional manifold utilizing only noisy function values at locations\nsampled from the manifold with noise. To produce the approximation we do not\nrequire any knowledge regarding the manifold other than its dimension $d$. We\nuse the Manifold Moving Least-Squares approach of (Sober and Levin 2016) to\nreconstruct the atlas of charts and the approximation is built on-top of those\ncharts. The resulting approximant is shown to be a function defined over a\nneighborhood of a manifold, approximating the originally sampled manifold. In\nother words, given a new point, located near the manifold, the approximation\ncan be evaluated directly on that point. We prove that our construction yields\na smooth function, and in case of noiseless samples the approximation order is\n$\\mathcal{O}(h^{m+1})$, where $h$ is a local density of sample parameter (i.e.,\nthe fill distance) and $m$ is the degree of a local polynomial approximation,\nused in our algorithm. In addition, the proposed algorithm has linear time\ncomplexity with respect to the ambient-space's dimension. Thus, we are able to\navoid the computational complexity, commonly encountered in high dimensional\napproximations, without having to perform non-linear dimension reduction, which\ninevitably introduces distortions to the geometry of the data. Additionaly, we\nshow numerical experiments that the proposed approach compares favorably to\nstatistical approaches for regression over manifolds and show its potential.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 14:37:04 GMT"}, {"version": "v2", "created": "Tue, 23 Jan 2018 07:49:10 GMT"}, {"version": "v3", "created": "Wed, 8 May 2019 00:05:59 GMT"}, {"version": "v4", "created": "Fri, 17 Jan 2020 02:15:41 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Sober", "Barak", ""], ["Aizenbud", "Yariv", ""], ["Levin", "David", ""]]}, {"id": "1711.00811", "submitter": "Valentin Khrulkov", "authors": "Valentin Khrulkov, Alexander Novikov, Ivan Oseledets", "title": "Expressive power of recurrent neural networks", "comments": "Accepted as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are surprisingly efficient at solving practical tasks,\nbut the theory behind this phenomenon is only starting to catch up with the\npractice. Numerous works show that depth is the key to this efficiency. A\ncertain class of deep convolutional networks -- namely those that correspond to\nthe Hierarchical Tucker (HT) tensor decomposition -- has been proven to have\nexponentially higher expressive power than shallow networks. I.e. a shallow\nnetwork of exponential width is required to realize the same score function as\ncomputed by the deep architecture. In this paper, we prove the expressive power\ntheorem (an exponential lower bound on the width of the equivalent shallow\nnetwork) for a class of recurrent neural networks -- ones that correspond to\nthe Tensor Train (TT) decomposition. This means that even processing an image\npatch by patch with an RNN can be exponentially more efficient than a (shallow)\nconvolutional network with one hidden layer. Using theoretical results on the\nrelation between the tensor decompositions we compare expressive powers of the\nHT- and TT-Networks. We also implement the recurrent TT-Networks and provide\nnumerical evidence of their expressivity.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 16:49:19 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 21:43:25 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Khrulkov", "Valentin", ""], ["Novikov", "Alexander", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1711.00812", "submitter": "Dripta Raychaudhuri", "authors": "Dripta S. Raychaudhuri, Josif Grabocka, Lars Schmidt-Thieme", "title": "Channel masking for multivariate time series shapelets", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series shapelets are discriminative sub-sequences and their similarity\nto time series can be used for time series classification. Initial shapelet\nextraction algorithms searched shapelets by complete enumeration of all\npossible data sub-sequences. Research on shapelets for univariate time series\nproposed a mechanism called shapelet learning which parameterizes the shapelets\nand learns them jointly with a prediction model in an optimization procedure.\nTrivial extension of this method to multivariate time series does not yield\nvery good results due to the presence of noisy channels which lead to\noverfitting. In this paper we propose a shapelet learning scheme for\nmultivariate time series in which we introduce channel masks to discount noisy\nchannels and serve as an implicit regularization.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 16:51:06 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Raychaudhuri", "Dripta S.", ""], ["Grabocka", "Josif", ""], ["Schmidt-Thieme", "Lars", ""]]}, {"id": "1711.00817", "submitter": "Martin Zhang", "authors": "Vivek Bagaria, Govinda M. Kamath, Vasilis Ntranos, Martin J. Zhang,\n  and David Tse", "title": "Medoids in almost linear time via multi-armed bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing the medoid of a large number of points in high-dimensional space is\nan increasingly common operation in many data science problems. We present an\nalgorithm Med-dit which uses O(n log n) distance evaluations to compute the\nmedoid with high probability. Med-dit is based on a connection with the\nmulti-armed bandit problem. We evaluate the performance of Med-dit empirically\non the Netflix-prize and the single-cell RNA-Seq datasets, containing hundreds\nof thousands of points living in tens of thousands of dimensions, and observe a\n5-10x improvement in performance over the current state of the art. Med-dit is\navailable at https://github.com/bagavi/Meddit\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 17:00:05 GMT"}, {"version": "v2", "created": "Sun, 5 Nov 2017 01:58:25 GMT"}, {"version": "v3", "created": "Tue, 7 Nov 2017 07:15:42 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Bagaria", "Vivek", ""], ["Kamath", "Govinda M.", ""], ["Ntranos", "Vasilis", ""], ["Zhang", "Martin J.", ""], ["Tse", "David", ""]]}, {"id": "1711.00832", "submitter": "Marc Lanctot", "authors": "Marc Lanctot, Vinicius Zambaldi, Audrunas Gruslys, Angeliki Lazaridou,\n  Karl Tuyls, Julien Perolat, David Silver, Thore Graepel", "title": "A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning", "comments": "Camera-ready copy of NIPS 2017 paper, including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To achieve general intelligence, agents must learn how to interact with\nothers in a shared environment: this is the challenge of multiagent\nreinforcement learning (MARL). The simplest form is independent reinforcement\nlearning (InRL), where each agent treats its experience as part of its\n(non-stationary) environment. In this paper, we first observe that policies\nlearned using InRL can overfit to the other agents' policies during training,\nfailing to sufficiently generalize during execution. We introduce a new metric,\njoint-policy correlation, to quantify this effect. We describe an algorithm for\ngeneral MARL, based on approximate best responses to mixtures of policies\ngenerated using deep reinforcement learning, and empirical game-theoretic\nanalysis to compute meta-strategies for policy selection. The algorithm\ngeneralizes previous ones such as InRL, iterated best response, double oracle,\nand fictitious play. Then, we present a scalable implementation which reduces\nthe memory requirement using decoupled meta-solvers. Finally, we demonstrate\nthe generality of the resulting policies in two partially observable settings:\ngridworld coordination games and poker.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 17:34:24 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 12:38:37 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Lanctot", "Marc", ""], ["Zambaldi", "Vinicius", ""], ["Gruslys", "Audrunas", ""], ["Lazaridou", "Angeliki", ""], ["Tuyls", "Karl", ""], ["Perolat", "Julien", ""], ["Silver", "David", ""], ["Graepel", "Thore", ""]]}, {"id": "1711.00837", "submitter": "Felix Last", "authors": "Felix Last, Georgios Douzas, Fernando Bacao", "title": "Oversampling for Imbalanced Learning Based on K-Means and SMOTE", "comments": "19 pages, 8 figures", "journal-ref": "Information Sciences 465 (2018) 1-20", "doi": "10.1016/j.ins.2018.06.056", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from class-imbalanced data continues to be a common and challenging\nproblem in supervised learning as standard classification algorithms are\ndesigned to handle balanced class distributions. While different strategies\nexist to tackle this problem, methods which generate artificial data to achieve\na balanced class distribution are more versatile than modifications to the\nclassification algorithm. Such techniques, called oversamplers, modify the\ntraining data, allowing any classifier to be used with class-imbalanced\ndatasets. Many algorithms have been proposed for this task, but most are\ncomplex and tend to generate unnecessary noise. This work presents a simple and\neffective oversampling method based on k-means clustering and SMOTE\noversampling, which avoids the generation of noise and effectively overcomes\nimbalances between and within classes. Empirical results of extensive\nexperiments with 71 datasets show that training data oversampled with the\nproposed method improves classification results. Moreover, k-means SMOTE\nconsistently outperforms other popular oversampling methods. An implementation\nis made available in the python programming language.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 17:43:03 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 18:33:14 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Last", "Felix", ""], ["Douzas", "Georgios", ""], ["Bacao", "Fernando", ""]]}, {"id": "1711.00843", "submitter": "Mike Ludkovski", "authors": "Sergio Rodriguez and Michael Ludkovski", "title": "Generalized Probabilistic Bisection for Stochastic Root-Finding", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider numerical schemes for root finding of noisy responses through\ngeneralizing the Probabilistic Bisection Algorithm (PBA) to the more practical\ncontext where the sampling distribution is unknown and location-dependent. As\nin standard PBA, we rely on a knowledge state for the approximate posterior of\nthe root location. To implement the corresponding Bayesian updating, we also\ncarry out inference of oracle accuracy, namely learning the probability of\ncorrect response. To this end we utilize batched querying in combination with a\nvariety of frequentist and Bayesian estimators based on majority vote, as well\nas the underlying functional responses, if available. For guiding sampling\nselection we investigate both Information Directed sampling, as well as\nQuantile sampling. Our numerical experiments show that these strategies perform\nquite differently; in particular we demonstrate the efficiency of randomized\nquantile sampling which is reminiscent of Thompson sampling. Our work is\nmotivated by the root-finding sub-routine in pricing of Bermudan financial\nderivatives, illustrated in the last section of the paper.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 17:55:48 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Rodriguez", "Sergio", ""], ["Ludkovski", "Michael", ""]]}, {"id": "1711.00848", "submitter": "Abhishek Kumar", "authors": "Abhishek Kumar, Prasanna Sattigeri, Avinash Balakrishnan", "title": "Variational Inference of Disentangled Latent Concepts from Unlabeled\n  Observations", "comments": "ICLR 2018 Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disentangled representations, where the higher level data generative factors\nare reflected in disjoint latent dimensions, offer several benefits such as\nease of deriving invariant representations, transferability to other tasks,\ninterpretability, etc. We consider the problem of unsupervised learning of\ndisentangled representations from large pool of unlabeled observations, and\npropose a variational inference based approach to infer disentangled latent\nfactors. We introduce a regularizer on the expectation of the approximate\nposterior over observed data that encourages the disentanglement. We also\npropose a new disentanglement metric which is better aligned with the\nqualitative disentanglement observed in the decoder's output. We empirically\nobserve significant improvement over existing methods in terms of both\ndisentanglement and data likelihood (reconstruction quality).\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 17:57:43 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 21:29:36 GMT"}, {"version": "v3", "created": "Thu, 27 Dec 2018 19:25:22 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Kumar", "Abhishek", ""], ["Sattigeri", "Prasanna", ""], ["Balakrishnan", "Avinash", ""]]}, {"id": "1711.00851", "submitter": "Eric Wong", "authors": "Eric Wong, J. Zico Kolter", "title": "Provable defenses against adversarial examples via the convex outer\n  adversarial polytope", "comments": "ICML final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to learn deep ReLU-based classifiers that are provably\nrobust against norm-bounded adversarial perturbations on the training data. For\npreviously unseen examples, the approach is guaranteed to detect all\nadversarial examples, though it may flag some non-adversarial examples as well.\nThe basic idea is to consider a convex outer approximation of the set of\nactivations reachable through a norm-bounded perturbation, and we develop a\nrobust optimization procedure that minimizes the worst case loss over this\nouter region (via a linear program). Crucially, we show that the dual problem\nto this linear program can be represented itself as a deep network similar to\nthe backpropagation network, leading to very efficient optimization approaches\nthat produce guaranteed bounds on the robust loss. The end result is that by\nexecuting a few more forward and backward passes through a slightly modified\nversion of the original network (though possibly with much larger batch sizes),\nwe can learn a classifier that is provably robust to any norm-bounded\nadversarial attack. We illustrate the approach on a number of tasks to train\nclassifiers with robust adversarial guarantees (e.g. for MNIST, we produce a\nconvolutional classifier that provably has less than 5.8% test error for any\nadversarial attack with bounded $\\ell_\\infty$ norm less than $\\epsilon = 0.1$),\nand code for all experiments in the paper is available at\nhttps://github.com/locuslab/convex_adversarial.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 17:59:24 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 00:41:56 GMT"}, {"version": "v3", "created": "Fri, 8 Jun 2018 19:04:49 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Wong", "Eric", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1711.00867", "submitter": "Pieter-Jan Kindermans", "authors": "Pieter-Jan Kindermans, Sara Hooker, Julius Adebayo, Maximilian Alber,\n  Kristof T. Sch\\\"utt, Sven D\\\"ahne, Dumitru Erhan, Been Kim", "title": "The (Un)reliability of saliency methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saliency methods aim to explain the predictions of deep neural networks.\nThese methods lack reliability when the explanation is sensitive to factors\nthat do not contribute to the model prediction. We use a simple and common\npre-processing step ---adding a constant shift to the input data--- to show\nthat a transformation with no effect on the model can cause numerous methods to\nincorrectly attribute. In order to guarantee reliability, we posit that methods\nshould fulfill input invariance, the requirement that a saliency method mirror\nthe sensitivity of the model with respect to transformations of the input. We\nshow, through several examples, that saliency methods that do not satisfy input\ninvariance result in misleading attribution.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 18:01:30 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Kindermans", "Pieter-Jan", ""], ["Hooker", "Sara", ""], ["Adebayo", "Julius", ""], ["Alber", "Maximilian", ""], ["Sch\u00fctt", "Kristof T.", ""], ["D\u00e4hne", "Sven", ""], ["Erhan", "Dumitru", ""], ["Kim", "Been", ""]]}, {"id": "1711.00888", "submitter": "I-Hong Jhuo", "authors": "I-Hong Jhuo, Jun Wang", "title": "Set-to-Set Hashing with Applications in Visual Recognition", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual data, such as an image or a sequence of video frames, is often\nnaturally represented as a point set. In this paper, we consider the\nfundamental problem of finding a nearest set from a collection of sets, to a\nquery set. This problem has obvious applications in large-scale visual\nretrieval and recognition, and also in applied fields beyond computer vision.\nOne challenge stands out in solving the problem---set representation and\nmeasure of similarity. Particularly, the query set and the sets in dataset\ncollection can have varying cardinalities. The training collection is large\nenough such that linear scan is impractical. We propose a simple representation\nscheme that encodes both statistical and structural information of the sets.\nThe derived representations are integrated in a kernel framework for flexible\nsimilarity measurement. For the query set process, we adopt a learning-to-hash\npipeline that turns the kernel representations into hash bits based on simple\nlearners, using multiple kernel learning. Experiments on two visual retrieval\ndatasets show unambiguously that our set-to-set hashing framework outperforms\nprior methods that do not take the set-to-set search setting.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 18:57:43 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 02:16:43 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Jhuo", "I-Hong", ""], ["Wang", "Jun", ""]]}, {"id": "1711.00889", "submitter": "Hao Zhang", "authors": "Zhijie Deng, Hao Zhang, Xiaodan Liang, Luona Yang, Shizhen Xu, Jun\n  Zhu, Eric P. Xing", "title": "Structured Generative Adversarial Networks", "comments": "To appear in NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of conditional generative modeling based on designated\nsemantics or structures. Existing models that build conditional generators\neither require massive labeled instances as supervision or are unable to\naccurately control the semantics of generated samples. We propose structured\ngenerative adversarial networks (SGANs) for semi-supervised conditional\ngenerative modeling. SGAN assumes the data x is generated conditioned on two\nindependent latent variables: y that encodes the designated semantics, and z\nthat contains other factors of variation. To ensure disentangled semantics in y\nand z, SGAN builds two collaborative games in the hidden space to minimize the\nreconstruction error of y and z, respectively. Training SGAN also involves\nsolving two adversarial games that have their equilibrium concentrating at the\ntrue joint data distributions p(x, z) and p(x, y), avoiding distributing the\nprobability mass diffusely over data space that MLE-based methods may suffer.\nWe assess SGAN by evaluating its trained networks, and its performance on\ndownstream tasks. We show that SGAN delivers a highly controllable generator,\nand disentangled representations; it also establishes start-of-the-art results\nacross multiple datasets when applied for semi-supervised image classification\n(1.27%, 5.73%, 17.26% error rates on MNIST, SVHN and CIFAR-10 using 50, 1000\nand 4000 labels, respectively). Benefiting from the separate modeling of y and\nz, SGAN can generate images with high visual quality and strictly following the\ndesignated semantic, and can be extended to a wide spectrum of applications,\nsuch as style transfer.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 19:00:56 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Deng", "Zhijie", ""], ["Zhang", "Hao", ""], ["Liang", "Xiaodan", ""], ["Yang", "Luona", ""], ["Xu", "Shizhen", ""], ["Zhu", "Jun", ""], ["Xing", "Eric P.", ""]]}, {"id": "1711.00905", "submitter": "Xuehang Zheng", "authors": "Xuehang Zheng, Il Yong Chun, Zhipeng Li, Yong Long, Jeffrey A. Fessler", "title": "Sparse-View X-Ray CT Reconstruction Using $\\ell_1$ Prior with Learned\n  Transform", "comments": "The first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in X-ray computed tomography (CT) is reducing radiation\ndose while maintaining high quality of reconstructed images. To reduce the\nradiation dose, one can reduce the number of projection views (sparse-view CT);\nhowever, it becomes difficult to achieve high-quality image reconstruction as\nthe number of projection views decreases. Researchers have applied the concept\nof learning sparse representations from (high-quality) CT image dataset to the\nsparse-view CT reconstruction. We propose a new statistical CT reconstruction\nmodel that combines penalized weighted-least squares (PWLS) and $\\ell_1$ prior\nwith learned sparsifying transform (PWLS-ST-$\\ell_1$), and a corresponding\nefficient algorithm based on Alternating Direction Method of Multipliers\n(ADMM). To moderate the difficulty of tuning ADMM parameters, we propose a new\nADMM parameter selection scheme based on approximated condition numbers. We\ninterpret the proposed model by analyzing the minimum mean square error of its\n($\\ell_2$-norm relaxed) image update estimator. Our results with the extended\ncardiac-torso (XCAT) phantom data and clinical chest data show that, for\nsparse-view 2D fan-beam CT and 3D axial cone-beam CT, PWLS-ST-$\\ell_1$ improves\nthe quality of reconstructed images compared to the CT reconstruction methods\nusing edge-preserving regularizer and $\\ell_2$ prior with learned ST. These\nresults also show that, for sparse-view 2D fan-beam CT, PWLS-ST-$\\ell_1$\nachieves comparable or better image quality and requires much shorter runtime\nthan PWLS-DL using a learned overcomplete dictionary. Our results with clinical\nchest data show that, methods using the unsupervised learned prior generalize\nbetter than a state-of-the-art deep \"denoising\" neural network that does not\nuse a physical imaging model.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 19:46:45 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 02:54:07 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2019 02:25:53 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Zheng", "Xuehang", ""], ["Chun", "Il Yong", ""], ["Li", "Zhipeng", ""], ["Long", "Yong", ""], ["Fessler", "Jeffrey A.", ""]]}, {"id": "1711.00937", "submitter": "A\\\"aron van den Oord", "authors": "Aaron van den Oord, Oriol Vinyals, Koray Kavukcuoglu", "title": "Neural Discrete Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning useful representations without supervision remains a key challenge\nin machine learning. In this paper, we propose a simple yet powerful generative\nmodel that learns such discrete representations. Our model, the Vector\nQuantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways:\nthe encoder network outputs discrete, rather than continuous, codes; and the\nprior is learnt rather than static. In order to learn a discrete latent\nrepresentation, we incorporate ideas from vector quantisation (VQ). Using the\nVQ method allows the model to circumvent issues of \"posterior collapse\" --\nwhere the latents are ignored when they are paired with a powerful\nautoregressive decoder -- typically observed in the VAE framework. Pairing\nthese representations with an autoregressive prior, the model can generate high\nquality images, videos, and speech as well as doing high quality speaker\nconversion and unsupervised learning of phonemes, providing further evidence of\nthe utility of the learnt representations.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 21:14:44 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 14:58:27 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Oord", "Aaron van den", ""], ["Vinyals", "Oriol", ""], ["Kavukcuoglu", "Koray", ""]]}, {"id": "1711.00939", "submitter": "Zhongang Qi", "authors": "Zhongang Qi, Tianchun Wang, Guojie Song, Weisong Hu, Xi Li, Zhongfei\n  (Mark) Zhang", "title": "Deep Air Learning: Interpolation, Prediction, and Feature Analysis of\n  Fine-grained Air Quality", "comments": null, "journal-ref": "IEEE Transactions on Knowledge and Data Engineering, 2018", "doi": "10.1109/TKDE.2018.2823740", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interpolation, prediction, and feature analysis of fine-gained air\nquality are three important topics in the area of urban air computing. The\nsolutions to these topics can provide extremely useful information to support\nair pollution control, and consequently generate great societal and technical\nimpacts. Most of the existing work solves the three problems separately by\ndifferent models. In this paper, we propose a general and effective approach to\nsolve the three problems in one model called the Deep Air Learning (DAL). The\nmain idea of DAL lies in embedding feature selection and semi-supervised\nlearning in different layers of the deep learning network. The proposed\napproach utilizes the information pertaining to the unlabeled spatio-temporal\ndata to improve the performance of the interpolation and the prediction, and\nperforms feature selection and association analysis to reveal the main relevant\nfeatures to the variation of the air quality. We evaluate our approach with\nextensive experiments based on real data sources obtained in Beijing, China.\nExperiments show that DAL is superior to the peer models from the recent\nliterature when solving the topics of interpolation, prediction, and feature\nanalysis of fine-gained air quality.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 21:18:42 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2018 01:50:48 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Qi", "Zhongang", "", "Mark"], ["Wang", "Tianchun", "", "Mark"], ["Song", "Guojie", "", "Mark"], ["Hu", "Weisong", "", "Mark"], ["Li", "Xi", "", "Mark"], ["Zhongfei", "", "", "Mark"], ["Zhang", "", ""]]}, {"id": "1711.00941", "submitter": "Yonatan Geifman", "authors": "Yonatan Geifman, Ran El-Yaniv", "title": "Deep Active Learning over the Long Tail", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with pool-based active learning for deep neural\nnetworks. Motivated by coreset dataset compression ideas, we present a novel\nactive learning algorithm that queries consecutive points from the pool using\nfarthest-first traversals in the space of neural activation over a\nrepresentation layer. We show consistent and overwhelming improvement in sample\ncomplexity over passive learning (random sampling) for three datasets: MNIST,\nCIFAR-10, and CIFAR-100. In addition, our algorithm outperforms the traditional\nuncertainty sampling technique (obtained using softmax activations), and we\nidentify cases where uncertainty sampling is only slightly better than random\nsampling.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 21:21:11 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Geifman", "Yonatan", ""], ["El-Yaniv", "Ran", ""]]}, {"id": "1711.00946", "submitter": "Cyril Zhang", "authors": "Elad Hazan, Karan Singh, Cyril Zhang", "title": "Learning Linear Dynamical Systems via Spectral Filtering", "comments": "Published as a conference paper at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient and practical algorithm for the online prediction of\ndiscrete-time linear dynamical systems with a symmetric transition matrix. We\ncircumvent the non-convex optimization problem using improper learning:\ncarefully overparameterize the class of LDSs by a polylogarithmic factor, in\nexchange for convexity of the loss functions. From this arises a\npolynomial-time algorithm with a near-optimal regret guarantee, with an\nanalogous sample complexity bound for agnostic learning. Our algorithm is based\non a novel filtering technique, which may be of independent interest: we\nconvolve the time series with the eigenvectors of a certain Hankel matrix.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 21:30:00 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Hazan", "Elad", ""], ["Singh", "Karan", ""], ["Zhang", "Cyril", ""]]}, {"id": "1711.00950", "submitter": "Rebecca E. Morrison", "authors": "Rebecca E. Morrison, Ricardo Baptista, Youssef Marzouk", "title": "Beyond normality: Learning sparse probabilistic graphical models in the\n  non-Gaussian setting", "comments": "Accepted in NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm to identify sparse dependence structure in continuous\nand non-Gaussian probability distributions, given a corresponding set of data.\nThe conditional independence structure of an arbitrary distribution can be\nrepresented as an undirected graph (or Markov random field), but most\nalgorithms for learning this structure are restricted to the discrete or\nGaussian cases. Our new approach allows for more realistic and accurate\ndescriptions of the distribution in question, and in turn better estimates of\nits sparse Markov structure. Sparsity in the graph is of interest as it can\naccelerate inference, improve sampling methods, and reveal important\ndependencies between variables. The algorithm relies on exploiting the\nconnection between the sparsity of the graph and the sparsity of transport\nmaps, which deterministically couple one probability measure to another.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 21:45:07 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 16:30:25 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Morrison", "Rebecca E.", ""], ["Baptista", "Ricardo", ""], ["Marzouk", "Youssef", ""]]}, {"id": "1711.00970", "submitter": "Shibani Santurkar", "authors": "Shibani Santurkar, Ludwig Schmidt and Aleksander M\\k{a}dry", "title": "A Classification-Based Study of Covariate Shift in GAN Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A basic, and still largely unanswered, question in the context of Generative\nAdversarial Networks (GANs) is whether they are truly able to capture all the\nfundamental characteristics of the distributions they are trained on. In\nparticular, evaluating the diversity of GAN distributions is challenging and\nexisting methods provide only a partial understanding of this issue. In this\npaper, we develop quantitative and scalable tools for assessing the diversity\nof GAN distributions. Specifically, we take a classification-based perspective\nand view loss of diversity as a form of covariate shift introduced by GANs. We\nexamine two specific forms of such shift: mode collapse and boundary\ndistortion. In contrast to prior work, our methods need only minimal human\nsupervision and can be readily applied to state-of-the-art GANs on large,\ncanonical datasets. Examining popular GANs using our tools indicates that these\nGANs have significant problems in reproducing the more distributional\nproperties of their training dataset.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 23:13:39 GMT"}, {"version": "v2", "created": "Sat, 11 Nov 2017 14:41:30 GMT"}, {"version": "v3", "created": "Sun, 19 Nov 2017 16:46:20 GMT"}, {"version": "v4", "created": "Wed, 11 Apr 2018 02:07:59 GMT"}, {"version": "v5", "created": "Wed, 30 May 2018 03:23:47 GMT"}, {"version": "v6", "created": "Sat, 2 Jun 2018 03:49:25 GMT"}, {"version": "v7", "created": "Wed, 6 Jun 2018 02:51:11 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Santurkar", "Shibani", ""], ["Schmidt", "Ludwig", ""], ["M\u0105dry", "Aleksander", ""]]}, {"id": "1711.00982", "submitter": "Varun Kanade", "authors": "Cheng Li, Felix Wong, Zhenming Liu, Varun Kanade", "title": "From which world is your graph?", "comments": "To appear in NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering statistical structure from links is a fundamental problem in the\nanalysis of social networks. Choosing a misspecified model, or equivalently, an\nincorrect inference algorithm will result in an invalid analysis or even\nfalsely uncover patterns that are in fact artifacts of the model. This work\nfocuses on unifying two of the most widely used link-formation models: the\nstochastic blockmodel (SBM) and the small world (or latent space) model (SWM).\nIntegrating techniques from kernel learning, spectral graph theory, and\nnonlinear dimensionality reduction, we develop the first statistically sound\npolynomial-time algorithm to discover latent patterns in sparse graphs for both\nmodels. When the network comes from an SBM, the algorithm outputs a block\nstructure. When it is from an SWM, the algorithm outputs estimates of each\nnode's latent position.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 00:24:39 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Li", "Cheng", ""], ["Wong", "Felix", ""], ["Liu", "Zhenming", ""], ["Kanade", "Varun", ""]]}, {"id": "1711.00991", "submitter": "Arash Ali Amini", "authors": "Arash A. Amini, Bryon Aragam, Qing Zhou", "title": "The neighborhood lattice for encoding partial correlations in a Hilbert\n  space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neighborhood regression has been a successful approach in graphical and\nstructural equation modeling, with applications to learning undirected and\ndirected graphical models. We extend these ideas by defining and studying an\nalgebraic structure called the neighborhood lattice based on a generalized\nnotion of neighborhood regression. We show that this algebraic structure has\nthe potential to provide an economic encoding of all conditional independence\nstatements in a Gaussian distribution (or conditional uncorrelatedness in\ngeneral), even in the cases where no graphical model exists that could\n\"perfectly\" encode all such statements. We study the computational complexity\nof computing these structures and show that under a sparsity assumption, they\ncan be computed in polynomial time, even in the absence of the assumption of\nperfectness to a graph. On the other hand, assuming perfectness, we show how\nthese neighborhood lattices may be \"graphically\" computed using the separation\nproperties of the so-called partial correlation graph. We also draw connections\nwith directed acyclic graphical models and Bayesian networks. We derive these\nresults using an abstract generalization of partial uncorrelatedness, called\npartial orthogonality, which allows us to use algebraic properties of\nprojection operators on Hilbert spaces to significantly simplify and extend\nexisting ideas and arguments. Consequently, our results apply to a wide range\nof random objects and data structures, such as random vectors, data matrices,\nand functions.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 01:45:53 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 06:05:21 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Amini", "Arash A.", ""], ["Aragam", "Bryon", ""], ["Zhou", "Qing", ""]]}, {"id": "1711.01012", "submitter": "Tanmay Gangwani", "authors": "Tanmay Gangwani, Jian Peng", "title": "Policy Optimization by Genetic Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic algorithms have been widely used in many practical optimization\nproblems. Inspired by natural selection, operators, including mutation,\ncrossover and selection, provide effective heuristics for search and black-box\noptimization. However, they have not been shown useful for deep reinforcement\nlearning, possibly due to the catastrophic consequence of parameter crossovers\nof neural networks. Here, we present Genetic Policy Optimization (GPO), a new\ngenetic algorithm for sample-efficient deep policy optimization. GPO uses\nimitation learning for policy crossover in the state space and applies policy\ngradient methods for mutation. Our experiments on MuJoCo tasks show that GPO as\na genetic algorithm is able to provide superior performance over the\nstate-of-the-art policy gradient methods and achieves comparable or higher\nsample efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 03:29:32 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2018 20:18:21 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Gangwani", "Tanmay", ""], ["Peng", "Jian", ""]]}, {"id": "1711.01037", "submitter": "Sebastien Bubeck", "authors": "S\\'ebastien Bubeck and Michael B. Cohen and Yuanzhi Li", "title": "Sparsity, variance and curvature in multi-armed bandits", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In (online) learning theory the concepts of sparsity, variance and curvature\nare well-understood and are routinely used to obtain refined regret and\ngeneralization bounds. In this paper we further our understanding of these\nconcepts in the more challenging limited feedback scenario. We consider the\nadversarial multi-armed bandit and linear bandit settings and solve several\nopen problems pertaining to the existence of algorithms with favorable regret\nbounds under the following assumptions: (i) sparsity of the individual losses,\n(ii) small variation of the loss sequence, and (iii) curvature of the action\nset. Specifically we show that (i) for $s$-sparse losses one can obtain\n$\\tilde{O}(\\sqrt{s T})$-regret (solving an open problem by Kwon and Perchet),\n(ii) for loss sequences with variation bounded by $Q$ one can obtain\n$\\tilde{O}(\\sqrt{Q})$-regret (solving an open problem by Kale and Hazan), and\n(iii) for linear bandit on an $\\ell_p^n$ ball one can obtain $\\tilde{O}(\\sqrt{n\nT})$-regret for $p \\in [1,2]$ and one has $\\tilde{\\Omega}(n \\sqrt{T})$-regret\nfor $p>2$ (solving an open problem by Bubeck, Cesa-Bianchi and Kakade). A key\nnew insight to obtain these results is to use regularizers satisfying more\nrefined conditions than general self-concordance\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 06:46:45 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Cohen", "Michael B.", ""], ["Li", "Yuanzhi", ""]]}, {"id": "1711.01131", "submitter": "Vincent Adam", "authors": "Vincent Adam", "title": "Structured Variational Inference for Coupled Gaussian Processes", "comments": "* Updated references. * Corrected typos", "journal-ref": "Advances in Approximate Bayesian Inference, NIPS 2017 Workshop", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse variational approximations allow for principled and scalable inference\nin Gaussian Process (GP) models. In settings where several GPs are part of the\ngenerative model, theses GPs are a posteriori coupled. For many applications\nsuch as regression where predictive accuracy is the quantity of interest, this\ncoupling is not crucial. Howewer if one is interested in posterior uncertainty,\nit cannot be ignored. A key element of variational inference schemes is the\nchoice of the approximate posterior parameterization. When the number of latent\nvariables is large, mean field (MF) methods provide fast and accurate posterior\nmeans while more structured posterior lead to inference algorithm of greater\ncomputational complexity. Here, we extend previous sparse GP approximations and\npropose a novel parameterization of variational posteriors in the multi-GP\nsetting allowing for fast and scalable inference capturing posterior\ndependencies.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 12:44:50 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 12:13:54 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Adam", "Vincent", ""]]}, {"id": "1711.01149", "submitter": "Thai Hung Le", "authors": "Hung Thai Le, Khang Ding Tran, Hung Van Le", "title": "Fuzzy clustering using linguistic-valued exponent", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to study the algorithm FCM and some of its\nfamous innovations, analyse and discover the method of applying hedge algebra\ntheory that uses algebra to represent linguistic-valued variables, to FCM.\nThen, this paper will propose a new FCM-based algorithm which uses hedge\nalgebra to model FCM's exponent parameter. Finally, the design, analysis and\nimplementation of the new algorithm as well some experimental results will be\npresented to prove our algorithm's capacity of solving clustering problems in\npractice.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 01:44:15 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Le", "Hung Thai", ""], ["Tran", "Khang Ding", ""], ["Van Le", "Hung", ""]]}, {"id": "1711.01204", "submitter": "Nutan Chen", "authors": "Nutan Chen, Alexej Klushyn, Richard Kurle, Xueyan Jiang, Justin Bayer,\n  Patrick van der Smagt", "title": "Metrics for Deep Generative Models", "comments": "Published on the 21st International Conference on Artificial\n  Intelligence and Statistics (AISTATS), 2018", "journal-ref": "The 21st International Conference on Artificial Intelligence and\n  Statistics, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural samplers such as variational autoencoders (VAEs) or generative\nadversarial networks (GANs) approximate distributions by transforming samples\nfrom a simple random source---the latent space---to samples from a more complex\ndistribution represented by a dataset. While the manifold hypothesis implies\nthat the density induced by a dataset contains large regions of low density,\nthe training criterions of VAEs and GANs will make the latent space densely\ncovered. Consequently points that are separated by low-density regions in\nobservation space will be pushed together in latent space, making stationary\ndistances poor proxies for similarity. We transfer ideas from Riemannian\ngeometry to this setting, letting the distance between two points be the\nshortest path on a Riemannian manifold induced by the transformation. The\nmethod yields a principled distance measure, provides a tool for visual\ninspection of deep generative models, and an alternative to linear\ninterpolation in latent space. In addition, it can be applied for robot\nmovement generalization using previously learned skills. The method is\nevaluated on a synthetic dataset with known ground truth; on a simulated robot\narm dataset; on human motion capture data; and on a generative model of\nhandwritten digits.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 15:18:10 GMT"}, {"version": "v2", "created": "Thu, 8 Feb 2018 14:53:43 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Chen", "Nutan", ""], ["Klushyn", "Alexej", ""], ["Kurle", "Richard", ""], ["Jiang", "Xueyan", ""], ["Bayer", "Justin", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "1711.01239", "submitter": "Clemens Rosenbaum", "authors": "Clemens Rosenbaum, Tim Klinger and Matthew Riemer", "title": "Routing Networks: Adaptive Selection of Non-linear Functions for\n  Multi-Task Learning", "comments": "Under Review at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning (MTL) with neural networks leverages commonalities in\ntasks to improve performance, but often suffers from task interference which\nreduces the benefits of transfer. To address this issue we introduce the\nrouting network paradigm, a novel neural network and training algorithm. A\nrouting network is a kind of self-organizing neural network consisting of two\ncomponents: a router and a set of one or more function blocks. A function block\nmay be any neural network - for example a fully-connected or a convolutional\nlayer. Given an input the router makes a routing decision, choosing a function\nblock to apply and passing the output back to the router recursively,\nterminating when a fixed recursion depth is reached. In this way the routing\nnetwork dynamically composes different function blocks for each input. We\nemploy a collaborative multi-agent reinforcement learning (MARL) approach to\njointly train the router and function blocks. We evaluate our model against\ncross-stitch networks and shared-layer baselines on multi-task settings of the\nMNIST, mini-imagenet, and CIFAR-100 datasets. Our experiments demonstrate a\nsignificant improvement in accuracy, with sharper convergence. In addition,\nrouting networks have nearly constant per-task training cost while cross-stitch\nnetworks scale linearly with the number of tasks. On CIFAR-100 (20 tasks) we\nobtain cross-stitch performance levels with an 85% reduction in training time.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 17:07:51 GMT"}, {"version": "v2", "created": "Sun, 31 Dec 2017 14:53:00 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Rosenbaum", "Clemens", ""], ["Klinger", "Tim", ""], ["Riemer", "Matthew", ""]]}, {"id": "1711.01243", "submitter": "Mohammad Ghasemzadeh", "authors": "Mohammad Ghasemzadeh, Mohammad Samragh, Farinaz Koushanfar", "title": "ReBNet: Residual Binarized Neural Network", "comments": "To Appear In The 26th IEEE International Symposium on\n  Field-Programmable Custom Computing Machines", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes ReBNet, an end-to-end framework for training\nreconfigurable binary neural networks on software and developing efficient\naccelerators for execution on FPGA. Binary neural networks offer an intriguing\nopportunity for deploying large-scale deep learning models on\nresource-constrained devices. Binarization reduces the memory footprint and\nreplaces the power-hungry matrix-multiplication with light-weight XnorPopcount\noperations. However, binary networks suffer from a degraded accuracy compared\nto their fixed-point counterparts. We show that the state-of-the-art methods\nfor optimizing binary networks accuracy, significantly increase the\nimplementation cost and complexity. To compensate for the degraded accuracy\nwhile adhering to the simplicity of binary networks, we devise the first\nreconfigurable scheme that can adjust the classification accuracy based on the\napplication. Our proposition improves the classification accuracy by\nrepresenting features with multiple levels of residual binarization. Unlike\nprevious methods, our approach does not exacerbate the area cost of the\nhardware accelerator. Instead, it provides a tradeoff between throughput and\naccuracy while the area overhead of multi-level binarization is negligible.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 17:12:15 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 00:45:57 GMT"}, {"version": "v3", "created": "Tue, 27 Mar 2018 20:58:01 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Ghasemzadeh", "Mohammad", ""], ["Samragh", "Mohammad", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "1711.01244", "submitter": "Ron Amit", "authors": "Ron Amit and Ron Meir", "title": "Meta-Learning by Adjusting Priors Based on Extended PAC-Bayes Theory", "comments": "Accepted to ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In meta-learning an agent extracts knowledge from observed tasks, aiming to\nfacilitate learning of novel future tasks. Under the assumption that future\ntasks are 'related' to previous tasks, the accumulated knowledge should be\nlearned in a way which captures the common structure across learned tasks,\nwhile allowing the learner sufficient flexibility to adapt to novel aspects of\nnew tasks. We present a framework for meta-learning that is based on\ngeneralization error bounds, allowing us to extend various PAC-Bayes bounds to\nmeta-learning. Learning takes place through the construction of a distribution\nover hypotheses based on the observed tasks, and its utilization for learning a\nnew task. Thus, prior knowledge is incorporated through setting an\nexperience-dependent prior for novel tasks. We develop a gradient-based\nalgorithm which minimizes an objective function derived from the bounds and\ndemonstrate its effectiveness numerically with deep neural networks. In\naddition to establishing the improved performance available through\nmeta-learning, we demonstrate the intuitive way by which prior information is\nmanifested at different levels of the network.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 17:14:14 GMT"}, {"version": "v2", "created": "Thu, 28 Dec 2017 19:38:13 GMT"}, {"version": "v3", "created": "Tue, 13 Feb 2018 05:26:27 GMT"}, {"version": "v4", "created": "Thu, 17 May 2018 18:33:49 GMT"}, {"version": "v5", "created": "Tue, 22 May 2018 08:43:18 GMT"}, {"version": "v6", "created": "Fri, 8 Jun 2018 09:34:51 GMT"}, {"version": "v7", "created": "Tue, 31 Jul 2018 09:44:24 GMT"}, {"version": "v8", "created": "Mon, 20 May 2019 10:29:06 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Amit", "Ron", ""], ["Meir", "Ron", ""]]}, {"id": "1711.01263", "submitter": "Jingyang Zhu", "authors": "Jingyang Zhu, Jingbo Jiang, Xizi Chen, Chi-Ying Tsui", "title": "SparseNN: An Energy-Efficient Neural Network Accelerator Exploiting\n  Input and Output Sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary Deep Neural Network (DNN) contains millions of synaptic\nconnections with tens to hundreds of layers. The large computation and memory\nrequirements pose a challenge to the hardware design. In this work, we leverage\nthe intrinsic activation sparsity of DNN to substantially reduce the execution\ncycles and the energy consumption. An end-to-end training algorithm is proposed\nto develop a lightweight run-time predictor for the output activation sparsity\non the fly. From our experimental results, the computation overhead of the\nprediction phase can be reduced to less than 5% of the original feedforward\nphase with negligible accuracy loss. Furthermore, an energy-efficient hardware\narchitecture, SparseNN, is proposed to exploit both the input and output\nsparsity. SparseNN is a scalable architecture with distributed memories and\nprocessing elements connected through a dedicated on-chip network. Compared\nwith the state-of-the-art accelerators which only exploit the input sparsity,\nSparseNN can achieve a 10%-70% improvement in throughput and a power reduction\nof around 50%.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 09:21:08 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Zhu", "Jingyang", ""], ["Jiang", "Jingbo", ""], ["Chen", "Xizi", ""], ["Tsui", "Chi-Ying", ""]]}, {"id": "1711.01287", "submitter": "Niek Tax", "authors": "Niek Tax, Natalia Sidorova, Wil M. P. van der Aalst", "title": "Discovering More Precise Process Models from Event Logs by Filtering Out\n  Chaotic Activities", "comments": null, "journal-ref": "Journal of Intelligent Information Systems, (2018), 1-33", "doi": "10.1007/s10844-018-0507-6", "report-no": null, "categories": "cs.DB cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process Discovery is concerned with the automatic generation of a process\nmodel that describes a business process from execution data of that business\nprocess. Real life event logs can contain chaotic activities. These activities\nare independent of the state of the process and can, therefore, happen at\nrather arbitrary points in time. We show that the presence of such chaotic\nactivities in an event log heavily impacts the quality of the process models\nthat can be discovered with process discovery techniques. The current modus\noperandi for filtering activities from event logs is to simply filter out\ninfrequent activities. We show that frequency-based filtering of activities\ndoes not solve the problems that are caused by chaotic activities. Moreover, we\npropose a novel technique to filter out chaotic activities from event logs. We\nevaluate this technique on a collection of seventeen real-life event logs that\noriginate from both the business process management domain and the smart home\nenvironment domain. As demonstrated, the developed activity filtering methods\nenable the discovery of process models that are more behaviorally specific\ncompared to process models that are discovered using standard frequency-based\nfiltering.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 18:13:36 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Tax", "Niek", ""], ["Sidorova", "Natalia", ""], ["van der Aalst", "Wil M. P.", ""]]}, {"id": "1711.01297", "submitter": "Nick Pawlowski", "authors": "Nick Pawlowski, Andrew Brock, Matthew C.H. Lee, Martin Rajchl, Ben\n  Glocker", "title": "Implicit Weight Uncertainty in Neural Networks", "comments": "Submitted to NIPS 2018, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural networks tend to be overconfident on unseen, noisy or\nincorrectly labelled data and do not produce meaningful uncertainty measures.\nBayesian deep learning aims to address this shortcoming with variational\napproximations (such as Bayes by Backprop or Multiplicative Normalising Flows).\nHowever, current approaches have limitations regarding flexibility and\nscalability. We introduce Bayes by Hypernet (BbH), a new method of variational\napproximation that interprets hypernetworks as implicit distributions. It\nnaturally uses neural networks to model arbitrarily complex distributions and\nscales to modern deep learning architectures. In our experiments, we\ndemonstrate that our method achieves competitive accuracies and predictive\nuncertainties on MNIST and a CIFAR5 task, while being the most robust against\nadversarial attacks.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 18:49:04 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 07:00:07 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Pawlowski", "Nick", ""], ["Brock", "Andrew", ""], ["Lee", "Matthew C. H.", ""], ["Rajchl", "Martin", ""], ["Glocker", "Ben", ""]]}, {"id": "1711.01333", "submitter": "Chara Podimata", "authors": "Zhe Feng, Chara Podimata, Vasilis Syrgkanis", "title": "Learning to Bid Without Knowing your Value", "comments": "In the Proceedings of the 19th ACM Conference on Economics and\n  Computation, 2018 (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address online learning in complex auction settings, such as sponsored\nsearch auctions, where the value of the bidder is unknown to her, evolving in\nan arbitrary manner and observed only if the bidder wins an allocation. We\nleverage the structure of the utility of the bidder and the partial feedback\nthat bidders typically receive in auctions, in order to provide algorithms with\nregret rates against the best fixed bid in hindsight, that are exponentially\nfaster in convergence in terms of dependence on the action space, than what\nwould have been derived by applying a generic bandit algorithm and almost\nequivalent to what would have been achieved in the full information setting.\nOur results are enabled by analyzing a new online learning setting with\noutcome-based feedback, which generalizes learning with feedback graphs. We\nprovide an online learning algorithm for this setting, of independent interest,\nwith regret that grows only logarithmically with the number of actions and\nlinearly only in the number of potential outcomes (the latter being very small\nin most auction settings). Last but not least, we show that our algorithm\noutperforms the bandit approach experimentally and that this performance is\nrobust to dropping some of our theoretical assumptions or introducing noise in\nthe feedback that the bidder receives.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 21:04:21 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 01:46:20 GMT"}, {"version": "v3", "created": "Fri, 1 Dec 2017 03:42:29 GMT"}, {"version": "v4", "created": "Mon, 28 May 2018 17:15:58 GMT"}, {"version": "v5", "created": "Fri, 1 Jun 2018 17:12:23 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Feng", "Zhe", ""], ["Podimata", "Chara", ""], ["Syrgkanis", "Vasilis", ""]]}, {"id": "1711.01343", "submitter": "Sourya Dey", "authors": "Sourya Dey, Yinan Shao, Keith M. Chugg and Peter A. Beerel", "title": "Accelerating Training of Deep Neural Networks via Sparse Edge Processing", "comments": "Presented at the 26th International Conference on Artificial Neural\n  Networks (ICANN) 2017 in Alghero, Italy", "journal-ref": "Proceedings Part 1 of ICANN 2017, pp 273-280. Lecture Notes in\n  Computer Science, vol 10613. Springer, Cham", "doi": "10.1007/978-3-319-68600-4_32", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a reconfigurable hardware architecture for deep neural networks\n(DNNs) capable of online training and inference, which uses algorithmically\npre-determined, structured sparsity to significantly lower memory and\ncomputational requirements. This novel architecture introduces the notion of\nedge-processing to provide flexibility and combines junction pipelining and\noperational parallelization to speed up training. The overall effect is to\nreduce network complexity by factors up to 30x and training time by up to 35x\nrelative to GPUs, while maintaining high fidelity of inference results. This\nhas the potential to enable extensive parameter searches and development of the\nlargely unexplored theoretical foundation of DNNs. The architecture\nautomatically adapts itself to different network sizes given available hardware\nresources. As proof of concept, we show results obtained for different bit\nwidths.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 21:44:08 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Dey", "Sourya", ""], ["Shao", "Yinan", ""], ["Chugg", "Keith M.", ""], ["Beerel", "Peter A.", ""]]}, {"id": "1711.01391", "submitter": "Beomjoon Kim", "authors": "Beomjoon Kim, Leslie Pack Kaelbling, Tomas Lozano-Perez", "title": "Guiding the search in continuous state-action spaces by learning an\n  action sampling distribution from off-target samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In robotics, it is essential to be able to plan efficiently in\nhigh-dimensional continuous state-action spaces for long horizons. For such\ncomplex planning problems, unguided uniform sampling of actions until a path to\na goal is found is hopelessly inefficient, and gradient-based approaches often\nfall short when the optimization manifold of a given problem is not smooth. In\nthis paper we present an approach that guides the search of a state-space\nplanner, such as A*, by learning an action-sampling distribution that can\ngeneralize across different instances of a planning problem. The motivation is\nthat, unlike typical learning approaches for planning for continuous action\nspace that estimate a policy, an estimated action sampler is more robust to\nerror since it has a planner to fall back on. We use a Generative Adversarial\nNetwork (GAN), and address an important issue: search experience consists of a\nrelatively large number of actions that are not on a solution path and a\nrelatively small number of actions that actually are on a solution path. We\nintroduce a new technique, based on an importance-ratio estimation method, for\nusing samples from a non-target distribution to make GAN learning more\ndata-efficient. We provide theoretical guarantees and empirical evaluation in\nthree challenging continuous robot planning problems to illustrate the\neffectiveness of our algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 4 Nov 2017 04:10:05 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Kim", "Beomjoon", ""], ["Kaelbling", "Leslie Pack", ""], ["Lozano-Perez", "Tomas", ""]]}, {"id": "1711.01396", "submitter": "Weiyu Xu", "authors": "Weiyu Xu, Jirong Yi, Soura Dasgupta, Jian-Feng Cai, Mathews Jacob,\n  Myung Cho", "title": "Separation-Free Super-Resolution from Compressed Measurements is\n  Possible: an Orthonormal Atomic Norm Minimization Approach", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of recovering the superposition of $R$ distinct\ncomplex exponential functions from compressed non-uniform time-domain samples.\nTotal Variation (TV) minimization or atomic norm minimization was proposed in\nthe literature to recover the $R$ frequencies or the missing data. However, it\nis known that in order for TV minimization and atomic norm minimization to\nrecover the missing data or the frequencies, the underlying $R$ frequencies are\nrequired to be well-separated, even when the measurements are noiseless. This\npaper shows that the Hankel matrix recovery approach can super-resolve the $R$\ncomplex exponentials and their frequencies from compressed non-uniform\nmeasurements, regardless of how close their frequencies are to each other. We\npropose a new concept of orthonormal atomic norm minimization (OANM), and\ndemonstrate that the success of Hankel matrix recovery in separation-free\nsuper-resolution comes from the fact that the nuclear norm of a Hankel matrix\nis an orthonormal atomic norm. More specifically, we show that, in traditional\natomic norm minimization, the underlying parameter values $\\textbf{must}$ be\nwell separated to achieve successful signal recovery, if the atoms are changing\ncontinuously with respect to the continuously-valued parameter. In contrast,\nfor the OANM, it is possible the OANM is successful even though the original\natoms can be arbitrarily close.\n  As a byproduct of this research, we provide one matrix-theoretic inequality\nof nuclear norm, and give its proof from the theory of compressed sensing.\n", "versions": [{"version": "v1", "created": "Sat, 4 Nov 2017 05:50:42 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Xu", "Weiyu", ""], ["Yi", "Jirong", ""], ["Dasgupta", "Soura", ""], ["Cai", "Jian-Feng", ""], ["Jacob", "Mathews", ""], ["Cho", "Myung", ""]]}, {"id": "1711.01416", "submitter": "Vasily Pestun", "authors": "Vasily Pestun, John Terilla, Yiannis Vlassopoulos", "title": "Language as a matrix product state", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cond-mat.dis-nn cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a statistical model for natural language that begins by\nconsidering language as a monoid, then representing it in complex matrices with\na compatible translation invariant probability measure. We interpret the\nprobability measure as arising via the Born rule from a translation invariant\nmatrix product state.\n", "versions": [{"version": "v1", "created": "Sat, 4 Nov 2017 09:11:18 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Pestun", "Vasily", ""], ["Terilla", "John", ""], ["Vlassopoulos", "Yiannis", ""]]}, {"id": "1711.01431", "submitter": "Johan Loeckx", "authors": "Johan Loeckx", "title": "The Case for Meta-Cognitive Machine Learning: On Model Entropy and\n  Concept Formation in Deep Learning", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is usually defined in behaviourist terms, where external\nvalidation is the primary mechanism of learning. In this paper, I argue for a\nmore holistic interpretation in which finding more probable, efficient and\nabstract representations is as central to learning as performance. In other\nwords, machine learning should be extended with strategies to reason over its\nown learning process, leading to so-called meta-cognitive machine learning. As\nsuch, the de facto definition of machine learning should be reformulated in\nthese intrinsically multi-objective terms, taking into account not only the\ntask performance but also internal learning objectives. To this end, we suggest\na \"model entropy function\" to be defined that quantifies the efficiency of the\ninternal learning processes. It is conjured that the minimization of this model\nentropy leads to concept formation. Besides philosophical aspects, some initial\nillustrations are included to support the claims.\n", "versions": [{"version": "v1", "created": "Sat, 4 Nov 2017 12:54:35 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Loeckx", "Johan", ""]]}, {"id": "1711.01434", "submitter": "Xurui Li", "authors": "Xurui Li, Wei Yu, Tianyu Luwang, Jianbin Zheng, Xuetao Qiu, Jintao\n  Zhao, Lei Xia, Yujiao Li", "title": "Transaction Fraud Detection Using GRU-centered Sandwich-structured Model", "comments": "accepted by cscwd2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid growth of modern technologies such as internet and mobile computing are\nbringing dramatically increased e-commerce payments, as well as the explosion\nin transaction fraud. Meanwhile, fraudsters are continually refining their\ntricks, making rule-based fraud detection systems difficult to handle the\never-changing fraud patterns. Many data mining and artificial intelligence\nmethods have been proposed for identifying small anomalies in large transaction\ndata sets, increasing detecting efficiency to some extent. Nevertheless, there\nis always a contradiction that most methods are irrelevant to transaction\nsequence, yet sequence-related methods usually cannot learn information at\nsingle-transaction level well. In this paper, a new \"within->between->within\"\nsandwich-structured sequence learning architecture has been proposed by\nstacking an ensemble method, a deep sequential learning method and another\ntop-layer ensemble classifier in proper order. Moreover, attention mechanism\nhas also been introduced in to further improve performance. Models in this\nstructure have been manifested to be very efficient in scenarios like fraud\ndetection, where the information sequence is made up of vectors with complex\ninterconnected features.\n", "versions": [{"version": "v1", "created": "Sat, 4 Nov 2017 13:26:54 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 01:56:05 GMT"}, {"version": "v3", "created": "Mon, 19 Mar 2018 13:39:07 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Li", "Xurui", ""], ["Yu", "Wei", ""], ["Luwang", "Tianyu", ""], ["Zheng", "Jianbin", ""], ["Qiu", "Xuetao", ""], ["Zhao", "Jintao", ""], ["Xia", "Lei", ""], ["Li", "Yujiao", ""]]}, {"id": "1711.01464", "submitter": "Ashish Mani Dr.", "authors": "Arit Kumar Bishwas, Ashish Mani and Vasile Palade", "title": "Gaussian Kernel in Quantum Learning", "comments": null, "journal-ref": "International Journal of Quantum Information 2020", "doi": "10.1142/S0219749920500069", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gaussian kernel is a very popular kernel function used in many machine\nlearning algorithms, especially in support vector machines (SVMs). It is more\noften used than polynomial kernels when learning from nonlinear datasets, and\nis usually employed in formulating the classical SVM for nonlinear problems. In\n[3], Rebentrost et al. discussed an elegant quantum version of a least square\nsupport vector machine using quantum polynomial kernels, which is exponentially\nfaster than the classical counterpart. This paper demonstrates a quantum\nversion of the Gaussian kernel and analyzes its runtime complexity using the\nquantum random access memory (QRAM) in the context of quantum SVM. Our analysis\nshows that the runtime computational complexity of the quantum Gaussian kernel\nseems to be significantly faster as compared to its classical version.\n", "versions": [{"version": "v1", "created": "Sat, 4 Nov 2017 16:54:57 GMT"}, {"version": "v2", "created": "Sun, 11 Nov 2018 01:12:26 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 04:23:25 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Bishwas", "Arit Kumar", ""], ["Mani", "Ashish", ""], ["Palade", "Vasile", ""]]}, {"id": "1711.01468", "submitter": "Konstantinos Kamnitsas", "authors": "Konstantinos Kamnitsas, Wenjia Bai, Enzo Ferrante, Steven McDonagh,\n  Matthew Sinclair, Nick Pawlowski, Martin Rajchl, Matthew Lee, Bernhard Kainz,\n  Daniel Rueckert, Ben Glocker", "title": "Ensembles of Multiple Models and Architectures for Robust Brain Tumour\n  Segmentation", "comments": "The method won the 1st-place in the Brain Tumour Segmentation (BRATS)\n  2017 competition (segmentation task)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning approaches such as convolutional neural nets have consistently\noutperformed previous methods on challenging tasks such as dense, semantic\nsegmentation. However, the various proposed networks perform differently, with\nbehaviour largely influenced by architectural choices and training settings.\nThis paper explores Ensembles of Multiple Models and Architectures (EMMA) for\nrobust performance through aggregation of predictions from a wide range of\nmethods. The approach reduces the influence of the meta-parameters of\nindividual models and the risk of overfitting the configuration to a particular\ndatabase. EMMA can be seen as an unbiased, generic deep learning model which is\nshown to yield excellent performance, winning the first position in the BRATS\n2017 competition among 50+ participating teams.\n", "versions": [{"version": "v1", "created": "Sat, 4 Nov 2017 17:43:07 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Kamnitsas", "Konstantinos", ""], ["Bai", "Wenjia", ""], ["Ferrante", "Enzo", ""], ["McDonagh", "Steven", ""], ["Sinclair", "Matthew", ""], ["Pawlowski", "Nick", ""], ["Rajchl", "Martin", ""], ["Lee", "Matthew", ""], ["Kainz", "Bernhard", ""], ["Rueckert", "Daniel", ""], ["Glocker", "Ben", ""]]}, {"id": "1711.01501", "submitter": "Luiz F. O. Chamon", "authors": "Luiz F. O. Chamon and Alejandro Ribeiro", "title": "Approximate Supermodularity Bounds for Experimental Design", "comments": "15 pages, NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work provides performance guarantees for the greedy solution of\nexperimental design problems. In particular, it focuses on A- and E-optimal\ndesigns, for which typical guarantees do not apply since the mean-square error\nand the maximum eigenvalue of the estimation error covariance matrix are not\nsupermodular. To do so, it leverages the concept of approximate supermodularity\nto derive non-asymptotic worst-case suboptimality bounds for these greedy\nsolutions. These bounds reveal that as the SNR of the experiments decreases,\nthese cost functions behave increasingly as supermodular functions. As such,\ngreedy A- and E-optimal designs approach (1-1/e)-optimality. These results\nreconcile the empirical success of greedy experimental design with the\nnon-supermodularity of the A- and E-optimality criteria.\n", "versions": [{"version": "v1", "created": "Sat, 4 Nov 2017 22:28:01 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 21:14:32 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Chamon", "Luiz F. O.", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1711.01514", "submitter": "Karthikeyan Natesan Ramamurthy", "authors": "Dennis Wei and Karthikeyan Natesan Ramamurthy and Kush R. Varshney", "title": "Distribution-Preserving k-Anonymity", "comments": "Portions of this work were first presented at the 2015 SIAM\n  International Conference on Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preserving the privacy of individuals by protecting their sensitive\nattributes is an important consideration during microdata release. However, it\nis equally important to preserve the quality or utility of the data for at\nleast some targeted workloads. We propose a novel framework for privacy\npreservation based on the k-anonymity model that is ideally suited for\nworkloads that require preserving the probability distribution of the\nquasi-identifier variables in the data. Our framework combines the principles\nof distribution-preserving quantization and k-member clustering, and we\nspecialize it to two variants that respectively use intra-cluster and Gaussian\ndithering of cluster centers to achieve distribution preservation. We perform\ntheoretical analysis of the proposed schemes in terms of distribution\npreservation, and describe their utility in workloads such as covariate shift\nand transfer learning where such a property is necessary. Using extensive\nexperiments on real-world Medical Expenditure Panel Survey data, we demonstrate\nthe merits of our algorithms over standard k-anonymization for a hallmark\nhealth care application where an insurance company wishes to understand the\nrisk in entering a new market. Furthermore, by empirically quantifying the\nreidentification risk, we also show that the proposed approaches indeed\nmaintain k-anonymity.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 01:31:25 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Wei", "Dennis", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Varshney", "Kush R.", ""]]}, {"id": "1711.01519", "submitter": "Zahra Khatami", "authors": "Zahra Khatami and Lukas Troska and Hartmut Kaiser and J. Ramanujam and\n  Adrian Serio", "title": "HPX Smart Executors", "comments": "In Proceedings of ESPM2'17: Third International Workshop on Extreme\n  Scale Programming Models and Middleware, Denver, CO, USA, November\n  12-17,,2017 (ESPM2'17), 8 pages", "journal-ref": null, "doi": "10.1145/3152041.3152084", "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of many parallel applications depends on loop-level\nparallelism. However, manually parallelizing all loops may result in degrading\nparallel performance, as some of them cannot scale desirably to a large number\nof threads. In addition, the overheads of manually tuning loop parameters might\nprevent an application from reaching its maximum parallel performance. We\nillustrate how machine learning techniques can be applied to address these\nchallenges. In this research, we develop a framework that is able to\nautomatically capture the static and dynamic information of a loop. Moreover,\nwe advocate a novel method by introducing HPX smart executors for determining\nthe execution policy, chunk size, and prefetching distance of an HPX loop to\nachieve higher possible performance by feeding static information captured\nduring compilation and runtime-based dynamic information to our learning model.\nOur evaluated execution results show that using these smart executors can speed\nup the HPX execution process by around 12%-35% for the Matrix Multiplication,\nStream and $2D$ Stencil benchmarks compared to setting their HPX loop's\nexecution policy/parameters manually or using HPX auto-parallelization\ntechniques.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 02:11:07 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Khatami", "Zahra", ""], ["Troska", "Lukas", ""], ["Kaiser", "Hartmut", ""], ["Ramanujam", "J.", ""], ["Serio", "Adrian", ""]]}, {"id": "1711.01526", "submitter": "Omid Ardakanian", "authors": "Omid Ardakanian, Vincent W.S. Wong, Roel Dobbe, Steven H. Low,\n  Alexandra von Meier, Claire Tomlin, Ye Yuan", "title": "On Identification of Distribution Grids", "comments": null, "journal-ref": null, "doi": "10.1109/TCNS.2019.2891002", "report-no": null, "categories": "cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale integration of distributed energy resources into residential\ndistribution feeders necessitates careful control of their operation through\npower flow analysis. While the knowledge of the distribution system model is\ncrucial for this type of analysis, it is often unavailable or outdated. The\nrecent introduction of synchrophasor technology in low-voltage distribution\ngrids has created an unprecedented opportunity to learn this model from\nhigh-precision, time-synchronized measurements of voltage and current phasors\nat various locations. This paper focuses on joint estimation of model\nparameters (admittance values) and operational structure of a poly-phase\ndistribution network from the available telemetry data via the lasso, a method\nfor regression shrinkage and selection. We propose tractable convex programs\ncapable of tackling the low rank structure of the distribution system and\ndevelop an online algorithm for early detection and localization of critical\nevents that induce a change in the admittance matrix. The efficacy of these\ntechniques is corroborated through power flow studies on four three-phase\nradial distribution systems serving real household demands.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 03:45:06 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Ardakanian", "Omid", ""], ["Wong", "Vincent W. S.", ""], ["Dobbe", "Roel", ""], ["Low", "Steven H.", ""], ["von Meier", "Alexandra", ""], ["Tomlin", "Claire", ""], ["Yuan", "Ye", ""]]}, {"id": "1711.01530", "submitter": "James Stokes", "authors": "Tengyuan Liang, Tomaso Poggio, Alexander Rakhlin and James Stokes", "title": "Fisher-Rao Metric, Geometry, and Complexity of Neural Networks", "comments": "To appear in the proceedings of the 22nd International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2019", "journal-ref": "The 22nd International Conference on Artificial Intelligence and\n  Statistics 89 (2019) 888-896", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the relationship between geometry and capacity measures for deep\nneural networks from an invariance viewpoint. We introduce a new notion of\ncapacity --- the Fisher-Rao norm --- that possesses desirable invariance\nproperties and is motivated by Information Geometry. We discover an analytical\ncharacterization of the new capacity measure, through which we establish\nnorm-comparison inequalities and further show that the new measure serves as an\numbrella for several existing norm-based complexity measures. We discuss upper\nbounds on the generalization error induced by the proposed measure. Extensive\nnumerical experiments on CIFAR-10 support our theoretical findings. Our\ntheoretical analysis rests on a key structural lemma about partial derivatives\nof multi-layer rectifier networks.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 04:32:59 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 21:27:30 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Liang", "Tengyuan", ""], ["Poggio", "Tomaso", ""], ["Rakhlin", "Alexander", ""], ["Stokes", "James", ""]]}, {"id": "1711.01558", "submitter": "Ilya Tolstikhin", "authors": "Ilya Tolstikhin and Olivier Bousquet and Sylvain Gelly and Bernhard\n  Schoelkopf", "title": "Wasserstein Auto-Encoders", "comments": "Published at ICLR 2018.. Included much wider hyperparameter sweep: in\n  significant improvements in FIDs on CelebA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Wasserstein Auto-Encoder (WAE)---a new algorithm for building\na generative model of the data distribution. WAE minimizes a penalized form of\nthe Wasserstein distance between the model distribution and the target\ndistribution, which leads to a different regularizer than the one used by the\nVariational Auto-Encoder (VAE). This regularizer encourages the encoded\ntraining distribution to match the prior. We compare our algorithm with several\nother techniques and show that it is a generalization of adversarial\nauto-encoders (AAE). Our experiments show that WAE shares many of the\nproperties of VAEs (stable training, encoder-decoder architecture, nice latent\nmanifold structure) while generating samples of better quality, as measured by\nthe FID score.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 10:18:27 GMT"}, {"version": "v2", "created": "Tue, 19 Dec 2017 08:24:54 GMT"}, {"version": "v3", "created": "Mon, 12 Mar 2018 15:06:34 GMT"}, {"version": "v4", "created": "Thu, 5 Dec 2019 10:27:44 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Tolstikhin", "Ilya", ""], ["Bousquet", "Olivier", ""], ["Gelly", "Sylvain", ""], ["Schoelkopf", "Bernhard", ""]]}, {"id": "1711.01559", "submitter": "Louis-Serge Bouchard", "authors": "K. Youssef, Louis-S. Bouchard, K.Z. Haigh, H. Krovi, J. Silovsky, C.P.\n  Vander Valk", "title": "Machine Learning Approach to RF Transmitter Identification", "comments": "14 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development and widespread use of wireless devices in recent years\n(mobile phones, Internet of Things, Wi-Fi), the electromagnetic spectrum has\nbecome extremely crowded. In order to counter security threats posed by rogue\nor unknown transmitters, it is important to identify RF transmitters not by the\ndata content of the transmissions but based on the intrinsic physical\ncharacteristics of the transmitters. RF waveforms represent a particular\nchallenge because of the extremely high data rates involved and the potentially\nlarge number of transmitters present in a given location. These factors outline\nthe need for rapid fingerprinting and identification methods that go beyond the\ntraditional hand-engineered approaches. In this study, we investigate the use\nof machine learning (ML) strategies to the classification and identification\nproblems, and the use of wavelets to reduce the amount of data required. Four\ndifferent ML strategies are evaluated: deep neural nets (DNN), convolutional\nneural nets (CNN), support vector machines (SVM), and multi-stage training\n(MST) using accelerated Levenberg-Marquardt (A-LM) updates. The A-LM MST method\npreconditioned by wavelets was by far the most accurate, achieving 100%\nclassification accuracy of transmitters, as tested using data originating from\n12 different transmitters. We discuss strategies for extension of MST to a much\nlarger number of transmitters.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 10:41:05 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 06:14:22 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Youssef", "K.", ""], ["Bouchard", "Louis-S.", ""], ["Haigh", "K. Z.", ""], ["Krovi", "H.", ""], ["Silovsky", "J.", ""], ["Valk", "C. P. Vander", ""]]}, {"id": "1711.01566", "submitter": "Mohammad Reza Karimi", "authors": "Mohammad Reza Karimi and Mario Lucic and Hamed Hassani and Andreas\n  Krause", "title": "Stochastic Submodular Maximization: The Case of Coverage Functions", "comments": "31st Conference on Neural Information Processing Systems (NIPS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic optimization of continuous objectives is at the heart of modern\nmachine learning. However, many important problems are of discrete nature and\noften involve submodular objectives. We seek to unleash the power of stochastic\ncontinuous optimization, namely stochastic gradient descent and its variants,\nto such discrete problems. We first introduce the problem of stochastic\nsubmodular optimization, where one needs to optimize a submodular objective\nwhich is given as an expectation. Our model captures situations where the\ndiscrete objective arises as an empirical risk (e.g., in the case of\nexemplar-based clustering), or is given as an explicit stochastic model (e.g.,\nin the case of influence maximization in social networks). By exploiting that\ncommon extensions act linearly on the class of submodular functions, we employ\nprojected stochastic gradient ascent and its variants in the continuous domain,\nand perform rounding to obtain discrete solutions. We focus on the rich and\nwidely used family of weighted coverage functions. We show that our approach\nyields solutions that are guaranteed to match the optimal approximation\nguarantees, while reducing the computational cost by several orders of\nmagnitude, as we demonstrate empirically.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 11:58:55 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Karimi", "Mohammad Reza", ""], ["Lucic", "Mario", ""], ["Hassani", "Hamed", ""], ["Krause", "Andreas", ""]]}, {"id": "1711.01567", "submitter": "Anuroop Sriram", "authors": "Anuroop Sriram, Heewoo Jun, Yashesh Gaur and Sanjeev Satheesh", "title": "Robust Speech Recognition Using Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a general, scalable, end-to-end framework that uses the\ngenerative adversarial network (GAN) objective to enable robust speech\nrecognition. Encoders trained with the proposed approach enjoy improved\ninvariance by learning to map noisy audio to the same embedding space as that\nof clean audio. Unlike previous methods, the new framework does not rely on\ndomain expertise or simplifying assumptions as are often needed in signal\nprocessing, and directly encourages robustness in a data-driven way. We show\nthe new approach improves simulated far-field speech recognition of vanilla\nsequence-to-sequence models without specialized front-ends or preprocessing.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 12:00:18 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Sriram", "Anuroop", ""], ["Jun", "Heewoo", ""], ["Gaur", "Yashesh", ""], ["Satheesh", "Sanjeev", ""]]}, {"id": "1711.01569", "submitter": "Markus Dumke", "authors": "Markus Dumke", "title": "Double Q($\\sigma$) and Q($\\sigma, \\lambda$): Unifying Reinforcement\n  Learning Control Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal-difference (TD) learning is an important field in reinforcement\nlearning. Sarsa and Q-Learning are among the most used TD algorithms. The\nQ($\\sigma$) algorithm (Sutton and Barto (2017)) unifies both. This paper\nextends the Q($\\sigma$) algorithm to an online multi-step algorithm Q($\\sigma,\n\\lambda$) using eligibility traces and introduces Double Q($\\sigma$) as the\nextension of Q($\\sigma$) to double learning. Experiments suggest that the new\nQ($\\sigma, \\lambda$) algorithm can outperform the classical TD control methods\nSarsa($\\lambda$), Q($\\lambda$) and Q($\\sigma$).\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 12:05:31 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Dumke", "Markus", ""]]}, {"id": "1711.01577", "submitter": "Zhen He", "authors": "Zhen He, Shaobing Gao, Liang Xiao, Daxue Liu, Hangen He, David Barber", "title": "Wider and Deeper, Cheaper and Faster: Tensorized LSTMs for Sequence\n  Learning", "comments": "Accepted by NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short-Term Memory (LSTM) is a popular approach to boosting the ability\nof Recurrent Neural Networks to store longer term temporal information. The\ncapacity of an LSTM network can be increased by widening and adding layers.\nHowever, usually the former introduces additional parameters, while the latter\nincreases the runtime. As an alternative we propose the Tensorized LSTM in\nwhich the hidden states are represented by tensors and updated via a\ncross-layer convolution. By increasing the tensor size, the network can be\nwidened efficiently without additional parameters since the parameters are\nshared across different locations in the tensor; by delaying the output, the\nnetwork can be deepened implicitly with little additional runtime since deep\ncomputations for each timestep are merged into temporal computations of the\nsequence. Experiments conducted on five challenging sequence learning tasks\nshow the potential of the proposed model.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 12:30:35 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 10:41:28 GMT"}, {"version": "v3", "created": "Wed, 13 Dec 2017 02:14:14 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["He", "Zhen", ""], ["Gao", "Shaobing", ""], ["Xiao", "Liang", ""], ["Liu", "Daxue", ""], ["He", "Hangen", ""], ["Barber", "David", ""]]}, {"id": "1711.01596", "submitter": "Cameron Musco", "authors": "Cameron Musco and David P. Woodruff", "title": "Is Input Sparsity Time Possible for Kernel Low-Rank Approximation?", "comments": "To appear, NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank approximation is a common tool used to accelerate kernel methods:\nthe $n \\times n$ kernel matrix $K$ is approximated via a rank-$k$ matrix\n$\\tilde K$ which can be stored in much less space and processed more quickly.\nIn this work we study the limits of computationally efficient low-rank kernel\napproximation. We show that for a broad class of kernels, including the popular\nGaussian and polynomial kernels, computing a relative error $k$-rank\napproximation to $K$ is at least as difficult as multiplying the input data\nmatrix $A \\in \\mathbb{R}^{n \\times d}$ by an arbitrary matrix $C \\in\n\\mathbb{R}^{d \\times k}$. Barring a breakthrough in fast matrix multiplication,\nwhen $k$ is not too large, this requires $\\Omega(nnz(A)k)$ time where $nnz(A)$\nis the number of non-zeros in $A$. This lower bound matches, in many parameter\nregimes, recent work on subquadratic time algorithms for low-rank approximation\nof general kernels [MM16,MW17], demonstrating that these algorithms are\nunlikely to be significantly improved, in particular to $O(nnz(A))$ input\nsparsity runtimes. At the same time there is hope: we show for the first time\nthat $O(nnz(A))$ time approximation is possible for general radial basis\nfunction kernels (e.g., the Gaussian kernel) for the closely related problem of\nlow-rank approximation of the kernelized dataset.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 14:36:25 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Musco", "Cameron", ""], ["Woodruff", "David P.", ""]]}, {"id": "1711.01628", "submitter": "Alper Kose", "authors": "Noyan Evirgen, Alper Kose", "title": "The Effect of Communication on Noncooperative Multiplayer Multi-Armed\n  Bandit Problems", "comments": "This work has been accepted to the 2017 IEEE ICMLA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider decentralized stochastic multi-armed bandit problem with multiple\nplayers in the case of different communication probabilities between players.\nEach player makes a decision of pulling an arm without cooperation while aiming\nto maximize his or her reward but informs his or her neighbors in the end of\nevery turn about the arm he or she pulled and the reward he or she got.\nNeighbors of players are determined according to an Erdos-Renyi graph with\nwhich is reproduced in the beginning of every turn. We consider i.i.d. rewards\ngenerated by a Bernoulli distribution and assume that players are unaware about\nthe arms' probability distributions and their mean values. In case of a\ncollision, we assume that only one of the players who is randomly chosen gets\nthe reward where the others get zero reward. We study the effects of\nconnectivity, the degree of communication between players, on the cumulative\nregret using well-known algorithms UCB1, epsilon-Greedy and Thompson Sampling.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 18:13:25 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Evirgen", "Noyan", ""], ["Kose", "Alper", ""]]}, {"id": "1711.01634", "submitter": "Maarten Grachten", "authors": "Maarten Grachten and Carlos Eduardo Cancino Chac\\'on", "title": "Strategies for Conceptual Change in Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A remarkable feature of human beings is their capacity for creative\nbehaviour, referring to their ability to react to problems in ways that are\nnovel, surprising, and useful. Transformational creativity is a form of\ncreativity where the creative behaviour is induced by a transformation of the\nactor's conceptual space, that is, the representational system with which the\nactor interprets its environment. In this report, we focus on ways of adapting\nsystems of learned representations as they switch from performing one task to\nperforming another. We describe an experimental comparison of multiple\nstrategies for adaptation of learned features, and evaluate how effectively\neach of these strategies realizes the adaptation, in terms of the amount of\ntraining, and in terms of their ability to cope with restricted availability of\ntraining data. We show, among other things, that across handwritten digits,\nnatural images, and classical music, adaptive strategies are systematically\nmore effective than a baseline method that starts learning from scratch.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 18:31:26 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 08:54:37 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Grachten", "Maarten", ""], ["Chac\u00f3n", "Carlos Eduardo Cancino", ""]]}, {"id": "1711.01647", "submitter": "Alper Kose", "authors": "Alper Kose, Can Kanbak, Noyan Evirgen", "title": "Performance Comparison of Algorithms for Movie Rating Estimation", "comments": "This work has been accepted to the 2017 IEEE ICMLA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, our goal is to compare performances of three different\nalgorithms to predict the ratings that will be given to movies by potential\nusers where we are given a user-movie rating matrix based on the past\nobservations. To this end, we evaluate User-Based Collaborative Filtering,\nIterative Matrix Factorization and Yehuda Koren's Integrated model using\nneighborhood and factorization where we use root mean square error (RMSE) as\nthe performance evaluation metric. In short, we do not observe significant\ndifferences between performances, especially when the complexity increase is\nconsidered. We can conclude that Iterative Matrix Factorization performs fairly\nwell despite its simplicity.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 19:29:21 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Kose", "Alper", ""], ["Kanbak", "Can", ""], ["Evirgen", "Noyan", ""]]}, {"id": "1711.01655", "submitter": "Elchanan Mossel", "authors": "Vishesh Jain, Frederic Koehler, Elchanan Mossel", "title": "Approximating Partition Functions in Constant Time", "comments": "This preprint is completely subsumed by preprints arXiv:1802.06126\n  and arXiv:1802.06129 by the same authors which also include important\n  references that are missing in the current preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study approximations of the partition function of dense graphical models.\nPartition functions of graphical models play a fundamental role is statistical\nphysics, in statistics and in machine learning. Two of the main methods for\napproximating the partition function are Markov Chain Monte Carlo and\nVariational Methods. An impressive body of work in mathematics, physics and\ntheoretical computer science provides conditions under which Markov Chain Monte\nCarlo methods converge in polynomial time. These methods often lead to\npolynomial time approximation algorithms for the partition function in cases\nwhere the underlying model exhibits correlation decay. There are very few\ntheoretical guarantees for the performance of variational methods. One\nexception is recent results by Risteski (2016) who considered dense graphical\nmodels and showed that using variational methods, it is possible to find an\n$O(\\epsilon n)$ additive approximation to the log partition function in time\n$n^{O(1/\\epsilon^2)}$ even in a regime where correlation decay does not hold.\n  We show that under essentially the same conditions, an $O(\\epsilon n)$\nadditive approximation of the log partition function can be found in constant\ntime, independent of $n$. In particular, our results cover dense Ising and\nPotts models as well as dense graphical models with $k$-wise interaction. They\nalso apply for low threshold rank models.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 20:06:01 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 16:31:41 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Jain", "Vishesh", ""], ["Koehler", "Frederic", ""], ["Mossel", "Elchanan", ""]]}, {"id": "1711.01660", "submitter": "Aryan Mokhtari", "authors": "Aryan Mokhtari and Hamed Hassani and Amin Karbasi", "title": "Conditional Gradient Method for Stochastic Submodular Maximization:\n  Closing the Gap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of \\textit{constrained} and\n\\textit{stochastic} continuous submodular maximization. Even though the\nobjective function is not concave (nor convex) and is defined in terms of an\nexpectation, we develop a variant of the conditional gradient method, called\n\\alg, which achieves a \\textit{tight} approximation guarantee. More precisely,\nfor a monotone and continuous DR-submodular function and subject to a\n\\textit{general} convex body constraint, we prove that \\alg achieves a\n$[(1-1/e)\\text{OPT} -\\eps]$ guarantee (in expectation) with\n$\\mathcal{O}{(1/\\eps^3)}$ stochastic gradient computations. This guarantee\nmatches the known hardness results and closes the gap between deterministic and\nstochastic continuous submodular maximization. By using stochastic continuous\noptimization as an interface, we also provide the first $(1-1/e)$ tight\napproximation guarantee for maximizing a \\textit{monotone but stochastic}\nsubmodular \\textit{set} function subject to a general matroid constraint.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 20:56:44 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Mokhtari", "Aryan", ""], ["Hassani", "Hamed", ""], ["Karbasi", "Amin", ""]]}, {"id": "1711.01666", "submitter": "Yipeng Hu", "authors": "Yipeng Hu, Marc Modat, Eli Gibson, Nooshin Ghavami, Ester Bonmati,\n  Caroline M. Moore, Mark Emberton, J. Alison Noble, Dean C. Barratt, Tom\n  Vercauteren", "title": "Label-driven weakly-supervised learning for multimodal deformable image\n  registration", "comments": "Accepted to ISBI 2018", "journal-ref": null, "doi": "10.1109/ISBI.2018.8363756", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatially aligning medical images from different modalities remains a\nchallenging task, especially for intraoperative applications that require fast\nand robust algorithms. We propose a weakly-supervised, label-driven formulation\nfor learning 3D voxel correspondence from higher-level label correspondence,\nthereby bypassing classical intensity-based image similarity measures. During\ntraining, a convolutional neural network is optimised by outputting a dense\ndisplacement field (DDF) that warps a set of available anatomical labels from\nthe moving image to match their corresponding counterparts in the fixed image.\nThese label pairs, including solid organs, ducts, vessels, point landmarks and\nother ad hoc structures, are only required at training time and can be\nspatially aligned by minimising a cross-entropy function of the warped moving\nlabel and the fixed label. During inference, the trained network takes a new\nimage pair to predict an optimal DDF, resulting in a fully-automatic,\nlabel-free, real-time and deformable registration. For interventional\napplications where large global transformation prevails, we also propose a\nneural network architecture to jointly optimise the global- and local\ndisplacements. Experiment results are presented based on cross-validating\nregistrations of 111 pairs of T2-weighted magnetic resonance images and 3D\ntransrectal ultrasound images from prostate cancer patients with a total of\nover 4000 anatomical labels, yielding a median target registration error of 4.2\nmm on landmark centroids and a median Dice of 0.88 on prostate glands.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 22:01:57 GMT"}, {"version": "v2", "created": "Sun, 24 Dec 2017 22:23:19 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Hu", "Yipeng", ""], ["Modat", "Marc", ""], ["Gibson", "Eli", ""], ["Ghavami", "Nooshin", ""], ["Bonmati", "Ester", ""], ["Moore", "Caroline M.", ""], ["Emberton", "Mark", ""], ["Noble", "J. Alison", ""], ["Barratt", "Dean C.", ""], ["Vercauteren", "Tom", ""]]}, {"id": "1711.01703", "submitter": "Oliver Obst", "authors": "Olivia Michael and Oliver Obst and Falk Schmidsberger and Frieder\n  Stolzenburg", "title": "RoboCupSimData: A RoboCup soccer research dataset", "comments": "6 pages; https://bitbucket.org/oliverobst/robocupsimdata", "journal-ref": "In Dirk Holz, Katie Genter, Maarouf Saad, and Oskar von Stryk,\n  editors, RoboCup 2018: Robot Soccer World Cup XXII. RoboCup International\n  Symposium, LNAI 11374, pages 230-237, Montr\\'eal, Canada, 2019. Springer\n  Nature Switzerland", "doi": "10.1007/978-3-030-27544-0_19", "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RoboCup is an international scientific robot competition in which teams of\nmultiple robots compete against each other. Its different leagues provide many\nsources of robotics data, that can be used for further analysis and application\nof machine learning. This paper describes a large dataset from games of some of\nthe top teams (from 2016 and 2017) in RoboCup Soccer Simulation League (2D),\nwhere teams of 11 robots (agents) compete against each other. Overall, we used\n10 different teams to play each other, resulting in 45 unique pairings. For\neach pairing, we ran 25 matches (of 10mins), leading to 1125 matches or more\nthan 180 hours of game play. The generated CSV files are 17GB of data (zipped),\nor 229GB (unzipped). The dataset is unique in the sense that it contains both\nthe ground truth data (global, complete, noise-free information of all objects\non the field), as well as the noisy, local and incomplete percepts of each\nrobot. These data are made available as CSV files, as well as in the original\nsoccer simulator formats.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 03:09:38 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Michael", "Olivia", ""], ["Obst", "Oliver", ""], ["Schmidsberger", "Falk", ""], ["Stolzenburg", "Frieder", ""]]}, {"id": "1711.01742", "submitter": "Ji Chen", "authors": "Ji Chen, Xiaodong Li", "title": "Model-free Nonconvex Matrix Completion: Local Minima Analysis and\n  Applications in Memory-efficient Kernel PCA", "comments": "Main theorem improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies low-rank approximation of a positive semidefinite matrix\nfrom partial entries via nonconvex optimization. We characterized how well\nlocal-minimum based low-rank factorization approximates a fixed positive\nsemidefinite matrix without any assumptions on the rank-matching, the condition\nnumber or eigenspace incoherence parameter. Furthermore, under certain\nassumptions on rank-matching and well-boundedness of condition numbers and\neigenspace incoherence parameters, a corollary of our main theorem improves the\nstate-of-the-art sampling rate results for nonconvex matrix completion with no\nspurious local minima in Ge et al. [2016, 2017]. In addition, we investigated\nwhen the proposed nonconvex optimization results in accurate low-rank\napproximations even in presence of large condition numbers, large incoherence\nparameters, or rank mismatching. We also propose to apply the nonconvex\noptimization to memory-efficient Kernel PCA. Compared to the well-known\nNystr\\\"{o}m methods, numerical experiments indicate that the proposed nonconvex\noptimization approach yields more stable results in both low-rank approximation\nand clustering.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 06:24:59 GMT"}, {"version": "v2", "created": "Tue, 26 Dec 2017 07:10:00 GMT"}, {"version": "v3", "created": "Thu, 4 Apr 2019 23:08:24 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Chen", "Ji", ""], ["Li", "Xiaodong", ""]]}, {"id": "1711.01744", "submitter": "Minh Trung Le", "authors": "Trung Le, Tu Dinh Nguyen, Dinh Phung", "title": "KGAN: How to Break The Minimax Game in GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) were intuitively and attractively\nexplained under the perspective of game theory, wherein two involving parties\nare a discriminator and a generator. In this game, the task of the\ndiscriminator is to discriminate the real and generated (i.e., fake) data,\nwhilst the task of the generator is to generate the fake data that maximally\nconfuses the discriminator. In this paper, we propose a new viewpoint for GANs,\nwhich is termed as the minimizing general loss viewpoint. This viewpoint shows\na connection between the general loss of a classification problem regarding a\nconvex loss function and a f-divergence between the true and fake data\ndistributions. Mathematically, we proposed a setting for the classification\nproblem of the true and fake data, wherein we can prove that the general loss\nof this classification problem is exactly the negative f-divergence for a\ncertain convex function f. This allows us to interpret the problem of learning\nthe generator for dismissing the f-divergence between the true and fake data\ndistributions as that of maximizing the general loss which is equivalent to the\nmin-max problem in GAN if the Logistic loss is used in the classification\nproblem. However, this viewpoint strengthens GANs in two ways. First, it allows\nus to employ any convex loss function for the discriminator. Second, it\nsuggests that rather than limiting ourselves in NN-based discriminators, we can\nalternatively utilize other powerful families. Bearing this viewpoint, we then\npropose using the kernel-based family for discriminators. This family has two\nappealing features: i) a powerful capacity in classifying non-linear nature\ndata and ii) being convex in the feature space. Using the convexity of this\nfamily, we can further develop Fenchel duality to equivalently transform the\nmax-min problem to the max-max dual problem.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 06:33:01 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Le", "Trung", ""], ["Nguyen", "Tu Dinh", ""], ["Phung", "Dinh", ""]]}, {"id": "1711.01754", "submitter": "Ju-Hong Lee", "authors": "Ju-Hong Lee, Moon-Ju Kang, Bumghi Choi", "title": "Learning Solving Procedure for Artificial Neural Network", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is expected that progress toward true artificial intelligence will be\nachieved through the emergence of a system that integrates representation\nlearning and complex reasoning (LeCun et al. 2015). In response to this\nprediction, research has been conducted on implementing the symbolic reasoning\nof a von Neumann computer in an artificial neural network (Graves et al. 2016;\nGraves et al. 2014; Reed et al. 2015). However, these studies have many\nlimitations in realizing neural-symbolic integration (Jaeger. 2016). Here, we\npresent a new learning paradigm: a learning solving procedure (LSP) that learns\nthe procedure for solving complex problems. This is not accomplished merely by\nlearning input-output data, but by learning algorithms through a solving\nprocedure that obtains the output as a sequence of tasks for a given input\nproblem. The LSP neural network system not only learns simple problems of\naddition and multiplication, but also the algorithms of complicated problems,\nsuch as complex arithmetic expression, sorting, and Hanoi Tower. To realize\nthis, the LSP neural network structure consists of a deep neural network and\nlong short-term memory, which are recursively combined. Through\nexperimentation, we demonstrate the efficiency and scalability of LSP and its\nvalidity as a mechanism of complex reasoning.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 07:28:10 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Lee", "Ju-Hong", ""], ["Kang", "Moon-Ju", ""], ["Choi", "Bumghi", ""]]}, {"id": "1711.01761", "submitter": "Alexandre Defossez", "authors": "Alexandre D\\'efossez (FAIR), Francis Bach (SIERRA)", "title": "AdaBatch: Efficient Gradient Aggregation Rules for Sequential and\n  Parallel Stochastic Gradient Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a new aggregation operator for gradients coming from a mini-batch\nfor stochastic gradient (SG) methods that allows a significant speed-up in the\ncase of sparse optimization problems. We call this method AdaBatch and it only\nrequires a few lines of code change compared to regular mini-batch SGD\nalgorithms. We provide a theoretical insight to understand how this new class\nof algorithms is performing and show that it is equivalent to an implicit\nper-coordinate rescaling of the gradients, similarly to what Adagrad methods\ncan do. In theory and in practice, this new aggregation allows to keep the same\nsample efficiency of SG methods while increasing the batch size.\nExperimentally, we also show that in the case of smooth convex optimization,\nour procedure can even obtain a better loss when increasing the batch size for\na fixed number of samples. We then apply this new algorithm to obtain a\nparallelizable stochastic gradient method that is synchronous but allows\nspeed-up on par with Hogwild! methods as convergence does not deteriorate with\nthe increase of the batch size. The same approach can be used to make\nmini-batch provably efficient for variance-reduced SG methods such as SVRG.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 07:52:34 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["D\u00e9fossez", "Alexandre", "", "FAIR"], ["Bach", "Francis", "", "SIERRA"]]}, {"id": "1711.01768", "submitter": "Seong Joon Oh", "authors": "Seong Joon Oh, Max Augustin, Bernt Schiele, Mario Fritz", "title": "Towards Reverse-Engineering Black-Box Neural Networks", "comments": "20 pages, 12 figures, to appear at ICLR'18. Code:\n  https://goo.gl/MbYfsv", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many deployed learned models are black boxes: given input, returns output.\nInternal information about the model, such as the architecture, optimisation\nprocedure, or training data, is not disclosed explicitly as it might contain\nproprietary information or make the system more vulnerable. This work shows\nthat such attributes of neural networks can be exposed from a sequence of\nqueries. This has multiple implications. On the one hand, our work exposes the\nvulnerability of black-box neural networks to different types of attacks -- we\nshow that the revealed internal information helps generate more effective\nadversarial examples against the black box model. On the other hand, this\ntechnique can be used for better protection of private content from automatic\nrecognition models using adversarial examples. Our paper suggests that it is\nactually hard to draw a line between white box and black box models.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 07:58:48 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 14:04:23 GMT"}, {"version": "v3", "created": "Wed, 14 Feb 2018 18:50:53 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Oh", "Seong Joon", ""], ["Augustin", "Max", ""], ["Schiele", "Bernt", ""], ["Fritz", "Mario", ""]]}, {"id": "1711.01790", "submitter": "Hang Xiao", "authors": "Hang Xiao, Zhengli Xing, Linxiao Yang, Jun Fang, Yanlun Wu", "title": "Simultaneous Block-Sparse Signal Recovery Using Pattern-Coupled Sparse\n  Bayesian Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the block-sparse signals recovery problem in the\ncontext of multiple measurement vectors (MMV) with common row sparsity\npatterns. We develop a new method for recovery of common row sparsity MMV\nsignals, where a pattern-coupled hierarchical Gaussian prior model is\nintroduced to characterize both the block-sparsity of the coefficients and the\nstatistical dependency between neighboring coefficients of the common row\nsparsity MMV signals. Unlike many other methods, the proposed method is able to\nautomatically capture the block sparse structure of the unknown signal. Our\nmethod is developed using an expectation-maximization (EM) framework.\nSimulation results show that our proposed method offers competitive performance\nin recovering block-sparse common row sparsity pattern MMV signals.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 09:00:00 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Xiao", "Hang", ""], ["Xing", "Zhengli", ""], ["Yang", "Linxiao", ""], ["Fang", "Jun", ""], ["Wu", "Yanlun", ""]]}, {"id": "1711.01843", "submitter": "Mahardhika Pratama Dr", "authors": "Mahardhika Pratama, Eric Dimla, Edwin Lughofer, Witold Pedrycz, Tegoeh\n  Tjahjowidowo", "title": "Online Tool Condition Monitoring Based on Parsimonious Ensemble+", "comments": "this paper has been published by IEEE Transactions on Cybernetics", "journal-ref": "IEEE Transactions on Cybernetics, 2018", "doi": "10.1109/TCYB.2018.2871120", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate diagnosis of tool wear in metal turning process remains an open\nchallenge for both scientists and industrial practitioners because of\ninhomogeneities in workpiece material, nonstationary machining settings to suit\nproduction requirements, and nonlinear relations between measured variables and\ntool wear. Common methodologies for tool condition monitoring still rely on\nbatch approaches which cannot cope with a fast sampling rate of metal cutting\nprocess. Furthermore they require a retraining process to be completed from\nscratch when dealing with a new set of machining parameters. This paper\npresents an online tool condition monitoring approach based on Parsimonious\nEnsemble+, pENsemble+. The unique feature of pENsemble+ lies in its highly\nflexible principle where both ensemble structure and base-classifier structure\ncan automatically grow and shrink on the fly based on the characteristics of\ndata streams. Moreover, the online feature selection scenario is integrated to\nactively sample relevant input attributes. The paper presents advancement of a\nnewly developed ensemble learning algorithm, pENsemble+, where online active\nlearning scenario is incorporated to reduce operator labelling effort. The\nensemble merging scenario is proposed which allows reduction of ensemble\ncomplexity while retaining its diversity. Experimental studies utilising\nreal-world manufacturing data streams and comparisons with well known\nalgorithms were carried out. Furthermore, the efficacy of pENsemble was\nexamined using benchmark concept drift data streams. It has been found that\npENsemble+ incurs low structural complexity and results in a significant\nreduction of operator labelling effort.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 11:31:46 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 21:12:37 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Pratama", "Mahardhika", ""], ["Dimla", "Eric", ""], ["Lughofer", "Edwin", ""], ["Pedrycz", "Witold", ""], ["Tjahjowidowo", "Tegoeh", ""]]}, {"id": "1711.01846", "submitter": "Artur Speiser", "authors": "Artur Speiser, Jinyao Yan, Evan Archer, Lars Buesing, Srinivas C.\n  Turaga, Jakob H. Macke", "title": "Fast amortized inference of neural activity from calcium imaging data\n  with variational autoencoders", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calcium imaging permits optical measurement of neural activity. Since\nintracellular calcium concentration is an indirect measurement of neural\nactivity, computational tools are necessary to infer the true underlying\nspiking activity from fluorescence measurements. Bayesian model inversion can\nbe used to solve this problem, but typically requires either computationally\nexpensive MCMC sampling, or faster but approximate maximum-a-posteriori\noptimization. Here, we introduce a flexible algorithmic framework for fast,\nefficient and accurate extraction of neural spikes from imaging data. Using the\nframework of variational autoencoders, we propose to amortize inference by\ntraining a deep neural network to perform model inversion efficiently. The\nrecognition network is trained to produce samples from the posterior\ndistribution over spike trains. Once trained, performing inference amounts to a\nfast single forward pass through the network, without the need for iterative\noptimization or sampling. We show that amortization can be applied flexibly to\na wide range of nonlinear generative models and significantly improves upon the\nstate of the art in computation time, while achieving competitive accuracy. Our\nframework is also able to represent posterior distributions over spike-trains.\nWe demonstrate the generality of our method by proposing the first\nprobabilistic approach for separating backpropagating action potentials from\nputative synaptic inputs in calcium imaging of dendritic spines.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 11:57:54 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Speiser", "Artur", ""], ["Yan", "Jinyao", ""], ["Archer", "Evan", ""], ["Buesing", "Lars", ""], ["Turaga", "Srinivas C.", ""], ["Macke", "Jakob H.", ""]]}, {"id": "1711.01870", "submitter": "Snehasis Banerjee", "authors": "Snehasis Banerjee and Tanushyam Chattopadhyay and Ayan Mukherjee", "title": "Interpretable Feature Recommendation for Signal Analytics", "comments": "4 pages, Interpretable Data Mining Workshop, CIKM 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an automated approach for interpretable feature\nrecommendation for solving signal data analytics problems. The method has been\ntested by performing experiments on datasets in the domain of prognostics where\ninterpretation of features is considered very important. The proposed approach\nis based on Wide Learning architecture and provides means for interpretation of\nthe recommended features. It is to be noted that such an interpretation is not\navailable with feature learning approaches like Deep Learning (such as\nConvolutional Neural Network) or feature transformation approaches like\nPrincipal Component Analysis. Results show that the feature recommendation and\ninterpretation techniques are quite effective for the problems at hand in terms\nof performance and drastic reduction in time to develop a solution. It is\nfurther shown by an example, how this human-in-loop interpretation system can\nbe used as a prescriptive system.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 13:03:37 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Banerjee", "Snehasis", ""], ["Chattopadhyay", "Tanushyam", ""], ["Mukherjee", "Ayan", ""]]}, {"id": "1711.01968", "submitter": "Jiajun Zhang", "authors": "Jiajun Zhang, Zhiguo Shi", "title": "Deformable Deep Convolutional Generative Adversarial Network in\n  Microwave Based Hand Gesture Recognition System", "comments": "Accepted by International Conference on Wireless Communications and\n  Signal Processing 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional vision-based hand gesture recognition systems is limited under\ndark circumstances. In this paper, we build a hand gesture recognition system\nbased on microwave transceiver and deep learning algorithm. A Doppler radar\nsensor with dual receiving channels at 5.8GHz is used to acquire a big database\nof hand gestures signals. The received hand gesture signals are then processed\nwith time-frequency analysis. Based on these big databases of hand gesture, we\npropose a new machine learning architecture called deformable deep\nconvolutional generative adversarial network. Experimental results show the new\narchitecture can upgrade the recognition rate by 10% and the deformable kernel\ncan reduce the testing time cost by 30%.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 15:44:28 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 12:05:19 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Zhang", "Jiajun", ""], ["Shi", "Zhiguo", ""]]}, {"id": "1711.01970", "submitter": "Eirikur Agustsson", "authors": "Eirikur Agustsson, Alexander Sage, Radu Timofte, Luc Van Gool", "title": "Optimal transport maps for distribution preserving operations on latent\n  spaces of Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models such as Variational Auto Encoders (VAEs) and Generative\nAdversarial Networks (GANs) are typically trained for a fixed prior\ndistribution in the latent space, such as uniform or Gaussian. After a trained\nmodel is obtained, one can sample the Generator in various forms for\nexploration and understanding, such as interpolating between two samples,\nsampling in the vicinity of a sample or exploring differences between a pair of\nsamples applied to a third sample. In this paper, we show that the latent space\noperations used in the literature so far induce a distribution mismatch between\nthe resulting outputs and the prior distribution the model was trained on. To\naddress this, we propose to use distribution matching transport maps to ensure\nthat such latent space operations preserve the prior distribution, while\nminimally modifying the original operation. Our experimental results validate\nthat the proposed operations give higher quality samples compared to the\noriginal operations.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 15:51:29 GMT"}, {"version": "v2", "created": "Wed, 24 Jan 2018 21:55:52 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Agustsson", "Eirikur", ""], ["Sage", "Alexander", ""], ["Timofte", "Radu", ""], ["Van Gool", "Luc", ""]]}, {"id": "1711.02033", "submitter": "Siamak Ravanbakhsh", "authors": "Siamak Ravanbakhsh and Junier Oliva and Sebastien Fromenteau and Layne\n  C. Price and Shirley Ho and Jeff Schneider and Barnabas Poczos", "title": "Estimating Cosmological Parameters from the Dark Matter Distribution", "comments": "ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A grand challenge of the 21st century cosmology is to accurately estimate the\ncosmological parameters of our Universe. A major approach to estimating the\ncosmological parameters is to use the large-scale matter distribution of the\nUniverse. Galaxy surveys provide the means to map out cosmic large-scale\nstructure in three dimensions. Information about galaxy locations is typically\nsummarized in a \"single\" function of scale, such as the galaxy correlation\nfunction or power-spectrum. We show that it is possible to estimate these\ncosmological parameters directly from the distribution of matter. This paper\npresents the application of deep 3D convolutional networks to volumetric\nrepresentation of dark-matter simulations as well as the results obtained using\na recently proposed distribution regression framework, showing that machine\nlearning techniques are comparable to, and can sometimes outperform,\nmaximum-likelihood point estimates using \"cosmological models\". This opens the\nway to estimating the parameters of our Universe with higher accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 17:37:43 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Ravanbakhsh", "Siamak", ""], ["Oliva", "Junier", ""], ["Fromenteau", "Sebastien", ""], ["Price", "Layne C.", ""], ["Ho", "Shirley", ""], ["Schneider", "Jeff", ""], ["Poczos", "Barnabas", ""]]}, {"id": "1711.02038", "submitter": "Xun Gao", "authors": "Xun Gao, Zhengyu Zhang, Luming Duan", "title": "An efficient quantum algorithm for generative machine learning", "comments": "7+15 pages, 3+6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central task in the field of quantum computing is to find applications\nwhere quantum computer could provide exponential speedup over any classical\ncomputer. Machine learning represents an important field with broad\napplications where quantum computer may offer significant speedup. Several\nquantum algorithms for discriminative machine learning have been found based on\nefficient solving of linear algebraic problems, with potential exponential\nspeedup in runtime under the assumption of effective input from a quantum\nrandom access memory. In machine learning, generative models represent another\nlarge class which is widely used for both supervised and unsupervised learning.\nHere, we propose an efficient quantum algorithm for machine learning based on a\nquantum generative model. We prove that our proposed model is exponentially\nmore powerful to represent probability distributions compared with classical\ngenerative models and has exponential speedup in training and inference at\nleast for some instances under a reasonable assumption in computational\ncomplexity theory. Our result opens a new direction for quantum machine\nlearning and offers a remarkable example in which a quantum algorithm shows\nexponential improvement over any classical algorithm in an important\napplication field.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 17:44:03 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Gao", "Xun", ""], ["Zhang", "Zhengyu", ""], ["Duan", "Luming", ""]]}, {"id": "1711.02074", "submitter": "Dufan Wu", "authors": "Dufan Wu, Kyungsang Kim, Bin Dong, Georges El Fakhri and Quanzheng Li", "title": "End-to-end Lung Nodule Detection in Computed Tomography", "comments": "published at MLMI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer aided diagnostic (CAD) system is crucial for modern med-ical\nimaging. But almost all CAD systems operate on reconstructed images, which were\noptimized for radiologists. Computer vision can capture features that is subtle\nto human observers, so it is desirable to design a CAD system op-erating on the\nraw data. In this paper, we proposed a deep-neural-network-based detection\nsystem for lung nodule detection in computed tomography (CT). A\nprimal-dual-type deep reconstruction network was applied first to convert the\nraw data to the image space, followed by a 3-dimensional convolutional neural\nnetwork (3D-CNN) for the nodule detection. For efficient network training, the\ndeep reconstruction network and the CNN detector was trained sequentially\nfirst, then followed by one epoch of end-to-end fine tuning. The method was\nevaluated on the Lung Image Database Consortium image collection (LIDC-IDRI)\nwith simulated forward projections. With 144 multi-slice fanbeam pro-jections,\nthe proposed end-to-end detector could achieve comparable sensitivity with the\nreference detector, which was trained and applied on the fully-sampled image\ndata. It also demonstrated superior detection performance compared to detectors\ntrained on the reconstructed images. The proposed method is general and could\nbe expanded to most detection tasks in medical imaging.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 18:41:18 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 18:15:45 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Wu", "Dufan", ""], ["Kim", "Kyungsang", ""], ["Dong", "Bin", ""], ["Fakhri", "Georges El", ""], ["Li", "Quanzheng", ""]]}, {"id": "1711.02088", "submitter": "Ronnie Mainieri", "authors": "Curt Hastings and Ronnie Mainieri", "title": "Computer activity learning from system call time series", "comments": "27 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a previously introduced similarity function for the stream of system\ncalls generated by a computer, we engineer a program-in-execution classifier\nusing deep learning methods. Tested on malware classification, it significantly\noutperforms current state of the art. We provide a series of performance\nmeasures and tests to demonstrate the capabilities, including measurements from\nproduction use. We show how the system scales linearly with the number of\nendpoints. With the system we estimate the total number of malware families\ncreated over the last 10 years as 3450, in line with reasonable economic\nconstraints. The more limited rate for new malware families than previously\nacknowledged implies that machine learning malware classifiers risk being\ntested on their training set; we achieve F1 = 0.995 in a test carefully\ndesigned to mitigate this risk.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 11:33:09 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Hastings", "Curt", ""], ["Mainieri", "Ronnie", ""]]}, {"id": "1711.02114", "submitter": "Thiago Serra", "authors": "Thiago Serra and Christian Tjandraatmadja and Srikumar Ramalingam", "title": "Bounding and Counting Linear Regions of Deep Neural Networks", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the complexity of deep neural networks (DNN) that represent\npiecewise linear (PWL) functions. In particular, we study the number of linear\nregions, i.e. pieces, that a PWL function represented by a DNN can attain, both\ntheoretically and empirically. We present (i) tighter upper and lower bounds\nfor the maximum number of linear regions on rectifier networks, which are exact\nfor inputs of dimension one; (ii) a first upper bound for multi-layer maxout\nnetworks; and (iii) a first method to perform exact enumeration or counting of\nthe number of regions by modeling the DNN with a mixed-integer linear\nformulation. These bounds come from leveraging the dimension of the space\ndefining each linear region. The results also indicate that a deep rectifier\nnetwork can only have more linear regions than every shallow counterpart with\nsame number of neurons if that number exceeds the dimension of the input.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 19:06:12 GMT"}, {"version": "v2", "created": "Sat, 6 Jan 2018 13:18:46 GMT"}, {"version": "v3", "created": "Sat, 9 Jun 2018 10:30:13 GMT"}, {"version": "v4", "created": "Sun, 16 Sep 2018 01:36:41 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Serra", "Thiago", ""], ["Tjandraatmadja", "Christian", ""], ["Ramalingam", "Srikumar", ""]]}, {"id": "1711.02128", "submitter": "Qiyu Kang", "authors": "Qiyu Kang and Wee Peng Tay", "title": "Sequential Multi-Class Labeling in Crowdsourcing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a crowdsourcing platform where workers' responses to questions\nposed by a crowdsourcer are used to determine the hidden state of a multi-class\nlabeling problem. As workers may be unreliable, we propose to perform\nsequential questioning in which the questions posed to the workers are designed\nbased on previous questions and answers. We propose a Partially-Observable\nMarkov Decision Process (POMDP) framework to determine the best questioning\nstrategy, subject to the crowdsourcer's budget constraint. As this POMDP\nformulation is in general intractable, we develop a suboptimal approach based\non a $q$-ary Ulam-R\\'enyi game. We also propose a sampling heuristic, which can\nbe used in tandem with standard POMDP solvers, using our Ulam-R\\'enyi strategy.\nWe demonstrate through simulations that our approaches outperform a\nnon-sequential strategy based on error correction coding and which does not\nutilize workers' previous responses.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 19:23:07 GMT"}, {"version": "v2", "created": "Sat, 19 May 2018 03:28:03 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Kang", "Qiyu", ""], ["Tay", "Wee Peng", ""]]}, {"id": "1711.02131", "submitter": "Sourya Dey", "authors": "Sourya Dey, Kuan-Wen Huang, Peter A. Beerel, Keith M. Chugg", "title": "Characterizing Sparse Connectivity Patterns in Neural Networks", "comments": "Presented at the 2018 Information Theory and Applications Workshop,\n  San Diego, California", "journal-ref": "in 2018 Information Theory and Applications Workshop (ITA), pp.\n  1--8, Feb 2018", "doi": "10.1109/ITA.2018.8502950", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel way of reducing the number of parameters in the\nstorage-hungry fully connected layers of a neural network by using pre-defined\nsparsity, where the majority of connections are absent prior to starting\ntraining. Our results indicate that convolutional neural networks can operate\nwithout any loss of accuracy at less than half percent classification layer\nconnection density, or less than 5 percent overall network connection density.\nWe also investigate the effects of pre-defining the sparsity of networks with\nonly fully connected layers. Based on our sparsifying technique, we introduce\nthe `scatter' metric to characterize the quality of a particular connection\npattern. As proof of concept, we show results on CIFAR, MNIST and a new dataset\non classifying Morse code symbols, which highlights some interesting trends and\nlimits of sparse connection patterns.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 19:26:21 GMT"}, {"version": "v2", "created": "Wed, 8 Nov 2017 02:45:55 GMT"}, {"version": "v3", "created": "Tue, 30 Jan 2018 00:33:48 GMT"}, {"version": "v4", "created": "Fri, 23 Feb 2018 03:31:44 GMT"}, {"version": "v5", "created": "Thu, 25 Apr 2019 23:42:23 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Dey", "Sourya", ""], ["Huang", "Kuan-Wen", ""], ["Beerel", "Peter A.", ""], ["Chugg", "Keith M.", ""]]}, {"id": "1711.02159", "submitter": "Anirban Roychowdhury", "authors": "Anirban Roychowdhury and Srinivasan Parthasarathy", "title": "Adaptive Bayesian Sampling with Monte Carlo EM", "comments": "In Proc. 30th Advances in Neural Information Processing Systems\n  (NIPS), 2017 (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel technique for learning the mass matrices in samplers\nobtained from discretized dynamics that preserve some energy function. Existing\nadaptive samplers use Riemannian preconditioning techniques, where the mass\nmatrices are functions of the parameters being sampled. This leads to\nsignificant complexities in the energy reformulations and resultant dynamics,\noften leading to implicit systems of equations and requiring inversion of\nhigh-dimensional matrices in the leapfrog steps. Our approach provides a\nsimpler alternative, by using existing dynamics in the sampling step of a Monte\nCarlo EM framework, and learning the mass matrices in the M step with a novel\nonline technique. We also propose a way to adaptively set the number of samples\ngathered in the E step, using sampling error estimates from the leapfrog\ndynamics. Along with a novel stochastic sampler based on Nos\\'{e}-Poincar\\'{e}\ndynamics, we use this framework with standard Hamiltonian Monte Carlo (HMC) as\nwell as newer stochastic algorithms such as SGHMC and SGNHT, and show strong\nperformance on synthetic and real high-dimensional sampling scenarios; we\nachieve sampling accuracies comparable to Riemannian samplers while being\nsignificantly faster.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 20:23:24 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Roychowdhury", "Anirban", ""], ["Parthasarathy", "Srinivasan", ""]]}, {"id": "1711.02173", "submitter": "Yonatan Belinkov", "authors": "Yonatan Belinkov, Yonatan Bisk", "title": "Synthetic and Natural Noise Both Break Neural Machine Translation", "comments": "ICLR 2018 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Character-based neural machine translation (NMT) models alleviate\nout-of-vocabulary issues, learn morphology, and move us closer to completely\nend-to-end translation systems. Unfortunately, they are also very brittle and\neasily falter when presented with noisy data. In this paper, we confront NMT\nmodels with synthetic and natural sources of noise. We find that\nstate-of-the-art models fail to translate even moderately noisy texts that\nhumans have no trouble comprehending. We explore two approaches to increase\nmodel robustness: structure-invariant word representations and robust training\non noisy texts. We find that a model based on a character convolutional neural\nnetwork is able to simultaneously learn representations robust to multiple\nkinds of noise.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 20:59:58 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 19:44:38 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Belinkov", "Yonatan", ""], ["Bisk", "Yonatan", ""]]}, {"id": "1711.02195", "submitter": "Hunter Lang", "authors": "Hunter Lang, David Sontag, Aravindan Vijayaraghavan", "title": "Optimality of Approximate Inference Algorithms on Stable Instances", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate algorithms for structured prediction problems---such as LP\nrelaxations and the popular alpha-expansion algorithm (Boykov et al.\n2001)---typically far exceed their theoretical performance guarantees on\nreal-world instances. These algorithms often find solutions that are very close\nto optimal. The goal of this paper is to partially explain the performance of\nalpha-expansion and an LP relaxation algorithm on MAP inference in\nFerromagnetic Potts models (FPMs). Our main results give stability conditions\nunder which these two algorithms provably recover the optimal MAP solution.\nThese theoretical results complement numerous empirical observations of good\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 22:14:34 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 16:02:44 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Lang", "Hunter", ""], ["Sontag", "David", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "1711.02198", "submitter": "Mina Karzand", "authors": "Guy Bresler and Mina Karzand", "title": "Regret Bounds and Regimes of Optimality for User-User and Item-Item\n  Collaborative Filtering", "comments": "51 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an online model for recommendation systems, with each user being\nrecommended an item at each time-step and providing 'like' or 'dislike'\nfeedback. Each user may be recommended a given item at most once. A latent\nvariable model specifies the user preferences: both users and items are\nclustered into types. All users of a given type have identical preferences for\nthe items, and similarly, items of a given type are either all liked or all\ndisliked by a given user. We assume that the matrix encoding the preferences of\neach user type for each item type is randomly generated; in this way, the model\ncaptures structure in both the item and user spaces, the amount of structure\ndepending on the number of each of the types. The measure of performance of the\nrecommendation system is the expected number of disliked recommendations per\nuser, defined as expected regret. We propose two algorithms inspired by\nuser-user and item-item collaborative filtering (CF), modified to explicitly\nmake exploratory recommendations, and prove performance guarantees in terms of\ntheir expected regret. For two regimes of model parameters, with structure only\nin item space or only in user space, we prove information-theoretic lower\nbounds on regret that match our upper bounds up to logarithmic factors. Our\nanalysis elucidates system operating regimes in which existing CF algorithms\nare nearly optimal.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 22:25:43 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 17:40:59 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Bresler", "Guy", ""], ["Karzand", "Mina", ""]]}, {"id": "1711.02211", "submitter": "Ziwei Ji", "authors": "Ziwei Ji, Ruta Mehta, Matus Telgarsky", "title": "Social welfare and profit maximization from revealed preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the seller's problem of finding optimal prices for her $n$\n(divisible) goods when faced with a set of $m$ consumers, given that she can\nonly observe their purchased bundles at posted prices, i.e., revealed\npreferences. We study both social welfare and profit maximization with revealed\npreferences. Although social welfare maximization is a seemingly non-convex\noptimization problem in prices, we show that (i) it can be reduced to a dual\nconvex optimization problem in prices, and (ii) the revealed preferences can be\ninterpreted as supergradients of the concave conjugate of valuation, with which\nsubgradients of the dual function can be computed. We thereby obtain a simple\nsubgradient-based algorithm for strongly concave valuations and convex cost,\nwith query complexity $O(m^2/\\epsilon^2)$, where $\\epsilon$ is the additive\ndifference between the social welfare induced by our algorithm and the optimum\nsocial welfare. We also study social welfare maximization under the online\nsetting, specifically the random permutation model, where consumers arrive\none-by-one in a random order. For the case where consumer valuations can be\narbitrary continuous functions, we propose a price posting mechanism that\nachieves an expected social welfare up to an additive factor of $O(\\sqrt{mn})$\nfrom the maximum social welfare. Finally, for profit maximization (which may be\nnon-convex in simple cases), we give nearly matching upper and lower bounds on\nthe query complexity for separable valuations and cost (i.e., each good can be\ntreated independently).\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 22:57:57 GMT"}, {"version": "v2", "created": "Sat, 6 Oct 2018 04:16:29 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Ji", "Ziwei", ""], ["Mehta", "Ruta", ""], ["Telgarsky", "Matus", ""]]}, {"id": "1711.02213", "submitter": "Xin Wang", "authors": "Urs K\\\"oster, Tristan J. Webb, Xin Wang, Marcel Nassar, Arjun K.\n  Bansal, William H. Constable, O\\u{g}uz H. Elibol, Scott Gray, Stewart Hall,\n  Luke Hornof, Amir Khosrowshahi, Carey Kloss, Ruby J. Pai, Naveen Rao", "title": "Flexpoint: An Adaptive Numerical Format for Efficient Training of Deep\n  Neural Networks", "comments": "14 pages, 5 figures, accepted in Neural Information Processing\n  Systems 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are commonly developed and trained in 32-bit floating\npoint format. Significant gains in performance and energy efficiency could be\nrealized by training and inference in numerical formats optimized for deep\nlearning. Despite advances in limited precision inference in recent years,\ntraining of neural networks in low bit-width remains a challenging problem.\nHere we present the Flexpoint data format, aiming at a complete replacement of\n32-bit floating point format training and inference, designed to support modern\ndeep network topologies without modifications. Flexpoint tensors have a shared\nexponent that is dynamically adjusted to minimize overflows and maximize\navailable dynamic range. We validate Flexpoint by training AlexNet, a deep\nresidual network and a generative adversarial network, using a simulator\nimplemented with the neon deep learning framework. We demonstrate that 16-bit\nFlexpoint closely matches 32-bit floating point in training all three models,\nwithout any need for tuning of model hyperparameters. Our results suggest\nFlexpoint as a promising numerical format for future hardware for training and\ninference.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 23:05:10 GMT"}, {"version": "v2", "created": "Sat, 2 Dec 2017 17:08:50 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["K\u00f6ster", "Urs", ""], ["Webb", "Tristan J.", ""], ["Wang", "Xin", ""], ["Nassar", "Marcel", ""], ["Bansal", "Arjun K.", ""], ["Constable", "William H.", ""], ["Elibol", "O\u011fuz H.", ""], ["Gray", "Scott", ""], ["Hall", "Stewart", ""], ["Hornof", "Luke", ""], ["Khosrowshahi", "Amir", ""], ["Kloss", "Carey", ""], ["Pai", "Ruby J.", ""], ["Rao", "Naveen", ""]]}, {"id": "1711.02255", "submitter": "Guoqing Zheng", "authors": "Guoqing Zheng, Yiming Yang, Jaime Carbonell", "title": "Convolutional Normalizing Flows", "comments": "ICML 2018 Workshop on Theoretical Foundations and Applications of\n  Deep Generative Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian posterior inference is prevalent in various machine learning\nproblems. Variational inference provides one way to approximate the posterior\ndistribution, however its expressive power is limited and so is the accuracy of\nresulting approximation. Recently, there has a trend of using neural networks\nto approximate the variational posterior distribution due to the flexibility of\nneural network architecture. One way to construct flexible variational\ndistribution is to warp a simple density into a complex by normalizing flows,\nwhere the resulting density can be analytically evaluated. However, there is a\ntrade-off between the flexibility of normalizing flow and computation cost for\nefficient transformation. In this paper, we propose a simple yet effective\narchitecture of normalizing flows, ConvFlow, based on convolution over the\ndimensions of random input vector. Experiments on synthetic and real world\nposterior inference problems demonstrate the effectiveness and efficiency of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 02:03:39 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 19:02:14 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Zheng", "Guoqing", ""], ["Yang", "Yiming", ""], ["Carbonell", "Jaime", ""]]}, {"id": "1711.02271", "submitter": "Longhao Yuan", "authors": "Longhao Yuan, Qibin Zhao and Jianting Cao", "title": "High-order Tensor Completion for Data Recovery via Sparse Tensor-train\n  Optimization", "comments": "5 pages (include 1 page of reference) ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim at the problem of tensor data completion. Tensor-train\ndecomposition is adopted because of its powerful representation ability and\nlinear scalability to tensor order. We propose an algorithm named Sparse\nTensor-train Optimization (STTO) which considers incomplete data as sparse\ntensor and uses first-order optimization method to find the factors of\ntensor-train decomposition. Our algorithm is shown to perform well in\nsimulation experiments at both low-order cases and high-order cases. We also\nemploy a tensorization method to transform data to a higher-order form to\nenhance the performance of our algorithm. The results of image recovery\nexperiments in various cases manifest that our method outperforms other\ncompletion algorithms. Especially when the missing rate is very high, e.g.,\n90\\% to 99\\%, our method is significantly better than the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 03:25:49 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 02:16:24 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Yuan", "Longhao", ""], ["Zhao", "Qibin", ""], ["Cao", "Jianting", ""]]}, {"id": "1711.02281", "submitter": "Jiatao Gu", "authors": "Jiatao Gu, James Bradbury, Caiming Xiong, Victor O.K. Li and Richard\n  Socher", "title": "Non-Autoregressive Neural Machine Translation", "comments": "Accepted by ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches to neural machine translation condition each output word\non previously generated outputs. We introduce a model that avoids this\nautoregressive property and produces its outputs in parallel, allowing an order\nof magnitude lower latency during inference. Through knowledge distillation,\nthe use of input token fertilities as a latent variable, and policy gradient\nfine-tuning, we achieve this at a cost of as little as 2.0 BLEU points relative\nto the autoregressive Transformer network used as a teacher. We demonstrate\nsubstantial cumulative improvements associated with each of the three aspects\nof our training strategy, and validate our approach on IWSLT 2016\nEnglish-German and two WMT language pairs. By sampling fertilities in parallel\nat inference time, our non-autoregressive model achieves near-state-of-the-art\nperformance of 29.8 BLEU on WMT 2016 English-Romanian.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 04:42:48 GMT"}, {"version": "v2", "created": "Fri, 9 Mar 2018 03:37:52 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Gu", "Jiatao", ""], ["Bradbury", "James", ""], ["Xiong", "Caiming", ""], ["Li", "Victor O. K.", ""], ["Socher", "Richard", ""]]}, {"id": "1711.02282", "submitter": "Nan Rosemary Ke", "authors": "Anirudh Goyal, Nan Rosemary Ke, Surya Ganguli, Yoshua Bengio", "title": "Variational Walkback: Learning a Transition Operator as a Stochastic\n  Recurrent Net", "comments": "To appear at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method to directly learn a stochastic transition operator\nwhose repeated application provides generated samples. Traditional undirected\ngraphical models approach this problem indirectly by learning a Markov chain\nmodel whose stationary distribution obeys detailed balance with respect to a\nparameterized energy function. The energy function is then modified so the\nmodel and data distributions match, with no guarantee on the number of steps\nrequired for the Markov chain to converge. Moreover, the detailed balance\ncondition is highly restrictive: energy based models corresponding to neural\nnetworks must have symmetric weights, unlike biological neural circuits. In\ncontrast, we develop a method for directly learning arbitrarily parameterized\ntransition operators capable of expressing non-equilibrium stationary\ndistributions that violate detailed balance, thereby enabling us to learn more\nbiologically plausible asymmetric neural networks and more general non-energy\nbased dynamical systems. The proposed training objective, which we derive via\nprincipled variational methods, encourages the transition operator to \"walk\nback\" in multi-step trajectories that start at data-points, as quickly as\npossible back to the original data points. We present a series of experimental\nresults illustrating the soundness of the proposed approach, Variational\nWalkback (VW), on the MNIST, CIFAR-10, SVHN and CelebA datasets, demonstrating\nsuperior samples compared to earlier attempts to learn a transition operator.\nWe also show that although each rapid training trajectory is limited to a\nfinite but variable number of steps, our transition operator continues to\ngenerate good samples well past the length of such trajectories, thereby\ndemonstrating the match of its non-equilibrium stationary distribution to the\ndata distribution. Source Code: http://github.com/anirudh9119/walkback_nips17\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 04:45:13 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Goyal", "Anirudh", ""], ["Ke", "Nan Rosemary", ""], ["Ganguli", "Surya", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1711.02295", "submitter": "Ricardo Baeza-Yates", "authors": "Ricardo Baeza-Yates, Zeinab Liaghat", "title": "Quality-Efficiency Trade-offs in Machine Learning for Text Processing", "comments": "Ten pages, long version of paper that will be presented at IEEE Big\n  Data 2017 (8 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data mining, machine learning, and natural language processing are powerful\ntechniques that can be used together to extract information from large texts.\nDepending on the task or problem at hand, there are many different approaches\nthat can be used. The methods available are continuously being optimized, but\nnot all these methods have been tested and compared in a set of problems that\ncan be solved using supervised machine learning algorithms. The question is\nwhat happens to the quality of the methods if we increase the training data\nsize from, say, 100 MB to over 1 GB? Moreover, are quality gains worth it when\nthe rate of data processing diminishes? Can we trade quality for time\nefficiency and recover the quality loss by just being able to process more\ndata? We attempt to answer these questions in a general way for text processing\ntasks, considering the trade-offs involving training data size, learning time,\nand quality obtained. We propose a performance trade-off framework and apply it\nto three important text processing problems: Named Entity Recognition,\nSentiment Analysis and Document Classification. These problems were also chosen\nbecause they have different levels of object granularity: words, paragraphs,\nand documents. For each problem, we selected several supervised machine\nlearning algorithms and we evaluated the trade-offs of them on large publicly\navailable data sets (news, reviews, patents). To explore these trade-offs, we\nuse different data subsets of increasing size ranging from 50 MB to several GB.\nWe also consider the impact of the data set and the evaluation technique. We\nfind that the results do not change significantly and that most of the time the\nbest algorithms is the fastest. However, we also show that the results for\nsmall data (say less than 100 MB) are different from the results for big data\nand in those cases the best algorithm is much harder to determine.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 05:43:34 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Baeza-Yates", "Ricardo", ""], ["Liaghat", "Zeinab", ""]]}, {"id": "1711.02305", "submitter": "Kai Sheng Tai", "authors": "Kai Sheng Tai, Vatsal Sharan, Peter Bailis, Gregory Valiant", "title": "Sketching Linear Classifiers over Data Streams", "comments": "Full version of paper appearing at SIGMOD 2018 with more detailed\n  proofs of theoretical results. Code available at\n  https://github.com/stanford-futuredata/wmsketch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new sub-linear space sketch---the Weight-Median Sketch---for\nlearning compressed linear classifiers over data streams while supporting the\nefficient recovery of large-magnitude weights in the model. This enables\nmemory-limited execution of several statistical analyses over streams,\nincluding online feature selection, streaming data explanation, relative\ndeltoid detection, and streaming estimation of pointwise mutual information.\nUnlike related sketches that capture the most frequently-occurring features (or\nitems) in a data stream, the Weight-Median Sketch captures the features that\nare most discriminative of one stream (or class) compared to another. The\nWeight-Median Sketch adopts the core data structure used in the Count-Sketch,\nbut, instead of sketching counts, it captures sketched gradient updates to the\nmodel parameters. We provide a theoretical analysis that establishes recovery\nguarantees for batch and online learning, and demonstrate empirical\nimprovements in memory-accuracy trade-offs over alternative memory-budgeted\nmethods, including count-based sketches and feature hashing.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 06:37:27 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 18:08:41 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Tai", "Kai Sheng", ""], ["Sharan", "Vatsal", ""], ["Bailis", "Peter", ""], ["Valiant", "Gregory", ""]]}, {"id": "1711.02309", "submitter": "Vatsal Sharan", "authors": "Vatsal Sharan, Sham Kakade, Percy Liang, Gregory Valiant", "title": "Learning Overcomplete HMMs", "comments": "Added acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning overcomplete HMMs---those that have many\nhidden states but a small output alphabet. Despite having significant practical\nimportance, such HMMs are poorly understood with no known positive or negative\nresults for efficient learning. In this paper, we present several new\nresults---both positive and negative---which help define the boundaries between\nthe tractable and intractable settings. Specifically, we show positive results\nfor a large subclass of HMMs whose transition matrices are sparse,\nwell-conditioned, and have small probability mass on short cycles. On the other\nhand, we show that learning is impossible given only a polynomial number of\nsamples for HMMs with a small output alphabet and whose transition matrices are\nrandom regular graphs with large degree. We also discuss these results in the\ncontext of learning HMMs which can capture long-term dependencies.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 06:55:03 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2018 01:49:33 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Sharan", "Vatsal", ""], ["Kakade", "Sham", ""], ["Liang", "Percy", ""], ["Valiant", "Gregory", ""]]}, {"id": "1711.02316", "submitter": "Seongchan Kim", "authors": "Seongchan Kim, Seungkyun Hong, Minsu Joh, Sa-kwang Song", "title": "DeepRain: ConvLSTM Network for Precipitation Prediction using\n  Multichannel Radar Data", "comments": "Climate Informatics Workshop 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate rainfall forecasting is critical because it has a great impact on\npeople's social and economic activities. Recent trends on various literatures\nshow that Deep Learning (Neural Network) is a promising methodology to tackle\nmany challenging tasks. In this study, we introduce a brand-new data-driven\nprecipitation prediction model called DeepRain. This model predicts the amount\nof rainfall from weather radar data, which is three-dimensional and\nfour-channel data, using convolutional LSTM (ConvLSTM). ConvLSTM is a variant\nof LSTM (Long Short-Term Memory) containing a convolution operation inside the\nLSTM cell. For the experiment, we used radar reflectivity data for a two-year\nperiod whose input is in a time series format in units of 6 min divided into 15\nrecords. The output is the predicted rainfall information for the input data.\nExperimental results show that two-stacked ConvLSTM reduced RMSE by 23.0%\ncompared to linear regression.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 07:08:54 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Kim", "Seongchan", ""], ["Hong", "Seungkyun", ""], ["Joh", "Minsu", ""], ["Song", "Sa-kwang", ""]]}, {"id": "1711.02317", "submitter": "Lilian Besson", "authors": "Lilian Besson (IETR, SEQUEL), Emilie Kaufmann (CRIStAL, SEQUEL)", "title": "Multi-Player Bandits Revisited", "comments": null, "journal-ref": "Algorithmic Learning Theory, Apr 2018, Lanzarote, Spain. 2018,\n  http://www.cs.cornell.edu/conferences/alt2018/", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-player Multi-Armed Bandits (MAB) have been extensively studied in the\nliterature, motivated by applications to Cognitive Radio systems. Driven by\nsuch applications as well, we motivate the introduction of several levels of\nfeedback for multi-player MAB algorithms. Most existing work assume that\nsensing information is available to the algorithm. Under this assumption, we\nimprove the state-of-the-art lower bound for the regret of any decentralized\nalgorithms and introduce two algorithms, RandTopM and MCTopM, that are shown to\nempirically outperform existing algorithms. Moreover, we provide strong\ntheoretical guarantees for these algorithms, including a notion of asymptotic\noptimality in terms of the number of selections of bad arms. We then introduce\na promising heuristic, called Selfish, that can operate without sensing\ninformation, which is crucial for emerging applications to Internet of Things\nnetworks. We investigate the empirical performance of this algorithm and\nprovide some first theoretical elements for the understanding of its behavior.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 07:10:47 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 14:41:15 GMT"}, {"version": "v3", "created": "Tue, 13 Mar 2018 07:30:42 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Besson", "Lilian", "", "IETR, SEQUEL"], ["Kaufmann", "Emilie", "", "CRIStAL, SEQUEL"]]}, {"id": "1711.02326", "submitter": "Nan Rosemary Ke", "authors": "Nan Rosemary Ke, Anirudh Goyal, Olexa Bilaniuk, Jonathan Binas,\n  Laurent Charlin, Chris Pal, Yoshua Bengio", "title": "Sparse Attentive Backtracking: Long-Range Credit Assignment in Recurrent\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major drawback of backpropagation through time (BPTT) is the difficulty of\nlearning long-term dependencies, coming from having to propagate credit\ninformation backwards through every single step of the forward computation.\nThis makes BPTT both computationally impractical and biologically implausible.\nFor this reason, full backpropagation through time is rarely used on long\nsequences, and truncated backpropagation through time is used as a heuristic.\nHowever, this usually leads to biased estimates of the gradient in which longer\nterm dependencies are ignored. Addressing this issue, we propose an alternative\nalgorithm, Sparse Attentive Backtracking, which might also be related to\nprinciples used by brains to learn long-term dependencies. Sparse Attentive\nBacktracking learns an attention mechanism over the hidden states of the past\nand selectively backpropagates through paths with high attention weights. This\nallows the model to learn long term dependencies while only backtracking for a\nsmall number of time steps, not just from the recent past but also from\nattended relevant past states.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 07:52:12 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Ke", "Nan Rosemary", ""], ["Goyal", "Anirudh", ""], ["Bilaniuk", "Olexa", ""], ["Binas", "Jonathan", ""], ["Charlin", "Laurent", ""], ["Pal", "Chris", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1711.02329", "submitter": "Reza Abbasi-Asl", "authors": "Reza Abbasi-Asl, Bin Yu", "title": "Interpreting Convolutional Neural Networks Through Compression", "comments": "Presented at NIPS 2017 Symposium on Interpretable Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) achieve state-of-the-art performance in\na wide variety of tasks in computer vision. However, interpreting CNNs still\nremains a challenge. This is mainly due to the large number of parameters in\nthese networks. Here, we investigate the role of compression and particularly\npruning filters in the interpretation of CNNs. We exploit our recently-proposed\ngreedy structural compression scheme that prunes filters in a trained CNN. In\nour compression, the filter importance index is defined as the classification\naccuracy reduction (CAR) of the network after pruning that filter. The filters\nare then iteratively pruned based on the CAR index. We demonstrate the\ninterpretability of CAR-compressed CNNs by showing that our algorithm prunes\nfilters with visually redundant pattern selectivity. Specifically, we show the\nimportance of shape-selective filters for object recognition, as opposed to\ncolor-selective filters. Out of top 20 CAR-pruned filters in AlexNet, 17 of\nthem in the first layer and 14 of them in the second layer are color-selective\nfilters. Finally, we introduce a variant of our CAR importance index that\nquantifies the importance of each image class to each CNN filter. We show that\nthe most and the least important class labels present a meaningful\ninterpretation of each filter that is consistent with the visualized pattern\nselectivity of that filter.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 08:10:52 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Abbasi-Asl", "Reza", ""], ["Yu", "Bin", ""]]}, {"id": "1711.02361", "submitter": "Kristiaan Pelckmans", "authors": "Kristiaan Pelckmans", "title": "FADO: A Deterministic Detection/Learning Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes and studies a detection technique for adversarial\nscenarios (dubbed deterministic detection). This technique provides an\nalternative detection methodology in case the usual stochastic methods are not\napplicable: this can be because the studied phenomenon does not follow a\nstochastic sampling scheme, samples are high-dimensional and subsequent\nmultiple-testing corrections render results overly conservative, sample sizes\nare too low for asymptotic results (as e.g. the central limit theorem) to kick\nin, or one cannot allow for the small probability of failure inherent to\nstochastic approaches. This paper instead designs a method based on insights\nfrom machine learning and online learning theory: this detection algorithm -\nnamed Online FAult Detection (FADO) - comes with theoretical guarantees of its\ndetection capabilities. A version of the margin is found to regulate the\ndetection performance of FADO. A precise expression is derived for bounding the\nperformance, and experimental results are presented assessing the influence of\ninvolved quantities. A case study of scene detection is used to illustrate the\napproach. The technology is closely related to the linear perceptron rule,\ninherits its computational attractiveness and flexibility towards various\nextensions.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 09:57:44 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Pelckmans", "Kristiaan", ""]]}, {"id": "1711.02368", "submitter": "Masato Asahara", "authors": "Masato Asahara and Ryohei Fujimaki", "title": "Distributed Bayesian Piecewise Sparse Linear Models", "comments": "Short version of this paper will be published in IEEE BigData 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of interpretability of machine learning models has been\nincreasing due to emerging enterprise predictive analytics, threat of data\nprivacy, accountability of artificial intelligence in society, and so on.\nPiecewise linear models have been actively studied to achieve both accuracy and\ninterpretability. They often produce competitive accuracy against\nstate-of-the-art non-linear methods. In addition, their representations (i.e.,\nrule-based segmentation plus sparse linear formula) are often preferred by\ndomain experts. A disadvantage of such models, however, is high computational\ncost for simultaneous determinations of the number of \"pieces\" and cardinality\nof each linear predictor, which has restricted their applicability to\nmiddle-scale data sets. This paper proposes a distributed factorized asymptotic\nBayesian (FAB) inference of learning piece-wise sparse linear models on\ndistributed memory architectures. The distributed FAB inference solves the\nsimultaneous model selection issue without communicating $O(N)$ data where N is\nthe number of training samples and achieves linear scale-out against the number\nof CPU cores. Experimental results demonstrate that the distributed FAB\ninference achieves high prediction accuracy and performance scalability with\nboth synthetic and benchmark data.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 10:05:31 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Asahara", "Masato", ""], ["Fujimaki", "Ryohei", ""]]}, {"id": "1711.02391", "submitter": "Viivi Uurtio MSc", "authors": "Viivi Uurtio, Jo\\~ao M. Monteiro, Jaz Kandola, John Shawe-Taylor,\n  Delmiro Fernandez-Reyes, and Juho Rousu", "title": "A Tutorial on Canonical Correlation Methods", "comments": "33 pages", "journal-ref": "ACM Computing Surveys, Vol. 50, No. 6, Article 95. Publication\n  date: October 2017", "doi": "10.1145/3136624", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical correlation analysis is a family of multivariate statistical\nmethods for the analysis of paired sets of variables. Since its proposition,\ncanonical correlation analysis has for instance been extended to extract\nrelations between two sets of variables when the sample size is insufficient in\nrelation to the data dimensionality, when the relations have been considered to\nbe non-linear, and when the dimensionality is too large for human\ninterpretation. This tutorial explains the theory of canonical correlation\nanalysis including its regularised, kernel, and sparse variants. Additionally,\nthe deep and Bayesian CCA extensions are briefly reviewed. Together with the\nnumerical examples, this overview provides a coherent compendium on the\napplicability of the variants of canonical correlation analysis. By bringing\ntogether techniques for solving the optimisation problems, evaluating the\nstatistical significance and generalisability of the canonical correlation\nmodel, and interpreting the relations, we hope that this article can serve as a\nhands-on tool for applying canonical correlation methods in data analysis.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 11:01:00 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Uurtio", "Viivi", ""], ["Monteiro", "Jo\u00e3o M.", ""], ["Kandola", "Jaz", ""], ["Shawe-Taylor", "John", ""], ["Fernandez-Reyes", "Delmiro", ""], ["Rousu", "Juho", ""]]}, {"id": "1711.02413", "submitter": "Chaoyun Zhang", "authors": "Chaoyun Zhang, Xi Ouyang, Paul Patras", "title": "ZipNet-GAN: Inferring Fine-grained Mobile Traffic Patterns via a\n  Generative Adversarial Neural Network", "comments": "To appear ACM CoNEXT 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale mobile traffic analytics is becoming essential to digital\ninfrastructure provisioning, public transportation, events planning, and other\ndomains. Monitoring city-wide mobile traffic is however a complex and costly\nprocess that relies on dedicated probes. Some of these probes have limited\nprecision or coverage, others gather tens of gigabytes of logs daily, which\nindependently offer limited insights. Extracting fine-grained patterns involves\nexpensive spatial aggregation of measurements, storage, and post-processing. In\nthis paper, we propose a mobile traffic super-resolution technique that\novercomes these problems by inferring narrowly localised traffic consumption\nfrom coarse measurements. We draw inspiration from image processing and design\na deep-learning architecture tailored to mobile networking, which combines\nZipper Network (ZipNet) and Generative Adversarial neural Network (GAN) models.\nThis enables to uniquely capture spatio-temporal relations between traffic\nvolume snapshots routinely monitored over broad coverage areas\n(`low-resolution') and the corresponding consumption at 0.05 km $^2$ level\n(`high-resolution') usually obtained after intensive computation. Experiments\nwe conduct with a real-world data set demonstrate that the proposed\nZipNet(-GAN) infers traffic consumption with remarkable accuracy and up to\n100$\\times$ higher granularity as compared to standard probing, while\noutperforming existing data interpolation techniques. To our knowledge, this is\nthe first time super-resolution concepts are applied to large-scale mobile\ntraffic analysis and our solution is the first to infer fine-grained urban\ntraffic patterns from coarse aggregates.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 11:38:11 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Zhang", "Chaoyun", ""], ["Ouyang", "Xi", ""], ["Patras", "Paul", ""]]}, {"id": "1711.02421", "submitter": "Amichai Painsky", "authors": "Amichai Painsky and Naftali Tishby", "title": "Gaussian Lower Bound for the Information Bottleneck Limit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Information Bottleneck (IB) is a conceptual method for extracting the\nmost compact, yet informative, representation of a set of variables, with\nrespect to the target. It generalizes the notion of minimal sufficient\nstatistics from classical parametric statistics to a broader\ninformation-theoretic sense. The IB curve defines the optimal trade-off between\nrepresentation complexity and its predictive power. Specifically, it is\nachieved by minimizing the level of mutual information (MI) between the\nrepresentation and the original variables, subject to a minimal level of MI\nbetween the representation and the target. This problem is shown to be in\ngeneral NP hard. One important exception is the multivariate Gaussian case, for\nwhich the Gaussian IB (GIB) is known to obtain an analytical closed form\nsolution, similar to Canonical Correlation Analysis (CCA). In this work we\nintroduce a Gaussian lower bound to the IB curve; we find an embedding of the\ndata which maximizes its \"Gaussian part\", on which we apply the GIB. This\nembedding provides an efficient (and practical) representation of any arbitrary\ndata-set (in the IB sense), which in addition holds the favorable properties of\na Gaussian distribution. Importantly, we show that the optimal Gaussian\nembedding is bounded from above by non-linear CCA. This allows a fundamental\nlimit for our ability to Gaussianize arbitrary data-sets and solve complex\nproblems by linear methods.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 11:58:37 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Painsky", "Amichai", ""], ["Tishby", "Naftali", ""]]}, {"id": "1711.02478", "submitter": "Shin Matsushima", "authors": "Taito Lee, Shin Matsushima, Kenji Yamanishi", "title": "Grafting for Combinatorial Boolean Model using Frequent Itemset Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the combinatorial Boolean model (CBM), which is defined\nas the class of linear combinations of conjunctions of Boolean attributes. This\npaper addresses the issue of learning CBM from labeled data. CBM is of high\nknowledge interpretability but na\\\"{i}ve learning of it requires exponentially\nlarge computation time with respect to data dimension and sample size. To\novercome this computational difficulty, we propose an algorithm GRAB (GRAfting\nfor Boolean datasets), which efficiently learns CBM within the\n$L_1$-regularized loss minimization framework. The key idea of GRAB is to\nreduce the loss minimization problem to the weighted frequent itemset mining,\nin which frequent patterns are efficiently computable. We employ benchmark\ndatasets to empirically demonstrate that GRAB is effective in terms of\ncomputational efficiency, prediction accuracy and knowledge discovery.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 14:21:36 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 11:03:30 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Lee", "Taito", ""], ["Matsushima", "Shin", ""], ["Yamanishi", "Kenji", ""]]}, {"id": "1711.02487", "submitter": "Stavros Theodorakis PhD", "authors": "Yoel Zeldes, Stavros Theodorakis, Efrat Solodnik, Aviv Rotman, Gil\n  Chamiel and Dan Friedman", "title": "Deep density networks and uncertainty in recommender systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building robust online content recommendation systems requires learning\ncomplex interactions between user preferences and content features. The field\nhas evolved rapidly in recent years from traditional multi-arm bandit and\ncollaborative filtering techniques, with new methods employing Deep Learning\nmodels to capture non-linearities. Despite progress, the dynamic nature of\nonline recommendations still poses great challenges, such as finding the\ndelicate balance between exploration and exploitation. In this paper we show\nhow uncertainty estimations can be incorporated by employing them in an\noptimistic exploitation/exploration strategy for more efficient exploration of\nnew recommendations. We provide a novel hybrid deep neural network model, Deep\nDensity Networks (DDN), which integrates content-based deep learning models\nwith a collaborative scheme that is able to robustly model and estimate\nuncertainty. Finally, we present online and offline results after incorporating\nDNN into a real world content recommendation system that serves billions of\nrecommendations per day, and show the benefit of using DDN in practice.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 14:30:04 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 22:44:10 GMT"}, {"version": "v3", "created": "Sun, 6 May 2018 19:47:10 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Zeldes", "Yoel", ""], ["Theodorakis", "Stavros", ""], ["Solodnik", "Efrat", ""], ["Rotman", "Aviv", ""], ["Chamiel", "Gil", ""], ["Friedman", "Dan", ""]]}, {"id": "1711.02510", "submitter": "Juan Quiroz", "authors": "Juan C. Quiroz, Norman Mariun, Mohammad Rezazadeh Mehrjou, Mahdi\n  Izadi, Norhisam Misron, Mohd Amran Mohd Radzi", "title": "Fault Detection of Broken Rotor Bar in LS-PMSM Using Random Forests", "comments": "Elsevier Measurement", "journal-ref": null, "doi": "10.1016/j.measurement.2017.11.004", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper proposes a new approach to diagnose broken rotor bar failure in a\nline start-permanent magnet synchronous motor (LS-PMSM) using random forests.\nThe transient current signal during the motor startup was acquired from a\nhealthy motor and a faulty motor with a broken rotor bar fault. We extracted 13\nstatistical time domain features from the startup transient current signal, and\nused these features to train and test a random forest to determine whether the\nmotor was operating under normal or faulty conditions. For feature selection,\nwe used the feature importances from the random forest to reduce the number of\nfeatures to two features. The results showed that the random forest classifies\nthe motor condition as healthy or faulty with an accuracy of 98.8% using all\nfeatures and with an accuracy of 98.4% by using only the mean-index and\nimpulsion features. The performance of the random forest was compared with a\ndecision tree, Na\\\"ive Bayes classifier, logistic regression, linear ridge, and\na support vector machine, with the random forest consistently having a higher\naccuracy than the other algorithms. The proposed approach can be used in\nindustry for online monitoring and fault diagnostic of LS-PMSM motors and the\nresults can be helpful for the establishment of preventive maintenance plans in\nfactories.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 19:18:26 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Quiroz", "Juan C.", ""], ["Mariun", "Norman", ""], ["Mehrjou", "Mohammad Rezazadeh", ""], ["Izadi", "Mahdi", ""], ["Misron", "Norhisam", ""], ["Radzi", "Mohd Amran Mohd", ""]]}, {"id": "1711.02515", "submitter": "Yatao A. Bian", "authors": "An Bian, Kfir Y. Levy, Andreas Krause, Joachim M. Buhmann", "title": "Continuous DR-submodular Maximization: Structure and Algorithms", "comments": "Published in NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DR-submodular continuous functions are important objectives with wide\nreal-world applications spanning MAP inference in determinantal point processes\n(DPPs), and mean-field inference for probabilistic submodular models, amongst\nothers. DR-submodularity captures a subclass of non-convex functions that\nenables both exact minimization and approximate maximization in polynomial\ntime.\n  In this work we study the problem of maximizing non-monotone DR-submodular\ncontinuous functions under general down-closed convex constraints. We start by\ninvestigating geometric properties that underlie such objectives, e.g., a\nstrong relation between (approximately) stationary points and global optimum is\nproved. These properties are then used to devise two optimization algorithms\nwith provable guarantees. Concretely, we first devise a \"two-phase\" algorithm\nwith $1/4$ approximation guarantee. This algorithm allows the use of existing\nmethods for finding (approximately) stationary points as a subroutine, thus,\nharnessing recent progress in non-convex optimization. Then we present a\nnon-monotone Frank-Wolfe variant with $1/e$ approximation guarantee and\nsublinear convergence rate. Finally, we extend our approach to a broader class\nof generalized DR-submodular continuous functions, which captures a wider\nspectrum of applications. Our theoretical findings are validated on synthetic\nand real-world problem instances.\n", "versions": [{"version": "v1", "created": "Sat, 4 Nov 2017 01:07:56 GMT"}, {"version": "v2", "created": "Fri, 24 Nov 2017 20:38:16 GMT"}, {"version": "v3", "created": "Sat, 16 Dec 2017 18:39:02 GMT"}, {"version": "v4", "created": "Fri, 24 May 2019 16:14:41 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Bian", "An", ""], ["Levy", "Kfir Y.", ""], ["Krause", "Andreas", ""], ["Buhmann", "Joachim M.", ""]]}, {"id": "1711.02545", "submitter": "Kwang-Sung Jun", "authors": "Kwang-Sung Jun, Francesco Orabona, Stephen Wright, Rebecca Willett", "title": "Online Learning for Changing Environments using Coin Betting", "comments": "submitted to a journal. arXiv admin note: substantial text overlap\n  with arXiv:1610.04578", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge in online learning is that classical algorithms can be slow\nto adapt to changing environments. Recent studies have proposed \"meta\"\nalgorithms that convert any online learning algorithm to one that is adaptive\nto changing environments, where the adaptivity is analyzed in a quantity called\nthe strongly-adaptive regret. This paper describes a new meta algorithm that\nhas a strongly-adaptive regret bound that is a factor of $\\sqrt{\\log(T)}$\nbetter than other algorithms with the same time complexity, where $T$ is the\ntime horizon. We also extend our algorithm to achieve a first-order (i.e.,\ndependent on the observed losses) strongly-adaptive regret bound for the first\ntime, to our knowledge. At its heart is a new parameter-free algorithm for the\nlearning with expert advice (LEA) problem in which experts sometimes do not\noutput advice for consecutive time steps (i.e., \\emph{sleeping} experts). This\nalgorithm is derived by a reduction from optimal algorithms for the so-called\ncoin betting problem. Empirical results show that our algorithm outperforms\nstate-of-the-art methods in both learning with expert advice and metric\nlearning scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 07:02:53 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Jun", "Kwang-Sung", ""], ["Orabona", "Francesco", ""], ["Wright", "Stephen", ""], ["Willett", "Rebecca", ""]]}, {"id": "1711.02604", "submitter": "Edouard Grave", "authors": "Edouard Grave, Moustapha Cisse, Armand Joulin", "title": "Unbounded cache model for online language modeling with open vocabulary", "comments": "Accepted to NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, continuous cache models were proposed as extensions to recurrent\nneural network language models, to adapt their predictions to local changes in\nthe data distribution. These models only capture the local context, of up to a\nfew thousands tokens. In this paper, we propose an extension of continuous\ncache models, which can scale to larger contexts. In particular, we use a large\nscale non-parametric memory component that stores all the hidden activations\nseen in the past. We leverage recent advances in approximate nearest neighbor\nsearch and quantization algorithms to store millions of representations while\nsearching them efficiently. We conduct extensive experiments showing that our\napproach significantly improves the perplexity of pre-trained language models\non new distributions, and can scale efficiently to much larger contexts than\npreviously proposed local cache models.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 16:51:52 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Grave", "Edouard", ""], ["Cisse", "Moustapha", ""], ["Joulin", "Armand", ""]]}, {"id": "1711.02613", "submitter": "Elliot J. Crowley", "authors": "Elliot J. Crowley, Gavin Gray, Amos Storkey", "title": "Moonshine: Distilling with Cheap Convolutions", "comments": "32nd Conference on Neural Information Processing Systems (NeurIPS\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many engineers wish to deploy modern neural networks in memory-limited\nsettings; but the development of flexible methods for reducing memory use is in\nits infancy, and there is little knowledge of the resulting cost-benefit. We\npropose structural model distillation for memory reduction using a strategy\nthat produces a student architecture that is a simple transformation of the\nteacher architecture: no redesign is needed, and the same hyperparameters can\nbe used. Using attention transfer, we provide Pareto curves/tables for\ndistillation of residual networks with four benchmark datasets, indicating the\nmemory versus accuracy payoff. We show that substantial memory savings are\npossible with very little loss of accuracy, and confirm that distillation\nprovides student network performance that is better than training that student\narchitecture directly on data.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 17:21:06 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 11:43:02 GMT"}, {"version": "v3", "created": "Mon, 22 Oct 2018 16:47:40 GMT"}, {"version": "v4", "created": "Thu, 17 Jan 2019 12:26:19 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Crowley", "Elliot J.", ""], ["Gray", "Gavin", ""], ["Storkey", "Amos", ""]]}, {"id": "1711.02621", "submitter": "Oren Mangoubi", "authors": "Oren Mangoubi, Nisheeth K. Vishnoi", "title": "Convex Optimization with Unbounded Nonconvex Oracles using Simulated\n  Annealing", "comments": "To appear in COLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of minimizing a convex objective function $F$ when\none can only evaluate its noisy approximation $\\hat{F}$. Unless one assumes\nsome structure on the noise, $\\hat{F}$ may be an arbitrary nonconvex function,\nmaking the task of minimizing $F$ intractable. To overcome this, prior work has\noften focused on the case when $F(x)-\\hat{F}(x)$ is uniformly-bounded. In this\npaper we study the more general case when the noise has magnitude $\\alpha F(x)\n+ \\beta$ for some $\\alpha, \\beta > 0$, and present a polynomial time algorithm\nthat finds an approximate minimizer of $F$ for this noise model. Previously,\nMarkov chains, such as the stochastic gradient Langevin dynamics, have been\nused to arrive at approximate solutions to these optimization problems.\nHowever, for the noise model considered in this paper, no single temperature\nallows such a Markov chain to both mix quickly and concentrate near the global\nminimizer. We bypass this by combining \"simulated annealing\" with the\nstochastic gradient Langevin dynamics, and gradually decreasing the temperature\nof the chain in order to approach the global minimizer. As a corollary one can\napproximately minimize a nonconvex function that is close to a convex function;\nhowever, the closeness can deteriorate as one moves away from the optimum.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 17:36:47 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 09:00:43 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Mangoubi", "Oren", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1711.02637", "submitter": "Sebastian U. Stich", "authors": "Sebastian U. Stich, Anant Raj, Martin Jaggi", "title": "Safe Adaptive Importance Sampling", "comments": "To appear at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Importance sampling has become an indispensable strategy to speed up\noptimization algorithms for large-scale applications. Improved adaptive\nvariants - using importance values defined by the complete gradient information\nwhich changes during optimization - enjoy favorable theoretical properties, but\nare typically computationally infeasible. In this paper we propose an efficient\napproximation of gradient-based sampling, which is based on safe bounds on the\ngradient. The proposed sampling distribution is (i) provably the best sampling\nwith respect to the given bounds, (ii) always better than uniform sampling and\nfixed importance sampling and (iii) can efficiently be computed - in many\napplications at negligible extra cost. The proposed sampling scheme is generic\nand can easily be integrated into existing algorithms. In particular, we show\nthat coordinate-descent (CD) and stochastic gradient descent (SGD) can enjoy\nsignificant a speed-up under the novel scheme. The proven efficiency of the\nproposed sampling is verified by extensive numerical testing.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 17:56:57 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Stich", "Sebastian U.", ""], ["Raj", "Anant", ""], ["Jaggi", "Martin", ""]]}, {"id": "1711.02651", "submitter": "Andrej Risteski", "authors": "Sanjeev Arora, Andrej Risteski, Yi Zhang", "title": "Theoretical limitations of Encoder-Decoder GAN architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encoder-decoder GANs architectures (e.g., BiGAN and ALI) seek to add an\ninference mechanism to the GANs setup, consisting of a small encoder deep net\nthat maps data-points to their succinct encodings. The intuition is that being\nforced to train an encoder alongside the usual generator forces the system to\nlearn meaningful mappings from the code to the data-point and vice-versa, which\nshould improve the learning of the target distribution and ameliorate\nmode-collapse. It should also yield meaningful codes that are useful as\nfeatures for downstream tasks. The current paper shows rigorously that even on\nreal-life distributions of images, the encode-decoder GAN training objectives\n(a) cannot prevent mode collapse; i.e. the objective can be near-optimal even\nwhen the generated distribution has low and finite support (b) cannot prevent\nlearning meaningless codes for data -- essentially white noise. Thus if\nencoder-decoder GANs do indeed work then it must be due to reasons as yet not\nunderstood, since the training objective can be low even for meaningless\nsolutions.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 18:30:24 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Arora", "Sanjeev", ""], ["Risteski", "Andrej", ""], ["Zhang", "Yi", ""]]}, {"id": "1711.02653", "submitter": "David Klindt", "authors": "David A. Klindt, Alexander S. Ecker, Thomas Euler, Matthias Bethge", "title": "Neural system identification for large populations separating \"what\" and\n  \"where\"", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroscientists classify neurons into different types that perform similar\ncomputations at different locations in the visual field. Traditional methods\nfor neural system identification do not capitalize on this separation of 'what'\nand 'where'. Learning deep convolutional feature spaces that are shared among\nmany neurons provides an exciting path forward, but the architectural design\nneeds to account for data limitations: While new experimental techniques enable\nrecordings from thousands of neurons, experimental time is limited so that one\ncan sample only a small fraction of each neuron's response space. Here, we show\nthat a major bottleneck for fitting convolutional neural networks (CNNs) to\nneural data is the estimation of the individual receptive field locations, a\nproblem that has been scratched only at the surface thus far. We propose a CNN\narchitecture with a sparse readout layer factorizing the spatial (where) and\nfeature (what) dimensions. Our network scales well to thousands of neurons and\nshort recordings and can be trained end-to-end. We evaluate this architecture\non ground-truth data to explore the challenges and limitations of CNN-based\nsystem identification. Moreover, we show that our network model outperforms\ncurrent state-of-the art system identification models of mouse primary visual\ncortex.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 18:33:02 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 12:56:18 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Klindt", "David A.", ""], ["Ecker", "Alexander S.", ""], ["Euler", "Thomas", ""], ["Bethge", "Matthias", ""]]}, {"id": "1711.02666", "submitter": "Xiao-Yang Liu", "authors": "Chenxiao Zhu, Lingqing Xu, Xiao-Yang Liu, Feng Qian", "title": "Tensor-Generative Adversarial Network with Two-dimensional Sparse\n  Coding: Application to Real-time Indoor Localization", "comments": "6 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Localization technology is important for the development of indoor\nlocation-based services (LBS). Global Positioning System (GPS) becomes invalid\nin indoor environments due to the non-line-of-sight issue, so it is urgent to\ndevelop a real-time high-accuracy localization approach for smartphones.\nHowever, accurate localization is challenging due to issues such as real-time\nresponse requirements, limited fingerprint samples and mobile device storage.\nTo address these problems, we propose a novel deep learning architecture:\nTensor-Generative Adversarial Network (TGAN).\n  We first introduce a transform-based 3D tensor to model fingerprint samples.\nInstead of those passive methods that construct a fingerprint database as a\nprior, our model applies artificial neural network with deep learning to train\nnetwork classifiers and then gives out estimations. Then we propose a novel\ntensor-based super-resolution scheme using the generative adversarial network\n(GAN) that adopts sparse coding as the generator network and a residual\nlearning network as the discriminator. Further, we analyze the performance of\ntensor-GAN and implement a trace-based localization experiment, which achieves\nbetter performance. Compared to existing methods for smartphones indoor\npositioning, that are energy-consuming and high demands on devices, TGAN can\ngive out an improved solution in localization accuracy, response time and\nimplementation complexity.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 17:10:28 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Zhu", "Chenxiao", ""], ["Xu", "Lingqing", ""], ["Liu", "Xiao-Yang", ""], ["Qian", "Feng", ""]]}, {"id": "1711.02679", "submitter": "Volodymyr Kuleshov", "authors": "Volodymyr Kuleshov, Stefano Ermon", "title": "Neural Variational Inference and Learning in Undirected Graphical Models", "comments": "Appearing in Proceedings of the 31st Conference on Neural Information\n  Processing Systems (NIPS) 2017, Long Beach, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in machine learning are naturally expressed in the language of\nundirected graphical models. Here, we propose black-box learning and inference\nalgorithms for undirected models that optimize a variational approximation to\nthe log-likelihood of the model. Central to our approach is an upper bound on\nthe log-partition function parametrized by a function q that we express as a\nflexible neural network. Our bound makes it possible to track the partition\nfunction during learning, to speed-up sampling, and to train a broad class of\nhybrid directed/undirected models via a unified variational inference\nframework. We empirically demonstrate the effectiveness of our method on\nseveral popular generative modeling datasets.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 19:00:20 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 21:33:11 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Kuleshov", "Volodymyr", ""], ["Ermon", "Stefano", ""]]}, {"id": "1711.02702", "submitter": "J. Nathan Kutz", "authors": "Thomas Baumeister and Steven L. Brunton and J. Nathan Kutz", "title": "Deep Learning and Model Predictive Control for Self-Tuning Mode-Locked\n  Lasers", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": "10.1364/JOSAB.35.000617", "report-no": null, "categories": "cs.LG nlin.PS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-tuning optical systems are of growing importance in technological\napplications such as mode-locked fiber lasers. Such self-tuning paradigms\nrequire {\\em intelligent} algorithms capable of inferring approximate models of\nthe underlying physics and discovering appropriate control laws in order to\nmaintain robust performance for a given objective. In this work, we demonstrate\nthe first integration of a {\\em deep learning} (DL) architecture with {\\em\nmodel predictive control} (MPC) in order to self-tune a mode-locked fiber\nlaser. Not only can our DL-MPC algorithmic architecture approximate the unknown\nfiber birefringence, it also builds a dynamical model of the laser and\nappropriate control law for maintaining robust, high-energy pulses despite a\nstochastically drifting birefringence. We demonstrate the effectiveness of this\nmethod on a fiber laser which is mode-locked by nonlinear polarization\nrotation. The method advocated can be broadly applied to a variety of optical\nsystems that require robust controllers.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 20:25:40 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Baumeister", "Thomas", ""], ["Brunton", "Steven L.", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "1711.02741", "submitter": "Kuan Fang", "authors": "Kuan Fang, Yu Xiang, Xiaocheng Li, Silvio Savarese", "title": "Recurrent Autoregressive Networks for Online Multi-Object Tracking", "comments": "10 pages, 3 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main challenge of online multi-object tracking is to reliably associate\nobject trajectories with detections in each video frame based on their tracking\nhistory. In this work, we propose the Recurrent Autoregressive Network (RAN), a\ntemporal generative modeling framework to characterize the appearance and\nmotion dynamics of multiple objects over time. The RAN couples an external\nmemory and an internal memory. The external memory explicitly stores previous\ninputs of each trajectory in a time window, while the internal memory learns to\nsummarize long-term tracking history and associate detections by processing the\nexternal memory. We conduct experiments on the MOT 2015 and 2016 datasets to\ndemonstrate the robustness of our tracking method in highly crowded and\noccluded scenes. Our method achieves top-ranked results on the two benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 21:51:22 GMT"}, {"version": "v2", "created": "Sun, 4 Mar 2018 04:21:03 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Fang", "Kuan", ""], ["Xiang", "Yu", ""], ["Li", "Xiaocheng", ""], ["Savarese", "Silvio", ""]]}, {"id": "1711.02771", "submitter": "Pengchuan Zhang", "authors": "Pengchuan Zhang, Qiang Liu, Dengyong Zhou, Tao Xu, Xiaodong He", "title": "On the Discrimination-Generalization Tradeoff in GANs", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial training can be generally understood as minimizing\ncertain moment matching loss defined by a set of discriminator functions,\ntypically neural networks. The discriminator set should be large enough to be\nable to uniquely identify the true distribution (discriminative), and also be\nsmall enough to go beyond memorizing samples (generalizable). In this paper, we\nshow that a discriminator set is guaranteed to be discriminative whenever its\nlinear span is dense in the set of bounded continuous functions. This is a very\nmild condition satisfied even by neural networks with a single neuron. Further,\nwe develop generalization bounds between the learned distribution and true\ndistribution under different evaluation metrics. When evaluated with neural\ndistance, our bounds show that generalization is guaranteed as long as the\ndiscriminator set is small enough, regardless of the size of the generator or\nhypothesis set. When evaluated with KL divergence, our bound provides an\nexplanation on the counter-intuitive behaviors of testing likelihood in GAN\ntraining. Our analysis sheds lights on understanding the practical performance\nof GANs.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 23:45:20 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 20:25:46 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Zhang", "Pengchuan", ""], ["Liu", "Qiang", ""], ["Zhou", "Dengyong", ""], ["Xu", "Tao", ""], ["He", "Xiaodong", ""]]}, {"id": "1711.02782", "submitter": "Sharan Narang", "authors": "Sharan Narang, Eric Undersander, Gregory Diamos", "title": "Block-Sparse Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are used in state-of-the-art models in\ndomains such as speech recognition, machine translation, and language\nmodelling. Sparsity is a technique to reduce compute and memory requirements of\ndeep learning models. Sparse RNNs are easier to deploy on devices and high-end\nserver processors. Even though sparse operations need less compute and memory\nrelative to their dense counterparts, the speed-up observed by using sparse\noperations is less than expected on different hardware platforms. In order to\naddress this issue, we investigate two different approaches to induce block\nsparsity in RNNs: pruning blocks of weights in a layer and using group lasso\nregularization to create blocks of weights with zeros. Using these techniques,\nwe demonstrate that we can create block-sparse RNNs with sparsity ranging from\n80% to 90% with small loss in accuracy. This allows us to reduce the model size\nby roughly 10x. Additionally, we can prune a larger dense network to recover\nthis loss in accuracy while maintaining high block sparsity and reducing the\noverall parameter count. Our technique works with a variety of block sizes up\nto 32x32. Block-sparse RNNs eliminate overheads related to data storage and\nirregular memory accesses while increasing hardware efficiency compared to\nunstructured sparsity.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 00:57:54 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Narang", "Sharan", ""], ["Undersander", "Eric", ""], ["Diamos", "Gregory", ""]]}, {"id": "1711.02783", "submitter": "Chris Paxton", "authors": "Chris Paxton, Kapil Katyal, Christian Rupprecht, Raman Arora, Gregory\n  D. Hager", "title": "Learning to Imagine Manipulation Goals for Robot Task Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prospection is an important part of how humans come up with new task plans,\nbut has not been explored in depth in robotics. Predicting multiple task-level\nis a challenging problem that involves capturing both task semantics and\ncontinuous variability over the state of the world. Ideally, we would combine\nthe ability of machine learning to leverage big data for learning the semantics\nof a task, while using techniques from task planning to reliably generalize to\nnew environment. In this work, we propose a method for learning a model\nencoding just such a representation for task planning. We learn a neural net\nthat encodes the $k$ most likely outcomes from high level actions from a given\nworld. Our approach creates comprehensible task plans that allow us to predict\nchanges to the environment many time steps into the future. We demonstrate this\napproach via application to a stacking task in a cluttered environment, where\nthe robot must select between different colored blocks while avoiding\nobstacles, in order to perform a task. We also show results on a simple\nnavigation task. Our algorithm generates realistic image and pose predictions\nat multiple points in a given task.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 01:10:01 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 21:29:37 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Paxton", "Chris", ""], ["Katyal", "Kapil", ""], ["Rupprecht", "Christian", ""], ["Arora", "Raman", ""], ["Hager", "Gregory D.", ""]]}, {"id": "1711.02792", "submitter": "Zi-Yi Dou", "authors": "Zi-Yi Dou", "title": "Metric Learning-based Generative Adversarial Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs), as a framework for estimating\ngenerative models via an adversarial process, have attracted huge attention and\nhave proven to be powerful in a variety of tasks. However, training GANs is\nwell known for being delicate and unstable, partially caused by its sig- moid\ncross entropy loss function for the discriminator. To overcome such a problem,\nmany researchers directed their attention on various ways to measure how close\nthe model distribution and real distribution are and have applied dif- ferent\nmetrics as their objective functions. In this paper, we propose a novel\nframework to train GANs based on distance metric learning and we call it Metric\nLearning-based Gener- ative Adversarial Network (MLGAN). The discriminator of\nMLGANs can dynamically learn an appropriate metric, rather than a static one,\nto measure the distance between generated samples and real samples. Afterwards,\nMLGANs update the generator under the newly learned metric. We evaluate our ap-\nproach on several representative datasets and the experimen- tal results\ndemonstrate that MLGANs can achieve superior performance compared with several\nexisting state-of-the-art approaches. We also empirically show that MLGANs\ncould increase the stability of training GANs.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 01:25:37 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Dou", "Zi-Yi", ""]]}, {"id": "1711.02795", "submitter": "Ayaka Sakata", "authors": "Ayaka Sakata and Yingying Xu", "title": "Approximate message passing for nonconvex sparse regularization with\n  stability and asymptotic analysis", "comments": null, "journal-ref": null, "doi": "10.1088/1742-5468/aab051", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse a linear regression problem with nonconvex regularization called\nsmoothly clipped absolute deviation (SCAD) under an overcomplete Gaussian basis\nfor Gaussian random data. We propose an approximate message passing (AMP)\nalgorithm considering nonconvex regularization, namely SCAD-AMP, and\nanalytically show that the stability condition corresponds to the de\nAlmeida--Thouless condition in spin glass literature. Through asymptotic\nanalysis, we show the correspondence between the density evolution of SCAD-AMP\nand the replica symmetric solution. Numerical experiments confirm that for a\nsufficiently large system size, SCAD-AMP achieves the optimal performance\npredicted by the replica method. Through replica analysis, a phase transition\nbetween replica symmetric (RS) and replica symmetry breaking (RSB) region is\nfound in the parameter space of SCAD. The appearance of the RS region for a\nnonconvex penalty is a significant advantage that indicates the region of\nsmooth landscape of the optimization problem. Furthermore, we analytically show\nthat the statistical representation performance of the SCAD penalty is better\nthan that of L1-based methods, and the minimum representation error under RS\nassumption is obtained at the edge of the RS/RSB phase. The correspondence\nbetween the convergence of the existing coordinate descent algorithm and RS/RSB\ntransition is also indicated.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 01:36:55 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 11:10:04 GMT"}, {"version": "v3", "created": "Mon, 19 Feb 2018 01:43:55 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Sakata", "Ayaka", ""], ["Xu", "Yingying", ""]]}, {"id": "1711.02799", "submitter": "Mostafa Dehghani", "authors": "Mostafa Dehghani, Arash Mehrjou, Stephan Gouws, Jaap Kamps, Bernhard\n  Sch\\\"olkopf", "title": "Fidelity-Weighted Learning", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks requires many training samples, but in practice\ntraining labels are expensive to obtain and may be of varying quality, as some\nmay be from trusted expert labelers while others might be from heuristics or\nother sources of weak supervision such as crowd-sourcing. This creates a\nfundamental quality versus-quantity trade-off in the learning process. Do we\nlearn from the small amount of high-quality data or the potentially large\namount of weakly-labeled data? We argue that if the learner could somehow know\nand take the label-quality into account when learning the data representation,\nwe could get the best of both worlds. To this end, we propose\n\"fidelity-weighted learning\" (FWL), a semi-supervised student-teacher approach\nfor training deep neural networks using weakly-labeled data. FWL modulates the\nparameter updates to a student network (trained on the task we care about) on a\nper-sample basis according to the posterior confidence of its label-quality\nestimated by a teacher (who has access to the high-quality labels). Both\nstudent and teacher are learned from the data. We evaluate FWL on two tasks in\ninformation retrieval and natural language processing where we outperform\nstate-of-the-art alternative semi-supervised methods, indicating that our\napproach makes better use of strong and weak labels, and leads to better\ntask-dependent data representations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 02:05:11 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 14:27:21 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Dehghani", "Mostafa", ""], ["Mehrjou", "Arash", ""], ["Gouws", "Stephan", ""], ["Kamps", "Jaap", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1711.02810", "submitter": "Biswarup Bhattacharya", "authors": "Biswarup Bhattacharya, Abhishek Sinha", "title": "Deep Fault Analysis and Subset Selection in Solar Power Grids", "comments": "Presented at NIPS 2017 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-availability of reliable and sustainable electric power is a major\nproblem in the developing world. Renewable energy sources like solar are not\nvery lucrative in the current stage due to various uncertainties like weather,\nstorage, land use among others. There also exists various other issues like\nmis-commitment of power, absence of intelligent fault analysis, congestion,\netc. In this paper, we propose a novel deep learning-based system for\npredicting faults and selecting power generators optimally so as to reduce\ncosts and ensure higher reliability in solar power systems. The results are\nhighly encouraging and they suggest that the approaches proposed in this paper\nhave the potential to be applied successfully in the developing world.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 03:09:51 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Bhattacharya", "Biswarup", ""], ["Sinha", "Abhishek", ""]]}, {"id": "1711.02827", "submitter": "Dylan Hadfield-Menell", "authors": "Dylan Hadfield-Menell, Smitha Milli, Pieter Abbeel, Stuart Russell,\n  Anca Dragan", "title": "Inverse Reward Design", "comments": "Advances in Neural Information Processing Systems 30 (NIPS 2017)\n  Revised Oct 2020 to fix a typo in Eq. 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents optimize the reward function we give them. What they don't\nknow is how hard it is for us to design a reward function that actually\ncaptures what we want. When designing the reward, we might think of some\nspecific training scenarios, and make sure that the reward will lead to the\nright behavior in those scenarios. Inevitably, agents encounter new scenarios\n(e.g., new types of terrain) where optimizing that same reward may lead to\nundesired behavior. Our insight is that reward functions are merely\nobservations about what the designer actually wants, and that they should be\ninterpreted in the context in which they were designed. We introduce inverse\nreward design (IRD) as the problem of inferring the true objective based on the\ndesigned reward and the training MDP. We introduce approximate methods for\nsolving IRD problems, and use their solution to plan risk-averse behavior in\ntest MDPs. Empirical results suggest that this approach can help alleviate\nnegative side effects of misspecified reward functions and mitigate reward\nhacking.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 04:44:32 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 15:41:58 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Hadfield-Menell", "Dylan", ""], ["Milli", "Smitha", ""], ["Abbeel", "Pieter", ""], ["Russell", "Stuart", ""], ["Dragan", "Anca", ""]]}, {"id": "1711.02838", "submitter": "Nilesh Tripuraneni", "authors": "Nilesh Tripuraneni, Mitchell Stern, Chi Jin, Jeffrey Regier, Michael\n  I. Jordan", "title": "Stochastic Cubic Regularization for Fast Nonconvex Optimization", "comments": "The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a stochastic variant of a classic algorithm---the\ncubic-regularized Newton method [Nesterov and Polyak 2006]. The proposed\nalgorithm efficiently escapes saddle points and finds approximate local minima\nfor general smooth, nonconvex functions in only\n$\\mathcal{\\tilde{O}}(\\epsilon^{-3.5})$ stochastic gradient and stochastic\nHessian-vector product evaluations. The latter can be computed as efficiently\nas stochastic gradients. This improves upon the\n$\\mathcal{\\tilde{O}}(\\epsilon^{-4})$ rate of stochastic gradient descent. Our\nrate matches the best-known result for finding local minima without requiring\nany delicate acceleration or variance-reduction techniques.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 05:39:46 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 20:40:44 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Tripuraneni", "Nilesh", ""], ["Stern", "Mitchell", ""], ["Jin", "Chi", ""], ["Regier", "Jeffrey", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1711.02846", "submitter": "Ekin Dogus Cubuk", "authors": "Ekin D. Cubuk, Barret Zoph, Samuel S. Schoenholz, Quoc V. Le", "title": "Intriguing Properties of Adversarial Examples", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is becoming increasingly clear that many machine learning classifiers are\nvulnerable to adversarial examples. In attempting to explain the origin of\nadversarial examples, previous studies have typically focused on the fact that\nneural networks operate on high dimensional data, they overfit, or they are too\nlinear. Here we argue that the origin of adversarial examples is primarily due\nto an inherent uncertainty that neural networks have about their predictions.\nWe show that the functional form of this uncertainty is independent of\narchitecture, dataset, and training protocol; and depends only on the\nstatistics of the logit differences of the network, which do not change\nsignificantly during training. This leads to adversarial error having a\nuniversal scaling, as a power-law, with respect to the size of the adversarial\nperturbation. We show that this universality holds for a broad range of\ndatasets (MNIST, CIFAR10, ImageNet, and random data), models (including\nstate-of-the-art deep networks, linear models, adversarially trained networks,\nand networks trained on randomly shuffled labels), and attacks (FGSM, step\nl.l., PGD). Motivated by these results, we study the effects of reducing\nprediction entropy on adversarial robustness. Finally, we study the effect of\nnetwork architectures on adversarial sensitivity. To do this, we use neural\narchitecture search with reinforcement learning to find adversarially robust\narchitectures on CIFAR10. Our resulting architecture is more robust to white\n\\emph{and} black box attacks compared to previous attempts.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 06:54:49 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Cubuk", "Ekin D.", ""], ["Zoph", "Barret", ""], ["Schoenholz", "Samuel S.", ""], ["Le", "Quoc V.", ""]]}, {"id": "1711.02857", "submitter": "Jianqiao Wangni", "authors": "Jianqiao Wangni, Dahua Lin", "title": "Learning Sparse Visual Representations with Leaky Capped Norm\n  Regularizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity inducing regularization is an important part for learning\nover-complete visual representations. Despite the popularity of $\\ell_1$\nregularization, in this paper, we investigate the usage of non-convex\nregularizations in this problem. Our contribution consists of three parts.\nFirst, we propose the leaky capped norm regularization (LCNR), which allows\nmodel weights below a certain threshold to be regularized more strongly as\nopposed to those above, therefore imposes strong sparsity and only introduces\ncontrollable estimation bias. We propose a majorization-minimization algorithm\nto optimize the joint objective function. Second, our study over monocular 3D\nshape recovery and neural networks with LCNR outperforms $\\ell_1$ and other\nnon-convex regularizations, achieving state-of-the-art performance and faster\nconvergence. Third, we prove a theoretical global convergence speed on the 3D\nrecovery problem. To the best of our knowledge, this is the first convergence\nanalysis of the 3D recovery problem.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 07:54:41 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Wangni", "Jianqiao", ""], ["Lin", "Dahua", ""]]}, {"id": "1711.02877", "submitter": "Michel Fliess", "authors": "C\\'edric Join, Emmanuel Delaleau, Michel Fliess, Claude H. Moog", "title": "Un r\\'esultat intrigant en commande sans mod\\`ele", "comments": "in French,\n  https://www.openscience.fr/Un-resultat-intrigant-en-commande-sans-modele", "journal-ref": "ISTE OpenScience Automatique, vol. 1, 2017", "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An elementary mathematical example proves, thanks to the Routh-Hurwitz\ncriterion, a result that is intriguing with respect to today's practical\nunderstanding of model-free control, i.e., an \"intelligent\" proportional\ncontroller (iP) may turn to be more difficult to tune than an intelligent\nproportional-derivative one (iPD). The vast superiority of iPDs when compared\nto classic PIDs is shown via computer simulations. The introduction as well as\nthe conclusion analyse model-free control in the light of recent advances.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 09:26:09 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Join", "C\u00e9dric", ""], ["Delaleau", "Emmanuel", ""], ["Fliess", "Michel", ""], ["Moog", "Claude H.", ""]]}, {"id": "1711.02879", "submitter": "Antonia Creswell", "authors": "Antonia Creswell, Anil A. Bharath, Biswa Sengupta", "title": "LatentPoison - Adversarial Attacks On The Latent Space", "comments": "Submitted to ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness and security of machine learning (ML) systems are intertwined,\nwherein a non-robust ML system (classifiers, regressors, etc.) can be subject\nto attacks using a wide variety of exploits. With the advent of scalable deep\nlearning methodologies, a lot of emphasis has been put on the robustness of\nsupervised, unsupervised and reinforcement learning algorithms. Here, we study\nthe robustness of the latent space of a deep variational autoencoder (dVAE), an\nunsupervised generative framework, to show that it is indeed possible to\nperturb the latent space, flip the class predictions and keep the\nclassification probability approximately equal before and after an attack. This\nmeans that an agent that looks at the outputs of a decoder would remain\noblivious to an attack.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 09:37:16 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Creswell", "Antonia", ""], ["Bharath", "Anil A.", ""], ["Sengupta", "Biswa", ""]]}, {"id": "1711.02974", "submitter": "Michel  Barlaud", "authors": "Cyprien Gilet, Marie Deprez, Jean-Baptiste Caillau and Michel Barlaud", "title": "Clustering with feature selection using alternating minimization,\n  Application to computational biology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with unsupervised clustering with feature selection. The\nproblem is to estimate both labels and a sparse projection matrix of weights.\nTo address this combinatorial non-convex problem maintaining a strict control\non the sparsity of the matrix of weights, we propose an alternating\nminimization of the Frobenius norm criterion. We provide a new efficient\nalgorithm named K-sparse which alternates k-means with projection-gradient\nminimization. The projection-gradient step is a method of splitting type, with\nexact projection on the $\\ell^1$ ball to promote sparsity. The convergence of\nthe gradient-projection step is addressed, and a preliminary analysis of the\nalternating minimization is made. The Frobenius norm criterion converges as the\nnumber of iterates in Algorithm K-sparse goes to infinity. Experiments on\nSingle Cell RNA sequencing datasets show that our method significantly improves\nthe results of PCA k-means, spectral clustering, SIMLR, and Sparcl methods, and\nachieves a relevant selection of genes. The complexity of K-sparse is linear in\nthe number of samples (cells), so that the method scales up to large datasets.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 14:42:55 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 09:45:42 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2018 14:29:53 GMT"}, {"version": "v4", "created": "Fri, 24 May 2019 12:04:34 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Gilet", "Cyprien", ""], ["Deprez", "Marie", ""], ["Caillau", "Jean-Baptiste", ""], ["Barlaud", "Michel", ""]]}, {"id": "1711.03016", "submitter": "Lane Schwartz", "authors": "Richard Wei, Lane Schwartz, Vikram Adve", "title": "DLVM: A modern compiler infrastructure for deep learning systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning software demands reliability and performance. However, many of\nthe existing deep learning frameworks are software libraries that act as an\nunsafe DSL in Python and a computation graph interpreter. We present DLVM, a\ndesign and implementation of a compiler infrastructure with a linear algebra\nintermediate representation, algorithmic differentiation by adjoint code\ngeneration, domain-specific optimizations and a code generator targeting GPU\nvia LLVM. Designed as a modern compiler infrastructure inspired by LLVM, DLVM\nis more modular and more generic than existing deep learning compiler\nframeworks, and supports tensor DSLs with high expressivity. With our\nprototypical staged DSL embedded in Swift, we argue that the DLVM system\nenables a form of modular, safe and performant frameworks for deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 15:33:23 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 14:47:33 GMT"}, {"version": "v3", "created": "Wed, 6 Dec 2017 01:55:59 GMT"}, {"version": "v4", "created": "Mon, 11 Dec 2017 21:49:48 GMT"}, {"version": "v5", "created": "Fri, 2 Feb 2018 21:07:25 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Wei", "Richard", ""], ["Schwartz", "Lane", ""], ["Adve", "Vikram", ""]]}, {"id": "1711.03038", "submitter": "Kristjan Kalm", "authors": "Kristjan Kalm", "title": "Recency-weighted Markovian inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a Markov latent state space (MLSS) model, where the latent state\ndistribution is a decaying mixture over multiple past states. We present a\nsimple sampling algorithm that allows to approximate such high-order MLSS with\nfixed time and memory costs.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 16:30:56 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Kalm", "Kristjan", ""]]}, {"id": "1711.03067", "submitter": "Ting Chen", "authors": "Ting Chen, Martin Renqiang Min and Yizhou Sun", "title": "Learning K-way D-dimensional Discrete Code For Compact Embedding\n  Representations", "comments": "NIPS'17 DISCML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding methods such as word embedding have become pillars for many\napplications containing discrete structures. Conventional embedding methods\ndirectly associate each symbol with a continuous embedding vector, which is\nequivalent to applying linear transformation based on \"one-hot\" encoding of the\ndiscrete symbols. Despite its simplicity, such approach yields number of\nparameters that grows linearly with the vocabulary size and can lead to\noverfitting. In this work we propose a much more compact K-way D-dimensional\ndiscrete encoding scheme to replace the \"one-hot\" encoding. In \"KD encoding\",\neach symbol is represented by a $D$-dimensional code, and each of its dimension\nhas a cardinality of $K$. The final symbol embedding vector can be generated by\ncomposing the code embedding vectors. To learn the semantically meaningful\ncode, we derive a relaxed discrete optimization technique based on stochastic\ngradient descent. By adopting the new coding system, the efficiency of\nparameterization can be significantly improved (from linear to logarithmic),\nand this can also mitigate the over-fitting problem. In our experiments with\nlanguage modeling, the number of embedding parameters can be reduced by 97\\%\nwhile achieving similar or better performance.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 17:46:55 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 06:12:54 GMT"}, {"version": "v3", "created": "Sun, 10 Dec 2017 22:00:30 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Chen", "Ting", ""], ["Min", "Martin Renqiang", ""], ["Sun", "Yizhou", ""]]}, {"id": "1711.03073", "submitter": "Anirbit Mukherjee", "authors": "Anirbit Mukherjee, Amitabh Basu", "title": "Lower bounds over Boolean inputs for deep neural networks with ReLU\n  gates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the resurgence of neural networks in being able to solve complex\nlearning tasks we undertake a study of high depth networks using ReLU gates\nwhich implement the function $x \\mapsto \\max\\{0,x\\}$. We try to understand the\nrole of depth in such neural networks by showing size lowerbounds against such\nnetwork architectures in parameter regimes hitherto unexplored. In particular\nwe show the following two main results about neural nets computing Boolean\nfunctions of input dimension $n$,\n  1. We use the method of random restrictions to show almost linear,\n$\\Omega(\\epsilon^{2(1-\\delta)}n^{1-\\delta})$, lower bound for completely weight\nunrestricted LTF-of-ReLU circuits to match the Andreev function on at least\n$\\frac{1}{2} +\\epsilon$ fraction of the inputs for $\\epsilon >\n\\sqrt{2\\frac{\\log^{\\frac {2}{2-\\delta}}(n)}{n}}$ for any $\\delta \\in (0,\\frac 1\n2)$\n  2. We use the method of sign-rank to show exponential in dimension lower\nbounds for ReLU circuits ending in a LTF gate and of depths upto $O(n^{\\xi})$\nwith $\\xi < \\frac{1}{8}$ with some restrictions on the weights in the bottom\nmost layer. All other weights in these circuits are kept unrestricted. This in\nturns also implies the same lowerbounds for LTF circuits with the same\narchitecture and the same weight restrictions on their bottom most layer.\n  Along the way we also show that there exists a $\\mathbb{R}^ n\\rightarrow\n\\mathbb{R}$ Sum-of-ReLU-of-ReLU function which Sum-of-ReLU neural nets can\nnever represent no matter how large they are allowed to be.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 18:02:47 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 02:35:25 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Mukherjee", "Anirbit", ""], ["Basu", "Amitabh", ""]]}, {"id": "1711.03091", "submitter": "Ellen Vitercik", "authors": "Maria-Florina Balcan, Travis Dick, and Ellen Vitercik", "title": "Dispersion for Data-Driven Algorithm Design, Online Learning, and\n  Private Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven algorithm design, that is, choosing the best algorithm for a\nspecific application, is a crucial problem in modern data science.\nPractitioners often optimize over a parameterized algorithm family, tuning\nparameters based on problems from their domain. These procedures have\nhistorically come with no guarantees, though a recent line of work studies\nalgorithm selection from a theoretical perspective. We advance the foundations\nof this field in several directions: we analyze online algorithm selection,\nwhere problems arrive one-by-one and the goal is to minimize regret, and\nprivate algorithm selection, where the goal is to find good parameters over a\nset of problems without revealing sensitive information contained therein. We\nstudy important algorithm families, including SDP-rounding schemes for problems\nformulated as integer quadratic programs, and greedy techniques for canonical\nsubset selection problems. In these cases, the algorithm's performance is a\nvolatile and piecewise Lipschitz function of its parameters, since tweaking the\nparameters can completely change the algorithm's behavior. We give a sufficient\nand general condition, dispersion, defining a family of piecewise Lipschitz\nfunctions that can be optimized online and privately, which includes the\nfunctions measuring the performance of the algorithms we study. Intuitively, a\nset of piecewise Lipschitz functions is dispersed if no small region contains\nmany of the functions' discontinuities. We present general techniques for\nonline and private optimization of the sum of dispersed piecewise Lipschitz\nfunctions. We improve over the best-known regret bounds for a variety of\nproblems, prove regret bounds for problems not previously studied, and give\nmatching lower bounds. We also give matching upper and lower bounds on the\nutility loss due to privacy. Moreover, we uncover dispersion in auction design\nand pricing problems.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 18:50:49 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 17:46:48 GMT"}, {"version": "v3", "created": "Mon, 2 Jul 2018 17:37:03 GMT"}, {"version": "v4", "created": "Mon, 22 Oct 2018 17:27:50 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Dick", "Travis", ""], ["Vitercik", "Ellen", ""]]}, {"id": "1711.03121", "submitter": "Daniel George", "authors": "Daniel George, E. A. Huerta", "title": "Deep Learning for Real-time Gravitational Wave Detection and Parameter\n  Estimation: Results with Advanced LIGO Data", "comments": "6 pages, 7 figures; First application of deep learning to real LIGO\n  events; Includes direct comparison against matched-filtering", "journal-ref": "Physics Letters B, 778 (2018) 64-70", "doi": "10.1016/j.physletb.2017.12.053", "report-no": null, "categories": "gr-qc astro-ph.HE astro-ph.IM cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent Nobel-prize-winning detections of gravitational waves from merging\nblack holes and the subsequent detection of the collision of two neutron stars\nin coincidence with electromagnetic observations have inaugurated a new era of\nmultimessenger astrophysics. To enhance the scope of this emergent field of\nscience, we pioneered the use of deep learning with convolutional neural\nnetworks, that take time-series inputs, for rapid detection and\ncharacterization of gravitational wave signals. This approach, Deep Filtering,\nwas initially demonstrated using simulated LIGO noise. In this article, we\npresent the extension of Deep Filtering using real data from LIGO, for both\ndetection and parameter estimation of gravitational waves from binary black\nhole mergers using continuous data streams from multiple LIGO detectors. We\ndemonstrate for the first time that machine learning can detect and estimate\nthe true parameters of real events observed by LIGO. Our results show that Deep\nFiltering achieves similar sensitivities and lower errors compared to\nmatched-filtering while being far more computationally efficient and more\nresilient to glitches, allowing real-time processing of weak time-series\nsignals in non-stationary non-Gaussian noise with minimal resources, and also\nenables the detection of new classes of gravitational wave sources that may go\nunnoticed with existing detection algorithms. This unified framework for data\nanalysis is ideally suited to enable coincident detection campaigns of\ngravitational waves and their multimessenger counterparts in real-time.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 19:05:28 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["George", "Daniel", ""], ["Huerta", "E. A.", ""]]}, {"id": "1711.03127", "submitter": "Hao Wang", "authors": "Hao Wang, Baosen Zhang", "title": "Energy Storage Arbitrage in Real-Time Markets via Reinforcement Learning", "comments": null, "journal-ref": "2018 IEEE Power & Energy Society General Meeting (PESGM)", "doi": "10.1109/PESGM.2018.8586321", "report-no": null, "categories": "cs.SY cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive a temporal arbitrage policy for storage via\nreinforcement learning. Real-time price arbitrage is an important source of\nrevenue for storage units, but designing good strategies have proven to be\ndifficult because of the highly uncertain nature of the prices. Instead of\ncurrent model predictive or dynamic programming approaches, we use\nreinforcement learning to design an optimal arbitrage policy. This policy is\nlearned through repeated charge and discharge actions performed by the storage\nunit through updating a value matrix. We design a reward function that does not\nonly reflect the instant profit of charge/discharge decisions but also\nincorporate the history information. Simulation results demonstrate that our\ndesigned reward function leads to significant performance improvement compared\nwith existing algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 19:24:27 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 23:57:12 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 09:57:08 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Wang", "Hao", ""], ["Zhang", "Baosen", ""]]}, {"id": "1711.03129", "submitter": "Jiajun Wu", "authors": "Jiajun Wu, Yifan Wang, Tianfan Xue, Xingyuan Sun, William T Freeman,\n  Joshua B Tenenbaum", "title": "MarrNet: 3D Shape Reconstruction via 2.5D Sketches", "comments": "NIPS 2017. The first two authors contributed equally to this paper.\n  Project page: http://marrnet.csail.mit.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D object reconstruction from a single image is a highly under-determined\nproblem, requiring strong prior knowledge of plausible 3D shapes. This\nintroduces challenges for learning-based approaches, as 3D object annotations\nare scarce in real images. Previous work chose to train on synthetic data with\nground truth 3D information, but suffered from domain adaptation when tested on\nreal data. In this work, we propose MarrNet, an end-to-end trainable model that\nsequentially estimates 2.5D sketches and 3D object shape. Our disentangled,\ntwo-step formulation has three advantages. First, compared to full 3D shape,\n2.5D sketches are much easier to be recovered from a 2D image; models that\nrecover 2.5D sketches are also more likely to transfer from synthetic to real\ndata. Second, for 3D reconstruction from 2.5D sketches, systems can learn\npurely from synthetic data. This is because we can easily render realistic 2.5D\nsketches without modeling object appearance variations in real images,\nincluding lighting, texture, etc. This further relieves the domain adaptation\nproblem. Third, we derive differentiable projective functions from 3D shape to\n2.5D sketches; the framework is therefore end-to-end trainable on real images,\nrequiring no human annotations. Our model achieves state-of-the-art performance\non 3D shape reconstruction.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 19:29:01 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Wu", "Jiajun", ""], ["Wang", "Yifan", ""], ["Xue", "Tianfan", ""], ["Sun", "Xingyuan", ""], ["Freeman", "William T", ""], ["Tenenbaum", "Joshua B", ""]]}, {"id": "1711.03130", "submitter": "Javier Gonzalvo", "authors": "Gus Kristiansen, Xavi Gonzalvo", "title": "EnergyNet: Energy-based Adaptive Structural Learning of Artificial\n  Neural Network Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present E NERGY N ET , a new framework for analyzing and building\nartificial neural network architectures. Our approach adaptively learns the\nstructure of the networks in an unsupervised manner. The methodology is based\nupon the theoretical guarantees of the energy function of restricted Boltzmann\nmachines (RBM) of infinite number of nodes. We present experimental results to\nshow that the final network adapts to the complexity of a given problem.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 19:30:15 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Kristiansen", "Gus", ""], ["Gonzalvo", "Xavi", ""]]}, {"id": "1711.03156", "submitter": "Jiachen Yang", "authors": "Jiachen Yang, Xiaojing Ye, Rakshit Trivedi, Huan Xu, Hongyuan Zha", "title": "Learning Deep Mean Field Games for Modeling Large Population Behavior", "comments": "Accepted to International Conference on Learning Representations\n  (2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of representing collective behavior of large\npopulations and predicting the evolution of a population distribution over a\ndiscrete state space. A discrete time mean field game (MFG) is motivated as an\ninterpretable model founded on game theory for understanding the aggregate\neffect of individual actions and predicting the temporal evolution of\npopulation distributions. We achieve a synthesis of MFG and Markov decision\nprocesses (MDP) by showing that a special MFG is reducible to an MDP. This\nenables us to broaden the scope of mean field game theory and infer MFG models\nof large real-world systems via deep inverse reinforcement learning. Our method\nlearns both the reward function and forward dynamics of an MFG from real data,\nand we report the first empirical test of a mean field game model of a\nreal-world social media population.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 20:43:39 GMT"}, {"version": "v2", "created": "Sun, 22 Apr 2018 06:33:04 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Yang", "Jiachen", ""], ["Ye", "Xiaojing", ""], ["Trivedi", "Rakshit", ""], ["Xu", "Huan", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1711.03167", "submitter": "Yao-Hung Tsai", "authors": "Yao-Hung Hubert Tsai, Han Zhao, Ruslan Salakhutdinov, Nebojsa Jojic", "title": "Learning Markov Chain in Unordered Dataset", "comments": "This would be the final update for this technical report on learning\n  Markov Chain in the unordered dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The assumption that data samples are independently identically distributed is\nthe backbone of many learning algorithms. Nevertheless, datasets often exhibit\nrich structure in practice, and we argue that there exist some unknown order\nwithin the data instances. In this technical report, we introduce OrderNet that\ncan be used to extract the order of data instances in an unsupervised way. By\nassuming that the instances are sampled from a Markov chain, our goal is to\nlearn the transitional operator of the underlying Markov chain, as well as the\norder by maximizing the generation probability under all possible data\npermutations. Specifically, we use neural network as a compact and soft lookup\ntable to approximate the possibly huge, but discrete transition matrix. This\nstrategy allows us to amortize the space complexity with a single model.\nFurthermore, this simple and compact representation also provides a short\ndescription to the dataset and generalizes to unseen instances as well. To\nensure that the learned Markov chain is ergodic, we propose a greedy batch-wise\npermutation scheme that allows fast training. Empirically, we show that\nOrderNet is able to discover an order among data instances. We also extend the\nproposed OrderNet to one-shot recognition task and demonstrate favorable\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 21:11:26 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 05:14:46 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 06:38:12 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Tsai", "Yao-Hung Hubert", ""], ["Zhao", "Han", ""], ["Salakhutdinov", "Ruslan", ""], ["Jojic", "Nebojsa", ""]]}, {"id": "1711.03189", "submitter": "Weiyang Liu", "authors": "Weiyang Liu, Yan-Ming Zhang, Xingguo Li, Zhiding Yu, Bo Dai, Tuo Zhao,\n  Le Song", "title": "Deep Hyperspherical Learning", "comments": "NIPS 2017 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolution as inner product has been the founding basis of convolutional\nneural networks (CNNs) and the key to end-to-end visual representation\nlearning. Benefiting from deeper architectures, recent CNNs have demonstrated\nincreasingly strong representation abilities. Despite such improvement, the\nincreased depth and larger parameter space have also led to challenges in\nproperly training a network. In light of such challenges, we propose\nhyperspherical convolution (SphereConv), a novel learning framework that gives\nangular representations on hyperspheres. We introduce SphereNet, deep\nhyperspherical convolution networks that are distinct from conventional inner\nproduct based convolutional networks. In particular, SphereNet adopts\nSphereConv as its basic convolution operator and is supervised by generalized\nangular softmax loss - a natural loss formulation under SphereConv. We show\nthat SphereNet can effectively encode discriminative representation and\nalleviate training difficulty, leading to easier optimization, faster\nconvergence and comparable (even better) classification accuracy over\nconvolutional counterparts. We also provide some theoretical insights for the\nadvantages of learning on hyperspheres. In addition, we introduce the learnable\nSphereConv, i.e., a natural improvement over prefixed SphereConv, and\nSphereNorm, i.e., hyperspherical learning as a normalization method.\nExperiments have verified our conclusions.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 22:21:21 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 15:15:19 GMT"}, {"version": "v3", "created": "Wed, 22 Nov 2017 18:18:04 GMT"}, {"version": "v4", "created": "Mon, 27 Nov 2017 20:48:17 GMT"}, {"version": "v5", "created": "Tue, 30 Jan 2018 16:00:14 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Liu", "Weiyang", ""], ["Zhang", "Yan-Ming", ""], ["Li", "Xingguo", ""], ["Yu", "Zhiding", ""], ["Dai", "Bo", ""], ["Zhao", "Tuo", ""], ["Song", "Le", ""]]}, {"id": "1711.03190", "submitter": "Jiaxuan Wang", "authors": "Jiaxuan Wang, Jeeheh Oh, Haozhu Wang, Jenna Wiens", "title": "Learning Credible Models", "comments": null, "journal-ref": "KDD '18 Proceedings of the 24th ACM SIGKDD International\n  Conference on Knowledge Discovery & Data Mining 2018", "doi": "10.1145/3219819.3220070", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many settings, it is important that a model be capable of providing\nreasons for its predictions (i.e., the model must be interpretable). However,\nthe model's reasoning may not conform with well-established knowledge. In such\ncases, while interpretable, the model lacks \\textit{credibility}. In this work,\nwe formally define credibility in the linear setting and focus on techniques\nfor learning models that are both accurate and credible. In particular, we\npropose a regularization penalty, expert yielded estimates (EYE), that\nincorporates expert knowledge about well-known relationships among covariates\nand the outcome of interest. We give both theoretical and empirical results\ncomparing our proposed method to several other regularization techniques.\nAcross a range of settings, experiments on both synthetic and real data show\nthat models learned using the EYE penalty are significantly more credible than\nthose learned using other penalties. Applied to a large-scale patient risk\nstratification task, our proposed technique results in a model whose top\nfeatures overlap significantly with known clinical risk factors, while still\nachieving good predictive performance.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 22:28:09 GMT"}, {"version": "v2", "created": "Tue, 14 Nov 2017 23:52:27 GMT"}, {"version": "v3", "created": "Thu, 7 Jun 2018 18:46:56 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Wang", "Jiaxuan", ""], ["Oh", "Jeeheh", ""], ["Wang", "Haozhu", ""], ["Wiens", "Jenna", ""]]}, {"id": "1711.03194", "submitter": "Alexander Korotin", "authors": "Alexander Korotin and Vladimir V'yugin and Evgeny Burnaev", "title": "Long-Term Online Smoothing Prediction Using Expert Advice", "comments": "22 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the prediction with experts' advice setting, we construct forecasting\nalgorithms that suffer loss not much more than any expert in the pool. In\ncontrast to the standard approach, we investigate the case of long-term\nforecasting of time series and consider two scenarios. In the first one, at\neach step $t$ the learner has to combine the point forecasts of the experts\nissued for the time interval $[t+1, t+d]$ ahead. Our approach implies that at\neach time step experts issue point forecasts for arbitrary many steps ahead and\nthen the learner (algorithm) combines these forecasts and the forecasts made\nearlier into one vector forecast for steps $[t+1,t+d]$. By combining past and\nthe current long-term forecasts we obtain a smoothing mechanism that protects\nour algorithm from temporary trend changes, noise and outliers. In the second\nscenario, at each step $t$ experts issue a prediction function, and the learner\nhas to combine these functions into the single one, which will be used for\nlong-term time-series prediction. For each scenario, we develop an algorithm\nfor combining experts forecasts and prove $O(\\ln T)$ adversarial regret upper\nbound for both algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 22:35:56 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 07:19:02 GMT"}, {"version": "v3", "created": "Wed, 27 Feb 2019 09:58:44 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Korotin", "Alexander", ""], ["V'yugin", "Vladimir", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1711.03198", "submitter": "Fang Liu", "authors": "Fang Liu, Swapna Buccapatnam, Ness Shroff", "title": "Information Directed Sampling for Stochastic Bandits with Graph Feedback", "comments": "Accepted by AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider stochastic multi-armed bandit problems with graph feedback, where\nthe decision maker is allowed to observe the neighboring actions of the chosen\naction. We allow the graph structure to vary with time and consider both\ndeterministic and Erd\\H{o}s-R\\'enyi random graph models. For such a graph\nfeedback model, we first present a novel analysis of Thompson sampling that\nleads to tighter performance bound than existing work. Next, we propose new\nInformation Directed Sampling based policies that are graph-aware in their\ndecision making. Under the deterministic graph case, we establish a Bayesian\nregret bound for the proposed policies that scales with the clique cover number\nof the graph instead of the number of actions. Under the random graph case, we\nprovide a Bayesian regret bound for the proposed policies that scales with the\nratio of the number of actions over the expected number of observations per\niteration. To the best of our knowledge, this is the first analytical result\nfor stochastic bandits with random graph feedback. Finally, using numerical\nevaluations, we demonstrate that our proposed IDS policies outperform existing\napproaches, including adaptions of upper confidence bound, $\\epsilon$-greedy\nand Exp3 algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 22:47:59 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Liu", "Fang", ""], ["Buccapatnam", "Swapna", ""], ["Shroff", "Ness", ""]]}, {"id": "1711.03280", "submitter": "Yuan Gong", "authors": "Yuan Gong, Christian Poellabauer", "title": "Crafting Adversarial Examples For Speech Paralinguistics Applications", "comments": "Published in DYnamic and Novel Advances in Machine Learning and\n  Intelligent Cyber Security (DYNAMICS) Workshop in conjunction with ACSAC'18,\n  San Juan, Puerto Rico, December 2018", "journal-ref": null, "doi": "10.1145/3306195.3306196", "report-no": null, "categories": "cs.LG cs.CR cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational paralinguistic analysis is increasingly being used in a wide\nrange of cyber applications, including security-sensitive applications such as\nspeaker verification, deceptive speech detection, and medical diagnostics.\nWhile state-of-the-art machine learning techniques, such as deep neural\nnetworks, can provide robust and accurate speech analysis, they are susceptible\nto adversarial attacks. In this work, we propose an end-to-end scheme to\ngenerate adversarial examples for computational paralinguistic applications by\nperturbing directly the raw waveform of an audio recording rather than specific\nacoustic features. Our experiments show that the proposed adversarial\nperturbation can lead to a significant performance drop of state-of-the-art\ndeep neural networks, while only minimally impairing the audio quality.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 07:41:53 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 06:57:33 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Gong", "Yuan", ""], ["Poellabauer", "Christian", ""]]}, {"id": "1711.03321", "submitter": "Alessandro Achille", "authors": "Alessandro Achille, Stefano Soatto", "title": "A Separation Principle for Control in the Age of Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review the problem of defining and inferring a \"state\" for a control\nsystem based on complex, high-dimensional, highly uncertain measurement streams\nsuch as videos. Such a state, or representation, should contain all and only\nthe information needed for control, and discount nuisance variability in the\ndata. It should also have finite complexity, ideally modulated depending on\navailable resources. This representation is what we want to store in memory in\nlieu of the data, as it \"separates\" the control task from the measurement\nprocess. For the trivial case with no dynamics, a representation can be\ninferred by minimizing the Information Bottleneck Lagrangian in a function\nclass realized by deep neural networks. The resulting representation has much\nhigher dimension than the data, already in the millions, but it is smaller in\nthe sense of information content, retaining only what is needed for the task.\nThis process also yields representations that are invariant to nuisance factors\nand having maximally independent components. We extend these ideas to the\ndynamic case, where the representation is the posterior density of the task\nvariable given the measurements up to the current time, which is in general\nmuch simpler than the prediction density maintained by the classical Bayesian\nfilter. Again this can be finitely-parametrized using a deep neural network,\nand already some applications are beginning to emerge. No explicit assumption\nof Markovianity is needed; instead, complexity trades off approximation of an\noptimal representation, including the degree of Markovianity.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 11:10:24 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Achille", "Alessandro", ""], ["Soatto", "Stefano", ""]]}, {"id": "1711.03343", "submitter": "Kazuyuki Hara", "authors": "Kazuyuki Hara", "title": "Analysis of Dropout in Online Learning", "comments": "8 pages, 6 pages", "journal-ref": "IEICE Technical Report IBIS2017-61", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is the state-of-the-art in fields such as visual object\nrecognition and speech recognition. This learning uses a large number of layers\nand a huge number of units and connections. Therefore, overfitting is a serious\nproblem with it, and the dropout which is a kind of regularization tool is\nused. However, in online learning, the effect of dropout is not well known.\nThis paper presents our investigation on the effect of dropout in online\nlearning. We analyzed the effect of dropout on convergence speed near the\nsingular point. Our results indicated that dropout is effective in online\nlearning. Dropout tends to avoid the singular point for convergence speed near\nthat point.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 12:10:27 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Hara", "Kazuyuki", ""]]}, {"id": "1711.03361", "submitter": "Tianchun Wang", "authors": "Tianchun Wang", "title": "Multi-Relevance Transfer Learning", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning aims to faciliate learning tasks in a label-scarce target\ndomain by leveraging knowledge from a related source domain with plenty of\nlabeled data. Often times we may have multiple domains with little or no\nlabeled data as targets waiting to be solved. Most existing efforts tackle\ntarget domains separately by modeling the `source-target' pairs without\nexploring the relatedness between them, which would cause loss of crucial\ninformation, thus failing to achieve optimal capability of knowledge transfer.\nIn this paper, we propose a novel and effective approach called Multi-Relevance\nTransfer Learning (MRTL) for this purpose, which can simultaneously transfer\ndifferent knowledge from the source and exploits the shared common latent\nfactors between target domains. Specifically, we formulate the problem as an\noptimization task based on a collective nonnegative matrix tri-factorization\nframework. The proposed approach achieves both source-target transfer and\ntarget-target leveraging by sharing multiple decomposed latent subspaces.\nFurther, an alternative minimization learning algorithm is developed with\nconvergence guarantee. Empirical study validates the performance and\neffectiveness of MRTL compared to the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 13:06:09 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Wang", "Tianchun", ""]]}, {"id": "1711.03386", "submitter": "Pengfei Xu", "authors": "Pengfei Xu, Shaohuai Shi, Xiaowen Chu", "title": "Performance Evaluation of Deep Learning Tools in Docker Containers", "comments": "Conference: BIgCom2017, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the success of deep learning techniques in a broad range of application\ndomains, many deep learning software frameworks have been developed and are\nbeing updated frequently to adapt to new hardware features and software\nlibraries, which bring a big challenge for end users and system administrators.\nTo address this problem, container techniques are widely used to simplify the\ndeployment and management of deep learning software. However, it remains\nunknown whether container techniques bring any performance penalty to deep\nlearning applications. The purpose of this work is to systematically evaluate\nthe impact of docker container on the performance of deep learning\napplications. We first benchmark the performance of system components (IO, CPU\nand GPU) in a docker container and the host system and compare the results to\nsee if there's any difference. According to our results, we find that\ncomputational intensive jobs, either running on CPU or GPU, have small overhead\nindicating docker containers can be applied to deep learning programs. Then we\nevaluate the performance of some popular deep learning tools deployed in a\ndocker container and the host system. It turns out that the docker container\nwill not cause noticeable drawbacks while running those deep learning tools. So\nencapsulating deep learning tool in a container is a feasible solution.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 14:28:12 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Xu", "Pengfei", ""], ["Shi", "Shaohuai", ""], ["Chu", "Xiaowen", ""]]}, {"id": "1711.03398", "submitter": "Mohsen Mahoor", "authors": "Mohsen Mahoor and Amin Khodaei", "title": "Data Fusion and Machine Learning Integration for Transformer Loss of\n  Life Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid growth of machine learning methodologies and their applications offer\nnew opportunity for improved transformer asset management. Accordingly, power\nsystem operators are currently looking for data-driven methods to make\nbetter-informed decisions in terms of network management. In this paper,\nmachine learning and data fusion techniques are integrated to estimate\ntransformer loss of life. Using IEEE Std. C57.91-2011, a data synthesis process\nis proposed based on hourly transformer loading and ambient temperature values.\nThis synthesized data is employed to estimate transformer loss of life by using\nAdaptive Network-Based Fuzzy Inference System (ANFIS) and Radial Basis Function\n(RBF) network, which are further fused together with the objective of improving\nthe estimation accuracy. Among various data fusion techniques, Ordered Weighted\nAveraging (OWA) and sequential Kalman filter are selected to fuse the output\nresults of the estimated ANFIS and RBF. Simulation results demonstrate the\nmerit and the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 17:16:24 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Mahoor", "Mohsen", ""], ["Khodaei", "Amin", ""]]}, {"id": "1711.03404", "submitter": "Romain Couillet", "authors": "Xiaoyi Mai and Romain Couillet", "title": "A random matrix analysis and improvement of semi-supervised learning for\n  large dimensional data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides an original understanding of the behavior of a class of\ngraph-oriented semi-supervised learning algorithms in the limit of large and\nnumerous data. It is demonstrated that the intuition at the root of these\nmethods collapses in this limit and that, as a result, most of them become\ninconsistent. Corrective measures and a new data-driven parametrization scheme\nare proposed along with a theoretical analysis of the asymptotic performances\nof the resulting approach. A surprisingly close behavior between theoretical\nperformances on Gaussian mixture models and on real datasets is also\nillustrated throughout the article, thereby suggesting the importance of the\nproposed analysis for dealing with practical data. As a result, significant\nperformance gains are observed on practical data classification using the\nproposed parametrization.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 14:59:30 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Mai", "Xiaoyi", ""], ["Couillet", "Romain", ""]]}, {"id": "1711.03406", "submitter": "Chen Zheng", "authors": "HuaChun Zhang, Lynden Kagan, Chen Zheng", "title": "Machine Learning Based Fast Power Integrity Classifier", "comments": "6 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed a new machine learning based fast power integrity\nclassifier that quickly flags the EM/IR hotspots. We discussed the features to\nextract to describe the power grid, cell power density, routing impact and\ncontrolled collapse chip connection (C4) bumps, etc. The continuous and\ndiscontinuous cases are identified and treated using different machine learning\nmodels. Nearest neighbors, random forest and neural network models are compared\nto select the best performance candidates. Experiments are run on open source\nbenchmark, and result is showing promising prediction accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 03:07:05 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Zhang", "HuaChun", ""], ["Kagan", "Lynden", ""], ["Zheng", "Chen", ""]]}, {"id": "1711.03410", "submitter": "Pedram Gharani", "authors": "Brian Suffoletto, Pedram Gharani, Tammy Chung, Hassan Karimi", "title": "Using Phone Sensors and an Artificial Neural Network to Detect Gait\n  Changes During Drinking Episodes in the Natural Environment", "comments": null, "journal-ref": "Gait Posture 60 (2018) 116-12", "doi": "10.1016/j.gaitpost.2017.11.019", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phone sensors could be useful in assessing changes in gait that occur with\nalcohol consumption. This study determined (1) feasibility of collecting\ngait-related data during drinking occasions in the natural environment, and (2)\nhow gait-related features measured by phone sensors relate to estimated blood\nalcohol concentration (eBAC). Ten young adult heavy drinkers were prompted to\ncomplete a 5-step gait task every hour from 8pm to 12am over four consecutive\nweekends. We collected 3-xis accelerometer, gyroscope, and magnetometer data\nfrom phone sensors, and computed 24 gait-related features using a sliding\nwindow technique. eBAC levels were calculated at each time point based on\nEcological Momentary Assessment (EMA) of alcohol use. We used an artificial\nneural network model to analyze associations between sensor features and eBACs\nin training (70% of the data) and validation and test (30% of the data)\ndatasets. We analyzed 128 data points where both eBAC and gait-related sensor\ndata was captured, either when not drinking (n=60), while eBAC was ascending\n(n=55) or eBAC was descending (n=13). 21 data points were captured at times\nwhen the eBAC was greater than the legal limit (0.08 mg/dl). Using a Bayesian\nregularized neural network, gait-related phone sensor features showed a high\ncorrelation with eBAC (Pearson's r > 0.9), and >95% of estimated eBAC would\nfall between -0.012 and +0.012 of actual eBAC. It is feasible to collect\ngait-related data from smartphone sensors during drinking occasions in the\nnatural environment. Sensor-based features can be used to infer gait changes\nassociated with elevated blood alcohol content.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 15:05:59 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 21:34:30 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Suffoletto", "Brian", ""], ["Gharani", "Pedram", ""], ["Chung", "Tammy", ""], ["Karimi", "Hassan", ""]]}, {"id": "1711.03440", "submitter": "Zhao Song", "authors": "Kai Zhong, Zhao Song, Inderjit S. Dhillon", "title": "Learning Non-overlapping Convolutional Neural Networks with Multiple\n  Kernels", "comments": "arXiv admin note: text overlap with arXiv:1706.03175", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we consider parameter recovery for non-overlapping\nconvolutional neural networks (CNNs) with multiple kernels. We show that when\nthe inputs follow Gaussian distribution and the sample size is sufficiently\nlarge, the squared loss of such CNNs is $\\mathit{~locally~strongly~convex}$ in\na basin of attraction near the global optima for most popular activation\nfunctions, like ReLU, Leaky ReLU, Squared ReLU, Sigmoid and Tanh. The required\nsample complexity is proportional to the dimension of the input and polynomial\nin the number of kernels and a condition number of the parameters. We also show\nthat tensor methods are able to initialize the parameters to the local strong\nconvex region. Hence, for most smooth activations, gradient descent following\ntensor initialization is guaranteed to converge to the global optimal with time\nthat is linear in input dimension, logarithmic in precision and polynomial in\nother factors. To the best of our knowledge, this is the first work that\nprovides recovery guarantees for CNNs with multiple kernels under polynomial\nsample and computational complexities.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 14:45:31 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Zhong", "Kai", ""], ["Song", "Zhao", ""], ["Dhillon", "Inderjit S.", ""]]}, {"id": "1711.03441", "submitter": "Gabriele Farina", "authors": "Gabriele Farina and Christian Kroer and Tuomas Sandholm", "title": "Regret Minimization in Behaviorally-Constrained Zero-Sum Games", "comments": "Published at ICML 17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  No-regret learning has emerged as a powerful tool for solving extensive-form\ngames. This was facilitated by the counterfactual-regret minimization (CFR)\nframework, which relies on the instantiation of regret minimizers for simplexes\nat each information set of the game. We use an instantiation of the CFR\nframework to develop algorithms for solving behaviorally-constrained (and, as a\nspecial case, perturbed in the Selten sense) extensive-form games, which allows\nus to compute approximate Nash equilibrium refinements. Nash equilibrium\nrefinements are motivated by a major deficiency in Nash equilibrium: it\nprovides virtually no guarantees on how it will play in parts of the game tree\nthat are reached with zero probability. Refinements can mend this issue, but\nhave not been adopted in practice, mostly due to a lack of scalable algorithms.\nWe show that, compared to standard algorithms, our method finds solutions that\nhave substantially better refinement properties, while enjoying a convergence\nrate that is comparable to that of state-of-the-art algorithms for Nash\nequilibrium computation both in theory and practice.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 16:05:39 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Farina", "Gabriele", ""], ["Kroer", "Christian", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "1711.03481", "submitter": "David Eriksson", "authors": "Kun Dong, David Eriksson, Hannes Nickisch, David Bindel, Andrew Gordon\n  Wilson", "title": "Scalable Log Determinants for Gaussian Process Kernel Learning", "comments": "Appears at Advances in Neural Information Processing Systems 30\n  (NIPS), 2017", "journal-ref": "Advances in Neural Information Processing Systems 30 (NIPS), 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For applications as varied as Bayesian neural networks, determinantal point\nprocesses, elliptical graphical models, and kernel learning for Gaussian\nprocesses (GPs), one must compute a log determinant of an $n \\times n$ positive\ndefinite matrix, and its derivatives - leading to prohibitive\n$\\mathcal{O}(n^3)$ computations. We propose novel $\\mathcal{O}(n)$ approaches\nto estimating these quantities from only fast matrix vector multiplications\n(MVMs). These stochastic approximations are based on Chebyshev, Lanczos, and\nsurrogate models, and converge quickly even for kernel matrices that have\nchallenging spectra. We leverage these approximations to develop a scalable\nGaussian process approach to kernel learning. We find that Lanczos is generally\nsuperior to Chebyshev for kernel learning, and that a surrogate approach can be\nhighly efficient and accurate with popular kernels.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 17:25:30 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Dong", "Kun", ""], ["Eriksson", "David", ""], ["Nickisch", "Hannes", ""], ["Bindel", "David", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1711.03512", "submitter": "Gerrit van den Burg", "authors": "Gerrit J. J. van den Burg, Alfred O. Hero", "title": "Fast Meta-Learning for Adaptive Hierarchical Classifier Design", "comments": "Code available at: https://github.com/HeroResearchGroup/SmartSVM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new splitting criterion for a meta-learning approach to\nmulticlass classifier design that adaptively merges the classes into a\ntree-structured hierarchy of increasingly difficult binary classification\nproblems. The classification tree is constructed from empirical estimates of\nthe Henze-Penrose bounds on the pairwise Bayes misclassification rates that\nrank the binary subproblems in terms of difficulty of classification. The\nproposed empirical estimates of the Bayes error rate are computed from the\nminimal spanning tree (MST) of the samples from each pair of classes. Moreover,\na meta-learning technique is presented for quantifying the one-vs-rest Bayes\nerror rate for each individual class from a single MST on the entire dataset.\nExtensive simulations on benchmark datasets show that the proposed hierarchical\nmethod can often be learned much faster than competing methods, while achieving\ncompetitive accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 18:22:32 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Burg", "Gerrit J. J. van den", ""], ["Hero", "Alfred O.", ""]]}, {"id": "1711.03539", "submitter": "Fang Liu", "authors": "Fang Liu, Joohyun Lee, Ness Shroff", "title": "A Change-Detection based Framework for Piecewise-stationary Multi-Armed\n  Bandit Problem", "comments": "accepted by AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-armed bandit problem has been extensively studied under the\nstationary assumption. However in reality, this assumption often does not hold\nbecause the distributions of rewards themselves may change over time. In this\npaper, we propose a change-detection (CD) based framework for multi-armed\nbandit problems under the piecewise-stationary setting, and study a class of\nchange-detection based UCB (Upper Confidence Bound) policies, CD-UCB, that\nactively detects change points and restarts the UCB indices. We then develop\nCUSUM-UCB and PHT-UCB, that belong to the CD-UCB class and use cumulative sum\n(CUSUM) and Page-Hinkley Test (PHT) to detect changes. We show that CUSUM-UCB\nobtains the best known regret upper bound under mild assumptions. We also\ndemonstrate the regret reduction of the CD-UCB policies over arbitrary\nBernoulli rewards and Yahoo! datasets of webpage click-through rates.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 22:48:20 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 21:25:15 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Liu", "Fang", ""], ["Lee", "Joohyun", ""], ["Shroff", "Ness", ""]]}, {"id": "1711.03543", "submitter": "Anush Sankaran", "authors": "Akshay Sethi, Anush Sankaran, Naveen Panwar, Shreya Khare, Senthil\n  Mani", "title": "DLPaper2Code: Auto-generation of Code from Deep Learning Research Papers", "comments": "AAAI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With an abundance of research papers in deep learning, reproducibility or\nadoption of the existing works becomes a challenge. This is due to the lack of\nopen source implementations provided by the authors. Further, re-implementing\nresearch papers in a different library is a daunting task. To address these\nchallenges, we propose a novel extensible approach, DLPaper2Code, to extract\nand understand deep learning design flow diagrams and tables available in a\nresearch paper and convert them to an abstract computational graph. The\nextracted computational graph is then converted into execution ready source\ncode in both Keras and Caffe, in real-time. An arXiv-like website is created\nwhere the automatically generated designs is made publicly available for 5,000\nresearch papers. The generated designs could be rated and edited using an\nintuitive drag-and-drop UI framework in a crowdsourced manner. To evaluate our\napproach, we create a simulated dataset with over 216,000 valid design\nvisualizations using a manually defined grammar. Experiments on the simulated\ndataset show that the proposed framework provide more than $93\\%$ accuracy in\nflow diagram content extraction.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 10:00:19 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Sethi", "Akshay", ""], ["Sankaran", "Anush", ""], ["Panwar", "Naveen", ""], ["Khare", "Shreya", ""], ["Mani", "Senthil", ""]]}, {"id": "1711.03560", "submitter": "Francisco Ruiz", "authors": "Francisco J. R. Ruiz, Susan Athey, David M. Blei", "title": "SHOPPER: A Probabilistic Model of Consumer Choice with Substitutes and\n  Complements", "comments": "Published at Annals of Applied Statistics. 27 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop SHOPPER, a sequential probabilistic model of shopping data.\nSHOPPER uses interpretable components to model the forces that drive how a\ncustomer chooses products; in particular, we designed SHOPPER to capture how\nitems interact with other items. We develop an efficient posterior inference\nalgorithm to estimate these forces from large-scale data, and we analyze a\nlarge dataset from a major chain grocery store. We are interested in answering\ncounterfactual queries about changes in prices. We found that SHOPPER provides\naccurate predictions even under price interventions, and that it helps identify\ncomplementary and substitutable pairs of products.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 19:04:21 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 13:51:36 GMT"}, {"version": "v3", "created": "Sun, 9 Jun 2019 18:16:17 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Ruiz", "Francisco J. R.", ""], ["Athey", "Susan", ""], ["Blei", "David M.", ""]]}, {"id": "1711.03573", "submitter": "Wahid Bhimji", "authors": "Wahid Bhimji, Steven Andrew Farrell, Thorsten Kurth, Michela Paganini,\n  Prabhat, Evan Racah", "title": "Deep Neural Networks for Physics Analysis on low-level whole-detector\n  data at the LHC", "comments": "Presented at ACAT 2017 Conference, Submitted to J. Phys. Conf. Ser", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ex cs.DC cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been considerable recent activity applying deep convolutional\nneural nets (CNNs) to data from particle physics experiments. Current\napproaches on ATLAS/CMS have largely focussed on a subset of the calorimeter,\nand for identifying objects or particular particle types. We explore approaches\nthat use the entire calorimeter, combined with track information, for directly\nconducting physics analyses: i.e. classifying events as known-physics\nbackground or new-physics signals.\n  We use an existing RPV-Supersymmetry analysis as a case study and explore\nCNNs on multi-channel, high-resolution sparse images: applied on GPU and\nmulti-node CPU architectures (including Knights Landing (KNL) Xeon Phi nodes)\non the Cori supercomputer at NERSC.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 20:02:59 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 18:03:18 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Bhimji", "Wahid", ""], ["Farrell", "Steven Andrew", ""], ["Kurth", "Thorsten", ""], ["Paganini", "Michela", ""], ["Prabhat", "", ""], ["Racah", "Evan", ""]]}, {"id": "1711.03577", "submitter": "Chuyu Xiong", "authors": "Chuyu Xiong", "title": "What Really is Deep Learning Doing?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved a great success in many areas, from computer\nvision to natural language processing, to game playing, and much more. Yet,\nwhat deep learning is really doing is still an open question. There are a lot\nof works in this direction. For example, [5] tried to explain deep learning by\ngroup renormalization, and [6] tried to explain deep learning from the view of\nfunctional approximation. In order to address this very crucial question, here\nwe see deep learning from perspective of mechanical learning and learning\nmachine (see [1], [2]). From this particular angle, we can see deep learning\nmuch better and answer with confidence: What deep learning is really doing? why\nit works well, how it works, and how much data is necessary for learning. We\nalso will discuss advantages and disadvantages of deep learning at the end of\nthis work.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 23:00:13 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Xiong", "Chuyu", ""]]}, {"id": "1711.03591", "submitter": "Subhojyoti Mukherjee", "authors": "Subhojyoti Mukherjee, K. P. Naveen, Nandan Sudarsanam, Balaraman\n  Ravindran", "title": "Efficient-UCBV: An Almost Optimal Algorithm using Variance Estimates", "comments": null, "journal-ref": "Proceedings of the Thirty-Second AAAI Conference on Artificial\n  Intelligence, New Orleans, Louisiana, USA, February 2-7, 2018", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel variant of the UCB algorithm (referred to as\nEfficient-UCB-Variance (EUCBV)) for minimizing cumulative regret in the\nstochastic multi-armed bandit (MAB) setting. EUCBV incorporates the arm\nelimination strategy proposed in UCB-Improved \\citep{auer2010ucb}, while taking\ninto account the variance estimates to compute the arms' confidence bounds,\nsimilar to UCBV \\citep{audibert2009exploration}. Through a theoretical analysis\nwe establish that EUCBV incurs a \\emph{gap-dependent} regret bound of\n{\\scriptsize $O\\left( \\dfrac{K\\sigma^2_{\\max} \\log (T\\Delta^2\n/K)}{\\Delta}\\right)$} after $T$ trials, where $\\Delta$ is the minimal gap\nbetween optimal and sub-optimal arms; the above bound is an improvement over\nthat of existing state-of-the-art UCB algorithms (such as UCB1, UCB-Improved,\nUCBV, MOSS). Further, EUCBV incurs a \\emph{gap-independent} regret bound of\n{\\scriptsize $O\\left(\\sqrt{KT}\\right)$} which is an improvement over that of\nUCB1, UCBV and UCB-Improved, while being comparable with that of MOSS and\nOCUCB. Through an extensive numerical study we show that EUCBV significantly\noutperforms the popular UCB variants (like MOSS, OCUCB, etc.) as well as\nThompson sampling and Bayes-UCB algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 20:36:21 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Mukherjee", "Subhojyoti", ""], ["Naveen", "K. P.", ""], ["Sudarsanam", "Nandan", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1711.03634", "submitter": "Niladri Chatterji", "authors": "Niladri S. Chatterji and Peter L. Bartlett", "title": "Alternating minimization for dictionary learning: Local Convergence\n  Guarantees", "comments": "Erratum: An earlier version of this paper appeared in NIPS 2017 which\n  had an erroneous claim about convergence guarantees with random\n  initialization. The main result -- Theorem 3 -- has been corrected by adding\n  an assumption about the initialization (Assumption B1)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present theoretical guarantees for an alternating minimization algorithm\nfor the dictionary learning/sparse coding problem. The dictionary learning\nproblem is to factorize vector samples $y^{1},y^{2},\\ldots, y^{n}$ into an\nappropriate basis (dictionary) $A^*$ and sparse vectors $x^{1*},\\ldots,x^{n*}$.\nOur algorithm is a simple alternating minimization procedure that switches\nbetween $\\ell_1$ minimization and gradient descent in alternate steps.\nDictionary learning and specifically alternating minimization algorithms for\ndictionary learning are well studied both theoretically and empirically.\nHowever, in contrast to previous theoretical analyses for this problem, we\nreplace a condition on the operator norm (that is, the largest magnitude\nsingular value) of the true underlying dictionary $A^*$ with a condition on the\nmatrix infinity norm (that is, the largest magnitude term). Our guarantees are\nunder a reasonable generative model that allows for dictionaries with growing\noperator norms, and can handle an arbitrary level of overcompleteness, while\nhaving sparsity that is information theoretically optimal. We also establish\nupper bounds on the sample complexity of our algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 22:55:35 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 19:35:13 GMT"}, {"version": "v3", "created": "Tue, 30 Jan 2018 04:37:54 GMT"}, {"version": "v4", "created": "Tue, 30 Jul 2019 23:29:38 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Chatterji", "Niladri S.", ""], ["Bartlett", "Peter L.", ""]]}, {"id": "1711.03637", "submitter": "Shruti Kulkarni", "authors": "Shruti R. Kulkarni, John M. Alexiades, Bipin Rajendran", "title": "Learning and Real-time Classification of Hand-written Digits With\n  Spiking Neural Networks", "comments": "4 pages, 4 figures, 1 table, accepted at ICECS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel spiking neural network (SNN) for automated, real-time\nhandwritten digit classification and its implementation on a GP-GPU platform.\nInformation processing within the network, from feature extraction to\nclassification is implemented by mimicking the basic aspects of neuronal spike\ninitiation and propagation in the brain. The feature extraction layer of the\nSNN uses fixed synaptic weight maps to extract the key features of the image\nand the classifier layer uses the recently developed NormAD approximate\ngradient descent based supervised learning algorithm for spiking neural\nnetworks to adjust the synaptic weights. On the standard MNIST database images\nof handwritten digits, our network achieves an accuracy of 99.80% on the\ntraining set and 98.06% on the test set, with nearly 7x fewer parameters\ncompared to the state-of-the-art spiking networks. We further use this network\nin a GPU based user-interface system demonstrating real-time SNN simulation to\ninfer digits written by different users. On a test set of 500 such images, this\nreal-time platform achieves an accuracy exceeding 97% while making a prediction\nwithin an SNN emulation time of less than 100ms.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 23:01:42 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Kulkarni", "Shruti R.", ""], ["Alexiades", "John M.", ""], ["Rajendran", "Bipin", ""]]}, {"id": "1711.03638", "submitter": "Thanh Nguyen", "authors": "Thanh V. Nguyen, Raymond K. W. Wong, and Chinmay Hegde", "title": "Provably Accurate Double-Sparse Coding", "comments": "40 pages. An abbreviated conference version appears at AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse coding is a crucial subroutine in algorithms for various signal\nprocessing, deep learning, and other machine learning applications. The central\ngoal is to learn an overcomplete dictionary that can sparsely represent a given\ninput dataset. However, a key challenge is that storage, transmission, and\nprocessing of the learned dictionary can be untenably high if the data\ndimension is high. In this paper, we consider the double-sparsity model\nintroduced by Rubinstein et al. (2010b) where the dictionary itself is the\nproduct of a fixed, known basis and a data-adaptive sparse component. First, we\nintroduce a simple algorithm for double-sparse coding that can be amenable to\nefficient implementation via neural architectures. Second, we theoretically\nanalyze its performance and demonstrate asymptotic sample complexity and\nrunning time benefits over existing (provable) approaches for sparse coding. To\nour knowledge, our work introduces the first computationally efficient\nalgorithm for double-sparse coding that enjoys rigorous statistical guarantees.\nFinally, we support our analysis via several numerical experiments on simulated\ndata, confirming that our method can indeed be useful in problem sizes\nencountered in practical applications.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 23:06:15 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 22:20:25 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Nguyen", "Thanh V.", ""], ["Wong", "Raymond K. W.", ""], ["Hegde", "Chinmay", ""]]}, {"id": "1711.03639", "submitter": "Thodoris Lykouris", "authors": "Thodoris Lykouris, Karthik Sridharan, and Eva Tardos", "title": "Small-loss bounds for online learning with partial information", "comments": "The current version represents the content that will appear in\n  Mathematics of Operations Research. An extended abstract of the paper\n  appeared at the 31st Annual Conference on Learning Theory (COLT 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of adversarial (non-stochastic) online learning with\npartial information feedback, where at each round, a decision maker selects an\naction from a finite set of alternatives. We develop a black-box approach for\nsuch problems where the learner observes as feedback only losses of a subset of\nthe actions that includes the selected action. When losses of actions are\nnon-negative, under the graph-based feedback model introduced by Mannor and\nShamir, we offer algorithms that attain the so called \"small-loss\" $o(\\alpha\nL^{\\star})$ regret bounds with high probability, where $\\alpha$ is the\nindependence number of the graph, and $L^{\\star}$ is the loss of the best\naction. Prior to our work, there was no data-dependent guarantee for general\nfeedback graphs even for pseudo-regret (without dependence on the number of\nactions, i.e. utilizing the increased information feedback). Taking advantage\nof the black-box nature of our technique, we extend our results to many other\napplications such as semi-bandits (including routing in networks), contextual\nbandits (even with an infinite comparator class), as well as learning with\nslowly changing (shifting) comparators.\n  In the special case of classical bandit and semi-bandit problems, we provide\noptimal small-loss, high-probability guarantees of\n$\\tilde{O}(\\sqrt{dL^{\\star}})$ for actual regret, where $d$ is the number of\nactions, answering open questions of Neu. Previous bounds for bandits and\nsemi-bandits were known only for pseudo-regret and only in expectation. We also\noffer an optimal $\\tilde{O}(\\sqrt{\\kappa L^{\\star}})$ regret guarantee for\nfixed feedback graphs with clique-partition number at most $\\kappa$.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 23:06:55 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 01:13:42 GMT"}, {"version": "v3", "created": "Tue, 12 Jun 2018 05:12:21 GMT"}, {"version": "v4", "created": "Sat, 8 Feb 2020 16:41:42 GMT"}, {"version": "v5", "created": "Mon, 26 Jul 2021 19:01:09 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Lykouris", "Thodoris", ""], ["Sridharan", "Karthik", ""], ["Tardos", "Eva", ""]]}, {"id": "1711.03640", "submitter": "Anakha Vasanthakumari Babu", "authors": "Anakha V Babu, Bipin Rajendran", "title": "Stochastic Deep Learning in Memristive Networks", "comments": "4 pages, 5 figures, accepted at ICECS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the performance of stochastically trained deep neural networks\n(DNNs) whose synaptic weights are implemented using emerging memristive devices\nthat exhibit limited dynamic range, resolution, and variability in their\nprogramming characteristics. We show that a key device parameter to optimize\nthe learning efficiency of DNNs is the variability in its programming\ncharacteristics. DNNs with such memristive synapses, even with dynamic range as\nlow as $15$ and only $32$ discrete levels, when trained based on stochastic\nupdates suffer less than $3\\%$ loss in accuracy compared to floating point\nsoftware baseline. We also study the performance of stochastic memristive DNNs\nwhen used as inference engines with noise corrupted data and find that if the\ndevice variability can be minimized, the relative degradation in performance\nfor the Stochastic DNN is better than that of the software baseline. Hence, our\nstudy presents a new optimization corner for memristive devices for building\nlarge noise-immune deep learning systems.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 23:09:36 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Babu", "Anakha V", ""], ["Rajendran", "Bipin", ""]]}, {"id": "1711.03654", "submitter": "Anthony Perez", "authors": "Anthony Perez, Christopher Yeh, George Azzari, Marshall Burke, David\n  Lobell, Stefano Ermon", "title": "Poverty Prediction with Public Landsat 7 Satellite Imagery and Machine\n  Learning", "comments": "Presented at NIPS 2017 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining detailed and reliable data about local economic livelihoods in\ndeveloping countries is expensive, and data are consequently scarce. Previous\nwork has shown that it is possible to measure local-level economic livelihoods\nusing high-resolution satellite imagery. However, such imagery is relatively\nexpensive to acquire, often not updated frequently, and is mainly available for\nrecent years. We train CNN models on free and publicly available multispectral\ndaytime satellite images of the African continent from the Landsat 7 satellite,\nwhich has collected imagery with global coverage for almost two decades. We\nshow that despite these images' lower resolution, we can achieve accuracies\nthat exceed previous benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 00:21:54 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Perez", "Anthony", ""], ["Yeh", "Christopher", ""], ["Azzari", "George", ""], ["Burke", "Marshall", ""], ["Lobell", "David", ""], ["Ermon", "Stefano", ""]]}, {"id": "1711.03656", "submitter": "Se Eun Oh", "authors": "Se Eun Oh, Saikrishna Sunkam, Nicholas Hopper", "title": "p-FP: Extraction, Classification, and Prediction of Website Fingerprints\n  with Deep Learning", "comments": "Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in learning Deep Neural Network (DNN) architectures have\nreceived a great deal of attention due to their ability to outperform\nstate-of-the-art classifiers across a wide range of applications, with little\nor no feature engineering. In this paper, we broadly study the applicability of\ndeep learning to website fingerprinting. We show that unsupervised DNNs can be\nused to extract low-dimensional feature vectors that improve the performance of\nstate-of-the-art website fingerprinting attacks. When used as classifiers, we\nshow that they can match or exceed performance of existing attacks across a\nrange of application scenarios, including fingerprinting Tor website traces,\nfingerprinting search engine queries over Tor, defeating fingerprinting\ndefenses, and fingerprinting TLS-encrypted websites. Finally, we show that DNNs\ncan be used to predict the fingerprintability of a website based on its\ncontents, achieving 99% accuracy on a data set of 4500 website downloads.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 00:56:20 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2018 15:48:04 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Oh", "Se Eun", ""], ["Sunkam", "Saikrishna", ""], ["Hopper", "Nicholas", ""]]}, {"id": "1711.03674", "submitter": "Krzysztof J. Geras", "authors": "Nan Wu, Krzysztof J. Geras, Yiqiu Shen, Jingyi Su, S. Gene Kim, Eric\n  Kim, Stacey Wolfson, Linda Moy, Kyunghyun Cho", "title": "Breast density classification with deep convolutional neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast density classification is an essential part of breast cancer\nscreening. Although a lot of prior work considered this problem as a task for\nlearning algorithms, to our knowledge, all of them used small and not\nclinically realistic data both for training and evaluation of their models. In\nthis work, we explore the limits of this task with a data set coming from over\n200,000 breast cancer screening exams. We use this data to train and evaluate a\nstrong convolutional neural network classifier. In a reader study, we find that\nour model can perform this task comparably to a human expert.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 02:50:46 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Wu", "Nan", ""], ["Geras", "Krzysztof J.", ""], ["Shen", "Yiqiu", ""], ["Su", "Jingyi", ""], ["Kim", "S. Gene", ""], ["Kim", "Eric", ""], ["Wolfson", "Stacey", ""], ["Moy", "Linda", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1711.03676", "submitter": "Patrick M. Pilarski", "authors": "Patrick M. Pilarski, Richard S. Sutton, Kory W. Mathewson, Craig\n  Sherstan, Adam S. R. Parker, Ann L. Edwards", "title": "Communicative Capital for Prosthetic Agents", "comments": "33 pages, 10 figures; unpublished technical report undergoing peer\n  review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents an overarching perspective on the role that machine\nintelligence can play in enhancing human abilities, especially those that have\nbeen diminished due to injury or illness. As a primary contribution, we develop\nthe hypothesis that assistive devices, and specifically artificial arms and\nhands, can and should be viewed as agents in order for us to most effectively\nimprove their collaboration with their human users. We believe that increased\nagency will enable more powerful interactions between human users and next\ngeneration prosthetic devices, especially when the sensorimotor space of the\nprosthetic technology greatly exceeds the conventional control and\ncommunication channels available to a prosthetic user. To more concretely\nexamine an agency-based view on prosthetic devices, we propose a new schema for\ninterpreting the capacity of a human-machine collaboration as a function of\nboth the human's and machine's degrees of agency. We then introduce the idea of\ncommunicative capital as a way of thinking about the communication resources\ndeveloped by a human and a machine during their ongoing interaction. Using this\nschema of agency and capacity, we examine the benefits and disadvantages of\nincreasing the agency of a prosthetic limb. To do so, we present an analysis of\nexamples from the literature where building communicative capital has enabled a\nprogression of fruitful, task-directed interactions between prostheses and\ntheir human users. We then describe further work that is needed to concretely\nevaluate the hypothesis that prostheses are best thought of as agents. The\nagent-based viewpoint developed in this article significantly extends current\nthinking on how best to support the natural, functional use of increasingly\ncomplex prosthetic enhancements, and opens the door for more powerful\ninteractions between humans and their assistive technologies.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 03:19:59 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Pilarski", "Patrick M.", ""], ["Sutton", "Richard S.", ""], ["Mathewson", "Kory W.", ""], ["Sherstan", "Craig", ""], ["Parker", "Adam S. R.", ""], ["Edwards", "Ann L.", ""]]}, {"id": "1711.03678", "submitter": "Michael Janner", "authors": "Michael Janner, Jiajun Wu, Tejas D. Kulkarni, Ilker Yildirim, Joshua\n  B. Tenenbaum", "title": "Self-Supervised Intrinsic Image Decomposition", "comments": "NIPS 2017 camera-ready version, project page:\n  http://rin.csail.mit.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsic decomposition from a single image is a highly challenging task, due\nto its inherent ambiguity and the scarcity of training data. In contrast to\ntraditional fully supervised learning approaches, in this paper we propose\nlearning intrinsic image decomposition by explaining the input image. Our\nmodel, the Rendered Intrinsics Network (RIN), joins together an image\ndecomposition pipeline, which predicts reflectance, shape, and lighting\nconditions given a single image, with a recombination function, a learned\nshading model used to recompose the original input based off of intrinsic image\npredictions. Our network can then use unsupervised reconstruction error as an\nadditional signal to improve its intermediate representations. This allows\nlarge-scale unlabeled data to be useful during training, and also enables\ntransferring learned knowledge to images of unseen object categories, lighting\nconditions, and shapes. Extensive experiments demonstrate that our method\nperforms well on both intrinsic image decomposition and knowledge transfer.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 03:31:27 GMT"}, {"version": "v2", "created": "Mon, 5 Feb 2018 22:52:18 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Janner", "Michael", ""], ["Wu", "Jiajun", ""], ["Kulkarni", "Tejas D.", ""], ["Yildirim", "Ilker", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1711.03689", "submitter": "Taku Kato", "authors": "Taku Kato, Takahiro Shinozaki", "title": "Reinforcement Learning of Speech Recognition System Based on Policy\n  Gradient and Hypothesis Selection", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech recognition systems have achieved high recognition performance for\nseveral tasks. However, the performance of such systems is dependent on the\ntremendously costly development work of preparing vast amounts of task-matched\ntranscribed speech data for supervised training. The key problem here is the\ncost of transcribing speech data. The cost is repeatedly required to support\nnew languages and new tasks. Assuming broad network services for transcribing\nspeech data for many users, a system would become more self-sufficient and more\nuseful if it possessed the ability to learn from very light feedback from the\nusers without annoying them. In this paper, we propose a general reinforcement\nlearning framework for speech recognition systems based on the policy gradient\nmethod. As a particular instance of the framework, we also propose a hypothesis\nselection-based reinforcement learning method. The proposed framework provides\na new view for several existing training and adaptation methods. The\nexperimental results show that the proposed method improves the recognition\nperformance compared to unsupervised adaptation.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 04:42:44 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Kato", "Taku", ""], ["Shinozaki", "Takahiro", ""]]}, {"id": "1711.03705", "submitter": "Doyen Sahoo", "authors": "Doyen Sahoo, Quang Pham, Jing Lu, Steven C.H. Hoi", "title": "Online Deep Learning: Learning Deep Neural Networks on the Fly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are typically trained by backpropagation in a\nbatch learning setting, which requires the entire training data to be made\navailable prior to the learning task. This is not scalable for many real-world\nscenarios where new data arrives sequentially in a stream form. We aim to\naddress an open challenge of \"Online Deep Learning\" (ODL) for learning DNNs on\nthe fly in an online setting. Unlike traditional online learning that often\noptimizes some convex objective function with respect to a shallow model (e.g.,\na linear/kernel-based hypothesis), ODL is significantly more challenging since\nthe optimization of the DNN objective function is non-convex, and regular\nbackpropagation does not work well in practice, especially for online learning\nsettings. In this paper, we present a new online deep learning framework that\nattempts to tackle the challenges by learning DNN models of adaptive depth from\na sequence of training data in an online learning setting. In particular, we\npropose a novel Hedge Backpropagation (HBP) method for online updating the\nparameters of DNN effectively, and validate the efficacy of our method on\nlarge-scale data sets, including both stationary and concept drifting\nscenarios.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 05:54:14 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Sahoo", "Doyen", ""], ["Pham", "Quang", ""], ["Lu", "Jing", ""], ["Hoi", "Steven C. H.", ""]]}, {"id": "1711.03707", "submitter": "Mohammad Mahmoody", "authors": "Saeed Mahloujifar, Dimitrios I. Diochnos, Mohammad Mahmoody", "title": "Learning under $p$-Tampering Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Mahloujifar and Mahmoody (TCC'17) studied attacks against learning\nalgorithms using a special case of Valiant's malicious noise, called\n$p$-tampering, in which the adversary gets to change any training example with\nindependent probability $p$ but is limited to only choose malicious examples\nwith correct labels. They obtained $p$-tampering attacks that increase the\nerror probability in the so called targeted poisoning model in which the\nadversary's goal is to increase the loss of the trained hypothesis over a\nparticular test example. At the heart of their attack was an efficient\nalgorithm to bias the expected value of any bounded real-output function\nthrough $p$-tampering.\n  In this work, we present new biasing attacks for increasing the expected\nvalue of bounded real-valued functions. Our improved biasing attacks, directly\nimply improved $p$-tampering attacks against learners in the targeted poisoning\nmodel. As a bonus, our attacks come with considerably simpler analysis. We also\nstudy the possibility of PAC learning under $p$-tampering attacks in the\nnon-targeted (aka indiscriminate) setting where the adversary's goal is to\nincrease the risk of the generated hypothesis (for a random test example). We\nshow that PAC learning is possible under $p$-tampering poisoning attacks\nessentially whenever it is possible in the realizable setting without the\nattacks. We further show that PAC learning under \"correct-label\" adversarial\nnoise is not possible in general, if the adversary could choose the (still\nlimited to only $p$ fraction of) tampered examples that she substitutes with\nadversarially chosen ones. Our formal model for such \"bounded-budget\" tampering\nattackers is inspired by the notions of (strong) adaptive corruption in secure\nmulti-party computation.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 06:23:25 GMT"}, {"version": "v2", "created": "Thu, 30 Nov 2017 05:11:12 GMT"}, {"version": "v3", "created": "Tue, 1 May 2018 18:30:26 GMT"}, {"version": "v4", "created": "Tue, 27 Nov 2018 18:43:56 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Mahloujifar", "Saeed", ""], ["Diochnos", "Dimitrios I.", ""], ["Mahmoody", "Mohammad", ""]]}, {"id": "1711.03712", "submitter": "Seongsik Park", "authors": "Seongsik Park, Seijoon Kim, Seil Lee, Ho Bae, Sungroh Yoon", "title": "Quantized Memory-Augmented Neural Networks", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory-augmented neural networks (MANNs) refer to a class of neural network\nmodels equipped with external memory (such as neural Turing machines and memory\nnetworks). These neural networks outperform conventional recurrent neural\nnetworks (RNNs) in terms of learning long-term dependency, allowing them to\nsolve intriguing AI tasks that would otherwise be hard to address. This paper\nconcerns the problem of quantizing MANNs. Quantization is known to be effective\nwhen we deploy deep models on embedded systems with limited resources.\nFurthermore, quantization can substantially reduce the energy consumption of\nthe inference procedure. These benefits justify recent developments of\nquantized multi layer perceptrons, convolutional networks, and RNNs. However,\nno prior work has reported the successful quantization of MANNs. The in-depth\nanalysis presented here reveals various challenges that do not appear in the\nquantization of the other networks. Without addressing them properly, quantized\nMANNs would normally suffer from excessive quantization error which leads to\ndegraded performance. In this paper, we identify memory addressing\n(specifically, content-based addressing) as the main reason for the performance\ndegradation and propose a robust quantization method for MANNs to address the\nchallenge. In our experiments, we achieved a computation-energy gain of 22x\nwith 8-bit fixed-point and binary quantization compared to the floating-point\nimplementation. Measured on the bAbI dataset, the resulting model, named the\nquantized MANN (Q-MANN), improved the error rate by 46% and 30% with 8-bit\nfixed-point and binary quantization, respectively, compared to the MANN\nquantized using conventional techniques.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 06:54:45 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Park", "Seongsik", ""], ["Kim", "Seijoon", ""], ["Lee", "Seil", ""], ["Bae", "Ho", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1711.03736", "submitter": "Masoud Fatemi", "authors": "Masoud Fatemi and Mehran Safayani", "title": "Joint Sentiment/Topic Modeling on Text Data Using Boosted Restricted\n  Boltzmann Machine", "comments": null, "journal-ref": null, "doi": "10.1007/s11042-019-7427-5", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently by the development of the Internet and the Web, different types of\nsocial media such as web blogs become an immense source of text data. Through\nthe processing of these data, it is possible to discover practical information\nabout different topics, individuals opinions and a thorough understanding of\nthe society. Therefore, applying models which can automatically extract the\nsubjective information from the documents would be efficient and helpful. Topic\nmodeling methods, also sentiment analysis are the most raised topics in the\nnatural language processing and text mining fields. In this paper a new\nstructure for joint sentiment-topic modeling based on Restricted Boltzmann\nMachine (RBM) which is a type of neural networks is proposed. By modifying the\nstructure of RBM as well as appending a layer which is analogous to sentiment\nof text data to it, we propose a generative structure for joint sentiment topic\nmodeling based on neutral networks. The proposed method is supervised and\ntrained by the Contrastive Divergence algorithm. The new attached layer in the\nproposed model is a layer with the multinomial probability distribution which\ncan be used in text data sentiment classification or any other supervised\napplication. The proposed model is compared with existing models in the\nexperiments such as evaluating as a generative model, sentiment classification,\ninformation retrieval and the corresponding results demonstrate the efficiency\nof the method.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 09:17:02 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Fatemi", "Masoud", ""], ["Safayani", "Mehran", ""]]}, {"id": "1711.03822", "submitter": "Nicol\\`o Navarin", "authors": "Nicol\\`o Navarin, Beatrice Vincenzi, Mirko Polato and Alessandro\n  Sperduti", "title": "LSTM Networks for Data-Aware Remaining Time Prediction of Business\n  Process Instances", "comments": "Article accepted for publication in 2017 IEEE Symposium on Deep\n  Learning (IEEE DL'17) @ SSCI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the completion time of business process instances would be a very\nhelpful aid when managing processes under service level agreement constraints.\nThe ability to know in advance the trend of running process instances would\nallow business managers to react in time, in order to prevent delays or\nundesirable situations. However, making such accurate forecasts is not easy:\nmany factors may influence the required time to complete a process instance. In\nthis paper, we propose an approach based on deep Recurrent Neural Networks\n(specifically LSTMs) that is able to exploit arbitrary information associated\nto single events, in order to produce an as-accurate-as-possible prediction of\nthe completion time of running instances. Experiments on real-world datasets\nconfirm the quality of our proposal.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 13:58:43 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Navarin", "Nicol\u00f2", ""], ["Vincenzi", "Beatrice", ""], ["Polato", "Mirko", ""], ["Sperduti", "Alessandro", ""]]}, {"id": "1711.03905", "submitter": "Jayaraman J. Thiagarajan", "authors": "Huan Song, Deepta Rajan, Jayaraman J. Thiagarajan and Andreas Spanias", "title": "Attend and Diagnose: Clinical Time Series Analysis using Attention\n  Models", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With widespread adoption of electronic health records, there is an increased\nemphasis for predictive models that can effectively deal with clinical\ntime-series data. Powered by Recurrent Neural Network (RNN) architectures with\nLong Short-Term Memory (LSTM) units, deep neural networks have achieved\nstate-of-the-art results in several clinical prediction tasks. Despite the\nsuccess of RNNs, its sequential nature prohibits parallelized computing, thus\nmaking it inefficient particularly when processing long sequences. Recently,\narchitectures which are based solely on attention mechanisms have shown\nremarkable success in transduction tasks in NLP, while being computationally\nsuperior. In this paper, for the first time, we utilize attention models for\nclinical time-series modeling, thereby dispensing recurrence entirely. We\ndevelop the \\textit{SAnD} (Simply Attend and Diagnose) architecture, which\nemploys a masked, self-attention mechanism, and uses positional encoding and\ndense interpolation strategies for incorporating temporal order. Furthermore,\nwe develop a multi-task variant of \\textit{SAnD} to jointly infer models with\nmultiple diagnosis tasks. Using the recent MIMIC-III benchmark datasets, we\ndemonstrate that the proposed approach achieves state-of-the-art performance in\nall tasks, outperforming LSTM models and classical baselines with\nhand-engineered features.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 16:26:14 GMT"}, {"version": "v2", "created": "Sun, 19 Nov 2017 21:19:12 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Song", "Huan", ""], ["Rajan", "Deepta", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Spanias", "Andreas", ""]]}, {"id": "1711.03906", "submitter": "Amr Alanwar", "authors": "Amr Alanwar, Henrique Ferraz, Kevin Hsieh, Rohit Thazhath, Paul\n  Martin, Joao Hespanha, Mani Srivastava", "title": "D-SLATS: Distributed Simultaneous Localization and Time Synchronization", "comments": null, "journal-ref": null, "doi": "10.1145/3084041.3084049", "report-no": null, "categories": "cs.LG cs.DC cs.NI cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through the last decade, we have witnessed a surge of Internet of Things\n(IoT) devices, and with that a greater need to choreograph their actions across\nboth time and space. Although these two problems, namely time synchronization\nand localization, share many aspects in common, they are traditionally treated\nseparately or combined on centralized approaches that results in an ineffcient\nuse of resources, or in solutions that are not scalable in terms of the number\nof IoT devices. Therefore, we propose D-SLATS, a framework comprised of three\ndifferent and independent algorithms to jointly solve time synchronization and\nlocalization problems in a distributed fashion. The First two algorithms are\nbased mainly on the distributed Extended Kalman Filter (EKF) whereas the third\none uses optimization techniques. No fusion center is required, and the devices\nonly communicate with their neighbors. The proposed methods are evaluated on\ncustom Ultra-Wideband communication Testbed and a quadrotor, representing a\nnetwork of both static and mobile nodes. Our algorithms achieve up to three\nmicroseconds time synchronization accuracy and 30 cm localization error.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 16:26:29 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Alanwar", "Amr", ""], ["Ferraz", "Henrique", ""], ["Hsieh", "Kevin", ""], ["Thazhath", "Rohit", ""], ["Martin", "Paul", ""], ["Hespanha", "Joao", ""], ["Srivastava", "Mani", ""]]}, {"id": "1711.03937", "submitter": "Zhouyuan Huo", "authors": "Zhouyuan Huo, Bin Gu, Ji Liu, Heng Huang", "title": "Accelerated Method for Stochastic Composition Optimization with\n  Nonsmooth Regularization", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic composition optimization draws much attention recently and has\nbeen successful in many emerging applications of machine learning, statistical\nanalysis, and reinforcement learning. In this paper, we focus on the\ncomposition problem with nonsmooth regularization penalty. Previous works\neither have slow convergence rate or do not provide complete convergence\nanalysis for the general problem. In this paper, we tackle these two issues by\nproposing a new stochastic composition optimization method for composition\nproblem with nonsmooth regularization penalty. In our method, we apply variance\nreduction technique to accelerate the speed of convergence. To the best of our\nknowledge, our method admits the fastest convergence rate for stochastic\ncomposition optimization: for strongly convex composition problem, our\nalgorithm is proved to admit linear convergence; for general composition\nproblem, our algorithm significantly improves the state-of-the-art convergence\nrate from $O(T^{-1/2})$ to $O((n_1+n_2)^{{2}/{3}}T^{-1})$. Finally, we apply\nour proposed algorithm to portfolio management and policy evaluation in\nreinforcement learning. Experimental results verify our theoretical analysis.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 17:48:27 GMT"}, {"version": "v2", "created": "Fri, 29 Dec 2017 00:20:49 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Huo", "Zhouyuan", ""], ["Gu", "Bin", ""], ["Liu", "Ji", ""], ["Huang", "Heng", ""]]}, {"id": "1711.03938", "submitter": "Alexey Dosovitskiy", "authors": "Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio Lopez,\n  Vladlen Koltun", "title": "CARLA: An Open Urban Driving Simulator", "comments": "Published at the 1st Conference on Robot Learning (CoRL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce CARLA, an open-source simulator for autonomous driving research.\nCARLA has been developed from the ground up to support development, training,\nand validation of autonomous urban driving systems. In addition to open-source\ncode and protocols, CARLA provides open digital assets (urban layouts,\nbuildings, vehicles) that were created for this purpose and can be used freely.\nThe simulation platform supports flexible specification of sensor suites and\nenvironmental conditions. We use CARLA to study the performance of three\napproaches to autonomous driving: a classic modular pipeline, an end-to-end\nmodel trained via imitation learning, and an end-to-end model trained via\nreinforcement learning. The approaches are evaluated in controlled scenarios of\nincreasing difficulty, and their performance is examined via metrics provided\nby CARLA, illustrating the platform's utility for autonomous driving research.\nThe supplementary video can be viewed at https://youtu.be/Hp8Dz-Zek2E\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 17:54:40 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Dosovitskiy", "Alexey", ""], ["Ros", "German", ""], ["Codevilla", "Felipe", ""], ["Lopez", "Antonio", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1711.03946", "submitter": "Robert Bamler", "authors": "Geng Ji, Robert Bamler, Erik B. Sudderth, Stephan Mandt", "title": "Bayesian Paragraph Vectors", "comments": "Presented at the NIPS 2017 workshop \"Advances in Approximate Bayesian\n  Inference\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word2vec (Mikolov et al., 2013) has proven to be successful in natural\nlanguage processing by capturing the semantic relationships between different\nwords. Built on top of single-word embeddings, paragraph vectors (Le and\nMikolov, 2014) find fixed-length representations for pieces of text with\narbitrary lengths, such as documents, paragraphs, and sentences. In this work,\nwe propose a novel interpretation for neural-network-based paragraph vectors by\ndeveloping an unsupervised generative model whose maximum likelihood solution\ncorresponds to traditional paragraph vectors. This probabilistic formulation\nallows us to go beyond point estimates of parameters and to perform Bayesian\nposterior inference. We find that the entropy of paragraph vectors decreases\nwith the length of documents, and that information about posterior uncertainty\nimproves performance in supervised learning tasks such as sentiment analysis\nand paraphrase detection.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 18:09:15 GMT"}, {"version": "v2", "created": "Thu, 7 Dec 2017 20:37:31 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Ji", "Geng", ""], ["Bamler", "Robert", ""], ["Sudderth", "Erik B.", ""], ["Mandt", "Stephan", ""]]}, {"id": "1711.03953", "submitter": "Zhilin Yang", "authors": "Zhilin Yang, Zihang Dai, Ruslan Salakhutdinov, William W. Cohen", "title": "Breaking the Softmax Bottleneck: A High-Rank RNN Language Model", "comments": "ICLR Oral 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate language modeling as a matrix factorization problem, and show\nthat the expressiveness of Softmax-based models (including the majority of\nneural language models) is limited by a Softmax bottleneck. Given that natural\nlanguage is highly context-dependent, this further implies that in practice\nSoftmax with distributed word embeddings does not have enough capacity to model\nnatural language. We propose a simple and effective method to address this\nissue, and improve the state-of-the-art perplexities on Penn Treebank and\nWikiText-2 to 47.69 and 40.68 respectively. The proposed method also excels on\nthe large-scale 1B Word dataset, outperforming the baseline by over 5.6 points\nin perplexity.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 18:29:00 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 20:40:35 GMT"}, {"version": "v3", "created": "Fri, 9 Feb 2018 01:15:08 GMT"}, {"version": "v4", "created": "Fri, 2 Mar 2018 20:20:52 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Yang", "Zhilin", ""], ["Dai", "Zihang", ""], ["Salakhutdinov", "Ruslan", ""], ["Cohen", "William W.", ""]]}, {"id": "1711.03985", "submitter": "Mufti Mahmud", "authors": "Mufti Mahmud, M. Shamim Kaiser, Amir Hussain, Stefano Vassanelli", "title": "Applications of Deep Learning and Reinforcement Learning to Biological\n  Data", "comments": "33 pages, 5 figures, 1 table, survey paper, IEEE Trans. Neural Netw.\n  Learn. Syst., 2018", "journal-ref": null, "doi": "10.1109/TNNLS.2018.2790388", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Rapid advances of hardware-based technologies during the past decades have\nopened up new possibilities for Life scientists to gather multimodal data in\nvarious application domains (e.g., Omics, Bioimaging, Medical Imaging, and\n[Brain/Body]-Machine Interfaces), thus generating novel opportunities for\ndevelopment of dedicated data intensive machine learning techniques. Overall,\nrecent research in Deep learning (DL), Reinforcement learning (RL), and their\ncombination (Deep RL) promise to revolutionize Artificial Intelligence. The\ngrowth in computational power accompanied by faster and increased data storage\nand declining computing costs have already allowed scientists in various fields\nto apply these techniques on datasets that were previously intractable for\ntheir size and complexity. This review article provides a comprehensive survey\non the application of DL, RL, and Deep RL techniques in mining Biological data.\nIn addition, we compare performances of DL techniques when applied to different\ndatasets across various application domains. Finally, we outline open issues in\nthis challenging research area and discuss future development perspectives.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 19:06:46 GMT"}, {"version": "v2", "created": "Sun, 7 Jan 2018 07:06:20 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Mahmud", "Mufti", ""], ["Kaiser", "M. Shamim", ""], ["Hussain", "Amir", ""], ["Vassanelli", "Stefano", ""]]}, {"id": "1711.04015", "submitter": "Kuan Liu", "authors": "Kuan Liu and Prem Natarajan", "title": "WMRB: Learning to Rank in a Scalable Batch Training Approach", "comments": "RecSys 2017 Poster Proceedings, August 27-31, Como, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new learning to rank algorithm, named Weighted Margin-Rank Batch\nloss (WMRB), to extend the popular Weighted Approximate-Rank Pairwise loss\n(WARP). WMRB uses a new rank estimator and an efficient batch training\nalgorithm. The approach allows more accurate item rank approximation and\nexplicit utilization of parallel computation to accelerate training. In three\nitem recommendation tasks, WMRB consistently outperforms WARP and other\nbaselines. Moreover, WMRB shows clear time efficiency advantages as data scale\nincreases.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 21:18:21 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Liu", "Kuan", ""], ["Natarajan", "Prem", ""]]}, {"id": "1711.04019", "submitter": "Kuan Liu", "authors": "Kuan Liu and Prem Natarajan", "title": "A Batch Learning Framework for Scalable Personalized Ranking", "comments": "AAAI 2018, Feb 2-7, New Orleans, USA", "journal-ref": "AAAI Conference on Artificial Intelligence 2018; Thirty-Second\n  AAAI Conference on Artificial Intelligence", "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In designing personalized ranking algorithms, it is desirable to encourage a\nhigh precision at the top of the ranked list. Existing methods either seek a\nsmooth convex surrogate for a non-smooth ranking metric or directly modify\nupdating procedures to encourage top accuracy. In this work we point out that\nthese methods do not scale well to a large-scale setting, and this is partly\ndue to the inaccurate pointwise or pairwise rank estimation. We propose a new\nframework for personalized ranking. It uses batch-based rank estimators and\nsmooth rank-sensitive loss functions. This new batch learning framework leads\nto more stable and accurate rank approximations compared to previous work.\nMoreover, it enables explicit use of parallel computation to speed up training.\nWe conduct empirical evaluation on three item recommendation tasks. Our method\nshows consistent accuracy improvements over state-of-the-art methods.\nAdditionally, we observe time efficiency advantages when data scale increases.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 21:25:30 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Liu", "Kuan", ""], ["Natarajan", "Prem", ""]]}, {"id": "1711.04022", "submitter": "Hamid Eghbal-zadeh", "authors": "Hamid Eghbal-zadeh, Matthias Dorfer and Gerhard Widmer", "title": "Deep Within-Class Covariance Analysis for Robust Audio Representation\n  Learning", "comments": "11 pages, 3 tables, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) can learn effective features, though\nhave been shown to suffer from a performance drop when the distribution of the\ndata changes from training to test data. In this paper we analyze the internal\nrepresentations of CNNs and observe that the representations of unseen data in\neach class, spread more (with higher variance) in the embedding space of the\nCNN compared to representations of the training data. More importantly, this\ndifference is more extreme if the unseen data comes from a shifted\ndistribution. Based on this observation, we objectively evaluate the degree of\nrepresentation's variance in each class via eigenvalue decomposition on the\nwithin-class covariance of the internal representations of CNNs and observe the\nsame behaviour. This can be problematic as larger variances might lead to\nmis-classification if the sample crosses the decision boundary of its class. We\napply nearest neighbor classification on the representations and empirically\nshow that the embeddings with the high variance actually have significantly\nworse KNN classification performances, although this could not be foreseen from\ntheir end-to-end classification results. To tackle this problem, we propose\nDeep Within-Class Covariance Analysis (DWCCA), a deep neural network layer that\nsignificantly reduces the within-class covariance of a DNN's representation,\nimproving performance on unseen test data from a shifted distribution. We\nempirically evaluate DWCCA on two datasets for Acoustic Scene Classification\n(DCASE2016 and DCASE2017). We demonstrate that not only does DWCCA\nsignificantly improve the network's internal representation, it also increases\nthe end-to-end classification accuracy, especially when the test set exhibits a\ndistribution shift. By adding DWCCA to a VGG network, we achieve around 6\npercentage points improvement in the case of a distribution mismatch.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 21:39:12 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 09:48:48 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Eghbal-zadeh", "Hamid", ""], ["Dorfer", "Matthias", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1711.04030", "submitter": "Zhen Huang", "authors": "Zhen Huang and David Lie", "title": "Ocasta: Clustering Configuration Settings For Error Recovery", "comments": "Published in Proceedings of the 44th Annual IEEE/IFIP International\n  Conference on Dependable Systems and Networks (DSN 2014)", "journal-ref": "44th Annual IEEE/IFIP International Conference on Dependable\n  Systems and Networks, 2014, pages={479-490}", "doi": "10.1109/DSN.2014.51", "report-no": null, "categories": "cs.SE cs.LG cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective machine-aided diagnosis and repair of configuration errors\ncontinues to elude computer systems designers. Most of the literature targets\nerrors that can be attributed to a single erroneous configuration setting.\nHowever, a recent study found that a significant amount of configuration errors\nrequire fixing more than one setting together. To address this limitation,\nOcasta statistically clusters dependent configuration settings based on the\napplication's accesses to its configuration settings and utilizes the extracted\nclustering of configuration settings to fix configuration errors involving more\nthan one configuration settings. Ocasta treats applications as black-boxes and\nonly relies on the ability to observe application accesses to their\nconfiguration settings.\n  We collected traces of real application usage from 24 Linux and 5 Windows\ndesktops computers and found that Ocasta is able to correctly identify clusters\nwith 88.6% accuracy. To demonstrate the effectiveness of Ocasta, we evaluated\nit on 16 real-world configuration errors of 11 Linux and Windows applications.\nOcasta is able to successfully repair all evaluated configuration errors in 11\nminutes on average and only requires the user to examine an average of 3\nscreenshots of the output of the application to confirm that the error is\nrepaired. A user study we conducted shows that Ocasta is easy to use by both\nexpert and non-expert users and is more efficient than manual configuration\nerror troubleshooting.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 15:45:05 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Huang", "Zhen", ""], ["Lie", "David", ""]]}, {"id": "1711.04043", "submitter": "Victor Garcia Satorras", "authors": "Victor Garcia, Joan Bruna", "title": "Few-Shot Learning with Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to study the problem of few-shot learning with the prism of\ninference on a partially observed graphical model, constructed from a\ncollection of input images whose label can be either observed or not. By\nassimilating generic message-passing inference algorithms with their\nneural-network counterparts, we define a graph neural network architecture that\ngeneralizes several of the recently proposed few-shot learning models. Besides\nproviding improved numerical performance, our framework is easily extended to\nvariants of few-shot learning, such as semi-supervised or active learning,\ndemonstrating the ability of graph-based models to operate well on 'relational'\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 23:32:47 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 12:13:06 GMT"}, {"version": "v3", "created": "Tue, 20 Feb 2018 16:52:36 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Garcia", "Victor", ""], ["Bruna", "Joan", ""]]}, {"id": "1711.04044", "submitter": "Sahil Garg", "authors": "Sahil Garg and Aram Galstyan and Greg Ver Steeg and Irina Rish and\n  Guillermo Cecchi and Shuyang Gao", "title": "Kernelized Hashcode Representations for Relation Extraction", "comments": "To appear in the proceedings of conference, AAAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods have produced state-of-the-art results for a number of NLP\ntasks such as relation extraction, but suffer from poor scalability due to the\nhigh cost of computing kernel similarities between natural language structures.\nA recently proposed technique, kernelized locality-sensitive hashing (KLSH),\ncan significantly reduce the computational cost, but is only applicable to\nclassifiers operating on kNN graphs. Here we propose to use random subspaces of\nKLSH codes for efficiently constructing an explicit representation of NLP\nstructures suitable for general classification methods. Further, we propose an\napproach for optimizing the KLSH model for classification problems by\nmaximizing an approximation of mutual information between the KLSH codes\n(feature vectors) and the class labels. We evaluate the proposed approach on\nbiomedical relation extraction datasets, and observe significant and robust\nimprovements in accuracy w.r.t. state-of-the-art classifiers, along with\ndrastic (orders-of-magnitude) speedup compared to conventional kernel methods.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 23:42:42 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 23:10:27 GMT"}, {"version": "v3", "created": "Fri, 17 Aug 2018 16:28:56 GMT"}, {"version": "v4", "created": "Wed, 31 Oct 2018 22:48:42 GMT"}, {"version": "v5", "created": "Mon, 3 Dec 2018 17:17:25 GMT"}, {"version": "v6", "created": "Mon, 25 Feb 2019 04:10:53 GMT"}, {"version": "v7", "created": "Mon, 20 May 2019 22:01:52 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Garg", "Sahil", ""], ["Galstyan", "Aram", ""], ["Steeg", "Greg Ver", ""], ["Rish", "Irina", ""], ["Cecchi", "Guillermo", ""], ["Gao", "Shuyang", ""]]}, {"id": "1711.04094", "submitter": "Junliang Guo", "authors": "Junliang Guo, Linli Xu, Xunpeng Huang, Enhong Chen", "title": "Enhancing Network Embedding with Auxiliary Information: An Explicit\n  Matrix Factorization Perspective", "comments": "DASFAA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in the field of network embedding have shown the\nlow-dimensional network representation is playing a critical role in network\nanalysis. However, most of the existing principles of network embedding do not\nincorporate auxiliary information such as content and labels of nodes flexibly.\nIn this paper, we take a matrix factorization perspective of network embedding,\nand incorporate structure, content and label information of the network\nsimultaneously. For structure, we validate that the matrix we construct\npreserves high-order proximities of the network. Label information can be\nfurther integrated into the matrix via the process of random walk sampling to\nenhance the quality of embedding in an unsupervised manner, i.e., without\nleveraging downstream classifiers. In addition, we generalize the Skip-Gram\nNegative Sampling model to integrate the content of the network in a matrix\nfactorization framework. As a consequence, network embedding can be learned in\na unified framework integrating network structure and node content as well as\nlabel information simultaneously. We demonstrate the efficacy of the proposed\nmodel with the tasks of semi-supervised node classification and link prediction\non a variety of real-world benchmark network datasets.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 08:07:23 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 03:39:23 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Guo", "Junliang", ""], ["Xu", "Linli", ""], ["Huang", "Xunpeng", ""], ["Chen", "Enhong", ""]]}, {"id": "1711.04126", "submitter": "Uiwon Hwang", "authors": "Uiwon Hwang, Sungwoon Choi, Han-Byoel Lee, Sungroh Yoon", "title": "Adversarial Training for Disease Prediction from Electronic Health\n  Records with Missing Data", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health records (EHRs) have contributed to the computerization of\npatient records and can thus be used not only for efficient and systematic\nmedical services, but also for research on biomedical data science. However,\nthere are many missing values in EHRs when provided in matrix form, which is an\nimportant issue in many biomedical EHR applications. In this paper, we propose\na two-stage framework that includes missing data imputation and disease\nprediction to address the missing data problem in EHRs. We compared the disease\nprediction performance of generative adversarial networks (GANs) and\nconventional learning algorithms in combination with missing data prediction\nmethods. As a result, we obtained a level of accuracy of 0.9777, sensitivity of\n0.9521, specificity of 0.9925, area under the receiver operating characteristic\ncurve (AUC-ROC) of 0.9889, and F-score of 0.9688 with a stacked autoencoder as\nthe missing data prediction method and an auxiliary classifier GAN (AC-GAN) as\nthe disease prediction method. The comparison results show that a combination\nof a stacked autoencoder and an AC-GAN significantly outperforms other existing\napproaches. Our results suggest that the proposed framework is more robust for\ndisease prediction from EHRs with missing data.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 12:32:01 GMT"}, {"version": "v2", "created": "Thu, 18 Jan 2018 13:41:08 GMT"}, {"version": "v3", "created": "Tue, 1 May 2018 09:14:33 GMT"}, {"version": "v4", "created": "Tue, 22 May 2018 02:41:02 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Hwang", "Uiwon", ""], ["Choi", "Sungwoon", ""], ["Lee", "Han-Byoel", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1711.04150", "submitter": "Supriya Pandhre", "authors": "Supriya Pandhre, Himangi Mittal, Manish Gupta, Vineeth N\n  Balasubramanian", "title": "STWalk: Learning Trajectory Representations in Temporal Graphs", "comments": "10 pages, 5 figures, 2 tables", "journal-ref": null, "doi": "10.1145/3152494.3152512", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Analyzing the temporal behavior of nodes in time-varying graphs is useful for\nmany applications such as targeted advertising, community evolution and outlier\ndetection. In this paper, we present a novel approach, STWalk, for learning\ntrajectory representations of nodes in temporal graphs. The proposed framework\nmakes use of structural properties of graphs at current and previous time-steps\nto learn effective node trajectory representations. STWalk performs random\nwalks on a graph at a given time step (called space-walk) as well as on graphs\nfrom past time-steps (called time-walk) to capture the spatio-temporal behavior\nof nodes. We propose two variants of STWalk to learn trajectory\nrepresentations. In one algorithm, we perform space-walk and time-walk as part\nof a single step. In the other variant, we perform space-walk and time-walk\nseparately and combine the learned representations to get the final trajectory\nembedding. Extensive experiments on three real-world temporal graph datasets\nvalidate the effectiveness of the learned representations when compared to\nthree baseline methods. We also show the goodness of the learned trajectory\nembeddings for change point detection, as well as demonstrate that arithmetic\noperations on these trajectory representations yield interesting and\ninterpretable results.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 15:19:27 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Pandhre", "Supriya", ""], ["Mittal", "Himangi", ""], ["Gupta", "Manish", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "1711.04162", "submitter": "Wenting Ye", "authors": "Wenting Ye, Xiang Liu, Haohan Wang and Eric P. Xing", "title": "A Sparse Graph-Structured Lasso Mixed Model for Genetic Association with\n  Confounding Correction", "comments": "Code available at https://github.com/YeWenting/sGLMM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While linear mixed model (LMM) has shown a competitive performance in\ncorrecting spurious associations raised by population stratification, family\nstructures, and cryptic relatedness, more challenges are still to be addressed\nregarding the complex structure of genotypic and phenotypic data. For example,\ngeneticists have discovered that some clusters of phenotypes are more\nco-expressed than others. Hence, a joint analysis that can utilize such\nrelatedness information in a heterogeneous data set is crucial for genetic\nmodeling.\n  We proposed the sparse graph-structured linear mixed model (sGLMM) that can\nincorporate the relatedness information from traits in a dataset with\nconfounding correction. Our method is capable of uncovering the genetic\nassociations of a large number of phenotypes together while considering the\nrelatedness of these phenotypes. Through extensive simulation experiments, we\nshow that the proposed model outperforms other existing approaches and can\nmodel correlation from both population structure and shared signals. Further,\nwe validate the effectiveness of sGLMM in the real-world genomic dataset on two\ndifferent species from plants and humans. In Arabidopsis thaliana data, sGLMM\nbehaves better than all other baseline models for 63.4% traits. We also discuss\nthe potential causal genetic variation of Human Alzheimer's disease discovered\nby our model and justify some of the most important genetic loci.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 16:01:53 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Ye", "Wenting", ""], ["Liu", "Xiang", ""], ["Wang", "Haohan", ""], ["Xing", "Eric P.", ""]]}, {"id": "1711.04168", "submitter": "Maksims Volkovs", "authors": "Chundi Liu, Shunan Zhao, Maksims Volkovs", "title": "Unsupervised Document Embedding With CNNs", "comments": "Major revision with additional experiments and model description", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new model for unsupervised document embedding. Leading existing\napproaches either require complex inference or use recurrent neural networks\n(RNN) that are difficult to parallelize. We take a different route and develop\na convolutional neural network (CNN) embedding model. Our CNN architecture is\nfully parallelizable resulting in over 10x speedup in inference time over RNN\nmodels. Parallelizable architecture enables to train deeper models where each\nsuccessive layer has increasingly larger receptive field and models longer\nrange semantic structure within the document. We additionally propose a fully\nunsupervised learning algorithm to train this model based on stochastic forward\nprediction. Empirical results on two public benchmarks show that our approach\nproduces comparable to state-of-the-art accuracy at a fraction of computational\ncost.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 16:43:38 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 17:33:30 GMT"}, {"version": "v3", "created": "Tue, 20 Feb 2018 01:54:17 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Liu", "Chundi", ""], ["Zhao", "Shunan", ""], ["Volkovs", "Maksims", ""]]}, {"id": "1711.04178", "submitter": "Keaton Hamm", "authors": "Akram Aldroubi, Keaton Hamm, Ahmet Bugra Koku, and Ali Sekmen", "title": "CUR Decompositions, Similarity Matrices, and Subspace Clustering", "comments": "Approximately 30 pages. Current version contains improved algorithm\n  and numerical experiments from the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general framework for solving the subspace clustering problem using the CUR\ndecomposition is presented. The CUR decomposition provides a natural way to\nconstruct similarity matrices for data that come from a union of unknown\nsubspaces $\\mathscr{U}=\\underset{i=1}{\\overset{M}\\bigcup}S_i$. The similarity\nmatrices thus constructed give the exact clustering in the noise-free case.\nAdditionally, this decomposition gives rise to many distinct similarity\nmatrices from a given set of data, which allow enough flexibility to perform\naccurate clustering of noisy data. We also show that two known methods for\nsubspace clustering can be derived from the CUR decomposition. An algorithm\nbased on the theoretical construction of similarity matrices is presented, and\nexperiments on synthetic and real data are presented to test the method.\n  Additionally, an adaptation of our CUR based similarity matrices is utilized\nto provide a heuristic algorithm for subspace clustering; this algorithm yields\nthe best overall performance to date for clustering the Hopkins155 motion\nsegmentation dataset.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 18:34:34 GMT"}, {"version": "v2", "created": "Fri, 14 Sep 2018 21:14:03 GMT"}, {"version": "v3", "created": "Tue, 11 Dec 2018 20:53:22 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Aldroubi", "Akram", ""], ["Hamm", "Keaton", ""], ["Koku", "Ahmet Bugra", ""], ["Sekmen", "Ali", ""]]}, {"id": "1711.04181", "submitter": "Diego Marcondes", "authors": "Diego Marcondes, Adilson Simonis and Junior Barrera", "title": "Feature Selection based on the Local Lift Dependence Scale", "comments": null, "journal-ref": null, "doi": "10.3390/e20020097", "report-no": null, "categories": "stat.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper uses a classical approach to feature selection: minimization of a\ncost function applied on estimated joint distributions. However, the search\nspace in which such minimization is performed is extended. In the original\nformulation, the search space is the Boolean lattice of features sets (BLFS),\nwhile, in the present formulation, it is a collection of Boolean lattices of\nordered pairs (features, associated value) (CBLOP), indexed by the elements of\nthe BLFS. In this approach, we may not only select the features that are most\nrelated to a variable Y, but also select the values of the features that most\ninfluence the variable or that are most prone to have a specific value of Y. A\nlocal formulation of Shanon's mutual information is applied on a CBLOP to\nselect features, namely, the Local Lift Dependence Scale, an scale for\nmeasuring variable dependence in multiple resolutions. The main contribution of\nthis paper is to define and apply this local measure, which permits to analyse\nlocal properties of joint distributions that are neglected by the classical\nShanon's global measure. The proposed approach is applied to a dataset\nconsisting of student performances on a university entrance exam, as well as on\nundergraduate courses. The approach is also applied to two datasets of the UCI\nMachine Learning Repository.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 18:51:13 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 10:34:57 GMT"}, {"version": "v3", "created": "Mon, 18 Dec 2017 20:03:31 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Marcondes", "Diego", ""], ["Simonis", "Adilson", ""], ["Barrera", "Junior", ""]]}, {"id": "1711.04213", "submitter": "Albert Cheu", "authors": "Albert Cheu, Ravi Sundaram, Jonathan Ullman", "title": "Skyline Identification in Multi-Armed Bandits", "comments": "18 pages, 2 Figures; an ALT'18/ISIT'18 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a variant of the classical PAC multi-armed bandit problem. There\nis an ordered set of $n$ arms $A[1],\\dots,A[n]$, each with some stochastic\nreward drawn from some unknown bounded distribution. The goal is to identify\nthe $skyline$ of the set $A$, consisting of all arms $A[i]$ such that $A[i]$\nhas larger expected reward than all lower-numbered arms $A[1],\\dots,A[i-1]$. We\ndefine a natural notion of an $\\varepsilon$-approximate skyline and prove\nmatching upper and lower bounds for identifying an $\\varepsilon$-skyline.\nSpecifically, we show that in order to identify an $\\varepsilon$-skyline from\namong $n$ arms with probability $1-\\delta$, $$\n\\Theta\\bigg(\\frac{n}{\\varepsilon^2} \\cdot \\min\\bigg\\{\n\\log\\bigg(\\frac{1}{\\varepsilon \\delta}\\bigg), \\log\\bigg(\\frac{n}{\\delta}\\bigg)\n\\bigg\\} \\bigg) $$ samples are necessary and sufficient. When $\\varepsilon \\gg\n1/n$, our results improve over the naive algorithm, which draws enough samples\nto approximate the expected reward of every arm; the algorithm of (Auer et al.,\nAISTATS'16) for Pareto-optimal arm identification is likewise superseded. Our\nresults show that the sample complexity of the skyline problem lies strictly in\nbetween that of best arm identification (Even-Dar et al., COLT'02) and that of\napproximating the expected reward of every arm.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 00:35:02 GMT"}, {"version": "v2", "created": "Tue, 9 Jan 2018 19:05:10 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Cheu", "Albert", ""], ["Sundaram", "Ravi", ""], ["Ullman", "Jonathan", ""]]}, {"id": "1711.04237", "submitter": "Shiqi Yang", "authors": "Shiqi Yang and Gang Peng", "title": "D-PCN: Parallel Convolutional Networks for Image Recognition via a\n  Discriminator", "comments": "20 pages, 8 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a simple but quite effective recognition\nframework dubbed D-PCN, aiming at enhancing feature extracting ability of CNN.\nThe framework consists of two parallel CNNs, a discriminator and an extra\nclassifier which takes integrated features from parallel networks and gives\nfinal prediction. The discriminator is core which drives parallel networks to\nfocus on different regions and learn complementary representations. The\ncorresponding joint training strategy is introduced which ensures the\nutilization of discriminator. We validate D-PCN with several CNN models on two\nbenchmark datasets: CIFAR-100 and ImageNet32x32, D-PCN enhances all models. In\nparticular it yields state of the art performance on CIFAR-100 compared with\nrelated works. We also conduct visualization experiment on fine-grained\nStanford Dogs dataset and verify our motivation. Additionally, we apply D-PCN\nfor segmentation on PASCAL VOC 2012 and also find promotion.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 05:11:42 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 01:29:55 GMT"}, {"version": "v3", "created": "Wed, 14 Mar 2018 13:55:43 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Yang", "Shiqi", ""], ["Peng", "Gang", ""]]}, {"id": "1711.04248", "submitter": "Yunsung Kim", "authors": "Yunsung Kim", "title": "Linking Sequences of Events with Sparse or No Common Occurrence across\n  Data Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data of practical interest - such as personal records, transaction logs, and\nmedical histories - are sequential collections of events relevant to a\nparticular source entity. Recent studies have attempted to link sequences that\nrepresent a common entity across data sets to allow more comprehensive\nstatistical analyses and to identify potential privacy failures. Yet, current\napproaches remain tailored to their specific domains of application, and they\nfail when co-referent sequences in different data sets contain sparse or no\ncommon events, which occurs frequently in many cases.\n  To address this, we formalize the general problem of \"sequence linkage\" and\ndescribe \"LDA-Link,\" a generic solution that is applicable even when\nco-referent event sequences contain no common items at all. LDA-Link is built\nupon \"Split-Document\" model, a new mixed-membership probabilistic model for the\ngeneration of event sequence collections. It detects the latent similarity of\nsequences and thus achieves robustness particularly when co-referent sequences\nshare sparse or no event overlap. We apply LDA-Link in the context of social\nmedia profile reconciliation where users make no common posts across platforms,\ncomparing to the state-of-the-art generic solution to sequence linkage.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 07:46:28 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Kim", "Yunsung", ""]]}, {"id": "1711.04258", "submitter": "Zhao Kang", "authors": "Zhao Kang, Chong Peng, Qiang Cheng, Zenglin Xu", "title": "Unified Spectral Clustering with Optimal Graph", "comments": "Accepted by AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering has found extensive use in many areas. Most traditional\nspectral clustering algorithms work in three separate steps: similarity graph\nconstruction; continuous labels learning; discretizing the learned labels by\nk-means clustering. Such common practice has two potential flaws, which may\nlead to severe information loss and performance degradation. First, predefined\nsimilarity graph might not be optimal for subsequent clustering. It is\nwell-accepted that similarity graph highly affects the clustering results. To\nthis end, we propose to automatically learn similarity information from data\nand simultaneously consider the constraint that the similarity matrix has exact\nc connected components if there are c clusters. Second, the discrete solution\nmay deviate from the spectral solution since k-means method is well-known as\nsensitive to the initialization of cluster centers. In this work, we transform\nthe candidate solution into a new one that better approximates the discrete\none. Finally, those three subtasks are integrated into a unified framework,\nwith each subtask iteratively boosted by using the results of the others\ntowards an overall optimal solution. It is known that the performance of a\nkernel method is largely determined by the choice of kernels. To tackle this\npractical problem of how to select the most suitable kernel for a particular\ndata set, we further extend our model to incorporate multiple kernel learning\nability. Extensive experiments demonstrate the superiority of our proposed\nmethod as compared to existing clustering approaches.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 09:20:25 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Kang", "Zhao", ""], ["Peng", "Chong", ""], ["Cheng", "Qiang", ""], ["Xu", "Zenglin", ""]]}, {"id": "1711.04291", "submitter": "Valeriu Codreanu", "authors": "Valeriu Codreanu, Damian Podareanu, and Vikram Saletore", "title": "Scale out for large minibatch SGD: Residual network training on\n  ImageNet-1K with improved accuracy and reduced time to train", "comments": "10 pages, 4 figures, 13 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the past 5 years, the ILSVRC competition and the ImageNet dataset have\nattracted a lot of interest from the Computer Vision community, allowing for\nstate-of-the-art accuracy to grow tremendously. This should be credited to the\nuse of deep artificial neural network designs. As these became more complex,\nthe storage, bandwidth, and compute requirements increased. This means that\nwith a non-distributed approach, even when using the most high-density server\navailable, the training process may take weeks, making it prohibitive.\nFurthermore, as datasets grow, the representation learning potential of deep\nnetworks grows as well by using more complex models. This synchronicity\ntriggers a sharp increase in the computational requirements and motivates us to\nexplore the scaling behaviour on petaflop scale supercomputers. In this paper\nwe will describe the challenges and novel solutions needed in order to train\nResNet-50 in this large scale environment. We demonstrate above 90\\% scaling\nefficiency and a training time of 28 minutes using up to 104K x86 cores. This\nis supported by software tools from Intel's ecosystem. Moreover, we show that\nwith regular 90 - 120 epoch train runs we can achieve a top-1 accuracy as high\nas 77\\% for the unmodified ResNet-50 topology. We also introduce the novel\nCollapsed Ensemble (CE) technique that allows us to obtain a 77.5\\% top-1\naccuracy, similar to that of a ResNet-152, while training a unmodified\nResNet-50 topology for the same fixed training budget. All ResNet-50 models as\nwell as the scripts needed to replicate them will be posted shortly.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 13:26:31 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 19:47:04 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Codreanu", "Valeriu", ""], ["Podareanu", "Damian", ""], ["Saletore", "Vikram", ""]]}, {"id": "1711.04297", "submitter": "Yuanhong Wang", "authors": "Yuanhong Wang, Yuyi Wang, Xingwu Liu, Juhua Pu", "title": "On the ERM Principle with Networked Data", "comments": "accepted by AAAI. arXiv admin note: substantial text overlap with\n  arXiv:math/0702683 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Networked data, in which every training example involves two objects and may\nshare some common objects with others, is used in many machine learning tasks\nsuch as learning to rank and link prediction. A challenge of learning from\nnetworked examples is that target values are not known for some pairs of\nobjects. In this case, neither the classical i.i.d.\\ assumption nor techniques\nbased on complete U-statistics can be used. Most existing theoretical results\nof this problem only deal with the classical empirical risk minimization (ERM)\nprinciple that always weights every example equally, but this strategy leads to\nunsatisfactory bounds. We consider general weighted ERM and show new universal\nrisk bounds for this problem. These new bounds naturally define an optimization\nproblem which leads to appropriate weights for networked examples. Though this\noptimization problem is not convex in general, we devise a new fully\npolynomial-time approximation scheme (FPTAS) to solve it.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 14:00:44 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 10:41:42 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Wang", "Yuanhong", ""], ["Wang", "Yuyi", ""], ["Liu", "Xingwu", ""], ["Pu", "Juhua", ""]]}, {"id": "1711.04313", "submitter": "Randall Balestriero", "authors": "Randall Balestriero, Vincent Roger, Herve G. Glotin, Richard G.\n  Baraniuk", "title": "Semi-Supervised Learning via New Deep Network Inversion", "comments": "arXiv admin note: substantial text overlap with arXiv:1710.09302", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We exploit a recently derived inversion scheme for arbitrary deep neural\nnetworks to develop a new semi-supervised learning framework that applies to a\nwide range of systems and problems. The approach outperforms current\nstate-of-the-art methods on MNIST reaching $99.14\\%$ of test set accuracy while\nusing $5$ labeled examples per class. Experiments with one-dimensional signals\nhighlight the generality of the method. Importantly, our approach is simple,\nefficient, and requires no change in the deep network architecture.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 15:42:24 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Balestriero", "Randall", ""], ["Roger", "Vincent", ""], ["Glotin", "Herve G.", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1711.04315", "submitter": "Shing Chan", "authors": "Shing Chan, Ahmed H. Elsheikh", "title": "A machine learning approach for efficient uncertainty quantification\n  using multiscale methods", "comments": "Journal of Computational Physics (2017)", "journal-ref": null, "doi": "10.1016/j.jcp.2017.10.034", "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several multiscale methods account for sub-grid scale features using coarse\nscale basis functions. For example, in the Multiscale Finite Volume method the\ncoarse scale basis functions are obtained by solving a set of local problems\nover dual-grid cells. We introduce a data-driven approach for the estimation of\nthese coarse scale basis functions. Specifically, we employ a neural network\npredictor fitted using a set of solution samples from which it learns to\ngenerate subsequent basis functions at a lower computational cost than solving\nthe local problems. The computational advantage of this approach is realized\nfor uncertainty quantification tasks where a large number of realizations has\nto be evaluated. We attribute the ability to learn these basis functions to the\nmodularity of the local problems and the redundancy of the permeability patches\nbetween samples. The proposed method is evaluated on elliptic problems yielding\nvery promising results.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 15:45:34 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Chan", "Shing", ""], ["Elsheikh", "Ahmed H.", ""]]}, {"id": "1711.04323", "submitter": "Idan Schwartz", "authors": "Idan Schwartz, Alexander G. Schwing, Tamir Hazan", "title": "High-Order Attention Models for Visual Question Answering", "comments": "9 pages, 8 figures, NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quest for algorithms that enable cognitive abilities is an important part\nof machine learning. A common trait in many recently investigated\ncognitive-like tasks is that they take into account different data modalities,\nsuch as visual and textual input. In this paper we propose a novel and\ngenerally applicable form of attention mechanism that learns high-order\ncorrelations between various data modalities. We show that high-order\ncorrelations effectively direct the appropriate attention to the relevant\nelements in the different data modalities that are required to solve the joint\ntask. We demonstrate the effectiveness of our high-order attention mechanism on\nthe task of visual question answering (VQA), where we achieve state-of-the-art\nperformance on the standard VQA dataset.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 17:30:05 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Schwartz", "Idan", ""], ["Schwing", "Alexander G.", ""], ["Hazan", "Tamir", ""]]}, {"id": "1711.04325", "submitter": "Takuya Akiba", "authors": "Takuya Akiba, Shuji Suzuki, Keisuke Fukuda", "title": "Extremely Large Minibatch SGD: Training ResNet-50 on ImageNet in 15\n  Minutes", "comments": "NIPS'17 Workshop: Deep Learning at Supercomputer Scale", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that training ResNet-50 on ImageNet for 90 epochs can be\nachieved in 15 minutes with 1024 Tesla P100 GPUs. This was made possible by\nusing a large minibatch size of 32k. To maintain accuracy with this large\nminibatch size, we employed several techniques such as RMSprop warm-up, batch\nnormalization without moving averages, and a slow-start learning rate schedule.\nThis paper also describes the details of the hardware and software of the\nsystem used to achieve the above performance.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 17:36:46 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Akiba", "Takuya", ""], ["Suzuki", "Shuji", ""], ["Fukuda", "Keisuke", ""]]}, {"id": "1711.04329", "submitter": "Shiyue Zhang", "authors": "Shiyue Zhang, Pengtao Xie, Dong Wang, Eric P. Xing", "title": "Medical Diagnosis From Laboratory Tests by Combining Generative and\n  Discriminative Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A primary goal of computational phenotype research is to conduct medical\ndiagnosis. In hospital, physicians rely on massive clinical data to make\ndiagnosis decisions, among which laboratory tests are one of the most important\nresources. However, the longitudinal and incomplete nature of laboratory test\ndata casts a significant challenge on its interpretation and usage, which may\nresult in harmful decisions by both human physicians and automatic diagnosis\nsystems. In this work, we take advantage of deep generative models to deal with\nthe complex laboratory tests. Specifically, we propose an end-to-end\narchitecture that involves a deep generative variational recurrent neural\nnetworks (VRNN) to learn robust and generalizable features, and a\ndiscriminative neural network (NN) model to learn diagnosis decision making,\nand the two models are trained jointly. Our experiments are conducted on a\ndataset involving 46,252 patients, and the 50 most frequent tests are used to\npredict the 50 most common diagnoses. The results show that our model, VRNN+NN,\nsignificantly (p<0.001) outperforms other baseline models. Moreover, we\ndemonstrate that the representations learned by the joint training are more\ninformative than those learned by pure generative models. Finally, we find that\nour model offers a surprisingly good imputation for missing values.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 17:58:42 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 21:40:58 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Zhang", "Shiyue", ""], ["Xie", "Pengtao", ""], ["Wang", "Dong", ""], ["Xing", "Eric P.", ""]]}, {"id": "1711.04340", "submitter": "Antreas Antoniou Mr", "authors": "Antreas Antoniou, Amos Storkey and Harrison Edwards", "title": "Data Augmentation Generative Adversarial Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective training of neural networks requires much data. In the low-data\nregime, parameters are underdetermined, and learnt networks generalise poorly.\nData Augmentation alleviates this by using existing data more effectively.\nHowever standard data augmentation produces only limited plausible alternative\ndata. Given there is potential to generate a much broader set of augmentations,\nwe design and train a generative model to do data augmentation. The model,\nbased on image conditional Generative Adversarial Networks, takes data from a\nsource domain and learns to take any data item and generalise it to generate\nother within-class data items. As this generative process does not depend on\nthe classes themselves, it can be applied to novel unseen classes of data. We\nshow that a Data Augmentation Generative Adversarial Network (DAGAN) augments\nstandard vanilla classifiers well. We also show a DAGAN can enhance few-shot\nlearning systems such as Matching Networks. We demonstrate these approaches on\nOmniglot, on EMNIST having learnt the DAGAN on Omniglot, and VGG-Face data. In\nour experiments we can see over 13% increase in accuracy in the low-data regime\nexperiments in Omniglot (from 69% to 82%), EMNIST (73.9% to 76%) and VGG-Face\n(4.5% to 12%); in Matching Networks for Omniglot we observe an increase of 0.5%\n(from 96.9% to 97.4%) and an increase of 1.8% in EMNIST (from 59.5% to 61.3%).\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 19:17:57 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 16:46:40 GMT"}, {"version": "v3", "created": "Wed, 21 Mar 2018 23:26:15 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Antoniou", "Antreas", ""], ["Storkey", "Amos", ""], ["Edwards", "Harrison", ""]]}, {"id": "1711.04345", "submitter": "Riashat Islam", "authors": "Bogdan Mazoure, Riashat Islam", "title": "Alpha-Divergences in Variational Dropout", "comments": "Bogdan Mazoure and Riashat Islam contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of alternative divergences to Kullback-Leibler (KL) in\nvariational inference(VI), based on the Variational Dropout \\cite{kingma2015}.\nStochastic gradient variational Bayes (SGVB) \\cite{aevb} is a general framework\nfor estimating the evidence lower bound (ELBO) in Variational Bayes. In this\nwork, we extend the SGVB estimator with using Alpha-Divergences, which are\nalternative to divergences to VI' KL objective. The Gaussian dropout can be\nseen as a local reparametrization trick of the SGVB objective. We extend the\nVariational Dropout to use alpha divergences for variational inference. Our\nresults compare $\\alpha$-divergence variational dropout with standard\nvariational dropout with correlated and uncorrelated weight noise. We show that\nthe $\\alpha$-divergence with $\\alpha \\rightarrow 1$ (or KL divergence) is still\na good measure for use in variational inference, in spite of the efficient use\nof Alpha-divergences for Dropout VI \\cite{Li17}. $\\alpha \\rightarrow 1$ can\nyield the lowest training error, and optimizes a good lower bound for the\nevidence lower bound (ELBO) among all values of the parameter $\\alpha \\in\n[0,\\infty)$.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 19:38:09 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Mazoure", "Bogdan", ""], ["Islam", "Riashat", ""]]}, {"id": "1711.04366", "submitter": "Nicolas Papadakis", "authors": "Arnaud Dessein and Nicolas Papadakis and Charles-Alban Deledalle", "title": "Parameter Estimation in Finite Mixture Models by Regularized Optimal\n  Transport: A Unified Framework for Hard and Soft Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short paper, we formulate parameter estimation for finite mixture\nmodels in the context of discrete optimal transportation with convex\nregularization. The proposed framework unifies hard and soft clustering methods\nfor general mixture models. It also generalizes the celebrated\n$k$\\nobreakdash-means and expectation-maximization algorithms in relation to\nassociated Bregman divergences when applied to exponential family mixture\nmodels.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 21:52:54 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Dessein", "Arnaud", ""], ["Papadakis", "Nicolas", ""], ["Deledalle", "Charles-Alban", ""]]}, {"id": "1711.04368", "submitter": "Jihun Hamm", "authors": "Jihun Hamm and Akshay Mehra", "title": "Machine vs Machine: Minimax-Optimal Defense Against Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, researchers have discovered that the state-of-the-art object\nclassifiers can be fooled easily by small perturbations in the input\nunnoticeable to human eyes. It is also known that an attacker can generate\nstrong adversarial examples if she knows the classifier parameters. Conversely,\na defender can robustify the classifier by retraining if she has access to the\nadversarial examples. We explain and formulate this adversarial example problem\nas a two-player continuous zero-sum game, and demonstrate the fallacy of\nevaluating a defense or an attack as a static problem. To find the best\nworst-case defense against whitebox attacks, we propose a continuous minimax\noptimization algorithm. We demonstrate the minimax defense with two types of\nattack classes -- gradient-based and neural network-based attacks. Experiments\nwith the MNIST and the CIFAR-10 datasets demonstrate that the defense found by\nnumerical minimax optimization is indeed more robust than non-minimax defenses.\nWe discuss directions for improving the result toward achieving robustness\nagainst multiple types of attack classes.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 22:07:36 GMT"}, {"version": "v2", "created": "Wed, 13 Dec 2017 05:19:56 GMT"}, {"version": "v3", "created": "Wed, 27 Jun 2018 03:45:47 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Hamm", "Jihun", ""], ["Mehra", "Akshay", ""]]}, {"id": "1711.04453", "submitter": "Saeid Soheily-Khah", "authors": "Saeid Soheily-Khah (LIG, UGA, UBS, EXPRESSION, AMA),\n  Pierre-Fran\\c{c}ois Marteau (UBS, EXPRESSION)", "title": "Sparsification of the Alignment Path Search Space in Dynamic Time\n  Warping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal data are naturally everywhere, especially in the digital era that\nsees the advent of big data and internet of things. One major challenge that\narises during temporal data analysis and mining is the comparison of time\nseries or sequences, which requires to determine a proper distance or\n(dis)similarity measure. In this context, the Dynamic Time Warping (DTW) has\nenjoyed success in many domains, due to its 'temporal elasticity', a property\nparticularly useful when matching temporal data. Unfortunately this\ndissimilarity measure suffers from a quadratic computational cost, which\nprohibits its use for large scale applications. This work addresses the\nsparsification of the alignment path search space for DTW-like measures,\nessentially to lower their computational cost without loosing on the quality of\nthe measure. As a result of our sparsification approach, two new\n(dis)similarity measures, namely SP-DTW (Sparsified-Paths search space DTW) and\nits kernelization SP-K rdtw (Sparsified-Paths search space K rdtw kernel) are\nproposed for time series comparison. A wide range of public datasets is used to\nevaluate the efficiency (estimated in term of speed-up ratio and classification\naccuracy) of the proposed (dis)similarity measures on the 1-Nearest Neighbor\n(1-NN) and the Support Vector Machine (SVM) classification algorithms. Our\nexperiment shows that our proposed measures provide a significant speed-up\nwithout loosing on accuracy. Furthermore, at the cost of a slight reduction of\nthe speedup they significantly outperform on the accuracy criteria the old but\nwell known Sakoe-Chiba approach that reduces the DTW path search space using a\nsymmetric corridor.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 07:31:52 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Soheily-Khah", "Saeid", "", "LIG, UGA, UBS, EXPRESSION, AMA"], ["Marteau", "Pierre-Fran\u00e7ois", "", "UBS, EXPRESSION"]]}, {"id": "1711.04489", "submitter": "Yang Yang", "authors": "Yang Yang, Marius Pesavento", "title": "A Parallel Best-Response Algorithm with Exact Line Search for Nonconvex\n  Sparsity-Regularized Rank Minimization", "comments": "Submitted to IEEE ICASSP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a convergent parallel best-response algorithm with\nthe exact line search for the nondifferentiable nonconvex sparsity-regularized\nrank minimization problem. On the one hand, it exhibits a faster convergence\nthan subgradient algorithms and block coordinate descent algorithms. On the\nother hand, its convergence to a stationary point is guaranteed, while ADMM\nalgorithms only converge for convex problems. Furthermore, the exact line\nsearch procedure in the proposed algorithm is performed efficiently in\nclosed-form to avoid the meticulous choice of stepsizes, which is however a\ncommon bottleneck in subgradient algorithms and successive convex approximation\nalgorithms. Finally, the proposed algorithm is numerically tested.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 09:28:43 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Yang", "Yang", ""], ["Pesavento", "Marius", ""]]}, {"id": "1711.04518", "submitter": "Marius St\\\"ark", "authors": "Marius St\\\"ark, Damian Backes, Christian Kehl", "title": "A Supervised Learning Concept for Reducing User Interaction in Passenger\n  Cars", "comments": "4 pages, 9 figures, concept only", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.HC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article an automation system for human-machine-interfaces (HMI) for\nsetpoint adjustment using supervised learning is presented. We use HMIs of\nmulti-modal thermal conditioning systems in passenger cars as example for a\ncomplex setpoint selection system. The goal is the reduction of interaction\ncomplexity up to full automation. The approach is not limited to climate\ncontrol applications but can be extended to other setpoint-based HMIs.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 10:58:58 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["St\u00e4rk", "Marius", ""], ["Backes", "Damian", ""], ["Kehl", "Christian", ""]]}, {"id": "1711.04528", "submitter": "Thomas Elsken", "authors": "Thomas Elsken, Jan-Hendrik Metzen, Frank Hutter", "title": "Simple And Efficient Architecture Search for Convolutional Neural\n  Networks", "comments": "Under review as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have recently had a lot of success for many tasks. However,\nneural network architectures that perform well are still typically designed\nmanually by experts in a cumbersome trial-and-error process. We propose a new\nmethod to automatically search for well-performing CNN architectures based on a\nsimple hill climbing procedure whose operators apply network morphisms,\nfollowed by short optimization runs by cosine annealing. Surprisingly, this\nsimple method yields competitive results, despite only requiring resources in\nthe same order of magnitude as training a single network. E.g., on CIFAR-10,\nour method designs and trains networks with an error rate below 6% in only 12\nhours on a single GPU; training for one day reduces this error further, to\nalmost 5%.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 11:23:36 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Elsken", "Thomas", ""], ["Metzen", "Jan-Hendrik", ""], ["Hutter", "Frank", ""]]}, {"id": "1711.04596", "submitter": "William Blum", "authors": "Mohit Rajpal, William Blum, Rishabh Singh", "title": "Not all bytes are equal: Neural byte sieve for fuzzing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzing is a popular dynamic program analysis technique used to find\nvulnerabilities in complex software. Fuzzing involves presenting a target\nprogram with crafted malicious input designed to cause crashes, buffer\noverflows, memory errors, and exceptions. Crafting malicious inputs in an\nefficient manner is a difficult open problem and often the best approach to\ngenerating such inputs is through applying uniform random mutations to\npre-existing valid inputs (seed files). We present a learning technique that\nuses neural networks to learn patterns in the input files from past fuzzing\nexplorations to guide future fuzzing explorations. In particular, the neural\nmodels learn a function to predict good (and bad) locations in input files to\nperform fuzzing mutations based on the past mutations and corresponding code\ncoverage information. We implement several neural models including LSTMs and\nsequence-to-sequence models that can encode variable length input files. We\nincorporate our models in the state-of-the-art AFL (American Fuzzy Lop) fuzzer\nand show significant improvements in terms of code coverage, unique code paths,\nand crashes for various input formats including ELF, PNG, PDF, and XML.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 01:29:47 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Rajpal", "Mohit", ""], ["Blum", "William", ""], ["Singh", "Rishabh", ""]]}, {"id": "1711.04606", "submitter": "Yichen Huang", "authors": "Yichen Huang", "title": "Provably efficient neural network representation for image\n  classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-the-art approaches for image classification are based on neural\nnetworks. Mathematically, the task of classifying images is equivalent to\nfinding the function that maps an image to the label it is associated with. To\nrigorously establish the success of neural network methods, we should first\nprove that the function has an efficient neural network representation, and\nthen design provably efficient training algorithms to find such a\nrepresentation. Here, we achieve the first goal based on a set of assumptions\nabout the patterns in the images. The validity of these assumptions is very\nintuitive in many image classification problems, including but not limited to,\nrecognizing handwritten digits.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 14:55:32 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Huang", "Yichen", ""]]}, {"id": "1711.04623", "submitter": "Zachary Kenton", "authors": "Stanis{\\l}aw Jastrz\\k{e}bski, Zachary Kenton, Devansh Arpit, Nicolas\n  Ballas, Asja Fischer, Yoshua Bengio, Amos Storkey", "title": "Three Factors Influencing Minima in SGD", "comments": "First two authors contributed equally. Short version accepted into\n  ICLR workshop. Accepted to Artificial Neural Networks and Machine Learning,\n  ICANN 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the dynamical and convergent properties of stochastic gradient\ndescent (SGD) applied to Deep Neural Networks (DNNs). Characterizing the\nrelation between learning rate, batch size and the properties of the final\nminima, such as width or generalization, remains an open question. In order to\ntackle this problem we investigate the previously proposed approximation of SGD\nby a stochastic differential equation (SDE). We theoretically argue that three\nfactors - learning rate, batch size and gradient covariance - influence the\nminima found by SGD. In particular we find that the ratio of learning rate to\nbatch size is a key determinant of SGD dynamics and of the width of the final\nminima, and that higher values of the ratio lead to wider minima and often\nbetter generalization. We confirm these findings experimentally. Further, we\ninclude experiments which show that learning rate schedules can be replaced\nwith batch size schedules and that the ratio of learning rate to batch size is\nan important factor influencing the memorization process.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 15:11:56 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 16:22:54 GMT"}, {"version": "v3", "created": "Thu, 13 Sep 2018 09:29:55 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Jastrz\u0119bski", "Stanis\u0142aw", ""], ["Kenton", "Zachary", ""], ["Arpit", "Devansh", ""], ["Ballas", "Nicolas", ""], ["Fischer", "Asja", ""], ["Bengio", "Yoshua", ""], ["Storkey", "Amos", ""]]}, {"id": "1711.04679", "submitter": "Stephan Baier", "authors": "Stephan Baier, Sigurd Spieckermann and Volker Tresp", "title": "Attention-based Information Fusion using Multi-Encoder-Decoder Recurrent\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rising number of interconnected devices and sensors, modeling\ndistributed sensor networks is of increasing interest. Recurrent neural\nnetworks (RNN) are considered particularly well suited for modeling sensory and\nstreaming data. When predicting future behavior, incorporating information from\nneighboring sensor stations is often beneficial. We propose a new RNN based\narchitecture for context specific information fusion across multiple spatially\ndistributed sensor stations. Hereby, latent representations of multiple local\nmodels, each modeling one sensor station, are jointed and weighted, according\nto their importance for the prediction. The particular importance is assessed\ndepending on the current context using a separate attention function. We\ndemonstrate the effectiveness of our model on three different real-world sensor\nnetwork datasets.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 16:17:45 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Baier", "Stephan", ""], ["Spieckermann", "Sigurd", ""], ["Tresp", "Volker", ""]]}, {"id": "1711.04683", "submitter": "Stephan Baier", "authors": "Stephan Baier and Volker Tresp", "title": "Tensor Decompositions for Modeling Inverse Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling inverse dynamics is crucial for accurate feedforward robot control.\nThe model computes the necessary joint torques, to perform a desired movement.\nThe highly non-linear inverse function of the dynamical system can be\napproximated using regression techniques. We propose as regression method a\ntensor decomposition model that exploits the inherent three-way interaction of\npositions x velocities x accelerations. Most work in tensor factorization has\naddressed the decomposition of dense tensors. In this paper, we build upon the\ndecomposition of sparse tensors, with only small amounts of nonzero entries.\nThe decomposition of sparse tensors has successfully been used in relational\nlearning, e.g., the modeling of large knowledge graphs. Recently, the approach\nhas been extended to multi-class classification with discrete input variables.\nRepresenting the data in high dimensional sparse tensors enables the\napproximation of complex highly non-linear functions. In this paper we show how\nthe decomposition of sparse tensors can be applied to regression problems.\nFurthermore, we extend the method to continuous inputs, by learning a mapping\nfrom the continuous inputs to the latent representations of the tensor\ndecomposition, using basis functions. We evaluate our proposed model on a\ndataset with trajectories from a seven degrees of freedom SARCOS robot arm. Our\nexperimental results show superior performance of the proposed functional\ntensor model, compared to challenging state-of-the art methods.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 16:26:51 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Baier", "Stephan", ""], ["Tresp", "Volker", ""]]}, {"id": "1711.04686", "submitter": "Brandon Reagen", "authors": "Brandon Reagen, Udit Gupta, Robert Adolf, Michael M. Mitzenmacher,\n  Alexander M. Rush, Gu-Yeon Wei, David Brooks", "title": "Weightless: Lossy Weight Encoding For Deep Neural Network Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large memory requirements of deep neural networks limit their deployment\nand adoption on many devices. Model compression methods effectively reduce the\nmemory requirements of these models, usually through applying transformations\nsuch as weight pruning or quantization. In this paper, we present a novel\nscheme for lossy weight encoding which complements conventional compression\ntechniques. The encoding is based on the Bloomier filter, a probabilistic data\nstructure that can save space at the cost of introducing random errors.\nLeveraging the ability of neural networks to tolerate these imperfections and\nby re-training around the errors, the proposed technique, Weightless, can\ncompress DNN weights by up to 496x with the same model accuracy. This results\nin up to a 1.51x improvement over the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 16:28:37 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Reagen", "Brandon", ""], ["Gupta", "Udit", ""], ["Adolf", "Robert", ""], ["Mitzenmacher", "Michael M.", ""], ["Rush", "Alexander M.", ""], ["Wei", "Gu-Yeon", ""], ["Brooks", "David", ""]]}, {"id": "1711.04689", "submitter": "A.V. Narasimhadhan Dr.", "authors": "Thingom Bishal Singha, Rajsekhar Kumar Nath and A. V. Narsimhadhan", "title": "Person Recognition using Smartphones' Accelerometer Data", "comments": "Currently under review at IEEE National Conference on Communications\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphones have become quite pervasive in various aspects of our daily\nlives. They have become important links to a host of important data and\napplications, which if compromised, can lead to disastrous results. Due to\nthis, today's smartphones are equipped with multiple layers of authentication\nmodules. However, there still lies the need for a viable and unobtrusive layer\nof security which can perform the task of user authentication using resources\nwhich are cost-efficient and widely available on smartphones. In this work, we\npropose a method to recognize users using data from a phone's embedded\naccelerometer sensors. Features encapsulating information from both time and\nfrequency domains are extracted from walking data samples, and are used to\nbuild a Random Forest ensemble classification model. Based on the experimental\nresults, the resultant model delivers an accuracy of 0.9679 and Area under\nCurve (AUC) of 0.9822.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 16:33:12 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Singha", "Thingom Bishal", ""], ["Nath", "Rajsekhar Kumar", ""], ["Narsimhadhan", "A. V.", ""]]}, {"id": "1711.04708", "submitter": "Anuj Karpatne", "authors": "Anuj Karpatne, Imme Ebert-Uphoff, Sai Ravela, Hassan Ali Babaie, and\n  Vipin Kumar", "title": "Machine Learning for the Geosciences: Challenges and Opportunities", "comments": "Under review at IEEE Transactions on Knowledge and Data Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geosciences is a field of great societal relevance that requires solutions to\nseveral urgent problems facing our humanity and the planet. As geosciences\nenters the era of big data, machine learning (ML) -- that has been widely\nsuccessful in commercial domains -- offers immense potential to contribute to\nproblems in geosciences. However, problems in geosciences have several unique\nchallenges that are seldom found in traditional applications, requiring novel\nproblem formulations and methodologies in machine learning. This article\nintroduces researchers in the machine learning (ML) community to these\nchallenges offered by geoscience problems and the opportunities that exist for\nadvancing both machine learning and geosciences. We first highlight typical\nsources of geoscience data and describe their properties that make it\nchallenging to use traditional machine learning techniques. We then describe\nsome of the common categories of geoscience problems where machine learning can\nplay a role, and discuss some of the existing efforts and promising directions\nfor methodological development in machine learning. We conclude by discussing\nsome of the emerging research themes in machine learning that are applicable\nacross all problems in the geosciences, and the importance of a deep\ncollaboration between machine learning and geosciences for synergistic\nadvancements in both disciplines.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 17:16:38 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Karpatne", "Anuj", ""], ["Ebert-Uphoff", "Imme", ""], ["Ravela", "Sai", ""], ["Babaie", "Hassan Ali", ""], ["Kumar", "Vipin", ""]]}, {"id": "1711.04710", "submitter": "Anuj Karpatne", "authors": "Gowtham Atluri, Anuj Karpatne, and Vipin Kumar", "title": "Spatio-Temporal Data Mining: A Survey of Problems and Methods", "comments": "Accepted for publication at ACM Computing Surveys", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large volumes of spatio-temporal data are increasingly collected and studied\nin diverse domains including, climate science, social sciences, neuroscience,\nepidemiology, transportation, mobile health, and Earth sciences.\nSpatio-temporal data differs from relational data for which computational\napproaches are developed in the data mining community for multiple decades, in\nthat both spatial and temporal attributes are available in addition to the\nactual measurements/attributes. The presence of these attributes introduces\nadditional challenges that needs to be dealt with. Approaches for mining\nspatio-temporal data have been studied for over a decade in the data mining\ncommunity. In this article we present a broad survey of this relatively young\nfield of spatio-temporal data mining. We discuss different types of\nspatio-temporal data and the relevant data mining questions that arise in the\ncontext of analyzing each of these datasets. Based on the nature of the data\nmining problem studied, we classify literature on spatio-temporal data mining\ninto six major categories: clustering, predictive learning, change detection,\nfrequent pattern mining, anomaly detection, and relationship mining. We discuss\nthe various forms of spatio-temporal data mining problems in each of these\ncategories.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 17:17:29 GMT"}, {"version": "v2", "created": "Fri, 17 Nov 2017 17:31:54 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Atluri", "Gowtham", ""], ["Karpatne", "Anuj", ""], ["Kumar", "Vipin", ""]]}, {"id": "1711.04713", "submitter": "Moritz Milde", "authors": "Moritz B. Milde, Daniel Neil, Alessandro Aimar, Tobi Delbruck and\n  Giacomo Indiveri", "title": "ADaPTION: Toolbox and Benchmark for Training Convolutional Neural\n  Networks with Reduced Numerical Precision Weights and Activation", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) and Convolutional Neural Networks (CNNs) are\nuseful for many practical tasks in machine learning. Synaptic weights, as well\nas neuron activation functions within the deep network are typically stored\nwith high-precision formats, e.g. 32 bit floating point. However, since storage\ncapacity is limited and each memory access consumes power, both storage\ncapacity and memory access are two crucial factors in these networks. Here we\npresent a method and present the ADaPTION toolbox to extend the popular deep\nlearning library Caffe to support training of deep CNNs with reduced numerical\nprecision of weights and activations using fixed point notation. ADaPTION\nincludes tools to measure the dynamic range of weights and activations. Using\nthe ADaPTION tools, we quantized several CNNs including VGG16 down to 16-bit\nweights and activations with only 0.8% drop in Top-1 accuracy. The\nquantization, especially of the activations, leads to increase of up to 50% of\nsparsity especially in early and intermediate layers, which we exploit to skip\nmultiplications with zero, thus performing faster and computationally cheaper\ninference.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 17:24:34 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Milde", "Moritz B.", ""], ["Neil", "Daniel", ""], ["Aimar", "Alessandro", ""], ["Delbruck", "Tobi", ""], ["Indiveri", "Giacomo", ""]]}, {"id": "1711.04735", "submitter": "Jeffrey Pennington", "authors": "Jeffrey Pennington, Samuel S. Schoenholz, Surya Ganguli", "title": "Resurrecting the sigmoid in deep learning through dynamical isometry:\n  theory and practice", "comments": "13 pages, 6 figures. Appearing at the 31st Conference on Neural\n  Information Processing Systems (NIPS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that the initialization of weights in deep neural networks\ncan have a dramatic impact on learning speed. For example, ensuring the mean\nsquared singular value of a network's input-output Jacobian is $O(1)$ is\nessential for avoiding the exponential vanishing or explosion of gradients. The\nstronger condition that all singular values of the Jacobian concentrate near\n$1$ is a property known as dynamical isometry. For deep linear networks,\ndynamical isometry can be achieved through orthogonal weight initialization and\nhas been shown to dramatically speed up learning; however, it has remained\nunclear how to extend these results to the nonlinear setting. We address this\nquestion by employing powerful tools from free probability theory to compute\nanalytically the entire singular value distribution of a deep network's\ninput-output Jacobian. We explore the dependence of the singular value\ndistribution on the depth of the network, the weight initialization, and the\nchoice of nonlinearity. Intriguingly, we find that ReLU networks are incapable\nof dynamical isometry. On the other hand, sigmoidal networks can achieve\nisometry, but only with orthogonal weight initialization. Moreover, we\ndemonstrate empirically that deep nonlinear networks achieving dynamical\nisometry learn orders of magnitude faster than networks that do not. Indeed, we\nshow that properly-initialized deep sigmoidal networks consistently outperform\ndeep ReLU networks. Overall, our analysis reveals that controlling the entire\ndistribution of Jacobian singular values is an important design consideration\nin deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 18:06:09 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Pennington", "Jeffrey", ""], ["Schoenholz", "Samuel S.", ""], ["Ganguli", "Surya", ""]]}, {"id": "1711.04755", "submitter": "Nan Rosemary Ke", "authors": "Anirudh Goyal, Nan Rosemary Ke, Alex Lamb, R Devon Hjelm, Chris Pal,\n  Joelle Pineau, Yoshua Bengio", "title": "ACtuAL: Actor-Critic Under Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are a powerful framework for deep\ngenerative modeling. Posed as a two-player minimax problem, GANs are typically\ntrained end-to-end on real-valued data and can be used to train a generator of\nhigh-dimensional and realistic images. However, a major limitation of GANs is\nthat training relies on passing gradients from the discriminator through the\ngenerator via back-propagation. This makes it fundamentally difficult to train\nGANs with discrete data, as generation in this case typically involves a\nnon-differentiable function. These difficulties extend to the reinforcement\nlearning setting when the action space is composed of discrete decisions. We\naddress these issues by reframing the GAN framework so that the generator is no\nlonger trained using gradients through the discriminator, but is instead\ntrained using a learned critic in the actor-critic framework with a Temporal\nDifference (TD) objective. This is a natural fit for sequence modeling and we\nuse it to achieve improvements on language modeling tasks over the standard\nTeacher-Forcing methods.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 18:49:06 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Goyal", "Anirudh", ""], ["Ke", "Nan Rosemary", ""], ["Lamb", "Alex", ""], ["Hjelm", "R Devon", ""], ["Pal", "Chris", ""], ["Pineau", "Joelle", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1711.04810", "submitter": "Th\\'eophile Gaudin", "authors": "Philippe Schwaller and Theophile Gaudin, David Lanyi, Costas Bekas,\n  Teodoro Laino", "title": "\"Found in Translation\": Predicting Outcomes of Complex Organic Chemistry\n  Reactions using Neural Sequence-to-Sequence Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an intuitive analogy of an organic chemist's understanding of a\ncompound and a language speaker's understanding of a word. Consequently, it is\npossible to introduce the basic concepts and analyze potential impacts of\nlinguistic analysis to the world of organic chemistry. In this work, we cast\nthe reaction prediction task as a translation problem by introducing a\ntemplate-free sequence-to-sequence model, trained end-to-end and fully\ndata-driven. We propose a novel way of tokenization, which is arbitrarily\nextensible with reaction information. With this approach, we demonstrate\nresults superior to the state-of-the-art solution by a significant margin on\nthe top-1 accuracy. Specifically, our approach achieves an accuracy of 80.1%\nwithout relying on auxiliary knowledge such as reaction templates. Also, 66.4%\naccuracy is reached on a larger and noisier dataset.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 19:38:14 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 08:06:57 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Schwaller", "Philippe", ""], ["Gaudin", "Theophile", ""], ["Lanyi", "David", ""], ["Bekas", "Costas", ""], ["Laino", "Teodoro", ""]]}, {"id": "1711.04837", "submitter": "Zachary Lipton", "authors": "John Alberg, Zachary C. Lipton", "title": "Improving Factor-Based Quantitative Investing by Forecasting Company\n  Fundamentals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On a periodic basis, publicly traded companies are required to report\nfundamentals: financial data such as revenue, operating income, debt, among\nothers. These data points provide some insight into the financial health of a\ncompany. Academic research has identified some factors, i.e. computed features\nof the reported data, that are known through retrospective analysis to\noutperform the market average. Two popular factors are the book value\nnormalized by market capitalization (book-to-market) and the operating income\nnormalized by the enterprise value (EBIT/EV). In this paper: we first show\nthrough simulation that if we could (clairvoyantly) select stocks using factors\ncalculated on future fundamentals (via oracle), then our portfolios would far\noutperform a standard factor approach. Motivated by this analysis, we train\ndeep neural networks to forecast future fundamentals based on a trailing\n5-years window. Quantitative analysis demonstrates a significant improvement in\nMSE over a naive strategy. Moreover, in retrospective analysis using an\nindustry-grade stock portfolio simulator (backtester), we show an improvement\nin compounded annual return to 17.1% (MLP) vs 14.4% for a standard factor\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 20:30:02 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 03:19:32 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Alberg", "John", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1711.04845", "submitter": "John Thickstun", "authors": "John Thickstun, Zaid Harchaoui, Dean Foster, Sham M. Kakade", "title": "Invariances and Data Augmentation for Supervised Music Transcription", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores a variety of models for frame-based music transcription,\nwith an emphasis on the methods needed to reach state-of-the-art on human\nrecordings. The translation-invariant network discussed in this paper, which\ncombines a traditional filterbank with a convolutional neural network, was the\ntop-performing model in the 2017 MIREX Multiple Fundamental Frequency\nEstimation evaluation. This class of models shares parameters in the\nlog-frequency domain, which exploits the frequency invariance of music to\nreduce the number of model parameters and avoid overfitting to the training\ndata. All models in this paper were trained with supervision by labeled data\nfrom the MusicNet dataset, augmented by random label-preserving pitch-shift\ntransformations.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 20:47:57 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Thickstun", "John", ""], ["Harchaoui", "Zaid", ""], ["Foster", "Dean", ""], ["Kakade", "Sham M.", ""]]}, {"id": "1711.04851", "submitter": "Aditya Balu", "authors": "Sambit Ghadai, Aditya Balu, Adarsh Krishnamurthy, Soumik Sarkar", "title": "Learning and Visualizing Localized Geometric Features Using 3D-CNN: An\n  Application to Manufacturability Analysis of Drilled Holes", "comments": "Presented at NIPS 2017 Symposium on Interpretable Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D Convolutional Neural Networks (3D-CNN) have been used for object\nrecognition based on the voxelized shape of an object. However, interpreting\nthe decision making process of these 3D-CNNs is still an infeasible task. In\nthis paper, we present a unique 3D-CNN based Gradient-weighted Class Activation\nMapping method (3D-GradCAM) for visual explanations of the distinct local\ngeometric features of interest within an object. To enable efficient learning\nof 3D geometries, we augment the voxel data with surface normals of the object\nboundary. We then train a 3D-CNN with this augmented data and identify the\nlocal features critical for decision-making using 3D GradCAM. An application of\nthis feature identification framework is to recognize difficult-to-manufacture\ndrilled hole features in a complex CAD geometry. The framework can be extended\nto identify difficult-to-manufacture features at multiple spatial scales\nleading to a real-time design for manufacturability decision support system.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 21:05:39 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 18:49:35 GMT"}, {"version": "v3", "created": "Wed, 28 Mar 2018 03:52:41 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Ghadai", "Sambit", ""], ["Balu", "Aditya", ""], ["Krishnamurthy", "Adarsh", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1711.04855", "submitter": "Ruairidh Battleday", "authors": "Ruairidh M. Battleday, Joshua C. Peterson, Thomas L. Griffiths", "title": "Modeling Human Categorization of Natural Images Using Deep Feature\n  Representations", "comments": "13 pages, 7 figures, 6 tables. Preliminary work presented at CogSci\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few decades, psychologists have developed sophisticated formal\nmodels of human categorization using simple artificial stimuli. In this paper,\nwe use modern machine learning methods to extend this work into the realm of\nnaturalistic stimuli, enabling human categorization to be studied over the\ncomplex visual domain in which it evolved and developed. We show that\nrepresentations derived from a convolutional neural network can be used to\nmodel behavior over a database of >300,000 human natural image classifications,\nand find that a group of models based on these representations perform well,\nnear the reliability of human judgments. Interestingly, this group includes\nboth exemplar and prototype models, contrasting with the dominance of exemplar\nmodels in previous work. We are able to improve the performance of the\nremaining models by preprocessing neural network representations to more\nclosely capture human similarity judgments.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 21:18:29 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Battleday", "Ruairidh M.", ""], ["Peterson", "Joshua C.", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "1711.04887", "submitter": "Mohsen Ghassemi", "authors": "Mohsen Ghassemi, Zahra Shakeri, Anand D. Sarwate, Waheed U. Bajwa", "title": "STARK: Structured Dictionary Learning Through Rank-one Tensor Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, a class of dictionaries have been proposed for\nmultidimensional (tensor) data representation that exploit the structure of\ntensor data by imposing a Kronecker structure on the dictionary underlying the\ndata. In this work, a novel algorithm called \"STARK\" is provided to learn\nKronecker structured dictionaries that can represent tensors of any order. By\nestablishing that the Kronecker product of any number of matrices can be\nrearranged to form a rank-1 tensor, we show that Kronecker structure can be\nenforced on the dictionary by solving a rank-1 tensor recovery problem. Because\nrank-1 tensor recovery is a challenging nonconvex problem, we resort to solving\na convex relaxation of this problem. Empirical experiments on synthetic and\nreal data show promising results for our proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 23:17:51 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Ghassemi", "Mohsen", ""], ["Shakeri", "Zahra", ""], ["Sarwate", "Anand D.", ""], ["Bajwa", "Waheed U.", ""]]}, {"id": "1711.04894", "submitter": "Youssef  Mroueh", "authors": "Youssef Mroueh, Chun-Liang Li, Tom Sercu, Anant Raj, Yu Cheng", "title": "Sobolev GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new Integral Probability Metric (IPM) between distributions: the\nSobolev IPM. The Sobolev IPM compares the mean discrepancy of two distributions\nfor functions (critic) restricted to a Sobolev ball defined with respect to a\ndominant measure $\\mu$. We show that the Sobolev IPM compares two distributions\nin high dimensions based on weighted conditional Cumulative Distribution\nFunctions (CDF) of each coordinate on a leave one out basis. The Dominant\nmeasure $\\mu$ plays a crucial role as it defines the support on which\nconditional CDFs are compared. Sobolev IPM can be seen as an extension of the\none dimensional Von-Mises Cram\\'er statistics to high dimensional\ndistributions. We show how Sobolev IPM can be used to train Generative\nAdversarial Networks (GANs). We then exploit the intrinsic conditioning implied\nby Sobolev IPM in text generation. Finally we show that a variant of Sobolev\nGAN achieves competitive results in semi-supervised learning on CIFAR-10,\nthanks to the smoothness enforced on the critic by Sobolev GAN which relates to\nLaplacian regularization.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 00:41:09 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Mroueh", "Youssef", ""], ["Li", "Chun-Liang", ""], ["Sercu", "Tom", ""], ["Raj", "Anant", ""], ["Cheng", "Yu", ""]]}, {"id": "1711.04903", "submitter": "Michihiro Yasunaga", "authors": "Michihiro Yasunaga, Jungo Kasai, Dragomir Radev", "title": "Robust Multilingual Part-of-Speech Tagging via Adversarial Training", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training (AT) is a powerful regularization method for neural\nnetworks, aiming to achieve robustness to input perturbations. Yet, the\nspecific effects of the robustness obtained from AT are still unclear in the\ncontext of natural language processing. In this paper, we propose and analyze a\nneural POS tagging model that exploits AT. In our experiments on the Penn\nTreebank WSJ corpus and the Universal Dependencies (UD) dataset (27 languages),\nwe find that AT not only improves the overall tagging accuracy, but also 1)\nprevents over-fitting well in low resource languages and 2) boosts tagging\naccuracy for rare / unseen words. We also demonstrate that 3) the improved\ntagging performance by AT contributes to the downstream task of dependency\nparsing, and that 4) AT helps the model to learn cleaner word representations.\n5) The proposed AT model is generally effective in different sequence labeling\ntasks. These positive results motivate further use of AT for natural language\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 01:50:30 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 15:49:22 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Yasunaga", "Michihiro", ""], ["Kasai", "Jungo", ""], ["Radev", "Dragomir", ""]]}, {"id": "1711.04913", "submitter": "Asa Ben-Hur", "authors": "Amina Asif, Wajid Arshad Abbasi, Farzeen Munir, Asa Ben-Hur, and\n  Fayyaz ul Amir Afsar Minhas", "title": "pyLEMMINGS: Large Margin Multiple Instance Classification and Ranking\n  for Bioinformatics Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: A major challenge in the development of machine learning based\nmethods in computational biology is that data may not be accurately labeled due\nto the time and resources required for experimentally annotating properties of\nproteins and DNA sequences. Standard supervised learning algorithms assume\naccurate instance-level labeling of training data. Multiple instance learning\nis a paradigm for handling such labeling ambiguities. However, the widely used\nlarge-margin classification methods for multiple instance learning are\nheuristic in nature with high computational requirements. In this paper, we\npresent stochastic sub-gradient optimization large margin algorithms for\nmultiple instance classification and ranking, and provide them in a software\nsuite called pyLEMMINGS.\n  Results: We have tested pyLEMMINGS on a number of bioinformatics problems as\nwell as benchmark datasets. pyLEMMINGS has successfully been able to identify\nfunctionally important segments of proteins: binding sites in Calmodulin\nbinding proteins, prion forming regions, and amyloid cores. pyLEMMINGS achieves\nstate-of-the-art performance in all these tasks, demonstrating the value of\nmultiple instance learning. Furthermore, our method has shown more than\n100-fold improvement in terms of running time as compared to heuristic\nsolutions with improved accuracy over benchmark datasets.\n  Availability and Implementation: pyLEMMINGS python package is available for\ndownload at: http://faculty.pieas.edu.pk/fayyaz/software.html#pylemmings.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 02:41:01 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Asif", "Amina", ""], ["Abbasi", "Wajid Arshad", ""], ["Munir", "Farzeen", ""], ["Ben-Hur", "Asa", ""], ["Minhas", "Fayyaz ul Amir Afsar", ""]]}, {"id": "1711.04915", "submitter": "Zhe Gan", "authors": "Yunchen Pu, Weiyao Wang, Ricardo Henao, Liqun Chen, Zhe Gan, Chunyuan\n  Li, Lawrence Carin", "title": "Adversarial Symmetric Variational Autoencoder", "comments": "Accepted to NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new form of variational autoencoder (VAE) is developed, in which the joint\ndistribution of data and codes is considered in two (symmetric) forms: ($i$)\nfrom observed data fed through the encoder to yield codes, and ($ii$) from\nlatent codes drawn from a simple prior and propagated through the decoder to\nmanifest data. Lower bounds are learned for marginal log-likelihood fits\nobserved data and latent codes. When learning with the variational bound, one\nseeks to minimize the symmetric Kullback-Leibler divergence of joint density\nfunctions from ($i$) and ($ii$), while simultaneously seeking to maximize the\ntwo marginal log-likelihoods. To facilitate learning, a new form of adversarial\ntraining is developed. An extensive set of experiments is performed, in which\nwe demonstrate state-of-the-art data reconstruction and generation on several\nimage benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 02:48:01 GMT"}, {"version": "v2", "created": "Sat, 18 Nov 2017 18:29:28 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Pu", "Yunchen", ""], ["Wang", "Weiyao", ""], ["Henao", "Ricardo", ""], ["Chen", "Liqun", ""], ["Gan", "Zhe", ""], ["Li", "Chunyuan", ""], ["Carin", "Lawrence", ""]]}, {"id": "1711.04955", "submitter": "Sen Na", "authors": "Sen Na, Mingyuan Ma, Mladen Kolar", "title": "Scalable Peaceman-Rachford Splitting Method with Proximal Terms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Along with developing of Peaceman-Rachford Splittling Method (PRSM), many\nbatch algorithms based on it have been studied very deeply. But almost no\nalgorithm focused on the performance of stochastic version of PRSM. In this\npaper, we propose a new stochastic algorithm based on PRSM, prove its\nconvergence rate in ergodic sense, and test its performance on both artificial\nand real data. We show that our proposed algorithm, Stochastic Scalable PRSM\n(SS-PRSM), enjoys the $O(1/K)$ convergence rate, which is the same as those\nnewest stochastic algorithms that based on ADMM but faster than general\nStochastic ADMM (which is $O(1/\\sqrt{K})$). Our algorithm also owns wide\nflexibility, outperforms many state-of-the-art stochastic algorithms coming\nfrom ADMM, and has low memory cost in large-scale splitting optimization\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 05:45:32 GMT"}, {"version": "v2", "created": "Sat, 10 Feb 2018 02:27:16 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Na", "Sen", ""], ["Ma", "Mingyuan", ""], ["Kolar", "Mladen", ""]]}, {"id": "1711.04965", "submitter": "Navid Ghadermarzy", "authors": "Navid Ghadermarzy, Yaniv Plan, \\\"Ozg\\\"ur Y{\\i}lmaz", "title": "Near-optimal sample complexity for convex tensor completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze low rank tensor completion (TC) using noisy measurements of a\nsubset of the tensor. Assuming a rank-$r$, order-$d$, $N \\times N \\times \\cdots\n\\times N$ tensor where $r=O(1)$, the best sampling complexity that was achieved\nis $O(N^{\\frac{d}{2}})$, which is obtained by solving a tensor nuclear-norm\nminimization problem. However, this bound is significantly larger than the\nnumber of free variables in a low rank tensor which is $O(dN)$. In this paper,\nwe show that by using an atomic-norm whose atoms are rank-$1$ sign tensors, one\ncan obtain a sample complexity of $O(dN)$. Moreover, we generalize the matrix\nmax-norm definition to tensors, which results in a max-quasi-norm (max-qnorm)\nwhose unit ball has small Rademacher complexity. We prove that solving a\nconstrained least squares estimation using either the convex atomic-norm or the\nnonconvex max-qnorm results in optimal sample complexity for the problem of\nlow-rank tensor completion. Furthermore, we show that these bounds are nearly\nminimax rate-optimal. We also provide promising numerical results for max-qnorm\nconstrained tensor completion, showing improved recovery results compared to\nmatricization and alternating least squares.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 06:20:05 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Ghadermarzy", "Navid", ""], ["Plan", "Yaniv", ""], ["Y\u0131lmaz", "\u00d6zg\u00fcr", ""]]}, {"id": "1711.04969", "submitter": "Can Karakus", "authors": "Can Karakus, Yifan Sun, Suhas Diggavi, Wotao Yin", "title": "Straggler Mitigation in Distributed Optimization Through Data Encoding", "comments": "appeared at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Slow running or straggler tasks can significantly reduce computation speed in\ndistributed computation. Recently, coding-theory-inspired approaches have been\napplied to mitigate the effect of straggling, through embedding redundancy in\ncertain linear computational steps of the optimization algorithm, thus\ncompleting the computation without waiting for the stragglers. In this paper,\nwe propose an alternate approach where we embed the redundancy directly in the\ndata itself, and allow the computation to proceed completely oblivious to\nencoding. We propose several encoding schemes, and demonstrate that popular\nbatch algorithms, such as gradient descent and L-BFGS, applied in a\ncoding-oblivious manner, deterministically achieve sample path linear\nconvergence to an approximate solution of the original problem, using an\narbitrarily varying subset of the nodes at each iteration. Moreover, this\napproximation can be controlled by the amount of redundancy and the number of\nnodes used in each iteration. We provide experimental results demonstrating the\nadvantage of the approach over uncoded and data replication strategies.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 06:29:41 GMT"}, {"version": "v2", "created": "Mon, 22 Jan 2018 23:28:11 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Karakus", "Can", ""], ["Sun", "Yifan", ""], ["Diggavi", "Suhas", ""], ["Yin", "Wotao", ""]]}, {"id": "1711.04992", "submitter": "Bogdan Kulynych", "authors": "Bogdan Kulynych, Carmela Troncoso", "title": "Feature importance scores and lossless feature pruning using Banzhaf\n  power indices", "comments": "Presented at NIPS 2017 Symposium on Interpretable Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the influence of features in machine learning is crucial to\ninterpreting models and selecting the best features for classification. In this\nwork we propose the use of principles from coalitional game theory to reason\nabout importance of features. In particular, we propose the use of the Banzhaf\npower index as a measure of influence of features on the outcome of a\nclassifier. We show that features having Banzhaf power index of zero can be\nlosslessly pruned without damage to classifier accuracy. Computing the power\nindices does not require having access to data samples. However, if samples are\navailable, the indices can be empirically estimated. We compute Banzhaf power\nindices for a neural network classifier on real-life data, and compare the\nresults with gradient-based feature saliency, and coefficients of a logistic\nregression model with $L_1$ regularization.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 08:24:01 GMT"}, {"version": "v2", "created": "Sun, 3 Dec 2017 05:40:39 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Kulynych", "Bogdan", ""], ["Troncoso", "Carmela", ""]]}, {"id": "1711.05037", "submitter": "Judy Hoffman", "authors": "Judy Hoffman, Mehryar Mohri, Ningshan Zhang", "title": "Multiple-Source Adaptation for Regression Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a detailed theoretical analysis of the problem of multiple-source\nadaptation in the general stochastic scenario, extending known results that\nassume a single target labeling function. Our results cover a more realistic\nscenario and show the existence of a single robust predictor accurate for\n\\emph{any} target mixture of the source distributions. Moreover, we present an\nefficient and practical optimization solution to determine the robust predictor\nin the important case of squared loss, by casting the problem as an instance of\nDC-programming. We report the results of experiments with both an artificial\ntask and a sentiment analysis task. We find that our algorithm outperforms\ncompeting approaches by producing a single robust model that performs well on\nany target mixture distribution.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 10:05:45 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Hoffman", "Judy", ""], ["Mohri", "Mehryar", ""], ["Zhang", "Ningshan", ""]]}, {"id": "1711.05060", "submitter": "Hong-Min Chu", "authors": "Hong-Min Chu, Kuan-Hao Huang and Hsuan-Tien Lin", "title": "Dynamic Principal Projection for Cost-Sensitive Online Multi-Label\n  Classification", "comments": null, "journal-ref": null, "doi": "10.1007/s10994-018-5773-6", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study multi-label classification (MLC) with three important real-world\nissues: online updating, label space dimensional reduction (LSDR), and\ncost-sensitivity. Current MLC algorithms have not been designed to address\nthese three issues simultaneously. In this paper, we propose a novel algorithm,\ncost-sensitive dynamic principal projection (CS-DPP) that resolves all three\nissues. The foundation of CS-DPP is an online LSDR framework derived from a\nleading LSDR algorithm. In particular, CS-DPP is equipped with an efficient\nonline dimension reducer motivated by matrix stochastic gradient, and\nestablishes its theoretical backbone when coupled with a carefully-designed\nonline regression learner. In addition, CS-DPP embeds the cost information into\nlabel weights to achieve cost-sensitivity along with theoretical guarantees.\nExperimental results verify that CS-DPP achieves better practical performance\nthan current MLC algorithms across different evaluation criteria, and\ndemonstrate the importance of resolving the three issues simultaneously.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 11:20:29 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 12:37:37 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Chu", "Hong-Min", ""], ["Huang", "Kuan-Hao", ""], ["Lin", "Hsuan-Tien", ""]]}, {"id": "1711.05068", "submitter": "Peng-Bo Zhang", "authors": "Peng-Bo Zhang and Zhi-Xin Yang", "title": "Robust Matrix Elastic Net based Canonical Correlation Analysis: An\n  Effective Algorithm for Multi-View Unsupervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a robust matrix elastic net based canonical correlation\nanalysis (RMEN-CCA) for multiple view unsupervised learning problems, which\nemphasizes the combination of CCA and the robust matrix elastic net (RMEN) used\nas coupled feature selection. The RMEN-CCA leverages the strength of the RMEN\nto distill naturally meaningful features without any prior assumption and to\nmeasure effectively correlations between different 'views'. We can further\nemploy directly the kernel trick to extend the RMEN-CCA to the kernel scenario\nwith theoretical guarantees, which takes advantage of the kernel trick for\nhighly complicated nonlinear feature learning. Rather than simply incorporating\nexisting regularization minimization terms into CCA, this paper provides a new\nlearning paradigm for CCA and is the first to derive a coupled feature\nselection based CCA algorithm that guarantees convergence. More significantly,\nfor CCA, the newly-derived RMEN-CCA bridges the gap between measurement of\nrelevance and coupled feature selection. Moreover, it is nontrivial to tackle\ndirectly the RMEN-CCA by previous optimization approaches derived from its\nsophisticated model architecture. Therefore, this paper further offers a bridge\nbetween a new optimization problem and an existing efficient iterative\napproach. As a consequence, the RMEN-CCA can overcome the limitation of CCA and\naddress large-scale and streaming data problems. Experimental results on four\npopular competing datasets illustrate that the RMEN-CCA performs more\neffectively and efficiently than do state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 12:00:53 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 07:38:17 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Zhang", "Peng-Bo", ""], ["Yang", "Zhi-Xin", ""]]}, {"id": "1711.05084", "submitter": "Gongze Cao", "authors": "Gongze Cao, Yezhou Yang, Jie Lei, Cheng Jin, Yang Liu, Mingli Song", "title": "TripletGAN: Training Generative Model with Triplet Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an effective way of metric learning, triplet loss has been widely used in\nmany deep learning tasks, including face recognition and person-ReID, leading\nto many states of the arts. The main innovation of triplet loss is using\nfeature map to replace softmax in the classification task. Inspired by this\nconcept, we propose here a new adversarial modeling method by substituting the\nclassification loss of discriminator with triplet loss. Theoretical proof based\non IPM (Integral probability metric) demonstrates that such setting will help\nthe generator converge to the given distribution theoretically under some\nconditions. Moreover, since triplet loss requires the generator to maximize\ndistance within a class, we justify tripletGAN is also helpful to prevent mode\ncollapse through both theory and experiment.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 12:45:10 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Cao", "Gongze", ""], ["Yang", "Yezhou", ""], ["Lei", "Jie", ""], ["Jin", "Cheng", ""], ["Liu", "Yang", ""], ["Song", "Mingli", ""]]}, {"id": "1711.05099", "submitter": "Maxwell Hutchinson", "authors": "Maxwell L. Hutchinson, Erin Antono, Brenna M. Gibbons, Sean Paradiso,\n  Julia Ling, Bryce Meredig", "title": "Overcoming data scarcity with transfer learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.mtrl-sci stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite increasing focus on data publication and discovery in materials\nscience and related fields, the global view of materials data is highly sparse.\nThis sparsity encourages training models on the union of multiple datasets, but\nsimple unions can prove problematic as (ostensibly) equivalent properties may\nbe measured or computed differently depending on the data source. These hidden\ncontextual differences introduce irreducible errors into analyses,\nfundamentally limiting their accuracy. Transfer learning, where information\nfrom one dataset is used to inform a model on another, can be an effective tool\nfor bridging sparse data while preserving the contextual differences in the\nunderlying measurements. Here, we describe and compare three techniques for\ntransfer learning: multi-task, difference, and explicit latent variable\narchitectures. We show that difference architectures are most accurate in the\nmulti-fidelity case of mixed DFT and experimental band gaps, while multi-task\nmost improves classification performance of color with band gaps. For\nactivation energies of steps in NO reduction, the explicit latent variable\nmethod is not only the most accurate, but also enjoys cancellation of errors in\nfunctions that depend on multiple tasks. These results motivate the publication\nof high quality materials datasets that encode transferable information,\nindependent of industrial or academic interest in the particular labels, and\nencourage further development and application of transfer learning methods to\nmaterials informatics problems.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 12:54:51 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Hutchinson", "Maxwell L.", ""], ["Antono", "Erin", ""], ["Gibbons", "Brenna M.", ""], ["Paradiso", "Sean", ""], ["Ling", "Julia", ""], ["Meredig", "Bryce", ""]]}, {"id": "1711.05101", "submitter": "Ilya Loshchilov", "authors": "Ilya Loshchilov, Frank Hutter", "title": "Decoupled Weight Decay Regularization", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  L$_2$ regularization and weight decay regularization are equivalent for\nstandard stochastic gradient descent (when rescaled by the learning rate), but\nas we demonstrate this is \\emph{not} the case for adaptive gradient algorithms,\nsuch as Adam. While common implementations of these algorithms employ L$_2$\nregularization (often calling it \"weight decay\" in what may be misleading due\nto the inequivalence we expose), we propose a simple modification to recover\nthe original formulation of weight decay regularization by \\emph{decoupling}\nthe weight decay from the optimization steps taken w.r.t. the loss function. We\nprovide empirical evidence that our proposed modification (i) decouples the\noptimal choice of weight decay factor from the setting of the learning rate for\nboth standard SGD and Adam and (ii) substantially improves Adam's\ngeneralization performance, allowing it to compete with SGD with momentum on\nimage classification datasets (on which it was previously typically\noutperformed by the latter). Our proposed decoupled weight decay has already\nbeen adopted by many researchers, and the community has implemented it in\nTensorFlow and PyTorch; the complete source code for our experiments is\navailable at https://github.com/loshchil/AdamW-and-SGDW\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 14:24:06 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 14:03:35 GMT"}, {"version": "v3", "created": "Fri, 4 Jan 2019 21:01:49 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Loshchilov", "Ilya", ""], ["Hutter", "Frank", ""]]}, {"id": "1711.05102", "submitter": "Qianqian Yang", "authors": "Qianqian Yang, Pablo Piantanida, Deniz G\\\"und\\\"uz", "title": "The Multi-layer Information Bottleneck Problem", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The muti-layer information bottleneck (IB) problem, where information is\npropagated (or successively refined) from layer to layer, is considered. Based\non information forwarded by the preceding layer, each stage of the network is\nrequired to preserve a certain level of relevance with regards to a specific\nhidden variable, quantified by the mutual information. The hidden variables and\nthe source can be arbitrarily correlated. The optimal trade-off between rates\nof relevance and compression (or complexity) is obtained through a\nsingle-letter characterization, referred to as the rate-relevance region.\nConditions of successive refinabilty are given. Binary source with BSC hidden\nvariables and binary source with BSC/BEC mixed hidden variables are both proved\nto be successively refinable. We further extend our result to Guassian models.\nA counterexample of successive refinability is also provided.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 14:24:37 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Yang", "Qianqian", ""], ["Piantanida", "Pablo", ""], ["G\u00fcnd\u00fcz", "Deniz", ""]]}, {"id": "1711.05136", "submitter": "Guillaume Bellec", "authors": "Guillaume Bellec, David Kappel, Wolfgang Maass and Robert Legenstein", "title": "Deep Rewiring: Training very sparse deep networks", "comments": "Accepted for publication at ICLR 2018. 10 pages (12 with references,\n  24 with appendix), 4 Figures in the main text. Reviews are available at:\n  https://openreview.net/forum?id=BJ_wN01C- . This recent version contains\n  minor corrections in the appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic hardware tends to pose limits on the connectivity of deep\nnetworks that one can run on them. But also generic hardware and software\nimplementations of deep learning run more efficiently for sparse networks.\nSeveral methods exist for pruning connections of a neural network after it was\ntrained without connectivity constraints. We present an algorithm, DEEP R, that\nenables us to train directly a sparsely connected neural network. DEEP R\nautomatically rewires the network during supervised training so that\nconnections are there where they are most needed for the task, while its total\nnumber is all the time strictly bounded. We demonstrate that DEEP R can be used\nto train very sparse feedforward and recurrent neural networks on standard\nbenchmark tasks with just a minor loss in performance. DEEP R is based on a\nrigorous theoretical foundation that views rewiring as stochastic sampling of\nnetwork configurations from a posterior.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 15:02:47 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 18:33:53 GMT"}, {"version": "v3", "created": "Fri, 2 Feb 2018 15:57:44 GMT"}, {"version": "v4", "created": "Mon, 5 Feb 2018 11:01:41 GMT"}, {"version": "v5", "created": "Tue, 7 Aug 2018 18:12:10 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Bellec", "Guillaume", ""], ["Kappel", "David", ""], ["Maass", "Wolfgang", ""], ["Legenstein", "Robert", ""]]}, {"id": "1711.05144", "submitter": "Seth  Neel", "authors": "Michael Kearns, Seth Neel, Aaron Roth, Zhiwei Steven Wu", "title": "Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup\n  Fairness", "comments": "Added new experimental results and a slightly modified fairness\n  definition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most prevalent notions of fairness in machine learning are statistical\ndefinitions: they fix a small collection of pre-defined groups, and then ask\nfor parity of some statistic of the classifier across these groups. Constraints\nof this form are susceptible to intentional or inadvertent \"fairness\ngerrymandering\", in which a classifier appears to be fair on each individual\ngroup, but badly violates the fairness constraint on one or more structured\nsubgroups defined over the protected attributes. We propose instead to demand\nstatistical notions of fairness across exponentially (or infinitely) many\nsubgroups, defined by a structured class of functions over the protected\nattributes. This interpolates between statistical definitions of fairness and\nrecently proposed individual notions of fairness, but raises several\ncomputational challenges. It is no longer clear how to audit a fixed classifier\nto see if it satisfies such a strong definition of fairness. We prove that the\ncomputational problem of auditing subgroup fairness for both equality of false\npositive rates and statistical parity is equivalent to the problem of weak\nagnostic learning, which means it is computationally hard in the worst case,\neven for simple structured subclasses.\n  We then derive two algorithms that provably converge to the best fair\nclassifier, given access to oracles which can solve the agnostic learning\nproblem. The algorithms are based on a formulation of subgroup fairness as a\ntwo-player zero-sum game between a Learner and an Auditor. Our first algorithm\nprovably converges in a polynomial number of steps. Our second algorithm enjoys\nonly provably asymptotic convergence, but has the merit of simplicity and\nfaster per-step computation. We implement the simpler algorithm using linear\nregression as a heuristic oracle, and show that we can effectively both audit\nand learn fair classifiers on real datasets.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 15:34:27 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 13:55:17 GMT"}, {"version": "v3", "created": "Mon, 8 Jan 2018 01:15:28 GMT"}, {"version": "v4", "created": "Thu, 12 Apr 2018 21:15:28 GMT"}, {"version": "v5", "created": "Mon, 3 Dec 2018 18:18:34 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Kearns", "Michael", ""], ["Neel", "Seth", ""], ["Roth", "Aaron", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1711.05170", "submitter": "Diego Molla-Aliod", "authors": "Hamideh Hajiabadi, Diego Molla-Aliod, Reza Monsefi", "title": "On Extending Neural Networks with Loss Ensembles for Text Classification", "comments": "5 pages, 5 tables, 1 figure. Camera-ready submitted to The 2017\n  Australasian Language Technology Association Workshop (ALTA 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble techniques are powerful approaches that combine several weak\nlearners to build a stronger one. As a meta learning framework, ensemble\ntechniques can easily be applied to many machine learning techniques. In this\npaper we propose a neural network extended with an ensemble loss function for\ntext classification. The weight of each weak loss function is tuned within the\ntraining phase through the gradient propagation optimization method of the\nneural network. The approach is evaluated on several text classification\ndatasets. We also evaluate its performance in various environments with several\ndegrees of label noise. Experimental results indicate an improvement of the\nresults and strong resilience against label noise in comparison with other\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 16:19:34 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Hajiabadi", "Hamideh", ""], ["Molla-Aliod", "Diego", ""], ["Monsefi", "Reza", ""]]}, {"id": "1711.05174", "submitter": "Yining Wang", "authors": "Zeyuan Allen-Zhu and Yuanzhi Li and Aarti Singh and Yining Wang", "title": "Near-Optimal Discrete Optimization for Experimental Design: A Regret\n  Minimization Approach", "comments": "33 pages, 4 tables. A preliminary version of this paper titled\n  \"Near-Optimal Experimental Design via Regret Minimization\" with weaker\n  results appeared in the Proceedings of the 34th International Conference on\n  Machine Learning (ICML 2017), Sydney", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The experimental design problem concerns the selection of k points from a\npotentially large design pool of p-dimensional vectors, so as to maximize the\nstatistical efficiency regressed on the selected k design points. Statistical\nefficiency is measured by optimality criteria, including A(verage),\nD(eterminant), T(race), E(igen), V(ariance) and G-optimality. Except for the\nT-optimality, exact optimization is NP-hard.\n  We propose a polynomial-time regret minimization framework to achieve a\n$(1+\\varepsilon)$ approximation with only $O(p/\\varepsilon^2)$ design points,\nfor all the optimality criteria above.\n  In contrast, to the best of our knowledge, before our work, no\npolynomial-time algorithm achieves $(1+\\varepsilon)$ approximations for\nD/E/G-optimality, and the best poly-time algorithm achieving\n$(1+\\varepsilon)$-approximation for A/V-optimality requires $k =\n\\Omega(p^2/\\varepsilon)$ design points.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 16:21:57 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""], ["Singh", "Aarti", ""], ["Wang", "Yining", ""]]}, {"id": "1711.05189", "submitter": "Ehsan Hesamifard", "authors": "Ehsan Hesamifard, Hassan Takabi, Mehdi Ghasemi", "title": "CryptoDL: Deep Neural Networks over Encrypted Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms based on deep neural networks have achieved\nremarkable results and are being extensively used in different domains.\nHowever, the machine learning algorithms requires access to raw data which is\noften privacy sensitive. To address this issue, we develop new techniques to\nprovide solutions for running deep neural networks over encrypted data. In this\npaper, we develop new techniques to adopt deep neural networks within the\npractical limitation of current homomorphic encryption schemes. More\nspecifically, we focus on classification of the well-known convolutional neural\nnetworks (CNN). First, we design methods for approximation of the activation\nfunctions commonly used in CNNs (i.e. ReLU, Sigmoid, and Tanh) with low degree\npolynomials which is essential for efficient homomorphic encryption schemes.\nThen, we train convolutional neural networks with the approximation polynomials\ninstead of original activation functions and analyze the performance of the\nmodels. Finally, we implement convolutional neural networks over encrypted data\nand measure performance of the models. Our experimental results validate the\nsoundness of our approach with several convolutional neural networks with\nvarying number of layers and structures. When applied to the MNIST optical\ncharacter recognition tasks, our approach achieves 99.52\\% accuracy which\nsignificantly outperforms the state-of-the-art solutions and is very close to\nthe accuracy of the best non-private version, 99.77\\%. Also, it can make close\nto 164000 predictions per hour. We also applied our approach to CIFAR-10, which\nis much more complex compared to MNIST, and were able to achieve 91.5\\%\naccuracy with approximation polynomials used as activation functions. These\nresults show that CryptoDL provides efficient, accurate and scalable\nprivacy-preserving predictions.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 16:53:39 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Hesamifard", "Ehsan", ""], ["Takabi", "Hassan", ""], ["Ghasemi", "Mehdi", ""]]}, {"id": "1711.05195", "submitter": "Shai Ben-David", "authors": "Shai Ben-David, Pavel Hrubes, Shay Moran, Amir Shpilka and Amir\n  Yehudayoff", "title": "A learning problem that is independent of the set theory ZFC axioms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following statistical estimation problem: given a family F of\nreal valued functions over some domain X and an i.i.d. sample drawn from an\nunknown distribution P over X, find h in F such that the expectation of h\nw.r.t. P is probably approximately equal to the supremum over expectations on\nmembers of F. This Expectation Maximization (EMX) problem captures many well\nstudied learning problems; in fact, it is equivalent to Vapnik's general\nsetting of learning.\n  Surprisingly, we show that the EMX learnability, as well as the learning\nrates of some basic class F, depend on the cardinality of the continuum and is\ntherefore independent of the set theory ZFC axioms (that are widely accepted as\na formalization of the notion of a mathematical proof).\n  We focus on the case where the functions in F are Boolean, which generalizes\nclassification problems. We study the interaction between the statistical\nsample complexity of F and its combinatorial structure. We introduce a new\nversion of sample compression schemes and show that it characterizes EMX\nlearnability for a wide family of classes. However, we show that for the class\nof finite subsets of the real line, the existence of such compression schemes\nis independent of set theory. We conclude that the learnability of that class\nwith respect to the family of probability distributions of countable support is\nindependent of the set theory ZFC axioms.\n  We also explore the existence of a \"VC-dimension-like\" parameter that\ncaptures learnability in this setting. Our results imply that that there exist\nno \"finitary\" combinatorial parameter that characterizes EMX learnability in a\nway similar to the VC-dimension based characterization of binary valued\nclassification problems.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 16:58:54 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Ben-David", "Shai", ""], ["Hrubes", "Pavel", ""], ["Moran", "Shay", ""], ["Shpilka", "Amir", ""], ["Yehudayoff", "Amir", ""]]}, {"id": "1711.05197", "submitter": "Daniel Heestermans Svendsen", "authors": "Daniel Heestermans Svendsen, Luca Martino, Manuel Campos-Taberner,\n  Francisco Javier Garc\\'ia-Haro and Gustau Camps-Valls", "title": "Joint Gaussian Processes for Biophysical Parameter Retrieval", "comments": "21 pages single column, Accepted for publication in IEEE Transactions\n  on Geoscience and Remote Sensing", "journal-ref": null, "doi": "10.1109/TGRS.2017.2767205", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving inverse problems is central to geosciences and remote sensing.\nRadiative transfer models (RTMs) represent mathematically the physical laws\nwhich govern the phenomena in remote sensing applications (forward models). The\nnumerical inversion of the RTM equations is a challenging and computationally\ndemanding problem, and for this reason, often the application of a nonlinear\nstatistical regression is preferred. In general, regression models predict the\nbiophysical parameter of interest from the corresponding received radiance.\nHowever, this approach does not employ the physical information encoded in the\nRTMs. An alternative strategy, which attempts to include the physical\nknowledge, consists in learning a regression model trained using data simulated\nby an RTM code. In this work, we introduce a nonlinear nonparametric regression\nmodel which combines the benefits of the two aforementioned approaches. The\ninversion is performed taking into account jointly both real observations and\nRTM-simulated data. The proposed Joint Gaussian Process (JGP) provides a solid\nframework for exploiting the regularities between the two types of data. The\nJGP automatically detects the relative quality of the simulated and real data,\nand combines them accordingly. This occurs by learning an additional\nhyper-parameter w.r.t. a standard GP model, and fitting parameters through\nmaximizing the pseudo-likelihood of the real observations. The resulting scheme\nis both simple and robust, i.e., capable of adapting to different scenarios.\nThe advantages of the JGP method compared to benchmark strategies are shown\nconsidering RTM-simulated and real observations in different experiments.\nSpecifically, we consider leaf area index (LAI) retrieval from Landsat data\ncombined with simulated data generated by the PROSAIL model.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 17:03:51 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Svendsen", "Daniel Heestermans", ""], ["Martino", "Luca", ""], ["Campos-Taberner", "Manuel", ""], ["Garc\u00eda-Haro", "Francisco Javier", ""], ["Camps-Valls", "Gustau", ""]]}, {"id": "1711.05225", "submitter": "Pranav Rajpurkar", "authors": "Pranav Rajpurkar, Jeremy Irvin, Kaylie Zhu, Brandon Yang, Hershel\n  Mehta, Tony Duan, Daisy Ding, Aarti Bagul, Curtis Langlotz, Katie Shpanskaya,\n  Matthew P. Lungren, Andrew Y. Ng", "title": "CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an algorithm that can detect pneumonia from chest X-rays at a\nlevel exceeding practicing radiologists. Our algorithm, CheXNet, is a 121-layer\nconvolutional neural network trained on ChestX-ray14, currently the largest\npublicly available chest X-ray dataset, containing over 100,000 frontal-view\nX-ray images with 14 diseases. Four practicing academic radiologists annotate a\ntest set, on which we compare the performance of CheXNet to that of\nradiologists. We find that CheXNet exceeds average radiologist performance on\nthe F1 metric. We extend CheXNet to detect all 14 diseases in ChestX-ray14 and\nachieve state of the art results on all 14 diseases.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 17:58:50 GMT"}, {"version": "v2", "created": "Sat, 25 Nov 2017 04:21:27 GMT"}, {"version": "v3", "created": "Mon, 25 Dec 2017 11:09:06 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Rajpurkar", "Pranav", ""], ["Irvin", "Jeremy", ""], ["Zhu", "Kaylie", ""], ["Yang", "Brandon", ""], ["Mehta", "Hershel", ""], ["Duan", "Tony", ""], ["Ding", "Daisy", ""], ["Bagul", "Aarti", ""], ["Langlotz", "Curtis", ""], ["Shpanskaya", "Katie", ""], ["Lungren", "Matthew P.", ""], ["Ng", "Andrew Y.", ""]]}, {"id": "1711.05240", "submitter": "Omer Goldman", "authors": "Omer Goldman and Veronica Latcinnik and Udi Naveh and Amir Globerson\n  and Jonathan Berant", "title": "Weakly-supervised Semantic Parsing with Abstract Examples", "comments": "CNLVR,NLVR. Accepted to ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training semantic parsers from weak supervision (denotations) rather than\nstrong supervision (programs) complicates training in two ways. First, a large\nsearch space of potential programs needs to be explored at training time to\nfind a correct program. Second, spurious programs that accidentally lead to a\ncorrect denotation add noise to training. In this work we propose that in\nclosed worlds with clear semantic types, one can substantially alleviate these\nproblems by utilizing an abstract representation, where tokens in both the\nlanguage utterance and program are lifted to an abstract form. We show that\nthese abstractions can be defined with a handful of lexical rules and that they\nresult in sharing between different examples that alleviates the difficulties\nin training. To test our approach, we develop the first semantic parser for\nCNLVR, a challenging visual reasoning dataset, where the search space is large\nand overcoming spuriousness is critical, because denotations are either TRUE or\nFALSE, and thus random programs are likely to lead to a correct denotation. Our\nmethod substantially improves performance, and reaches 82.5% accuracy, a 14.7%\nabsolute accuracy improvement compared to the best reported accuracy so far.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 18:29:05 GMT"}, {"version": "v2", "created": "Sun, 22 Apr 2018 12:12:06 GMT"}, {"version": "v3", "created": "Sat, 12 May 2018 20:12:13 GMT"}, {"version": "v4", "created": "Thu, 24 May 2018 14:22:57 GMT"}, {"version": "v5", "created": "Wed, 13 Mar 2019 09:30:38 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Goldman", "Omer", ""], ["Latcinnik", "Veronica", ""], ["Naveh", "Udi", ""], ["Globerson", "Amir", ""], ["Berant", "Jonathan", ""]]}, {"id": "1711.05246", "submitter": "Sean Welleck", "authors": "Sean Welleck, Zixin Yao, Yu Gai, Jialin Mao, Zheng Zhang, Kyunghyun\n  Cho", "title": "Loss Functions for Multiset Prediction", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of multiset prediction. The goal of multiset prediction\nis to train a predictor that maps an input to a multiset consisting of multiple\nitems. Unlike existing problems in supervised learning, such as classification,\nranking and sequence generation, there is no known order among items in a\ntarget multiset, and each item in the multiset may appear more than once,\nmaking this problem extremely challenging. In this paper, we propose a novel\nmultiset loss function by viewing this problem from the perspective of\nsequential decision making. The proposed multiset loss function is empirically\nevaluated on two families of datasets, one synthetic and the other real, with\nvarying levels of difficulty, against various baseline loss functions including\nreinforcement learning, sequence, and aggregated distribution matching loss\nfunctions. The experiments reveal the effectiveness of the proposed loss\nfunction over the others.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 18:43:22 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 18:32:36 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Welleck", "Sean", ""], ["Yao", "Zixin", ""], ["Gai", "Yu", ""], ["Mao", "Jialin", ""], ["Zhang", "Zheng", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1711.05253", "submitter": "Anusha Nagabandi", "authors": "Anusha Nagabandi, Guangzhao Yang, Thomas Asmar, Ravi Pandya, Gregory\n  Kahn, Sergey Levine, Ronald S. Fearing", "title": "Learning Image-Conditioned Dynamics Models for Control of Under-actuated\n  Legged Millirobots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millirobots are a promising robotic platform for many applications due to\ntheir small size and low manufacturing costs. Legged millirobots, in\nparticular, can provide increased mobility in complex environments and improved\nscaling of obstacles. However, controlling these small, highly dynamic, and\nunderactuated legged systems is difficult. Hand-engineered controllers can\nsometimes control these legged millirobots, but they have difficulties with\ndynamic maneuvers and complex terrains. We present an approach for controlling\na real-world legged millirobot that is based on learned neural network models.\nUsing less than 17 minutes of data, our method can learn a predictive model of\nthe robot's dynamics that can enable effective gaits to be synthesized on the\nfly for following user-specified waypoints on a given terrain. Furthermore, by\nleveraging expressive, high-capacity neural network models, our approach allows\nfor these predictions to be directly conditioned on camera images, endowing the\nrobot with the ability to predict how different terrains might affect its\ndynamics. This enables sample-efficient and effective learning for locomotion\nof a dynamic legged millirobot on various terrains, including gravel, turf,\ncarpet, and styrofoam. Experiment videos can be found at\nhttps://sites.google.com/view/imageconddyn\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 18:56:12 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 17:32:20 GMT"}, {"version": "v3", "created": "Fri, 30 Mar 2018 17:37:00 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Nagabandi", "Anusha", ""], ["Yang", "Guangzhao", ""], ["Asmar", "Thomas", ""], ["Pandya", "Ravi", ""], ["Kahn", "Gregory", ""], ["Levine", "Sergey", ""], ["Fearing", "Ronald S.", ""]]}, {"id": "1711.05255", "submitter": "Qianli Ma", "authors": "Qianli Ma, Lifeng Shen, Garrison W. Cottrell", "title": "Deep-ESN: A Multiple Projection-encoding Hierarchical Reservoir\n  Computing Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an efficient recurrent neural network (RNN) model, reservoir computing\n(RC) models, such as Echo State Networks, have attracted widespread attention\nin the last decade. However, while they have had great success with time series\ndata [1], [2], many time series have a multiscale structure, which a\nsingle-hidden-layer RC model may have difficulty capturing. In this paper, we\npropose a novel hierarchical reservoir computing framework we call Deep Echo\nState Networks (Deep-ESNs). The most distinctive feature of a Deep-ESN is its\nability to deal with time series through hierarchical projections.\nSpecifically, when an input time series is projected into the high-dimensional\necho-state space of a reservoir, a subsequent encoding layer (e.g., a PCA,\nautoencoder, or a random projection) can project the echo-state representations\ninto a lower-dimensional space. These low-dimensional representations can then\nbe processed by another ESN. By using projection layers and encoding layers\nalternately in the hierarchical framework, a Deep-ESN can not only attenuate\nthe effects of the collinearity problem in ESNs, but also fully take advantage\nof the temporal kernel property of ESNs to explore multiscale dynamics of time\nseries. To fuse the multiscale representations obtained by each reservoir, we\nadd connections from each encoding layer to the last output layer. Theoretical\nanalyses prove that stability of a Deep-ESN is guaranteed by the echo state\nproperty (ESP), and the time complexity is equivalent to a conventional ESN.\nExperimental results on some artificial and real world time series demonstrate\nthat Deep-ESNs can capture multiscale dynamics, and outperform both standard\nESNs and previous hierarchical ESN-based models.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 13:33:46 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Ma", "Qianli", ""], ["Shen", "Lifeng", ""], ["Cottrell", "Garrison W.", ""]]}, {"id": "1711.05305", "submitter": "Chenxin Ma", "authors": "Chenxin Ma, Martin Jaggi, Frank E. Curtis, Nathan Srebro and Martin\n  Tak\\'a\\v{c}", "title": "An Accelerated Communication-Efficient Primal-Dual Optimization\n  Framework for Structured Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed optimization algorithms are essential for training machine\nlearning models on very large-scale datasets. However, they often suffer from\ncommunication bottlenecks. Confronting this issue, a communication-efficient\nprimal-dual coordinate ascent framework (CoCoA) and its improved variant CoCoA+\nhave been proposed, achieving a convergence rate of $\\mathcal{O}(1/t)$ for\nsolving empirical risk minimization problems with Lipschitz continuous losses.\nIn this paper, an accelerated variant of CoCoA+ is proposed and shown to\npossess a convergence rate of $\\mathcal{O}(1/t^2)$ in terms of reducing\nsuboptimality. The analysis of this rate is also notable in that the\nconvergence rate bounds involve constants that, except in extreme cases, are\nsignificantly reduced compared to those previously provided for CoCoA+. The\nresults of numerical experiments are provided to show that acceleration can\nlead to significant performance gains.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 20:19:10 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Ma", "Chenxin", ""], ["Jaggi", "Martin", ""], ["Curtis", "Frank E.", ""], ["Srebro", "Nathan", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1711.05323", "submitter": "Ahmad Beirami", "authors": "Ahmad Beirami and Meisam Razaviyayn and Shahin Shahrampour and Vahid\n  Tarokh", "title": "On Optimal Generalizability in Parametric Learning", "comments": "Proc. of 2017 Advances in Neural Information Processing Systems (NIPS\n  2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the parametric learning problem, where the objective of the\nlearner is determined by a parametric loss function. Employing empirical risk\nminimization with possibly regularization, the inferred parameter vector will\nbe biased toward the training samples. Such bias is measured by the cross\nvalidation procedure in practice where the data set is partitioned into a\ntraining set used for training and a validation set, which is not used in\ntraining and is left to measure the out-of-sample performance. A classical\ncross validation strategy is the leave-one-out cross validation (LOOCV) where\none sample is left out for validation and training is done on the rest of the\nsamples that are presented to the learner, and this process is repeated on all\nof the samples. LOOCV is rarely used in practice due to the high computational\ncomplexity. In this paper, we first develop a computationally efficient\napproximate LOOCV (ALOOCV) and provide theoretical guarantees for its\nperformance. Then we use ALOOCV to provide an optimization algorithm for\nfinding the regularizer in the empirical risk minimization framework. In our\nnumerical experiments, we illustrate the accuracy and efficiency of ALOOCV as\nwell as our proposed framework for the optimization of the regularizer.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 21:37:03 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Beirami", "Ahmad", ""], ["Razaviyayn", "Meisam", ""], ["Shahrampour", "Shahin", ""], ["Tarokh", "Vahid", ""]]}, {"id": "1711.05365", "submitter": "Sajid Ahmed", "authors": "Sajid Ahmed, Farshid Rayhan, Asif Mahbub, Md. Rafsan Jani, Swakkhar\n  Shatabda, Dewan Md. Farid and Chowdhury Mofizur Rahman", "title": "LIUBoost : Locality Informed Underboosting for Imbalanced Data\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of class imbalance along with class-overlapping has become a\nmajor issue in the domain of supervised learning. Most supervised learning\nalgorithms assume equal cardinality of the classes under consideration while\noptimizing the cost function and this assumption does not hold true for\nimbalanced datasets which results in sub-optimal classification. Therefore,\nvarious approaches, such as undersampling, oversampling, cost-sensitive\nlearning and ensemble based methods have been proposed for dealing with\nimbalanced datasets. However, undersampling suffers from information loss,\noversampling suffers from increased runtime and potential overfitting while\ncost-sensitive methods suffer due to inadequately defined cost assignment\nschemes. In this paper, we propose a novel boosting based method called\nLIUBoost. LIUBoost uses under sampling for balancing the datasets in every\nboosting iteration like RUSBoost while incorporating a cost term for every\ninstance based on their hardness into the weight update formula minimizing the\ninformation loss introduced by undersampling. LIUBoost has been extensively\nevaluated on 18 imbalanced datasets and the results indicate significant\nimprovement over existing best performing method RUSBoost.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 00:44:41 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Ahmed", "Sajid", ""], ["Rayhan", "Farshid", ""], ["Mahbub", "Asif", ""], ["Jani", "Md. Rafsan", ""], ["Shatabda", "Swakkhar", ""], ["Farid", "Dewan Md.", ""], ["Rahman", "Chowdhury Mofizur", ""]]}, {"id": "1711.05374", "submitter": "Huan Song", "authors": "Huan Song, Jayaraman J. Thiagarajan, Prasanna Sattigeri, Andreas\n  Spanias", "title": "Optimizing Kernel Machines using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building highly non-linear and non-parametric models is central to several\nstate-of-the-art machine learning systems. Kernel methods form an important\nclass of techniques that induce a reproducing kernel Hilbert space (RKHS) for\ninferring non-linear models through the construction of similarity functions\nfrom data. These methods are particularly preferred in cases where the training\ndata sizes are limited and when prior knowledge of the data similarities is\navailable. Despite their usefulness, they are limited by the computational\ncomplexity and their inability to support end-to-end learning with a\ntask-specific objective. On the other hand, deep neural networks have become\nthe de facto solution for end-to-end inference in several learning paradigms.\nIn this article, we explore the idea of using deep architectures to perform\nkernel machine optimization, for both computational efficiency and end-to-end\ninferencing. To this end, we develop the DKMO (Deep Kernel Machine\nOptimization) framework, that creates an ensemble of dense embeddings using\nNystrom kernel approximations and utilizes deep learning to generate\ntask-specific representations through the fusion of the embeddings.\nIntuitively, the filters of the network are trained to fuse information from an\nensemble of linear subspaces in the RKHS. Furthermore, we introduce the kernel\ndropout regularization to enable improved training convergence. Finally, we\nextend this framework to the multiple kernel case, by coupling a global fusion\nlayer with pre-trained deep kernel machines for each of the constituent\nkernels. Using case studies with limited training data, and lack of explicit\nfeature sources, we demonstrate the effectiveness of our framework over\nconventional model inferencing techniques.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 01:30:58 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Song", "Huan", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Sattigeri", "Prasanna", ""], ["Spanias", "Andreas", ""]]}, {"id": "1711.05376", "submitter": "Soheil Kolouri", "authors": "Soheil Kolouri, Gustavo K. Rohde, Heiko Hoffmann", "title": "Sliced Wasserstein Distance for Learning Gaussian Mixture Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian mixture models (GMM) are powerful parametric tools with many\napplications in machine learning and computer vision. Expectation maximization\n(EM) is the most popular algorithm for estimating the GMM parameters. However,\nEM guarantees only convergence to a stationary point of the log-likelihood\nfunction, which could be arbitrarily worse than the optimal solution. Inspired\nby the relationship between the negative log-likelihood function and the\nKullback-Leibler (KL) divergence, we propose an alternative formulation for\nestimating the GMM parameters using the sliced Wasserstein distance, which\ngives rise to a new algorithm. Specifically, we propose minimizing the\nsliced-Wasserstein distance between the mixture model and the data distribution\nwith respect to the GMM parameters. In contrast to the KL-divergence, the\nenergy landscape for the sliced-Wasserstein distance is more well-behaved and\ntherefore more suitable for a stochastic gradient descent scheme to obtain the\noptimal GMM parameters. We show that our formulation results in parameter\nestimates that are more robust to random initializations and demonstrate that\nit can estimate high-dimensional data distributions more faithfully than the EM\nalgorithm.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 01:33:01 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 02:05:11 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Kolouri", "Soheil", ""], ["Rohde", "Gustavo K.", ""], ["Hoffmann", "Heiko", ""]]}, {"id": "1711.05391", "submitter": "Tianpei Xie", "authors": "Tianpei Xie, Sijia Liu, Alfred O. Hero III", "title": "Semiblind subgraph reconstruction in Gaussian graphical models", "comments": "7 pages; 5 figures; 2017 5th IEEE Global Conference on Signal and\n  Information Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a social network where only a few nodes (agents) have meaningful\ninteractions in the sense that the conditional dependency graph over node\nattribute variables (behaviors) is sparse. A company that can only observe the\ninteractions between its own customers will generally not be able to accurately\nestimate its customers' dependency subgraph: it is blinded to any external\ninteractions of its customers and this blindness creates false edges in its\nsubgraph. In this paper we address the semiblind scenario where the company has\naccess to a noisy summary of the complementary subgraph connecting external\nagents, e.g., provided by a consolidator. The proposed framework applies to\nother applications as well, including field estimation from a network of awake\nand sleeping sensors and privacy-constrained information sharing over social\nsubnetworks. We propose a penalized likelihood approach in the context of a\ngraph signal obeying a Gaussian graphical models (GGM). We use a convex-concave\niterative optimization algorithm to maximize the penalized likelihood.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 03:04:51 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Xie", "Tianpei", ""], ["Liu", "Sijia", ""], ["Hero", "Alfred O.", "III"]]}, {"id": "1711.05401", "submitter": "Chandrahas Dewangan", "authors": "Srinivas Ravishankar, Chandrahas, Partha Pratim Talukdar", "title": "Revisiting Simple Neural Networks for Learning Representations of\n  Knowledge Graphs", "comments": "7 pages, submitted to and accepted in Automated Knowledge Base\n  Construction (AKBC) Workshop 2017, at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of learning vector representations for entities and\nrelations in Knowledge Graphs (KGs) for Knowledge Base Completion (KBC). This\nproblem has received significant attention in the past few years and multiple\nmethods have been proposed. Most of the existing methods in the literature use\na predefined characteristic scoring function for evaluating the correctness of\nKG triples. These scoring functions distinguish correct triples (high score)\nfrom incorrect ones (low score). However, their performance vary across\ndifferent datasets. In this work, we demonstrate that a simple neural network\nbased score function can consistently achieve near start-of-the-art performance\non multiple datasets. We also quantitatively demonstrate biases in standard\nbenchmark datasets, and highlight the need to perform evaluation spanning\nvarious datasets.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 04:12:27 GMT"}, {"version": "v2", "created": "Fri, 17 Nov 2017 10:02:28 GMT"}, {"version": "v3", "created": "Mon, 8 Jan 2018 07:20:37 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Ravishankar", "Srinivas", ""], ["Chandrahas", "", ""], ["Talukdar", "Partha Pratim", ""]]}, {"id": "1711.05406", "submitter": "Bin-Bin Gao", "authors": "Bin-Bin Gao and Jian-Jun Wang", "title": "A Fast and Robust TSVM for Pattern Classification", "comments": "14 pages, Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twin support vector machine~(TSVM) is a powerful learning algorithm by\nsolving a pair of smaller SVM-type problems. However, there are still some\nspecific issues such as low efficiency and weak robustness when it is faced\nwith some real applications. In this paper, we propose a Fast and Robust\nTSVM~(FR-TSVM) to deal with the above issues. In order to alleviate the effects\nof noisy inputs, we propose an effective fuzzy membership function and\nreformulate the TSVMs such that different input instances can make different\ncontributions to the learning of the separating hyperplanes. To further speed\nup the training procedure, we develop an efficient coordinate descent algorithm\nwith shirking to solve the involved a pair of quadratic programming problems\n(QPPs). Moreover, theoretical foundations of the proposed model are analyzed in\ndetails. The experimental results on several artificial and benchmark datasets\nindicate that the FR-TSVM not only obtains a fast learning speed but also shows\na robust classification performance. Code has been made available at:\nhttps://github.com/gaobb/FR-TSVM.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 04:48:14 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 05:00:05 GMT"}, {"version": "v3", "created": "Sun, 28 Jul 2019 17:57:22 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Gao", "Bin-Bin", ""], ["Wang", "Jian-Jun", ""]]}, {"id": "1711.05407", "submitter": "Rushil Anirudh", "authors": "Rushil Anirudh, Jayaraman J. Thiagarajan, Rahul Sridhar, Peer-Timo\n  Bremer", "title": "MARGIN: Uncovering Deep Neural Networks using Graph Signal Analysis", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability has emerged as a crucial aspect of building trust in machine\nlearning systems, aimed at providing insights into the working of complex\nneural networks that are otherwise opaque to a user. There are a plethora of\nexisting solutions addressing various aspects of interpretability ranging from\nidentifying prototypical samples in a dataset to explaining image predictions\nor explaining mis-classifications. While all of these diverse techniques\naddress seemingly different aspects of interpretability, we hypothesize that a\nlarge family of interepretability tasks are variants of the same central\nproblem which is identifying \\emph{relative} change in a model's prediction.\nThis paper introduces MARGIN, a simple yet general approach to address a large\nset of interpretability tasks MARGIN exploits ideas rooted in graph signal\nanalysis to determine influential nodes in a graph, which are defined as those\nnodes that maximally describe a function defined on the graph. By carefully\ndefining task-specific graphs and functions, we demonstrate that MARGIN\noutperforms existing approaches in a number of disparate interpretability\nchallenges.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 04:52:38 GMT"}, {"version": "v2", "created": "Sat, 10 Feb 2018 15:58:09 GMT"}, {"version": "v3", "created": "Tue, 4 Dec 2018 04:36:36 GMT"}, {"version": "v4", "created": "Fri, 15 Jan 2021 20:40:23 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Anirudh", "Rushil", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Sridhar", "Rahul", ""], ["Bremer", "Peer-Timo", ""]]}, {"id": "1711.05411", "submitter": "Anirudh Goyal", "authors": "Anirudh Goyal, Alessandro Sordoni, Marc-Alexandre C\\^ot\\'e, Nan\n  Rosemary Ke, Yoshua Bengio", "title": "Z-Forcing: Training Stochastic Recurrent Networks", "comments": "To appear in NIPS'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many efforts have been devoted to training generative latent variable models\nwith autoregressive decoders, such as recurrent neural networks (RNN).\nStochastic recurrent models have been successful in capturing the variability\nobserved in natural sequential data such as speech. We unify successful ideas\nfrom recently proposed architectures into a stochastic recurrent model: each\nstep in the sequence is associated with a latent variable that is used to\ncondition the recurrent dynamics for future steps. Training is performed with\namortized variational inference where the approximate posterior is augmented\nwith a RNN that runs backward through the sequence. In addition to maximizing\nthe variational lower bound, we ease training of the latent variables by adding\nan auxiliary cost which forces them to reconstruct the state of the backward\nrecurrent network. This provides the latent variables with a task-independent\nobjective that enhances the performance of the overall model. We found this\nstrategy to perform better than alternative approaches such as KL annealing.\nAlthough being conceptually simple, our model achieves state-of-the-art results\non standard speech benchmarks such as TIMIT and Blizzard and competitive\nperformance on sequential MNIST. Finally, we apply our model to language\nmodeling on the IMDB dataset where the auxiliary cost helps in learning\ninterpretable latent variables. Source Code:\n\\url{https://github.com/anirudh9119/zforcing_nips17}\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 05:16:49 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 05:10:54 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Goyal", "Anirudh", ""], ["Sordoni", "Alessandro", ""], ["C\u00f4t\u00e9", "Marc-Alexandre", ""], ["Ke", "Nan Rosemary", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1711.05429", "submitter": "Alok Singh", "authors": "Alok Singh, Mai Nguyen, Shweta Purawat, Daniel Crawl, Ilkay Altintas", "title": "Modular Resource Centric Learning for Workflow Performance Prediction", "comments": "This paper was presented at: 6th Workshop on Big Data Analytics:\n  Challenges, and Opportunities (BDAC) at the 27th IEEE/ACM International\n  Conference for High Performance Computing, Networking, Storage, and Analysis\n  (SC 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Workflows provide an expressive programming model for fine-grained control of\nlarge-scale applications in distributed computing environments. Accurate\nestimates of complex workflow execution metrics on large-scale machines have\nseveral key advantages. The performance of scheduling algorithms that rely on\nestimates of execution metrics degrades when the accuracy of predicted\nexecution metrics decreases. This in-progress paper presents a technique being\ndeveloped to improve the accuracy of predicted performance metrics of\nlarge-scale workflows on distributed platforms. The central idea of this work\nis to train resource-centric machine learning agents to capture complex\nrelationships between a set of program instructions and their performance\nmetrics when executed on a specific resource. This resource-centric view of a\nworkflow exploits the fact that predicting execution times of sub-modules of a\nworkflow requires monitoring and modeling of a few dynamic and static features.\nWe transform the input workflow that is essentially a directed acyclic graph of\nactions into a Physical Resource Execution Plan (PREP). This transformation\nenables us to model an arbitrarily complex workflow as a set of simpler\nprograms running on physical nodes. We delegate a machine learning model to\ncapture performance metrics for each resource type when it executes different\nprogram instructions under varying degrees of resource contention. Our\nalgorithm takes the prediction metrics from each resource agent and composes\nthe overall workflow performance metrics by utilizing the structure of the\ncorresponding Physical Resource Execution Plan.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 06:58:47 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 01:57:07 GMT"}, {"version": "v3", "created": "Tue, 17 Apr 2018 06:26:23 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Singh", "Alok", ""], ["Nguyen", "Mai", ""], ["Purawat", "Shweta", ""], ["Crawl", "Daniel", ""], ["Altintas", "Ilkay", ""]]}, {"id": "1711.05448", "submitter": "Shankar Kumar", "authors": "Shankar Kumar, Michael Nirschl, Daniel Holtmann-Rice, Hank Liao,\n  Ananda Theertha Suresh, Felix Yu", "title": "Lattice Rescoring Strategies for Long Short Term Memory Language Models\n  in Speech Recognition", "comments": "Accepted at ASRU 2017", "journal-ref": "Proceedings of ASRU 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural network (RNN) language models (LMs) and Long Short Term\nMemory (LSTM) LMs, a variant of RNN LMs, have been shown to outperform\ntraditional N-gram LMs on speech recognition tasks. However, these models are\ncomputationally more expensive than N-gram LMs for decoding, and thus,\nchallenging to integrate into speech recognizers. Recent research has proposed\nthe use of lattice-rescoring algorithms using RNNLMs and LSTMLMs as an\nefficient strategy to integrate these models into a speech recognition system.\nIn this paper, we evaluate existing lattice rescoring algorithms along with new\nvariants on a YouTube speech recognition task. Lattice rescoring using LSTMLMs\nreduces the word error rate (WER) for this task by 8\\% relative to the WER\nobtained using an N-gram LM.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 08:30:56 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Kumar", "Shankar", ""], ["Nirschl", "Michael", ""], ["Holtmann-Rice", "Daniel", ""], ["Liao", "Hank", ""], ["Suresh", "Ananda Theertha", ""], ["Yu", "Felix", ""]]}, {"id": "1711.05462", "submitter": "Caleb Robinson", "authors": "Caleb Robinson, Bistra Dilkina", "title": "A Machine Learning Approach to Modeling Human Migration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human migration is a type of human mobility, where a trip involves a person\nmoving with the intention of changing their home location. Predicting human\nmigration as accurately as possible is important in city planning applications,\ninternational trade, spread of infectious diseases, conservation planning, and\npublic policy development. Traditional human mobility models, such as gravity\nmodels or the more recent radiation model, predict human mobility flows based\non population and distance features only. These models have been validated on\ncommuting flows, a different type of human mobility, and are mainly used in\nmodeling scenarios where large amounts of prior ground truth mobility data are\nnot available. One downside of these models is that they have a fixed form and\nare therefore not able to capture more complicated migration dynamics. We\npropose machine learning models that are able to incorporate any number of\nexogenous features, to predict origin/destination human migration flows. Our\nmachine learning models outperform traditional human mobility models on a\nvariety of evaluation metrics, both in the task of predicting migrations\nbetween US counties as well as international migrations. In general, predictive\nmachine learning models of human migration will provide a flexible base with\nwhich to model human migration under different what-if conditions, such as\npotential sea level rise or population growth scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 09:10:02 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Robinson", "Caleb", ""], ["Dilkina", "Bistra", ""]]}, {"id": "1711.05475", "submitter": "Yannic Kilcher", "authors": "Yannic Kilcher, Thomas Hofmann", "title": "The best defense is a good offense: Countering black box attacks by\n  predicting slightly wrong labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-Box attacks on machine learning models occur when an attacker, despite\nhaving no access to the inner workings of a model, can successfully craft an\nattack by means of model theft. The attacker will train an own substitute model\nthat mimics the model to be attacked. The substitute can then be used to design\nattacks against the original model, for example by means of adversarial\nsamples. We put ourselves in the shoes of the defender and present a method\nthat can successfully avoid model theft by mounting a counter-attack.\nSpecifically, to any incoming query, we slightly perturb our output label\ndistribution in a way that makes substitute training infeasible. We demonstrate\nthat the perturbation does not affect the ordinary use of our model, but\nresults in an effective defense against attacks based on model theft.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 09:39:07 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Kilcher", "Yannic", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1711.05477", "submitter": "Brendon Colbert", "authors": "Brendon K. Colbert and Matthew M. Peet", "title": "A Convex Parametrization of a New Class of Universal Kernel Functions", "comments": "29 pages, 7 figures", "journal-ref": "Journal of Machine Learning Research 21.45 (2020): 1-29", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accuracy and complexity of kernel learning algorithms is determined by\nthe set of kernels over which it is able to optimize. An ideal set of kernels\nshould: admit a linear parameterization (tractability); be dense in the set of\nall kernels (accuracy); and every member should be universal so that the\nhypothesis space is infinite-dimensional (scalability). Currently, there is no\nclass of kernel that meets all three criteria - e.g. Gaussians are not\ntractable or accurate; polynomials are not scalable. We propose a new class\nthat meet all three criteria - the Tessellated Kernel (TK) class. Specifically,\nthe TK class: admits a linear parameterization using positive matrices; is\ndense in all kernels; and every element in the class is universal. This implies\nthat the use of TK kernels for learning the kernel can obviate the need for\nselecting candidate kernels in algorithms such as SimpleMKL and parameters such\nas the bandwidth. Numerical testing on soft margin Support Vector Machine (SVM)\nproblems show that algorithms using TK kernels outperform other kernel learning\nalgorithms and neural networks. Furthermore, our results show that when the\nratio of the number of training data to features is high, the improvement of TK\nover MKL increases significantly.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 09:44:18 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 00:36:23 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Colbert", "Brendon K.", ""], ["Peet", "Matthew M.", ""]]}, {"id": "1711.05482", "submitter": "Vivek Gupta", "authors": "Dhruv Mahajan, Vivek Gupta, S Sathiya Keerthi, Sellamanickam\n  Sundararajan, Shravan Narayanamurthy, Rahul Kidambi", "title": "Efficient Estimation of Generalization Error and Bias-Variance\n  Components of Ensembles", "comments": "12 Pages, 4 Figures, 12 Pages, Under Review in SDM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many applications, an ensemble of base classifiers is an effective\nsolution. The tuning of its parameters(number of classes, amount of data on\nwhich each classifier is to be trained on, etc.) requires G, the generalization\nerror of a given ensemble. The efficient estimation of G is the focus of this\npaper. The key idea is to approximate the variance of the class\nscores/probabilities of the base classifiers over the randomness imposed by the\ntraining subset by normal/beta distribution at each point x in the input\nfeature space. We estimate the parameters of the distribution using a small set\nof randomly chosen base classifiers and use those parameters to give efficient\nestimation schemes for G. We give empirical evidence for the quality of the\nvarious estimators. We also demonstrate their usefulness in making design\nchoices such as the number of classifiers in the ensemble and the size of a\nsubset of data used for training that is needed to achieve a certain value of\ngeneralization error. Our approach also has great potential for designing\ndistributed ensemble classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 10:03:01 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Mahajan", "Dhruv", ""], ["Gupta", "Vivek", ""], ["Keerthi", "S Sathiya", ""], ["Sundararajan", "Sellamanickam", ""], ["Narayanamurthy", "Shravan", ""], ["Kidambi", "Rahul", ""]]}, {"id": "1711.05519", "submitter": "HanQin Cai", "authors": "HanQin Cai, Jian-Feng Cai, Ke Wei", "title": "Accelerated Alternating Projections for Robust Principal Component\n  Analysis", "comments": null, "journal-ref": "Journal of Machine Learning Research, 20 (2019): 685-717", "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study robust PCA for the fully observed setting, which is about separating\na low rank matrix $\\boldsymbol{L}$ and a sparse matrix $\\boldsymbol{S}$ from\ntheir sum $\\boldsymbol{D}=\\boldsymbol{L}+\\boldsymbol{S}$. In this paper, a new\nalgorithm, dubbed accelerated alternating projections, is introduced for robust\nPCA which significantly improves the computational efficiency of the existing\nalternating projections proposed in [Netrapalli, Praneeth, et al., 2014] when\nupdating the low rank factor. The acceleration is achieved by first projecting\na matrix onto some low dimensional subspace before obtaining a new estimate of\nthe low rank matrix via truncated SVD. Exact recovery guarantee has been\nestablished which shows linear convergence of the proposed algorithm. Empirical\nperformance evaluations establish the advantage of our algorithm over other\nstate-of-the-art algorithms for robust PCA.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 12:24:49 GMT"}, {"version": "v2", "created": "Sun, 14 Jan 2018 04:35:12 GMT"}, {"version": "v3", "created": "Tue, 20 Nov 2018 09:11:39 GMT"}, {"version": "v4", "created": "Mon, 11 Feb 2019 01:56:32 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Cai", "HanQin", ""], ["Cai", "Jian-Feng", ""], ["Wei", "Ke", ""]]}, {"id": "1711.05560", "submitter": "Mohammad Emtiyaz Khan", "authors": "Mohammad Emtiyaz Khan, Wu Lin, Voot Tangkaratt, Zuozhu Liu, Didrik\n  Nielsen", "title": "Variational Adaptive-Newton Method for Explorative Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Variational Adaptive Newton (VAN) method which is a black-box\noptimization method especially suitable for explorative-learning tasks such as\nactive learning and reinforcement learning. Similar to Bayesian methods, VAN\nestimates a distribution that can be used for exploration, but requires\ncomputations that are similar to continuous optimization methods. Our\ntheoretical contribution reveals that VAN is a second-order method that unifies\nexisting methods in distinct fields of continuous optimization, variational\ninference, and evolution strategies. Our experimental results show that VAN\nperforms well on a wide-variety of learning tasks. This work presents a\ngeneral-purpose explorative-learning method that has the potential to improve\nlearning in areas such as active learning and reinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 13:23:29 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Khan", "Mohammad Emtiyaz", ""], ["Lin", "Wu", ""], ["Tangkaratt", "Voot", ""], ["Liu", "Zuozhu", ""], ["Nielsen", "Didrik", ""]]}, {"id": "1711.05597", "submitter": "Cheng Zhang", "authors": "Cheng Zhang, Judith Butepage, Hedvig Kjellstrom, Stephan Mandt", "title": "Advances in Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern unsupervised or semi-supervised machine learning algorithms rely\non Bayesian probabilistic models. These models are usually intractable and thus\nrequire approximate inference. Variational inference (VI) lets us approximate a\nhigh-dimensional Bayesian posterior with a simpler variational distribution by\nsolving an optimization problem. This approach has been successfully used in\nvarious models and large-scale applications. In this review, we give an\noverview of recent trends in variational inference. We first introduce standard\nmean field variational inference, then review recent advances focusing on the\nfollowing aspects: (a) scalable VI, which includes stochastic approximations,\n(b) generic VI, which extends the applicability of VI to a large class of\notherwise intractable models, such as non-conjugate models, (c) accurate VI,\nwhich includes variational models beyond the mean field approximation or with\natypical divergences, and (d) amortized VI, which implements the inference over\nlocal latent variables with inference networks. Finally, we provide a summary\nof promising future research directions.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 14:46:27 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 23:41:26 GMT"}, {"version": "v3", "created": "Tue, 23 Oct 2018 17:05:19 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Zhang", "Cheng", ""], ["Butepage", "Judith", ""], ["Kjellstrom", "Hedvig", ""], ["Mandt", "Stephan", ""]]}, {"id": "1711.05626", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta, Subburam Rajaram, Hinrich Sch\\\"utze, Bernt Andrassy", "title": "Deep Temporal-Recurrent-Replicated-Softmax for Topical Trends over Time", "comments": "In Proceedings of the 16th Annual Conference of the North American\n  Chapter of the Association for Computational Linguistics: Human Language\n  Technologies (NAACL-HLT 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic topic modeling facilitates the identification of topical trends over\ntime in temporal collections of unstructured documents. We introduce a novel\nunsupervised neural dynamic topic model named as Recurrent Neural\nNetwork-Replicated Softmax Model (RNNRSM), where the discovered topics at each\ntime influence the topic discovery in the subsequent time steps. We account for\nthe temporal ordering of documents by explicitly modeling a joint distribution\nof latent topical dependencies over time, using distributional estimators with\ntemporal recurrent connections. Applying RNN-RSM to 19 years of articles on NLP\nresearch, we demonstrate that compared to state-of-the art topic models, RNNRSM\nshows better generalization, topic interpretation, evolution and trends. We\nalso introduce a metric (named as SPAN) to quantify the capability of dynamic\ntopic model to capture word evolution in topics over time.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 15:33:59 GMT"}, {"version": "v2", "created": "Tue, 1 May 2018 09:17:46 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Gupta", "Pankaj", ""], ["Rajaram", "Subburam", ""], ["Sch\u00fctze", "Hinrich", ""], ["Andrassy", "Bernt", ""]]}, {"id": "1711.05627", "submitter": "Senjian An Dr.", "authors": "Senjian An, Farid Boussaid, Mohammed Bennamoun, Ferdous Sohel", "title": "Exploiting Layerwise Convexity of Rectifier Networks with Sign\n  Constrained Weights", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By introducing sign constraints on the weights, this paper proposes sign\nconstrained rectifier networks (SCRNs), whose training can be solved\nefficiently by the well known majorization-minimization (MM) algorithms. We\nprove that the proposed two-hidden-layer SCRNs, which exhibit negative weights\nin the second hidden layer and negative weights in the output layer, are\ncapable of separating any two (or more) disjoint pattern sets. Furthermore, the\nproposed two-hidden-layer SCRNs can decompose the patterns of each class into\nseveral clusters so that each cluster is convexly separable from all the\npatterns from the other classes. This provides a means to learn the pattern\nstructures and analyse the discriminant factors between different classes of\npatterns.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 10:20:44 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["An", "Senjian", ""], ["Boussaid", "Farid", ""], ["Bennamoun", "Mohammed", ""], ["Sohel", "Ferdous", ""]]}, {"id": "1711.05697", "submitter": "Aravind Sankar", "authors": "Aravind Sankar, Xinyang Zhang, Kevin Chen-Chuan Chang", "title": "Motif-based Convolutional Neural Network on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a generalization of Convolutional Neural Networks\n(CNNs) to graphs with irregular linkage structures, especially heterogeneous\ngraphs with typed nodes and schemas. We propose a novel spatial convolution\noperation to model the key properties of local connectivity and translation\ninvariance, using high-order connection patterns or motifs. We develop a novel\ndeep architecture Motif-CNN that employs an attention model to combine the\nfeatures extracted from multiple patterns, thus effectively capturing\nhigh-order structural and feature information. Our experiments on\nsemi-supervised node classification on real-world social networks and multiple\nrepresentative heterogeneous graph datasets indicate significant gains of 6-21%\nover existing graph CNNs and other state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 17:48:35 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 01:34:49 GMT"}, {"version": "v3", "created": "Mon, 5 Feb 2018 16:55:18 GMT"}, {"version": "v4", "created": "Sun, 21 Jul 2019 22:00:26 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Sankar", "Aravind", ""], ["Zhang", "Xinyang", ""], ["Chang", "Kevin Chen-Chuan", ""]]}, {"id": "1711.05712", "submitter": "Haoyi Xiong", "authors": "Jiang Bian, Haoyi Xiong, Yanjie Fu, Sajal K. Das", "title": "CSWA: Aggregation-Free Spatial-Temporal Community Sensing", "comments": "This paper has been accepted by AAAI 2018. First two authors are\n  equally contributed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel community sensing paradigm -- {C}ommunity\n{S}ensing {W}ithout {A}ggregation}. CSWA is designed to obtain the environment\ninformation (e.g., air pollution or temperature) in each subarea of the target\narea, without aggregating sensor and location data collected by community\nmembers. CSWA operates on top of a secured peer-to-peer network over the\ncommunity members and proposes a novel \\emph{Decentralized Spatial-Temporal\nCompressive Sensing} framework based on \\emph{Parallelized Stochastic Gradient\nDescent}. Through learning the \\emph{low-rank structure} via distributed\noptimization, CSWA approximates the value of the sensor data in each subarea\n(both covered and uncovered) for each sensing cycle using the sensor data\nlocally stored in each member's mobile device. Simulation experiments based on\nreal-world datasets demonstrate that CSWA exhibits low approximation error\n(i.e., less than $0.2 ^\\circ$C in city-wide temperature sensing task and $10$\nunits of PM2.5 index in urban air pollution sensing) and performs comparably to\n(sometimes better than) state-of-the-art algorithms based on the data\naggregation and centralized computation.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 18:18:35 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Bian", "Jiang", ""], ["Xiong", "Haoyi", ""], ["Fu", "Yanjie", ""], ["Das", "Sajal K.", ""]]}, {"id": "1711.05715", "submitter": "Zachary Lipton", "authors": "Zachary Lipton, Xiujun Li, Jianfeng Gao, Lihong Li, Faisal Ahmed, Li\n  Deng", "title": "BBQ-Networks: Efficient Exploration in Deep Reinforcement Learning for\n  Task-Oriented Dialogue Systems", "comments": "Duplicate of article already in the arXiv: arXiv:1608.05081", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm that significantly improves the efficiency of\nexploration for deep Q-learning agents in dialogue systems. Our agents explore\nvia Thompson sampling, drawing Monte Carlo samples from a Bayes-by-Backprop\nneural network. Our algorithm learns much faster than common exploration\nstrategies such as \\epsilon-greedy, Boltzmann, bootstrapping, and\nintrinsic-reward-based ones. Additionally, we show that spiking the replay\nbuffer with experiences from just a few successful episodes can make Q-learning\nfeasible when it might otherwise fail.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 18:23:48 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 04:22:45 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Lipton", "Zachary", ""], ["Li", "Xiujun", ""], ["Gao", "Jianfeng", ""], ["Li", "Lihong", ""], ["Ahmed", "Faisal", ""], ["Deng", "Li", ""]]}, {"id": "1711.05717", "submitter": "Samira Shabanian", "authors": "Samira Shabanian, Devansh Arpit, Adam Trischler, Yoshua Bengio", "title": "Variational Bi-LSTMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks like long short-term memory (LSTM) are important\narchitectures for sequential prediction tasks. LSTMs (and RNNs in general)\nmodel sequences along the forward time direction. Bidirectional LSTMs\n(Bi-LSTMs) on the other hand model sequences along both forward and backward\ndirections and are generally known to perform better at such tasks because they\ncapture a richer representation of the data. In the training of Bi-LSTMs, the\nforward and backward paths are learned independently. We propose a variant of\nthe Bi-LSTM architecture, which we call Variational Bi-LSTM, that creates a\nchannel between the two paths (during training, but which may be omitted during\ninference); thus optimizing the two paths jointly. We arrive at this joint\nobjective for our model by minimizing a variational lower bound of the joint\nlikelihood of the data sequence. Our model acts as a regularizer and encourages\nthe two networks to inform each other in making their respective predictions\nusing distinct information. We perform ablation studies to better understand\nthe different components of our model and evaluate the method on various\nbenchmarks, showing state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 18:30:05 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Shabanian", "Samira", ""], ["Arpit", "Devansh", ""], ["Trischler", "Adam", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1711.05726", "submitter": "Aditya Modi", "authors": "Aditya Modi, Nan Jiang, Satinder Singh, Ambuj Tewari", "title": "Markov Decision Processes with Continuous Side Information", "comments": null, "journal-ref": "PMLR Volume 83: Algorithmic Learning Theory, 7-9 April 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a reinforcement learning (RL) setting in which the agent\ninteracts with a sequence of episodic MDPs. At the start of each episode the\nagent has access to some side-information or context that determines the\ndynamics of the MDP for that episode. Our setting is motivated by applications\nin healthcare where baseline measurements of a patient at the start of a\ntreatment episode form the context that may provide information about how the\npatient might respond to treatment decisions. We propose algorithms for\nlearning in such Contextual Markov Decision Processes (CMDPs) under an\nassumption that the unobserved MDP parameters vary smoothly with the observed\ncontext. We also give lower and upper PAC bounds under the smoothness\nassumption. Because our lower bound has an exponential dependence on the\ndimension, we consider a tractable linear setting where the context is used to\ncreate linear combinations of a finite set of MDPs. For the linear setting, we\ngive a PAC learning algorithm based on KWIK learning techniques.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 18:49:16 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Modi", "Aditya", ""], ["Jiang", "Nan", ""], ["Singh", "Satinder", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1711.05734", "submitter": "Francesco Conti", "authors": "Francesco Conti, Lukas Cavigelli, Gianna Paulin, Igor Susmelj, Luca\n  Benini", "title": "Chipmunk: A Systolically Scalable 0.9 mm${}^2$, 3.08 Gop/s/mW @ 1.2 mW\n  Accelerator for Near-Sensor Recurrent Neural Network Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are state-of-the-art in voice\nawareness/understanding and speech recognition. On-device computation of RNNs\non low-power mobile and wearable devices would be key to applications such as\nzero-latency voice-based human-machine interfaces. Here we present Chipmunk, a\nsmall (<1 mm${}^2$) hardware accelerator for Long-Short Term Memory RNNs in UMC\n65 nm technology capable to operate at a measured peak efficiency up to 3.08\nGop/s/mW at 1.24 mW peak power. To implement big RNN models without incurring\nin huge memory transfer overhead, multiple Chipmunk engines can cooperate to\nform a single systolic array. In this way, the Chipmunk architecture in a 75\ntiles configuration can achieve real-time phoneme extraction on a demanding RNN\ntopology proposed by Graves et al., consuming less than 13 mW of average power.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 10:15:44 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 21:43:55 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Conti", "Francesco", ""], ["Cavigelli", "Lukas", ""], ["Paulin", "Gianna", ""], ["Susmelj", "Igor", ""], ["Benini", "Luca", ""]]}, {"id": "1711.05747", "submitter": "Chris Donahue", "authors": "Chris Donahue, Bo Li, Rohit Prabhavalkar", "title": "Exploring Speech Enhancement with Generative Adversarial Networks for\n  Robust Speech Recognition", "comments": "Published as a conference paper at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.NE eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the effectiveness of generative adversarial networks (GANs)\nfor speech enhancement, in the context of improving noise robustness of\nautomatic speech recognition (ASR) systems. Prior work demonstrates that GANs\ncan effectively suppress additive noise in raw waveform speech signals,\nimproving perceptual quality metrics; however this technique was not justified\nin the context of ASR. In this work, we conduct a detailed study to measure the\neffectiveness of GANs in enhancing speech contaminated by both additive and\nreverberant noise. Motivated by recent advances in image processing, we propose\noperating GANs on log-Mel filterbank spectra instead of waveforms, which\nrequires less computation and is more robust to reverberant noise. While GAN\nenhancement improves the performance of a clean-trained ASR system on noisy\nspeech, it falls short of the performance achieved by conventional multi-style\ntraining (MTR). By appending the GAN-enhanced features to the noisy inputs and\nretraining, we achieve a 7% WER improvement relative to the MTR system.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 19:00:07 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 00:48:59 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Donahue", "Chris", ""], ["Li", "Bo", ""], ["Prabhavalkar", "Rohit", ""]]}, {"id": "1711.05762", "submitter": "Yi Zhou", "authors": "Guanghui Lan and Yi Zhou", "title": "Random gradient extrapolation for distributed and stochastic\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a class of finite-sum convex optimization problems\ndefined over a distributed multiagent network with $m$ agents connected to a\ncentral server. In particular, the objective function consists of the average\nof $m$ ($\\ge 1$) smooth components associated with each network agent together\nwith a strongly convex term. Our major contribution is to develop a new\nrandomized incremental gradient algorithm, namely random gradient extrapolation\nmethod (RGEM), which does not require any exact gradient evaluation even for\nthe initial point, but can achieve the optimal ${\\cal O}(\\log(1/\\epsilon))$\ncomplexity bound in terms of the total number of gradient evaluations of\ncomponent functions to solve the finite-sum problems. Furthermore, we\ndemonstrate that for stochastic finite-sum optimization problems, RGEM\nmaintains the optimal ${\\cal O}(1/\\epsilon)$ complexity (up to a certain\nlogarithmic factor) in terms of the number of stochastic gradient computations,\nbut attains an ${\\cal O}(\\log(1/\\epsilon))$ complexity in terms of\ncommunication rounds (each round involves only one agent). It is worth noting\nthat the former bound is independent of the number of agents $m$, while the\nlatter one only linearly depends on $m$ or even $\\sqrt m$ for ill-conditioned\nproblems. To the best of our knowledge, this is the first time that these\ncomplexity bounds have been obtained for distributed and stochastic\noptimization problems. Moreover, our algorithms were developed based on a novel\ndual perspective of Nesterov's accelerated gradient method.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 19:18:59 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Lan", "Guanghui", ""], ["Zhou", "Yi", ""]]}, {"id": "1711.05772", "submitter": "Jesse Engel", "authors": "Jesse Engel, Matthew Hoffman, Adam Roberts", "title": "Latent Constraints: Learning to Generate Conditionally from\n  Unconditional Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative neural networks have proven effective at both conditional and\nunconditional modeling of complex data distributions. Conditional generation\nenables interactive control, but creating new controls often requires expensive\nretraining. In this paper, we develop a method to condition generation without\nretraining the model. By post-hoc learning latent constraints, value functions\nthat identify regions in latent space that generate outputs with desired\nattributes, we can conditionally sample from these regions with gradient-based\noptimization or amortized actor functions. Combining attribute constraints with\na universal \"realism\" constraint, which enforces similarity to the data\ndistribution, we generate realistic conditional images from an unconditional\nvariational autoencoder. Further, using gradient-based optimization, we\ndemonstrate identity-preserving transformations that make the minimal\nadjustment in latent space to modify the attributes of an image. Finally, with\ndiscrete sequences of musical notes, we demonstrate zero-shot conditional\ngeneration, learning latent constraints in the absence of labeled data or a\ndifferentiable reward function. Code with dedicated cloud instance has been\nmade publicly available (https://goo.gl/STGMGx).\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 19:45:10 GMT"}, {"version": "v2", "created": "Thu, 21 Dec 2017 23:50:53 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Engel", "Jesse", ""], ["Hoffman", "Matthew", ""], ["Roberts", "Adam", ""]]}, {"id": "1711.05792", "submitter": "Yukun Chen", "authors": "Yukun Chen, Jianbo Ye, and Jia Li", "title": "Aggregated Wasserstein Metric and State Registration for Hidden Markov\n  Models", "comments": "Our manuscript is based on our conference paper [arXiv:1608.01747]\n  published in 14th European Conference on Computer Vision (ECCV 2016,\n  spotlight). It has been significantly extended and is now in journal\n  submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework, named Aggregated Wasserstein, for computing a\ndissimilarity measure or distance between two Hidden Markov Models with state\nconditional distributions being Gaussian. For such HMMs, the marginal\ndistribution at any time position follows a Gaussian mixture distribution, a\nfact exploited to softly match, aka register, the states in two HMMs. We refer\nto such HMMs as Gaussian mixture model-HMM (GMM-HMM). The registration of\nstates is inspired by the intrinsic relationship of optimal transport and the\nWasserstein metric between distributions. Specifically, the components of the\nmarginal GMMs are matched by solving an optimal transport problem where the\ncost between components is the Wasserstein metric for Gaussian distributions.\nThe solution of the optimization problem is a fast approximation to the\nWasserstein metric between two GMMs. The new Aggregated Wasserstein distance is\na semi-metric and can be computed without generating Monte Carlo samples. It is\ninvariant to relabeling or permutation of states. The distance is defined\nmeaningfully even for two HMMs that are estimated from data of different\ndimensionality, a situation that can arise due to missing variables. This\ndistance quantifies the dissimilarity of GMM-HMMs by measuring both the\ndifference between the two marginal GMMs and that between the two transition\nmatrices. Our new distance is tested on tasks of retrieval, classification, and\nt-SNE visualization of time series. Experiments on both synthetic and real data\nhave demonstrated its advantages in terms of accuracy as well as efficiency in\ncomparison with existing distances based on the Kullback-Leibler divergence.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 22:43:22 GMT"}, {"version": "v2", "created": "Sun, 19 Nov 2017 20:19:50 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Chen", "Yukun", ""], ["Ye", "Jianbo", ""], ["Li", "Jia", ""]]}, {"id": "1711.05799", "submitter": "Ankush Khandelwal", "authors": "Ankush Khandelwal, Anuj Karpatne, Vipin Kumar", "title": "ORBIT: Ordering Based Information Transfer Across Space and Time for\n  Global Surface Water Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many earth science applications require data at both high spatial and\ntemporal resolution for effective monitoring of various ecosystem resources.\nDue to practical limitations in sensor design, there is often a trade-off in\ndifferent resolutions of spatio-temporal datasets and hence a single sensor\nalone cannot provide the required information. Various data fusion methods have\nbeen proposed in the literature that mainly rely on individual timesteps when\nboth datasets are available to learn a mapping between features values at\ndifferent resolutions using local relationships between pixels. Earth\nobservation data is often plagued with spatially and temporally correlated\nnoise, outliers and missing data due to atmospheric disturbances which pose a\nchallenge in learning the mapping from a local neighborhood at individual\ntimesteps. In this paper, we aim to exploit time-independent global\nrelationships between pixels for robust transfer of information across\ndifferent scales. Specifically, we propose a new framework, ORBIT (Ordering\nBased Information Transfer) that uses relative ordering constraint among pixels\nto transfer information across both time and scales. The effectiveness of the\nframework is demonstrated for global surface water monitoring using both\nsynthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 20:50:08 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Khandelwal", "Ankush", ""], ["Karpatne", "Anuj", ""], ["Kumar", "Vipin", ""]]}, {"id": "1711.05809", "submitter": "Huaiyang Zhong", "authors": "Huaiyang Zhong, Xiaocheng Li, David Lobell, Stefano Ermon and Margaret\n  L. Brandeau", "title": "Hierarchical Modeling of Seed Variety Yields and Decision Making for\n  Future Planting Plans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eradicating hunger and malnutrition is a key development goal of the 21st\ncentury. We address the problem of optimally identifying seed varieties to\nreliably increase crop yield within a risk-sensitive decision-making framework.\nSpecifically, we introduce a novel hierarchical machine learning mechanism for\npredicting crop yield (the yield of different seed varieties of the same crop).\nWe integrate this prediction mechanism with a weather forecasting model, and\npropose three different approaches for decision making under uncertainty to\nselect seed varieties for planting so as to balance yield maximization and\nrisk.We apply our model to the problem of soybean variety selection given in\nthe 2016 Syngenta Crop Challenge. Our prediction model achieves a median\nabsolute error of 3.74 bushels per acre and thus provides good estimates for\ninput into the decision models.Our decision models identify the selection of\nsoybean varieties that appropriately balance yield and risk as a function of\nthe farmer's risk aversion level. More generally, our models support farmers in\ndecision making about which seed varieties to plant.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 21:12:30 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Zhong", "Huaiyang", ""], ["Li", "Xiaocheng", ""], ["Lobell", "David", ""], ["Ermon", "Stefano", ""], ["Brandeau", "Margaret L.", ""]]}, {"id": "1711.05817", "submitter": "Douglas Tweed", "authors": "Bita Behrouzi, Xuefei Liu, Douglas Tweed", "title": "Costate-focused models for reinforcement learning", "comments": "7 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent algorithms for reinforcement learning are model-free and founded\non the Bellman equation. Here we present a method founded on the costate\nequation and models of the state dynamics. We use the costate -- the gradient\nof cost with respect to state -- to improve the policy and also to \"focus\" the\nmodel, training it to detect and mimic those features of the environment that\nare most relevant to its task. We show that this method can handle difficult\ntime-optimal control problems, driving deterministic or stochastic mechanical\nsystems quickly to a target. On these tasks it works well compared to deep\ndeterministic policy gradient, a recent Bellman method. And because it creates\na model, the costate method can also learn from mental practice.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 21:42:55 GMT"}, {"version": "v2", "created": "Sat, 18 Nov 2017 20:43:39 GMT"}, {"version": "v3", "created": "Fri, 23 Feb 2018 23:23:23 GMT"}, {"version": "v4", "created": "Fri, 22 Jun 2018 00:31:39 GMT"}, {"version": "v5", "created": "Wed, 3 Oct 2018 02:12:06 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Behrouzi", "Bita", ""], ["Liu", "Xuefei", ""], ["Tweed", "Douglas", ""]]}, {"id": "1711.05820", "submitter": "Wenlin Wang", "authors": "Wenlin Wang, Yunchen Pu, Vinay Kumar Verma, Kai Fan, Yizhe Zhang,\n  Changyou Chen, Piyush Rai, Lawrence Carin", "title": "Zero-Shot Learning via Class-Conditioned Deep Generative Models", "comments": "To appear in AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep generative model for learning to predict classes not seen\nat training time. Unlike most existing methods for this problem, that represent\neach class as a point (via a semantic embedding), we represent each seen/unseen\nclass using a class-specific latent-space distribution, conditioned on class\nattributes. We use these latent-space distributions as a prior for a supervised\nvariational autoencoder (VAE), which also facilitates learning highly\ndiscriminative feature representations for the inputs. The entire framework is\nlearned end-to-end using only the seen-class training data. The model infers\ncorresponding attributes of a test image by maximizing the VAE lower bound; the\ninferred attributes may be linked to labels not seen when training. We further\nextend our model to a (1) semi-supervised/transductive setting by leveraging\nunlabeled unseen-class data via an unsupervised learning module, and (2)\nfew-shot learning where we also have a small number of labeled inputs from the\nunseen classes. We compare our model with several state-of-the-art methods\nthrough a comprehensive set of experiments on a variety of benchmark data sets.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 21:53:11 GMT"}, {"version": "v2", "created": "Sun, 19 Nov 2017 23:32:05 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Wang", "Wenlin", ""], ["Pu", "Yunchen", ""], ["Verma", "Vinay Kumar", ""], ["Fan", "Kai", ""], ["Zhang", "Yizhe", ""], ["Chen", "Changyou", ""], ["Rai", "Piyush", ""], ["Carin", "Lawrence", ""]]}, {"id": "1711.05822", "submitter": "Jiangen He", "authors": "Jiangen He and Chaomei Chen", "title": "Understanding the Changing Roles of Scientific Publications via Citation\n  Embeddings", "comments": "CLBib-2017: Second Workshop on Mining Scientific Papers:\n  Computational Linguistics and Bibliometrics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers may describe different aspects of past scientific publications in\ntheir publications and the descriptions may keep changing in the evolution of\nscience. The diverse and changing descriptions (i.e., citation context) on a\npublication characterize the impact and contributions of the past publication.\nIn this article, we aim to provide an approach to understanding the changing\nand complex roles of a publication characterized by its citation context. We\ndescribed a method to represent the publications' dynamic roles in science\ncommunity in different periods as a sequence of vectors by training temporal\nembedding models. The temporal representations can be used to quantify how much\nthe roles of publications changed and interpret how they changed. Our study in\nthe biomedical domain shows that our metric on the changes of publications'\nroles is stable over time at the population level but significantly distinguish\nindividuals. We also show the interpretability of our methods by a concrete\nexample.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 22:00:43 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["He", "Jiangen", ""], ["Chen", "Chaomei", ""]]}, {"id": "1711.05826", "submitter": "Simona Colabrese", "authors": "K. Gustavsson, L. Biferale, A. Celani, S. Colabrese", "title": "Finding Efficient Swimming Strategies in a Three Dimensional Chaotic\n  Flow by Reinforcement Learning", "comments": "Published on Eur. Phys. J. E (December 14, 2017)", "journal-ref": "Eur. Phys. J. E 40, 110 (2017)", "doi": "10.1140/epje/i2017-11602-9", "report-no": null, "categories": "physics.flu-dyn cond-mat.stat-mech cs.LG nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply a reinforcement learning algorithm to show how smart particles can\nlearn approximately optimal strategies to navigate in complex flows. In this\npaper we consider microswimmers in a paradigmatic three-dimensional case given\nby a stationary superposition of two Arnold-Beltrami-Childress flows with\nchaotic advection along streamlines. In such a flow, we study the evolution of\npoint-like particles which can decide in which direction to swim, while keeping\nthe velocity amplitude constant. We show that it is sufficient to endow the\nswimmers with a very restricted set of actions (six fixed swimming directions\nin our case) to have enough freedom to find efficient strategies to move upward\nand escape local fluid traps. The key ingredient is the\nlearning-from-experience structure of the algorithm, which assigns positive or\nnegative rewards depending on whether the taken action is, or is not,\nprofitable for the predetermined goal in the long term horizon. This is another\nexample supporting the efficiency of the reinforcement learning approach to\nlearn how to accomplish difficult tasks in complex fluid environments.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 22:20:46 GMT"}, {"version": "v2", "created": "Sun, 31 Dec 2017 17:05:44 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Gustavsson", "K.", ""], ["Biferale", "L.", ""], ["Celani", "A.", ""], ["Colabrese", "S.", ""]]}, {"id": "1711.05828", "submitter": "Rhicheek Patra", "authors": "Rhicheek Patra, Egor Samosvat, Michael Roizner, Andrei Mishchenko", "title": "BoostJet: Towards Combining Statistical Aggregates with Neural\n  Embeddings for Recommendations", "comments": "9 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommenders have become widely popular in recent years because of their\nbroader applicability in many e-commerce applications. These applications rely\non recommenders for generating advertisements for various offers or providing\ncontent recommendations. However, the quality of the generated recommendations\ndepends on user features (like demography, temporality), offer features (like\npopularity, price), and user-offer features (like implicit or explicit\nfeedback). Current state-of-the-art recommenders do not explore such diverse\nfeatures concurrently while generating the recommendations.\n  In this paper, we first introduce the notion of Trackers which enables us to\ncapture the above-mentioned features and thus incorporate users' online\nbehaviour through statistical aggregates of different features (demography,\ntemporality, popularity, price). We also show how to capture offer-to-offer\nrelations, based on their consumption sequence, leveraging neural embeddings\nfor offers in our Offer2Vec algorithm. We then introduce BoostJet, a novel\nrecommender which integrates the Trackers along with the neural embeddings\nusing MatrixNet, an efficient distributed implementation of gradient boosted\ndecision tree, to improve the recommendation quality significantly. We provide\nan in-depth evaluation of BoostJet on Yandex's dataset, collecting online\nbehaviour from tens of millions of online users, to demonstrate the\npracticality of BoostJet in terms of recommendation quality as well as\nscalability.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 22:25:49 GMT"}, {"version": "v2", "created": "Thu, 7 Dec 2017 21:16:53 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Patra", "Rhicheek", ""], ["Samosvat", "Egor", ""], ["Roizner", "Michael", ""], ["Mishchenko", "Andrei", ""]]}, {"id": "1711.05848", "submitter": "Olga Dergachyova", "authors": "Olga Dergachyova and Xavier Morandi and Pierre Jannin", "title": "Knowledge transfer for surgical activity prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lack of training data hinders automatic recognition and prediction of\nsurgical activities necessary for situation-aware operating rooms. We propose\nusing knowledge transfer to compensate for data deficit and improve prediction.\nWe used two approaches to extract and transfer surgical process knowledge.\nFirst, we encoded semantic information about surgical terms using word\nembedding which boosted learning process. Secondly, we passed knowledge between\ndifferent clinical datasets of neurosurgical procedures using transfer\nlearning. Transfer learning was shown to be more effective than a simple\ncombination of data, especially for less similar procedures. The combination of\ntwo methods provided 22% improvement of activity prediction. We also made\nseveral pertinent observations about surgical practices.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 23:42:47 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Dergachyova", "Olga", ""], ["Morandi", "Xavier", ""], ["Jannin", "Pierre", ""]]}, {"id": "1711.05852", "submitter": "Asit Mishra", "authors": "Asit Mishra, Debbie Marr", "title": "Apprentice: Using Knowledge Distillation Techniques To Improve\n  Low-Precision Network Accuracy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning networks have achieved state-of-the-art accuracies on computer\nvision workloads like image classification and object detection. The performant\nsystems, however, typically involve big models with numerous parameters. Once\ntrained, a challenging aspect for such top performing models is deployment on\nresource constrained inference systems - the models (often deep networks or\nwide networks or both) are compute and memory intensive. Low-precision numerics\nand model compression using knowledge distillation are popular techniques to\nlower both the compute requirements and memory footprint of these deployed\nmodels. In this paper, we study the combination of these two techniques and\nshow that the performance of low-precision networks can be significantly\nimproved by using knowledge distillation techniques. Our approach, Apprentice,\nachieves state-of-the-art accuracies using ternary precision and 4-bit\nprecision for variants of ResNet architecture on ImageNet dataset. We present\nthree schemes using which one can apply knowledge distillation techniques to\nvarious stages of the train-and-deploy pipeline.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 23:45:59 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Mishra", "Asit", ""], ["Marr", "Debbie", ""]]}, {"id": "1711.05859", "submitter": "Sungmin Rhee", "authors": "Sungmin Rhee, Seokjun Seo, Sun Kim", "title": "Hybrid Approach of Relation Network and Localized Graph Convolutional\n  Filtering for Breast Cancer Subtype Classification", "comments": "8 pages, To be published in proceeding of IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network biology has been successfully used to help reveal complex mechanisms\nof disease, especially cancer. On the other hand, network biology requires\nin-depth knowledge to construct disease-specific networks, but our current\nknowledge is very limited even with the recent advances in human cancer\nbiology. Deep learning has shown a great potential to address the difficult\nsituation like this. However, deep learning technologies conventionally use\ngrid-like structured data, thus application of deep learning technologies to\nthe classification of human disease subtypes is yet to be explored. Recently,\ngraph based deep learning techniques have emerged, which becomes an opportunity\nto leverage analyses in network biology. In this paper, we proposed a hybrid\nmodel, which integrates two key components 1) graph convolution neural network\n(graph CNN) and 2) relation network (RN). We utilize graph CNN as a component\nto learn expression patterns of cooperative gene community, and RN as a\ncomponent to learn associations between learned patterns. The proposed model is\napplied to the PAM50 breast cancer subtype classification task, the standard\nbreast cancer subtype classification of clinical utility. In experiments of\nboth subtype classification and patient survival analysis, our proposed method\nachieved significantly better performances than existing methods. We believe\nthat this work is an important starting point to realize the upcoming\npersonalized medicine.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 15:15:31 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 09:10:25 GMT"}, {"version": "v3", "created": "Fri, 15 Jun 2018 05:29:23 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Rhee", "Sungmin", ""], ["Seo", "Seokjun", ""], ["Kim", "Sun", ""]]}, {"id": "1711.05865", "submitter": "Sourya Dey", "authors": "Sourya Dey", "title": "Pricing Football Players using Neural Networks", "comments": "10 pages technical report (v2: Revised wording and formatting from\n  v1)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We designed a multilayer perceptron neural network to predict the price of a\nfootball (soccer) player using data on more than 15,000 players from the\nfootball simulation video game FIFA 2017. The network was optimized by\nexperimenting with different activation functions, number of neurons and\nlayers, learning rate and its decay, Nesterov momentum based stochastic\ngradient descent, L2 regularization, and early stopping. Simultaneous\nexploration of various aspects of neural network training is performed and\ntheir trade-offs are investigated. Our final model achieves a top-5 accuracy of\n87.2% among 119 pricing categories, and places any footballer within 6.32% of\nhis actual price on average.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 00:14:49 GMT"}, {"version": "v2", "created": "Sat, 18 Nov 2017 00:46:39 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Dey", "Sourya", ""]]}, {"id": "1711.05869", "submitter": "Franz J. Kir\\'aly", "authors": "Samuel Burkart and Franz J Kir\\'aly", "title": "Predictive Independence Testing, Predictive Conditional Independence\n  Testing, and Predictive Graphical Modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing (conditional) independence of multivariate random variables is a task\ncentral to statistical inference and modelling in general - though\nunfortunately one for which to date there does not exist a practicable\nworkflow. State-of-art workflows suffer from the need for heuristic or\nsubjective manual choices, high computational complexity, or strong parametric\nassumptions.\n  We address these problems by establishing a theoretical link between\nmultivariate/conditional independence testing, and model comparison in the\nmultivariate predictive modelling aka supervised learning task. This link\nallows advances in the extensively studied supervised learning workflow to be\ndirectly transferred to independence testing workflows - including automated\ntuning of machine learning type which addresses the need for a heuristic\nchoice, the ability to quantitatively trade-off computational demand with\naccuracy, and the modern black-box philosophy for checking and interfacing.\n  As a practical implementation of this link between the two workflows, we\npresent a python package 'pcit', which implements our novel multivariate and\nconditional independence tests, interfacing the supervised learning API of the\nscikit-learn package. Theory and package also allow for straightforward\nindependence test based learning of graphical model structure.\n  We empirically show that our proposed predictive independence test outperform\nor are on par to current practice, and the derived graphical model structure\nlearning algorithms asymptotically recover the 'true' graph. This paper, and\nthe 'pcit' package accompanying it, thus provide powerful, scalable,\ngeneralizable, and easy-to-use methods for multivariate and conditional\nindependence testing, as well as for graphical model structure learning.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 00:37:34 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2018 20:32:52 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Burkart", "Samuel", ""], ["Kir\u00e1ly", "Franz J", ""]]}, {"id": "1711.05893", "submitter": "Shay Moran", "authors": "Daniel M. Kane and Roi Livni and Shay Moran and Amir Yehudayoff", "title": "On Communication Complexity of Classification Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies distributed learning in the spirit of Yao's model of\ncommunication complexity: consider a two-party setting, where each of the\nplayers gets a list of labelled examples and they communicate in order to\njointly perform some learning task. To naturally fit into the framework of\nlearning theory, the players can send each other examples (as well as bits)\nwhere each example/bit costs one unit of communication. This enables a uniform\ntreatment of infinite classes such as half-spaces in $\\mathbb{R}^d$, which are\nubiquitous in machine learning.\n  We study several fundamental questions in this model. For example, we provide\ncombinatorial characterizations of the classes that can be learned with\nefficient communication in the proper-case as well as in the improper-case.\nThese findings imply unconditional separations between various learning\ncontexts, e.g.\\ realizable versus agnostic learning, proper versus improper\nlearning, etc.\n  The derivation of these results hinges on a type of decision problems we term\n\"{\\it realizability problems}\" where the goal is deciding whether a distributed\ninput sample is consistent with an hypothesis from a pre-specified class.\n  From a technical perspective, the protocols we use are based on ideas from\nmachine learning theory and the impossibility results are based on ideas from\ncommunication complexity theory.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 02:13:55 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 01:35:08 GMT"}, {"version": "v3", "created": "Mon, 23 Apr 2018 15:02:18 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Kane", "Daniel M.", ""], ["Livni", "Roi", ""], ["Moran", "Shay", ""], ["Yehudayoff", "Amir", ""]]}, {"id": "1711.05914", "submitter": "Uiwon Hwang", "authors": "Yongjun Hong, Uiwon Hwang, Jaeyoon Yoo and Sungroh Yoon", "title": "How Generative Adversarial Networks and Their Variants Work: An Overview", "comments": "41 pages, 16 figures, Published in ACM Computing Surveys (CSUR)", "journal-ref": "ACM Computing Surveys (CSUR) Volume 52 Issue 1, February 2019\n  Article No. 10", "doi": "10.1145/3301282", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GAN) have received wide attention in the\nmachine learning field for their potential to learn high-dimensional, complex\nreal data distribution. Specifically, they do not rely on any assumptions about\nthe distribution and can generate real-like samples from latent space in a\nsimple manner. This powerful property leads GAN to be applied to various\napplications such as image synthesis, image attribute editing, image\ntranslation, domain adaptation and other academic fields. In this paper, we aim\nto discuss the details of GAN for those readers who are familiar with, but do\nnot comprehend GAN deeply or who wish to view GAN from various perspectives. In\naddition, we explain how GAN operates and the fundamental meaning of various\nobjective functions that have been suggested recently. We then focus on how the\nGAN can be combined with an autoencoder framework. Finally, we enumerate the\nGAN variants that are applied to various tasks and other fields for those who\nare interested in exploiting GAN for their research.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 04:07:42 GMT"}, {"version": "v10", "created": "Thu, 28 Feb 2019 15:05:58 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 12:27:42 GMT"}, {"version": "v3", "created": "Thu, 23 Nov 2017 11:11:33 GMT"}, {"version": "v4", "created": "Fri, 1 Dec 2017 08:56:12 GMT"}, {"version": "v5", "created": "Tue, 2 Jan 2018 16:03:39 GMT"}, {"version": "v6", "created": "Tue, 23 Jan 2018 11:52:29 GMT"}, {"version": "v7", "created": "Fri, 27 Jul 2018 09:56:00 GMT"}, {"version": "v8", "created": "Sat, 10 Nov 2018 06:38:25 GMT"}, {"version": "v9", "created": "Tue, 13 Nov 2018 03:35:29 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Hong", "Yongjun", ""], ["Hwang", "Uiwon", ""], ["Yoo", "Jaeyoon", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1711.05918", "submitter": "Amir Rosenfeld", "authors": "Amir Rosenfeld, Mahdi Biparva, John K. Tsotsos", "title": "Priming Neural Networks", "comments": "fixed error in author name", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual priming is known to affect the human visual system to allow detection\nof scene elements, even those that may have been near unnoticeable before, such\nas the presence of camouflaged animals. This process has been shown to be an\neffect of top-down signaling in the visual system triggered by the said cue. In\nthis paper, we propose a mechanism to mimic the process of priming in the\ncontext of object detection and segmentation. We view priming as having a\nmodulatory, cue dependent effect on layers of features within a network. Our\nresults show how such a process can be complementary to, and at times more\neffective than simple post-processing applied to the output of the network,\nnotably so in cases where the object is hard to detect such as in severe noise.\nMoreover, we find the effects of priming are sometimes stronger when early\nvisual layers are affected. Overall, our experiments confirm that top-down\nsignals can go a long way in improving object detection and segmentation.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 04:21:14 GMT"}, {"version": "v2", "created": "Fri, 17 Nov 2017 01:50:00 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Rosenfeld", "Amir", ""], ["Biparva", "Mahdi", ""], ["Tsotsos", "John K.", ""]]}, {"id": "1711.05928", "submitter": "Datong-Paul Zhou", "authors": "Datong P. Zhou, Claire J. Tomlin", "title": "Budget-Constrained Multi-Armed Bandits with Multiple Plays", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the multi-armed bandit problem with multiple plays and a budget\nconstraint for both the stochastic and the adversarial setting. At each round,\nexactly $K$ out of $N$ possible arms have to be played (with $1\\leq K \\leq N$).\nIn addition to observing the individual rewards for each arm played, the player\nalso learns a vector of costs which has to be covered with an a-priori defined\nbudget $B$. The game ends when the sum of current costs associated with the\nplayed arms exceeds the remaining budget.\n  Firstly, we analyze this setting for the stochastic case, for which we assume\neach arm to have an underlying cost and reward distribution with support\n$[c_{\\min}, 1]$ and $[0, 1]$, respectively. We derive an Upper Confidence Bound\n(UCB) algorithm which achieves $O(NK^4 \\log B)$ regret.\n  Secondly, for the adversarial case in which the entire sequence of rewards\nand costs is fixed in advance, we derive an upper bound on the regret of order\n$O(\\sqrt{NB\\log(N/K)})$ utilizing an extension of the well-known\n$\\texttt{Exp3}$ algorithm. We also provide upper bounds that hold with high\nprobability and a lower bound of order $\\Omega((1 - K/N)^2 \\sqrt{NB/K})$.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 05:07:34 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Zhou", "Datong P.", ""], ["Tomlin", "Claire J.", ""]]}, {"id": "1711.05934", "submitter": "Yujia Liu", "authors": "Yujia Liu, Weiming Zhang, Shaohua Li, Nenghai Yu", "title": "Enhanced Attacks on Defensively Distilled Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have achieved tremendous success in many tasks of\nmachine learning, such as the image classification. Unfortunately, researchers\nhave shown that DNNs are easily attacked by adversarial examples, slightly\nperturbed images which can mislead DNNs to give incorrect classification\nresults. Such attack has seriously hampered the deployment of DNN systems in\nareas where security or safety requirements are strict, such as autonomous\ncars, face recognition, malware detection. Defensive distillation is a\nmechanism aimed at training a robust DNN which significantly reduces the\neffectiveness of adversarial examples generation. However, the state-of-the-art\nattack can be successful on distilled networks with 100% probability. But it is\na white-box attack which needs to know the inner information of DNN. Whereas,\nthe black-box scenario is more general. In this paper, we first propose the\nepsilon-neighborhood attack, which can fool the defensively distilled networks\nwith 100% success rate in the white-box setting, and it is fast to generate\nadversarial examples with good visual quality. On the basis of this attack, we\nfurther propose the region-based attack against defensively distilled DNNs in\nthe black-box setting. And we also perform the bypass attack to indirectly\nbreak the distillation defense as a complementary method. The experimental\nresults show that our black-box attacks have a considerable success rate on\ndefensively distilled networks.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 05:37:14 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Liu", "Yujia", ""], ["Zhang", "Weiming", ""], ["Li", "Shaohua", ""], ["Yu", "Nenghai", ""]]}, {"id": "1711.05959", "submitter": "Heechul Jung", "authors": "Heechul Jung, Jeongwoo Ju, Minju Jung, Junmo Kim", "title": "Less-forgetful Learning for Domain Expansion in Deep Neural Networks", "comments": "8 pages, accepted to AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expanding the domain that deep neural network has already learned without\naccessing old domain data is a challenging task because deep neural networks\nforget previously learned information when learning new data from a new domain.\nIn this paper, we propose a less-forgetful learning method for the domain\nexpansion scenario. While existing domain adaptation techniques solely focused\non adapting to new domains, the proposed technique focuses on working well with\nboth old and new domains without needing to know whether the input is from the\nold or new domain. First, we present two naive approaches which will be\nproblematic, then we provide a new method using two proposed properties for\nless-forgetful learning. Finally, we prove the effectiveness of our method\nthrough experiments on image classification tasks. All datasets used in the\npaper, will be released on our website for someone's follow-up study.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 07:04:51 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Jung", "Heechul", ""], ["Ju", "Jeongwoo", ""], ["Jung", "Minju", ""], ["Kim", "Junmo", ""]]}, {"id": "1711.06006", "submitter": "Paulo Rauber", "authors": "Paulo Rauber, Avinash Ummadisingu, Filipe Mutz, Juergen Schmidhuber", "title": "Hindsight policy gradients", "comments": "Accepted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A reinforcement learning agent that needs to pursue different goals across\nepisodes requires a goal-conditional policy. In addition to their potential to\ngeneralize desirable behavior to unseen goals, such policies may also enable\nhigher-level planning based on subgoals. In sparse-reward environments, the\ncapacity to exploit information about the degree to which an arbitrary goal has\nbeen achieved while another goal was intended appears crucial to enable sample\nefficient learning. However, reinforcement learning agents have only recently\nbeen endowed with such capacity for hindsight. In this paper, we demonstrate\nhow hindsight can be introduced to policy gradient methods, generalizing this\nidea to a broad class of successful algorithms. Our experiments on a diverse\nselection of sparse-reward environments show that hindsight leads to a\nremarkable increase in sample efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 10:05:31 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2018 14:11:06 GMT"}, {"version": "v3", "created": "Wed, 20 Feb 2019 10:46:44 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Rauber", "Paulo", ""], ["Ummadisingu", "Avinash", ""], ["Mutz", "Filipe", ""], ["Schmidhuber", "Juergen", ""]]}, {"id": "1711.06064", "submitter": "Kian Hsiang Low", "authors": "Ruofei Ouyang, Kian Hsiang Low", "title": "Gaussian Process Decentralized Data Fusion Meets Transfer Learning in\n  Large-Scale Distributed Cooperative Perception", "comments": "32nd AAAI Conference on Artificial Intelligence (AAAI 2018), Extended\n  version with proofs, 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents novel Gaussian process decentralized data fusion\nalgorithms exploiting the notion of agent-centric support sets for distributed\ncooperative perception of large-scale environmental phenomena. To overcome the\nlimitations of scale in existing works, our proposed algorithms allow every\nmobile sensing agent to choose a different support set and dynamically switch\nto another during execution for encapsulating its own data into a local summary\nthat, perhaps surprisingly, can still be assimilated with the other agents'\nlocal summaries (i.e., based on their current choices of support sets) into a\nglobally consistent summary to be used for predicting the phenomenon. To\nachieve this, we propose a novel transfer learning mechanism for a team of\nagents capable of sharing and transferring information encapsulated in a\nsummary based on a support set to that utilizing a different support set with\nsome loss that can be theoretically bounded and analyzed. To alleviate the\nissue of information loss accumulating over multiple instances of transfer\nlearning, we propose a new information sharing mechanism to be incorporated\ninto our algorithms in order to achieve memory-efficient lazy transfer\nlearning. Empirical evaluation on real-world datasets show that our algorithms\noutperform the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 12:41:33 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Ouyang", "Ruofei", ""], ["Low", "Kian Hsiang", ""]]}, {"id": "1711.06068", "submitter": "Joos Behncke", "authors": "Joos Behncke, Robin Tibor Schirrmeister, Wolfram Burgard and Tonio\n  Ball", "title": "The signature of robot action success in EEG signals of a human\n  observer: Decoding and visualization using deep convolutional neural networks", "comments": null, "journal-ref": null, "doi": "10.1109/IWW-BCI.2018.8311531", "report-no": null, "categories": "cs.HC cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of robotic assistive devices grows in our work and everyday\nlife. Cooperative scenarios involving both robots and humans require safe\nhuman-robot interaction. One important aspect here is the management of robot\nerrors, including fast and accurate online robot-error detection and\ncorrection. Analysis of brain signals from a human interacting with a robot may\nhelp identifying robot errors, but accuracies of such analyses have still\nsubstantial space for improvement. In this paper we evaluate whether a novel\nframework based on deep convolutional neural networks (deep ConvNets) could\nimprove the accuracy of decoding robot errors from the EEG of a human observer,\nboth during an object grasping and a pouring task. We show that deep ConvNets\nreached significantly higher accuracies than both regularized Linear\nDiscriminant Analysis (rLDA) and filter bank common spatial patterns (FB-CSP)\ncombined with rLDA, both widely used EEG classifiers. Deep ConvNets reached\nmean accuracies of 75% +/- 9 %, rLDA 65% +/- 10% and FB-CSP + rLDA 63% +/- 6%\nfor decoding of erroneous vs. correct trials. Visualization of the time-domain\nEEG features learned by the ConvNets to decode errors revealed spatiotemporal\npatterns that reflected differences between the two experimental paradigms.\nAcross subjects, ConvNet decoding accuracies were significantly correlated with\nthose obtained with rLDA, but not CSP, indicating that in the present context\nConvNets behaved more 'rLDA-like' (but consistently better), while in a\nprevious decoding study with another task but the same ConvNet architecture, it\nwas found to behave more 'CSP-like'. Our findings thus provide further support\nfor the assumption that deep ConvNets are a versatile addition to the existing\ntoolbox of EEG decoding techniques, and we discuss steps how ConvNet EEG\ndecoding performance could be further optimized.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 12:59:25 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Behncke", "Joos", ""], ["Schirrmeister", "Robin Tibor", ""], ["Burgard", "Wolfram", ""], ["Ball", "Tonio", ""]]}, {"id": "1711.06104", "submitter": "Marco Ancona", "authors": "Marco Ancona, Enea Ceolini, Cengiz \\\"Oztireli and Markus Gross", "title": "Towards better understanding of gradient-based attribution methods for\n  Deep Neural Networks", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the flow of information in Deep Neural Networks (DNNs) is a\nchallenging problem that has gain increasing attention over the last few years.\nWhile several methods have been proposed to explain network predictions, there\nhave been only a few attempts to compare them from a theoretical perspective.\nWhat is more, no exhaustive empirical comparison has been performed in the\npast. In this work, we analyze four gradient-based attribution methods and\nformally prove conditions of equivalence and approximation between them. By\nreformulating two of these methods, we construct a unified framework which\nenables a direct comparison, as well as an easier implementation. Finally, we\npropose a novel evaluation metric, called Sensitivity-n and test the\ngradient-based attribution methods alongside with a simple perturbation-based\nattribution method on several datasets in the domains of image and text\nclassification, using various network architectures.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 14:19:29 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 09:53:41 GMT"}, {"version": "v3", "created": "Mon, 12 Feb 2018 12:14:04 GMT"}, {"version": "v4", "created": "Wed, 7 Mar 2018 10:49:28 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Ancona", "Marco", ""], ["Ceolini", "Enea", ""], ["\u00d6ztireli", "Cengiz", ""], ["Gross", "Markus", ""]]}, {"id": "1711.06114", "submitter": "Werner Zellinger", "authors": "Werner Zellinger, Bernhard A. Moser, Thomas Grubinger, Edwin Lughofer,\n  Thomas Natschl\\\"ager, and Susanne Saminger-Platz", "title": "Robust Unsupervised Domain Adaptation for Neural Networks via Moment\n  Alignment", "comments": "Preliminary version of this work appeared in ICLR", "journal-ref": "Information Sciences 483: 174-191, May 2019", "doi": "10.1016/j.ins.2019.01.025", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel approach for unsupervised domain adaptation for neural networks is\nproposed. It relies on metric-based regularization of the learning process. The\nmetric-based regularization aims at domain-invariant latent feature\nrepresentations by means of maximizing the similarity between domain-specific\nactivation distributions. The proposed metric results from modifying an\nintegral probability metric such that it becomes less translation-sensitive on\na polynomial function space. The metric has an intuitive interpretation in the\ndual space as the sum of differences of higher order central moments of the\ncorresponding activation distributions. Under appropriate assumptions on the\ninput distributions, error minimization is proven for the continuous case. As\ndemonstrated by an analysis of standard benchmark experiments for sentiment\nanalysis, object recognition and digit recognition, the outlined approach is\nrobust regarding parameter changes and achieves higher classification\naccuracies than comparable approaches. The source code is available at\nhttps://github.com/wzell/mann.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 14:45:05 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 16:40:41 GMT"}, {"version": "v3", "created": "Mon, 21 Jan 2019 11:40:16 GMT"}, {"version": "v4", "created": "Tue, 13 Aug 2019 06:40:25 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Zellinger", "Werner", ""], ["Moser", "Bernhard A.", ""], ["Grubinger", "Thomas", ""], ["Lughofer", "Edwin", ""], ["Natschl\u00e4ger", "Thomas", ""], ["Saminger-Platz", "Susanne", ""]]}, {"id": "1711.06116", "submitter": "Aaqib Saeed", "authors": "Aaqib Saeed and Stojan Trajanovski", "title": "Personalized Driver Stress Detection with Multi-task Neural Networks\n  using Physiological Signals", "comments": "6 pages, 1 figure, 2 tables, NIPS - Machine Learning for Health\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stress can be seen as a physiological response to everyday emotional, mental\nand physical challenges. A long-term exposure to stressful situations can have\nnegative health consequences, such as increased risk of cardiovascular diseases\nand immune system disorder. Therefore, a timely stress detection can lead to\nsystems for better management and prevention in future circumstances. In this\npaper, we suggest a multi-task learning based neural network approach (with\nhard parameter sharing of mutual representation and task-specific layers) for\npersonalized stress recognition using skin conductance and heart rate from\nwearable devices. The proposed method is tested on multi-modal physiological\nresponses collected during real-world and simulator driving tasks.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 12:20:11 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Saeed", "Aaqib", ""], ["Trajanovski", "Stojan", ""]]}, {"id": "1711.06148", "submitter": "Srikrishna Karanam", "authors": "Yunye Gong and Srikrishna Karanam and Ziyan Wu and Kuan-Chuan Peng and\n  Jan Ernst and Peter C. Doerschuk", "title": "Learning Compositional Visual Concepts with Mutual Consistency", "comments": "10 pages, 8 figures, 4 tables, CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compositionality of semantic concepts in image synthesis and analysis is\nappealing as it can help in decomposing known and generatively recomposing\nunknown data. For instance, we may learn concepts of changing illumination,\ngeometry or albedo of a scene, and try to recombine them to generate physically\nmeaningful, but unseen data for training and testing. In practice however we\noften do not have samples from the joint concept space available: We may have\ndata on illumination change in one data set and on geometric change in another\none without complete overlap. We pose the following question: How can we learn\ntwo or more concepts jointly from different data sets with mutual consistency\nwhere we do not have samples from the full joint space? We present a novel\nanswer in this paper based on cyclic consistency over multiple concepts,\nrepresented individually by generative adversarial networks (GANs). Our method,\nConceptGAN, can be understood as a drop in for data augmentation to improve\nresilience for real world applications. Qualitative and quantitative\nevaluations demonstrate its efficacy in generating semantically meaningful\nimages, as well as one shot face verification as an example application.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 15:41:34 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 15:22:53 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Gong", "Yunye", ""], ["Karanam", "Srikrishna", ""], ["Wu", "Ziyan", ""], ["Peng", "Kuan-Chuan", ""], ["Ernst", "Jan", ""], ["Doerschuk", "Peter C.", ""]]}, {"id": "1711.06178", "submitter": "Michael Hughes", "authors": "Mike Wu, Michael C. Hughes, Sonali Parbhoo, Maurizio Zazzi, Volker\n  Roth, and Finale Doshi-Velez", "title": "Beyond Sparsity: Tree Regularization of Deep Models for Interpretability", "comments": "To appear in AAAI 2018. Contains 9-page main paper and appendix with\n  supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of interpretability remains a key barrier to the adoption of deep\nmodels in many applications. In this work, we explicitly regularize deep models\nso human users might step through the process behind their predictions in\nlittle time. Specifically, we train deep time-series models so their\nclass-probability predictions have high accuracy while being closely modeled by\ndecision trees with few nodes. Using intuitive toy examples as well as medical\ntasks for treating sepsis and HIV, we demonstrate that this new tree\nregularization yields models that are easier for humans to simulate than\nsimpler L1 or L2 penalties without sacrificing predictive power.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 16:35:24 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Wu", "Mike", ""], ["Hughes", "Michael C.", ""], ["Parbhoo", "Sonali", ""], ["Zazzi", "Maurizio", ""], ["Roth", "Volker", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1711.06195", "submitter": "Payel Das", "authors": "Tejas Dharamsi, Payel Das, Tejaswini Pedapati, Gregory Bramble, Vinod\n  Muthusamy, Horst Samulowitz, Kush R. Varshney, Yuvaraj Rajamanickam, John\n  Thomas, Justin Dauwels", "title": "Neurology-as-a-Service for the Developing World", "comments": "Presented at NIPS 2017 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalography (EEG) is an extensively-used and well-studied\ntechnique in the field of medical diagnostics and treatment for brain\ndisorders, including epilepsy, migraines, and tumors. The analysis and\ninterpretation of EEGs require physicians to have specialized training, which\nis not common even among most doctors in the developed world, let alone the\ndeveloping world where physician shortages plague society. This problem can be\naddressed by teleEEG that uses remote EEG analysis by experts or by local\ncomputer processing of EEGs. However, both of these options are prohibitively\nexpensive and the second option requires abundant computing resources and\ninfrastructure, which is another concern in developing countries where there\nare resource constraints on capital and computing infrastructure. In this work,\nwe present a cloud-based deep neural network approach to provide decision\nsupport for non-specialist physicians in EEG analysis and interpretation. Named\n`neurology-as-a-service,' the approach requires almost no manual intervention\nin feature engineering and in the selection of an optimal architecture and\nhyperparameters of the neural network. In this study, we deploy a pipeline that\nincludes moving EEG data to the cloud and getting optimal models for various\nclassification tasks. Our initial prototype has been tested only in developed\nworld environments to-date, but our intention is to test it in developing world\nenvironments in future work. We demonstrate the performance of our proposed\napproach using the BCI2000 EEG MMI dataset, on which our service attains 63.4%\naccuracy for the task of classifying real vs. imaginary activity performed by\nthe subject, which is significantly higher than what is obtained with a shallow\napproach such as support vector machines.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 16:58:53 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 01:11:52 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Dharamsi", "Tejas", ""], ["Das", "Payel", ""], ["Pedapati", "Tejaswini", ""], ["Bramble", "Gregory", ""], ["Muthusamy", "Vinod", ""], ["Samulowitz", "Horst", ""], ["Varshney", "Kush R.", ""], ["Rajamanickam", "Yuvaraj", ""], ["Thomas", "John", ""], ["Dauwels", "Justin", ""]]}, {"id": "1711.06221", "submitter": "Aditya Balu", "authors": "Aditya Balu, Thanh V. Nguyen, Apurva Kokate, Chinmay Hegde and Soumik\n  Sarkar", "title": "A Forward-Backward Approach for Visualizing Information Flow in Deep\n  Networks", "comments": "Presented at NIPS 2017 Symposium on Interpretable Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new, systematic framework for visualizing information flow in\ndeep networks. Specifically, given any trained deep convolutional network model\nand a given test image, our method produces a compact support in the image\ndomain that corresponds to a (high-resolution) feature that contributes to the\ngiven explanation. Our method is both computationally efficient as well as\nnumerically robust. We present several preliminary numerical results that\nsupport the benefits of our framework over existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 18:00:24 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Balu", "Aditya", ""], ["Nguyen", "Thanh V.", ""], ["Kokate", "Apurva", ""], ["Hegde", "Chinmay", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1711.06252", "submitter": "Shojaeddin Chenouri", "authors": "Jiaxi Liang, Shojaeddin Chenouri and Christopher G. Small", "title": "A New Method for Performance Analysis in Nonlinear Dimensionality\n  Reduction", "comments": "20 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a local rank correlation measure which quantifies\nthe performance of dimension reduction methods. The local rank correlation is\neasily interpretable, and robust against the extreme skewness of nearest\nneighbor distributions in high dimensions. Some benchmark datasets are studied.\nWe find that the local rank correlation closely corresponds to our visual\ninterpretation of the quality of the output. In addition, we demonstrate that\nthe local rank correlation is useful in estimating the intrinsic dimensionality\nof the original data, and in selecting a suitable value of tuning parameters\nused in some algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 18:52:17 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Liang", "Jiaxi", ""], ["Chenouri", "Shojaeddin", ""], ["Small", "Christopher G.", ""]]}, {"id": "1711.06288", "submitter": "Jianbo Chen", "authors": "Jianbo Chen, Yelong Shen, Jianfeng Gao, Jingjing Liu, Xiaodong Liu", "title": "Language-Based Image Editing with Recurrent Attentive Models", "comments": "Accepted to CVPR 2018 as a Spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of Language-Based Image Editing (LBIE). Given a\nsource image and a natural language description, we want to generate a target\nimage by editing the source image based on the description. We propose a\ngeneric modeling framework for two sub-tasks of LBIE: language-based image\nsegmentation and image colorization. The framework uses recurrent attentive\nmodels to fuse image and language features. Instead of using a fixed step size,\nwe introduce for each region of the image a termination gate to dynamically\ndetermine after each inference step whether to continue extrapolating\nadditional information from the textual description. The effectiveness of the\nframework is validated on three datasets. First, we introduce a synthetic\ndataset, called CoSaL, to evaluate the end-to-end performance of our LBIE\nsystem. Second, we show that the framework leads to state-of-the-art\nperformance on image segmentation on the ReferIt dataset. Third, we present the\nfirst language-based colorization result on the Oxford-102 Flowers dataset.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 19:10:21 GMT"}, {"version": "v2", "created": "Sun, 10 Jun 2018 04:04:30 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Chen", "Jianbo", ""], ["Shen", "Yelong", ""], ["Gao", "Jianfeng", ""], ["Liu", "Jingjing", ""], ["Liu", "Xiaodong", ""]]}, {"id": "1711.06299", "submitter": "Pieter Libin", "authors": "Pieter Libin, Timothy Verstraeten, Diederik M. Roijers, Jelena Grujic,\n  Kristof Theys, Philippe Lemey, Ann Now\\'e", "title": "Bayesian Best-Arm Identification for Selecting Influenza Mitigation\n  Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pandemic influenza has the epidemic potential to kill millions of people.\nWhile various preventive measures exist (i.a., vaccination and school\nclosures), deciding on strategies that lead to their most effective and\nefficient use remains challenging. To this end, individual-based\nepidemiological models are essential to assist decision makers in determining\nthe best strategy to curb epidemic spread. However, individual-based models are\ncomputationally intensive and it is therefore pivotal to identify the optimal\nstrategy using a minimal amount of model evaluations. Additionally, as\nepidemiological modeling experiments need to be planned, a computational budget\nneeds to be specified a priori. Consequently, we present a new sampling\ntechnique to optimize the evaluation of preventive strategies using fixed\nbudget best-arm identification algorithms. We use epidemiological modeling\ntheory to derive knowledge about the reward distribution which we exploit using\nBayesian best-arm identification algorithms (i.e., Top-two Thompson sampling\nand BayesGap). We evaluate these algorithms in a realistic experimental setting\nand demonstrate that it is possible to identify the optimal strategy using only\na limited number of model evaluations, i.e., 2-to-3 times faster compared to\nthe uniform sampling method, the predominant technique used for epidemiological\ndecision making in the literature. Finally, we contribute and evaluate a\nstatistic for Top-two Thompson sampling to inform the decision makers about the\nconfidence of an arm recommendation.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 19:40:10 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 12:06:19 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Libin", "Pieter", ""], ["Verstraeten", "Timothy", ""], ["Roijers", "Diederik M.", ""], ["Grujic", "Jelena", ""], ["Theys", "Kristof", ""], ["Lemey", "Philippe", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "1711.06350", "submitter": "Mirco Musolesi", "authors": "Gatis Mikelsons and Matthew Smith and Abhinav Mehrotra and Mirco\n  Musolesi", "title": "Towards Deep Learning Models for Psychological State Prediction using\n  Smartphone Data: Challenges and Opportunities", "comments": "6 pages, 2 figures, In Proceedings of the NIPS Workshop on Machine\n  Learning for Healthcare 2017 (ML4H 2017). Colocated with NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing interest in exploiting mobile sensing technologies and\nmachine learning techniques for mental health monitoring and intervention.\nResearchers have effectively used contextual information, such as mobility,\ncommunication and mobile phone usage patterns for quantifying individuals' mood\nand wellbeing. In this paper, we investigate the effectiveness of neural\nnetwork models for predicting users' level of stress by using the location\ninformation collected by smartphones. We characterize the mobility patterns of\nindividuals using the GPS metrics presented in the literature and employ these\nmetrics as input to the network. We evaluate our approach on the open-source\nStudentLife dataset. Moreover, we discuss the challenges and trade-offs\ninvolved in building machine learning models for digital mental health and\nhighlight potential future work in this direction.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 23:18:03 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Mikelsons", "Gatis", ""], ["Smith", "Matthew", ""], ["Mehrotra", "Abhinav", ""], ["Musolesi", "Mirco", ""]]}, {"id": "1711.06351", "submitter": "Anselm Rothe", "authors": "Anselm Rothe, Brenden M. Lake, Todd M. Gureckis", "title": "Question Asking as Program Generation", "comments": "Published in Advances in Neural Information Processing Systems (NIPS)\n  30, December 2017", "journal-ref": "Rothe, A., Lake, B. M., and Gureckis, T. M. (2017). Question\n  asking as program generation. Advances in Neural Information Processing\n  Systems 30", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hallmark of human intelligence is the ability to ask rich, creative, and\nrevealing questions. Here we introduce a cognitive model capable of\nconstructing human-like questions. Our approach treats questions as formal\nprograms that, when executed on the state of the world, output an answer. The\nmodel specifies a probability distribution over a complex, compositional space\nof programs, favoring concise programs that help the agent learn in the current\ncontext. We evaluate our approach by modeling the types of open-ended questions\ngenerated by humans who were attempting to learn about an ambiguous situation\nin a game. We find that our model predicts what questions people will ask, and\ncan creatively produce novel questions that were not present in the training\nset. In addition, we compare a number of model variants, finding that both\nquestion informativeness and complexity are important for producing human-like\nquestions.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 23:27:04 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Rothe", "Anselm", ""], ["Lake", "Brenden M.", ""], ["Gureckis", "Todd M.", ""]]}, {"id": "1711.06379", "submitter": "Terrell Mundhenk", "authors": "T. Nathan Mundhenk, Daniel Ho and Barry Y. Chen", "title": "Improvements to context based self-supervised learning", "comments": "Accepted paper at CVPR 2018", "journal-ref": null, "doi": "10.1109/CVPR.2018.00973", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a set of methods to improve on the results of self-supervised\nlearning using context. We start with a baseline of patch based arrangement\ncontext learning and go from there. Our methods address some overt problems\nsuch as chromatic aberration as well as other potential problems such as\nspatial skew and mid-level feature neglect. We prevent problems with testing\ngeneralization on common self-supervised benchmark tests by using different\ndatasets during our development. The results of our methods combined yield top\nscores on all standard self-supervised benchmarks, including classification and\ndetection on PASCAL VOC 2007, segmentation on PASCAL VOC 2012, and \"linear\ntests\" on the ImageNet and CSAIL Places datasets. We obtain an improvement over\nour baseline method of between 4.0 to 7.1 percentage points on transfer\nlearning classification tests. We also show results on different standard\nnetwork architectures to demonstrate generalization as well as portability. All\ndata, models and programs are available at:\nhttps://gdo-datasci.llnl.gov/selfsupervised/.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 02:22:21 GMT"}, {"version": "v2", "created": "Tue, 2 Jan 2018 23:00:35 GMT"}, {"version": "v3", "created": "Wed, 28 Mar 2018 22:14:26 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Mundhenk", "T. Nathan", ""], ["Ho", "Daniel", ""], ["Chen", "Barry Y.", ""]]}, {"id": "1711.06402", "submitter": "Anand Avati", "authors": "Anand Avati, Kenneth Jung, Stephanie Harman, Lance Downing, Andrew Ng\n  and Nigam H. Shah", "title": "Improving Palliative Care with Deep Learning", "comments": "IEEE International Conference on Bioinformatics and Biomedicine 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving the quality of end-of-life care for hospitalized patients is a\npriority for healthcare organizations. Studies have shown that physicians tend\nto over-estimate prognoses, which in combination with treatment inertia results\nin a mismatch between patients wishes and actual care at the end of life. We\ndescribe a method to address this problem using Deep Learning and Electronic\nHealth Record (EHR) data, which is currently being piloted, with Institutional\nReview Board approval, at an academic medical center. The EHR data of admitted\npatients are automatically evaluated by an algorithm, which brings patients who\nare likely to benefit from palliative care services to the attention of the\nPalliative Care team. The algorithm is a Deep Neural Network trained on the EHR\ndata from previous years, to predict all-cause 3-12 month mortality of patients\nas a proxy for patients that could benefit from palliative care. Our\npredictions enable the Palliative Care team to take a proactive approach in\nreaching out to such patients, rather than relying on referrals from treating\nphysicians, or conduct time consuming chart reviews of all patients. We also\npresent a novel interpretation technique which we use to provide explanations\nof the model's predictions.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 04:46:17 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Avati", "Anand", ""], ["Jung", "Kenneth", ""], ["Harman", "Stephanie", ""], ["Downing", "Lance", ""], ["Ng", "Andrew", ""], ["Shah", "Nigam H.", ""]]}, {"id": "1711.06424", "submitter": "Seong Jin Cho", "authors": "Seong Jin Cho, Sunghun Kang, Chang D. Yoo", "title": "A Resizable Mini-batch Gradient Descent based on a Multi-Armed Bandit", "comments": "8 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the appropriate batch size for mini-batch gradient descent is\nalways time consuming as it often relies on grid search. This paper considers a\nresizable mini-batch gradient descent (RMGD) algorithm based on a multi-armed\nbandit for achieving best performance in grid search by selecting an\nappropriate batch size at each epoch with a probability defined as a function\nof its previous success/failure. This probability encourages exploration of\ndifferent batch size and then later exploitation of batch size with history of\nsuccess. At each epoch, the RMGD samples a batch size from its probability\ndistribution, then uses the selected batch size for mini-batch gradient\ndescent. After obtaining the validation loss at each epoch, the probability\ndistribution is updated to incorporate the effectiveness of the sampled batch\nsize. The RMGD essentially assists the learning process to explore the possible\ndomain of the batch size and exploit successful batch size. Experimental\nresults show that the RMGD achieves performance better than the best performing\nsingle batch size. Furthermore, it, obviously, attains this performance in a\nshorter amount of time than grid search. It is surprising that the RMGD\nachieves better performance than grid search.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 06:21:47 GMT"}, {"version": "v2", "created": "Sun, 3 Dec 2017 13:35:29 GMT"}, {"version": "v3", "created": "Tue, 27 Feb 2018 14:00:30 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Cho", "Seong Jin", ""], ["Kang", "Sunghun", ""], ["Yoo", "Chang D.", ""]]}, {"id": "1711.06445", "submitter": "Idan Kligvasser", "authors": "Idan Kligvasser, Tamar Rott Shaham and Tomer Michaeli", "title": "xUnit: Learning a Spatial Activation Function for Efficient Image\n  Restoration", "comments": "Conference on Computer Vision and Pattern Recognition (CVPR), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep neural networks (DNNs) achieved unprecedented\nperformance in many low-level vision tasks. However, state-of-the-art results\nare typically achieved by very deep networks, which can reach tens of layers\nwith tens of millions of parameters. To make DNNs implementable on platforms\nwith limited resources, it is necessary to weaken the tradeoff between\nperformance and efficiency. In this paper, we propose a new activation unit,\nwhich is particularly suitable for image restoration problems. In contrast to\nthe widespread per-pixel activation units, like ReLUs and sigmoids, our unit\nimplements a learnable nonlinear function with spatial connections. This\nenables the net to capture much more complex features, thus requiring a\nsignificantly smaller number of layers in order to reach the same performance.\nWe illustrate the effectiveness of our units through experiments with\nstate-of-the-art nets for denoising, de-raining, and super resolution, which\nare already considered to be very small. With our approach, we are able to\nfurther reduce these models by nearly 50% without incurring any degradation in\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 08:00:44 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 14:05:33 GMT"}, {"version": "v3", "created": "Sun, 25 Mar 2018 08:49:43 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Kligvasser", "Idan", ""], ["Shaham", "Tamar Rott", ""], ["Michaeli", "Tomer", ""]]}, {"id": "1711.06446", "submitter": "Ke Ma", "authors": "Ke Ma, Jinshan Zeng, Jiechao Xiong, Qianqian Xu, Xiaochun Cao, Wei\n  Liu, Yuan Yao", "title": "Stochastic Non-convex Ordinal Embedding with Stabilized Barzilai-Borwein\n  Step Size", "comments": "11 pages, 3 figures, 2 tables, accepted by AAAI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representation from relative similarity comparisons, often called\nordinal embedding, gains rising attention in recent years. Most of the existing\nmethods are batch methods designed mainly based on the convex optimization,\nsay, the projected gradient descent method. However, they are generally\ntime-consuming due to that the singular value decomposition (SVD) is commonly\nadopted during the update, especially when the data size is very large. To\novercome this challenge, we propose a stochastic algorithm called SVRG-SBB,\nwhich has the following features: (a) SVD-free via dropping convexity, with\ngood scalability by the use of stochastic algorithm, i.e., stochastic variance\nreduced gradient (SVRG), and (b) adaptive step size choice via introducing a\nnew stabilized Barzilai-Borwein (SBB) method as the original version for convex\nproblems might fail for the considered stochastic \\textit{non-convex}\noptimization problem. Moreover, we show that the proposed algorithm converges\nto a stationary point at a rate $\\mathcal{O}(\\frac{1}{T})$ in our setting,\nwhere $T$ is the number of total iterations. Numerous simulations and\nreal-world data experiments are conducted to show the effectiveness of the\nproposed algorithm via comparing with the state-of-the-art methods,\nparticularly, much lower computational cost with good prediction performance.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 08:01:07 GMT"}, {"version": "v2", "created": "Wed, 31 Jan 2018 02:47:26 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Ma", "Ke", ""], ["Zeng", "Jinshan", ""], ["Xiong", "Jiechao", ""], ["Xu", "Qianqian", ""], ["Cao", "Xiaochun", ""], ["Liu", "Wei", ""], ["Yao", "Yuan", ""]]}, {"id": "1711.06464", "submitter": "Jens Berg", "authors": "Jens Berg and Kaj Nystr\\\"om", "title": "A unified deep artificial neural network approach to partial\n  differential equations in complex geometries", "comments": "35 pages, 12 figures", "journal-ref": null, "doi": "10.1016/j.neucom.2018.06.056", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we use deep feedforward artificial neural networks to\napproximate solutions to partial differential equations in complex geometries.\nWe show how to modify the backpropagation algorithm to compute the partial\nderivatives of the network output with respect to the space variables which is\nneeded to approximate the differential operator. The method is based on an\nansatz for the solution which requires nothing but feedforward neural networks\nand an unconstrained gradient based optimization method such as gradient\ndescent or a quasi-Newton method.\n  We show an example where classical mesh based methods cannot be used and\nneural networks can be seen as an attractive alternative. Finally, we highlight\nthe benefits of deep compared to shallow neural networks and device some other\nconvergence enhancing techniques.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 09:29:52 GMT"}, {"version": "v2", "created": "Wed, 22 Aug 2018 07:28:28 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Berg", "Jens", ""], ["Nystr\u00f6m", "Kaj", ""]]}, {"id": "1711.06484", "submitter": "Saikat  Chatterjee", "authors": "Antoine Honor\\'e and Veronica Siljehav and Saikat Chatterjee and Eric\n  Herlenius", "title": "Large Neural Network Based Detection of Apnea, Bradycardia and\n  Desaturation Events", "comments": "Accepted for NIPS Workshop ML4H, 2017", "journal-ref": "Neural Information Processing Systems (NIPS) 2017 Workshop on\n  Machine Learning for Health, Long Beach, CA, USA", "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Apnea, bradycardia and desaturation (ABD) events often precede\nlife-threatening events including sepsis in newborn babies. Here, we explore\nmachine learning for detection of ABD events as a binary classification\nproblem. We investigate the use of a large neural network to achieve a good\ndetection performance. To be user friendly, the chosen neural network does not\nrequire a high level of parameter tuning. Furthermore, a limited amount of\ntraining data is available and the training dataset is unbalanced. Comparing\nwith two widely used state-of-the-art machine learning algorithms, the large\nneural network is found to be efficient. Even with a limited and unbalanced\ntraining data, the large neural network provides a detection performance level\nthat is feasible to use in clinical care.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 10:38:51 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Honor\u00e9", "Antoine", ""], ["Siljehav", "Veronica", ""], ["Chatterjee", "Saikat", ""], ["Herlenius", "Eric", ""]]}, {"id": "1711.06516", "submitter": "Filippo Maria Bianchi", "authors": "Andreas Storvik Strauman, Filippo Maria Bianchi, Karl {\\O}yvind\n  Mikalsen, Michael Kampffmeyer, Cristina Soguero-Ruiz, Robert Jenssen", "title": "Classification of postoperative surgical site infections from blood\n  measurements with missing data using recurrent neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical measurements that can be represented as time series constitute an\nimportant fraction of the electronic health records and are often both\nuncertain and incomplete. Recurrent neural networks are a special class of\nneural networks that are particularly suitable to process time series data but,\nin their original formulation, cannot explicitly deal with missing data. In\nthis paper, we explore imputation strategies for handling missing values in\nclassifiers based on recurrent neural network (RNN) and apply a recently\nproposed recurrent architecture, the Gated Recurrent Unit with Decay,\nspecifically designed to handle missing data. We focus on the problem of\ndetecting surgical site infection in patients by analyzing time series of their\nblood sample measurements and we compare the results obtained with different\nRNN-based classifiers.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 12:52:10 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Strauman", "Andreas Storvik", ""], ["Bianchi", "Filippo Maria", ""], ["Mikalsen", "Karl \u00d8yvind", ""], ["Kampffmeyer", "Michael", ""], ["Soguero-Ruiz", "Cristina", ""], ["Jenssen", "Robert", ""]]}, {"id": "1711.06528", "submitter": "Xu Sun", "authors": "Xu Sun, Xuancheng Ren, Shuming Ma, Bingzhen Wei, Wei Li, Jingjing Xu,\n  Houfeng Wang, Yi Zhang", "title": "Training Simplification and Model Simplification for Deep Learning: A\n  Minimal Effort Back Propagation Method", "comments": "14 pages, 4 figures, 13 tables, accepted for publication in IEEE\n  TKDE; this article supersedes arXiv:1706.06197", "journal-ref": null, "doi": "10.1109/TKDE.2018.2883613", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple yet effective technique to simplify the training and the\nresulting model of neural networks. In back propagation, only a small subset of\nthe full gradient is computed to update the model parameters. The gradient\nvectors are sparsified in such a way that only the top-k elements (in terms of\nmagnitude) are kept. As a result, only k rows or columns (depending on the\nlayout) of the weight matrix are modified, leading to a linear reduction in the\ncomputational cost. Based on the sparsified gradients, we further simplify the\nmodel by eliminating the rows or columns that are seldom updated, which will\nreduce the computational cost both in the training and decoding, and\npotentially accelerate decoding in real-world applications. Surprisingly,\nexperimental results demonstrate that most of time we only need to update fewer\nthan 5% of the weights at each back propagation pass. More interestingly, the\naccuracy of the resulting models is actually improved rather than degraded, and\na detailed analysis is given. The model simplification results show that we\ncould adaptively simplify the model which could often be reduced by around 9x,\nwithout any loss on accuracy or even with improved accuracy. The codes,\nincluding the extension, are available at https://github.com/lancopku/meSimp\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 13:36:51 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 01:22:44 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Sun", "Xu", ""], ["Ren", "Xuancheng", ""], ["Ma", "Shuming", ""], ["Wei", "Bingzhen", ""], ["Li", "Wei", ""], ["Xu", "Jingjing", ""], ["Wang", "Houfeng", ""], ["Zhang", "Yi", ""]]}, {"id": "1711.06552", "submitter": "Isa Inuwa-Dutse", "authors": "Isa Inuwa-Dutse", "title": "Introduction to intelligent computing unit 1", "comments": "23 Pages and 10 figures document", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This brief note highlights some basic concepts required toward understanding\nthe evolution of machine learning and deep learning models. The note starts\nwith an overview of artificial intelligence and its relationship to biological\nneuron that ultimately led to the evolution of todays intelligent models.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 16:52:48 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Inuwa-Dutse", "Isa", ""]]}, {"id": "1711.06562", "submitter": "Joose Rajam\\\"aki", "authors": "Joose Rajam\\\"aki and Perttu H\\\"am\\\"al\\\"ainen", "title": "An Iterative Closest Points Approach to Neural Generative Models", "comments": "Indexing errors have been corrected to this version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple way to learn a transformation that maps samples of one\ndistribution to the samples of another distribution. Our algorithm comprises an\niteration of 1) drawing samples from some simple distribution and transforming\nthem using a neural network, 2) determining pairwise correspondences between\nthe transformed samples and training data (or a minibatch), and 3) optimizing\nthe weights of the neural network being trained to minimize the distances\nbetween the corresponding vectors. This can be considered as a variant of the\nIterative Closest Points (ICP) algorithm, common in geometric computer vision,\nalthough ICP typically operates on sensor point clouds and linear transforms\ninstead of random sample sets and neural nonlinear transforms. We demonstrate\nthe algorithm on simple synthetic data and MNIST data. We furthermore\ndemonstrate that the algorithm is capable of handling distributions with both\ncontinuous and discrete variables.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 08:07:47 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2018 11:32:46 GMT"}, {"version": "v3", "created": "Fri, 29 Jun 2018 15:21:40 GMT"}, {"version": "v4", "created": "Mon, 2 Jul 2018 06:23:01 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Rajam\u00e4ki", "Joose", ""], ["H\u00e4m\u00e4l\u00e4inen", "Perttu", ""]]}, {"id": "1711.06581", "submitter": "Ryan Curtin", "authors": "Ryan R. Curtin and Shikhar Bhardwaj and Marcus Edel and Yannis\n  Mentekidis", "title": "A generic and fast C++ optimization framework", "comments": "6 pages + references submitted to MLSYS 2017 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of the mlpack C++ machine learning library\n(http://www.mlpack.org/) has required the design and implementation of a\nflexible, robust optimization system that is able to solve the types of\narbitrary optimization problems that may arise all throughout machine learning\nproblems. In this paper, we present the generic optimization framework that we\nhave designed for mlpack. A key priority in the design was ease of\nimplementation of both new optimizers and new objective functions to be\noptimized; therefore, implementation of a new optimizer requires only one\nmethod and implementation of a new objective function requires at most four\nfunctions. This leads to simple and intuitive code, which, for fast prototyping\nand experimentation, is of paramount importance. When compared to optimization\nframeworks of other libraries, we find that mlpack's supports more types of\nobjective functions, is able to make optimizations that other frameworks do\nnot, and seamlessly supports user-defined objective functions and optimizers.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 15:10:25 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Curtin", "Ryan R.", ""], ["Bhardwaj", "Shikhar", ""], ["Edel", "Marcus", ""], ["Mentekidis", "Yannis", ""]]}, {"id": "1711.06583", "submitter": "Pawe{\\l} Liskowski", "authors": "Pawe{\\l} Liskowski, Wojciech Ja\\'skowski, Krzysztof Krawiec", "title": "Learning to Play Othello with Deep Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TG.2018.2799997", "report-no": null, "categories": "cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving superhuman playing level by AlphaGo corroborated the capabilities\nof convolutional neural architectures (CNNs) for capturing complex spatial\npatterns. This result was to a great extent due to several analogies between Go\nboard states and 2D images CNNs have been designed for, in particular\ntranslational invariance and a relatively large board. In this paper, we verify\nwhether CNN-based move predictors prove effective for Othello, a game with\nsignificantly different characteristics, including a much smaller board size\nand complete lack of translational invariance. We compare several CNN\narchitectures and board encodings, augment them with state-of-the-art\nextensions, train on an extensive database of experts' moves, and examine them\nwith respect to move prediction accuracy and playing strength. The empirical\nevaluation confirms high capabilities of neural move predictors and suggests a\nstrong correlation between prediction accuracy and playing strength. The best\nCNNs not only surpass all other 1-ply Othello players proposed to date but\ndefeat (2-ply) Edax, the best open-source Othello player.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 15:14:20 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Liskowski", "Pawe\u0142", ""], ["Ja\u015bkowski", "Wojciech", ""], ["Krawiec", "Krzysztof", ""]]}, {"id": "1711.06586", "submitter": "Lukas Hewing", "authors": "Lukas Hewing, Alexander Liniger, Melanie N. Zeilinger", "title": "Cautious NMPC with Gaussian Process Dynamics for Autonomous Miniature\n  Race Cars", "comments": null, "journal-ref": "2018 European Control Conference (ECC), Limassol, 2018, pp.\n  1341-1348", "doi": "10.23919/ECC.2018.8550162", "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an adaptive high performance control method for\nautonomous miniature race cars. Racing dynamics are notoriously hard to model\nfrom first principles, which is addressed by means of a cautious nonlinear\nmodel predictive control (NMPC) approach that learns to improve its dynamics\nmodel from data and safely increases racing performance. The approach makes use\nof a Gaussian Process (GP) and takes residual model uncertainty into account\nthrough a chance constrained formulation. We present a sparse GP approximation\nwith dynamically adjusting inducing inputs, enabling a real-time implementable\ncontroller. The formulation is demonstrated in simulations, which show\nsignificant improvement with respect to both lap time and constraint\nsatisfaction compared to an NMPC without model learning.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 15:21:09 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 03:20:42 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Hewing", "Lukas", ""], ["Liniger", "Alexander", ""], ["Zeilinger", "Melanie N.", ""]]}, {"id": "1711.06598", "submitter": "Kathrin Grosse", "authors": "Kathrin Grosse, David Pfaff, Michael Thomas Smith, Michael Backes", "title": "How Wrong Am I? - Studying Adversarial Examples and their Impact on\n  Uncertainty in Gaussian Process Machine Learning Models", "comments": "Reasoning incomplete. Fixed issue in arXiv:1812.02606 (The\n  limitations of model uncertainty in adversarial settings)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are vulnerable to Adversarial Examples: minor\nperturbations to input samples intended to deliberately cause\nmisclassification. Current defenses against adversarial examples, especially\nfor Deep Neural Networks (DNN), are primarily derived from empirical\ndevelopments, and their security guarantees are often only justified\nretroactively. Many defenses therefore rely on hidden assumptions that are\nsubsequently subverted by increasingly elaborate attacks. This is not\nsurprising: deep learning notoriously lacks a comprehensive mathematical\nframework to provide meaningful guarantees.\n  In this paper, we leverage Gaussian Processes to investigate adversarial\nexamples in the framework of Bayesian inference. Across different models and\ndatasets, we find deviating levels of uncertainty reflect the perturbation\nintroduced to benign samples by state-of-the-art attacks, including novel\nwhite-box attacks on Gaussian Processes. Our experiments demonstrate that even\nunoptimized uncertainty thresholds already reject adversarial examples in many\nscenarios.\n  Comment: Thresholds can be broken in a modified attack, which was done in\narXiv:1812.02606 (The limitations of model uncertainty in adversarial\nsettings).\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 15:46:44 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 09:06:33 GMT"}, {"version": "v3", "created": "Fri, 16 Feb 2018 09:37:19 GMT"}, {"version": "v4", "created": "Thu, 3 Jan 2019 12:29:59 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Grosse", "Kathrin", ""], ["Pfaff", "David", ""], ["Smith", "Michael Thomas", ""], ["Backes", "Michael", ""]]}, {"id": "1711.06623", "submitter": "Dan Barnes", "authors": "Dan Barnes, Will Maddern, Geoffrey Pascoe and Ingmar Posner", "title": "Driven to Distraction: Self-Supervised Distractor Learning for Robust\n  Monocular Visual Odometry in Urban Environments", "comments": "International Conference on Robotics and Automation (ICRA), 2018.\n  Video summary: http://youtu.be/ebIrBn_nc-k", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a self-supervised approach to ignoring \"distractors\" in camera\nimages for the purposes of robustly estimating vehicle motion in cluttered\nurban environments. We leverage offline multi-session mapping approaches to\nautomatically generate a per-pixel ephemerality mask and depth map for each\ninput image, which we use to train a deep convolutional network. At run-time we\nuse the predicted ephemerality and depth as an input to a monocular visual\nodometry (VO) pipeline, using either sparse features or dense photometric\nmatching. Our approach yields metric-scale VO using only a single camera and\ncan recover the correct egomotion even when 90% of the image is obscured by\ndynamic, independently moving objects. We evaluate our robust VO methods on\nmore than 400km of driving from the Oxford RobotCar Dataset and demonstrate\nreduced odometry drift and significantly improved egomotion estimation in the\npresence of large moving vehicles in urban traffic.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 16:54:40 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 14:29:23 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Barnes", "Dan", ""], ["Maddern", "Will", ""], ["Pascoe", "Geoffrey", ""], ["Posner", "Ingmar", ""]]}, {"id": "1711.06652", "submitter": "Nathan Wiebe", "authors": "Nathan Wiebe, Ram Shankar Siva Kumar", "title": "Hardening Quantum Machine Learning Against Adversaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security for machine learning has begun to become a serious issue for present\nday applications. An important question remaining is whether emerging quantum\ntechnologies will help or hinder the security of machine learning. Here we\ndiscuss a number of ways that quantum information can be used to help make\nquantum classifiers more secure or private. In particular, we demonstrate a\nform of robust principal component analysis that, under some circumstances, can\nprovide an exponential speedup relative to robust methods used at present. To\ndemonstrate this approach we introduce a linear combinations of unitaries\nHamiltonian simulation method that we show functions when given an imprecise\nHamiltonian oracle, which may be of independent interest. We also introduce a\nnew quantum approach for bagging and boosting that can use quantum\nsuperposition over the classifiers or splits of the training set to aggregate\nover many more models than would be possible classically. Finally, we provide a\nprivate form of $k$--means clustering that can be used to prevent an all\npowerful adversary from learning more than a small fraction of a bit from any\nuser. These examples show the role that quantum technologies can play in the\nsecurity of ML and vice versa. This illustrates that quantum computing can\nprovide useful advantages to machine learning apart from speedups.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 18:02:26 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Wiebe", "Nathan", ""], ["Kumar", "Ram Shankar Siva", ""]]}, {"id": "1711.06664", "submitter": "David Madras", "authors": "David Madras, Toniann Pitassi, Richard Zemel", "title": "Predict Responsibly: Improving Fairness and Accuracy by Learning to\n  Defer", "comments": "Accepted as a conference paper at Neural Information Processing\n  Systems 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many machine learning applications, there are multiple decision-makers\ninvolved, both automated and human. The interaction between these agents often\ngoes unaddressed in algorithmic development. In this work, we explore a simple\nversion of this interaction with a two-stage framework containing an automated\nmodel and an external decision-maker. The model can choose to say \"Pass\", and\npass the decision downstream, as explored in rejection learning. We extend this\nconcept by proposing \"learning to defer\", which generalizes rejection learning\nby considering the effect of other agents in the decision-making process. We\npropose a learning algorithm which accounts for potential biases held by\nexternal decision-makers in a system. Experiments demonstrate that learning to\ndefer can make systems not only more accurate but also less biased. Even when\nworking with inconsistent or biased users, we show that deferring models still\ngreatly improve the accuracy and/or fairness of the entire system.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 18:43:04 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 16:34:56 GMT"}, {"version": "v3", "created": "Fri, 7 Sep 2018 00:48:55 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Madras", "David", ""], ["Pitassi", "Toniann", ""], ["Zemel", "Richard", ""]]}, {"id": "1711.06673", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu and Yuanzhi Li", "title": "Neon2: Finding Local Minima via First-Order Oracles", "comments": "version 2 and 3 improve writing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a reduction for non-convex optimization that can (1) turn an\nstationary-point finding algorithm into an local-minimum finding one, and (2)\nreplace the Hessian-vector product computations with only gradient\ncomputations. It works both in the stochastic and the deterministic settings,\nwithout hurting the algorithm's performance.\n  As applications, our reduction turns Natasha2 into a first-order method\nwithout hurting its performance. It also converts SGD, GD, SCSG, and SVRG into\nalgorithms finding approximate local minima, outperforming some best known\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 18:59:01 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 06:34:18 GMT"}, {"version": "v3", "created": "Fri, 20 Apr 2018 07:58:25 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""]]}, {"id": "1711.06677", "submitter": "Johanni Brea", "authors": "Johanni Brea", "title": "Is prioritized sweeping the better episodic control?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Episodic control has been proposed as a third approach to reinforcement\nlearning, besides model-free and model-based control, by analogy with the three\ntypes of human memory. i.e. episodic, procedural and semantic memory. But the\ntheoretical properties of episodic control are not well investigated. Here I\nshow that in deterministic tree Markov decision processes, episodic control is\nequivalent to a form of prioritized sweeping in terms of sample efficiency as\nwell as memory and computation demands. For general deterministic and\nstochastic environments, prioritized sweeping performs better even when memory\nand computation demands are restricted to be equal to those of episodic\ncontrol. These results suggest generalizations of prioritized sweeping to\npartially observable environments, its combined use with function approximation\nand the search for possible implementations of prioritized sweeping in brains.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 07:47:12 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2018 20:25:43 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Brea", "Johanni", ""]]}, {"id": "1711.06703", "submitter": "Zining Wang", "authors": "Zining Wang, Wei Zhan, Masayoshi Tomizuka", "title": "Fusing Bird View LIDAR Point Cloud and Front View Camera Image for Deep\n  Object Detection", "comments": "10 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for fusing a LIDAR point cloud and camera-captured\nimages in the deep convolutional neural network (CNN). The proposed method\nconstructs a new layer called non-homogeneous pooling layer to transform\nfeatures between bird view map and front view map. The sparse LIDAR point cloud\nis used to construct the mapping between the two maps. The pooling layer allows\nefficient fusion of the bird view and front view features at any stage of the\nnetwork. This is favorable for the 3D-object detection using camera-LIDAR\nfusion in autonomous driving scenarios. A corresponding deep CNN is designed\nand tested on the KITTI bird view object detection dataset, which produces 3D\nbounding boxes from the bird view map. The fusion method shows particular\nbenefit for detection of pedestrians in the bird view compared to other\nfusion-based object detection networks.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 19:36:49 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 01:22:13 GMT"}, {"version": "v3", "created": "Wed, 14 Feb 2018 03:52:03 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Wang", "Zining", ""], ["Zhan", "Wei", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1711.06705", "submitter": "Zhigang Yao", "authors": "Zhigang Yao and Zhenyue Zhang", "title": "Principal Boundary on Riemannian Manifolds", "comments": "31 pages,10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classification problem and focus on nonlinear methods for\nclassification on manifolds. For multivariate datasets lying on an embedded\nnonlinear Riemannian manifold within the higher-dimensional ambient space, we\naim to acquire a classification boundary for the classes with labels, using the\nintrinsic metric on the manifolds. Motivated by finding an optimal boundary\nbetween the two classes, we invent a novel approach -- the principal boundary.\nFrom the perspective of classification, the principal boundary is defined as an\noptimal curve that moves in between the principal flows traced out from two\nclasses of data, and at any point on the boundary, it maximizes the margin\nbetween the two classes. We estimate the boundary in quality with its\ndirection, supervised by the two principal flows. We show that the principal\nboundary yields the usual decision boundary found by the support vector machine\nin the sense that locally, the two boundaries coincide. Some optimality and\nconvergence properties of the random principal boundary and its population\ncounterpart are also shown. We illustrate how to find, use and interpret the\nprincipal boundary with an application in real data.\n", "versions": [{"version": "v1", "created": "Sat, 21 Oct 2017 14:35:45 GMT"}, {"version": "v2", "created": "Sat, 30 Mar 2019 17:34:40 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Yao", "Zhigang", ""], ["Zhang", "Zhenyue", ""]]}, {"id": "1711.06719", "submitter": "Alexander Terenin", "authors": "Alexander Terenin and Eric P. Xing", "title": "Techniques for proving Asynchronous Convergence results for Markov Chain\n  Monte Carlo methods", "comments": "Workshop on Advances in Approximate Bayesian Inference, 31st\n  Conference on Neural Information Processing Systems, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Chain Monte Carlo (MCMC) methods such as Gibbs sampling are finding\nwidespread use in applied statistics and machine learning. These often lead to\ndifficult computational problems, which are increasingly being solved on\nparallel and distributed systems such as compute clusters. Recent work has\nproposed running iterative algorithms such as gradient descent and MCMC in\nparallel asynchronously for increased performance, with good empirical results\nin certain problems. Unfortunately, for MCMC this parallelization technique\nrequires new convergence theory, as it has been explicitly demonstrated to lead\nto divergence on some examples. Recent theory on Asynchronous Gibbs sampling\ndescribes why these algorithms can fail, and provides a way to alter them to\nmake them converge. In this article, we describe how to apply this theory in a\ngeneric setting, to understand the asynchronous behavior of any MCMC algorithm,\nincluding those implemented using parameter servers, and those not based on\nGibbs sampling.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 20:46:38 GMT"}, {"version": "v2", "created": "Fri, 24 Nov 2017 21:38:29 GMT"}, {"version": "v3", "created": "Tue, 28 Nov 2017 16:01:13 GMT"}, {"version": "v4", "created": "Thu, 30 Nov 2017 15:54:34 GMT"}, {"version": "v5", "created": "Sun, 3 Jun 2018 23:42:46 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Terenin", "Alexander", ""], ["Xing", "Eric P.", ""]]}, {"id": "1711.06756", "submitter": "Hesham Mostafa", "authors": "Hesham Mostafa, Vishwajith Ramesh, Gert Cauwenberghs", "title": "Deep supervised learning using local errors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Error backpropagation is a highly effective mechanism for learning\nhigh-quality hierarchical features in deep networks. Updating the features or\nweights in one layer, however, requires waiting for the propagation of error\nsignals from higher layers. Learning using delayed and non-local errors makes\nit hard to reconcile backpropagation with the learning mechanisms observed in\nbiological neural networks as it requires the neurons to maintain a memory of\nthe input long enough until the higher-layer errors arrive. In this paper, we\npropose an alternative learning mechanism where errors are generated locally in\neach layer using fixed, random auxiliary classifiers. Lower layers could thus\nbe trained independently of higher layers and training could either proceed\nlayer by layer, or simultaneously in all layers using local error information.\nWe address biological plausibility concerns such as weight symmetry\nrequirements and show that the proposed learning mechanism based on fixed,\nbroad, and random tuning of each neuron to the classification categories\noutperforms the biologically-motivated feedback alignment learning technique on\nthe MNIST, CIFAR10, and SVHN datasets, approaching the performance of standard\nbackpropagation. Our approach highlights a potential biological mechanism for\nthe supervised, or task-dependent, learning of feature hierarchies. In\naddition, we show that it is well suited for learning deep networks in custom\nhardware where it can drastically reduce memory traffic and data communication\noverheads.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 22:48:02 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Mostafa", "Hesham", ""], ["Ramesh", "Vishwajith", ""], ["Cauwenberghs", "Gert", ""]]}, {"id": "1711.06761", "submitter": "Matthew Riemer", "authors": "Matthew Riemer, Tim Klinger, Djallel Bouneffouf, Michele Franceschini", "title": "Scalable Recollections for Continual Lifelong Learning", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the recent success of Deep Learning applied to a variety of single\ntasks, it is natural to consider more human-realistic settings. Perhaps the\nmost difficult of these settings is that of continual lifelong learning, where\nthe model must learn online over a continuous stream of non-stationary data. A\nsuccessful continual lifelong learning system must have three key capabilities:\nit must learn and adapt over time, it must not forget what it has learned, and\nit must be efficient in both training time and memory. Recent techniques have\nfocused their efforts primarily on the first two capabilities while questions\nof efficiency remain largely unexplored. In this paper, we consider the problem\nof efficient and effective storage of experiences over very large time-frames.\nIn particular we consider the case where typical experiences are O(n) bits and\nmemories are limited to O(k) bits for k << n. We present a novel scalable\narchitecture and training algorithm in this challenging domain and provide an\nextensive evaluation of its performance. Our results show that we can achieve\nconsiderable gains on top of state-of-the-art methods such as GEM.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 23:00:11 GMT"}, {"version": "v2", "created": "Sat, 17 Feb 2018 01:10:31 GMT"}, {"version": "v3", "created": "Mon, 26 Feb 2018 14:32:41 GMT"}, {"version": "v4", "created": "Thu, 20 Dec 2018 04:37:37 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Riemer", "Matthew", ""], ["Klinger", "Tim", ""], ["Bouneffouf", "Djallel", ""], ["Franceschini", "Michele", ""]]}, {"id": "1711.06771", "submitter": "Zachary Charles", "authors": "Zachary Charles, Dimitris Papailiopoulos, Jordan Ellenberg", "title": "Approximate Gradient Coding via Sparse Random Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.IT cs.LG math.IT stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed algorithms are often beset by the straggler effect, where the\nslowest compute nodes in the system dictate the overall running time.\nCoding-theoretic techniques have been recently proposed to mitigate stragglers\nvia algorithmic redundancy. Prior work in coded computation and gradient coding\nhas mainly focused on exact recovery of the desired output. However, slightly\ninexact solutions can be acceptable in applications that are robust to noise,\nsuch as model training via gradient-based algorithms. In this work, we present\ncomputationally simple gradient codes based on sparse graphs that guarantee\nfast and approximately accurate distributed computation. We demonstrate that\nsacrificing a small amount of accuracy can significantly increase algorithmic\nrobustness to stragglers.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 23:19:30 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Charles", "Zachary", ""], ["Papailiopoulos", "Dimitris", ""], ["Ellenberg", "Jordan", ""]]}, {"id": "1711.06779", "submitter": "Loubna Benabbou", "authors": "Abderrahim Khalifa, Younes Idsouguou, Loubna Benabbou, Mourad Zirari", "title": "Machine Learning Approaches for Traffic Volume Forecasting: A Case Study\n  of the Moroccan Highway Network", "comments": "Presented at NIPS 2017 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim to illustrate different approaches we followed while\ndeveloping a forecasting tool for highway traffic in Morocco. Two main\napproaches were adopted: Statistical Analysis as a step of data exploration and\ndata wrangling. Therefore, a beta model is carried out for a better\nunderstanding of traffic behavior. Next, we moved to Machine Learning where we\nworked with a bunch of algorithms such as Random Forest, Artificial Neural\nNetworks, Extra Trees, etc. yet, we were convinced that this field of study is\nstill considered under state of the art models, so, we were also covering an\napplication of Long Short-Term Memory Neural Networks.\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 00:26:44 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Khalifa", "Abderrahim", ""], ["Idsouguou", "Younes", ""], ["Benabbou", "Loubna", ""], ["Zirari", "Mourad", ""]]}, {"id": "1711.06782", "submitter": "Benjamin Eysenbach", "authors": "Benjamin Eysenbach, Shixiang Gu, Julian Ibarz and Sergey Levine", "title": "Leave no Trace: Learning to Reset for Safe and Autonomous Reinforcement\n  Learning", "comments": "Videos of our experiments are available at:\n  https://sites.google.com/site/mlleavenotrace/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning algorithms can learn complex behavioral skills,\nbut real-world application of these methods requires a large amount of\nexperience to be collected by the agent. In practical settings, such as\nrobotics, this involves repeatedly attempting a task, resetting the environment\nbetween each attempt. However, not all tasks are easily or automatically\nreversible. In practice, this learning process requires extensive human\nintervention. In this work, we propose an autonomous method for safe and\nefficient reinforcement learning that simultaneously learns a forward and reset\npolicy, with the reset policy resetting the environment for a subsequent\nattempt. By learning a value function for the reset policy, we can\nautomatically determine when the forward policy is about to enter a\nnon-reversible state, providing for uncertainty-aware safety aborts. Our\nexperiments illustrate that proper use of the reset policy can greatly reduce\nthe number of manual resets required to learn a task, can reduce the number of\nunsafe actions that lead to non-reversible states, and can automatically induce\na curriculum.\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 00:53:20 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Eysenbach", "Benjamin", ""], ["Gu", "Shixiang", ""], ["Ibarz", "Julian", ""], ["Levine", "Sergey", ""]]}, {"id": "1711.06783", "submitter": "Daniel Cullina", "authors": "Daniel Cullina and Negar Kiyavash", "title": "Exact alignment recovery for correlated Erd\\H{o}s-R\\'enyi graphs", "comments": "12 pages. arXiv admin note: text overlap with arXiv:1602.01042", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of perfectly recovering the vertex correspondence\nbetween two correlated Erd\\H{o}s-R\\'enyi (ER) graphs on the same vertex set.\nThe correspondence between the vertices can be obscured by randomly permuting\nthe vertex labels of one of the graphs. We determine the information-theoretic\nthreshold for exact recovery, i.e. the conditions under which the entire vertex\ncorrespondence can be correctly recovered given unbounded computational\nresources.\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 00:57:18 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 04:27:12 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Cullina", "Daniel", ""], ["Kiyavash", "Negar", ""]]}, {"id": "1711.06788", "submitter": "Minmin Chen", "authors": "Minmin Chen", "title": "MinimalRNN: Toward More Interpretable and Trainable Recurrent Neural\n  Networks", "comments": "Presented at NIPS 2017 Symposium on Interpretable Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce MinimalRNN, a new recurrent neural network architecture that\nachieves comparable performance as the popular gated RNNs with a simplified\nstructure. It employs minimal updates within RNN, which not only leads to\nefficient learning and testing but more importantly better interpretability and\ntrainability. We demonstrate that by endorsing the more restrictive update\nrule, MinimalRNN learns disentangled RNN states. We further examine the\nlearning dynamics of different RNN structures using input-output Jacobians, and\nshow that MinimalRNN is able to capture longer range dependencies than existing\nRNN architectures.\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 01:42:04 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 02:19:13 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Chen", "Minmin", ""]]}, {"id": "1711.06793", "submitter": "Jos\\'e Marcio Luna", "authors": "Jos\\'e Marcio Luna, Eric Eaton, Lyle H. Ungar, Eric Diffenderfer,\n  Shane T. Jensen, Efstathios D. Gennatas, Mateo Wirth, Charles B. Simone II,\n  Timothy D. Solberg, Gilmer Valdes", "title": "Tree-Structured Boosting: Connections Between Gradient Boosted Stumps\n  and Full Decision Trees", "comments": "Presented at NIPS 2017 Symposium on Interpretable Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Additive models, such as produced by gradient boosting, and full interaction\nmodels, such as classification and regression trees (CART), are widely used\nalgorithms that have been investigated largely in isolation. We show that these\nmodels exist along a spectrum, revealing never-before-known connections between\nthese two approaches. This paper introduces a novel technique called\ntree-structured boosting for creating a single decision tree, and shows that\nthis method can produce models equivalent to CART or gradient boosted stumps at\nthe extremes by varying a single parameter. Although tree-structured boosting\nis designed primarily to provide both the model interpretability and predictive\nperformance needed for high-stake applications like medicine, it also can\nproduce decision trees represented by hybrid models between CART and boosted\nstumps that can outperform either of these approaches.\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 02:05:44 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Luna", "Jos\u00e9 Marcio", ""], ["Eaton", "Eric", ""], ["Ungar", "Lyle H.", ""], ["Diffenderfer", "Eric", ""], ["Jensen", "Shane T.", ""], ["Gennatas", "Efstathios D.", ""], ["Wirth", "Mateo", ""], ["Simone", "Charles B.", "II"], ["Solberg", "Timothy D.", ""], ["Valdes", "Gilmer", ""]]}, {"id": "1711.06795", "submitter": "Bilal Alsallakh", "authors": "Medha Katehara, Emma Beauxis-Aussalet, Bilal Alsallakh", "title": "Prediction Scores as a Window into Classifier Behavior", "comments": "Presented at NIPS 2017 Symposium on Interpretable Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most multi-class classifiers make their prediction for a test sample by\nscoring the classes and selecting the one with the highest score. Analyzing\nthese prediction scores is useful to understand the classifier behavior and to\nassess its reliability. We present an interactive visualization that\nfacilitates per-class analysis of these scores. Our system, called Classilist,\nenables relating these scores to the classification correctness and to the\nunderlying samples and their features. We illustrate how such analysis reveals\nvarying behavior of different classifiers. Classilist is available for use\nonline, along with source code, video tutorials, and plugins for R, RapidMiner,\nand KNIME at https://katehara.github.io/classilist-site/.\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 02:07:52 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Katehara", "Medha", ""], ["Beauxis-Aussalet", "Emma", ""], ["Alsallakh", "Bilal", ""]]}, {"id": "1711.06798", "submitter": "Elad Eban", "authors": "Ariel Gordon, Elad Eban, Ofir Nachum, Bo Chen, Hao Wu, Tien-Ju Yang,\n  Edward Choi", "title": "MorphNet: Fast & Simple Resource-Constrained Structure Learning of Deep\n  Networks", "comments": "Added reproducibility and stability figures in the appendix, as well\n  minor typos and clarifications to the main text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MorphNet, an approach to automate the design of neural network\nstructures. MorphNet iteratively shrinks and expands a network, shrinking via a\nresource-weighted sparsifying regularizer on activations and expanding via a\nuniform multiplicative factor on all layers. In contrast to previous\napproaches, our method is scalable to large networks, adaptable to specific\nresource constraints (e.g. the number of floating-point operations per\ninference), and capable of increasing the network's performance. When applied\nto standard network architectures on a wide variety of datasets, our approach\ndiscovers novel structures in each domain, obtaining higher performance while\nrespecting the resource constraint.\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 02:33:39 GMT"}, {"version": "v2", "created": "Thu, 30 Nov 2017 06:38:56 GMT"}, {"version": "v3", "created": "Tue, 17 Apr 2018 19:07:21 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Gordon", "Ariel", ""], ["Eban", "Elad", ""], ["Nachum", "Ofir", ""], ["Chen", "Bo", ""], ["Wu", "Hao", ""], ["Yang", "Tien-Ju", ""], ["Choi", "Edward", ""]]}, {"id": "1711.06839", "submitter": "Eli (Omid) David", "authors": "Eli David, Moshe Koppel, Nathan S. Netanyahu", "title": "Genetic Algorithms for Mentor-Assisted Evaluation Function Optimization", "comments": "Winner of Best Paper Award in GECCO 2008. arXiv admin note:\n  substantial text overlap with arXiv:1711.06840, arXiv:1711.06841", "journal-ref": "ACM Genetic and Evolutionary Computation Conference (GECCO), pages\n  1469-1475, Atlanta, GA, July 2008", "doi": "10.1145/1389095.1389382", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we demonstrate how genetic algorithms can be used to reverse\nengineer an evaluation function's parameters for computer chess. Our results\nshow that using an appropriate mentor, we can evolve a program that is on par\nwith top tournament-playing chess programs, outperforming a two-time World\nComputer Chess Champion. This performance gain is achieved by evolving a\nprogram with a smaller number of parameters in its evaluation function to mimic\nthe behavior of a superior mentor which uses a more extensive evaluation\nfunction. In principle, our mentor-assisted approach could be used in a wide\nrange of problems for which appropriate mentors are available.\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 10:12:02 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["David", "Eli", ""], ["Koppel", "Moshe", ""], ["Netanyahu", "Nathan S.", ""]]}, {"id": "1711.06840", "submitter": "Eli (Omid) David", "authors": "Eli David, H. Jaap van den Herik, Moshe Koppel, Nathan S. Netanyahu", "title": "Simulating Human Grandmasters: Evolution and Coevolution of Evaluation\n  Functions", "comments": "arXiv admin note: substantial text overlap with arXiv:1711.06839,\n  arXiv:1711.06841", "journal-ref": "ACM Genetic and Evolutionary Computation Conference (GECCO), pages\n  1483-1489, Montreal, Canada, July 2009", "doi": "10.1145/1569901.1570100", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates the use of genetic algorithms for evolving a\ngrandmaster-level evaluation function for a chess program. This is achieved by\ncombining supervised and unsupervised learning. In the supervised learning\nphase the organisms are evolved to mimic the behavior of human grandmasters,\nand in the unsupervised learning phase these evolved organisms are further\nimproved upon by means of coevolution.\n  While past attempts succeeded in creating a grandmaster-level program by\nmimicking the behavior of existing computer chess programs, this paper presents\nthe first successful attempt at evolving a state-of-the-art evaluation function\nby learning only from databases of games played by humans. Our results\ndemonstrate that the evolved program outperforms a two-time World Computer\nChess Champion.\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 10:16:24 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["David", "Eli", ""], ["Herik", "H. Jaap van den", ""], ["Koppel", "Moshe", ""], ["Netanyahu", "Nathan S.", ""]]}, {"id": "1711.06841", "submitter": "Eli (Omid) David", "authors": "Eli David, Moshe Koppel, Nathan S. Netanyahu", "title": "Expert-Driven Genetic Algorithms for Simulating Evaluation Functions", "comments": "arXiv admin note: substantial text overlap with arXiv:1711.06839,\n  arXiv:1711.06840", "journal-ref": "Genetic Programming and Evolvable Machines, Vol. 12, No. 1, pp.\n  5-22, March 2011", "doi": "10.1007/s10710-010-9103-4", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we demonstrate how genetic algorithms can be used to reverse\nengineer an evaluation function's parameters for computer chess. Our results\nshow that using an appropriate expert (or mentor), we can evolve a program that\nis on par with top tournament-playing chess programs, outperforming a two-time\nWorld Computer Chess Champion. This performance gain is achieved by evolving a\nprogram that mimics the behavior of a superior expert. The resulting evaluation\nfunction of the evolved program consists of a much smaller number of parameters\nthan the expert's. The extended experimental results provided in this paper\ninclude a report of our successful participation in the 2008 World Computer\nChess Championship. In principle, our expert-driven approach could be used in a\nwide range of problems for which appropriate experts are available.\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 10:22:49 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["David", "Eli", ""], ["Koppel", "Moshe", ""], ["Netanyahu", "Nathan S.", ""]]}, {"id": "1711.06853", "submitter": "Nick Pawlowski", "authors": "Nick Pawlowski, Sofia Ira Ktena, Matthew C.H. Lee, Bernhard Kainz,\n  Daniel Rueckert, Ben Glocker, Martin Rajchl", "title": "DLTK: State of the Art Reference Implementations for Deep Learning on\n  Medical Images", "comments": "Submitted to Medical Imaging Meets NIPS 2017, Code at\n  https://github.com/DLTK/DLTK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DLTK, a toolkit providing baseline implementations for efficient\nexperimentation with deep learning methods on biomedical images. It builds on\ntop of TensorFlow and its high modularity and easy-to-use examples allow for a\nlow-threshold access to state-of-the-art implementations for typical medical\nimaging problems. A comparison of DLTK's reference implementations of popular\nnetwork architectures for image segmentation demonstrates new top performance\non the publicly available challenge data \"Multi-Atlas Labeling Beyond the\nCranial Vault\". The average test Dice similarity coefficient of $81.5$ exceeds\nthe previously best performing CNN ($75.7$) and the accuracy of the challenge\nwinning method ($79.0$).\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 12:31:10 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Pawlowski", "Nick", ""], ["Ktena", "Sofia Ira", ""], ["Lee", "Matthew C. H.", ""], ["Kainz", "Bernhard", ""], ["Rueckert", "Daniel", ""], ["Glocker", "Ben", ""], ["Rajchl", "Martin", ""]]}, {"id": "1711.06867", "submitter": "Zhiyong Yang", "authors": "Zhiyong Yang, Qianqian Xu, Xiaochun Cao, Qingming Huang", "title": "From Common to Special: When Multi-Attribute Learning Meets Personalized\n  Opinions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual attributes, which refer to human-labeled semantic annotations, have\ngained increasing popularity in a wide range of real world applications.\nGenerally, the existing attribute learning methods fall into two categories:\none focuses on learning user-specific labels separately for different\nattributes, while the other one focuses on learning crowd-sourced global labels\njointly for multiple attributes. However, both categories ignore the joint\neffect of the two mentioned factors: the personal diversity with respect to the\nglobal consensus; and the intrinsic correlation among multiple attributes. To\novercome this challenge, we propose a novel model to learn user-specific\npredictors across multiple attributes. In our proposed model, the diversity of\npersonalized opinions and the intrinsic relationship among multiple attributes\nare unified in a common-to-special manner. To this end, we adopt a\nthree-component decomposition. Specifically, our model integrates a common\ncognition factor, an attribute-specific bias factor and a user-specific bias\nfactor. Meanwhile Lasso and group Lasso penalties are adopted to leverage\nefficient feature selection. Furthermore, theoretical analysis is conducted to\nshow that our proposed method could reach reasonable performance. Eventually,\nthe empirical study carried out in this paper demonstrates the effectiveness of\nour proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 14:27:18 GMT"}, {"version": "v2", "created": "Sat, 4 Aug 2018 09:34:16 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Yang", "Zhiyong", ""], ["Xu", "Qianqian", ""], ["Cao", "Xiaochun", ""], ["Huang", "Qingming", ""]]}, {"id": "1711.06922", "submitter": "Mikhail Pavlov", "authors": "Mikhail Pavlov, Sergey Kolesnikov, Sergey M. Plis", "title": "Run, skeleton, run: skeletal model in a physics-based simulation", "comments": "Corrected typos and spelling", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our approach to solve a physics-based reinforcement\nlearning challenge \"Learning to Run\" with objective to train\nphysiologically-based human model to navigate a complex obstacle course as\nquickly as possible. The environment is computationally expensive, has a\nhigh-dimensional continuous action space and is stochastic. We benchmark state\nof the art policy-gradient methods and test several improvements, such as layer\nnormalization, parameter noise, action and state reflecting, to stabilize\ntraining and improve its sample-efficiency. We found that the Deep\nDeterministic Policy Gradient method is the most efficient method for this\nenvironment and the improvements we have introduced help to stabilize training.\nLearned models are able to generalize to new physical scenarios, e.g. different\nobstacle courses.\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 20:18:16 GMT"}, {"version": "v2", "created": "Sun, 28 Jan 2018 09:29:07 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Pavlov", "Mikhail", ""], ["Kolesnikov", "Sergey", ""], ["Plis", "Sergey M.", ""]]}, {"id": "1711.06929", "submitter": "Cinzia Viroli", "authors": "Cinzia Viroli and Geoffrey J. McLachlan", "title": "Deep Gaussian Mixture Models", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is a hierarchical inference method formed by subsequent\nmultiple layers of learning able to more efficiently describe complex\nrelationships. In this work, Deep Gaussian Mixture Models are introduced and\ndiscussed. A Deep Gaussian Mixture model (DGMM) is a network of multiple layers\nof latent variables, where, at each layer, the variables follow a mixture of\nGaussian distributions. Thus, the deep mixture model consists of a set of\nnested mixtures of linear models, which globally provide a nonlinear model able\nto describe the data in a very flexible way. In order to avoid\noverparameterized solutions, dimension reduction by factor models can be\napplied at each layer of the architecture thus resulting in deep mixtures of\nfactor analysers.\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 21:48:36 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Viroli", "Cinzia", ""], ["McLachlan", "Geoffrey J.", ""]]}, {"id": "1711.06935", "submitter": "Sourya Dey", "authors": "Sourya Dey, Peter A. Beerel, Keith M. Chugg", "title": "Interleaver Design for Deep Neural Networks", "comments": "Slightly abridged version presented at the 2017 51st Asilomar\n  Conference on Signals, Systems, and Computers, copyright IEEE", "journal-ref": null, "doi": "10.1109/ACSSC.2017.8335713", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a class of interleavers for a novel deep neural network (DNN)\narchitecture that uses algorithmically pre-determined, structured sparsity to\nsignificantly lower memory and computational requirements, and speed up\ntraining. The interleavers guarantee clash-free memory accesses to eliminate\nidle operational cycles, optimize spread and dispersion to improve network\nperformance, and are designed to ease the complexity of memory address\ncomputations in hardware. We present a design algorithm with mathematical\nproofs for these properties. We also explore interleaver variations and analyze\nthe behavior of neural networks as a function of interleaver metrics.\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 22:40:27 GMT"}, {"version": "v2", "created": "Sun, 22 Apr 2018 21:58:41 GMT"}, {"version": "v3", "created": "Thu, 25 Apr 2019 22:46:16 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Dey", "Sourya", ""], ["Beerel", "Peter A.", ""], ["Chugg", "Keith M.", ""]]}, {"id": "1711.06959", "submitter": "Ziming Zhang", "authors": "Ziming Zhang, Yuanwei Wu, Guanghui Wang", "title": "BPGrad: Towards Global Optimality in Deep Learning via Branch and\n  Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the global optimality in deep learning (DL) has been attracting\nmore and more attention recently. Conventional DL solvers, however, have not\nbeen developed intentionally to seek for such global optimality. In this paper\nwe propose a novel approximation algorithm, BPGrad, towards optimizing deep\nmodels globally via branch and pruning. Our BPGrad algorithm is based on the\nassumption of Lipschitz continuity in DL, and as a result it can adaptively\ndetermine the step size for current gradient given the history of previous\nupdates, wherein theoretically no smaller steps can achieve the global\noptimality. We prove that, by repeating such branch-and-pruning procedure, we\ncan locate the global optimality within finite iterations. Empirically an\nefficient solver based on BPGrad for DL is proposed as well, and it outperforms\nconventional DL solvers such as Adagrad, Adadelta, RMSProp, and Adam in the\ntasks of object recognition, detection, and segmentation.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 02:44:31 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Zhang", "Ziming", ""], ["Wu", "Yuanwei", ""], ["Wang", "Guanghui", ""]]}, {"id": "1711.06969", "submitter": "Swami Sankaranarayanan", "authors": "Swami Sankaranarayanan, Yogesh Balaji, Arpit Jain, Ser Nam Lim, Rama\n  Chellappa", "title": "Learning from Synthetic Data: Addressing Domain Shift for Semantic\n  Segmentation", "comments": "Accepted as spotlight talk at CVPR 2018. Code available here:\n  https://github.com/swamiviv/LSD-seg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Domain Adaptation is a problem of immense importance in computer\nvision. Previous approaches showcase the inability of even deep neural networks\nto learn informative representations across domain shift. This problem is more\nsevere for tasks where acquiring hand labeled data is extremely hard and\ntedious. In this work, we focus on adapting the representations learned by\nsegmentation networks across synthetic and real domains. Contrary to previous\napproaches that use a simple adversarial objective or superpixel information to\naid the process, we propose an approach based on Generative Adversarial\nNetworks (GANs) that brings the embeddings closer in the learned feature space.\nTo showcase the generality and scalability of our approach, we show that we can\nachieve state of the art results on two challenging scenarios of synthetic to\nreal domain adaptation. Additional exploratory experiments show that our\napproach: (1) generalizes to unseen domains and (2) results in improved\nalignment of source and target distributions.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 05:25:24 GMT"}, {"version": "v2", "created": "Sun, 1 Apr 2018 21:48:18 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Sankaranarayanan", "Swami", ""], ["Balaji", "Yogesh", ""], ["Jain", "Arpit", ""], ["Lim", "Ser Nam", ""], ["Chellappa", "Rama", ""]]}, {"id": "1711.06970", "submitter": "Dhanasekar Sundararaman", "authors": "Nabarun Pal, Priya Arora, Dhanasekar Sundararaman, Puneet Kohli, Sai\n  Sumanth Palakurthy", "title": "How much is my car worth? A methodology for predicting used cars prices\n  using Random Forest", "comments": "FICC Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cars are being sold more than ever. Developing countries adopt the lease\nculture instead of buying a new car due to affordability. Therefore, the rise\nof used cars sales is exponentially increasing. Car sellers sometimes take\nadvantage of this scenario by listing unrealistic prices owing to the demand.\nTherefore, arises a need for a model that can assign a price for a vehicle by\nevaluating its features taking the prices of other cars into consideration. In\nthis paper, we use supervised learning method namely Random Forest to predict\nthe prices of used cars. The model has been chosen after careful exploratory\ndata analysis to determine the impact of each feature on price. A Random Forest\nwith 500 Decision Trees were created to train the data. From experimental\nresults, the training accuracy was found out to be 95.82%, and the testing\naccuracy was 83.63%. The the model can predict the price of cars accurately by\nchoosing the most correlated features.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 05:26:38 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Pal", "Nabarun", ""], ["Arora", "Priya", ""], ["Sundararaman", "Dhanasekar", ""], ["Kohli", "Puneet", ""], ["Palakurthy", "Sai Sumanth", ""]]}, {"id": "1711.06989", "submitter": "George S. Eskander Ekladious PhD", "authors": "Shaunak D. Bopardikar and George S. Eskander Ekladious", "title": "Sequential Randomized Matrix Factorization for Gaussian Processes:\n  Efficient Predictions and Hyper-parameter Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a sequential randomized lowrank matrix factorization\napproach for incrementally predicting values of an unknown function at test\npoints using the Gaussian Processes framework. It is well-known that in the\nGaussian processes framework, the computational bottlenecks are the inversion\nof the (regularized) kernel matrix and the computation of the hyper-parameters\ndefining the kernel. The main contributions of this paper are two-fold. First,\nwe formalize an approach to compute the inverse of the kernel matrix using\nrandomized matrix factorization algorithms in a streaming scenario, i.e., data\nis generated incrementally over time. The metrics of accuracy and computational\nefficiency of the proposed method are compared against a batch approach based\non use of randomized matrix factorization and an existing streaming approach\nbased on approximating the Gaussian process by a finite set of basis vectors.\nSecond, we extend the sequential factorization approach to a class of kernel\nfunctions for which the hyperparameters can be efficiently optimized. All\nresults are demonstrated on two publicly available datasets.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 09:38:33 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Bopardikar", "Shaunak D.", ""], ["Ekladious", "George S. Eskander", ""]]}, {"id": "1711.07005", "submitter": "Zhifeng Kong", "authors": "Zhifeng Kong", "title": "Convergence Analysis of the Dynamics of a Special Kind of Two-Layered\n  Neural Networks with $\\ell_1$ and $\\ell_2$ Regularization", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we made an extension to the convergence analysis of the\ndynamics of two-layered bias-free networks with one $ReLU$ output. We took into\nconsideration two popular regularization terms: the $\\ell_1$ and $\\ell_2$ norm\nof the parameter vector $w$, and added it to the square loss function with\ncoefficient $\\lambda/2$. We proved that when $\\lambda$ is small, the weight\nvector $w$ converges to the optimal solution $\\hat{w}$ (with respect to the new\nloss function) with probability $\\geq (1-\\varepsilon)(1-A_d)/2$ under random\ninitiations in a sphere centered at the origin, where $\\varepsilon$ is a small\nvalue and $A_d$ is a constant. Numerical experiments including phase diagrams\nand repeated simulations verified our theory.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 11:54:45 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Kong", "Zhifeng", ""]]}, {"id": "1711.07033", "submitter": "Kian Hsiang Low", "authors": "Trong Nghia Hoang, Quang Minh Hoang, Ruofei Ouyang, Kian Hsiang Low", "title": "Decentralized High-Dimensional Bayesian Optimization with Factor Graphs", "comments": "32nd AAAI Conference on Artificial Intelligence (AAAI 2018), Extended\n  version with proofs, 13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel decentralized high-dimensional Bayesian\noptimization (DEC-HBO) algorithm that, in contrast to existing HBO algorithms,\ncan exploit the interdependent effects of various input components on the\noutput of the unknown objective function f for boosting the BO performance and\nstill preserve scalability in the number of input dimensions without requiring\nprior knowledge or the existence of a low (effective) dimension of the input\nspace. To realize this, we propose a sparse yet rich factor graph\nrepresentation of f to be exploited for designing an acquisition function that\ncan be similarly represented by a sparse factor graph and hence be efficiently\noptimized in a decentralized manner using distributed message passing. Despite\nrichly characterizing the interdependent effects of the input components on the\noutput of f with a factor graph, DEC-HBO can still guarantee no-regret\nperformance asymptotically. Empirical evaluation on synthetic and real-world\nexperiments (e.g., sparse Gaussian process model with 1811 hyperparameters)\nshows that DEC-HBO outperforms the state-of-the-art HBO algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 15:45:53 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 10:08:08 GMT"}, {"version": "v3", "created": "Wed, 24 Jan 2018 18:56:10 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Hoang", "Trong Nghia", ""], ["Hoang", "Quang Minh", ""], ["Ouyang", "Ruofei", ""], ["Low", "Kian Hsiang", ""]]}, {"id": "1711.07038", "submitter": "Ganzhao Yuan", "authors": "Ganzhao Yuan, Haoxian Tan, Wei-Shi Zheng", "title": "A Coordinate-wise Optimization Algorithm for Sparse Inverse Covariance\n  Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse inverse covariance selection is a fundamental problem for analyzing\ndependencies in high dimensional data. However, such a problem is difficult to\nsolve since it is NP-hard. Existing solutions are primarily based on convex\napproximation and iterative hard thresholding, which only lead to sub-optimal\nsolutions. In this work, we propose a coordinate-wise optimization algorithm to\nsolve this problem which is guaranteed to converge to a coordinate-wise minimum\npoint. The algorithm iteratively and greedily selects one variable or swaps two\nvariables to identify the support set, and then solves a reduced convex\noptimization problem over the support set to achieve the greatest descent. As a\nside contribution of this paper, we propose a Newton-like algorithm to solve\nthe reduced convex sub-problem, which is proven to always converge to the\noptimal solution with global linear convergence rate and local quadratic\nconvergence rate. Finally, we demonstrate the efficacy of our method on\nsynthetic data and real-world data sets. As a result, the proposed method\nconsistently outperforms existing solutions in terms of accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 16:04:51 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 07:14:58 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Yuan", "Ganzhao", ""], ["Tan", "Haoxian", ""], ["Zheng", "Wei-Shi", ""]]}, {"id": "1711.07042", "submitter": "Kieran Greer Dr", "authors": "Kieran Greer", "title": "An Improved Oscillating-Error Classifier with Branching", "comments": "This paper is now out of date. You should read 'An Improved Batch\n  Classifier with Bands and Dimensions', arXiv:1811.02617, instead", "journal-ref": "WSEAS Transactions on Computer Research, Vol. 6, pp. 49 - 54.\n  2018. E-ISSN: 2415-1521", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the earlier work on an oscillating error correction\ntechnique. Specifically, it extends the design to include further corrections,\nby adding new layers to the classifier through a branching method. This\ntechnique is still consistent with earlier work and also neural networks in\ngeneral. With this extended design, the classifier can now achieve the high\nlevels of accuracy reported previously.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 16:24:26 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 08:26:31 GMT"}, {"version": "v3", "created": "Thu, 3 Oct 2019 18:09:07 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Greer", "Kieran", ""]]}, {"id": "1711.07050", "submitter": "Jay Hennig", "authors": "Jay A. Hennig, Akash Umakantha, Ryan C. Williamson", "title": "A Classifying Variational Autoencoder with Application to Polyphonic\n  Music Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variational autoencoder (VAE) is a popular probabilistic generative\nmodel. However, one shortcoming of VAEs is that the latent variables cannot be\ndiscrete, which makes it difficult to generate data from different modes of a\ndistribution. Here, we propose an extension of the VAE framework that\nincorporates a classifier to infer the discrete class of the modeled data. To\nmodel sequential data, we can combine our Classifying VAE with a recurrent\nneural network such as an LSTM. We apply this model to algorithmic music\ngeneration, where our model learns to generate musical sequences in different\nkeys. Most previous work in this area avoids modeling key by transposing data\ninto only one or two keys, as opposed to the 10+ different keys in the original\nmusic. We show that our Classifying VAE and Classifying VAE+LSTM models\noutperform the corresponding non-classifying models in generating musical\nsamples that stay in key. This benefit is especially apparent when trained on\nuntransposed music data in the original keys.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 16:48:48 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Hennig", "Jay A.", ""], ["Umakantha", "Akash", ""], ["Williamson", "Ryan C.", ""]]}, {"id": "1711.07051", "submitter": "Fedor Ratnikov", "authors": "V. Azzolini, M. Borisyak, G. Cerminara, D. Derkach, G. Franzoni, F. De\n  Guio, O. Koval, M. Pierini, A. Pol, F. Ratnikov, F. Siroky, A. Ustyuzhanin\n  and J-R. Vlimant", "title": "Deep learning for inferring cause of data anomalies", "comments": "Presented at ACAT 2017 conference, Seattle, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.LG hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Daily operation of a large-scale experiment is a resource consuming task,\nparticularly from perspectives of routine data quality monitoring. Typically,\ndata comes from different sub-detectors and the global quality of data depends\non the combinatorial performance of each of them. In this paper, the problem of\nidentifying channels in which anomalies occurred is considered. We introduce a\ngeneric deep learning model and prove that, under reasonable assumptions, the\nmodel learns to identify 'channels' which are affected by an anomaly. Such\nmodel could be used for data quality manager cross-check and assistance and\nidentifying good channels in anomalous data samples. The main novelty of the\nmethod is that the model does not require ground truth labels for each channel,\nonly global flag is used. This effectively distinguishes the model from\nclassical classification methods. Being applied to CMS data collected in the\nyear 2010, this approach proves its ability to decompose anomaly by separate\nchannels.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 16:51:31 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Azzolini", "V.", ""], ["Borisyak", "M.", ""], ["Cerminara", "G.", ""], ["Derkach", "D.", ""], ["Franzoni", "G.", ""], ["De Guio", "F.", ""], ["Koval", "O.", ""], ["Pierini", "M.", ""], ["Pol", "A.", ""], ["Ratnikov", "F.", ""], ["Siroky", "F.", ""], ["Ustyuzhanin", "A.", ""], ["Vlimant", "J-R.", ""]]}, {"id": "1711.07065", "submitter": "Moontae Lee", "authors": "Moontae Lee, David Bindel, David Mimno", "title": "Prior-aware Dual Decomposition: Document-specific Topic Inference for\n  Spectral Topic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral topic modeling algorithms operate on matrices/tensors of word\nco-occurrence statistics to learn topic-specific word distributions. This\napproach removes the dependence on the original documents and produces\nsubstantial gains in efficiency and provable topic inference, but at a cost:\nthe model can no longer provide information about the topic composition of\nindividual documents. Recently Thresholded Linear Inverse (TLI) is proposed to\nmap the observed words of each document back to its topic composition. However,\nits linear characteristics limit the inference quality without considering the\nimportant prior information over topics. In this paper, we evaluate Simple\nProbabilistic Inverse (SPI) method and novel Prior-aware Dual Decomposition\n(PADD) that is capable of learning document-specific topic compositions in\nparallel. Experiments show that PADD successfully leverages topic correlations\nas a prior, notably outperforming TLI and learning quality topic compositions\ncomparable to Gibbs sampling on various data.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 19:56:23 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Lee", "Moontae", ""], ["Bindel", "David", ""], ["Mimno", "David", ""]]}, {"id": "1711.07076", "submitter": "Zachary Lipton", "authors": "Zachary C. Lipton, Alexandra Chouldechova, Julian McAuley", "title": "Does mitigating ML's impact disparity require treatment disparity?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following related work in law and policy, two notions of disparity have come\nto shape the study of fairness in algorithmic decision-making. Algorithms\nexhibit treatment disparity if they formally treat members of protected\nsubgroups differently; algorithms exhibit impact disparity when outcomes differ\nacross subgroups, even if the correlation arises unintentionally. Naturally, we\ncan achieve impact parity through purposeful treatment disparity. In one thread\nof technical work, papers aim to reconcile the two forms of parity proposing\ndisparate learning processes (DLPs). Here, the learning algorithm can see group\nmembership during training but produce a classifier that is group-blind at test\ntime. In this paper, we show theoretically that: (i) When other features\ncorrelate to group membership, DLPs will (indirectly) implement treatment\ndisparity, undermining the policy desiderata they are designed to address; (ii)\nWhen group membership is partly revealed by other features, DLPs induce\nwithin-class discrimination; and (iii) In general, DLPs provide a suboptimal\ntrade-off between accuracy and impact parity. Based on our technical analysis,\nwe argue that transparent treatment disparity is preferable to occluded methods\nfor achieving impact parity. Experimental results on several real-world\ndatasets highlight the practical consequences of applying DLPs vs. per-group\nthresholds.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 20:48:09 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 23:43:38 GMT"}, {"version": "v3", "created": "Fri, 11 Jan 2019 15:03:21 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Lipton", "Zachary C.", ""], ["Chouldechova", "Alexandra", ""], ["McAuley", "Julian", ""]]}, {"id": "1711.07077", "submitter": "Maria Dimakopoulou", "authors": "Maria Dimakopoulou, Zhengyuan Zhou, Susan Athey, Guido Imbens", "title": "Estimation Considerations in Contextual Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandit algorithms are sensitive to the estimation method of the\noutcome model as well as the exploration method used, particularly in the\npresence of rich heterogeneity or complex outcome models, which can lead to\ndifficult estimation problems along the path of learning. We study a\nconsideration for the exploration vs. exploitation framework that does not\narise in multi-armed bandits but is crucial in contextual bandits; the way\nexploration and exploitation is conducted in the present affects the bias and\nvariance in the potential outcome model estimation in subsequent stages of\nlearning. We develop parametric and non-parametric contextual bandits that\nintegrate balancing methods from the causal inference literature in their\nestimation to make it less prone to problems of estimation bias. We provide the\nfirst regret bound analyses for contextual bandits with balancing in the domain\nof linear contextual bandits that match the state of the art regret bounds. We\ndemonstrate the strong practical advantage of balanced contextual bandits on a\nlarge number of supervised learning datasets and on a synthetic example that\nsimulates model mis-specification and prejudice in the initial training data.\nAdditionally, we develop contextual bandits with simpler assignment policies by\nleveraging sparse model estimation methods from the econometrics literature and\ndemonstrate empirically that in the early stages they can improve the rate of\nlearning and decrease regret.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 20:49:47 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 00:57:42 GMT"}, {"version": "v3", "created": "Fri, 13 Jul 2018 11:14:23 GMT"}, {"version": "v4", "created": "Sun, 16 Dec 2018 07:50:33 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Dimakopoulou", "Maria", ""], ["Zhou", "Zhengyuan", ""], ["Athey", "Susan", ""], ["Imbens", "Guido", ""]]}, {"id": "1711.07099", "submitter": "Leonardo Rey Vega", "authors": "Mat\\'ias Vera, Leonardo Rey Vega, Pablo Piantanida", "title": "Compression-Based Regularization with an Application to Multi-Task\n  Learning", "comments": "13 pages, 7 figures. Submitted for publication", "journal-ref": null, "doi": "10.1109/JSTSP.2018.2846218", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates, from information theoretic grounds, a learning\nproblem based on the principle that any regularity in a given dataset can be\nexploited to extract compact features from data, i.e., using fewer bits than\nneeded to fully describe the data itself, in order to build meaningful\nrepresentations of a relevant content (multiple labels). We begin by\nintroducing the noisy lossy source coding paradigm with the log-loss fidelity\ncriterion which provides the fundamental tradeoffs between the\n\\emph{cross-entropy loss} (average risk) and the information rate of the\nfeatures (model complexity). Our approach allows an information theoretic\nformulation of the \\emph{multi-task learning} (MTL) problem which is a\nsupervised learning framework in which the prediction models for several\nrelated tasks are learned jointly from common representations to achieve better\ngeneralization performance. Then, we present an iterative algorithm for\ncomputing the optimal tradeoffs and its global convergence is proven provided\nthat some conditions hold. An important property of this algorithm is that it\nprovides a natural safeguard against overfitting, because it minimizes the\naverage risk taking into account a penalization induced by the model\ncomplexity. Remarkably, empirical results illustrate that there exists an\noptimal information rate minimizing the \\emph{excess risk} which depends on the\nnature and the amount of available training data. An application to\nhierarchical text categorization is also investigated, extending previous\nworks.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 23:07:18 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Vera", "Mat\u00edas", ""], ["Vega", "Leonardo Rey", ""], ["Piantanida", "Pablo", ""]]}, {"id": "1711.07112", "submitter": "Ehsan Kazemi", "authors": "Ehsan Kazemi and Morteza Zadimoghaddam and Amin Karbasi", "title": "Deletion-Robust Submodular Maximization at Scale", "comments": "27 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we efficiently extract useful information from a large user-generated\ndataset while protecting the privacy of the users and/or ensuring fairness in\nrepresentation. We cast this problem as an instance of a deletion-robust\nsubmodular maximization where part of the data may be deleted due to privacy\nconcerns or fairness criteria. We propose the first memory-efficient\ncentralized, streaming, and distributed methods with constant-factor\napproximation guarantees against any number of adversarial deletions. We\nextensively evaluate the performance of our algorithms against prior\nstate-of-the-art on real-world applications, including (i) Uber-pick up\nlocations with location privacy constraints; (ii) feature selection with\nfairness constraints for income prediction and crime rate prediction; and (iii)\nrobust to deletion summarization of census data, consisting of 2,458,285\nfeature vectors.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 01:05:17 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 02:20:36 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Kazemi", "Ehsan", ""], ["Zadimoghaddam", "Morteza", ""], ["Karbasi", "Amin", ""]]}, {"id": "1711.07128", "submitter": "Naveen Suda", "authors": "Yundong Zhang, Naveen Suda, Liangzhen Lai and Vikas Chandra", "title": "Hello Edge: Keyword Spotting on Microcontrollers", "comments": "Code available in github at\n  https://github.com/ARM-software/ML-KWS-for-MCU", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG cs.NE eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyword spotting (KWS) is a critical component for enabling speech based user\ninteractions on smart devices. It requires real-time response and high accuracy\nfor good user experience. Recently, neural networks have become an attractive\nchoice for KWS architecture because of their superior accuracy compared to\ntraditional speech processing algorithms. Due to its always-on nature, KWS\napplication has highly constrained power budget and typically runs on tiny\nmicrocontrollers with limited memory and compute capability. The design of\nneural network architecture for KWS must consider these constraints. In this\nwork, we perform neural network architecture evaluation and exploration for\nrunning KWS on resource-constrained microcontrollers. We train various neural\nnetwork architectures for keyword spotting published in literature to compare\ntheir accuracy and memory/compute requirements. We show that it is possible to\noptimize these neural network architectures to fit within the memory and\ncompute constraints of microcontrollers without sacrificing accuracy. We\nfurther explore the depthwise separable convolutional neural network (DS-CNN)\nand compare it against other neural network architectures. DS-CNN achieves an\naccuracy of 95.4%, which is ~10% higher than the DNN model with similar number\nof parameters.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 03:19:03 GMT"}, {"version": "v2", "created": "Wed, 13 Dec 2017 23:54:52 GMT"}, {"version": "v3", "created": "Wed, 14 Feb 2018 19:24:55 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Zhang", "Yundong", ""], ["Suda", "Naveen", ""], ["Lai", "Liangzhen", ""], ["Chandra", "Vikas", ""]]}, {"id": "1711.07131", "submitter": "Kuang-Huei Lee", "authors": "Kuang-Huei Lee, Xiaodong He, Lei Zhang, Linjun Yang", "title": "CleanNet: Transfer Learning for Scalable Image Classifier Training with\n  Label Noise", "comments": "Accepted to CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of learning image classification models\nwith label noise. Existing approaches depending on human supervision are\ngenerally not scalable as manually identifying correct or incorrect labels is\ntime-consuming, whereas approaches not relying on human supervision are\nscalable but less effective. To reduce the amount of human supervision for\nlabel noise cleaning, we introduce CleanNet, a joint neural embedding network,\nwhich only requires a fraction of the classes being manually verified to\nprovide the knowledge of label noise that can be transferred to other classes.\nWe further integrate CleanNet and conventional convolutional neural network\nclassifier into one framework for image classification learning. We demonstrate\nthe effectiveness of the proposed algorithm on both of the label noise\ndetection task and the image classification on noisy data task on several\nlarge-scale datasets. Experimental results show that CleanNet can reduce label\nnoise detection error rate on held-out classes where no human supervision\navailable by 41.5% compared to current weakly supervised methods. It also\nachieves 47% of the performance gain of verifying all images with only 3.2%\nimages verified on an image classification task. Source code and dataset will\nbe available at kuanghuei.github.io/CleanNetProject.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 03:50:53 GMT"}, {"version": "v2", "created": "Sun, 25 Mar 2018 23:07:58 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Lee", "Kuang-Huei", ""], ["He", "Xiaodong", ""], ["Zhang", "Lei", ""], ["Yang", "Linjun", ""]]}, {"id": "1711.07168", "submitter": "Dilin Wang", "authors": "Dilin Wang, Zhe Zeng, Qiang Liu", "title": "Stein Variational Message Passing for Continuous Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel distributed inference algorithm for continuous graphical\nmodels, by extending Stein variational gradient descent (SVGD) to leverage the\nMarkov dependency structure of the distribution of interest. Our approach\ncombines SVGD with a set of structured local kernel functions defined on the\nMarkov blanket of each node, which alleviates the curse of high dimensionality\nand simultaneously yields a distributed algorithm for decentralized inference\ntasks. We justify our method with theoretical analysis and show that the use of\nlocal kernels can be viewed as a new type of localized approximation that\nmatches the target distribution on the conditional distributions of each node\nover its Markov blanket. Our empirical results show that our method outperforms\na variety of baselines including standard MCMC and particle message passing\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 06:25:16 GMT"}, {"version": "v2", "created": "Sun, 18 Feb 2018 05:32:02 GMT"}, {"version": "v3", "created": "Thu, 7 Jun 2018 22:20:13 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Wang", "Dilin", ""], ["Zeng", "Zhe", ""], ["Liu", "Qiang", ""]]}, {"id": "1711.07211", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Daniel M. Kane and Alistair Stewart", "title": "List-Decodable Robust Mean Estimation and Learning Mixtures of Spherical\n  Gaussians", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of list-decodable Gaussian mean estimation and the\nrelated problem of learning mixtures of separated spherical Gaussians. We\ndevelop a set of techniques that yield new efficient algorithms with\nsignificantly improved guarantees for these problems.\n  {\\bf List-Decodable Mean Estimation.} Fix any $d \\in \\mathbb{Z}_+$ and $0<\n\\alpha <1/2$. We design an algorithm with runtime $O\n(\\mathrm{poly}(n/\\alpha)^{d})$ that outputs a list of $O(1/\\alpha)$ many\ncandidate vectors such that with high probability one of the candidates is\nwithin $\\ell_2$-distance $O(\\alpha^{-1/(2d)})$ from the true mean. The only\nprevious algorithm for this problem achieved error $\\tilde O(\\alpha^{-1/2})$\nunder second moment conditions. For $d = O(1/\\epsilon)$, our algorithm runs in\npolynomial time and achieves error $O(\\alpha^{\\epsilon})$. We also give a\nStatistical Query lower bound suggesting that the complexity of our algorithm\nis qualitatively close to best possible.\n  {\\bf Learning Mixtures of Spherical Gaussians.} We give a learning algorithm\nfor mixtures of spherical Gaussians that succeeds under significantly weaker\nseparation assumptions compared to prior work. For the prototypical case of a\nuniform mixture of $k$ identity covariance Gaussians we obtain: For any\n$\\epsilon>0$, if the pairwise separation between the means is at least\n$\\Omega(k^{\\epsilon}+\\sqrt{\\log(1/\\delta)})$, our algorithm learns the unknown\nparameters within accuracy $\\delta$ with sample complexity and running time\n$\\mathrm{poly} (n, 1/\\delta, (k/\\epsilon)^{1/\\epsilon})$. The previously best\nknown polynomial time algorithm required separation at least $k^{1/4}\n\\mathrm{polylog}(k/\\delta)$.\n  Our main technical contribution is a new technique, using degree-$d$\nmultivariate polynomials, to remove outliers from high-dimensional datasets\nwhere the majority of the points are corrupted.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 09:07:08 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Stewart", "Alistair", ""]]}, {"id": "1711.07221", "submitter": "Manish Kesarwani", "authors": "Manish Kesarwani, Bhaskar Mukhoty, Vijay Arya, Sameep Mehta", "title": "Model Extraction Warning in MLaaS Paradigm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud vendors are increasingly offering machine learning services as part of\ntheir platform and services portfolios. These services enable the deployment of\nmachine learning models on the cloud that are offered on a pay-per-query basis\nto application developers and end users. However recent work has shown that the\nhosted models are susceptible to extraction attacks. Adversaries may launch\nqueries to steal the model and compromise future query payments or privacy of\nthe training data. In this work, we present a cloud-based extraction monitor\nthat can quantify the extraction status of models by observing the query and\nresponse streams of both individual and colluding adversarial users. We present\na novel technique that uses information gain to measure the model learning rate\nby users with increasing number of queries. Additionally, we present an\nalternate technique that maintains intelligent query summaries to measure the\nlearning rate relative to the coverage of the input feature space in the\npresence of collusion. Both these approaches have low computational overhead\nand can easily be offered as services to model owners to warn them of possible\nextraction attacks from adversaries. We present performance results for these\napproaches for decision tree models deployed on BigML MLaaS platform, using\nopen source datasets and different adversarial attack strategies.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 09:33:45 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Kesarwani", "Manish", ""], ["Mukhoty", "Bhaskar", ""], ["Arya", "Vijay", ""], ["Mehta", "Sameep", ""]]}, {"id": "1711.07271", "submitter": "Micha\\\"el Fanuel", "authors": "Micha\\\"el Fanuel, Antoine Aspeel, Jean-Charles Delvenne, Johan A.K.\n  Suykens", "title": "Positive semi-definite embedding for dimensionality reduction and\n  out-of-sample extensions", "comments": "16 pages, 5 figures. Improved presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning or statistics, it is often desirable to reduce the\ndimensionality of a sample of data points in a high dimensional space\n$\\mathbb{R}^d$. This paper introduces a dimensionality reduction method where\nthe embedding coordinates are the eigenvectors of a positive semi-definite\nkernel obtained as the solution of an infinite dimensional analogue of a\nsemi-definite program. This embedding is adaptive and non-linear. A main\nfeature of our approach is the existence of a non-linear out-of-sample\nextension formula of the embedding coordinates, called a projected Nystr\\\"om\napproximation. This extrapolation formula yields an extension of the kernel\nmatrix to a data-dependent Mercer kernel function. Our empirical results\nindicate that this embedding method is more robust with respect to the\ninfluence of outliers, compared with a spectral embedding method.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 12:04:37 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 10:02:09 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 13:15:06 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Fanuel", "Micha\u00ebl", ""], ["Aspeel", "Antoine", ""], ["Delvenne", "Jean-Charles", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "1711.07289", "submitter": "Maurice Weiler", "authors": "Maurice Weiler, Fred A. Hamprecht, Martin Storath", "title": "Learning Steerable Filters for Rotation Equivariant CNNs", "comments": "Camera ready version, accepted for CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many machine learning tasks it is desirable that a model's prediction\ntransforms in an equivariant way under transformations of its input.\nConvolutional neural networks (CNNs) implement translational equivariance by\nconstruction; for other transformations, however, they are compelled to learn\nthe proper mapping. In this work, we develop Steerable Filter CNNs (SFCNNs)\nwhich achieve joint equivariance under translations and rotations by design.\nThe proposed architecture employs steerable filters to efficiently compute\norientation dependent responses for many orientations without suffering\ninterpolation artifacts from filter rotation. We utilize group convolutions\nwhich guarantee an equivariant mapping. In addition, we generalize He's weight\ninitialization scheme to filters which are defined as a linear combination of a\nsystem of atomic filters. Numerical experiments show a substantial enhancement\nof the sample complexity with a growing number of sampled filter orientations\nand confirm that the network generalizes learned patterns over orientations.\nThe proposed approach achieves state-of-the-art on the rotated MNIST benchmark\nand on the ISBI 2012 2D EM segmentation challenge.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 12:49:02 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 22:59:29 GMT"}, {"version": "v3", "created": "Mon, 19 Mar 2018 17:10:52 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Weiler", "Maurice", ""], ["Hamprecht", "Fred A.", ""], ["Storath", "Martin", ""]]}, {"id": "1711.07354", "submitter": "Ziming Zhang", "authors": "Ziming Zhang and Matthew Brand", "title": "Convergent Block Coordinate Descent for Training Tikhonov Regularized\n  Deep Neural Networks", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By lifting the ReLU function into a higher dimensional space, we develop a\nsmooth multi-convex formulation for training feed-forward deep neural networks\n(DNNs). This allows us to develop a block coordinate descent (BCD) training\nalgorithm consisting of a sequence of numerically well-behaved convex\noptimizations. Using ideas from proximal point methods in convex analysis, we\nprove that this BCD algorithm will converge globally to a stationary point with\nR-linear convergence rate of order one. In experiments with the MNIST database,\nDNNs trained with this BCD algorithm consistently yielded better test-set error\nrates than identical DNN architectures trained via all the stochastic gradient\ndescent (SGD) variants in the Caffe toolbox.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 15:04:45 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Zhang", "Ziming", ""], ["Brand", "Matthew", ""]]}, {"id": "1711.07356", "submitter": "Vincent B Tjeng", "authors": "Vincent Tjeng, Kai Xiao, Russ Tedrake", "title": "Evaluating Robustness of Neural Networks with Mixed Integer Programming", "comments": "Accepted as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have demonstrated considerable success on a wide variety of\nreal-world problems. However, networks trained only to optimize for training\naccuracy can often be fooled by adversarial examples - slightly perturbed\ninputs that are misclassified with high confidence. Verification of networks\nenables us to gauge their vulnerability to such adversarial examples. We\nformulate verification of piecewise-linear neural networks as a mixed integer\nprogram. On a representative task of finding minimum adversarial distortions,\nour verifier is two to three orders of magnitude quicker than the\nstate-of-the-art. We achieve this computational speedup via tight formulations\nfor non-linearities, as well as a novel presolve algorithm that makes full use\nof all information available. The computational speedup allows us to verify\nproperties on convolutional networks with an order of magnitude more ReLUs than\nnetworks previously verified by any complete verifier. In particular, we\ndetermine for the first time the exact adversarial accuracy of an MNIST\nclassifier to perturbations with bounded $l_\\infty$ norm $\\epsilon=0.1$: for\nthis classifier, we find an adversarial example for 4.38% of samples, and a\ncertificate of robustness (to perturbations with bounded norm) for the\nremainder. Across all robust training procedures and network architectures\nconsidered, we are able to certify more samples than the state-of-the-art and\nfind more adversarial examples than a strong first-order attack.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 15:05:33 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 17:41:34 GMT"}, {"version": "v3", "created": "Mon, 18 Feb 2019 04:39:10 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Tjeng", "Vincent", ""], ["Xiao", "Kai", ""], ["Tedrake", "Russ", ""]]}, {"id": "1711.07364", "submitter": "Jarom\\'ir Janisch", "authors": "Jarom\\'ir Janisch, Tom\\'a\\v{s} Pevn\\'y and Viliam Lis\\'y", "title": "Classification with Costly Features using Deep Reinforcement Learning", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a classification problem where each feature can be acquired for a\ncost and the goal is to optimize a trade-off between the expected\nclassification error and the feature cost. We revisit a former approach that\nhas framed the problem as a sequential decision-making problem and solved it by\nQ-learning with a linear approximation, where individual actions are either\nrequests for feature values or terminate the episode by providing a\nclassification decision. On a set of eight problems, we demonstrate that by\nreplacing the linear approximation with neural networks the approach becomes\ncomparable to the state-of-the-art algorithms developed specifically for this\nproblem. The approach is flexible, as it can be improved with any new\nreinforcement learning enhancement, it allows inclusion of pre-trained\nhigh-performance classifier, and unlike prior art, its performance is robust\nacross all evaluated datasets.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 15:14:29 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 17:09:14 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Janisch", "Jarom\u00edr", ""], ["Pevn\u00fd", "Tom\u00e1\u0161", ""], ["Lis\u00fd", "Viliam", ""]]}, {"id": "1711.07414", "submitter": "Bernease Herman", "authors": "Bernease Herman", "title": "The Promise and Peril of Human Evaluation for Model Interpretability", "comments": "Presented at NIPS 2017 Symposium on Interpretable Machine Learning.\n  I'm not happy with the writing and presentation of these ideas and hope to\n  submit an updated and extended version in 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transparency, user trust, and human comprehension are popular ethical\nmotivations for interpretable machine learning. In support of these goals,\nresearchers evaluate model explanation performance using humans and real world\napplications. This alone presents a challenge in many areas of artificial\nintelligence. In this position paper, we propose a distinction between\ndescriptive and persuasive explanations. We discuss reasoning suggesting that\nfunctional interpretability may be correlated with cognitive function and user\npreferences. If this is indeed the case, evaluation and optimization using\nfunctional metrics could perpetuate implicit cognitive bias in explanations\nthat threaten transparency. Finally, we propose two potential research\ndirections to disambiguate cognitive function and explanation models, retaining\ncontrol over the tradeoff between accuracy and interpretability.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 17:05:11 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 13:01:44 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Herman", "Bernease", ""]]}, {"id": "1711.07425", "submitter": "Kevin Feigelis", "authors": "Kevin T. Feigelis, Blue Sheffer, Daniel L. K. Yamins", "title": "Modular Continual Learning in a Unified Visual Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core aspect of human intelligence is the ability to learn new tasks quickly\nand switch between them flexibly. Here, we describe a modular continual\nreinforcement learning paradigm inspired by these abilities. We first introduce\na visual interaction environment that allows many types of tasks to be unified\nin a single framework. We then describe a reward map prediction scheme that\nlearns new tasks robustly in the very large state and action spaces required by\nsuch an environment. We investigate how properties of module architecture\ninfluence efficiency of task learning, showing that a module motif\nincorporating specific design principles (e.g. early bottlenecks, low-order\npolynomial nonlinearities, and symmetry) significantly outperforms more\nstandard neural network motifs, needing fewer training examples and fewer\nneurons to achieve high levels of performance. Finally, we present a\nmeta-controller architecture for task switching based on a dynamic neural\nvoting scheme, which allows new modules to use information learned from\npreviously-seen tasks to substantially improve their own learning efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 17:31:12 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 04:31:00 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Feigelis", "Kevin T.", ""], ["Sheffer", "Blue", ""], ["Yamins", "Daniel L. K.", ""]]}, {"id": "1711.07433", "submitter": "Taewan Kim", "authors": "Taewan Kim, Joydeep Ghosh", "title": "Relaxed Oracles for Semi-Supervised Clustering", "comments": "NIPS 2017 Workshop: Learning with Limited Labeled Data (LLD 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pairwise \"same-cluster\" queries are one of the most widely used forms of\nsupervision in semi-supervised clustering. However, it is impractical to ask\nhuman oracles to answer every query correctly. In this paper, we study the\ninfluence of allowing \"not-sure\" answers from a weak oracle and propose an\neffective algorithm to handle such uncertainties in query responses. Two\nrealistic weak oracle models are considered where ambiguity in answering\ndepends on the distance between two points. We show that a small query\ncomplexity is adequate for effective clustering with high probability by\nproviding better pairs to the weak oracle. Experimental results on synthetic\nand real data show the effectiveness of our approach in overcoming supervision\nuncertainties and yielding high quality clusters.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 17:40:50 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Kim", "Taewan", ""], ["Ghosh", "Joydeep", ""]]}, {"id": "1711.07437", "submitter": "Guoxu Zhou", "authors": "Yuning Qiu, Guoxu Zhou, Kan Xie", "title": "Deep Approximately Orthogonal Nonnegative Matrix Factorization for\n  Clustering", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative Matrix Factorization (NMF) is a widely used technique for data\nrepresentation. Inspired by the expressive power of deep learning, several NMF\nvariants equipped with deep architectures have been proposed. However, these\nmethods mostly use the only nonnegativity while ignoring task-specific features\nof data. In this paper, we propose a novel deep approximately orthogonal\nnonnegative matrix factorization method where both nonnegativity and\northogonality are imposed with the aim to perform a hierarchical clustering by\nusing different level of abstractions of data. Experiment on two face image\ndatasets showed that the proposed method achieved better clustering performance\nthan other deep matrix factorization methods and state-of-the-art single layer\nNMF variants.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 17:47:25 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Qiu", "Yuning", ""], ["Zhou", "Guoxu", ""], ["Xie", "Kan", ""]]}, {"id": "1711.07440", "submitter": "Weijia Chen", "authors": "Weijia Chen, Yuedong Xu, Xiaofeng Wu", "title": "Deep Reinforcement Learning for Multi-Resource Multi-Machine Job\n  Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimizing job scheduling time is a fundamental issue in data center networks\nthat has been extensively studied in recent years. The incoming jobs require\ndifferent CPU and memory units, and span different number of time slots. The\ntraditional solution is to design efficient heuristic algorithms with\nperformance guarantee under certain assumptions. In this paper, we improve a\nrecently proposed job scheduling algorithm using deep reinforcement learning\nand extend it to multiple server clusters. Our study reveals that deep\nreinforcement learning method has the potential to outperform traditional\nresource allocation algorithms in a variety of complicated environments.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 17:50:54 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Chen", "Weijia", ""], ["Xu", "Yuedong", ""], ["Wu", "Xiaofeng", ""]]}, {"id": "1711.07441", "submitter": "Kejun Huang", "authors": "Kejun Huang, Xiao Fu, Nicholas D. Sidiropoulos", "title": "On Convergence of Epanechnikov Mean Shift", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epanechnikov Mean Shift is a simple yet empirically very effective algorithm\nfor clustering. It localizes the centroids of data clusters via estimating\nmodes of the probability distribution that generates the data points, using the\n`optimal' Epanechnikov kernel density estimator. However, since the procedure\ninvolves non-smooth kernel density functions, the convergence behavior of\nEpanechnikov mean shift lacks theoretical support as of this writing---most of\nthe existing analyses are based on smooth functions and thus cannot be applied\nto Epanechnikov Mean Shift. In this work, we first show that the original\nEpanechnikov Mean Shift may indeed terminate at a non-critical point, due to\nthe non-smoothness nature. Based on our analysis, we propose a simple remedy to\nfix it. The modified Epanechnikov Mean Shift is guaranteed to terminate at a\nlocal maximum of the estimated density, which corresponds to a cluster\ncentroid, within a finite number of iterations. We also propose a way to avoid\nrunning the Mean Shift iterates from every data point, while maintaining good\nclustering accuracies under non-overlapping spherical Gaussian mixture models.\nThis further pushes Epanechnikov Mean Shift to handle very large and\nhigh-dimensional data sets. Experiments show surprisingly good performance\ncompared to the Lloyd's K-means algorithm and the EM algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 17:51:01 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Huang", "Kejun", ""], ["Fu", "Xiao", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "1711.07459", "submitter": "Alexander Wong", "authors": "Mohammad Javad Shafiee, Francis Li, Brendan Chwyl, and Alexander Wong", "title": "SquishedNets: Squishing SqueezeNet further for edge device scenarios via\n  deep evolutionary synthesis", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks have been shown in recent years to outperform\nother machine learning methods in a wide range of applications, one of the\nbiggest challenges with enabling deep neural networks for widespread deployment\non edge devices such as mobile and other consumer devices is high computational\nand memory requirements. Recently, there has been greater exploration into\nsmall deep neural network architectures that are more suitable for edge\ndevices, with one of the most popular architectures being SqueezeNet, with an\nincredibly small model size of 4.8MB. Taking further advantage of the notion\nthat many applications of machine learning on edge devices are often\ncharacterized by a low number of target classes, this study explores the\nutility of combining architectural modifications and an evolutionary synthesis\nstrategy for synthesizing even smaller deep neural architectures based on the\nmore recent SqueezeNet v1.1 macroarchitecture for applications with fewer\ntarget classes. In particular, architectural modifications are first made to\nSqueezeNet v1.1 to accommodate for a 10-class ImageNet-10 dataset, and then an\nevolutionary synthesis strategy is leveraged to synthesize more efficient deep\nneural networks based on this modified macroarchitecture. The resulting\nSquishedNets possess model sizes ranging from 2.4MB to 0.95MB (~5.17X smaller\nthan SqueezeNet v1.1, or 253X smaller than AlexNet). Furthermore, the\nSquishedNets are still able to achieve accuracies ranging from 81.2% to 77%,\nand able to process at speeds of 156 images/sec to as much as 256 images/sec on\na Nvidia Jetson TX1 embedded chip. These preliminary results show that a\ncombination of architectural modifications and an evolutionary synthesis\nstrategy can be a useful tool for producing very small deep neural network\narchitectures that are well-suited for edge device scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 18:50:05 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Shafiee", "Mohammad Javad", ""], ["Li", "Francis", ""], ["Chwyl", "Brendan", ""], ["Wong", "Alexander", ""]]}, {"id": "1711.07461", "submitter": "Ayush Jaiswal", "authors": "Ayush Jaiswal, Wael AbdAlmageed, Yue Wu, Premkumar Natarajan", "title": "Bidirectional Conditional Generative Adversarial Networks", "comments": "To appear in Proceedings of ACCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Generative Adversarial Networks (cGANs) are generative models\nthat can produce data samples ($x$) conditioned on both latent variables ($z$)\nand known auxiliary information ($c$). We propose the Bidirectional cGAN\n(BiCoGAN), which effectively disentangles $z$ and $c$ in the generation process\nand provides an encoder that learns inverse mappings from $x$ to both $z$ and\n$c$, trained jointly with the generator and the discriminator. We present\ncrucial techniques for training BiCoGANs, which involve an extrinsic factor\nloss along with an associated dynamically-tuned importance weight. As compared\nto other encoder-based cGANs, BiCoGANs encode $c$ more accurately, and utilize\n$z$ and $c$ more effectively and in a more disentangled way to generate\nsamples.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 18:54:05 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 01:23:01 GMT"}, {"version": "v3", "created": "Sat, 27 Oct 2018 07:42:44 GMT"}, {"version": "v4", "created": "Sat, 3 Nov 2018 23:03:07 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Jaiswal", "Ayush", ""], ["AbdAlmageed", "Wael", ""], ["Wu", "Yue", ""], ["Natarajan", "Premkumar", ""]]}, {"id": "1711.07465", "submitter": "Pravesh K Kothari", "authors": "Pravesh K. Kothari and Jacob Steinhardt", "title": "Better Agnostic Clustering Via Relaxed Tensor Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new family of convex relaxations for $k$-means clustering based\non sum-of-squares norms, a relaxation of the injective tensor norm that is\nefficiently computable using the Sum-of-Squares algorithm. We give an algorithm\nbased on this relaxation that recovers a faithful approximation to the true\nmeans in the given data whenever the low-degree moments of the points in each\ncluster have bounded sum-of-squares norms.\n  We then prove a sharp upper bound on the sum-of-squares norms for moment\ntensors of any distribution that satisfies the \\emph{Poincare inequality}. The\nPoincare inequality is a central inequality in probability theory, and a large\nclass of distributions satisfy it including Gaussians, product distributions,\nstrongly log-concave distributions, and any sum or uniformly continuous\ntransformation of such distributions.\n  As an immediate corollary, for any $\\gamma > 0$, we obtain an efficient\nalgorithm for learning the means of a mixture of $k$ arbitrary \\Poincare\ndistributions in $\\mathbb{R}^d$ in time $d^{O(1/\\gamma)}$ so long as the means\nhave separation $\\Omega(k^{\\gamma})$. This in particular yields an algorithm\nfor learning Gaussian mixtures with separation $\\Omega(k^{\\gamma})$, thus\npartially resolving an open problem of Regev and Vijayaraghavan\n\\citet{regev2017learning}.\n  Our algorithm works even in the outlier-robust setting where an $\\epsilon$\nfraction of arbitrary outliers are added to the data, as long as the fraction\nof outliers is smaller than the smallest cluster. We, therefore, obtain results\nin the strong agnostic setting where, in addition to not knowing the\ndistribution family, the data itself may be arbitrarily corrupted.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 18:56:40 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Kothari", "Pravesh K.", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "1711.07468", "submitter": "Daniel George", "authors": "Daniel George, Hongyu Shen, E. A. Huerta", "title": "Glitch Classification and Clustering for LIGO with Deep Transfer\n  Learning", "comments": "Camera-ready (final) paper accepted to NIPS 2017 conference workshop\n  on Deep Learning for Physical Sciences. Extended article: arXiv:1706.07446", "journal-ref": "Phys. Rev. D 97, 101501 (2018)", "doi": "10.1103/PhysRevD.97.101501", "report-no": null, "categories": "astro-ph.IM cs.LG gr-qc stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of gravitational waves with LIGO and Virgo requires a detailed\nunderstanding of the response of these instruments in the presence of\nenvironmental and instrumental noise. Of particular interest is the study of\nanomalous non-Gaussian noise transients known as glitches, since their high\noccurrence rate in LIGO/Virgo data can obscure or even mimic true gravitational\nwave signals. Therefore, successfully identifying and excising glitches is of\nutmost importance to detect and characterize gravitational waves. In this\narticle, we present the first application of Deep Learning combined with\nTransfer Learning for glitch classification, using real data from LIGO's first\ndiscovery campaign labeled by Gravity Spy, showing that knowledge from\npre-trained models for real-world object recognition can be transferred for\nclassifying spectrograms of glitches. We demonstrate that this method enables\nthe optimal use of very deep convolutional neural networks for glitch\nclassification given small unbalanced training datasets, significantly reduces\nthe training time, and achieves state-of-the-art accuracy above 98.8%. Once\ntrained via transfer learning, we show that the networks can be truncated and\nused as feature extractors for unsupervised clustering to automatically group\ntogether new classes of glitches and anomalies. This novel capability is of\ncritical importance to identify and remove new types of glitches which will\noccur as the LIGO/Virgo detectors gradually attain design sensitivity.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 18:58:28 GMT"}, {"version": "v2", "created": "Mon, 11 Dec 2017 18:11:34 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["George", "Daniel", ""], ["Shen", "Hongyu", ""], ["Huerta", "E. A.", ""]]}, {"id": "1711.07476", "submitter": "Saki Shinoda", "authors": "Saki Shinoda, Daniel E. Worrall, Gabriel J. Brostow", "title": "Virtual Adversarial Ladder Networks For Semi-supervised Learning", "comments": "Camera-ready version for NIPS 2017 workshop Learning with Limited\n  Labeled Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning (SSL) partially circumvents the high cost of\nlabeling data by augmenting a small labeled dataset with a large and relatively\ncheap unlabeled dataset drawn from the same distribution. This paper offers a\nnovel interpretation of two deep learning-based SSL approaches, ladder networks\nand virtual adversarial training (VAT), as applying distributional smoothing to\ntheir respective latent spaces. We propose a class of models that fuse these\napproaches. We achieve near-supervised accuracy with high consistency on the\nMNIST dataset using just 5 labels per class: our best model, ladder with\nlayer-wise virtual adversarial noise (LVAN-LW), achieves 1.42% +/- 0.12 average\nerror rate on the MNIST test set, in comparison with 1.62% +/- 0.65 reported\nfor the ladder network. On adversarial examples generated with L2-normalized\nfast gradient method, LVAN-LW trained with 5 examples per class achieves\naverage error rate 2.4% +/- 0.3 compared to 68.6% +/- 6.5 for the ladder\nnetwork and 9.9% +/- 7.5 for VAT.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 11:10:40 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 11:23:01 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Shinoda", "Saki", ""], ["Worrall", "Daniel E.", ""], ["Brostow", "Gabriel J.", ""]]}, {"id": "1711.07478", "submitter": "Melrose Roderick", "authors": "Melrose Roderick, James MacGlashan, Stefanie Tellex", "title": "Implementing the Deep Q-Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Deep Q-Network proposed by Mnih et al. [2015] has become a benchmark and\nbuilding point for much deep reinforcement learning research. However,\nreplicating results for complex systems is often challenging since original\nscientific publications are not always able to describe in detail every\nimportant parameter setting and software engineering solution. In this paper,\nwe present results from our work reproducing the results of the DQN paper. We\nhighlight key areas in the implementation that were not covered in great detail\nin the original paper to make it easier for researchers to replicate these\nresults, including termination conditions and gradient descent algorithms.\nFinally, we discuss methods for improving the computational performance and\nprovide our own implementation that is designed to work with a range of\ndomains, and not just the original Arcade Learning Environment [Bellemare et\nal., 2013].\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 16:40:33 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Roderick", "Melrose", ""], ["MacGlashan", "James", ""], ["Tellex", "Stefanie", ""]]}, {"id": "1711.07479", "submitter": "Gino Brunner", "authors": "Gino Brunner, Oliver Richter, Yuyi Wang, Roger Wattenhofer", "title": "Teaching a Machine to Read Maps with Deep Reinforcement Learning", "comments": "Paper accepted at 32nd AAAI Conference on Artificial Intelligence,\n  AAAI 2018, New Orleans, Louisiana, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to use a 2D map to navigate a complex 3D environment is quite\nremarkable, and even difficult for many humans. Localization and navigation is\nalso an important problem in domains such as robotics, and has recently become\na focus of the deep reinforcement learning community. In this paper we teach a\nreinforcement learning agent to read a map in order to find the shortest way\nout of a random maze it has never seen before. Our system combines several\nstate-of-the-art methods such as A3C and incorporates novel elements such as a\nrecurrent localization cell. Our agent learns to localize itself based on 3D\nfirst person images and an approximate orientation angle. The agent generalizes\nwell to bigger mazes, showing that it learned useful localization and\nnavigation capabilities.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 16:45:58 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Brunner", "Gino", ""], ["Richter", "Oliver", ""], ["Wang", "Yuyi", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "1711.07511", "submitter": "Matthew Norton", "authors": "Matthew Norton and Akiko Takeda and Alexander Mafusalov", "title": "Optimistic Robust Optimization With Applications To Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust Optimization has traditionally taken a pessimistic, or worst-case\nviewpoint of uncertainty which is motivated by a desire to find sets of optimal\npolicies that maintain feasibility under a variety of operating conditions. In\nthis paper, we explore an optimistic, or best-case view of uncertainty and show\nthat it can be a fruitful approach. We show that these techniques can be used\nto address a wide variety of problems. First, we apply our methods in the\ncontext of robust linear programming, providing a method for reducing\nconservatism in intuitive ways that encode economically realistic modeling\nassumptions. Second, we look at problems in machine learning and find that this\napproach is strongly connected to the existing literature. Specifically, we\nprovide a new interpretation for popular sparsity inducing non-convex\nregularization schemes. Additionally, we show that successful approaches for\ndealing with outliers and noise can be interpreted as optimistic robust\noptimization problems. Although many of the problems resulting from our\napproach are non-convex, we find that DCA or DCA-like optimization approaches\ncan be intuitive and efficient.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 19:39:48 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Norton", "Matthew", ""], ["Takeda", "Akiko", ""], ["Mafusalov", "Alexander", ""]]}, {"id": "1711.07553", "submitter": "Xavier Bresson", "authors": "Xavier Bresson and Thomas Laurent", "title": "Residual Gated Graph ConvNets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-structured data such as social networks, functional brain networks,\ngene regulatory networks, communications networks have brought the interest in\ngeneralizing deep learning techniques to graph domains. In this paper, we are\ninterested to design neural networks for graphs with variable length in order\nto solve learning problems such as vertex classification, graph classification,\ngraph regression, and graph generative tasks. Most existing works have focused\non recurrent neural networks (RNNs) to learn meaningful representations of\ngraphs, and more recently new convolutional neural networks (ConvNets) have\nbeen introduced. In this work, we want to compare rigorously these two\nfundamental families of architectures to solve graph learning tasks. We review\nexisting graph RNN and ConvNet architectures, and propose natural extension of\nLSTM and ConvNet to graphs with arbitrary size. Then, we design a set of\nanalytically controlled experiments on two basic graph problems, i.e. subgraph\nmatching and graph clustering, to test the different architectures. Numerical\nresults show that the proposed graph ConvNets are 3-17% more accurate and\n1.5-4x faster than graph RNNs. Graph ConvNets are also 36% more accurate than\nvariational (non-learning) techniques. Finally, the most effective graph\nConvNet architecture uses gated edges and residuality. Residuality plays an\nessential role to learn multi-layer architectures as they provide a 10% gain of\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 21:28:40 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 08:19:32 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Bresson", "Xavier", ""], ["Laurent", "Thomas", ""]]}, {"id": "1711.07566", "submitter": "Hiroharu Kato", "authors": "Hiroharu Kato, Yoshitaka Ushiku, Tatsuya Harada", "title": "Neural 3D Mesh Renderer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For modeling the 3D world behind 2D images, which 3D representation is most\nappropriate? A polygon mesh is a promising candidate for its compactness and\ngeometric properties. However, it is not straightforward to model a polygon\nmesh from 2D images using neural networks because the conversion from a mesh to\nan image, or rendering, involves a discrete operation called rasterization,\nwhich prevents back-propagation. Therefore, in this work, we propose an\napproximate gradient for rasterization that enables the integration of\nrendering into neural networks. Using this renderer, we perform single-image 3D\nmesh reconstruction with silhouette image supervision and our system\noutperforms the existing voxel-based approach. Additionally, we perform\ngradient-based 3D mesh editing operations, such as 2D-to-3D style transfer and\n3D DeepDream, with 2D supervision for the first time. These applications\ndemonstrate the potential of the integration of a mesh renderer into neural\nnetworks and the effectiveness of our proposed renderer.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 22:12:23 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Kato", "Hiroharu", ""], ["Ushiku", "Yoshitaka", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1711.07575", "submitter": "Ronak Mehta", "authors": "Ronak Mehta, Hyunwoo J. Kim, Shulei Wang, Sterling C. Johnson, Ming\n  Yuan, Vikas Singh", "title": "Finding Differentially Covarying Needles in a Temporally Evolving\n  Haystack: A Scan Statistics Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent results in coupled or temporal graphical models offer schemes for\nestimating the relationship structure between features when the data come from\nrelated (but distinct) longitudinal sources. A novel application of these ideas\nis for analyzing group-level differences, i.e., in identifying if trends of\nestimated objects (e.g., covariance or precision matrices) are different across\ndisparate conditions (e.g., gender or disease). Often, poor effect sizes make\ndetecting the differential signal over the full set of features difficult: for\nexample, dependencies between only a subset of features may manifest\ndifferently across groups. In this work, we first give a parametric model for\nestimating trends in the space of SPD matrices as a function of one or more\ncovariates. We then generalize scan statistics to graph structures, to search\nover distinct subsets of features (graph partitions) whose temporal dependency\nstructure may show statistically significant group-wise differences. We\ntheoretically analyze the Family Wise Error Rate (FWER) and bounds on Type 1\nand Type 2 error. On a cohort of individuals with risk factors for Alzheimer's\ndisease (but otherwise cognitively healthy), we find scientifically interesting\ngroup differences where the default analysis, i.e., models estimated on the\nfull graph, do not survive reasonable significance thresholds.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 23:14:20 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Mehta", "Ronak", ""], ["Kim", "Hyunwoo J.", ""], ["Wang", "Shulei", ""], ["Johnson", "Sterling C.", ""], ["Yuan", "Ming", ""], ["Singh", "Vikas", ""]]}, {"id": "1711.07601", "submitter": "Jure Leskovec", "authors": "Chantat Eksombatchai, Pranav Jindal, Jerry Zitao Liu, Yuchen Liu,\n  Rahul Sharma, Charles Sugnet, Mark Ulrich, Jure Leskovec", "title": "Pixie: A System for Recommending 3+ Billion Items to 200+ Million Users\n  in Real-Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.PF cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User experience in modern content discovery applications critically depends\non high-quality personalized recommendations. However, building systems that\nprovide such recommendations presents a major challenge due to a massive pool\nof items, a large number of users, and requirements for recommendations to be\nresponsive to user actions and generated on demand in real-time. Here we\npresent Pixie, a scalable graph-based real-time recommender system that we\ndeveloped and deployed at Pinterest. Given a set of user-specific pins as a\nquery, Pixie selects in real-time from billions of possible pins those that are\nmost related to the query. To generate recommendations, we develop Pixie Random\nWalk algorithm that utilizes the Pinterest object graph of 3 billion nodes and\n17 billion edges. Experiments show that recommendations provided by Pixie lead\nup to 50% higher user engagement when compared to the previous Hadoop-based\nproduction system. Furthermore, we develop a graph pruning strategy at that\nleads to an additional 58% improvement in recommendations. Last, we discuss\nsystem aspects of Pixie, where a single server executes 1,200 recommendation\nrequests per second with 60 millisecond latency. Today, systems backed by Pixie\ncontribute to more than 80% of all user engagement on Pinterest.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 01:51:35 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Eksombatchai", "Chantat", ""], ["Jindal", "Pranav", ""], ["Liu", "Jerry Zitao", ""], ["Liu", "Yuchen", ""], ["Sharma", "Rahul", ""], ["Sugnet", "Charles", ""], ["Ulrich", "Mark", ""], ["Leskovec", "Jure", ""]]}, {"id": "1711.07632", "submitter": "Xiaopeng Yang", "authors": "Xiaopeng Yang, Xiaowen Lin, Shunda Suo, and Ming Li", "title": "Generating Thematic Chinese Poetry using Conditional Variational\n  Autoencoders with Hybrid Decoders", "comments": "Accepted by IJCAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer poetry generation is our first step towards computer writing.\nWriting must have a theme. The current approaches of using sequence-to-sequence\nmodels with attention often produce non-thematic poems. We present a novel\nconditional variational autoencoder with a hybrid decoder adding the\ndeconvolutional neural networks to the general recurrent neural networks to\nfully learn topic information via latent variables. This approach significantly\nimproves the relevance of the generated poems by representing each line of the\npoem not only in a context-sensitive manner but also in a holistic way that is\nhighly related to the given keyword and the learned topic. A proposed augmented\nword2vec model further improves the rhythm and symmetry. Tests show that the\ngenerated poems by our approach are mostly satisfying with regulated rules and\nconsistent themes, and 73.42% of them receive an Overall score no less than 3\n(the highest score is 5).\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 04:40:38 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 22:05:22 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 15:52:12 GMT"}, {"version": "v4", "created": "Thu, 5 Mar 2020 15:39:39 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Yang", "Xiaopeng", ""], ["Lin", "Xiaowen", ""], ["Suo", "Shunda", ""], ["Li", "Ming", ""]]}, {"id": "1711.07638", "submitter": "Jia-Yun Jiang", "authors": "Jia-Yun Jiang, Cheng-Te Li, Shou-De Lin", "title": "Towards a More Reliable Privacy-preserving Recommender System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a privacy-preserving distributed recommendation\nframework, Secure Distributed Collaborative Filtering (SDCF), to preserve the\nprivacy of value, model and existence altogether. That says, not only the\nratings from the users to the items, but also the existence of the ratings as\nwell as the learned recommendation model are kept private in our framework. Our\nsolution relies on a distributed client-server architecture and a two-stage\nRandomized Response algorithm, along with an implementation on the popular\nrecommendation model, Matrix Factorization (MF). We further prove SDCF to meet\nthe guarantee of Differential Privacy so that clients are allowed to specify\narbitrary privacy levels. Experiments conducted on numerical rating prediction\nand one-class rating action prediction exhibit that SDCF does not sacrifice too\nmuch accuracy for privacy.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 05:32:09 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 12:27:59 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Jiang", "Jia-Yun", ""], ["Li", "Cheng-Te", ""], ["Lin", "Shou-De", ""]]}, {"id": "1711.07655", "submitter": "Eli (Omid) David", "authors": "Eli David, Iddo Greental", "title": "Genetic Algorithms for Evolving Deep Neural Networks", "comments": null, "journal-ref": "ACM Genetic and Evolutionary Computation Conference (GECCO), pages\n  1451-1452, Vancouver, Canada, July 2014", "doi": "10.1145/2598394.2602287", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning methods applying unsupervised learning to\ntrain deep layers of neural networks have achieved remarkable results in\nnumerous fields. In the past, many genetic algorithms based methods have been\nsuccessfully applied to training neural networks. In this paper, we extend\nprevious work and propose a GA-assisted method for deep learning. Our\nexperimental results indicate that this GA-assisted approach improves the\nperformance of a deep autoencoder, producing a sparser neural network.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 07:23:32 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["David", "Eli", ""], ["Greental", "Iddo", ""]]}, {"id": "1711.07661", "submitter": "Dalin Zhang", "authors": "Kaixuan Chen, Lina Yao, Tao Gu, Zhiwen Yu, Xianzhi Wang, Dalin Zhang", "title": "Fullie and Wiselie: A Dual-Stream Recurrent Convolutional Attention\n  Model for Activity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal features play a key role in wearable sensor based Human Activity\nRecognition (HAR). Selecting the most salient features adaptively is a\npromising way to maximize the effectiveness of multimodal sensor data. In this\nregard, we propose a \"collect fully and select wisely (Fullie and Wiselie)\"\nprinciple as well as a dual-stream recurrent convolutional attention model,\nRecurrent Attention and Activity Frame (RAAF), to improve the recognition\nperformance. We first collect modality features and the relations between each\npair of features to generate activity frames, and then introduce an attention\nmechanism to select the most prominent regions from activity frames precisely.\nThe selected frames not only maximize the utilization of valid features but\nalso reduce the number of features to be computed effectively. We further\nanalyze the hyper-parameters, accuracy, interpretability, and annotation\ndependency of the proposed model based on extensive experiments. The results\nshow that RAAF achieves competitive performance on two benchmarked datasets and\nworks well in real life scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 07:42:32 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Chen", "Kaixuan", ""], ["Yao", "Lina", ""], ["Gu", "Tao", ""], ["Yu", "Zhiwen", ""], ["Wang", "Xianzhi", ""], ["Zhang", "Dalin", ""]]}, {"id": "1711.07676", "submitter": "Ashley Edwards", "authors": "Ashley D. Edwards, Charles L. Isbell Jr", "title": "Transferring Agent Behaviors from Videos via Motion GANs", "comments": "Deep Reinforcement Learning Symposium, NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major bottleneck for developing general reinforcement learning agents is\ndetermining rewards that will yield desirable behaviors under various\ncircumstances. We introduce a general mechanism for automatically specifying\nmeaningful behaviors from raw pixels. In particular, we train a generative\nadversarial network to produce short sub-goals represented through motion\ntemplates. We demonstrate that this approach generates visually meaningful\nbehaviors in unknown environments with novel agents and describe how these\nmotions can be used to train reinforcement learning agents.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 08:51:31 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Edwards", "Ashley D.", ""], ["Isbell", "Charles L.", "Jr"]]}, {"id": "1711.07682", "submitter": "Gino Brunner", "authors": "Gino Brunner, Yuyi Wang, Roger Wattenhofer, Jonas Wiesendanger", "title": "JamBot: Music Theory Aware Chord Based Generation of Polyphonic Music\n  with LSTMs", "comments": "Paper presented at the 29th International Conference on Tools with\n  Artificial Intelligence, ICTAI 2017, Boston, MA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.IT cs.LG eess.AS math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for the generation of polyphonic music based on\nLSTMs. We generate music in two steps. First, a chord LSTM predicts a chord\nprogression based on a chord embedding. A second LSTM then generates polyphonic\nmusic from the predicted chord progression. The generated music sounds pleasing\nand harmonic, with only few dissonant notes. It has clear long-term structure\nthat is similar to what a musician would play during a jam session. We show\nthat our approach is sensible from a music theory perspective by evaluating the\nlearned chord embeddings. Surprisingly, our simple model managed to extract the\ncircle of fifths, an important tool in music theory, from the dataset.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 09:19:16 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Brunner", "Gino", ""], ["Wang", "Yuyi", ""], ["Wattenhofer", "Roger", ""], ["Wiesendanger", "Jonas", ""]]}, {"id": "1711.07684", "submitter": "Mukul Bhutani", "authors": "Mukul Bhutani and Bamdev Mishra", "title": "A two-dimensional decomposition approach for matrix completion through\n  gossip", "comments": "Appeared in the Emergent Communication Workshop at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factoring a matrix into two low rank matrices is at the heart of many\nproblems. The problem of matrix completion especially uses it to decompose a\nsparse matrix into two non sparse, low rank matrices which can then be used to\npredict unknown entries of the original matrix. We present a scalable and\ndecentralized approach in which instead of learning two factors for the\noriginal input matrix, we decompose the original matrix into a grid blocks,\neach of whose factors can be individually learned just by communicating\n(gossiping) with neighboring blocks. This eliminates any need for a central\nserver. We show that our algorithm performs well on both synthetic and real\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 09:21:13 GMT"}, {"version": "v2", "created": "Thu, 11 Jan 2018 12:41:33 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Bhutani", "Mukul", ""], ["Mishra", "Bamdev", ""]]}, {"id": "1711.07693", "submitter": "Wataru Kumagai", "authors": "Wataru Kumagai", "title": "Regret Analysis for Continuous Dueling Bandit", "comments": "14 pages. This paper was accepted at NIPS 2017 as a spotlight\n  presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dueling bandit is a learning framework wherein the feedback information\nin the learning process is restricted to a noisy comparison between a pair of\nactions. In this research, we address a dueling bandit problem based on a cost\nfunction over a continuous space. We propose a stochastic mirror descent\nalgorithm and show that the algorithm achieves an $O(\\sqrt{T\\log T})$-regret\nbound under strong convexity and smoothness assumptions for the cost function.\nSubsequently, we clarify the equivalence between regret minimization in dueling\nbandit and convex optimization for the cost function. Moreover, when\nconsidering a lower bound in convex optimization, our algorithm is shown to\nachieve the optimal convergence rate in convex optimization and the optimal\nregret in dueling bandit except for a logarithmic factor.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 09:58:00 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 07:32:36 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Kumagai", "Wataru", ""]]}, {"id": "1711.07724", "submitter": "Evgeniy Golikov", "authors": "Eugene Golikov, Vlad Zhukov, Maksim Kretov", "title": "Using stochastic computation graphs formalism for optimization of\n  sequence-to-sequence model", "comments": "Presented at 10th NIPS Workshop on Optimization for Machine Learning\n  (NIPS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variety of machine learning problems can be formulated as an optimization\ntask for some (surrogate) loss function. Calculation of loss function can be\nviewed in terms of stochastic computation graphs (SCG). We use this formalism\nto analyze a problem of optimization of famous sequence-to-sequence model with\nattention and propose reformulation of the task. Examples are given for machine\ntranslation (MT). Our work provides a unified view on different optimization\napproaches for sequence-to-sequence models and could help researchers in\ndeveloping new network architectures with embedded stochastic nodes.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 11:29:44 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 14:48:16 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Golikov", "Eugene", ""], ["Zhukov", "Vlad", ""], ["Kretov", "Maksim", ""]]}, {"id": "1711.07732", "submitter": "Zuozhu Liu", "authors": "Zuozhu Liu, Tony Q.S. Quek, Shaowei Lin", "title": "Variational Probability Flow for Biologically Plausible Training of Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quest for biologically plausible deep learning is driven, not just by the\ndesire to explain experimentally-observed properties of biological neural\nnetworks, but also by the hope of discovering more efficient methods for\ntraining artificial networks. In this paper, we propose a new algorithm named\nVariational Probably Flow (VPF), an extension of minimum probability flow for\ntraining binary Deep Boltzmann Machines (DBMs). We show that weight updates in\nVPF are local, depending only on the states and firing rates of the adjacent\nneurons. Unlike contrastive divergence, there is no need for Gibbs\nconfabulations; and unlike backpropagation, alternating feedforward and\nfeedback phases are not required. Moreover, the learning algorithm is effective\nfor training DBMs with intra-layer connections between the hidden nodes.\nExperiments with MNIST and Fashion MNIST demonstrate that VPF learns reasonable\nfeatures quickly, reconstructs corrupted images more accurately, and generates\nsamples with a high estimated log-likelihood. Lastly, we note that,\ninterestingly, if an asymmetric version of VPF exists, the weight updates\ndirectly explain experimental results in Spike-Timing-Dependent Plasticity\n(STDP).\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 11:49:05 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Liu", "Zuozhu", ""], ["Quek", "Tony Q. S.", ""], ["Lin", "Shaowei", ""]]}, {"id": "1711.07758", "submitter": "Guanhua Zheng", "authors": "Guanhua Zheng, Jitao Sang, Changsheng Xu", "title": "Understanding Deep Learning Generalization by Maximum Entropy", "comments": "13 pages,2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning achieves remarkable generalization capability with overwhelming\nnumber of model parameters. Theoretical understanding of deep learning\ngeneralization receives recent attention yet remains not fully explored. This\npaper attempts to provide an alternative understanding from the perspective of\nmaximum entropy. We first derive two feature conditions that softmax regression\nstrictly apply maximum entropy principle. DNN is then regarded as approximating\nthe feature conditions with multilayer feature learning, and proved to be a\nrecursive solution towards maximum entropy principle. The connection between\nDNN and maximum entropy well explains why typical designs such as shortcut and\nregularization improves model generalization, and provides instructions for\nfuture model development.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 13:03:12 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Zheng", "Guanhua", ""], ["Sang", "Jitao", ""], ["Xu", "Changsheng", ""]]}, {"id": "1711.07784", "submitter": "Davide Bacciu", "authors": "Davide Bacciu", "title": "Hidden Tree Markov Networks: Deep and Wide Learning for Structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces the Hidden Tree Markov Network (HTN), a\nneuro-probabilistic hybrid fusing the representation power of generative models\nfor trees with the incremental and discriminative learning capabilities of\nneural networks. We put forward a modular architecture in which multiple\ngenerative models of limited complexity are trained to learn structural feature\ndetectors whose outputs are then combined and integrated by neural layers at a\nlater stage. In this respect, the model is both deep, thanks to the unfolding\nof the generative models on the input structures, as well as wide, given the\npotentially large number of generative modules that can be trained in parallel.\nExperimental results show that the proposed approach can outperform\nstate-of-the-art syntactic kernels as well as generative kernels built on the\nsame probabilistic model as the HTN.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 13:50:34 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Bacciu", "Davide", ""]]}, {"id": "1711.07792", "submitter": "Kay Gregor Hartmann", "authors": "Kay Gregor Hartmann, Robin Tibor Schirrmeister, Tonio Ball", "title": "Hierarchical internal representation of spectral features in deep\n  convolutional networks trained for EEG decoding", "comments": "6 pages, 7 figures, The 6th International Winter Conference on\n  Brain-Computer Interface", "journal-ref": null, "doi": "10.1109/IWW-BCI.2018.8311493", "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there is increasing interest and research on the interpretability\nof machine learning models, for example how they transform and internally\nrepresent EEG signals in Brain-Computer Interface (BCI) applications. This can\nhelp to understand the limits of the model and how it may be improved, in\naddition to possibly provide insight about the data itself. Schirrmeister et\nal. (2017) have recently reported promising results for EEG decoding with deep\nconvolutional neural networks (ConvNets) trained in an end-to-end manner and,\nwith a causal visualization approach, showed that they learn to use spectral\namplitude changes in the input. In this study, we investigate how ConvNets\nrepresent spectral features through the sequence of intermediate stages of the\nnetwork. We show higher sensitivity to EEG phase features at earlier stages and\nhigher sensitivity to EEG amplitude features at later stages. Intriguingly, we\nobserved a specialization of individual stages of the network to the classical\nEEG frequency bands alpha, beta, and high gamma. Furthermore, we find first\nevidence that particularly in the last convolutional layer, the network learns\nto detect more complex oscillatory patterns beyond spectral phase and\namplitude, reminiscent of the representation of complex visual features in\nlater layers of ConvNets in computer vision tasks. Our findings thus provide\ninsights into how ConvNets hierarchically represent spectral EEG features in\ntheir intermediate layers and suggest that ConvNets can exploit and might help\nto better understand the compositional structure of EEG time series.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 14:05:25 GMT"}, {"version": "v2", "created": "Thu, 23 Nov 2017 18:12:03 GMT"}, {"version": "v3", "created": "Fri, 15 Dec 2017 16:29:12 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Hartmann", "Kay Gregor", ""], ["Schirrmeister", "Robin Tibor", ""], ["Ball", "Tonio", ""]]}, {"id": "1711.07831", "submitter": "Abien Fred Agarap", "authors": "Abien Fred Agarap", "title": "On Breast Cancer Detection: An Application of Machine Learning\n  Algorithms on the Wisconsin Diagnostic Dataset", "comments": "5 pages, 5 figures, 2 tables, presented at the International\n  Conference on Machine Learning and Soft Computing (ICMLSC) 2018 in Phu Quoc\n  Island, Viet Nam", "journal-ref": null, "doi": "10.1145/3184066.3184080", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a comparison of six machine learning (ML) algorithms:\nGRU-SVM (Agarap, 2017), Linear Regression, Multilayer Perceptron (MLP), Nearest\nNeighbor (NN) search, Softmax Regression, and Support Vector Machine (SVM) on\nthe Wisconsin Diagnostic Breast Cancer (WDBC) dataset (Wolberg, Street, &\nMangasarian, 1992) by measuring their classification test accuracy and their\nsensitivity and specificity values. The said dataset consists of features which\nwere computed from digitized images of FNA tests on a breast mass (Wolberg,\nStreet, & Mangasarian, 1992). For the implementation of the ML algorithms, the\ndataset was partitioned in the following fashion: 70% for training phase, and\n30% for the testing phase. The hyper-parameters used for all the classifiers\nwere manually assigned. Results show that all the presented ML algorithms\nperformed well (all exceeded 90% test accuracy) on the classification task. The\nMLP algorithm stands out among the implemented algorithms with a test accuracy\nof ~99.04%.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 06:33:34 GMT"}, {"version": "v2", "created": "Sun, 28 Jan 2018 01:30:05 GMT"}, {"version": "v3", "created": "Tue, 6 Mar 2018 13:47:58 GMT"}, {"version": "v4", "created": "Thu, 7 Feb 2019 06:30:57 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Agarap", "Abien Fred", ""]]}, {"id": "1711.07838", "submitter": "Quanyu Dai", "authors": "Quanyu Dai, Qiang Li, Jian Tang, Dan Wang", "title": "Adversarial Network Embedding", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning low-dimensional representations of networks has proved effective in\na variety of tasks such as node classification, link prediction and network\nvisualization. Existing methods can effectively encode different structural\nproperties into the representations, such as neighborhood connectivity\npatterns, global structural role similarities and other high-order proximities.\nHowever, except for objectives to capture network structural properties, most\nof them suffer from lack of additional constraints for enhancing the robustness\nof representations. In this paper, we aim to exploit the strengths of\ngenerative adversarial networks in capturing latent features, and investigate\nits contribution in learning stable and robust graph representations.\nSpecifically, we propose an Adversarial Network Embedding (ANE) framework,\nwhich leverages the adversarial learning principle to regularize the\nrepresentation learning. It consists of two components, i.e., a structure\npreserving component and an adversarial learning component. The former\ncomponent aims to capture network structural properties, while the latter\ncontributes to learning robust representations by matching the posterior\ndistribution of the latent representations to given priors. As shown by the\nempirical results, our method is competitive with or superior to\nstate-of-the-art approaches on benchmark network embedding tasks.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 15:19:31 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Dai", "Quanyu", ""], ["Li", "Qiang", ""], ["Tang", "Jian", ""], ["Wang", "Dan", ""]]}, {"id": "1711.07839", "submitter": "Thomas Blaschke", "authors": "Thomas Blaschke, Marcus Olivecrona, Ola Engkvist, J\\\"urgen Bajorath,\n  Hongming Chen", "title": "Application of generative autoencoder in de novo molecular design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in computational chemistry is the generation of novel\nmolecular structures with desirable pharmacological and physiochemical\nproperties. In this work, we investigate the potential use of autoencoder, a\ndeep learning methodology, for de novo molecular design. Various generative\nautoencoders were used to map molecule structures into a continuous latent\nspace and vice versa and their performance as structure generator was assessed.\nOur results show that the latent space preserves chemical similarity principle\nand thus can be used for the generation of analogue structures. Furthermore,\nthe latent space created by autoencoders were searched systematically to\ngenerate novel compounds with predicted activity against dopamine receptor type\n2 and compounds similar to known active compounds not included in the training\nset were identified.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 15:19:36 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Blaschke", "Thomas", ""], ["Olivecrona", "Marcus", ""], ["Engkvist", "Ola", ""], ["Bajorath", "J\u00fcrgen", ""], ["Chen", "Hongming", ""]]}, {"id": "1711.07871", "submitter": "Ya Ju Fan", "authors": "Ya Ju Fan", "title": "Autoencoder Node Saliency: Selecting Relevant Latent Representations", "comments": null, "journal-ref": "Pattern Recognition, Volume 88, 2019, Pages 643-653", "doi": "10.1016/j.patcog.2018.12.015", "report-no": "ISSN 0031-3203", "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The autoencoder is an artificial neural network model that learns hidden\nrepresentations of unlabeled data. With a linear transfer function it is\nsimilar to the principal component analysis (PCA). While both methods use\nweight vectors for linear transformations, the autoencoder does not come with\nany indication similar to the eigenvalues in PCA that are paired with the\neigenvectors. We propose a novel supervised node saliency (SNS) method that\nranks the hidden nodes by comparing class distributions of latent\nrepresentations against a fixed reference distribution. The latent\nrepresentations of a hidden node can be described using a one-dimensional\nhistogram. We apply normalized entropy difference (NED) to measure the\n\"interestingness\" of the histograms, and conclude a property for NED values to\nidentify a good classifying node. By applying our methods to real data sets, we\ndemonstrate the ability of SNS to explain what the trained autoencoders have\nlearned.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 16:17:14 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 02:09:31 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Fan", "Ya Ju", ""]]}, {"id": "1711.07875", "submitter": "Paolo Dragone", "authors": "Paolo Dragone, Stefano Teso, Andrea Passerini", "title": "Constructive Preference Elicitation over Hybrid Combinatorial Spaces", "comments": "AAAI 2018, computing methodologies, machine learning, learning\n  paradigms, supervised learning, structured outputs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preference elicitation is the task of suggesting a highly preferred\nconfiguration to a decision maker. The preferences are typically learned by\nquerying the user for choice feedback over pairs or sets of objects. In its\nconstructive variant, new objects are synthesized \"from scratch\" by maximizing\nan estimate of the user utility over a combinatorial (possibly infinite) space\nof candidates. In the constructive setting, most existing elicitation\ntechniques fail because they rely on exhaustive enumeration of the candidates.\nA previous solution explicitly designed for constructive tasks comes with no\nformal performance guarantees, and can be very expensive in (or unapplicable\nto) problems with non-Boolean attributes. We propose the Choice Perceptron, a\nPerceptron-like algorithm for learning user preferences from set-wise choice\nfeedback over constructive domains and hybrid Boolean-numeric feature spaces.\nWe provide a theoretical analysis on the attained regret that holds for a large\nclass of query selection strategies, and devise a heuristic strategy that aims\nat optimizing the regret in practice. Finally, we demonstrate its effectiveness\nby empirical evaluation against existing competitors on constructive scenarios\nof increasing complexity.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 16:20:24 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 16:56:59 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Dragone", "Paolo", ""], ["Teso", "Stefano", ""], ["Passerini", "Andrea", ""]]}, {"id": "1711.07878", "submitter": "Jingguang Zhou", "authors": "Jingguang Zhou, Zili Huang", "title": "Recover Missing Sensor Data with Iterative Imputing Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensor data has been playing an important role in machine learning tasks,\ncomplementary to the human-annotated data that is usually rather costly.\nHowever, due to systematic or accidental mis-operations, sensor data comes very\noften with a variety of missing values, resulting in considerable difficulties\nin the follow-up analysis and visualization. Previous work imputes the missing\nvalues by interpolating in the observational feature space, without consulting\nany latent (hidden) dynamics. In contrast, our model captures the latent\ncomplex temporal dynamics by summarizing each observation's context with a\nnovel Iterative Imputing Network, thus significantly outperforms previous work\non the benchmark Beijing air quality and meteorological dataset. Our model also\nyields consistent superiority over other methods in cases of different missing\nrates.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 15:58:02 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Zhou", "Jingguang", ""], ["Huang", "Zili", ""]]}, {"id": "1711.07886", "submitter": "Fayyaz Minhas", "authors": "Abdul Hannan Basit, Wajid Arshad Abbasi, Amina Asif, and Fayyaz Ul\n  Amir Afsar Minhas", "title": "Training large margin host-pathogen protein-protein interaction\n  predictors", "comments": "12 pages", "journal-ref": "Journal of Bioinformatics and Computational Biology 2018", "doi": "10.1142/S0219720018500142", "report-no": "Vol. 16, No. 04 1850014", "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection of protein-protein interactions (PPIs) plays a vital role in\nmolecular biology. Particularly, infections are caused by the interactions of\nhost and pathogen proteins. It is important to identify host-pathogen\ninteractions (HPIs) to discover new drugs to counter infectious diseases.\nConventional wet lab PPI prediction techniques have limitations in terms of\nlarge scale application and budget. Hence, computational approaches are\ndeveloped to predict PPIs. This study aims to develop large margin machine\nlearning models to predict interspecies PPIs with a special interest in\nhost-pathogen protein interactions (HPIs). Especially, we focus on seeking\nanswers to three queries that arise while developing an HPI predictor. 1) How\nshould we select negative samples? 2) What should be the size of negative\nsamples as compared to the positive samples? 3) What type of margin violation\npenalty should be used to train the predictor? We compare two available methods\nfor negative sampling. Moreover, we propose a new method of assigning weights\nto each training example in weighted SVM depending on the distance of the\nnegative examples from the positive examples. We have also developed a web\nserver for our HPI predictor called HoPItor (Host Pathogen Interaction\npredicTOR) that can predict interactions between human and viral proteins. This\nwebserver can be accessed at the URL:\nhttp://faculty.pieas.edu.pk/fayyaz/software.html#HoPItor.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 16:31:43 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Basit", "Abdul Hannan", ""], ["Abbasi", "Wajid Arshad", ""], ["Asif", "Amina", ""], ["Minhas", "Fayyaz Ul Amir Afsar", ""]]}, {"id": "1711.07966", "submitter": "Daniel George", "authors": "Daniel George and E. A. Huerta", "title": "Deep Learning for Real-time Gravitational Wave Detection and Parameter\n  Estimation with LIGO Data", "comments": "Camera-ready (final) version accepted to NIPS 2017 conference\n  workshop on Deep Learning for Physical Sciences and selected for contributed\n  talk. Also awarded 1st place at ACM SRC at SC17. Extended article:\n  arXiv:1711.03121", "journal-ref": null, "doi": null, "report-no": null, "categories": "gr-qc astro-ph.HE astro-ph.IM cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent Nobel-prize-winning detections of gravitational waves from merging\nblack holes and the subsequent detection of the collision of two neutron stars\nin coincidence with electromagnetic observations have inaugurated a new era of\nmultimessenger astrophysics. To enhance the scope of this emergent science, we\nproposed the use of deep convolutional neural networks for the detection and\ncharacterization of gravitational wave signals in real-time. This method, Deep\nFiltering, was initially demonstrated using simulated LIGO noise. In this\narticle, we present the extension of Deep Filtering using real data from the\nfirst observing run of LIGO, for both detection and parameter estimation of\ngravitational waves from binary black hole mergers with continuous data streams\nfrom multiple LIGO detectors. We show for the first time that machine learning\ncan detect and estimate the true parameters of a real GW event observed by\nLIGO. Our comparisons show that Deep Filtering is far more computationally\nefficient than matched-filtering, while retaining similar sensitivity and lower\nerrors, allowing real-time processing of weak time-series signals in\nnon-stationary non-Gaussian noise, with minimal resources, and also enables the\ndetection of new classes of gravitational wave sources that may go unnoticed\nwith existing detection algorithms. This approach is uniquely suited to enable\ncoincident detection campaigns of gravitational waves and their multimessenger\ncounterparts in real-time.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 18:45:01 GMT"}, {"version": "v2", "created": "Mon, 11 Dec 2017 19:36:44 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["George", "Daniel", ""], ["Huerta", "E. A.", ""]]}, {"id": "1711.07970", "submitter": "Arthur Pajot", "authors": "Emmanuel de Bezenac, Arthur Pajot, Patrick Gallinari", "title": "Deep Learning for Physical Processes: Incorporating Prior Scientific\n  Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the use of Deep Learning methods for modeling complex phenomena\nlike those occurring in natural physical processes. With the large amount of\ndata gathered on these phenomena the data intensive paradigm could begin to\nchallenge more traditional approaches elaborated over the years in fields like\nmaths or physics. However, despite considerable successes in a variety of\napplication domains, the machine learning field is not yet ready to handle the\nlevel of complexity required by such problems. Using an example application,\nnamely Sea Surface Temperature Prediction, we show how general background\nknowledge gained from physics could be used as a guideline for designing\nefficient Deep Learning models. In order to motivate the approach and to assess\nits generality we demonstrate a formal link between the solution of a class of\ndifferential equations underlying a large family of physical phenomena and the\nproposed model. Experiments and comparison with series of baselines including a\nstate of the art numerical approach is then provided.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 18:49:47 GMT"}, {"version": "v2", "created": "Tue, 9 Jan 2018 16:43:39 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["de Bezenac", "Emmanuel", ""], ["Pajot", "Arthur", ""], ["Gallinari", "Patrick", ""]]}, {"id": "1711.07979", "submitter": "Georgios Theocharous", "authors": "Georgios Theocharous and Zheng Wen and Yasin Abbasi-Yadkori and Nikos\n  Vlassis", "title": "Posterior Sampling for Large Scale Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a practical non-episodic PSRL algorithm that unlike recent\nstate-of-the-art PSRL algorithms uses a deterministic, model-independent\nepisode switching schedule. Our algorithm termed deterministic schedule PSRL\n(DS-PSRL) is efficient in terms of time, sample, and space complexity. We prove\na Bayesian regret bound under mild assumptions. Our result is more generally\napplicable to multiple parameters and continuous state action problems. We\ncompare our algorithm with state-of-the-art PSRL algorithms on standard\ndiscrete and continuous problems from the literature. Finally, we show how the\nassumptions of our algorithm satisfy a sensible parametrization for a large\nclass of problems in sequential recommendations.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 00:43:24 GMT"}, {"version": "v2", "created": "Wed, 6 Dec 2017 23:55:15 GMT"}, {"version": "v3", "created": "Mon, 22 Oct 2018 22:06:00 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Theocharous", "Georgios", ""], ["Wen", "Zheng", ""], ["Abbasi-Yadkori", "Yasin", ""], ["Vlassis", "Nikos", ""]]}, {"id": "1711.07980", "submitter": "Phuoc Nguyen", "authors": "Phuoc Nguyen, Truyen Tran and Svetha Venkatesh", "title": "Finding Algebraic Structure of Care in Time: A Deep Learning Approach", "comments": "Accepted NIPS ML4H workshop 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the latent processes from Electronic Medical Records could be a\ngame changer in modern healthcare. However, the processes are complex due to\nthe interaction between at least three dynamic components: the illness, the\ncare and the recording practice. Existing methods are inadequate in capturing\nthe dynamic structure of care. We propose an end-to-end model that reads\nmedical record and predicts future risk. The model adopts the algebraic view in\nthat discrete medical objects are embedded into continuous vectors lying in the\nsame space. The bag of disease and comorbidities recorded at each hospital\nvisit are modeled as function of sets. The same holds for the bag of\ntreatments. The interaction between diseases and treatments at a visit is\nmodeled as the residual of the diseases minus the treatments. Finally, the\nhealth trajectory, which is a sequence of visits, is modeled using a recurrent\nneural network. We report preliminary results on chronic diseases - diabetes\nand mental health - for predicting unplanned readmission.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 03:41:05 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Nguyen", "Phuoc", ""], ["Tran", "Truyen", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1711.08001", "submitter": "Xi Wu", "authors": "Xi Wu, Uyeong Jang, Jiefeng Chen, Lingjiao Chen, Somesh Jha", "title": "Reinforcing Adversarial Robustness using Model Confidence Induced by\n  Adversarial Training", "comments": "To appear in ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study leveraging confidence information induced by\nadversarial training to reinforce adversarial robustness of a given\nadversarially trained model. A natural measure of confidence is $\\|F({\\bf\nx})\\|_\\infty$ (i.e. how confident $F$ is about its prediction?). We start by\nanalyzing an adversarial training formulation proposed by Madry et al.. We\ndemonstrate that, under a variety of instantiations, an only somewhat good\nsolution to their objective induces confidence to be a discriminator, which can\ndistinguish between right and wrong model predictions in a neighborhood of a\npoint sampled from the underlying distribution. Based on this, we propose\nHighly Confident Near Neighbor (${\\tt HCNN}$), a framework that combines\nconfidence information and nearest neighbor search, to reinforce adversarial\nrobustness of a base model. We give algorithms in this framework and perform a\ndetailed empirical study. We report encouraging experimental results that\nsupport our analysis, and also discuss problems we observed with existing\nadversarial training.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 19:15:05 GMT"}, {"version": "v2", "created": "Mon, 1 Jan 2018 20:12:55 GMT"}, {"version": "v3", "created": "Fri, 8 Jun 2018 13:46:51 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Wu", "Xi", ""], ["Jang", "Uyeong", ""], ["Chen", "Jiefeng", ""], ["Chen", "Lingjiao", ""], ["Jha", "Somesh", ""]]}, {"id": "1711.08006", "submitter": "Ning Xie", "authors": "Ning Xie, Md Kamruzzaman Sarker, Derek Doran, Pascal Hitzler, Michael\n  Raymer", "title": "Relating Input Concepts to Convolutional Neural Network Decisions", "comments": "10 pages (including references), 9 figures, paper accepted by NIPS\n  IEVDL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many current methods to interpret convolutional neural networks (CNNs) use\nvisualization techniques and words to highlight concepts of the input seemingly\nrelevant to a CNN's decision. The methods hypothesize that the recognition of\nthese concepts are instrumental in the decision a CNN reaches, but the nature\nof this relationship has not been well explored. To address this gap, this\npaper examines the quality of a concept's recognition by a CNN and the degree\nto which the recognitions are associated with CNN decisions. The study\nconsiders a CNN trained for scene recognition over the ADE20k dataset. It uses\na novel approach to find and score the strength of minimally distributed\nrepresentations of input concepts (defined by objects in scene images) across\nlate stage feature maps. Subsequent analysis finds evidence that concept\nrecognition impacts decision making. Strong recognition of concepts\nfrequently-occurring in few scenes are indicative of correct decisions, but\nrecognizing concepts common to many scenes may mislead the network.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 19:37:13 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Xie", "Ning", ""], ["Sarker", "Md Kamruzzaman", ""], ["Doran", "Derek", ""], ["Hitzler", "Pascal", ""], ["Raymer", "Michael", ""]]}, {"id": "1711.08014", "submitter": "Abhishek Kumar", "authors": "Hang Shao, Abhishek Kumar, P. Thomas Fletcher", "title": "The Riemannian Geometry of Deep Generative Models", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models learn a mapping from a low dimensional latent space to\na high-dimensional data space. Under certain regularity conditions, these\nmodels parameterize nonlinear manifolds in the data space. In this paper, we\ninvestigate the Riemannian geometry of these generated manifolds. First, we\ndevelop efficient algorithms for computing geodesic curves, which provide an\nintrinsic notion of distance between points on the manifold. Second, we develop\nan algorithm for parallel translation of a tangent vector along a path on the\nmanifold. We show how parallel translation can be used to generate analogies,\ni.e., to transport a change in one data point into a semantically similar\nchange of another data point. Our experiments on real image data show that the\nmanifolds learned by deep generative models, while nonlinear, are surprisingly\nclose to zero curvature. The practical implication is that linear paths in the\nlatent space closely approximate geodesics on the generated manifold. However,\nfurther investigation into this phenomenon is warranted, to identify if there\nare other architectures or datasets where curvature plays a more prominent\nrole. We believe that exploring the Riemannian geometry of deep generative\nmodels, using the tools developed in this paper, will be an important step in\nunderstanding the high-dimensional, nonlinear spaces these models learn.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 19:59:24 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Shao", "Hang", ""], ["Kumar", "Abhishek", ""], ["Fletcher", "P. Thomas", ""]]}, {"id": "1711.08018", "submitter": "Akshay Krishnamurthy", "authors": "Tongyi Cao, Akshay Krishnamurthy", "title": "Disagreement-Based Combinatorial Pure Exploration: Sample Complexity\n  Bounds and an Efficient Algorithm", "comments": null, "journal-ref": "Conference on Learning Theory, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design new algorithms for the combinatorial pure exploration problem in\nthe multi-arm bandit framework. In this problem, we are given $K$ distributions\nand a collection of subsets $\\mathcal{V} \\subset 2^{[K]}$ of these\ndistributions, and we would like to find the subset $v \\in \\mathcal{V}$ that\nhas largest mean, while collecting, in a sequential fashion, as few samples\nfrom the distributions as possible. In both the fixed budget and fixed\nconfidence settings, our algorithms achieve new sample-complexity bounds that\nprovide polynomial improvements on previous results in some settings. Via an\ninformation-theoretic lower bound, we show that no approach based on uniform\nsampling can improve on ours in any regime, yielding the first interactive\nalgorithms for this problem with this basic property. Computationally, we show\nhow to efficiently implement our fixed confidence algorithm whenever\n$\\mathcal{V}$ supports efficient linear optimization. Our results involve\nprecise concentration-of-measure arguments and a new algorithm for linear\nprogramming with exponentially many constraints.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 20:16:35 GMT"}, {"version": "v2", "created": "Thu, 30 Nov 2017 12:44:57 GMT"}, {"version": "v3", "created": "Mon, 4 Feb 2019 15:04:12 GMT"}, {"version": "v4", "created": "Tue, 28 May 2019 12:59:42 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Cao", "Tongyi", ""], ["Krishnamurthy", "Akshay", ""]]}, {"id": "1711.08054", "submitter": "Ming Hou", "authors": "Ming Hou, Brahim Chaib-draa, Chao Li, Qibin Zhao", "title": "Generative Adversarial Positive-Unlabelled Learning", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the task of classifying binary positive-unlabeled\n(PU) data. The existing discriminative learning based PU models attempt to seek\nan optimal reweighting strategy for U data, so that a decent decision boundary\ncan be found. However, given limited P data, the conventional PU models tend to\nsuffer from overfitting when adapted to very flexible deep neural networks. In\ncontrast, we are the first to innovate a totally new paradigm to attack the\nbinary PU task, from perspective of generative learning by leveraging the\npowerful generative adversarial networks (GAN). Our generative\npositive-unlabeled (GenPU) framework incorporates an array of discriminators\nand generators that are endowed with different roles in simultaneously\nproducing positive and negative realistic samples. We provide theoretical\nanalysis to justify that, at equilibrium, GenPU is capable of recovering both\npositive and negative data distributions. Moreover, we show GenPU is\ngeneralizable and closely related to the semi-supervised classification. Given\nrather limited P data, experiments on both synthetic and real-world dataset\ndemonstrate the effectiveness of our proposed framework. With infinite\nrealistic and diverse sample streams generated from GenPU, a very flexible\nclassifier can then be trained using deep neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 21:40:24 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 08:18:27 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Hou", "Ming", ""], ["Chaib-draa", "Brahim", ""], ["Li", "Chao", ""], ["Zhao", "Qibin", ""]]}, {"id": "1711.08058", "submitter": "Ahmad Abdulkader", "authors": "Ahmad AbdulKader, Kareem Nassar, Mohamed Mahmoud, Daniel Galvez,\n  Chetan Patil", "title": "Multiple-Instance, Cascaded Classification for Keyword Spotting in\n  Narrow-Band Audio", "comments": "To be published in the proceedings of NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose using cascaded classifiers for a keyword spotting (KWS) task on\nnarrow-band (NB), 8kHz audio acquired in non-IID environments --- a more\nchallenging task than most state-of-the-art KWS systems face. We present a\nmodel that incorporates Deep Neural Networks (DNNs), cascading,\nmultiple-feature representations, and multiple-instance learning. The cascaded\nclassifiers handle the task's class imbalance and reduce power consumption on\ncomputationally-constrained devices via early termination. The KWS system\nachieves a false negative rate of 6% at an hourly false positive rate of 0.75\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 21:42:17 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["AbdulKader", "Ahmad", ""], ["Nassar", "Kareem", ""], ["Mahmoud", "Mohamed", ""], ["Galvez", "Daniel", ""], ["Patil", "Chetan", ""]]}, {"id": "1711.08068", "submitter": "Daniel L\\'evy", "authors": "Daniel Levy, Stefano Ermon", "title": "Deterministic Policy Optimization by Combining Pathwise and Score\n  Function Estimators for Discrete Action Spaces", "comments": "In AAAI 2018 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy optimization methods have shown great promise in solving complex\nreinforcement and imitation learning tasks. While model-free methods are\nbroadly applicable, they often require many samples to optimize complex\npolicies. Model-based methods greatly improve sample-efficiency but at the cost\nof poor generalization, requiring a carefully handcrafted model of the system\ndynamics for each task. Recently, hybrid methods have been successful in\ntrading off applicability for improved sample-complexity. However, these have\nbeen limited to continuous action spaces. In this work, we present a new hybrid\nmethod based on an approximation of the dynamics as an expectation over the\nnext state under the current policy. This relaxation allows us to derive a\nnovel hybrid policy gradient estimator, combining score function and pathwise\nderivative estimators, that is applicable to discrete action spaces. We show\nsignificant gains in sample complexity, ranging between $1.7$ and $25\\times$,\nwhen learning parameterized policies on Cart Pole, Acrobot, Mountain Car and\nHand Mass. Our method is applicable to both discrete and continuous action\nspaces, when competing pathwise methods are limited to the latter.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 22:05:18 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Levy", "Daniel", ""], ["Ermon", "Stefano", ""]]}, {"id": "1711.08095", "submitter": "Dongjin Choi", "authors": "Dongjin Choi, Lee Sael", "title": "SNeCT: Scalable network constrained Tucker decomposition for integrative\n  multi-platform data analysis", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: How do we integratively analyze large-scale multi-platform\ngenomic data that are high dimensional and sparse? Furthermore, how can we\nincorporate prior knowledge, such as the association between genes, in the\nanalysis systematically? Method: To solve this problem, we propose a Scalable\nNetwork Constrained Tucker decomposition method we call SNeCT. SNeCT adopts\nparallel stochastic gradient descent approach on the proposed parallelizable\nnetwork constrained optimization function. SNeCT decomposition is applied to\ntensor constructed from large scale multi-platform multi-cohort cancer data,\nPanCan12, constrained on a network built from PathwayCommons database. Results:\nThe decomposed factor matrices are applied to stratify cancers, to search for\ntop-k similar patients, and to illustrate how the matrices can be used for\npersonalized interpretation. In the stratification test, combined twelve-cohort\ndata is clustered to form thirteen subclasses. The thirteen subclasses have a\nhigh correlation to tissue of origin in addition to other interesting\nobservations, such as clear separation of OV cancers to two groups, and high\nclinical correlation within subclusters formed in cohorts BRCA and UCEC. In the\ntop-k search, a new patient's genomic profile is generated and searched against\nexisting patients based on the factor matrices. The similarity of the top-k\npatient to the query is high for 23 clinical features, including\nestrogen/progesterone receptor statuses of BRCA patients with average precision\nvalue ranges from 0.72 to 0.86 and from 0.68 to 0.86, respectively. We also\nprovide an illustration of how the factor matrices can be used for\ninterpretable personalized analysis of each patient.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 01:03:49 GMT"}, {"version": "v2", "created": "Sun, 26 Nov 2017 11:02:13 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Choi", "Dongjin", ""], ["Sael", "Lee", ""]]}, {"id": "1711.08113", "submitter": "Mingda Qiao", "authors": "Mingda Qiao, Gregory Valiant", "title": "Learning Discrete Distributions from Untrusted Batches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a discrete distribution in the presence\nof an $\\epsilon$ fraction of malicious data sources. Specifically, we consider\nthe setting where there is some underlying distribution, $p$, and each data\nsource provides a batch of $\\ge k$ samples, with the guarantee that at least a\n$(1-\\epsilon)$ fraction of the sources draw their samples from a distribution\nwith total variation distance at most $\\eta$ from $p$. We make no assumptions\non the data provided by the remaining $\\epsilon$ fraction of sources--this data\ncan even be chosen as an adversarial function of the $(1-\\epsilon)$ fraction of\n\"good\" batches. We provide two algorithms: one with runtime exponential in the\nsupport size, $n$, but polynomial in $k$, $1/\\epsilon$ and $1/\\eta$ that takes\n$O((n+k)/\\epsilon^2)$ batches and recovers $p$ to error\n$O(\\eta+\\epsilon/\\sqrt{k})$. This recovery accuracy is information\ntheoretically optimal, to constant factors, even given an infinite number of\ndata sources. Our second algorithm applies to the $\\eta = 0$ setting and also\nachieves an $O(\\epsilon/\\sqrt{k})$ recover guarantee, though it runs in\n$\\mathrm{poly}((nk)^k)$ time. This second algorithm, which approximates a\ncertain tensor via a rank-1 tensor minimizing $\\ell_1$ distance, is surprising\nin light of the hardness of many low-rank tensor approximation problems, and\nmay be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 02:39:21 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Qiao", "Mingda", ""], ["Valiant", "Gregory", ""]]}, {"id": "1711.08117", "submitter": "Zeke Xie", "authors": "Zeke Xie and Issei Sato", "title": "A Quantum-Inspired Ensemble Method and Quantum-Inspired Forest\n  Regressors", "comments": "17 pages, ACML2017", "journal-ref": "Asian Conference on Machine Learning 2017, PMLR 77, 81-96", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Quantum-Inspired Subspace(QIS) Ensemble Method for generating\nfeature ensembles based on feature selections. We assign each principal\ncomponent a Fraction Transition Probability as its probability weight based on\nPrincipal Component Analysis and quantum interpretations. In order to generate\nthe feature subset for each base regressor, we select a feature subset from\nprincipal components based on Fraction Transition Probabilities. The idea\noriginating from quantum mechanics can encourage ensemble diversity and the\naccuracy simultaneously. We incorporate Quantum-Inspired Subspace Method into\nRandom Forest and propose Quantum-Inspired Forest. We theoretically prove that\nthe quantum interpretation corresponds to the first order approximation of\nensemble regression. We also evaluate the empirical performance of\nQuantum-Inspired Forest and Random Forest in multiple hyperparameter settings.\nQuantum-Inspired Forest proves the significant robustness of the default\nhyperparameters on most data sets. The contribution of this work is two-fold, a\nnovel ensemble regression algorithm inspired by quantum mechanics and the\ntheoretical connection between quantum interpretations and machine learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 02:57:58 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Xie", "Zeke", ""], ["Sato", "Issei", ""]]}, {"id": "1711.08132", "submitter": "Liang Pang", "authors": "Liang Pang, Yanyan Lan, Jun Xu, Jiafeng Guo, Xueqi Cheng", "title": "Locally Smoothed Neural Networks", "comments": "In Proceedings of 9th Asian Conference on Machine Learning (ACML2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) and the locally connected layer are\nlimited in capturing the importance and relations of different local receptive\nfields, which are often crucial for tasks such as face verification, visual\nquestion answering, and word sequence prediction. To tackle the issue, we\npropose a novel locally smoothed neural network (LSNN) in this paper. The main\nidea is to represent the weight matrix of the locally connected layer as the\nproduct of the kernel and the smoother, where the kernel is shared over\ndifferent local receptive fields, and the smoother is for determining the\nimportance and relations of different local receptive fields. Specifically, a\nmulti-variate Gaussian function is utilized to generate the smoother, for\nmodeling the location relations among different local receptive fields.\nFurthermore, the content information can also be leveraged by setting the mean\nand precision of the Gaussian function according to the content. Experiments on\nsome variant of MNIST clearly show our advantages over CNN and locally\nconnected layer.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 05:05:32 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Pang", "Liang", ""], ["Lan", "Yanyan", ""], ["Xu", "Jun", ""], ["Guo", "Jiafeng", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1711.08135", "submitter": "Ian Manchester", "authors": "Ian R. Manchester", "title": "Contracting Nonlinear Observers: Convex Optimization and Learning from\n  Data", "comments": "conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new approach to design of nonlinear observers (state estimators) is\nproposed. The main idea is to (i) construct a convex set of dynamical systems\nwhich are contracting observers for a particular system, and (ii) optimize over\nthis set for one which minimizes a bound on state-estimation error on a\nsimulated noisy data set. We construct convex sets of continuous-time and\ndiscrete-time observers, as well as contracting sampled-data observers for\ncontinuous-time systems. Convex bounds for learning are constructed using\nLagrangian relaxation. The utility of the proposed methods are verified using\nnumerical simulation.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 05:10:32 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Manchester", "Ian R.", ""]]}, {"id": "1711.08149", "submitter": "Zohaib Iqbal", "authors": "Zohaib Iqbal, Da Luo, Peter Henry, Samaneh Kazemifar, Timothy Rozario,\n  Yulong Yan, Kenneth Westover, Weiguo Lu, Dan Nguyen, Troy Long, Jing Wang,\n  Hak Choy, Steve Jiang", "title": "Accurate Real Time Localization Tracking in A Clinical Environment using\n  Bluetooth Low Energy and Deep Learning", "comments": null, "journal-ref": "PLoS ONE 13(10): e0205392 (2018)", "doi": "10.1371/journal.pone.0205392", "report-no": null, "categories": "physics.med-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has started to revolutionize several different industries, and\nthe applications of these methods in medicine are now becoming more\ncommonplace. This study focuses on investigating the feasibility of tracking\npatients and clinical staff wearing Bluetooth Low Energy (BLE) tags in a\nradiation oncology clinic using artificial neural networks (ANNs) and\nconvolutional neural networks (CNNs). The performance of these networks was\ncompared to relative received signal strength indicator (RSSI) thresholding and\ntriangulation. By utilizing temporal information, a combined CNN+ANN network\nwas capable of correctly identifying the location of the BLE tag with an\naccuracy of 99.9%. It outperformed a CNN model (accuracy = 94%), a thresholding\nmodel employing majority voting (accuracy = 95%), and a triangulation\nclassifier utilizing majority voting (accuracy = 95%). Future studies will seek\nto deploy this affordable real time location system in hospitals to improve\nclinical workflow, efficiency, and patient safety.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 06:32:13 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 19:22:44 GMT"}, {"version": "v3", "created": "Mon, 15 Oct 2018 15:26:47 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Iqbal", "Zohaib", ""], ["Luo", "Da", ""], ["Henry", "Peter", ""], ["Kazemifar", "Samaneh", ""], ["Rozario", "Timothy", ""], ["Yan", "Yulong", ""], ["Westover", "Kenneth", ""], ["Lu", "Weiguo", ""], ["Nguyen", "Dan", ""], ["Long", "Troy", ""], ["Wang", "Jing", ""], ["Choy", "Hak", ""], ["Jiang", "Steve", ""]]}, {"id": "1711.08171", "submitter": "Shota Saito", "authors": "Shota Saito, Danilo P Mandic, Hideyuki Suzuki", "title": "Hypergraph $p$-Laplacian: A Differential Geometry View", "comments": "Extended version of our AAAI-18 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graph Laplacian plays key roles in information processing of relational\ndata, and has analogies with the Laplacian in differential geometry. In this\npaper, we generalize the analogy between graph Laplacian and differential\ngeometry to the hypergraph setting, and propose a novel hypergraph\n$p$-Laplacian. Unlike the existing two-node graph Laplacians, this\ngeneralization makes it possible to analyze hypergraphs, where the edges are\nallowed to connect any number of nodes. Moreover, we propose a semi-supervised\nlearning method based on the proposed hypergraph $p$-Laplacian, and formalize\nthem as the analogue to the Dirichlet problem, which often appears in physics.\nWe further explore theoretical connections to normalized hypergraph cut on a\nhypergraph, and propose normalized cut corresponding to hypergraph\n$p$-Laplacian. The proposed $p$-Laplacian is shown to outperform standard\nhypergraph Laplacians in the experiment on a hypergraph semi-supervised\nlearning and normalized cut setting.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 08:12:23 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Saito", "Shota", ""], ["Mandic", "Danilo P", ""], ["Suzuki", "Hideyuki", ""]]}, {"id": "1711.08172", "submitter": "Yuejiao Sun", "authors": "Yifan Chen, Yuejiao Sun, Wotao Yin", "title": "Run-and-Inspect Method for Nonconvex Optimization and Global Optimality\n  Bounds for R-Local Minimizers", "comments": null, "journal-ref": null, "doi": null, "report-no": "UCLA CAM 17-67", "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many optimization algorithms converge to stationary points. When the\nunderlying problem is nonconvex, they may get trapped at local minimizers and\noccasionally stagnate near saddle points. We propose the Run-and-Inspect\nMethod, which adds an \"inspect\" phase to existing algorithms that helps escape\nfrom non-global stationary points. The inspection samples a set of points in a\nradius $R$ around the current point. When a sample point yields a sufficient\ndecrease in the objective, we move there and resume an existing algorithm. If\nno sufficient decrease is found, the current point is called an approximate\n$R$-local minimizer. We show that an $R$-local minimizer is globally optimal,\nup to a specific error depending on $R$, if the objective function can be\nimplicitly decomposed into a smooth convex function plus a restricted function\nthat is possibly nonconvex, nonsmooth. For high-dimensional problems, we\nintroduce blockwise inspections to overcome the curse of dimensionality while\nstill maintaining optimality bounds up to a factor equal to the number of\nblocks. Our method performs well on a set of artificial and realistic nonconvex\nproblems by coupling with gradient descent, coordinate descent, EM, and\nprox-linear algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 08:15:03 GMT"}, {"version": "v2", "created": "Fri, 29 Jun 2018 07:03:25 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Chen", "Yifan", ""], ["Sun", "Yuejiao", ""], ["Yin", "Wotao", ""]]}, {"id": "1711.08198", "submitter": "Giuseppe Jurman", "authors": "Valerio Maggio and Marco Chierici and Giuseppe Jurman and Cesare\n  Furlanello", "title": "A multiobjective deep learning approach for predictive classification in\n  Neuroblastoma", "comments": "NIPS ML4H workshop 2017 & MAQC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroblastoma is a strongly heterogeneous cancer with very diverse clinical\ncourses that may vary from spontaneous regression to fatal progression; an\naccurate patient's risk estimation at diagnosis is essential to design\nappropriate tumor treatment strategies. Neuroblastoma is a paradigm disease\nwhere different diagnostic and prognostic endpoints should be predicted from\ncommon molecular and clinical information, with increasing complexity, as shown\nin the FDA MAQC-II study. Here we introduce the novel multiobjective deep\nlearning architecture CDRP (Concatenated Diagnostic Relapse Prognostic)\ncomposed by 8 layers to obtain a combined diagnostic and prognostic prediction\nfrom high-throughput transcriptomics data. Two distinct loss functions are\noptimized for the Event Free Survival (EFS) and Overall Survival (OS)\nprognosis, respectively. We use the High-Risk (HR) diagnostic information as an\nadditional input generated by an autoencoder embedding. The latter is used as\nnetwork regulariser, based on a clinical algorithm commonly adopted for\nstratifying patients from cancer stage, age at insurgence of disease, and MYCN,\nthe specific molecular marker. The architecture was applied to Illumina\nHiSeq2000 RNA-Seq for 498 neuroblastoma patients (176 at high risk) from the\nSequencing Quality Control (SEQC) study, obtaining state-of-art on the\ndiagnostic endpoint and improving prediction of prognosis over the HR cohort.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 09:54:48 GMT"}, {"version": "v2", "created": "Fri, 1 Dec 2017 13:38:22 GMT"}, {"version": "v3", "created": "Thu, 22 Feb 2018 18:43:29 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Maggio", "Valerio", ""], ["Chierici", "Marco", ""], ["Jurman", "Giuseppe", ""], ["Furlanello", "Cesare", ""]]}, {"id": "1711.08208", "submitter": "Sebasti\\'an Casta\\~no-Candamil", "authors": "Sebastian Casta\\~no-Candamil and Andreas Meinel and Michael Tangermann", "title": "Post-hoc labeling of arbitrary EEG recordings for data-efficient\n  evaluation of neural decoding methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many cognitive, sensory and motor processes have correlates in oscillatory\nneural sources, which are embedded as a subspace into the recorded brain\nsignals. Decoding such processes from noisy\nmagnetoencephalogram/electroencephalogram (M/EEG) signals usually requires the\nuse of data-driven analysis methods. The objective evaluation of such decoding\nalgorithms on experimental raw signals, however, is a challenge: the amount of\navailable M/EEG data typically is limited, labels can be unreliable, and raw\nsignals often are contaminated with artifacts. The latter is specifically\nproblematic, if the artifacts stem from behavioral confounds of the oscillatory\nneural processes of interest.\n  To overcome some of these problems, simulation frameworks have been\nintroduced for benchmarking decoding methods. Generating artificial brain\nsignals, however, most simulation frameworks make strong and partially\nunrealistic assumptions about brain activity, which limits the generalization\nof obtained results to real-world conditions.\n  In the present contribution, we thrive to remove many shortcomings of current\nsimulation frameworks and propose a versatile alternative, that allows for\nobjective evaluation and benchmarking of novel data-driven decoding methods for\nneural signals. Its central idea is to utilize post-hoc labelings of arbitrary\nM/EEG recordings. This strategy makes it paradigm-agnostic and allows to\ngenerate comparatively large datasets with noiseless labels. Source code and\ndata of the novel simulation approach are made available for facilitating its\nadoption.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 10:14:51 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Casta\u00f1o-Candamil", "Sebastian", ""], ["Meinel", "Andreas", ""], ["Tangermann", "Michael", ""]]}, {"id": "1711.08228", "submitter": "Rong Zhang", "authors": "Tong Mo, Rong Zhang, Weiping Li, Jingbo Zhang, Zhonghai Wu and Wei Tan", "title": "An influence-based fast preceding questionnaire model for elderly\n  assessments", "comments": "Accepted by the journal \"Intelligent Data Analysis\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the efficiency of elderly assessments, an influence-based fast\npreceding questionnaire model (FPQM) is proposed. Compared with traditional\nassessments, the FPQM optimizes questionnaires by reordering their attributes.\nThe values of low-ranking attributes can be predicted by the values of the\nhigh-ranking attributes. Therefore, the number of attributes can be reduced\nwithout redesigning the questionnaires. A new function for calculating the\ninfluence of the attributes is proposed based on probability theory. Reordering\nand reducing algorithms are given based on the attributes' influences. The\nmodel is verified through a practical application. The practice in an\nelderly-care company shows that the FPQM can reduce the number of attributes by\n90.56% with a prediction accuracy of 98.39%. Compared with other methods, such\nas the Expert Knowledge, Rough Set and C4.5 methods, the FPQM achieves the best\nperformance. In addition, the FPQM can also be applied to other questionnaires.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 11:10:39 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Mo", "Tong", ""], ["Zhang", "Rong", ""], ["Li", "Weiping", ""], ["Zhang", "Jingbo", ""], ["Wu", "Zhonghai", ""], ["Tan", "Wei", ""]]}, {"id": "1711.08244", "submitter": "Ambrish Rawat", "authors": "Ambrish Rawat, Martin Wistuba, Maria-Irina Nicolae", "title": "Adversarial Phenomenon in the Eyes of Bayesian Deep Learning", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning models are vulnerable to adversarial examples, i.e.\\ images\nobtained via deliberate imperceptible perturbations, such that the model\nmisclassifies them with high confidence. However, class confidence by itself is\nan incomplete picture of uncertainty. We therefore use principled Bayesian\nmethods to capture model uncertainty in prediction for observing adversarial\nmisclassification. We provide an extensive study with different Bayesian neural\nnetworks attacked in both white-box and black-box setups. The behaviour of the\nnetworks for noise, attacks and clean test data is compared. We observe that\nBayesian neural networks are uncertain in their predictions for adversarial\nperturbations, a behaviour similar to the one observed for random Gaussian\nperturbations. Thus, we conclude that Bayesian neural networks can be\nconsidered for detecting adversarial examples.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 12:02:53 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Rawat", "Ambrish", ""], ["Wistuba", "Martin", ""], ["Nicolae", "Maria-Irina", ""]]}, {"id": "1711.08247", "submitter": "Stefano Teso", "authors": "Paolo Dragone, Stefano Teso, Mohit Kumar, Andrea Passerini", "title": "Decomposition Strategies for Constructive Preference Elicitation", "comments": "Accepted at the Thirty-Second AAAI Conference on Artificial\n  Intelligence (AAAI-18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of constructive preference elicitation, that is the\nproblem of learning user preferences over very large decision problems,\ninvolving a combinatorial space of possible outcomes. In this setting, the\nsuggested configuration is synthesized on-the-fly by solving a constrained\noptimization problem, while the preferences are learned itera tively by\ninteracting with the user. Previous work has shown that Coactive Learning is a\nsuitable method for learning user preferences in constructive scenarios. In\nCoactive Learning the user provides feedback to the algorithm in the form of an\nimprovement to a suggested configuration. When the problem involves many\ndecision variables and constraints, this type of interaction poses a\nsignificant cognitive burden on the user. We propose a decomposition technique\nfor large preference-based decision problems relying exclusively on inference\nand feedback over partial configurations. This has the clear advantage of\ndrastically reducing the user cognitive load. Additionally, part-wise inference\ncan be (up to exponentially) less computationally demanding than inference over\nfull configurations. We discuss the theoretical implications of working with\nparts and present promising empirical results on one synthetic and two\nrealistic constructive problems.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 12:16:40 GMT"}, {"version": "v2", "created": "Sun, 6 May 2018 11:15:50 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Dragone", "Paolo", ""], ["Teso", "Stefano", ""], ["Kumar", "Mohit", ""], ["Passerini", "Andrea", ""]]}, {"id": "1711.08267", "submitter": "Hongwei Wang", "authors": "Hongwei Wang, Jia Wang, Jialin Wang, Miao Zhao, Weinan Zhang, Fuzheng\n  Zhang, Xing Xie, Minyi Guo", "title": "GraphGAN: Graph Representation Learning with Generative Adversarial Nets", "comments": "The 32nd AAAI Conference on Artificial Intelligence (AAAI 2018), 8\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of graph representation learning is to embed each vertex in a graph\ninto a low-dimensional vector space. Existing graph representation learning\nmethods can be classified into two categories: generative models that learn the\nunderlying connectivity distribution in the graph, and discriminative models\nthat predict the probability of edge existence between a pair of vertices. In\nthis paper, we propose GraphGAN, an innovative graph representation learning\nframework unifying above two classes of methods, in which the generative model\nand discriminative model play a game-theoretical minimax game. Specifically,\nfor a given vertex, the generative model tries to fit its underlying true\nconnectivity distribution over all other vertices and produces \"fake\" samples\nto fool the discriminative model, while the discriminative model tries to\ndetect whether the sampled vertex is from ground truth or generated by the\ngenerative model. With the competition between these two models, both of them\ncan alternately and iteratively boost their performance. Moreover, when\nconsidering the implementation of generative model, we propose a novel graph\nsoftmax to overcome the limitations of traditional softmax function, which can\nbe proven satisfying desirable properties of normalization, graph structure\nawareness, and computational efficiency. Through extensive experiments on\nreal-world datasets, we demonstrate that GraphGAN achieves substantial gains in\na variety of applications, including link prediction, node classification, and\nrecommendation, over state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 13:20:17 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Wang", "Hongwei", ""], ["Wang", "Jia", ""], ["Wang", "Jialin", ""], ["Zhao", "Miao", ""], ["Zhang", "Weinan", ""], ["Zhang", "Fuzheng", ""], ["Xie", "Xing", ""], ["Guo", "Minyi", ""]]}, {"id": "1711.08277", "submitter": "Boyang Deng", "authors": "Boyang Deng, Qing Liu, Siyuan Qiao, Alan Yuille", "title": "Few-shot Learning by Exploiting Visual Concepts within CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are one of the driving forces for the\nadvancement of computer vision. Despite their promising performances on many\ntasks, CNNs still face major obstacles on the road to achieving ideal machine\nintelligence. One is that CNNs are complex and hard to interpret. Another is\nthat standard CNNs require large amounts of annotated data, which is sometimes\nhard to obtain, and it is desirable to learn to recognize objects from few\nexamples. In this work, we address these limitations of CNNs by developing\nnovel, flexible, and interpretable models for few-shot learning. Our models are\nbased on the idea of encoding objects in terms of visual concepts (VCs), which\nare interpretable visual cues represented by the feature vectors within CNNs.\nWe first adapt the learning of VCs to the few-shot setting, and then uncover\ntwo key properties of feature encoding using VCs, which we call category\nsensitivity and spatial pattern. Motivated by these properties, we present two\nintuitive models for the problem of few-shot learning. Experiments show that\nour models achieve competitive performances, while being more flexible and\ninterpretable than alternative state-of-the-art few-shot learning methods. We\nconclude that using VCs helps expose the natural capability of CNNs for\nfew-shot learning.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 13:44:44 GMT"}, {"version": "v2", "created": "Tue, 16 Jan 2018 13:09:51 GMT"}, {"version": "v3", "created": "Tue, 13 Feb 2018 12:30:09 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Deng", "Boyang", ""], ["Liu", "Qing", ""], ["Qiao", "Siyuan", ""], ["Yuille", "Alan", ""]]}, {"id": "1711.08325", "submitter": "Elham Taghizadeh", "authors": "Elham Taghizadeh", "title": "Utilizing artificial neural networks to predict demand for\n  weather-sensitive products at retail stores", "comments": null, "journal-ref": "Proceedings of the International Annual Conference of the American\n  Society for Engineering Management 2017", "doi": null, "report-no": "2010278851", "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  One key requirement for effective supply chain management is the quality of\nits inventory management. Various inventory management methods are typically\nemployed for different types of products based on their demand patterns,\nproduct attributes, and supply network. In this paper, our goal is to develop\nrobust demand prediction methods for weather sensitive products at retail\nstores. We employ historical datasets from Walmart, whose customers and markets\nare often exposed to extreme weather events which can have a huge impact on\nsales regarding the affected stores and products. We want to accurately predict\nthe sales of 111 potentially weather-sensitive products around the time of\nmajor weather events at 45 of Walmart retails locations in the U.S.\nIntuitively, we may expect an uptick in the sales of umbrellas before a big\nthunderstorm, but it is difficult for replenishment managers to predict the\nlevel of inventory needed to avoid being out-of-stock or overstock during and\nafter that storm. While they rely on a variety of vendor tools to predict sales\naround extreme weather events, they mostly employ a time-consuming process that\nlacks a systematic measure of effectiveness. We employ all the methods critical\nto any analytics project and start with data exploration. Critical features are\nextracted from the raw historical dataset for demand forecasting accuracy and\nrobustness. In particular, we employ Artificial Neural Network for forecasting\ndemand for each product sold around the time of major weather events. Finally,\nwe evaluate our model to evaluate their accuracy and robustness.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 15:58:58 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Taghizadeh", "Elham", ""]]}, {"id": "1711.08331", "submitter": "Adish Singla", "authors": "Christoph Hirnschall, Adish Singla, Sebastian Tschiatschek, Andreas\n  Krause", "title": "Learning User Preferences to Incentivize Exploration in the Sharing\n  Economy", "comments": "Longer version of AAAI'18 paper. arXiv admin note: text overlap with\n  arXiv:1702.02849", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study platforms in the sharing economy and discuss the need for\nincentivizing users to explore options that otherwise would not be chosen. For\ninstance, rental platforms such as Airbnb typically rely on customer reviews to\nprovide users with relevant information about different options. Yet, often a\nlarge fraction of options does not have any reviews available. Such options are\nfrequently neglected as viable choices, and in turn are unlikely to be\nevaluated, creating a vicious cycle. Platforms can engage users to deviate from\ntheir preferred choice by offering monetary incentives for choosing a different\noption instead. To efficiently learn the optimal incentives to offer, we\nconsider structural information in user preferences and introduce a novel\nalgorithm - Coordinated Online Learning (CoOL) - for learning with structural\ninformation modeled as convex constraints. We provide formal guarantees on the\nperformance of our algorithm and test the viability of our approach in a user\nstudy with data of apartments on Airbnb. Our findings suggest that our approach\nis well-suited to learn appropriate incentives and increase exploration on the\ninvestigated platform.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 22:19:19 GMT"}, {"version": "v2", "created": "Fri, 24 Nov 2017 16:03:55 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Hirnschall", "Christoph", ""], ["Singla", "Adish", ""], ["Tschiatschek", "Sebastian", ""], ["Krause", "Andreas", ""]]}, {"id": "1711.08336", "submitter": "Eli (Omid) David", "authors": "Eli David, Nathan S. Netanyahu", "title": "DeepSign: Deep Learning for Automatic Malware Signature Generation and\n  Classification", "comments": null, "journal-ref": "International Joint Conference on Neural Networks (IJCNN), pages\n  1-8, Killarney, Ireland, July 2015", "doi": "10.1109/IJCNN.2015.7280815", "report-no": null, "categories": "cs.CR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel deep learning based method for automatic malware\nsignature generation and classification. The method uses a deep belief network\n(DBN), implemented with a deep stack of denoising autoencoders, generating an\ninvariant compact representation of the malware behavior. While conventional\nsignature and token based methods for malware detection do not detect a\nmajority of new variants for existing malware, the results presented in this\npaper show that signatures generated by the DBN allow for an accurate\nclassification of new malware variants. Using a dataset containing hundreds of\nvariants for several major malware families, our method achieves 98.6%\nclassification accuracy using the signatures generated by the DBN. The\npresented method is completely agnostic to the type of malware behavior that is\nlogged (e.g., API calls and their parameters, registry entries, websites and\nports accessed, etc.), and can use any raw input from a sandbox to successfully\ntrain the deep neural network which is used to generate malware signatures.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 07:22:58 GMT"}, {"version": "v2", "created": "Thu, 23 Nov 2017 16:27:18 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["David", "Eli", ""], ["Netanyahu", "Nathan S.", ""]]}, {"id": "1711.08337", "submitter": "Eli (Omid) David", "authors": "Eli David, H. Jaap van den Herik, Moshe Koppel, Nathan S. Netanyahu", "title": "Genetic Algorithms for Evolving Computer Chess Programs", "comments": "Winner of Gold Award in 11th Annual \"Humies\" Awards for\n  Human-Competitive Results. arXiv admin note: substantial text overlap with\n  arXiv:1711.06840, arXiv:1711.06841, arXiv:1711.06839", "journal-ref": "IEEE Transactions on Evolutionary Computation, Vol. 18, No. 5, pp.\n  779-789, September 2014", "doi": "10.1109/TEVC.2013.2285111", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates the use of genetic algorithms for evolving: 1) a\ngrandmaster-level evaluation function, and 2) a search mechanism for a chess\nprogram, the parameter values of which are initialized randomly. The evaluation\nfunction of the program is evolved by learning from databases of (human)\ngrandmaster games. At first, the organisms are evolved to mimic the behavior of\nhuman grandmasters, and then these organisms are further improved upon by means\nof coevolution. The search mechanism is evolved by learning from tactical test\nsuites. Our results show that the evolved program outperforms a two-time world\ncomputer chess champion and is at par with the other leading computer chess\nprograms.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 07:24:24 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["David", "Eli", ""], ["Herik", "H. Jaap van den", ""], ["Koppel", "Moshe", ""], ["Netanyahu", "Nathan S.", ""]]}, {"id": "1711.08352", "submitter": "Guoqing Zheng", "authors": "Guoqing Zheng, Yiming Yang, Jaime Carbonell", "title": "Asymmetric Variational Autoencoders", "comments": "ICML 2018 Workshop on Theoretical Foundations and Applications of\n  Deep Generative Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference for latent variable models is prevalent in various\nmachine learning problems, typically solved by maximizing the Evidence Lower\nBound (ELBO) of the true data likelihood with respect to a variational\ndistribution. However, freely enriching the family of variational distribution\nis challenging since the ELBO requires variational likelihood evaluations of\nthe latent variables. In this paper, we propose a novel framework to enrich the\nvariational family by incorporating auxiliary variables to the variational\nfamily. The resulting inference network doesn't require density evaluations for\nthe auxiliary variables and thus complex implicit densities over the auxiliary\nvariables can be constructed by neural networks. It can be shown that the\nactual variational posterior of the proposed approach is essentially modeling a\nrich probabilistic mixture of simple variational posterior indexed by auxiliary\nvariables, thus a flexible inference model can be built. Empirical evaluations\non several density estimation tasks demonstrates the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 21:27:32 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 18:44:43 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Zheng", "Guoqing", ""], ["Yang", "Yiming", ""], ["Carbonell", "Jaime", ""]]}, {"id": "1711.08393", "submitter": "Zuxuan Wu", "authors": "Zuxuan Wu, Tushar Nagarajan, Abhishek Kumar, Steven Rennie, Larry S.\n  Davis, Kristen Grauman, Rogerio Feris", "title": "BlockDrop: Dynamic Inference Paths in Residual Networks", "comments": "CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Very deep convolutional neural networks offer excellent recognition results,\nyet their computational expense limits their impact for many real-world\napplications. We introduce BlockDrop, an approach that learns to dynamically\nchoose which layers of a deep network to execute during inference so as to best\nreduce total computation without degrading prediction accuracy. Exploiting the\nrobustness of Residual Networks (ResNets) to layer dropping, our framework\nselects on-the-fly which residual blocks to evaluate for a given novel image.\nIn particular, given a pretrained ResNet, we train a policy network in an\nassociative reinforcement learning setting for the dual reward of utilizing a\nminimal number of blocks while preserving recognition accuracy. We conduct\nextensive experiments on CIFAR and ImageNet. The results provide strong\nquantitative and qualitative evidence that these learned policies not only\naccelerate inference but also encode meaningful visual information. Built upon\na ResNet-101 model, our method achieves a speedup of 20\\% on average, going as\nhigh as 36\\% for some images, while maintaining the same 76.4\\% top-1 accuracy\non ImageNet.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 17:01:59 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2018 15:18:01 GMT"}, {"version": "v3", "created": "Thu, 12 Apr 2018 20:46:15 GMT"}, {"version": "v4", "created": "Mon, 28 Jan 2019 16:36:44 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Wu", "Zuxuan", ""], ["Nagarajan", "Tushar", ""], ["Kumar", "Abhishek", ""], ["Rennie", "Steven", ""], ["Davis", "Larry S.", ""], ["Grauman", "Kristen", ""], ["Feris", "Rogerio", ""]]}, {"id": "1711.08416", "submitter": "Benjamin Scellier", "authors": "Benjamin Scellier and Yoshua Bengio", "title": "Equivalence of Equilibrium Propagation and Recurrent Backpropagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Backpropagation and Equilibrium Propagation are supervised learning\nalgorithms for fixed point recurrent neural networks which differ in their\nsecond phase. In the first phase, both algorithms converge to a fixed point\nwhich corresponds to the configuration where the prediction is made. In the\nsecond phase, Equilibrium Propagation relaxes to another nearby fixed point\ncorresponding to smaller prediction error, whereas Recurrent Backpropagation\nuses a side network to compute error derivatives iteratively. In this work we\nestablish a close connection between these two algorithms. We show that, at\nevery moment in the second phase, the temporal derivatives of the neural\nactivities in Equilibrium Propagation are equal to the error derivatives\ncomputed iteratively by Recurrent Backpropagation in the side network. This\nwork shows that it is not required to have a side network for the computation\nof error derivatives, and supports the hypothesis that, in biological neural\nnetworks, temporal derivatives of neural activities may code for error signals.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 17:49:58 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 18:19:12 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Scellier", "Benjamin", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1711.08421", "submitter": "Ryan Urbanowicz", "authors": "Ryan J. Urbanowicz, Melissa Meeker, William LaCava, Randal S. Olson,\n  Jason H. Moore", "title": "Relief-Based Feature Selection: Introduction and Review", "comments": "Submitted revisions for publication based on reviews by the Journal\n  of Biomedical Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Feature selection plays a critical role in biomedical data mining, driven by\nincreasing feature dimensionality in target problems and growing interest in\nadvanced but computationally expensive methodologies able to model complex\nassociations. Specifically, there is a need for feature selection methods that\nare computationally efficient, yet sensitive to complex patterns of\nassociation, e.g. interactions, so that informative features are not mistakenly\neliminated prior to downstream modeling. This paper focuses on Relief-based\nalgorithms (RBAs), a unique family of filter-style feature selection algorithms\nthat have gained appeal by striking an effective balance between these\nobjectives while flexibly adapting to various data characteristics, e.g.\nclassification vs. regression. First, this work broadly examines types of\nfeature selection and defines RBAs within that context. Next, we introduce the\noriginal Relief algorithm and associated concepts, emphasizing the intuition\nbehind how it works, how feature weights generated by the algorithm can be\ninterpreted, and why it is sensitive to feature interactions without evaluating\ncombinations of features. Lastly, we include an expansive review of RBA\nmethodological research beyond Relief and its popular descendant, ReliefF. In\nparticular, we characterize branches of RBA research, and provide comparative\nsummaries of RBA algorithms including contributions, strategies, functionality,\ntime complexity, adaptation to key data characteristics, and software\navailability.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 18:06:25 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2018 20:46:42 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Urbanowicz", "Ryan J.", ""], ["Meeker", "Melissa", ""], ["LaCava", "William", ""], ["Olson", "Randal S.", ""], ["Moore", "Jason H.", ""]]}, {"id": "1711.08426", "submitter": "Naman Agarwal", "authors": "Naman Agarwal, Sham Kakade, Rahul Kidambi, Yin Tat Lee, Praneeth\n  Netrapalli, Aaron Sidford", "title": "Leverage Score Sampling for Faster Accelerated Regression and ERM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a matrix $\\mathbf{A}\\in\\mathbb{R}^{n\\times d}$ and a vector $b\n\\in\\mathbb{R}^{d}$, we show how to compute an $\\epsilon$-approximate solution\nto the regression problem $ \\min_{x\\in\\mathbb{R}^{d}}\\frac{1}{2} \\|\\mathbf{A} x\n- b\\|_{2}^{2} $ in time $ \\tilde{O} ((n+\\sqrt{d\\cdot\\kappa_{\\text{sum}}})\\cdot\ns\\cdot\\log\\epsilon^{-1}) $ where\n$\\kappa_{\\text{sum}}=\\mathrm{tr}\\left(\\mathbf{A}^{\\top}\\mathbf{A}\\right)/\\lambda_{\\min}(\\mathbf{A}^{T}\\mathbf{A})$\nand $s$ is the maximum number of non-zero entries in a row of $\\mathbf{A}$. Our\nalgorithm improves upon the previous best running time of $ \\tilde{O}\n((n+\\sqrt{n \\cdot\\kappa_{\\text{sum}}})\\cdot s\\cdot\\log\\epsilon^{-1})$.\n  We achieve our result through a careful combination of leverage score\nsampling techniques, proximal point methods, and accelerated coordinate\ndescent. Our method not only matches the performance of previous methods, but\nfurther improves whenever leverage scores of rows are small (up to\npolylogarithmic factors). We also provide a non-linear generalization of these\nresults that improves the running time for solving a broader class of ERM\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 18:18:22 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Agarwal", "Naman", ""], ["Kakade", "Sham", ""], ["Kidambi", "Rahul", ""], ["Lee", "Yin Tat", ""], ["Netrapalli", "Praneeth", ""], ["Sidford", "Aaron", ""]]}, {"id": "1711.08442", "submitter": "Mayank Kakodkar", "authors": "Pedro H. P. Savarese, Mayank Kakodkar, Bruno Ribeiro", "title": "From Monte Carlo to Las Vegas: Improving Restricted Boltzmann Machine\n  Training Through Stopping Sets", "comments": "AAAI2018, 10 Pages", "journal-ref": "Proceedings of the Thirty-Second {AAAI} Conference on Artificial\n  Intelligence, New Orleans, Louisiana, USA, February 2-7, 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Las Vegas transformation of Markov Chain Monte Carlo (MCMC)\nestimators of Restricted Boltzmann Machines (RBMs). We denote our approach\nMarkov Chain Las Vegas (MCLV). MCLV gives statistical guarantees in exchange\nfor random running times. MCLV uses a stopping set built from the training data\nand has maximum number of Markov chain steps K (referred as MCLV-K). We present\na MCLV-K gradient estimator (LVS-K) for RBMs and explore the correspondence and\ndifferences between LVS-K and Contrastive Divergence (CD-K), with LVS-K\nsignificantly outperforming CD-K training RBMs over the MNIST dataset,\nindicating MCLV to be a promising direction in learning generative models.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 18:38:22 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Savarese", "Pedro H. P.", ""], ["Kakodkar", "Mayank", ""], ["Ribeiro", "Bruno", ""]]}, {"id": "1711.08477", "submitter": "Ryan Urbanowicz", "authors": "Ryan J. Urbanowicz, Randal S. Olson, Peter Schmitt, Melissa Meeker,\n  Jason H. Moore", "title": "Benchmarking Relief-Based Feature Selection Methods for Bioinformatics\n  Data Mining", "comments": "Revised submission to JBI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern biomedical data mining requires feature selection methods that can (1)\nbe applied to large scale feature spaces (e.g. `omics' data), (2) function in\nnoisy problems, (3) detect complex patterns of association (e.g. gene-gene\ninteractions), (4) be flexibly adapted to various problem domains and data\ntypes (e.g. genetic variants, gene expression, and clinical data) and (5) are\ncomputationally tractable. To that end, this work examines a set of\nfilter-style feature selection algorithms inspired by the `Relief' algorithm,\ni.e. Relief-Based algorithms (RBAs). We implement and expand these RBAs in an\nopen source framework called ReBATE (Relief-Based Algorithm Training\nEnvironment). We apply a comprehensive genetic simulation study comparing\nexisting RBAs, a proposed RBA called MultiSURF, and other established feature\nselection methods, over a variety of problems. The results of this study (1)\nsupport the assertion that RBAs are particularly flexible, efficient, and\npowerful feature selection methods that differentiate relevant features having\nunivariate, multivariate, epistatic, or heterogeneous associations, (2) confirm\nthe efficacy of expansions for classification vs. regression, discrete vs.\ncontinuous features, missing data, multiple classes, or class imbalance, (3)\nidentify previously unknown limitations of specific RBAs, and (4) suggest that\nwhile MultiSURF* performs best for explicitly identifying pure 2-way\ninteractions, MultiSURF yields the most reliable feature selection performance\nacross a wide range of problem types.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 19:18:47 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 00:55:05 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Urbanowicz", "Ryan J.", ""], ["Olson", "Randal S.", ""], ["Schmitt", "Peter", ""], ["Meeker", "Melissa", ""], ["Moore", "Jason H.", ""]]}, {"id": "1711.08478", "submitter": "Nicholas Carlini", "authors": "Nicholas Carlini, David Wagner", "title": "MagNet and \"Efficient Defenses Against Adversarial Attacks\" are Not\n  Robust to Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MagNet and \"Efficient Defenses...\" were recently proposed as a defense to\nadversarial examples. We find that we can construct adversarial examples that\ndefeat these defenses with only a slight increase in distortion.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 19:18:52 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Carlini", "Nicholas", ""], ["Wagner", "David", ""]]}, {"id": "1711.08513", "submitter": "Michael P. Kim", "authors": "\\'Ursula H\\'ebert-Johnson, Michael P. Kim, Omer Reingold, Guy N.\n  Rothblum", "title": "Calibration for the (Computationally-Identifiable) Masses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As algorithms increasingly inform and influence decisions made about\nindividuals, it becomes increasingly important to address concerns that these\nalgorithms might be discriminatory. The output of an algorithm can be\ndiscriminatory for many reasons, most notably: (1) the data used to train the\nalgorithm might be biased (in various ways) to favor certain populations over\nothers; (2) the analysis of this training data might inadvertently or\nmaliciously introduce biases that are not borne out in the data. This work\nfocuses on the latter concern.\n  We develop and study multicalbration -- a new measure of algorithmic fairness\nthat aims to mitigate concerns about discrimination that is introduced in the\nprocess of learning a predictor from data. Multicalibration guarantees accurate\n(calibrated) predictions for every subpopulation that can be identified within\na specified class of computations. We think of the class as being quite rich;\nin particular, it can contain many overlapping subgroups of a protected group.\n  We show that in many settings this strong notion of protection from\ndiscrimination is both attainable and aligned with the goal of obtaining\naccurate predictions. Along the way, we present new algorithms for learning a\nmulticalibrated predictor, study the computational complexity of this task, and\ndraw new connections to computational learning models such as agnostic\nlearning.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 21:47:55 GMT"}, {"version": "v2", "created": "Fri, 16 Mar 2018 17:50:06 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["H\u00e9bert-Johnson", "\u00darsula", ""], ["Kim", "Michael P.", ""], ["Reingold", "Omer", ""], ["Rothblum", "Guy N.", ""]]}, {"id": "1711.08534", "submitter": "William Wang", "authors": "William Wang, Angelina Wang, Aviv Tamar, Xi Chen, Pieter Abbeel", "title": "Safer Classification by Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discriminative approach to classification using deep neural networks has\nbecome the de-facto standard in various fields. Complementing recent\nreservations about safety against adversarial examples, we show that\nconventional discriminative methods can easily be fooled to provide incorrect\nlabels with very high confidence to out of distribution examples. We posit that\na generative approach is the natural remedy for this problem, and propose a\nmethod for classification using generative models. At training time, we learn a\ngenerative model for each class, while at test time, given an example to\nclassify, we query each generator for its most similar generation, and select\nthe class corresponding to the most similar one. Our approach is general and\ncan be used with expressive models such as GANs and VAEs. At test time, our\nmethod accurately \"knows when it does not know,\" and provides resilience to out\nof distribution examples while maintaining competitive performance for standard\nexamples.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 23:32:20 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 23:47:59 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Wang", "William", ""], ["Wang", "Angelina", ""], ["Tamar", "Aviv", ""], ["Chen", "Xi", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1711.08589", "submitter": "Benjamin Klein", "authors": "Benjamin Klein and Lior Wolf", "title": "End-to-End Supervised Product Quantization for Image Search and\n  Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Product Quantization, a dictionary based hashing method, is one of the\nleading unsupervised hashing techniques. While it ignores the labels, it\nharnesses the features to construct look up tables that can approximate the\nfeature space. In recent years, several works have achieved state of the art\nresults on hashing benchmarks by learning binary representations in a\nsupervised manner. This work presents Deep Product Quantization (DPQ), a\ntechnique that leads to more accurate retrieval and classification than the\nlatest state of the art methods, while having similar computational complexity\nand memory footprint as the Product Quantization method. To our knowledge, this\nis the first work to introduce a dictionary-based representation that is\ninspired by Product Quantization and which is learned end-to-end, and thus\nbenefits from the supervised signal. DPQ explicitly learns soft and hard\nrepresentations to enable an efficient and accurate asymmetric search, by using\na straight-through estimator. Our method obtains state of the art results on an\nextensive array of retrieval and classification experiments.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 06:40:28 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 22:56:50 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Klein", "Benjamin", ""], ["Wolf", "Lior", ""]]}, {"id": "1711.08594", "submitter": "Shuai Li", "authors": "Shuai Li", "title": "Online Clustering of Contextual Cascading Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a new setting of online clustering of contextual cascading\nbandits, an online learning problem where the underlying cluster structure over\nusers is unknown and needs to be learned from a random prefix feedback. More\nprecisely, a learning agent recommends an ordered list of items to a user, who\nchecks the list and stops at the first satisfactory item, if any. We propose an\nalgorithm of CLUB-cascade for this setting and prove a $T$-step regret bound of\norder $\\tilde{O}(\\sqrt{T})$. Previous work corresponds to the degenerate case\nof only one cluster, and our general regret bound in this special case also\nsignificantly improves theirs. We conduct experiments on both synthetic and\nreal data, and demonstrate the effectiveness of our algorithm and the advantage\nof incorporating online clustering method.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 07:00:22 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 08:58:07 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Li", "Shuai", ""]]}, {"id": "1711.08598", "submitter": "Maxime Voisin", "authors": "Maxime Voisin, Daniel Ritchie", "title": "An Improved Training Procedure for Neural Autoregressive Data Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural autoregressive models are explicit density estimators that achieve\nstate-of-the-art likelihoods for generative modeling. The D-dimensional data\ndistribution is factorized into an autoregressive product of one-dimensional\nconditional distributions according to the chain rule. Data completion is a\nmore involved task than data generation: the model must infer missing variables\nfor any partially observed input vector. Previous work introduced an\norder-agnostic training procedure for data completion with autoregressive\nmodels. Missing variables in any partially observed input vector can be imputed\nefficiently by choosing an ordering where observed dimensions precede\nunobserved ones and by computing the autoregressive product in this order. In\nthis paper, we provide evidence that the order-agnostic (OA) training procedure\nis suboptimal for data completion. We propose an alternative procedure (OA++)\nthat reaches better performance in fewer computations. It can handle all data\ncompletion queries while training fewer one-dimensional conditional\ndistributions than the OA procedure. In addition, these one-dimensional\nconditional distributions are trained proportionally to their expected usage at\ninference time, reducing overfitting. Finally, our OA++ procedure can exploit\nprior knowledge about the distribution of inference completion queries, as\nopposed to OA. We support these claims with quantitative experiments on\nstandard datasets used to evaluate autoregressive generative models.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 07:41:50 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Voisin", "Maxime", ""], ["Ritchie", "Daniel", ""]]}, {"id": "1711.08621", "submitter": "Carolin Lawrence", "authors": "Carolin Lawrence, Pratik Gajane, Stefan Riezler", "title": "Counterfactual Learning for Machine Translation: Degeneracies and\n  Solutions", "comments": "Workshop \"From 'What If?' To 'What Next?'\" at the 31st Conference on\n  Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual learning is a natural scenario to improve web-based machine\ntranslation services by offline learning from feedback logged during user\ninteractions. In order to avoid the risk of showing inferior translations to\nusers, in such scenarios mostly exploration-free deterministic logging policies\nare in place. We analyze possible degeneracies of inverse and reweighted\npropensity scoring estimators, in stochastic and deterministic settings, and\nrelate them to recently proposed techniques for counterfactual learning under\ndeterministic logging.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 08:54:05 GMT"}, {"version": "v2", "created": "Mon, 27 Nov 2017 13:25:49 GMT"}, {"version": "v3", "created": "Thu, 14 Dec 2017 13:47:21 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Lawrence", "Carolin", ""], ["Gajane", "Pratik", ""], ["Riezler", "Stefan", ""]]}, {"id": "1711.08646", "submitter": "Djork-Arn\\'e Clevert", "authors": "Robin Winter, Djork-Arn\\'e Clevert", "title": "IVE-GAN: Invariant Encoding Generative Adversarial Networks", "comments": "under review at ICLR2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are a powerful framework for\ngenerative tasks. However, they are difficult to train and tend to miss modes\nof the true data generation process. Although GANs can learn a rich\nrepresentation of the covered modes of the data in their latent space, the\nframework misses an inverse mapping from data to this latent space. We propose\nInvariant Encoding Generative Adversarial Networks (IVE-GANs), a novel GAN\nframework that introduces such a mapping for individual samples from the data\nby utilizing features in the data which are invariant to certain\ntransformations. Since the model maps individual samples to the latent space,\nit naturally encourages the generator to cover all modes. We demonstrate the\neffectiveness of our approach in terms of generative performance and learning\nrich representations on several datasets including common benchmark image\ngeneration tasks.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 10:36:52 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Winter", "Robin", ""], ["Clevert", "Djork-Arn\u00e9", ""]]}, {"id": "1711.08679", "submitter": "Doo Seok Jeong", "authors": "Guhyun Kim, Vladimir Kornijcuk, Dohun Kim, Inho Kim, Jaewook Kim, Hyo\n  Cheon Woo, Ji Hun Kim, Cheol Seong Hwang, Doo Seok Jeong", "title": "Markov chain Hebbian learning algorithm with ternary synaptic units", "comments": "25 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of remarkable progress in machine learning techniques, the\nstate-of-the-art machine learning algorithms often keep machines from real-time\nlearning (online learning) due in part to computational complexity in parameter\noptimization. As an alternative, a learning algorithm to train a memory in real\ntime is proposed, which is named as the Markov chain Hebbian learning\nalgorithm. The algorithm pursues efficient memory use during training in that\n(i) the weight matrix has ternary elements (-1, 0, 1) and (ii) each update\nfollows a Markov chain--the upcoming update does not need past weight memory.\nThe algorithm was verified by two proof-of-concept tasks (handwritten digit\nrecognition and multiplication table memorization) in which numbers were taken\nas symbols. Particularly, the latter bases multiplication arithmetic on memory,\nwhich may be analogous to humans' mental arithmetic. The memory-based\nmultiplication arithmetic feasibly offers the basis of factorization,\nsupporting novel insight into the arithmetic.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 13:07:37 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Kim", "Guhyun", ""], ["Kornijcuk", "Vladimir", ""], ["Kim", "Dohun", ""], ["Kim", "Inho", ""], ["Kim", "Jaewook", ""], ["Woo", "Hyo Cheon", ""], ["Kim", "Ji Hun", ""], ["Hwang", "Cheol Seong", ""], ["Jeong", "Doo Seok", ""]]}, {"id": "1711.08740", "submitter": "Stylianos Venieris", "authors": "Stylianos I. Venieris and Christos-Savvas Bouganis", "title": "fpgaConvNet: A Toolflow for Mapping Diverse Convolutional Neural\n  Networks on Embedded FPGAs", "comments": "Accepted at NIPS 2017 Workshop on Machine Learning on the Phone and\n  other Consumer Devices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Convolutional Neural Networks (ConvNets) have become an\nenabling technology for a wide range of novel embedded Artificial Intelligence\nsystems. Across the range of applications, the performance needs vary\nsignificantly, from high-throughput video surveillance to the very low-latency\nrequirements of autonomous cars. In this context, FPGAs can provide a potential\nplatform that can be optimally configured based on the different performance\nneeds. However, the complexity of ConvNet models keeps increasing making their\nmapping to an FPGA device a challenging task. This work presents fpgaConvNet,\nan end-to-end framework for mapping ConvNets on FPGAs. The proposed framework\nemploys an automated design methodology based on the Synchronous Dataflow (SDF)\nparadigm and defines a set of SDF transformations in order to efficiently\nexplore the architectural design space. By selectively optimising for\nthroughput, latency or multiobjective criteria, the presented tool is able to\nefficiently explore the design space and generate hardware designs from\nhigh-level ConvNet specifications, explicitly optimised for the performance\nmetric of interest. Overall, our framework yields designs that improve the\nperformance by up to 6.65x over highly optimised embedded GPU designs for the\nsame power constraints in embedded environments.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 15:37:21 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Venieris", "Stylianos I.", ""], ["Bouganis", "Christos-Savvas", ""]]}, {"id": "1711.08742", "submitter": "Jinsung Yoon", "authors": "Jinsung Yoon, William R. Zame, Mihaela van der Schaar", "title": "Estimating Missing Data in Temporal Data Streams Using Multi-directional\n  Recurrent Neural Networks", "comments": "19 pages (including 3 page Appendix and 2 page reference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing data is a ubiquitous problem. It is especially challenging in medical\nsettings because many streams of measurements are collected at different - and\noften irregular - times. Accurate estimation of those missing measurements is\ncritical for many reasons, including diagnosis, prognosis and treatment.\nExisting methods address this estimation problem by interpolating within data\nstreams or imputing across data streams (both of which ignore important\ninformation) or ignoring the temporal aspect of the data and imposing strong\nassumptions about the nature of the data-generating process and/or the pattern\nof missing data (both of which are especially problematic for medical data). We\npropose a new approach, based on a novel deep learning architecture that we\ncall a Multi-directional Recurrent Neural Network (M-RNN) that interpolates\nwithin data streams and imputes across data streams. We demonstrate the power\nof our approach by applying it to five real-world medical datasets. We show\nthat it provides dramatically improved estimation of missing measurements in\ncomparison to 11 state-of-the-art benchmarks (including Spline and Cubic\nInterpolations, MICE, MissForest, matrix completion and several RNN methods);\ntypical improvements in Root Mean Square Error are between 35% - 50%.\nAdditional experiments based on the same five datasets demonstrate that the\nimprovements provided by our method are extremely robust.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 15:39:04 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Yoon", "Jinsung", ""], ["Zame", "William R.", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1711.08762", "submitter": "Eli (Omid) David", "authors": "Dror Sholomon, Eli David, Nathan S. Netanyahu", "title": "DNN-Buddies: A Deep Neural Network-Based Estimation Metric for the\n  Jigsaw Puzzle Problem", "comments": null, "journal-ref": "International Conference on Artificial Neural Networks (ICANN),\n  Springer LNCS, Vol. 9887, pp. 170-178, Barcelona, Spain, September 2016", "doi": "10.1007/978-3-319-44781-0_21", "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the first deep neural network-based estimation metric\nfor the jigsaw puzzle problem. Given two puzzle piece edges, the neural network\npredicts whether or not they should be adjacent in the correct assembly of the\npuzzle, using nothing but the pixels of each piece. The proposed metric\nexhibits an extremely high precision even though no manual feature extraction\nis performed. When incorporated into an existing puzzle solver, the solution's\naccuracy increases significantly, achieving thereby a new state-of-the-art\nstandard.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 16:32:57 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Sholomon", "Dror", ""], ["David", "Eli", ""], ["Netanyahu", "Nathan S.", ""]]}, {"id": "1711.08763", "submitter": "Eli (Omid) David", "authors": "Eli David, Nathan S. Netanyahu", "title": "DeepPainter: Painter Classification Using Deep Convolutional\n  Autoencoders", "comments": null, "journal-ref": "International Conference on Artificial Neural Networks (ICANN),\n  Springer LNCS, Vol. 9887, pp. 20-28, Barcelona, Spain, September 2016", "doi": "10.1007/978-3-319-44781-0_3", "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe the problem of painter classification, and propose\na novel approach based on deep convolutional autoencoder neural networks. While\nprevious approaches relied on image processing and manual feature extraction\nfrom paintings, our approach operates on the raw pixel level, without any\npreprocessing or manual feature extraction. We first train a deep convolutional\nautoencoder on a dataset of paintings, and subsequently use it to initialize a\nsupervised convolutional neural network for the classification phase.\n  The proposed approach substantially outperforms previous methods, improving\nthe previous state-of-the-art for the 3-painter classification problem from\n90.44% accuracy (previous state-of-the-art) to 96.52% accuracy, i.e., a 63%\nreduction in error rate.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 16:36:28 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["David", "Eli", ""], ["Netanyahu", "Nathan S.", ""]]}, {"id": "1711.08770", "submitter": "Pengtao Xie", "authors": "Pengtao Xie, Jun Zhu, Eric P. Xing", "title": "Diversity-Promoting Bayesian Learning of Latent Variable Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address three important issues involved in latent variable models (LVMs),\nincluding capturing infrequent patterns, achieving small-sized but expressive\nmodels and alleviating overfitting, several studies have been devoted to\n\"diversifying\" LVMs, which aim at encouraging the components in LVMs to be\ndiverse. Most existing studies fall into a frequentist-style regularization\nframework, where the components are learned via point estimation. In this\npaper, we investigate how to \"diversify\" LVMs in the paradigm of Bayesian\nlearning. We propose two approaches that have complementary advantages. One is\nto define a diversity-promoting mutual angular prior which assigns larger\ndensity to components with larger mutual angles and use this prior to affect\nthe posterior via Bayes' rule. We develop two efficient approximate posterior\ninference algorithms based on variational inference and MCMC sampling. The\nother approach is to impose diversity-promoting regularization directly over\nthe post-data distribution of components. We also extend our approach to\n\"diversify\" Bayesian nonparametric models where the number of components is\ninfinite. A sampling algorithm based on slice sampling and Hamiltonian Monte\nCarlo is developed. We apply these methods to \"diversify\" Bayesian mixture of\nexperts model and infinite latent feature model. Experiments on various\ndatasets demonstrate the effectiveness and efficiency of our methods.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 16:44:36 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Xie", "Pengtao", ""], ["Zhu", "Jun", ""], ["Xing", "Eric P.", ""]]}, {"id": "1711.08797", "submitter": "S{\\o}ren Dahlgaard", "authors": "S{\\o}ren Dahlgaard, Mathias B{\\ae}k Tejs Knudsen, Mikkel Thorup", "title": "Practical Hash Functions for Similarity Estimation and Dimensionality\n  Reduction", "comments": "Preliminary version of this paper will appear at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hashing is a basic tool for dimensionality reduction employed in several\naspects of machine learning. However, the perfomance analysis is often carried\nout under the abstract assumption that a truly random unit cost hash function\nis used, without concern for which concrete hash function is employed. The\nconcrete hash function may work fine on sufficiently random input. The question\nis if it can be trusted in the real world when faced with more structured\ninput.\n  In this paper we focus on two prominent applications of hashing, namely\nsimilarity estimation with the one permutation hashing (OPH) scheme of Li et\nal. [NIPS'12] and feature hashing (FH) of Weinberger et al. [ICML'09], both of\nwhich have found numerous applications, i.e. in approximate near-neighbour\nsearch with LSH and large-scale classification with SVM.\n  We consider mixed tabulation hashing of Dahlgaard et al.[FOCS'15] which was\nproved to perform like a truly random hash function in many applications,\nincluding OPH. Here we first show improved concentration bounds for FH with\ntruly random hashing and then argue that mixed tabulation performs similar for\nsparse input. Our main contribution, however, is an experimental comparison of\ndifferent hashing schemes when used inside FH, OPH, and LSH.\n  We find that mixed tabulation hashing is almost as fast as the\nmultiply-mod-prime scheme ax+b mod p. Mutiply-mod-prime is guaranteed to work\nwell on sufficiently random data, but we demonstrate that in the above\napplications, it can lead to bias and poor concentration on both real-world and\nsynthetic data. We also compare with the popular MurmurHash3, which has no\nproven guarantees. Mixed tabulation and MurmurHash3 both perform similar to\ntruly random hashing in our experiments. However, mixed tabulation is 40%\nfaster than MurmurHash3, and it has the proven guarantee of good performance on\nall possible input.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 18:27:37 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Dahlgaard", "S\u00f8ren", ""], ["Knudsen", "Mathias B\u00e6k Tejs", ""], ["Thorup", "Mikkel", ""]]}, {"id": "1711.08811", "submitter": "Michela Paganini", "authors": "Michela Paganini", "title": "Machine Learning Algorithms for $b$-Jet Tagging at the ATLAS Experiment", "comments": "7 pages, 5 figures, in proceedings of the 18th International Workshop\n  on Advanced Computing and Analysis Techniques in Physics Research (ACAT 2017)", "journal-ref": null, "doi": null, "report-no": "ATL-PHYS-PROC-2017-211", "categories": "hep-ex cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The separation of $b$-quark initiated jets from those coming from lighter\nquark flavors ($b$-tagging) is a fundamental tool for the ATLAS physics program\nat the CERN Large Hadron Collider. The most powerful $b$-tagging algorithms\ncombine information from low-level taggers, exploiting reconstructed track and\nvertex information, into machine learning classifiers. The potential of modern\ndeep learning techniques is explored using simulated events, and compared to\nthat achievable from more traditional classifiers such as boosted decision\ntrees.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 19:17:45 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Paganini", "Michela", ""]]}, {"id": "1711.08813", "submitter": "Michela Paganini", "authors": "Luke de Oliveira, Michela Paganini, Benjamin Nachman", "title": "Controlling Physical Attributes in GAN-Accelerated Simulation of\n  Electromagnetic Calorimeters", "comments": "7 pages, 5 figures, in proceedings of the 18th International Workshop\n  on Advanced Computing and Analysis Techniques in Physics Research (ACAT 2017)", "journal-ref": null, "doi": "10.1088/1742-6596/1085/4/042017", "report-no": null, "categories": "hep-ex cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-precision modeling of subatomic particle interactions is critical for\nmany fields within the physical sciences, such as nuclear physics and high\nenergy particle physics. Most simulation pipelines in the sciences are\ncomputationally intensive -- in a variety of scientific fields, Generative\nAdversarial Networks have been suggested as a solution to speed up the forward\ncomponent of simulation, with promising results. An important component of any\nsimulation system for the sciences is the ability to condition on any number of\nphysically meaningful latent characteristics that can effect the forward\ngeneration procedure. We introduce an auxiliary task to the training of a\nGenerative Adversarial Network on particle showers in a multi-layer\nelectromagnetic calorimeter, which allows our model to learn an attribute-aware\nconditioning mechanism.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 19:29:50 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["de Oliveira", "Luke", ""], ["Paganini", "Michela", ""], ["Nachman", "Benjamin", ""]]}, {"id": "1711.08833", "submitter": "Bao Wang", "authors": "Bao Wang, Penghang Yin, Andrea L. Bertozzi, P. Jeffrey Brantingham,\n  Stanley J. Osher and Jack Xin", "title": "Deep Learning for Real-Time Crime Forecasting and its Ternarization", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time crime forecasting is important. However, accurate prediction of\nwhen and where the next crime will happen is difficult. No known physical model\nprovides a reasonable approximation to such a complex system. Historical crime\ndata are sparse in both space and time and the signal of interests is weak. In\nthis work, we first present a proper representation of crime data. We then\nadapt the spatial temporal residual network on the well represented data to\npredict the distribution of crime in Los Angeles at the scale of hours in\nneighborhood-sized parcels. These experiments as well as comparisons with\nseveral existing approaches to prediction demonstrate the superiority of the\nproposed model in terms of accuracy. Finally, we present a ternarization\ntechnique to address the resource consumption issue for its deployment in real\nworld. This work is an extension of our short conference proceeding paper [Wang\net al, Arxiv 1707.03340].\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 21:39:40 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Wang", "Bao", ""], ["Yin", "Penghang", ""], ["Bertozzi", "Andrea L.", ""], ["Brantingham", "P. Jeffrey", ""], ["Osher", "Stanley J.", ""], ["Xin", "Jack", ""]]}, {"id": "1711.08841", "submitter": "Pranjal Awasthi", "authors": "Pranjal Awasthi, Aravindan Vijayaraghavan", "title": "Clustering Semi-Random Mixtures of Gaussians", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian mixture models (GMM) are the most widely used statistical model for\nthe $k$-means clustering problem and form a popular framework for clustering in\nmachine learning and data analysis. In this paper, we propose a natural\nsemi-random model for $k$-means clustering that generalizes the Gaussian\nmixture model, and that we believe will be useful in identifying robust\nalgorithms. In our model, a semi-random adversary is allowed to make arbitrary\n\"monotone\" or helpful changes to the data generated from the Gaussian mixture\nmodel.\n  Our first contribution is a polynomial time algorithm that provably recovers\nthe ground-truth up to small classification error w.h.p., assuming certain\nseparation between the components. Perhaps surprisingly, the algorithm we\nanalyze is the popular Lloyd's algorithm for $k$-means clustering that is the\nmethod-of-choice in practice. Our second result complements the upper bound by\ngiving a nearly matching information-theoretic lower bound on the number of\nmisclassified points incurred by any $k$-means clustering algorithm on the\nsemi-random model.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 23:17:37 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "1711.08856", "submitter": "Alessandro Achille", "authors": "Alessandro Achille, Matteo Rovere, Stefano Soatto", "title": "Critical Learning Periods in Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": "UCLA-TR-170017", "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similar to humans and animals, deep artificial neural networks exhibit\ncritical periods during which a temporary stimulus deficit can impair the\ndevelopment of a skill. The extent of the impairment depends on the onset and\nlength of the deficit window, as in animal models, and on the size of the\nneural network. Deficits that do not affect low-level statistics, such as\nvertical flipping of the images, have no lasting effect on performance and can\nbe overcome with further training. To better understand this phenomenon, we use\nthe Fisher Information of the weights to measure the effective connectivity\nbetween layers of a network during training. Counterintuitively, information\nrises rapidly in the early phases of training, and then decreases, preventing\nredistribution of information resources in a phenomenon we refer to as a loss\nof \"Information Plasticity\". Our analysis suggests that the first few epochs\nare critical for the creation of strong connections that are optimal relative\nto the input data distribution. Once such strong connections are created, they\ndo not appear to change during additional training. These findings suggest that\nthe initial learning transient, under-scrutinized compared to asymptotic\nbehavior, plays a key role in determining the outcome of the training process.\nOur findings, combined with recent theoretical results in the literature, also\nsuggest that forgetting (decrease of information in the weights) is critical to\nachieving invariance and disentanglement in representation learning. Finally,\ncritical periods are not restricted to biological systems, but can emerge\nnaturally in learning systems, whether biological or artificial, due to\nfundamental constrains arising from learning dynamics and information\nprocessing.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 01:58:54 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 13:52:02 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 11:08:56 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Achille", "Alessandro", ""], ["Rovere", "Matteo", ""], ["Soatto", "Stefano", ""]]}, {"id": "1711.08870", "submitter": "Namkyu Jung", "authors": "Namkyu Jung, Hyeong In Choi", "title": "Continuous Semantic Topic Embedding Model Using Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the continuous semantic topic embedding model (CSTEM)\nwhich finds latent topic variables in documents using continuous semantic\ndistance function between the topics and the words by means of the variational\nautoencoder(VAE). The semantic distance could be represented by any symmetric\nbell-shaped geometric distance function on the Euclidean space, for which the\nMahalanobis distance is used in this paper. In order for the semantic distance\nto perform more properly, we newly introduce an additional model parameter for\neach word to take out the global factor from this distance indicating how\nlikely it occurs regardless of its topic. It certainly improves the problem\nthat the Gaussian distribution which is used in previous topic model with\ncontinuous word embedding could not explain the semantic relation correctly and\nhelps to obtain the higher topic coherence. Through the experiments with the\ndataset of 20 Newsgroup, NIPS papers and CNN/Dailymail corpus, the performance\nof the recent state-of-the-art models is accomplished by our model as well as\ngenerating topic embedding vectors which makes possible to observe where the\ntopic vectors are embedded with the word vectors in the real Euclidean space\nand how the topics are related each other semantically.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 05:37:35 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Jung", "Namkyu", ""], ["Choi", "Hyeong In", ""]]}, {"id": "1711.08875", "submitter": "Kwonjoon Lee", "authors": "Kwonjoon Lee, Weijian Xu, Fan Fan, Zhuowen Tu", "title": "Wasserstein Introspective Neural Networks", "comments": "Accepted to CVPR 2018 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Wasserstein introspective neural networks (WINN) that are both a\ngenerator and a discriminator within a single model. WINN provides a\nsignificant improvement over the recent introspective neural networks (INN)\nmethod by enhancing INN's generative modeling capability. WINN has three\ninteresting properties: (1) A mathematical connection between the formulation\nof the INN algorithm and that of Wasserstein generative adversarial networks\n(WGAN) is made. (2) The explicit adoption of the Wasserstein distance into INN\nresults in a large enhancement to INN, achieving compelling results even with a\nsingle classifier --- e.g., providing nearly a 20 times reduction in model size\nover INN for unsupervised generative modeling. (3) When applied to supervised\nclassification, WINN also gives rise to improved robustness against adversarial\nexamples in terms of the error reduction. In the experiments, we report\nencouraging results on unsupervised learning problems including texture, face,\nand object modeling, as well as a supervised classification task against\nadversarial attacks.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 06:04:02 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 23:18:09 GMT"}, {"version": "v3", "created": "Sun, 3 Dec 2017 08:32:47 GMT"}, {"version": "v4", "created": "Fri, 8 Dec 2017 03:42:16 GMT"}, {"version": "v5", "created": "Sat, 7 Apr 2018 17:05:25 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Lee", "Kwonjoon", ""], ["Xu", "Weijian", ""], ["Fan", "Fan", ""], ["Tu", "Zhuowen", ""]]}, {"id": "1711.08946", "submitter": "Arash Tavakoli", "authors": "Arash Tavakoli, Fabio Pardo, Petar Kormushev", "title": "Action Branching Architectures for Deep Reinforcement Learning", "comments": "AAAI 2018, NIPS 2017 Deep RL Symposium, code:\n  https://github.com/atavakol/action-branching-agents", "journal-ref": "AAAI 32: 4131-4138 (2018)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete-action algorithms have been central to numerous recent successes of\ndeep reinforcement learning. However, applying these algorithms to\nhigh-dimensional action tasks requires tackling the combinatorial increase of\nthe number of possible actions with the number of action dimensions. This\nproblem is further exacerbated for continuous-action tasks that require fine\ncontrol of actions via discretization. In this paper, we propose a novel neural\narchitecture featuring a shared decision module followed by several network\nbranches, one for each action dimension. This approach achieves a linear\nincrease of the number of network outputs with the number of degrees of freedom\nby allowing a level of independence for each individual action dimension. To\nillustrate the approach, we present a novel agent, called Branching Dueling\nQ-Network (BDQ), as a branching variant of the Dueling Double Deep Q-Network\n(Dueling DDQN). We evaluate the performance of our agent on a set of\nchallenging continuous control tasks. The empirical results show that the\nproposed agent scales gracefully to environments with increasing action\ndimensionality and indicate the significance of the shared decision module in\ncoordination of the distributed action branches. Furthermore, we show that the\nproposed agent performs competitively against a state-of-the-art continuous\ncontrol algorithm, Deep Deterministic Policy Gradient (DDPG).\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 12:45:30 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 04:01:24 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Tavakoli", "Arash", ""], ["Pardo", "Fabio", ""], ["Kormushev", "Petar", ""]]}, {"id": "1711.08992", "submitter": "Kalin Stefanov", "authors": "Kalin Stefanov, Jonas Beskow and Giampiero Salvi", "title": "Self-Supervised Vision-Based Detection of the Active Speaker as Support\n  for Socially-Aware Language Acquisition", "comments": "10 pages, IEEE Transactions on Cognitive and Developmental Systems", "journal-ref": null, "doi": "10.1109/TCDS.2019.2927941", "report-no": null, "categories": "cs.CV cs.CL cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a self-supervised method for visual detection of the\nactive speaker in a multi-person spoken interaction scenario. Active speaker\ndetection is a fundamental prerequisite for any artificial cognitive system\nattempting to acquire language in social settings. The proposed method is\nintended to complement the acoustic detection of the active speaker, thus\nimproving the system robustness in noisy conditions. The method can detect an\narbitrary number of possibly overlapping active speakers based exclusively on\nvisual information about their face. Furthermore, the method does not rely on\nexternal annotations, thus complying with cognitive development. Instead, the\nmethod uses information from the auditory modality to support learning in the\nvisual domain. This paper reports an extensive evaluation of the proposed\nmethod using a large multi-person face-to-face interaction dataset. The results\nshow good performance in a speaker dependent setting. However, in a speaker\nindependent setting the proposed method yields a significantly lower\nperformance. We believe that the proposed method represents an essential\ncomponent of any artificial cognitive system or robotic platform engaging in\nsocial interactions.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 14:45:06 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 17:55:38 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Stefanov", "Kalin", ""], ["Beskow", "Jonas", ""], ["Salvi", "Giampiero", ""]]}, {"id": "1711.09055", "submitter": "Giovanni Saponaro", "authors": "Giovanni Saponaro, Lorenzo Jamone, Alexandre Bernardino and Giampiero\n  Salvi", "title": "Interactive Robot Learning of Gestures, Language and Affordances", "comments": "code available at https://github.com/gsaponaro/glu-gestures", "journal-ref": "International Workshop on Grounding Language Understanding (GLU),\n  Satellite of Interspeech 2017", "doi": "10.21437/GLU.2017-17", "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing field in robotics and Artificial Intelligence (AI) research is\nhuman-robot collaboration, whose target is to enable effective teamwork between\nhumans and robots. However, in many situations human teams are still superior\nto human-robot teams, primarily because human teams can easily agree on a\ncommon goal with language, and the individual members observe each other\neffectively, leveraging their shared motor repertoire and sensorimotor\nresources. This paper shows that for cognitive robots it is possible, and\nindeed fruitful, to combine knowledge acquired from interacting with elements\nof the environment (affordance exploration) with the probabilistic observation\nof another agent's actions.\n  We propose a model that unites (i) learning robot affordances and word\ndescriptions with (ii) statistical recognition of human gestures with vision\nsensors. We discuss theoretical motivations, possible implementations, and we\nshow initial results which highlight that, after having acquired knowledge of\nits surrounding environment, a humanoid robot can generalize this knowledge to\nthe case when it observes another agent (human partner) performing the same\nmotor actions previously executed during training.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 17:34:32 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Saponaro", "Giovanni", ""], ["Jamone", "Lorenzo", ""], ["Bernardino", "Alexandre", ""], ["Salvi", "Giampiero", ""]]}, {"id": "1711.09059", "submitter": "Wojciech Fedorko", "authors": "Shannon Egan, Wojciech Fedorko, Alison Lister, Jannicke Pearkes, Colin\n  Gay", "title": "Long Short-Term Memory (LSTM) networks with jet constituents for boosted\n  top tagging at the LHC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ex cs.LG hep-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate techniques based on engineered features have found wide adoption\nin the identification of jets resulting from hadronic top decays at the Large\nHadron Collider (LHC). Recent Deep Learning developments in this area include\nthe treatment of the calorimeter activation as an image or supplying a list of\njet constituent momenta to a fully connected network. This latter approach\nlends itself well to the use of Recurrent Neural Networks. In this work the\napplicability of architectures incorporating Long Short-Term Memory (LSTM)\nnetworks is explored. Several network architectures, methods of ordering of jet\nconstituents, and input pre-processing are studied. The best performing LSTM\nnetwork achieves a background rejection of 100 for 50% signal efficiency. This\nrepresents more than a factor of two improvement over a fully connected Deep\nNeural Network (DNN) trained on similar types of inputs.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 17:48:21 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Egan", "Shannon", ""], ["Fedorko", "Wojciech", ""], ["Lister", "Alison", ""], ["Pearkes", "Jannicke", ""], ["Gay", "Colin", ""]]}, {"id": "1711.09090", "submitter": "Russell Tsuchida B.E.", "authors": "Russell Tsuchida, Farbod Roosta-Khorasani, Marcus Gallagher", "title": "Invariance of Weight Distributions in Rectified MLPs", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An interesting approach to analyzing neural networks that has received\nrenewed attention is to examine the equivalent kernel of the neural network.\nThis is based on the fact that a fully connected feedforward network with one\nhidden layer, a certain weight distribution, an activation function, and an\ninfinite number of neurons can be viewed as a mapping into a Hilbert space. We\nderive the equivalent kernels of MLPs with ReLU or Leaky ReLU activations for\nall rotationally-invariant weight distributions, generalizing a previous result\nthat required Gaussian weight distributions. Additionally, the Central Limit\nTheorem is used to show that for certain activation functions, kernels\ncorresponding to layers with weight distributions having $0$ mean and finite\nabsolute third moment are asymptotically universal, and are well approximated\nby the kernel corresponding to layers with spherical Gaussian weights. In deep\nnetworks, as depth increases the equivalent kernel approaches a pathological\nfixed point, which can be used to argue why training randomly initialized\nnetworks can be difficult. Our results also have implications for weight\ninitialization.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 05:27:19 GMT"}, {"version": "v2", "created": "Fri, 2 Feb 2018 07:04:51 GMT"}, {"version": "v3", "created": "Fri, 1 Jun 2018 00:11:34 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Tsuchida", "Russell", ""], ["Roosta-Khorasani", "Farbod", ""], ["Gallagher", "Marcus", ""]]}, {"id": "1711.09091", "submitter": "Xiao Dong", "authors": "Xiao Dong, Jiasong Wu, Ling Zhou", "title": "Demystifying AlphaGo Zero as AlphaGo GAN", "comments": "3 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The astonishing success of AlphaGo Zero\\cite{Silver_AlphaGo} invokes a\nworldwide discussion of the future of our human society with a mixed mood of\nhope, anxiousness, excitement and fear. We try to dymystify AlphaGo Zero by a\nqualitative analysis to indicate that AlphaGo Zero can be understood as a\nspecially structured GAN system which is expected to possess an inherent good\nconvergence property. Thus we deduct the success of AlphaGo Zero may not be a\nsign of a new generation of AI.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 08:11:11 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Dong", "Xiao", ""], ["Wu", "Jiasong", ""], ["Zhou", "Ling", ""]]}, {"id": "1711.09115", "submitter": "Can Kanbak", "authors": "Can Kanbak, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard", "title": "Geometric robustness of deep networks: analysis and improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks have been shown to be vulnerable to\narbitrary geometric transformations. However, there is no systematic method to\nmeasure the invariance properties of deep networks to such transformations. We\npropose ManiFool as a simple yet scalable algorithm to measure the invariance\nof deep networks. In particular, our algorithm measures the robustness of deep\nnetworks to geometric transformations in a worst-case regime as they can be\nproblematic for sensitive applications. Our extensive experimental results show\nthat ManiFool can be used to measure the invariance of fairly complex networks\non high dimensional datasets and these values can be used for analyzing the\nreasons for it. Furthermore, we build on Manifool to propose a new adversarial\ntraining scheme and we show its effectiveness on improving the invariance\nproperties of deep neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 19:32:57 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Kanbak", "Can", ""], ["Moosavi-Dezfooli", "Seyed-Mohsen", ""], ["Frossard", "Pascal", ""]]}, {"id": "1711.09156", "submitter": "Brijnesh Jain", "authors": "Brijnesh J. Jain", "title": "Warped-Linear Models for Time Series Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes and studies warped-linear models for time series\nclassification. The proposed models are time-warp invariant analogues of linear\nmodels. Their construction is in line with time series averaging and extensions\nof k-means and learning vector quantization to dynamic time warping (DTW)\nspaces. The main theoretical result is that warped-linear models correspond to\npolyhedral classifiers in Euclidean spaces. This result simplifies the analysis\nof time-warp invariant models by reducing to max-linear functions. We exploit\nthis relationship and derive solutions to the label-dependency problem and the\nproblem of learning warped-linear models. Empirical results on time series\nclassification suggest that warped-linear functions better trade solution\nquality against computation time than nearest-neighbor and prototype-based\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 22:22:41 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Jain", "Brijnesh J.", ""]]}, {"id": "1711.09159", "submitter": "Momchil Peychev", "authors": "Momchil Peychev, Petar Veli\\v{c}kovi\\'c, Pietro Li\\`o", "title": "Quantifying the Effects of Enforcing Disentanglement on Variational\n  Autoencoders", "comments": "Accepted to the Workshop on Learning Disentangled Representations at\n  the 31st Annual Conference on Neural Information Processing Systems (NIPS\n  2017), 5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of disentangled autoencoders was proposed as an extension to the\nvariational autoencoder by introducing a disentanglement parameter $\\beta$,\ncontrolling the learning pressure put on the possible underlying latent\nrepresentations. For certain values of $\\beta$ this kind of autoencoders is\ncapable of encoding independent input generative factors in separate elements\nof the code, leading to a more interpretable and predictable model behaviour.\nIn this paper we quantify the effects of the parameter $\\beta$ on the model\nperformance and disentanglement. After training multiple models with the same\nvalue of $\\beta$, we establish the existence of consistent variance in one of\nthe disentanglement measures, proposed in literature. The negative consequences\nof the disentanglement to the autoencoder's discriminative ability are also\nasserted while varying the amount of examples available during training.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 22:28:48 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Peychev", "Momchil", ""], ["Veli\u010dkovi\u0107", "Petar", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "1711.09163", "submitter": "Ershad Banijamali Mr.", "authors": "Ershad Banijamali, Amir-Hossein Karimi, Alexander Wong, Ali Ghodsi", "title": "JADE: Joint Autoencoders for Dis-Entanglement", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of feature disentanglement has been explored in the literature,\nfor the purpose of image and video processing and text analysis.\nState-of-the-art methods for disentangling feature representations rely on the\npresence of many labeled samples. In this work, we present a novel method for\ndisentangling factors of variation in data-scarce regimes. Specifically, we\nexplore the application of feature disentangling for the problem of supervised\nclassification in a setting where few labeled samples exist, and there are no\nunlabeled samples for use in unsupervised training. Instead, a similar datasets\nexists which shares at least one direction of variation with the\nsample-constrained datasets. We train our model end-to-end using the framework\nof variational autoencoders and are able to experimentally demonstrate that\nusing an auxiliary dataset with similar variation factors contribute positively\nto classification performance, yielding competitive results with the\nstate-of-the-art in unsupervised learning.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 22:58:10 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Banijamali", "Ershad", ""], ["Karimi", "Amir-Hossein", ""], ["Wong", "Alexander", ""], ["Ghodsi", "Ali", ""]]}, {"id": "1711.09165", "submitter": "Ershad Banijamali Mr.", "authors": "Ershad Banijamali, Ahmad Khajenezhad, Ali Ghodsi, Mohammad Ghavamzadeh", "title": "Disentangling Dynamics and Content for Control and Planning", "comments": "5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, We study the problem of learning a controllable representation\nfor high-dimensional observations of dynamical systems. Specifically, we\nconsider a situation where there are multiple sets of observations of dynamical\nsystems with identical underlying dynamics. Only one of these sets has\ninformation about the effect of actions on the observation and the rest are\njust some random observations of the system. Our goal is to utilize the\ninformation in that one set and find a representation for the other sets that\ncan be used for planning and ling-term prediction.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 23:17:43 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Banijamali", "Ershad", ""], ["Khajenezhad", "Ahmad", ""], ["Ghodsi", "Ali", ""], ["Ghavamzadeh", "Mohammad", ""]]}, {"id": "1711.09176", "submitter": "Jonathan Schneider", "authors": "Mark Braverman, Jieming Mao, Jon Schneider, S. Matthew Weinberg", "title": "Selling to a No-Regret Buyer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of a single seller repeatedly selling a single item\nto a single buyer (specifically, the buyer has a value drawn fresh from known\ndistribution $D$ in every round). Prior work assumes that the buyer is fully\nrational and will perfectly reason about how their bids today affect the\nseller's decisions tomorrow. In this work we initiate a different direction:\nthe buyer simply runs a no-regret learning algorithm over possible bids. We\nprovide a fairly complete characterization of optimal auctions for the seller\nin this domain. Specifically:\n  - If the buyer bids according to EXP3 (or any \"mean-based\" learning\nalgorithm), then the seller can extract expected revenue arbitrarily close to\nthe expected welfare. This auction is independent of the buyer's valuation $D$,\nbut somewhat unnatural as it is sometimes in the buyer's interest to overbid. -\nThere exists a learning algorithm $\\mathcal{A}$ such that if the buyer bids\naccording to $\\mathcal{A}$ then the optimal strategy for the seller is simply\nto post the Myerson reserve for $D$ every round. - If the buyer bids according\nto EXP3 (or any \"mean-based\" learning algorithm), but the seller is restricted\nto \"natural\" auction formats where overbidding is dominated (e.g. Generalized\nFirst-Price or Generalized Second-Price), then the optimal strategy for the\nseller is a pay-your-bid format with decreasing reserves over time. Moreover,\nthe seller's optimal achievable revenue is characterized by a linear program,\nand can be unboundedly better than the best truthful auction yet simultaneously\nunboundedly worse than the expected welfare.\n", "versions": [{"version": "v1", "created": "Sat, 25 Nov 2017 01:35:45 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Braverman", "Mark", ""], ["Mao", "Jieming", ""], ["Schneider", "Jon", ""], ["Weinberg", "S. Matthew", ""]]}, {"id": "1711.09195", "submitter": "Vincent Zhao", "authors": "Vincent Zhao, Steven W. Zucker", "title": "Feature Selection Facilitates Learning Mixtures of Discrete Product\n  Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection can facilitate the learning of mixtures of discrete random\nvariables as they arise, e.g. in crowdsourcing tasks. Intuitively, not all\nworkers are equally reliable but, if the less reliable ones could be\neliminated, then learning should be more robust. By analogy with Gaussian\nmixture models, we seek a low-order statistical approach, and here introduce an\nalgorithm based on the (pairwise) mutual information. This induces an order\nover workers that is well structured for the `one coin' model. More generally,\nit is justified by a goodness-of-fit measure and is validated empirically.\nImprovement in real data sets can be substantial.\n", "versions": [{"version": "v1", "created": "Sat, 25 Nov 2017 05:34:48 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Zhao", "Vincent", ""], ["Zucker", "Steven W.", ""]]}, {"id": "1711.09219", "submitter": "Shuai Zhang", "authors": "Shuai Zhang, Jianxin Li, Pengtao Xie, Yingchun Zhang, Minglai Shao,\n  Haoyi Zhou, Mengyi Yan", "title": "Stacked Kernel Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods are powerful tools to capture nonlinear patterns behind data.\nThey implicitly learn high (even infinite) dimensional nonlinear features in\nthe Reproducing Kernel Hilbert Space (RKHS) while making the computation\ntractable by leveraging the kernel trick. Classic kernel methods learn a single\nlayer of nonlinear features, whose representational power may be limited.\nMotivated by recent success of deep neural networks (DNNs) that learn\nmulti-layer hierarchical representations, we propose a Stacked Kernel Network\n(SKN) that learns a hierarchy of RKHS-based nonlinear features. SKN interleaves\nseveral layers of nonlinear transformations (from a linear space to a RKHS) and\nlinear transformations (from a RKHS to a linear space). Similar to DNNs, a SKN\nis composed of multiple layers of hidden units, but each parameterized by a\nRKHS function rather than a finite-dimensional vector. We propose three ways to\nrepresent the RKHS functions in SKN: (1)nonparametric representation,\n(2)parametric representation and (3)random Fourier feature representation.\nFurthermore, we expand SKN into CNN architecture called Stacked Kernel\nConvolutional Network (SKCN). SKCN learning a hierarchy of RKHS-based nonlinear\nfeatures by convolutional operation with each filter also parameterized by a\nRKHS function rather than a finite-dimensional matrix in CNN, which is suitable\nfor image inputs. Experiments on various datasets demonstrate the effectiveness\nof SKN and SKCN, which outperform the competitive methods.\n", "versions": [{"version": "v1", "created": "Sat, 25 Nov 2017 09:01:40 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Zhang", "Shuai", ""], ["Li", "Jianxin", ""], ["Xie", "Pengtao", ""], ["Zhang", "Yingchun", ""], ["Shao", "Minglai", ""], ["Zhou", "Haoyi", ""], ["Yan", "Mengyi", ""]]}, {"id": "1711.09220", "submitter": "Alberto Bemporad Prof.", "authors": "A. Bemporad, V. Breschi, D. Piga, S. Boyd", "title": "Fitting Jump Models", "comments": "Accepted for publication in Automatica", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new framework for fitting jump models to a sequence of data.\nThe key idea is to alternate between minimizing a loss function to fit multiple\nmodel parameters, and minimizing a discrete loss function to determine which\nset of model parameters is active at each data point. The framework is quite\ngeneral and encompasses popular classes of models, such as hidden Markov models\nand piecewise affine models. The shape of the chosen loss functions to minimize\ndetermine the shape of the resulting jump model.\n", "versions": [{"version": "v1", "created": "Sat, 25 Nov 2017 09:07:56 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 08:36:18 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Bemporad", "A.", ""], ["Breschi", "V.", ""], ["Piga", "D.", ""], ["Boyd", "S.", ""]]}, {"id": "1711.09223", "submitter": "Pranav Rajpurkar", "authors": "Pranav Rajpurkar, Vinaya Polamreddi, Anusha Balakrishnan", "title": "Malaria Likelihood Prediction By Effectively Surveying Households Using\n  Deep Reinforcement Learning", "comments": "Accepted at NIPS 2017 Workshop on Machine Learning for Health (NIPS\n  2017 ML4H)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build a deep reinforcement learning (RL) agent that can predict the\nlikelihood of an individual testing positive for malaria by asking questions\nabout their household. The RL agent learns to determine which survey question\nto ask next and when to stop to make a prediction about their likelihood of\nmalaria based on their responses hitherto. The agent incurs a small penalty for\neach question asked, and a large reward/penalty for making the correct/wrong\nprediction; it thus has to learn to balance the length of the survey with the\naccuracy of its final predictions. Our RL agent is a Deep Q-network that learns\na policy directly from the responses to the questions, with an action defined\nfor each possible survey question and for each possible prediction class. We\nfocus on Kenya, where malaria is a massive health burden, and train the RL\nagent on a dataset of 6481 households from the Kenya Malaria Indicator Survey\n2015. To investigate the importance of having survey questions be adaptive to\nresponses, we compare our RL agent to a supervised learning (SL) baseline that\nfixes its set of survey questions a priori. We evaluate on prediction accuracy\nand on the number of survey questions asked on a holdout set and find that the\nRL agent is able to predict with 80% accuracy, using only 2.5 questions on\naverage. In addition, the RL agent learns to survey adaptively to responses and\nis able to match the SL baseline in prediction accuracy while significantly\nreducing survey length.\n", "versions": [{"version": "v1", "created": "Sat, 25 Nov 2017 09:33:05 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Rajpurkar", "Pranav", ""], ["Polamreddi", "Vinaya", ""], ["Balakrishnan", "Anusha", ""]]}, {"id": "1711.09256", "submitter": "Benjamin Paassen", "authors": "Benjamin Paa{\\ss}en and Alexander Schulz and Janne Hahne and Barbara\n  Hammer", "title": "Expectation maximization transfer learning and its application for\n  bionic hand prostheses", "comments": "accepted for publication in a special issue of the Journal\n  'Neurocomputing' for extended contributions of the 25h European Symposium on\n  Artificial Neural Networks (ESANN 2017)", "journal-ref": "Neurocomputing 298 (2018) 122-133", "doi": "10.1016/j.neucom.2017.11.072", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models in practical settings are typically confronted with\nchanges to the distribution of the incoming data. Such changes can severely\naffect the model performance, leading for example to misclassifications of\ndata. This is particularly apparent in the domain of bionic hand prostheses,\nwhere machine learning models promise faster and more intuitive user\ninterfaces, but are hindered by their lack of robustness to everyday\ndisturbances, such as electrode shifts. One way to address changes in the data\ndistribution is transfer learning, that is, to transfer the disturbed data to a\nspace where the original model is applicable again. In this contribution, we\npropose a novel expectation maximization algorithm to learn linear\ntransformations that maximize the likelihood of disturbed data after the\ntransformation. We also show that this approach generalizes to discriminative\nmodels, in particular learning vector quantization models. In our evaluation on\ndata from the bionic prostheses domain we demonstrate that our approach can\nlearn a transformation which improves classification accuracy significantly and\noutperforms all tested baselines, if few data or few classes are available in\nthe target domain.\n", "versions": [{"version": "v1", "created": "Sat, 25 Nov 2017 16:04:07 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Paa\u00dfen", "Benjamin", ""], ["Schulz", "Alexander", ""], ["Hahne", "Janne", ""], ["Hammer", "Barbara", ""]]}, {"id": "1711.09268", "submitter": "Daniel L\\'evy", "authors": "Daniel Levy, Matthew D. Hoffman, Jascha Sohl-Dickstein", "title": "Generalizing Hamiltonian Monte Carlo with Neural Networks", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general-purpose method to train Markov chain Monte Carlo\nkernels, parameterized by deep neural networks, that converge and mix quickly\nto their target distribution. Our method generalizes Hamiltonian Monte Carlo\nand is trained to maximize expected squared jumped distance, a proxy for mixing\nspeed. We demonstrate large empirical gains on a collection of simple but\nchallenging distributions, for instance achieving a 106x improvement in\neffective sample size in one case, and mixing when standard HMC makes no\nmeasurable progress in a second. Finally, we show quantitative and qualitative\ngains on a real-world task: latent-variable generative modeling. We release an\nopen source TensorFlow implementation of the algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 25 Nov 2017 18:08:02 GMT"}, {"version": "v2", "created": "Fri, 12 Jan 2018 06:55:12 GMT"}, {"version": "v3", "created": "Fri, 2 Mar 2018 21:05:40 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Levy", "Daniel", ""], ["Hoffman", "Matthew D.", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1711.09279", "submitter": "Ritvik Shrivastava", "authors": "Anand Gupta, Hardeo Thakur, Ritvik Shrivastava, Pulkit Kumar, Sreyashi\n  Nag", "title": "A Big Data Analysis Framework Using Apache Spark and Deep Learning", "comments": "To be published in IEEE ICDM 2017 (International Conference on Data\n  Mining) Workshop on Data Science and Big Data Analytics (DSBDA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the spreading prevalence of Big Data, many advances have recently been\nmade in this field. Frameworks such as Apache Hadoop and Apache Spark have\ngained a lot of traction over the past decades and have become massively\npopular, especially in industries. It is becoming increasingly evident that\neffective big data analysis is key to solving artificial intelligence problems.\nThus, a multi-algorithm library was implemented in the Spark framework, called\nMLlib. While this library supports multiple machine learning algorithms, there\nis still scope to use the Spark setup efficiently for highly time-intensive and\ncomputationally expensive procedures like deep learning. In this paper, we\npropose a novel framework that combines the distributive computational\nabilities of Apache Spark and the advanced machine learning architecture of a\ndeep multi-layer perceptron (MLP), using the popular concept of Cascade\nLearning. We conduct empirical analysis of our framework on two real world\ndatasets. The results are encouraging and corroborate our proposed framework,\nin turn proving that it is an improvement over traditional big data analysis\nmethods that use either Spark or Deep learning as individual elements.\n", "versions": [{"version": "v1", "created": "Sat, 25 Nov 2017 20:11:41 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Gupta", "Anand", ""], ["Thakur", "Hardeo", ""], ["Shrivastava", "Ritvik", ""], ["Kumar", "Pulkit", ""], ["Nag", "Sreyashi", ""]]}, {"id": "1711.09294", "submitter": "Andrea Locatelli", "authors": "Andrea Locatelli, Alexandra Carpentier, Samory Kpotufe", "title": "An Adaptive Strategy for Active Learning with Smooth Decision Boundary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first adaptive strategy for active learning in the setting of\nclassification with smooth decision boundary. The problem of adaptivity (to\nunknown distributional parameters) has remained opened since the seminal work\nof Castro and Nowak (2007), which first established (active learning) rates for\nthis setting. While some recent advances on this problem establish adaptive\nrates in the case of univariate data, adaptivity in the more practical setting\nof multivariate data has so far remained elusive. Combining insights from\nvarious recent works, we show that, for the multivariate case, a careful\nreduction to univariate-adaptive strategies yield near-optimal rates without\nprior knowledge of distributional parameters.\n", "versions": [{"version": "v1", "created": "Sat, 25 Nov 2017 21:23:46 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Locatelli", "Andrea", ""], ["Carpentier", "Alexandra", ""], ["Kpotufe", "Samory", ""]]}, {"id": "1711.09300", "submitter": "Pengtao Xie", "authors": "Pengtao Xie, Hongbao Zhang, Eric P. Xing", "title": "Learning Less-Overlapping Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In representation learning (RL), how to make the learned representations easy\nto interpret and less overfitted to training data are two important but\nchallenging issues. To address these problems, we study a new type of\nregulariza- tion approach that encourages the supports of weight vectors in RL\nmodels to have small overlap, by simultaneously promoting near-orthogonality\namong vectors and sparsity of each vector. We apply the proposed regularizer to\ntwo models: neural networks (NNs) and sparse coding (SC), and develop an\nefficient ADMM-based algorithm for regu- larized SC. Experiments on various\ndatasets demonstrate that weight vectors learned under our regularizer are more\ninterpretable and have better generalization performance.\n", "versions": [{"version": "v1", "created": "Sat, 25 Nov 2017 21:52:14 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Xie", "Pengtao", ""], ["Zhang", "Hongbao", ""], ["Xing", "Eric P.", ""]]}, {"id": "1711.09306", "submitter": "Vassilis N. Ioannidis", "authors": "Vassilis N. Ioannidis, Daniel Romero, Georgios B. Giannakis", "title": "Inference of Spatio-Temporal Functions over Graphs via Multi-Kernel\n  Kriged Kalman Filtering", "comments": "Submitted to IEEE Transactions on Signal processing, Nov. 2017", "journal-ref": null, "doi": "10.1109/TSP.2018.2827328", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference of space-time varying signals on graphs emerges naturally in a\nplethora of network science related applications. A frequently encountered\nchallenge pertains to reconstructing such dynamic processes, given their values\nover a subset of vertices and time instants. The present paper develops a\ngraph-aware kernel-based kriged Kalman filter that accounts for the\nspatio-temporal variations, and offers efficient online reconstruction, even\nfor dynamically evolving network topologies. The kernel-based learning\nframework bypasses the need for statistical information by capitalizing on the\nsmoothness that graph signals exhibit with respect to the underlying graph. To\naddress the challenge of selecting the appropriate kernel, the proposed filter\nis combined with a multi-kernel selection module. Such a data-driven method\nselects a kernel attuned to the signal dynamics on-the-fly within the linear\nspan of a pre-selected dictionary. The novel multi-kernel learning algorithm\nexploits the eigenstructure of Laplacian kernel matrices to reduce\ncomputational complexity. Numerical tests with synthetic and real data\ndemonstrate the superior reconstruction performance of the novel approach\nrelative to state-of-the-art alternatives.\n", "versions": [{"version": "v1", "created": "Sat, 25 Nov 2017 23:25:49 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Ioannidis", "Vassilis N.", ""], ["Romero", "Daniel", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1711.09325", "submitter": "Kimin Lee", "authors": "Kimin Lee, Honglak Lee, Kibok Lee, Jinwoo Shin", "title": "Training Confidence-calibrated Classifiers for Detecting\n  Out-of-Distribution Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of detecting whether a test sample is from in-distribution (i.e.,\ntraining distribution by a classifier) or out-of-distribution sufficiently\ndifferent from it arises in many real-world machine learning applications.\nHowever, the state-of-art deep neural networks are known to be highly\noverconfident in their predictions, i.e., do not distinguish in- and\nout-of-distributions. Recently, to handle this issue, several threshold-based\ndetectors have been proposed given pre-trained neural classifiers. However, the\nperformance of prior works highly depends on how to train the classifiers since\nthey only focus on improving inference procedures. In this paper, we develop a\nnovel training method for classifiers so that such inference algorithms can\nwork better. In particular, we suggest two additional terms added to the\noriginal loss (e.g., cross entropy). The first one forces samples from\nout-of-distribution less confident by the classifier and the second one is for\n(implicitly) generating most effective training samples for the first one. In\nessence, our method jointly trains both classification and generative neural\nnetworks for out-of-distribution. We demonstrate its effectiveness using deep\nconvolutional neural networks on various popular image datasets.\n", "versions": [{"version": "v1", "created": "Sun, 26 Nov 2017 02:50:39 GMT"}, {"version": "v2", "created": "Fri, 1 Dec 2017 10:03:12 GMT"}, {"version": "v3", "created": "Fri, 23 Feb 2018 19:42:15 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Lee", "Kimin", ""], ["Lee", "Honglak", ""], ["Lee", "Kibok", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1711.09337", "submitter": "Donghan Yu", "authors": "Donghan Yu, Yong Li, Fengli Xu, Pengyu Zhang, Vassilis Kostakos", "title": "Smartphone App Usage Prediction Using Points of Interest", "comments": "21 pages, 6 figures, accepted by UbiComp 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the first population-level, city-scale analysis of\napplication usage on smartphones. Using deep packet inspection at the network\noperator level, we obtained a geo-tagged dataset with more than 6 million\nunique devices that launched more than 10,000 unique applications across the\ncity of Shanghai over one week. We develop a technique that leverages transfer\nlearning to predict which applications are most popular and estimate the whole\nusage distribution based on the Point of Interest (POI) information of that\nparticular location. We demonstrate that our technique has an 83.0% hitrate in\nsuccessfully identifying the top five popular applications, and a 0.15 RMSE\nwhen estimating usage with just 10% sampled sparse data. It outperforms by\nabout 25.7% over the existing state-of-the-art approaches. Our findings pave\nthe way for predicting which apps are relevant to a user given their current\nlocation, and which applications are popular where. The implications of our\nfindings are broad: it enables a range of systems to benefit from such timely\npredictions, including operating systems, network operators, appstores,\nadvertisers, and service providers.\n", "versions": [{"version": "v1", "created": "Sun, 26 Nov 2017 06:04:39 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Yu", "Donghan", ""], ["Li", "Yong", ""], ["Xu", "Fengli", ""], ["Zhang", "Pengyu", ""], ["Kostakos", "Vassilis", ""]]}, {"id": "1711.09395", "submitter": "Igor Melnyk", "authors": "Igor Melnyk, Cicero Nogueira dos Santos, Kahini Wadhawan, Inkit Padhi,\n  Abhishek Kumar", "title": "Improved Neural Text Attribute Transfer with Non-parallel Data", "comments": "NIPS 2017 Workshop on Learning Disentangled Representations: from\n  Perception to Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text attribute transfer using non-parallel data requires methods that can\nperform disentanglement of content and linguistic attributes. In this work, we\npropose multiple improvements over the existing approaches that enable the\nencoder-decoder framework to cope with the text attribute transfer from\nnon-parallel data. We perform experiments on the sentiment transfer task using\ntwo datasets. For both datasets, our proposed method outperforms a strong\nbaseline in two of the three employed evaluation metrics.\n", "versions": [{"version": "v1", "created": "Sun, 26 Nov 2017 14:42:52 GMT"}, {"version": "v2", "created": "Mon, 4 Dec 2017 23:20:56 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Melnyk", "Igor", ""], ["Santos", "Cicero Nogueira dos", ""], ["Wadhawan", "Kahini", ""], ["Padhi", "Inkit", ""], ["Kumar", "Abhishek", ""]]}, {"id": "1711.09404", "submitter": "Andrew Ross", "authors": "Andrew Slavin Ross, Finale Doshi-Velez", "title": "Improving the Adversarial Robustness and Interpretability of Deep Neural\n  Networks by Regularizing their Input Gradients", "comments": "To appear in AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have proven remarkably effective at solving many\nclassification problems, but have been criticized recently for two major\nweaknesses: the reasons behind their predictions are uninterpretable, and the\npredictions themselves can often be fooled by small adversarial perturbations.\nThese problems pose major obstacles for the adoption of neural networks in\ndomains that require security or transparency. In this work, we evaluate the\neffectiveness of defenses that differentiably penalize the degree to which\nsmall changes in inputs can alter model predictions. Across multiple attacks,\narchitectures, defenses, and datasets, we find that neural networks trained\nwith this input gradient regularization exhibit robustness to transferred\nadversarial examples generated to fool all of the other models. We also find\nthat adversarial examples generated to fool gradient-regularized models fool\nall other models equally well, and actually lead to more \"legitimate,\"\ninterpretable misclassifications as rated by people (which we confirm in a\nhuman subject experiment). Finally, we demonstrate that regularizing input\ngradients makes them more naturally interpretable as rationales for model\npredictions. We conclude by discussing this relationship between\ninterpretability and robustness in deep neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 26 Nov 2017 15:20:46 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Ross", "Andrew Slavin", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1711.09414", "submitter": "Boyu Liu", "authors": "Boyu Liu, Yanzhao Wang, Yu-Wing Tai, Chi-Keung Tang", "title": "MAVOT: Memory-Augmented Video Object Tracking", "comments": "Submitted to CVPR2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a one-shot learning approach for video object tracking. The\nproposed algorithm requires seeing the object to be tracked only once, and\nemploys an external memory to store and remember the evolving features of the\nforeground object as well as backgrounds over time during tracking. With the\nrelevant memory retrieved and updated in each tracking, our tracking model is\ncapable of maintaining long-term memory of the object, and thus can naturally\ndeal with hard tracking scenarios including partial and total occlusion, motion\nchanges and large scale and shape variations. In our experiments we use the\nImageNet ILSVRC2015 video detection dataset to train and use the VOT-2016\nbenchmark to test and compare our Memory-Augmented Video Object Tracking\n(MAVOT) model. From the results, we conclude that given its oneshot property\nand simplicity in design, MAVOT is an attractive approach in visual tracking\nbecause it shows good performance on VOT-2016 benchmark and is among the top 5\nperformers in accuracy and robustness in occlusion, motion changes and empty\ntarget.\n", "versions": [{"version": "v1", "created": "Sun, 26 Nov 2017 16:20:45 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Liu", "Boyu", ""], ["Wang", "Yanzhao", ""], ["Tai", "Yu-Wing", ""], ["Tang", "Chi-Keung", ""]]}, {"id": "1711.09482", "submitter": "Housam Khalifa Bashier Babiker", "authors": "Housam Khalifa Bashier Babiker and Randy Goebel", "title": "An Introduction to Deep Visual Explanation", "comments": "Accepted at NIPS 2017 - Workshop Interpreting, Explaining and\n  Visualizing Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The practical impact of deep learning on complex supervised learning problems\nhas been significant, so much so that almost every Artificial Intelligence\nproblem, or at least a portion thereof, has been somehow recast as a deep\nlearning problem. The applications appeal is significant, but this appeal is\nincreasingly challenged by what some call the challenge of explainability, or\nmore generally the more traditional challenge of debuggability: if the outcomes\nof a deep learning process produce unexpected results (e.g., less than expected\nperformance of a classifier), then there is little available in the way of\ntheories or tools to help investigate the potential causes of such unexpected\nbehavior, especially when this behavior could impact people's lives. We\ndescribe a preliminary framework to help address this issue, which we call\n\"deep visual explanation\" (DVE). \"Deep,\" because it is the development and\nperformance of deep neural network models that we want to understand. \"Visual,\"\nbecause we believe that the most rapid insight into a complex multi-dimensional\nmodel is provided by appropriate visualization techniques, and \"Explanation,\"\nbecause in the spectrum from instrumentation by inserting print statements to\nthe abductive inference of explanatory hypotheses, we believe that the key to\nunderstanding deep learning relies on the identification and exposure of\nhypotheses about the performance behavior of a learned deep model. In the\nexposition of our preliminary framework, we use relatively straightforward\nimage classification examples and a variety of choices on initial configuration\nof a deep model building scenario. By careful but not complicated\ninstrumentation, we expose classification outcomes of deep models using\nvisualization, and also show initial results for one potential application of\ninterpretability.\n", "versions": [{"version": "v1", "created": "Sun, 26 Nov 2017 22:54:18 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 19:18:33 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Babiker", "Housam Khalifa Bashier", ""], ["Goebel", "Randy", ""]]}, {"id": "1711.09511", "submitter": "Yafeng Liu", "authors": "Yafeng Liu, Shimin Feng, Zhikai Zhao and Enjie Ding", "title": "Highly Efficient Human Action Recognition with Quantum Genetic Algorithm\n  Optimized Support Vector Machine", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose the use of quantum genetic algorithm to optimize the\nsupport vector machine (SVM) for human action recognition. The Microsoft Kinect\nsensor can be used for skeleton tracking, which provides the joints' position\ndata. However, how to extract the motion features for representing the dynamics\nof a human skeleton is still a challenge due to the complexity of human motion.\nWe present a highly efficient features extraction method for action\nclassification, that is, using the joint angles to represent a human skeleton\nand calculating the variance of each angle during an action time window. Using\nthe proposed representation, we compared the human action classification\naccuracy of two approaches, including the optimized SVM based on quantum\ngenetic algorithm and the conventional SVM with grid search. Experimental\nresults on the MSR-12 dataset show that the conventional SVM achieved an\naccuracy of $ 93.85\\% $. The proposed approach outperforms the conventional\nmethod with an accuracy of $ 96.15\\% $.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 02:39:29 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 03:05:55 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Liu", "Yafeng", ""], ["Feng", "Shimin", ""], ["Zhao", "Zhikai", ""], ["Ding", "Enjie", ""]]}, {"id": "1711.09534", "submitter": "Ziang Xie", "authors": "Ziang Xie", "title": "Neural Text Generation: A Practical Guide", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods have recently achieved great empirical success on\nmachine translation, dialogue response generation, summarization, and other\ntext generation tasks. At a high level, the technique has been to train\nend-to-end neural network models consisting of an encoder model to produce a\nhidden representation of the source text, followed by a decoder model to\ngenerate the target. While such models have significantly fewer pieces than\nearlier systems, significant tuning is still required to achieve good\nperformance. For text generation models in particular, the decoder can behave\nin undesired ways, such as by generating truncated or repetitive outputs,\noutputting bland and generic responses, or in some cases producing\nungrammatical gibberish. This paper is intended as a practical guide for\nresolving such undesired behavior in text generation models, with the aim of\nhelping enable real-world applications.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 04:50:15 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Xie", "Ziang", ""]]}, {"id": "1711.09535", "submitter": "Dacheng Tao", "authors": "Xiyu Yu, Tongliang Liu, Mingming Gong, and Dacheng Tao", "title": "Learning with Biased Complementary Labels", "comments": "ECCV 2018 Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the classification problem in which we have access to\neasily obtainable surrogate for true labels, namely complementary labels, which\nspecify classes that observations do \\textbf{not} belong to. Let $Y$ and\n$\\bar{Y}$ be the true and complementary labels, respectively. We first model\nthe annotation of complementary labels via transition probabilities\n$P(\\bar{Y}=i|Y=j), i\\neq j\\in\\{1,\\cdots,c\\}$, where $c$ is the number of\nclasses. Previous methods implicitly assume that $P(\\bar{Y}=i|Y=j), \\forall\ni\\neq j$, are identical, which is not true in practice because humans are\nbiased toward their own experience. For example, as shown in Figure 1, if an\nannotator is more familiar with monkeys than prairie dogs when providing\ncomplementary labels for meerkats, she is more likely to employ \"monkey\" as a\ncomplementary label. We therefore reason that the transition probabilities will\nbe different. In this paper, we propose a framework that contributes three main\ninnovations to learning with \\textbf{biased} complementary labels: (1) It\nestimates transition probabilities with no bias. (2) It provides a general\nmethod to modify traditional loss functions and extends standard deep neural\nnetwork classifiers to learn with biased complementary labels. (3) It\ntheoretically ensures that the classifier learned with complementary labels\nconverges to the optimal one learned with true labels. Comprehensive\nexperiments on several benchmark datasets validate the superiority of our\nmethod to current state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 04:52:05 GMT"}, {"version": "v2", "created": "Sun, 3 Dec 2017 23:27:18 GMT"}, {"version": "v3", "created": "Wed, 8 Aug 2018 01:40:46 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Yu", "Xiyu", ""], ["Liu", "Tongliang", ""], ["Gong", "Mingming", ""], ["Tao", "Dacheng", ""]]}, {"id": "1711.09550", "submitter": "Chuang Gan", "authors": "Xiang Long, Chuang Gan, Gerard de Melo, Jiajun Wu, Xiao Liu, Shilei\n  Wen", "title": "Attention Clusters: Purely Attention Based Local Feature Integration for\n  Video Classification", "comments": "The backbone of the winner solution at ActivityNet Kinetics Challenge\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, substantial research effort has focused on how to apply CNNs or\nRNNs to better extract temporal patterns from videos, so as to improve the\naccuracy of video classification. In this paper, however, we show that temporal\ninformation, especially longer-term patterns, may not be necessary to achieve\ncompetitive results on common video classification datasets. We investigate the\npotential of a purely attention based local feature integration. Accounting for\nthe characteristics of such features in video classification, we propose a\nlocal feature integration framework based on attention clusters, and introduce\na shifting operation to capture more diverse signals. We carefully analyze and\ncompare the effect of different attention mechanisms, cluster sizes, and the\nuse of the shifting operation, and also investigate the combination of\nattention clusters for multimodal integration. We demonstrate the effectiveness\nof our framework on three real-world video classification datasets. Our model\nachieves competitive results across all of these. In particular, on the\nlarge-scale Kinetics dataset, our framework obtains an excellent single model\naccuracy of 79.4% in terms of the top-1 and 94.0% in terms of the top-5\naccuracy on the validation set. The attention clusters are the backbone of our\nwinner solution at ActivityNet Kinetics Challenge 2017. Code and models will be\nreleased soon.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 06:16:14 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Long", "Xiang", ""], ["Gan", "Chuang", ""], ["de Melo", "Gerard", ""], ["Wu", "Jiajun", ""], ["Liu", "Xiao", ""], ["Wen", "Shilei", ""]]}, {"id": "1711.09558", "submitter": "Jasper Zuallaert", "authors": "Jasper Zuallaert, Mijung Kim, Yvan Saeys, Wesley De Neve", "title": "Interpretable Convolutional Neural Networks for Effective Translation\n  Initiation Site Prediction", "comments": "Presented at International Workshop on Deep Learning in\n  Bioinformatics, Biomedicine, and Healthcare Informatics (DLB2H 2017) --- in\n  conjunction with the IEEE International Conference on Bioinformatics and\n  Biomedicine (BIBM 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to rapidly evolving sequencing techniques, the amount of genomic data\nat our disposal is growing increasingly large. Determining the gene structure\nis a fundamental requirement to effectively interpret gene function and\nregulation. An important part in that determination process is the\nidentification of translation initiation sites. In this paper, we propose a\nnovel approach for automatic prediction of translation initiation sites,\nleveraging convolutional neural networks that allow for automatic feature\nextraction. Our experimental results demonstrate that we are able to improve\nthe state-of-the-art approaches with a decrease of 75.2% in false positive rate\nand with a decrease of 24.5% in error rate on chosen datasets. Furthermore, an\nin-depth analysis of the decision-making process used by our predictive model\nshows that our neural network implicitly learns biologically relevant features\nfrom scratch, without any prior knowledge about the problem at hand, such as\nthe Kozak consensus sequence, the influence of stop and start codons in the\nsequence and the presence of donor splice site patterns. In summary, our\nfindings yield a better understanding of the internal reasoning of a\nconvolutional neural network when applying such a neural network to genomic\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 06:37:37 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Zuallaert", "Jasper", ""], ["Kim", "Mijung", ""], ["Saeys", "Yvan", ""], ["De Neve", "Wesley", ""]]}, {"id": "1711.09576", "submitter": "Gail Weiss", "authors": "Gail Weiss and Yoav Goldberg and Eran Yahav", "title": "Extracting Automata from Recurrent Neural Networks Using Queries and\n  Counterexamples", "comments": "Accepted in ICML 2018, (Feb 2020: added link to code, at\n  https://github.com/tech-srl/lstar_extraction )", "journal-ref": "ICML 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel algorithm that uses exact learning and abstraction to\nextract a deterministic finite automaton describing the state dynamics of a\ngiven trained RNN. We do this using Angluin's L* algorithm as a learner and the\ntrained RNN as an oracle. Our technique efficiently extracts accurate automata\nfrom trained RNNs, even when the state vectors are large and require fine\ndifferentiation.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 08:26:09 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 14:39:44 GMT"}, {"version": "v3", "created": "Sun, 24 Jun 2018 13:16:43 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2020 15:32:32 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Weiss", "Gail", ""], ["Goldberg", "Yoav", ""], ["Yahav", "Eran", ""]]}, {"id": "1711.09602", "submitter": "Aniruddh Raghu", "authors": "Aniruddh Raghu, Matthieu Komorowski, Imran Ahmed, Leo Celi, Peter\n  Szolovits, Marzyeh Ghassemi", "title": "Deep Reinforcement Learning for Sepsis Treatment", "comments": "Extensions on earlier work (arXiv:1705.08422). Accepted at workshop\n  on Machine Learning For Health at the conference on Neural Information\n  Processing Systems, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sepsis is a leading cause of mortality in intensive care units and costs\nhospitals billions annually. Treating a septic patient is highly challenging,\nbecause individual patients respond very differently to medical interventions\nand there is no universally agreed-upon treatment for sepsis. In this work, we\npropose an approach to deduce treatment policies for septic patients by using\ncontinuous state-space models and deep reinforcement learning. Our model learns\nclinically interpretable treatment policies, similar in important aspects to\nthe treatment policies of physicians. The learned policies could be used to aid\nintensive care clinicians in medical decision making and improve the likelihood\nof patient survival.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 09:49:57 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Raghu", "Aniruddh", ""], ["Komorowski", "Matthieu", ""], ["Ahmed", "Imran", ""], ["Celi", "Leo", ""], ["Szolovits", "Peter", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "1711.09645", "submitter": "Stefanos Angelidis", "authors": "Stefanos Angelidis, Mirella Lapata", "title": "Multiple Instance Learning Networks for Fine-Grained Sentiment Analysis", "comments": "Final published version. Please cite using appropriate date (2018).\n  Link to journal:\n  http://www.transacl.org/ojs/index.php/tacl/article/view/1225/277", "journal-ref": "Transactions of the Association for Computational Linguistics\n  (TACL), 2018, Volume 6, pages 17-31", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the task of fine-grained sentiment analysis from the perspective\nof multiple instance learning (MIL). Our neural model is trained on document\nsentiment labels, and learns to predict the sentiment of text segments, i.e.\nsentences or elementary discourse units (EDUs), without segment-level\nsupervision. We introduce an attention-based polarity scoring method for\nidentifying positive and negative text snippets and a new dataset which we call\nSPOT (as shorthand for Segment-level POlariTy annotations) for evaluating\nMIL-style sentiment models like ours. Experimental results demonstrate superior\nperformance against multiple baselines, whereas a judgement elicitation study\nshows that EDU-level opinion extraction produces more informative summaries\nthan sentence-based alternatives.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 12:21:22 GMT"}, {"version": "v2", "created": "Fri, 26 Jan 2018 15:53:12 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Angelidis", "Stefanos", ""], ["Lapata", "Mirella", ""]]}, {"id": "1711.09649", "submitter": "Olivier Bachem", "authors": "Olivier Bachem and Mario Lucic and Silvio Lattanzi", "title": "One-Shot Coresets: The Case of k-Clustering", "comments": "To Appear In AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scaling clustering algorithms to massive data sets is a challenging task.\nRecently, several successful approaches based on data summarization methods,\nsuch as coresets and sketches, were proposed. While these techniques provide\nprovably good and small summaries, they are inherently problem dependent - the\npractitioner has to commit to a fixed clustering objective before even\nexploring the data. However, can one construct small data summaries for a wide\nrange of clustering problems simultaneously? In this work, we affirmatively\nanswer this question by proposing an efficient algorithm that constructs such\none-shot summaries for k-clustering problems while retaining strong theoretical\nguarantees.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 12:33:20 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 15:31:27 GMT"}, {"version": "v3", "created": "Tue, 20 Feb 2018 15:22:51 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Bachem", "Olivier", ""], ["Lucic", "Mario", ""], ["Lattanzi", "Silvio", ""]]}, {"id": "1711.09663", "submitter": "Eli (Omid) David", "authors": "Ido Cohen, Eli David, Nathan S. Netanyahu, Noa Liscovitch, Gal Chechik", "title": "DeepBrain: Functional Representation of Neural In-Situ Hybridization\n  Images for Gene Ontology Classification Using Deep Convolutional Autoencoders", "comments": null, "journal-ref": "International Conference on Artificial Neural Networks (ICANN),\n  Springer LNCS, Vol. 10614, pp. 287-296, Alghero, Italy, September, 2017", "doi": "10.1007/978-3-319-68612-7_33", "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel deep learning-based method for learning a\nfunctional representation of mammalian neural images. The method uses a deep\nconvolutional denoising autoencoder (CDAE) for generating an invariant, compact\nrepresentation of in situ hybridization (ISH) images. While most existing\nmethods for bio-imaging analysis were not developed to handle images with\nhighly complex anatomical structures, the results presented in this paper show\nthat functional representation extracted by CDAE can help learn features of\nfunctional gene ontology categories for their classification in a highly\naccurate manner. Using this CDAE representation, our method outperforms the\nprevious state-of-the-art classification rate, by improving the average AUC\nfrom 0.92 to 0.98, i.e., achieving 75% reduction in error. The method operates\non input images that were downsampled significantly with respect to the\noriginal ones to make it computationally feasible.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 13:00:03 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Cohen", "Ido", ""], ["David", "Eli", ""], ["Netanyahu", "Nathan S.", ""], ["Liscovitch", "Noa", ""], ["Chechik", "Gal", ""]]}, {"id": "1711.09666", "submitter": "Eli (Omid) David", "authors": "Ishai Rosenberg, Guillaume Sicard, Eli David", "title": "DeepAPT: Nation-State APT Attribution Using End-to-End Deep Neural\n  Networks", "comments": null, "journal-ref": "International Conference on Artificial Neural Networks (ICANN),\n  Springer LNCS, Vol. 10614, pp. 91-99, Alghero, Italy, September, 2017", "doi": "10.1007/978-3-319-68612-7_11", "report-no": null, "categories": "cs.CR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years numerous advanced malware, aka advanced persistent threats\n(APT) are allegedly developed by nation-states. The task of attributing an APT\nto a specific nation-state is extremely challenging for several reasons. Each\nnation-state has usually more than a single cyber unit that develops such\nadvanced malware, rendering traditional authorship attribution algorithms\nuseless. Furthermore, those APTs use state-of-the-art evasion techniques,\nmaking feature extraction challenging. Finally, the dataset of such available\nAPTs is extremely small.\n  In this paper we describe how deep neural networks (DNN) could be\nsuccessfully employed for nation-state APT attribution. We use sandbox reports\n(recording the behavior of the APT when run dynamically) as raw input for the\nneural network, allowing the DNN to learn high level feature abstractions of\nthe APTs itself. Using a test set of 1,000 Chinese and Russian developed APTs,\nwe achieved an accuracy rate of 94.6%.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 13:04:46 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Rosenberg", "Ishai", ""], ["Sicard", "Guillaume", ""], ["David", "Eli", ""]]}, {"id": "1711.09667", "submitter": "Eli (Omid) David", "authors": "Eli David, Nathan S. Netanyahu, Lior Wolf", "title": "DeepChess: End-to-End Deep Neural Network for Automatic Learning in\n  Chess", "comments": "Winner of Best Paper Award in ICANN 2016", "journal-ref": "International Conference on Artificial Neural Networks (ICANN),\n  Springer LNCS, Vol. 9887, pp. 88-96, Barcelona, Spain, 2016", "doi": "10.1007/978-3-319-44781-0_11", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end learning method for chess, relying on deep neural\nnetworks. Without any a priori knowledge, in particular without any knowledge\nregarding the rules of chess, a deep neural network is trained using a\ncombination of unsupervised pretraining and supervised training. The\nunsupervised training extracts high level features from a given position, and\nthe supervised training learns to compare two chess positions and select the\nmore favorable one. The training relies entirely on datasets of several million\nchess games, and no further domain specific knowledge is incorporated.\n  The experiments show that the resulting neural network (referred to as\nDeepChess) is on a par with state-of-the-art chess playing programs, which have\nbeen developed through many years of manual feature selection and tuning.\nDeepChess is the first end-to-end machine learning-based method that results in\na grandmaster-level chess playing performance.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 13:04:57 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["David", "Eli", ""], ["Netanyahu", "Nathan S.", ""], ["Wolf", "Lior", ""]]}, {"id": "1711.09681", "submitter": "YoungJoon Yoo", "authors": "YoungJoon Yoo, Seonguk Park, Junyoung Choi, Sangdoo Yun, Nojun Kwak", "title": "Butterfly Effect: Bidirectional Control of Classification Performance by\n  Small Additive Perturbation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new algorithm for controlling classification results by\ngenerating a small additive perturbation without changing the classifier\nnetwork. Our work is inspired by existing works generating adversarial\nperturbation that worsens classification performance. In contrast to the\nexisting methods, our work aims to generate perturbations that can enhance\noverall classification performance. To solve this performance enhancement\nproblem, we newly propose a perturbation generation network (PGN) influenced by\nthe adversarial learning strategy. In our problem, the information in a large\nexternal dataset is summarized by a small additive perturbation, which helps to\nimprove the performance of the classifier trained with the target dataset. In\naddition to this performance enhancement problem, we show that the proposed PGN\ncan be adopted to solve the classical adversarial problem without utilizing the\ninformation on the target classifier. The mentioned characteristics of our\nmethod are verified through extensive experiments on publicly available visual\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 13:32:45 GMT"}, {"version": "v2", "created": "Mon, 4 Dec 2017 05:39:10 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Yoo", "YoungJoon", ""], ["Park", "Seonguk", ""], ["Choi", "Junyoung", ""], ["Yun", "Sangdoo", ""], ["Kwak", "Nojun", ""]]}, {"id": "1711.09783", "submitter": "Bharath Bhushan Damodaran", "authors": "Bharath Bhushan Damodaran, Nicolas Courty, Philippe-Henri Gosselin", "title": "Data Dependent Kernel Approximation using Pseudo Random Fourier Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Kernel methods are powerful and flexible approach to solve many problems in\nmachine learning. Due to the pairwise evaluations in kernel methods, the\ncomplexity of kernel computation grows as the data size increases; thus the\napplicability of kernel methods is limited for large scale datasets. Random\nFourier Features (RFF) has been proposed to scale the kernel method for solving\nlarge scale datasets by approximating kernel function using randomized Fourier\nfeatures. While this method proved very popular, still it exists shortcomings\nto be effectively used. As RFF samples the randomized features from a\ndistribution independent of training data, it requires sufficient large number\nof feature expansions to have similar performances to kernelized classifiers,\nand this is proportional to the number samples in the dataset. Thus, reducing\nthe number of feature dimensions is necessary to effectively scale to large\ndatasets. In this paper, we propose a kernel approximation method in a data\ndependent way, coined as Pseudo Random Fourier Features (PRFF) for reducing the\nnumber of feature dimensions and also to improve the prediction performance.\nThe proposed approach is evaluated on classification and regression problems\nand compared with the RFF, orthogonal random features and Nystr{\\\"o}m approach\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 15:48:31 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Damodaran", "Bharath Bhushan", ""], ["Courty", "Nicolas", ""], ["Gosselin", "Philippe-Henri", ""]]}, {"id": "1711.09784", "submitter": "Nicholas Frosst", "authors": "Nicholas Frosst, Geoffrey Hinton", "title": "Distilling a Neural Network Into a Soft Decision Tree", "comments": "presented at the CEX workshop at AI*IA 2017 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have proved to be a very effective way to perform\nclassification tasks. They excel when the input data is high dimensional, the\nrelationship between the input and the output is complicated, and the number of\nlabeled training examples is large. But it is hard to explain why a learned\nnetwork makes a particular classification decision on a particular test case.\nThis is due to their reliance on distributed hierarchical representations. If\nwe could take the knowledge acquired by the neural net and express the same\nknowledge in a model that relies on hierarchical decisions instead, explaining\na particular decision would be much easier. We describe a way of using a\ntrained neural net to create a type of soft decision tree that generalizes\nbetter than one learned directly from the training data.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 15:50:50 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Frosst", "Nicholas", ""], ["Hinton", "Geoffrey", ""]]}, {"id": "1711.09822", "submitter": "Clemens Marschner", "authors": "Aayush Garg, Thilo Will, William Darling, Willi Richert, Clemens\n  Marschner", "title": "Scalable Object Detection for Stylized Objects", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following recent breakthroughs in convolutional neural networks and\nmonolithic model architectures, state-of-the-art object detection models can\nreliably and accurately scale into the realm of up to thousands of classes.\nThings quickly break down, however, when scaling into the tens of thousands,\nor, eventually, to millions or billions of unique objects. Further, bounding\nbox-trained end-to-end models require extensive training data. Even though -\nwith some tricks using hierarchies - one can sometimes scale up to thousands of\nclasses, the labor requirements for clean image annotations quickly get out of\ncontrol. In this paper, we present a two-layer object detection method for\nbrand logos and other stylized objects for which prototypical images exist. It\ncan scale to large numbers of unique classes. Our first layer is a CNN from the\nSingle Shot Multibox Detector family of models that learns to propose regions\nwhere some stylized object is likely to appear. The contents of a proposed\nbounding box is then run against an image index that is targeted for the\nretrieval task at hand. The proposed architecture scales to a large number of\nobject classes, allows to continously add new classes without retraining, and\nexhibits state-of-the-art quality on a stylized object detection task such as\nlogo recognition.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 16:46:09 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 10:04:56 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Garg", "Aayush", ""], ["Will", "Thilo", ""], ["Darling", "William", ""], ["Richert", "Willi", ""], ["Marschner", "Clemens", ""]]}, {"id": "1711.09825", "submitter": "Andreas Veit", "authors": "Andreas Veit, Maximilian Nickel, Serge Belongie, Laurens van der\n  Maaten", "title": "Separating Self-Expression and Visual Content in Hashtag Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variety, abundance, and structured nature of hashtags make them an\ninteresting data source for training vision models. For instance, hashtags have\nthe potential to significantly reduce the problem of manual supervision and\nannotation when learning vision models for a large number of concepts. However,\na key challenge when learning from hashtags is that they are inherently\nsubjective because they are provided by users as a form of self-expression. As\na consequence, hashtags may have synonyms (different hashtags referring to the\nsame visual content) and may be ambiguous (the same hashtag referring to\ndifferent visual content). These challenges limit the effectiveness of\napproaches that simply treat hashtags as image-label pairs. This paper presents\nan approach that extends upon modeling simple image-label pairs by modeling the\njoint distribution of images, hashtags, and users. We demonstrate the efficacy\nof such approaches in image tagging and retrieval experiments, and show how the\njoint model can be used to perform user-conditional retrieval and tagging.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 16:50:52 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Veit", "Andreas", ""], ["Nickel", "Maximilian", ""], ["Belongie", "Serge", ""], ["van der Maaten", "Laurens", ""]]}, {"id": "1711.09846", "submitter": "Max Jaderberg", "authors": "Max Jaderberg, Valentin Dalibard, Simon Osindero, Wojciech M.\n  Czarnecki, Jeff Donahue, Ali Razavi, Oriol Vinyals, Tim Green, Iain Dunning,\n  Karen Simonyan, Chrisantha Fernando, Koray Kavukcuoglu", "title": "Population Based Training of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks dominate the modern machine learning landscape, but their\ntraining and success still suffer from sensitivity to empirical choices of\nhyperparameters such as model architecture, loss function, and optimisation\nalgorithm. In this work we present \\emph{Population Based Training (PBT)}, a\nsimple asynchronous optimisation algorithm which effectively utilises a fixed\ncomputational budget to jointly optimise a population of models and their\nhyperparameters to maximise performance. Importantly, PBT discovers a schedule\nof hyperparameter settings rather than following the generally sub-optimal\nstrategy of trying to find a single fixed set to use for the whole course of\ntraining. With just a small modification to a typical distributed\nhyperparameter training framework, our method allows robust and reliable\ntraining of models. We demonstrate the effectiveness of PBT on deep\nreinforcement learning problems, showing faster wall-clock convergence and\nhigher final performance of agents by optimising over a suite of\nhyperparameters. In addition, we show the same method can be applied to\nsupervised learning for machine translation, where PBT is used to maximise the\nBLEU score directly, and also to training of Generative Adversarial Networks to\nmaximise the Inception score of generated images. In all cases PBT results in\nthe automatic discovery of hyperparameter schedules and model selection which\nresults in stable training and better final performance.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 17:33:27 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 16:16:21 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Jaderberg", "Max", ""], ["Dalibard", "Valentin", ""], ["Osindero", "Simon", ""], ["Czarnecki", "Wojciech M.", ""], ["Donahue", "Jeff", ""], ["Razavi", "Ali", ""], ["Vinyals", "Oriol", ""], ["Green", "Tim", ""], ["Dunning", "Iain", ""], ["Simonyan", "Karen", ""], ["Fernando", "Chrisantha", ""], ["Kavukcuoglu", "Koray", ""]]}, {"id": "1711.09869", "submitter": "Martin Simonovsky", "authors": "Loic Landrieu, Martin Simonovsky", "title": "Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs", "comments": "Accepted to CVPR 2018; camera ready version. Major updates to [v1]:\n  Improved performance on S3DIS (from +5.8 to +12.4 mIoU) and extended ablation\n  study in Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel deep learning-based framework to tackle the challenge of\nsemantic segmentation of large-scale point clouds of millions of points. We\nargue that the organization of 3D point clouds can be efficiently captured by a\nstructure called superpoint graph (SPG), derived from a partition of the\nscanned scene into geometrically homogeneous elements. SPGs offer a compact yet\nrich representation of contextual relationships between object parts, which is\nthen exploited by a graph convolutional network. Our framework sets a new state\nof the art for segmenting outdoor LiDAR scans (+11.9 and +8.8 mIoU points for\nboth Semantic3D test sets), as well as indoor scans (+12.4 mIoU points for the\nS3DIS dataset).\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 18:37:50 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 09:01:33 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Landrieu", "Loic", ""], ["Simonovsky", "Martin", ""]]}, {"id": "1711.09874", "submitter": "Dibya Ghosh", "authors": "Dibya Ghosh, Avi Singh, Aravind Rajeswaran, Vikash Kumar, Sergey\n  Levine", "title": "Divide-and-Conquer Reinforcement Learning", "comments": "Presented at ICLR 2018. Videos and supporting materials are located\n  at http://bit.ly/dnc-rl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard model-free deep reinforcement learning (RL) algorithms sample a new\ninitial state for each trial, allowing them to optimize policies that can\nperform well even in highly stochastic environments. However, problems that\nexhibit considerable initial state variation typically produce high-variance\ngradient estimates for model-free RL, making direct policy or value function\noptimization challenging. In this paper, we develop a novel algorithm that\ninstead partitions the initial state space into \"slices\", and optimizes an\nensemble of policies, each on a different slice. The ensemble is gradually\nunified into a single policy that can succeed on the whole state space. This\napproach, which we term divide-and-conquer RL, is able to solve complex tasks\nwhere conventional deep RL methods are ineffective. Our results show that\ndivide-and-conquer RL greatly outperforms conventional policy gradient methods\non challenging grasping, manipulation, and locomotion tasks, and exceeds the\nperformance of a variety of prior methods. Videos of policies learned by our\nalgorithm can be viewed at http://bit.ly/dnc-rl\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 18:46:00 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 17:55:06 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Ghosh", "Dibya", ""], ["Singh", "Avi", ""], ["Rajeswaran", "Aravind", ""], ["Kumar", "Vikash", ""], ["Levine", "Sergey", ""]]}, {"id": "1711.09876", "submitter": "James Aimone", "authors": "James B. Aimone and William M. Severa", "title": "Context-modulation of hippocampal dynamics and deep convolutional\n  networks", "comments": "4 pages; short paper accepted to 2017 NIPS Cognitively Informed AI\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex architectures of biological neural circuits, such as parallel\nprocessing pathways, has been behaviorally implicated in many cognitive\nstudies. However, the theoretical consequences of circuit complexity on neural\ncomputation have only been explored in limited cases. Here, we introduce a\nmechanism by which direct and indirect pathways from cortex to the CA3 region\nof the hippocampus can balance both contextual gating of memory formation and\ndriving network activity. We implement this concept in a deep artificial neural\nnetwork by enabling a context-sensitive bias. The motivation for this is to\nimprove performance of a size-constrained network. Using direct knowledge of\nthe superclass information in the CIFAR-100 and Fashion-MNIST datasets, we show\na dramatic increase in performance without an increase in network size.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 18:47:21 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Aimone", "James B.", ""], ["Severa", "William M.", ""]]}, {"id": "1711.09883", "submitter": "Jan Leike", "authors": "Jan Leike, Miljan Martic, Victoria Krakovna, Pedro A. Ortega, Tom\n  Everitt, Andrew Lefrancq, Laurent Orseau, Shane Legg", "title": "AI Safety Gridworlds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a suite of reinforcement learning environments illustrating\nvarious safety properties of intelligent agents. These problems include safe\ninterruptibility, avoiding side effects, absent supervisor, reward gaming, safe\nexploration, as well as robustness to self-modification, distributional shift,\nand adversaries. To measure compliance with the intended safe behavior, we\nequip each environment with a performance function that is hidden from the\nagent. This allows us to categorize AI safety problems into robustness and\nspecification problems, depending on whether the performance function\ncorresponds to the observed reward function. We evaluate A2C and Rainbow, two\nrecent deep reinforcement learning agents, on our environments and show that\nthey are not able to solve them satisfactorily.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 18:57:13 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 17:40:36 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Leike", "Jan", ""], ["Martic", "Miljan", ""], ["Krakovna", "Victoria", ""], ["Ortega", "Pedro A.", ""], ["Everitt", "Tom", ""], ["Lefrancq", "Andrew", ""], ["Orseau", "Laurent", ""], ["Legg", "Shane", ""]]}, {"id": "1711.09919", "submitter": "Daniel George", "authors": "Hongyu Shen, Daniel George, E. A. Huerta, Zhizhen Zhao", "title": "Denoising Gravitational Waves using Deep Learning with Recurrent\n  Denoising Autoencoders", "comments": "5 pages, 2 figures", "journal-ref": "ICASSP 2019", "doi": "10.1109/ICASSP.2019.8683061", "report-no": null, "categories": "gr-qc astro-ph.HE astro-ph.IM cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gravitational wave astronomy is a rapidly growing field of modern\nastrophysics, with observations being made frequently by the LIGO detectors.\nGravitational wave signals are often extremely weak and the data from the\ndetectors, such as LIGO, is contaminated with non-Gaussian and non-stationary\nnoise, often containing transient disturbances which can obscure real signals.\nTraditional denoising methods, such as principal component analysis and\ndictionary learning, are not optimal for dealing with this non-Gaussian noise,\nespecially for low signal-to-noise ratio gravitational wave signals.\nFurthermore, these methods are computationally expensive on large datasets. To\novercome these issues, we apply state-of-the-art signal processing techniques,\nbased on recent groundbreaking advancements in deep learning, to denoise\ngravitational wave signals embedded either in Gaussian noise or in real LIGO\nnoise. We introduce SMTDAE, a Staired Multi-Timestep Denoising Autoencoder,\nbased on sequence-to-sequence bi-directional Long-Short-Term-Memory recurrent\nneural networks. We demonstrate the advantages of using our unsupervised deep\nlearning approach and show that, after training only using simulated Gaussian\nnoise, SMTDAE achieves superior recovery performance for gravitational wave\nsignals embedded in real non-Gaussian LIGO noise.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 19:00:09 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Shen", "Hongyu", ""], ["George", "Daniel", ""], ["Huerta", "E. A.", ""], ["Zhao", "Zhizhen", ""]]}, {"id": "1711.10019", "submitter": "Young Hun Jung", "authors": "Jacob Abernethy, Young Hun Jung, Chansoo Lee, Audra McMillan, Ambuj\n  Tewari", "title": "Online Learning via the Differential Privacy Lens", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use differential privacy as a lens to examine online\nlearning in both full and partial information settings. The differential\nprivacy framework is, at heart, less about privacy and more about algorithmic\nstability, and thus has found application in domains well beyond those where\ninformation security is central. Here we develop an algorithmic property called\none-step differential stability which facilitates a more refined regret\nanalysis for online learning methods. We show that tools from the differential\nprivacy literature can yield regret bounds for many interesting online learning\nproblems including online convex optimization and online linear optimization.\nOur stability notion is particularly well-suited for deriving first-order\nregret bounds for follow-the-perturbed-leader algorithms, something that all\nprevious analyses have struggled to achieve. We also generalize the standard\nmax-divergence to obtain a broader class called Tsallis max-divergences. These\ndefine stronger notions of stability that are useful in deriving bounds in\npartial information settings such as multi-armed bandits and bandits with\nexperts.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 22:03:13 GMT"}, {"version": "v2", "created": "Sat, 10 Feb 2018 15:00:10 GMT"}, {"version": "v3", "created": "Sat, 8 Jun 2019 00:10:13 GMT"}, {"version": "v4", "created": "Mon, 28 Oct 2019 19:20:54 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Abernethy", "Jacob", ""], ["Jung", "Young Hun", ""], ["Lee", "Chansoo", ""], ["McMillan", "Audra", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1711.10046", "submitter": "Morteza Mardani", "authors": "Morteza Mardani, Hatef Monajemi, Vardan Papyan, Shreyas Vasanawala,\n  David Donoho, and John Pauly", "title": "Recurrent Generative Adversarial Networks for Proximal Learning and\n  Automated Compressive Image Recovery", "comments": "11 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recovering images from undersampled linear measurements typically leads to an\nill-posed linear inverse problem, that asks for proper statistical priors.\nBuilding effective priors is however challenged by the low train and test\noverhead dictated by real-time tasks; and the need for retrieving visually\n\"plausible\" and physically \"feasible\" images with minimal hallucination. To\ncope with these challenges, we design a cascaded network architecture that\nunrolls the proximal gradient iterations by permeating benefits from generative\nresidual networks (ResNet) to modeling the proximal operator. A mixture of\npixel-wise and perceptual costs is then deployed to train proximals. The\noverall architecture resembles back-and-forth projection onto the intersection\nof feasible and plausible images. Extensive computational experiments are\nexamined for a global task of reconstructing MR images of pediatric patients,\nand a more local task of superresolving CelebA faces, that are insightful to\ndesign efficient architectures. Our observations indicate that for MRI\nreconstruction, a recurrent ResNet with a single residual block effectively\nlearns the proximal. This simple architecture appears to significantly\noutperform the alternative deep ResNet architecture by 2dB SNR, and the\nconventional compressed-sensing MRI by 4dB SNR with 100x faster inference. For\nimage superresolution, our preliminary results indicate that modeling the\ndenoising proximal demands deep ResNets.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 23:45:02 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Mardani", "Morteza", ""], ["Monajemi", "Hatef", ""], ["Papyan", "Vardan", ""], ["Vasanawala", "Shreyas", ""], ["Donoho", "David", ""], ["Pauly", "John", ""]]}, {"id": "1711.10051", "submitter": "Xue Chen", "authors": "Xue Chen and Eric Price", "title": "Active Regression via Linear-Sample Sparsification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach that improves the sample complexity for a variety of\ncurve fitting problems, including active learning for linear regression,\npolynomial regression, and continuous sparse Fourier transforms. In the active\nlinear regression problem, one would like to estimate the least squares\nsolution $\\beta^*$ minimizing $\\|X\\beta - y\\|_2$ given the entire unlabeled\ndataset $X \\in \\mathbb{R}^{n \\times d}$ but only observing a small number of\nlabels $y_i$. We show that $O(d)$ labels suffice to find a constant factor\napproximation $\\tilde{\\beta}$:\n  \\[\n  \\mathbb{E}[\\|X\\tilde{\\beta} - y\\|_2^2] \\leq 2 \\mathbb{E}[\\|X \\beta^* -\ny\\|_2^2].\n  \\] This improves on the best previous result of $O(d \\log d)$ from leverage\nscore sampling. We also present results for the \\emph{inductive} setting,\nshowing when $\\tilde{\\beta}$ will generalize to fresh samples; these apply to\ncontinuous settings such as polynomial regression. Finally, we show how the\ntechniques yield improved results for the non-linear sparse Fourier transform\nsetting.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 23:59:30 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2018 15:21:26 GMT"}, {"version": "v3", "created": "Thu, 21 Mar 2019 21:30:10 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Chen", "Xue", ""], ["Price", "Eric", ""]]}, {"id": "1711.10055", "submitter": "Sumeet Singh", "authors": "Sumeet Singh, Jonathan Lacotte, Anirudha Majumdar, Marco Pavone", "title": "Risk-sensitive Inverse Reinforcement Learning via Semi- and\n  Non-Parametric Methods", "comments": "Submitted to International Journal of Robotics Research; Revision 1:\n  (i) Clarified minor technical points; (ii) Revised proof for Theorem 3 to\n  hold under weaker assumptions; (iii) Added additional figures and expanded\n  discussions to improve readability", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The literature on Inverse Reinforcement Learning (IRL) typically assumes that\nhumans take actions in order to minimize the expected value of a cost function,\ni.e., that humans are risk neutral. Yet, in practice, humans are often far from\nbeing risk neutral. To fill this gap, the objective of this paper is to devise\na framework for risk-sensitive IRL in order to explicitly account for a human's\nrisk sensitivity. To this end, we propose a flexible class of models based on\ncoherent risk measures, which allow us to capture an entire spectrum of risk\npreferences from risk-neutral to worst-case. We propose efficient\nnon-parametric algorithms based on linear programming and semi-parametric\nalgorithms based on maximum likelihood for inferring a human's underlying risk\nmeasure and cost function for a rich class of static and dynamic\ndecision-making settings. The resulting approach is demonstrated on a simulated\ndriving game with ten human participants. Our method is able to infer and mimic\na wide range of qualitatively different driving styles from highly risk-averse\nto risk-neutral in a data-efficient manner. Moreover, comparisons of the\nRisk-Sensitive (RS) IRL approach with a risk-neutral model show that the RS-IRL\nframework more accurately captures observed participant behavior both\nqualitatively and quantitatively, especially in scenarios where catastrophic\noutcomes such as collisions can occur.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 00:07:10 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 07:24:55 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Singh", "Sumeet", ""], ["Lacotte", "Jonathan", ""], ["Majumdar", "Anirudha", ""], ["Pavone", "Marco", ""]]}, {"id": "1711.10056", "submitter": "Thomas Gebhart", "authors": "Thomas Gebhart and Paul Schrater", "title": "Adversary Detection in Neural Networks via Persistent Homology", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We outline a detection method for adversarial inputs to deep neural networks.\nBy viewing neural network computations as graphs upon which information flows\nfrom input space to out- put distribution, we compare the differences in graphs\ninduced by different inputs. Specifically, by applying persistent homology to\nthese induced graphs, we observe that the structure of the most persistent\nsubgraphs which generate the first homology group differ between adversarial\nand unperturbed inputs. Based on this observation, we build a detection\nalgorithm that depends only on the topological information extracted during\ntraining. We test our algorithm on MNIST and achieve 98% detection adversary\naccuracy with F1-score 0.98.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 00:08:10 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Gebhart", "Thomas", ""], ["Schrater", "Paul", ""]]}, {"id": "1711.10057", "submitter": "Harish S. Bhat", "authors": "Harish S. Bhat and Sidra J. Goldman-Mellor", "title": "Predicting Adolescent Suicide Attempts with Neural Networks", "comments": "Accepted poster at NIPS 2017 Workshop on Machine Learning for Health\n  (https://ml4health.github.io/2017/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though suicide is a major public health problem in the US, machine learning\nmethods are not commonly used to predict an individual's risk of\nattempting/committing suicide. In the present work, starting with an anonymized\ncollection of electronic health records for 522,056 unique, California-resident\nadolescents, we develop neural network models to predict suicide attempts. We\nframe the problem as a binary classification problem in which we use a\npatient's data from 2006-2009 to predict either the presence (1) or absence (0)\nof a suicide attempt in 2010. After addressing issues such as severely\nimbalanced classes and the variable length of a patient's history, we build\nneural networks with depths varying from two to eight hidden layers. For test\nset observations where we have at least five ED/hospital visits' worth of data\non a patient, our depth-4 model achieves a sensitivity of 0.703, specificity of\n0.980, and AUC of 0.958.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 00:08:33 GMT"}, {"version": "v2", "created": "Fri, 1 Dec 2017 08:26:34 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Bhat", "Harish S.", ""], ["Goldman-Mellor", "Sidra J.", ""]]}, {"id": "1711.10105", "submitter": "Qingquan Song", "authors": "Qingquan Song, Hancheng Ge, James Caverlee, Xia Hu", "title": "Tensor Completion Algorithms in Big Data Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor completion is a problem of filling the missing or unobserved entries\nof partially observed tensors. Due to the multidimensional character of tensors\nin describing complex datasets, tensor completion algorithms and their\napplications have received wide attention and achievement in areas like data\nmining, computer vision, signal processing, and neuroscience. In this survey,\nwe provide a modern overview of recent advances in tensor completion algorithms\nfrom the perspective of big data analytics characterized by diverse variety,\nlarge volume, and high velocity. We characterize these advances from four\nperspectives: general tensor completion algorithms, tensor completion with\nauxiliary information (variety), scalable tensor completion algorithms\n(volume), and dynamic tensor completion algorithms (velocity). Further, we\nidentify several tensor completion applications on real-world data-driven\nproblems and present some common experimental frameworks popularized in the\nliterature. Our goal is to summarize these popular methods and introduce them\nto researchers and practitioners for promoting future research and\napplications. We conclude with a discussion of key challenges and promising\nresearch directions in this community for future exploration.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 03:44:29 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 02:26:17 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Song", "Qingquan", ""], ["Ge", "Hancheng", ""], ["Caverlee", "James", ""], ["Hu", "Xia", ""]]}, {"id": "1711.10111", "submitter": "Hao Ge Dr.", "authors": "Hao Ge", "title": "A Parameter-Free Learning Automaton Scheme", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a learning automaton, a proper configuration of its learning parameters,\nwhich are crucial for the automaton's performance, is relatively difficult due\nto the necessity of a manual parameter tuning before real applications. To\nensure a stable and reliable performance in stochastic environments, parameter\ntuning can be a time-consuming and interaction-costing procedure in the field\nof LA. Especially, it is a fatal limitation for LA-based applications where the\ninteractions with environments are expensive.\n  In this paper, we propose a parameter-free learning automaton scheme to avoid\nparameter tuning by a Bayesian inference method. In contrast to existing\nschemes where the parameters should be carefully tuned according to the\nenvironment, the performance of this scheme is not sensitive to external\nenvironments because a set of parameters can be consistently applied to various\nenvironments, which dramatically reduce the difficulty of applying a learning\nautomaton to an unknown stochastic environment. A rigorous proof of\n$\\epsilon$-optimality for the proposed scheme is provided and numeric\nexperiments are carried out on benchmark environments to verify its\neffectiveness. The results show that, without any parameter tuning cost, the\nproposed parameter-free learning automaton (PFLA) can achieve a competitive\nperformance compared with other well-tuned schemes and outperform untuned\nschemes on consistency of performance.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 04:08:31 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Ge", "Hao", ""]]}, {"id": "1711.10123", "submitter": "Jaehee Jang", "authors": "Jaehee Jang and Byungook Na and Sungroh Yoon", "title": "Homomorphic Parameter Compression for Distributed Deep Learning Training", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed training of deep neural networks has received significant\nresearch interest, and its major approaches include implementations on multiple\nGPUs and clusters. Parallelization can dramatically improve the efficiency of\ntraining deep and complicated models with large-scale data. A fundamental\nbarrier against the speedup of DNN training, however, is the trade-off between\ncomputation and communication time. In other words, increasing the number of\nworker nodes decreases the time consumed in computation while simultaneously\nincreasing communication overhead under constrained network bandwidth,\nespecially in commodity hardware environments. To alleviate this trade-off, we\nsuggest the idea of homomorphic parameter compression, which compresses\nparameters with the least expense and trains the DNN with the compressed\nrepresentation. Although the specific method is yet to be discovered, we\ndemonstrate that there is a high probability that the homomorphism can reduce\nthe communication overhead, thanks to little compression and decompression\ntimes. We also provide theoretical speedup of homomorphic compression.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 04:47:59 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Jang", "Jaehee", ""], ["Na", "Byungook", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1711.10125", "submitter": "Yen-Chang Hsu", "authors": "Yen-Chang Hsu, Zhaoyang Lv, Zsolt Kira", "title": "Learning to cluster in order to transfer across domains and tasks", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel method to perform transfer learning across\ndomains and tasks, formulating it as a problem of learning to cluster. The key\ninsight is that, in addition to features, we can transfer similarity\ninformation and this is sufficient to learn a similarity function and\nclustering network to perform both domain adaptation and cross-task transfer\nlearning. We begin by reducing categorical information to pairwise constraints,\nwhich only considers whether two instances belong to the same class or not.\nThis similarity is category-agnostic and can be learned from data in the source\ndomain using a similarity network. We then present two novel approaches for\nperforming transfer learning using this similarity function. First, for\nunsupervised domain adaptation, we design a new loss function to regularize\nclassification with a constrained clustering loss, hence learning a clustering\nnetwork with the transferred similarity metric generating the training inputs.\nSecond, for cross-task learning (i.e., unsupervised clustering with unseen\ncategories), we propose a framework to reconstruct and estimate the number of\nsemantic clusters, again using the clustering network. Since the similarity\nnetwork is noisy, the key is to use a robust clustering algorithm, and we show\nthat our formulation is more robust than the alternative constrained and\nunconstrained clustering approaches. Using this method, we first show state of\nthe art results for the challenging cross-task problem, applied on Omniglot and\nImageNet. Our results show that we can reconstruct semantic clusters with high\naccuracy. We then evaluate the performance of cross-domain transfer using\nimages from the Office-31 and SVHN-MNIST tasks and present top accuracy on both\ndatasets. Our approach doesn't explicitly deal with domain discrepancy. If we\ncombine with a domain adaptation loss, it shows further improvement.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 04:59:58 GMT"}, {"version": "v2", "created": "Tue, 2 Jan 2018 15:54:59 GMT"}, {"version": "v3", "created": "Sat, 17 Mar 2018 04:42:49 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Hsu", "Yen-Chang", ""], ["Lv", "Zhaoyang", ""], ["Kira", "Zsolt", ""]]}, {"id": "1711.10127", "submitter": "Ching-An Cheng", "authors": "Ching-An Cheng, Byron Boots", "title": "Variational Inference for Gaussian Process Models with Linear Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale Gaussian process inference has long faced practical challenges\ndue to time and space complexity that is superlinear in dataset size. While\nsparse variational Gaussian process models are capable of learning from\nlarge-scale data, standard strategies for sparsifying the model can prevent the\napproximation of complex functions. In this work, we propose a novel\nvariational Gaussian process model that decouples the representation of mean\nand covariance functions in reproducing kernel Hilbert space. We show that this\nnew parametrization generalizes previous models. Furthermore, it yields a\nvariational inference problem that can be solved by stochastic gradient ascent\nwith time and space complexity that is only linear in the number of mean\nfunction parameters, regardless of the choice of kernels, likelihoods, and\ninducing points. This strategy makes the adoption of large-scale expressive\nGaussian process models possible. We run several experiments on regression\ntasks and show that this decoupled approach greatly outperforms previous sparse\nvariational Gaussian process inference procedures.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 05:29:32 GMT"}, {"version": "v2", "created": "Mon, 22 Jan 2018 18:41:36 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Cheng", "Ching-An", ""], ["Boots", "Byron", ""]]}, {"id": "1711.10137", "submitter": "Jake Bruce", "authors": "Jake Bruce, Niko Suenderhauf, Piotr Mirowski, Raia Hadsell, Michael\n  Milford", "title": "One-Shot Reinforcement Learning for Robot Navigation with Interactive\n  Replay", "comments": "NIPS Workshop on Acting and Interacting in the Real World: Challenges\n  in Robot Learning", "journal-ref": "Bruce, Jake, et al. \"One-Shot Reinforcement Learning for Robot\n  Navigation with Interactive Replay.\" Proceedings of the NIPS Workshop on\n  Acting and Interacting in the Real World: Challenges in Robot Learning. 2017", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, model-free reinforcement learning algorithms have been shown to\nsolve challenging problems by learning from extensive interaction with the\nenvironment. A significant issue with transferring this success to the robotics\ndomain is that interaction with the real world is costly, but training on\nlimited experience is prone to overfitting. We present a method for learning to\nnavigate, to a fixed goal and in a known environment, on a mobile robot. The\nrobot leverages an interactive world model built from a single traversal of the\nenvironment, a pre-trained visual feature encoder, and stochastic environmental\naugmentation, to demonstrate successful zero-shot transfer under real-world\nenvironmental variations without fine-tuning.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 06:03:14 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 02:56:39 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Bruce", "Jake", ""], ["Suenderhauf", "Niko", ""], ["Mirowski", "Piotr", ""], ["Hadsell", "Raia", ""], ["Milford", "Michael", ""]]}, {"id": "1711.10144", "submitter": "Jeff Calder", "authors": "Jeff Calder", "title": "The game theoretic p-Laplacian and semi-supervised learning with few\n  labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.LG math.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the game theoretic p-Laplacian for semi-supervised learning on\ngraphs, and show that it is well-posed in the limit of finite labeled data and\ninfinite unlabeled data. In particular, we show that the continuum limit of\ngraph-based semi-supervised learning with the game theoretic p-Laplacian is a\nweighted version of the continuous p-Laplace equation. We also prove that\nsolutions to the graph p-Laplace equation are approximately Holder continuous\nwith high probability. Our proof uses the viscosity solution machinery and the\nmaximum principle on a graph.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 06:39:31 GMT"}, {"version": "v2", "created": "Sat, 20 Jan 2018 02:19:47 GMT"}, {"version": "v3", "created": "Fri, 29 Jun 2018 03:29:18 GMT"}, {"version": "v4", "created": "Mon, 27 Aug 2018 16:47:22 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Calder", "Jeff", ""]]}, {"id": "1711.10157", "submitter": "Utako Yamamoto", "authors": "Utako Yamamoto, Megumi Nakao, Masayuki Ohzeki and Tetsuya Matsuda", "title": "Deformation estimation of an elastic object by partial observation using\n  a neural network", "comments": "12 pages, 12 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deformation estimation of elastic object assuming an internal organ is\nimportant for the computer navigation of surgery. The aim of this study is to\nestimate the deformation of an entire three-dimensional elastic object using\ndisplacement information of very few observation points. A learning approach\nwith a neural network was introduced to estimate the entire deformation of an\nobject. We applied our method to two elastic objects; a rectangular\nparallelepiped model, and a human liver model reconstructed from computed\ntomography data. The average estimation error for the human liver model was\n0.041 mm when the object was deformed up to 66.4 mm, from only around 3 %\nobservations. These results indicate that the deformation of an entire elastic\nobject can be estimated with an acceptable level of error from limited\nobservations by applying a trained neural network to a new deformation.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 07:28:48 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Yamamoto", "Utako", ""], ["Nakao", "Megumi", ""], ["Ohzeki", "Masayuki", ""], ["Matsuda", "Tetsuya", ""]]}, {"id": "1711.10160", "submitter": "Alexander Ratner", "authors": "Alexander Ratner, Stephen H. Bach, Henry Ehrenberg, Jason Fries, Sen\n  Wu, Christopher R\\'e", "title": "Snorkel: Rapid Training Data Creation with Weak Supervision", "comments": null, "journal-ref": "Proceedings of the VLDB Endowment, 11(3), 269-282, 2017", "doi": "10.14778/3157794.3157797", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labeling training data is increasingly the largest bottleneck in deploying\nmachine learning systems. We present Snorkel, a first-of-its-kind system that\nenables users to train state-of-the-art models without hand labeling any\ntraining data. Instead, users write labeling functions that express arbitrary\nheuristics, which can have unknown accuracies and correlations. Snorkel\ndenoises their outputs without access to ground truth by incorporating the\nfirst end-to-end implementation of our recently proposed machine learning\nparadigm, data programming. We present a flexible interface layer for writing\nlabeling functions based on our experience over the past year collaborating\nwith companies, agencies, and research labs. In a user study, subject matter\nexperts build models 2.8x faster and increase predictive performance an average\n45.5% versus seven hours of hand labeling. We study the modeling tradeoffs in\nthis new setting and propose an optimizer for automating tradeoff decisions\nthat gives up to 1.8x speedup per pipeline execution. In two collaborations,\nwith the U.S. Department of Veterans Affairs and the U.S. Food and Drug\nAdministration, and on four open-source text and image data sets representative\nof other deployments, Snorkel provides 132% average improvements to predictive\nperformance over prior heuristic approaches and comes within an average 3.60%\nof the predictive performance of large hand-curated training sets.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 07:48:05 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Ratner", "Alexander", ""], ["Bach", "Stephen H.", ""], ["Ehrenberg", "Henry", ""], ["Fries", "Jason", ""], ["Wu", "Sen", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1711.10162", "submitter": "Vincent Zheng", "authors": "Jia Wang, Vincent W. Zheng, Zemin Liu, Kevin Chen-Chuan Chang", "title": "Topological Recurrent Neural Network for Diffusion Prediction", "comments": "In Proc. of The IEEE International Conference on Data Mining (ICDM\n  '17), New Orleans, Louisiana, USA, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of using representation learning to\nassist information diffusion prediction on graphs. In particular, we aim at\nestimating the probability of an inactive node to be activated next in a\ncascade. Despite the success of recent deep learning methods for diffusion, we\nfind that they often underexplore the cascade structure. We consider a cascade\nas not merely a sequence of nodes ordered by their activation time stamps;\ninstead, it has a richer structure indicating the diffusion process over the\ndata graph. As a result, we introduce a new data model, namely diffusion\ntopologies, to fully describe the cascade structure. We find it challenging to\nmodel diffusion topologies, which are dynamic directed acyclic graphs (DAGs),\nwith the existing neural networks. Therefore, we propose a novel topological\nrecurrent neural network, namely Topo-LSTM, for modeling dynamic DAGs. We\ncustomize Topo-LSTM for the diffusion prediction task, and show it improves the\nstate-of-the-art baselines, by 20.1%--56.6% (MAP) relatively, across multiple\nreal-world data sets. Our code and data sets are available online at\nhttps://github.com/vwz/topolstm.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 07:53:51 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 03:20:41 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Wang", "Jia", ""], ["Zheng", "Vincent W.", ""], ["Liu", "Zemin", ""], ["Chang", "Kevin Chen-Chuan", ""]]}, {"id": "1711.10166", "submitter": "Tomas Kliegr", "authors": "Tomas Kliegr", "title": "QCBA: Postoptimization of Quantitative Attributes in Classifiers based\n  on Association Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need to prediscretize numeric attributes before they can be used in\nassociation rule learning is a source of inefficiencies in the resulting\nclassifier. This paper describes several new rule tuning steps aiming to\nrecover information lost in the discretization of numeric (quantitative)\nattributes, and a new rule pruning strategy, which further reduces the size of\nthe classification models. We demonstrate the effectiveness of the proposed\nmethods on postoptimization of models generated by three state-of-the-art\nassociation rule classification algorithms: Classification based on\nAssociations (Liu, 1998), Interpretable Decision Sets (Lakkaraju et al, 2016),\nand Scalable Bayesian Rule Lists (Yang, 2017). Benchmarks on 22 datasets from\nthe UCI repository show that the postoptimized models are consistently smaller\n-- typically by about 50% -- and have better classification performance on most\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 08:09:14 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 12:22:17 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Kliegr", "Tomas", ""]]}, {"id": "1711.10168", "submitter": "Kenta Oono", "authors": "Hai Nguyen, Shin-ichi Maeda, Kenta Oono", "title": "Semi-supervised learning of hierarchical representations of molecules\n  using neural message passing", "comments": "8 pages, 2 figures. Appeared as a poster presentation in workshop on\n  Machine Learning for Molecules and Materials in NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid increase of compound databases available in medicinal and\nmaterial science, there is a growing need for learning representations of\nmolecules in a semi-supervised manner. In this paper, we propose an\nunsupervised hierarchical feature extraction algorithm for molecules (or more\ngenerally, graph-structured objects with fixed number of types of nodes and\nedges), which is applicable to both unsupervised and semi-supervised tasks. Our\nmethod extends recently proposed Paragraph Vector algorithm and incorporates\nneural message passing to obtain hierarchical representations of subgraphs. We\napplied our method to an unsupervised task and demonstrated that it outperforms\nexisting proposed methods in several benchmark datasets. We also experimentally\nshowed that semi-supervised tasks enhanced predictive performance compared with\nsupervised ones with labeled molecules only.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 08:13:17 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 02:17:17 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Nguyen", "Hai", ""], ["Maeda", "Shin-ichi", ""], ["Oono", "Kenta", ""]]}, {"id": "1711.10173", "submitter": "Takayuki Osa", "authors": "Takayuki Osa and Masashi Sugiyama", "title": "Hierarchical Policy Search via Return-Weighted Density Estimation", "comments": "The 32nd AAAI Conference on Artificial Intelligence (AAAI 2018), 9\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning an optimal policy from a multi-modal reward function is a\nchallenging problem in reinforcement learning (RL). Hierarchical RL (HRL)\ntackles this problem by learning a hierarchical policy, where multiple option\npolicies are in charge of different strategies corresponding to modes of a\nreward function and a gating policy selects the best option for a given\ncontext. Although HRL has been demonstrated to be promising, current\nstate-of-the-art methods cannot still perform well in complex real-world\nproblems due to the difficulty of identifying modes of the reward function. In\nthis paper, we propose a novel method called hierarchical policy search via\nreturn-weighted density estimation (HPSDE), which can efficiently identify the\nmodes through density estimation with return-weighted importance sampling. Our\nproposed method finds option policies corresponding to the modes of the return\nfunction and automatically determines the number and the location of option\npolicies, which significantly reduces the burden of hyper-parameters tuning.\nThrough experiments, we demonstrate that the proposed HPSDE successfully learns\noption policies corresponding to modes of the return function and that it can\nbe successfully applied to a challenging motion planning problem of a redundant\nrobotic manipulator.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 08:30:11 GMT"}, {"version": "v2", "created": "Thu, 30 Nov 2017 08:43:26 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Osa", "Takayuki", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1711.10204", "submitter": "Kevin O'Regan", "authors": "Guglielmo Montone, J. Kevin O'Regan, Alexander V. Terekhov", "title": "Block Neural Network Avoids Catastrophic Forgetting When Learning\n  Multiple Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present work we propose a Deep Feed Forward network architecture which\ncan be trained according to a sequential learning paradigm, where tasks of\nincreasing difficulty are learned sequentially, yet avoiding catastrophic\nforgetting. The proposed architecture can re-use the features learned on\nprevious tasks in a new task when the old tasks and the new one are related.\nThe architecture needs fewer computational resources (neurons and connections)\nand less data for learning the new task than a network trained from scratch\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 09:47:51 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Montone", "Guglielmo", ""], ["O'Regan", "J. Kevin", ""], ["Terekhov", "Alexander V.", ""]]}, {"id": "1711.10207", "submitter": "Mohsen Ahmadi Fahandar", "authors": "Mohsen Ahmadi Fahandar, Eyke H\\\"ullermeier", "title": "Learning to Rank based on Analogical Reasoning", "comments": "Thirty-Second AAAI Conference on Artificial Intelligence (AAAI-18), 8\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object ranking or \"learning to rank\" is an important problem in the realm of\npreference learning. On the basis of training data in the form of a set of\nrankings of objects represented as feature vectors, the goal is to learn a\nranking function that predicts a linear order of any new set of objects. In\nthis paper, we propose a new approach to object ranking based on principles of\nanalogical reasoning. More specifically, our inference pattern is formalized in\nterms of so-called analogical proportions and can be summarized as follows:\nGiven objects $A,B,C,D$, if object $A$ is known to be preferred to $B$, and $C$\nrelates to $D$ as $A$ relates to $B$, then $C$ is (supposedly) preferred to\n$D$. Our method applies this pattern as a main building block and combines it\nwith ideas and techniques from instance-based learning and rank aggregation.\nBased on first experimental results for data sets from various domains (sports,\neducation, tourism, etc.), we conclude that our approach is highly competitive.\nIt appears to be specifically interesting in situations in which the objects\nare coming from different subdomains, and which hence require a kind of\nknowledge transfer.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 09:51:18 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Fahandar", "Mohsen Ahmadi", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "1711.10282", "submitter": "Yuji Tokozume", "authors": "Yuji Tokozume, Yoshitaka Ushiku, Tatsuya Harada", "title": "Learning from Between-class Examples for Deep Sound Recognition", "comments": "13 pages, 6 figures, published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods have achieved high performance in sound recognition\ntasks. Deciding how to feed the training data is important for further\nperformance improvement. We propose a novel learning method for deep sound\nrecognition: Between-Class learning (BC learning). Our strategy is to learn a\ndiscriminative feature space by recognizing the between-class sounds as\nbetween-class sounds. We generate between-class sounds by mixing two sounds\nbelonging to different classes with a random ratio. We then input the mixed\nsound to the model and train the model to output the mixing ratio. The\nadvantages of BC learning are not limited only to the increase in variation of\nthe training data; BC learning leads to an enlargement of Fisher's criterion in\nthe feature space and a regularization of the positional relationship among the\nfeature distributions of the classes. The experimental results show that BC\nlearning improves the performance on various sound recognition networks,\ndatasets, and data augmentation schemes, in which BC learning proves to be\nalways beneficial. Furthermore, we construct a new deep sound recognition\nnetwork (EnvNet-v2) and train it with BC learning. As a result, we achieved a\nperformance surpasses the human level.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 13:29:45 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 12:41:50 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Tokozume", "Yuji", ""], ["Ushiku", "Yoshitaka", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1711.10284", "submitter": "Yuji Tokozume", "authors": "Yuji Tokozume, Yoshitaka Ushiku, Tatsuya Harada", "title": "Between-class Learning for Image Classification", "comments": "11 pages, 8 figures, published as a conference paper at CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel learning method for image classification\ncalled Between-Class learning (BC learning). We generate between-class images\nby mixing two images belonging to different classes with a random ratio. We\nthen input the mixed image to the model and train the model to output the\nmixing ratio. BC learning has the ability to impose constraints on the shape of\nthe feature distributions, and thus the generalization ability is improved. BC\nlearning is originally a method developed for sounds, which can be digitally\nmixed. Mixing two image data does not appear to make sense; however, we argue\nthat because convolutional neural networks have an aspect of treating input\ndata as waveforms, what works on sounds must also work on images. First, we\npropose a simple mixing method using internal divisions, which surprisingly\nproves to significantly improve performance. Second, we propose a mixing method\nthat treats the images as waveforms, which leads to a further improvement in\nperformance. As a result, we achieved 19.4% and 2.26% top-1 errors on\nImageNet-1K and CIFAR-10, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 13:31:14 GMT"}, {"version": "v2", "created": "Sun, 8 Apr 2018 08:50:09 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Tokozume", "Yuji", ""], ["Ushiku", "Yoshitaka", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1711.10292", "submitter": "Rodrigo F. De Mello", "authors": "Rodrigo Fernandes de Mello, Martha Dais Ferreira, Moacir Antonelli\n  Ponti", "title": "Providing theoretical learning guarantees to Deep Learning Networks", "comments": "Submitted to JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) is one of the most common subjects when Machine Learning\nand Data Science approaches are considered. There are clearly two movements\nrelated to DL: the first aggregates researchers in quest to outperform other\nalgorithms from literature, trying to win contests by considering often small\ndecreases in the empirical risk; and the second investigates overfitting\nevidences, questioning the learning capabilities of DL classifiers. Motivated\nby such opposed points of view, this paper employs the Statistical Learning\nTheory (SLT) to study the convergence of Deep Neural Networks, with particular\ninterest in Convolutional Neural Networks. In order to draw theoretical\nconclusions, we propose an approach to estimate the Shattering coefficient of\nthose classification algorithms, providing a lower bound for the complexity of\ntheir space of admissible functions, a.k.a. algorithm bias. Based on such\nestimator, we generalize the complexity of network biases, and, next, we study\nAlexNet and VGG16 architectures in the point of view of their Shattering\ncoefficients, and number of training examples required to provide theoretical\nlearning guarantees. From our theoretical formulation, we show the conditions\nwhich Deep Neural Networks learn as well as point out another issue: DL\nbenchmarks may be strictly driven by empirical risks, disregarding the\ncomplexity of algorithms biases.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 13:54:56 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["de Mello", "Rodrigo Fernandes", ""], ["Ferreira", "Martha Dais", ""], ["Ponti", "Moacir Antonelli", ""]]}, {"id": "1711.10327", "submitter": "Danijar Hafner", "authors": "Danijar Hafner, Alexander Immer, Willi Raschkowski, Fabian Windheuser", "title": "Generative Interest Estimation for Document Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning distributed representations of documents has pushed the\nstate-of-the-art in several natural language processing tasks and was\nsuccessfully applied to the field of recommender systems recently. In this\npaper, we propose a novel content-based recommender system based on learned\nrepresentations and a generative model of user interest. Our method works as\nfollows: First, we learn representations on a corpus of text documents. Then,\nwe capture a user's interest as a generative model in the space of the document\nrepresentations. In particular, we model the distribution of interest for each\nuser as a Gaussian mixture model (GMM). Recommendations can be obtained\ndirectly by sampling from a user's generative model. Using Latent semantic\nanalysis (LSA) as comparison, we compute and explore document representations\non the Delicious bookmarks dataset, a standard benchmark for recommender\nsystems. We then perform density estimation in both spaces and show that\nlearned representations outperform LSA in terms of predictive performance.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 15:00:24 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Hafner", "Danijar", ""], ["Immer", "Alexander", ""], ["Raschkowski", "Willi", ""], ["Windheuser", "Fabian", ""]]}, {"id": "1711.10331", "submitter": "Xu Sun", "authors": "Xu Sun, Weiwei Sun, Shuming Ma, Xuancheng Ren, Yi Zhang, Wenjie Li,\n  Houfeng Wang", "title": "Complex Structure Leads to Overfitting: A Structure Regularization\n  Decoding Method for Natural Language Processing", "comments": "arXiv admin note: text overlap with arXiv:1411.6243", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent systems on structured prediction focus on increasing the level of\nstructural dependencies within the model. However, our study suggests that\ncomplex structures entail high overfitting risks. To control the\nstructure-based overfitting, we propose to conduct structure regularization\ndecoding (SR decoding). The decoding of the complex structure model is\nregularized by the additionally trained simple structure model. We\ntheoretically analyze the quantitative relations between the structural\ncomplexity and the overfitting risk. The analysis shows that complex structure\nmodels are prone to the structure-based overfitting. Empirical evaluations show\nthat the proposed method improves the performance of the complex structure\nmodels by reducing the structure-based overfitting. On the sequence labeling\ntasks, the proposed method substantially improves the performance of the\ncomplex neural network models. The maximum F1 error rate reduction is 36.4% for\nthe third-order model. The proposed method also works for the parsing task. The\nmaximum UAS improvement is 5.5% for the tri-sibling model. The results are\ncompetitive with or better than the state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sat, 25 Nov 2017 07:47:02 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Sun", "Xu", ""], ["Sun", "Weiwei", ""], ["Ma", "Shuming", ""], ["Ren", "Xuancheng", ""], ["Zhang", "Yi", ""], ["Li", "Wenjie", ""], ["Wang", "Houfeng", ""]]}, {"id": "1711.10337", "submitter": "Mario Lucic", "authors": "Mario Lucic, Karol Kurach, Marcin Michalski, Sylvain Gelly, Olivier\n  Bousquet", "title": "Are GANs Created Equal? A Large-Scale Study", "comments": "NIPS'18: Added a section on the limitations of the study and\n  additional empirical results", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GAN) are a powerful subclass of generative\nmodels. Despite a very rich research activity leading to numerous interesting\nGAN algorithms, it is still very hard to assess which algorithm(s) perform\nbetter than others. We conduct a neutral, multi-faceted large-scale empirical\nstudy on state-of-the art models and evaluation measures. We find that most\nmodels can reach similar scores with enough hyperparameter optimization and\nrandom restarts. This suggests that improvements can arise from a higher\ncomputational budget and tuning more than fundamental algorithmic changes. To\novercome some limitations of the current metrics, we also propose several data\nsets on which precision and recall can be computed. Our experimental results\nsuggest that future GAN research should be based on more systematic and\nobjective evaluation procedures. Finally, we did not find evidence that any of\nthe tested algorithms consistently outperforms the non-saturating GAN\nintroduced in \\cite{goodfellow2014generative}.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 15:19:53 GMT"}, {"version": "v2", "created": "Thu, 30 Nov 2017 17:09:16 GMT"}, {"version": "v3", "created": "Tue, 20 Mar 2018 09:18:08 GMT"}, {"version": "v4", "created": "Mon, 29 Oct 2018 15:34:15 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Lucic", "Mario", ""], ["Kurach", "Karol", ""], ["Michalski", "Marcin", ""], ["Gelly", "Sylvain", ""], ["Bousquet", "Olivier", ""]]}, {"id": "1711.10353", "submitter": "Vassilis N. Ioannidis", "authors": "Vassilis N. Ioannidis, Meng Ma, Athanasios N. Nikolakopoulos, Georgios\n  B. Giannakis, and Daniel Romero", "title": "Kernel-based Inference of Functions over Graphs", "comments": "To be published as a chapter in `Adaptive Learning Methods for\n  Nonlinear System Modeling', Elsevier Publishing, Eds. D. Comminiello and J.C.\n  Principe (2018). This chapter surveys recent work on kernel-based inference\n  of functions over graphs including arXiv:1612.03615 and arXiv:1605.07174 and\n  arXiv:1711.09306", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of networks has witnessed an explosive growth over the past decades\nwith several ground-breaking methods introduced. A particularly interesting --\nand prevalent in several fields of study -- problem is that of inferring a\nfunction defined over the nodes of a network. This work presents a versatile\nkernel-based framework for tackling this inference problem that naturally\nsubsumes and generalizes the reconstruction approaches put forth recently by\nthe signal processing on graphs community. Both the static and the dynamic\nsettings are considered along with effective modeling approaches for addressing\nreal-world problems. The herein analytical discussion is complemented by a set\nof numerical examples, which showcase the effectiveness of the presented\ntechniques, as well as their merits related to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 15:43:04 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2018 23:54:38 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Ioannidis", "Vassilis N.", ""], ["Ma", "Meng", ""], ["Nikolakopoulos", "Athanasios N.", ""], ["Giannakis", "Georgios B.", ""], ["Romero", "Daniel", ""]]}, {"id": "1711.10414", "submitter": "Nikita Zhivotovskiy", "authors": "Andrey Kupavskii, Nikita Zhivotovskiy", "title": "When are epsilon-nets small?", "comments": "22 pages; minor changes, accepted version", "journal-ref": null, "doi": "10.1016/j.jcss.2019.12.006", "report-no": null, "categories": "cs.CG cs.LG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many interesting situations the size of epsilon-nets depends only on\n$\\epsilon$ together with different complexity measures. The aim of this paper\nis to give a systematic treatment of such complexity measures arising in\nDiscrete and Computational Geometry and Statistical Learning, and to bridge the\ngap between the results appearing in these two fields. As a byproduct, we\nobtain several new upper bounds on the sizes of epsilon-nets that\ngeneralize/improve the best known general guarantees. In particular, our\nresults work with regimes when small epsilon-nets of size\n$o(\\frac{1}{\\epsilon})$ exist, which are not usually covered by standard upper\nbounds. Inspired by results in Statistical Learning we also give a short proof\nof the Haussler's upper bound on packing numbers.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 17:15:44 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 09:45:13 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 19:46:25 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Kupavskii", "Andrey", ""], ["Zhivotovskiy", "Nikita", ""]]}, {"id": "1711.10433", "submitter": "A\\\"aron van den Oord", "authors": "Aaron van den Oord, Yazhe Li, Igor Babuschkin, Karen Simonyan, Oriol\n  Vinyals, Koray Kavukcuoglu, George van den Driessche, Edward Lockhart, Luis\n  C. Cobo, Florian Stimberg, Norman Casagrande, Dominik Grewe, Seb Noury,\n  Sander Dieleman, Erich Elsen, Nal Kalchbrenner, Heiga Zen, Alex Graves, Helen\n  King, Tom Walters, Dan Belov, Demis Hassabis", "title": "Parallel WaveNet: Fast High-Fidelity Speech Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently-developed WaveNet architecture is the current state of the art\nin realistic speech synthesis, consistently rated as more natural sounding for\nmany different languages than any previous system. However, because WaveNet\nrelies on sequential generation of one audio sample at a time, it is poorly\nsuited to today's massively parallel computers, and therefore hard to deploy in\na real-time production setting. This paper introduces Probability Density\nDistillation, a new method for training a parallel feed-forward network from a\ntrained WaveNet with no significant difference in quality. The resulting system\nis capable of generating high-fidelity speech samples at more than 20 times\nfaster than real-time, and is deployed online by Google Assistant, including\nserving multiple English and Japanese voices.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 17:48:11 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Oord", "Aaron van den", ""], ["Li", "Yazhe", ""], ["Babuschkin", "Igor", ""], ["Simonyan", "Karen", ""], ["Vinyals", "Oriol", ""], ["Kavukcuoglu", "Koray", ""], ["Driessche", "George van den", ""], ["Lockhart", "Edward", ""], ["Cobo", "Luis C.", ""], ["Stimberg", "Florian", ""], ["Casagrande", "Norman", ""], ["Grewe", "Dominik", ""], ["Noury", "Seb", ""], ["Dieleman", "Sander", ""], ["Elsen", "Erich", ""], ["Kalchbrenner", "Nal", ""], ["Zen", "Heiga", ""], ["Graves", "Alex", ""], ["King", "Helen", ""], ["Walters", "Tom", ""], ["Belov", "Dan", ""], ["Hassabis", "Demis", ""]]}, {"id": "1711.10455", "submitter": "Brendan Fong", "authors": "Brendan Fong, David I. Spivak, R\\'emy Tuy\\'eras", "title": "Backprop as Functor: A compositional perspective on supervised learning", "comments": "13 pages + 4 page appendix", "journal-ref": "LICS 2019", "doi": null, "report-no": null, "categories": "math.CT cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A supervised learning algorithm searches over a set of functions $A \\to B$\nparametrised by a space $P$ to find the best approximation to some ideal\nfunction $f\\colon A \\to B$. It does this by taking examples $(a,f(a)) \\in\nA\\times B$, and updating the parameter according to some rule. We define a\ncategory where these update rules may be composed, and show that gradient\ndescent---with respect to a fixed step size and an error function satisfying a\ncertain property---defines a monoidal functor from a category of parametrised\nfunctions to this category of update rules. This provides a structural\nperspective on backpropagation, as well as a broad generalisation of neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 18:34:45 GMT"}, {"version": "v2", "created": "Wed, 13 Dec 2017 00:21:49 GMT"}, {"version": "v3", "created": "Wed, 1 May 2019 15:11:06 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Fong", "Brendan", ""], ["Spivak", "David I.", ""], ["Tuy\u00e9ras", "R\u00e9my", ""]]}, {"id": "1711.10456", "submitter": "Chi Jin", "authors": "Chi Jin, Praneeth Netrapalli, Michael I. Jordan", "title": "Accelerated Gradient Descent Escapes Saddle Points Faster than Gradient\n  Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nesterov's accelerated gradient descent (AGD), an instance of the general\nfamily of \"momentum methods\", provably achieves faster convergence rate than\ngradient descent (GD) in the convex setting. However, whether these methods are\nsuperior to GD in the nonconvex setting remains open. This paper studies a\nsimple variant of AGD, and shows that it escapes saddle points and finds a\nsecond-order stationary point in $\\tilde{O}(1/\\epsilon^{7/4})$ iterations,\nfaster than the $\\tilde{O}(1/\\epsilon^{2})$ iterations required by GD. To the\nbest of our knowledge, this is the first Hessian-free algorithm to find a\nsecond-order stationary point faster than GD, and also the first single-loop\nalgorithm with a faster rate than GD even in the setting of finding a\nfirst-order stationary point. Our analysis is based on two key ideas: (1) the\nuse of a simple Hamiltonian function, inspired by a continuous-time\nperspective, which AGD monotonically decreases per step even for nonconvex\nfunctions, and (2) a novel framework called improve or localize, which is\nuseful for tracking the long-term behavior of gradient-based optimization\nalgorithms. We believe that these techniques may deepen our understanding of\nboth acceleration algorithms and nonconvex optimization.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 18:38:35 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Jin", "Chi", ""], ["Netrapalli", "Praneeth", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1711.10462", "submitter": "Francis Dutil", "authors": "Francis Dutil, Caglar Gulcehre, Adam Trischler, Yoshua Bengio", "title": "Plan, Attend, Generate: Planning for Sequence-to-Sequence Models", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the integration of a planning mechanism into\nsequence-to-sequence models using attention. We develop a model which can plan\nahead in the future when it computes its alignments between input and output\nsequences, constructing a matrix of proposed future alignments and a commitment\nvector that governs whether to follow or recompute the plan. This mechanism is\ninspired by the recently proposed strategic attentive reader and writer (STRAW)\nmodel for Reinforcement Learning. Our proposed model is end-to-end trainable\nusing primarily differentiable operations. We show that it outperforms a strong\nbaseline on character-level translation tasks from WMT'15, the algorithmic task\nof finding Eulerian circuits of graphs, and question generation from the text.\nOur analysis demonstrates that the model computes qualitatively intuitive\nalignments, converges faster than the baselines, and achieves superior\nperformance with fewer parameters.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 18:50:05 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Dutil", "Francis", ""], ["Gulcehre", "Caglar", ""], ["Trischler", "Adam", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1711.10467", "submitter": "Cong Ma", "authors": "Cong Ma, Kaizheng Wang, Yuejie Chi, Yuxin Chen", "title": "Implicit Regularization in Nonconvex Statistical Estimation: Gradient\n  Descent Converges Linearly for Phase Retrieval, Matrix Completion, and Blind\n  Deconvolution", "comments": "accepted to Foundations of Computational Mathematics (FOCM)", "journal-ref": "Foundations of Computational Mathematics, vol. 20, no. 3, pp.\n  451-632, June 2020", "doi": "10.1007/s10208-019-09429-9", "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen a flurry of activities in designing provably efficient\nnonconvex procedures for solving statistical estimation problems. Due to the\nhighly nonconvex nature of the empirical loss, state-of-the-art procedures\noften require proper regularization (e.g. trimming, regularized cost,\nprojection) in order to guarantee fast convergence. For vanilla procedures such\nas gradient descent, however, prior theory either recommends highly\nconservative learning rates to avoid overshooting, or completely lacks\nperformance guarantees.\n  This paper uncovers a striking phenomenon in nonconvex optimization: even in\nthe absence of explicit regularization, gradient descent enforces proper\nregularization implicitly under various statistical models. In fact, gradient\ndescent follows a trajectory staying within a basin that enjoys nice geometry,\nconsisting of points incoherent with the sampling mechanism. This \"implicit\nregularization\" feature allows gradient descent to proceed in a far more\naggressive fashion without overshooting, which in turn results in substantial\ncomputational savings. Focusing on three fundamental statistical estimation\nproblems, i.e. phase retrieval, low-rank matrix completion, and blind\ndeconvolution, we establish that gradient descent achieves near-optimal\nstatistical and computational guarantees without explicit regularization. In\nparticular, by marrying statistical modeling with generic optimization theory,\nwe develop a general recipe for analyzing the trajectories of iterative\nalgorithms via a leave-one-out perturbation argument. As a byproduct, for noisy\nmatrix completion, we demonstrate that gradient descent achieves near-optimal\nerror control --- measured entrywise and by the spectral norm --- which might\nbe of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 18:53:38 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 10:47:03 GMT"}, {"version": "v3", "created": "Tue, 30 Jul 2019 02:14:54 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Ma", "Cong", ""], ["Wang", "Kaizheng", ""], ["Chi", "Yuejie", ""], ["Chen", "Yuxin", ""]]}, {"id": "1711.10540", "submitter": "Fayyaz Minhas", "authors": "Wajid Arshad Abbasi, Fahad Ul Hassan, Adiba Yaseen, Fayyaz Ul Amir\n  Afsar Minhas", "title": "ISLAND: In-Silico Prediction of Proteins Binding Affinity Using Sequence\n  Descriptors", "comments": "Keywords: Protein sequence analysis, Protein-protein interaction,\n  Support vector machines, Web services, Binding affinity", "journal-ref": "BioData Mining, 2020 13:20", "doi": "10.1186/s13040-020-00231-w", "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determination of binding affinity of proteins in the formation of protein\ncomplexes requires sophisticated, expensive and time-consuming experimentation\nwhich can be replaced with computational methods. Most computational prediction\ntechniques require protein structures which limit their applicability to\nprotein complexes with known structures. In this work, we explore sequence\nbased protein binding affinity prediction using machine learning. Our paper\nhighlights the fact that the generalization performance of even the state of\nthe art sequence-only predictor of binding affinity is far from satisfactory\nand that the development of effective and practical methods in this domain is\nstill an open problem. We also propose a novel sequence-only predictor of\nbinding affinity called ISLAND which gives better accuracy than existing\nmethods over the same validation set as well as on external independent test\ndataset. A cloud-based webserver implementation of ISLAND and its Python code\nare available at the URL:\nhttp://faculty.pieas.edu.pk/fayyaz/software.html#island.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 07:54:31 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 06:15:14 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Abbasi", "Wajid Arshad", ""], ["Hassan", "Fahad Ul", ""], ["Yaseen", "Adiba", ""], ["Minhas", "Fayyaz Ul Amir Afsar", ""]]}, {"id": "1711.10558", "submitter": "Biswarup Bhattacharya", "authors": "Biswarup Bhattacharya, Iftikhar Burhanuddin, Abhilasha Sancheti,\n  Kushal Satya", "title": "Intent-Aware Contextual Recommendation System", "comments": "Presented at the 5th International Workshop on Data Science and Big\n  Data Analytics (DSBDA), 17th IEEE International Conference on Data Mining\n  (ICDM) 2017; 8 pages; 4 figures; Due to the limitation \"The abstract field\n  cannot be longer than 1,920 characters,\" the abstract appearing here is\n  slightly shorter than the one in the PDF file", "journal-ref": null, "doi": "10.1109/ICDMW.2017.8", "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems take inputs from user history, use an internal ranking\nalgorithm to generate results and possibly optimize this ranking based on\nfeedback. However, often the recommender system is unaware of the actual intent\nof the user and simply provides recommendations dynamically without properly\nunderstanding the thought process of the user. An intelligent recommender\nsystem is not only useful for the user but also for businesses which want to\nlearn the tendencies of their users. Finding out tendencies or intents of a\nuser is a difficult problem to solve.\n  Keeping this in mind, we sought out to create an intelligent system which\nwill keep track of the user's activity on a web-application as well as\ndetermine the intent of the user in each session. We devised a way to encode\nthe user's activity through the sessions. Then, we have represented the\ninformation seen by the user in a high dimensional format which is reduced to\nlower dimensions using tensor factorization techniques. The aspect of intent\nawareness (or scoring) is dealt with at this stage. Finally, combining the user\nactivity data with the contextual information gives the recommendation score.\nThe final recommendations are then ranked using filtering and collaborative\nrecommendation techniques to show the top-k recommendations to the user. A\nprovision for feedback is also envisioned in the current system which informs\nthe model to update the various weights in the recommender system. Our overall\nmodel aims to combine both frequency-based and context-based recommendation\nsystems and quantify the intent of a user to provide better recommendations.\n  We ran experiments on real-world timestamped user activity data, in the\nsetting of recommending reports to the users of a business analytics tool and\nthe results are better than the baselines. We also tuned certain aspects of our\nmodel to arrive at optimized results.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 21:58:52 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Bhattacharya", "Biswarup", ""], ["Burhanuddin", "Iftikhar", ""], ["Sancheti", "Abhilasha", ""], ["Satya", "Kushal", ""]]}, {"id": "1711.10561", "submitter": "Maziar Raissi", "authors": "Maziar Raissi, Paris Perdikaris, and George Em Karniadakis", "title": "Physics Informed Deep Learning (Part I): Data-driven Solutions of\n  Nonlinear Partial Differential Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NA math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce physics informed neural networks -- neural networks that are\ntrained to solve supervised learning tasks while respecting any given law of\nphysics described by general nonlinear partial differential equations. In this\ntwo part treatise, we present our developments in the context of solving two\nmain classes of problems: data-driven solution and data-driven discovery of\npartial differential equations. Depending on the nature and arrangement of the\navailable data, we devise two distinct classes of algorithms, namely continuous\ntime and discrete time models. The resulting neural networks form a new class\nof data-efficient universal function approximators that naturally encode any\nunderlying physical laws as prior information. In this first part, we\ndemonstrate how these networks can be used to infer solutions to partial\ndifferential equations, and obtain physics-informed surrogate models that are\nfully differentiable with respect to all input coordinates and free parameters.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 21:21:59 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Raissi", "Maziar", ""], ["Perdikaris", "Paris", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1711.10563", "submitter": "Ronald Kemker", "authors": "Ronald Kemker and Christopher Kanan", "title": "FearNet: Brain-Inspired Model for Incremental Learning", "comments": "To appear in ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incremental class learning involves sequentially learning classes in bursts\nof examples from the same class. This violates the assumptions that underlie\nmethods for training standard deep neural networks, and will cause them to\nsuffer from catastrophic forgetting. Arguably, the best method for incremental\nclass learning is iCaRL, but it requires storing training examples for each\nclass, making it challenging to scale. Here, we propose FearNet for incremental\nclass learning. FearNet is a generative model that does not store previous\nexamples, making it memory efficient. FearNet uses a brain-inspired dual-memory\nsystem in which new memories are consolidated from a network for recent\nmemories inspired by the mammalian hippocampal complex to a network for\nlong-term storage inspired by medial prefrontal cortex. Memory consolidation is\ninspired by mechanisms that occur during sleep. FearNet also uses a module\ninspired by the basolateral amygdala for determining which memory system to use\nfor recall. FearNet achieves state-of-the-art performance at incremental class\nlearning on image (CIFAR-100, CUB-200) and audio classification (AudioSet)\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 21:26:15 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 20:32:27 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Kemker", "Ronald", ""], ["Kanan", "Christopher", ""]]}, {"id": "1711.10566", "submitter": "Maziar Raissi", "authors": "Maziar Raissi, Paris Perdikaris, and George Em Karniadakis", "title": "Physics Informed Deep Learning (Part II): Data-driven Discovery of\n  Nonlinear Partial Differential Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG math.AP math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce physics informed neural networks -- neural networks that are\ntrained to solve supervised learning tasks while respecting any given law of\nphysics described by general nonlinear partial differential equations. In this\nsecond part of our two-part treatise, we focus on the problem of data-driven\ndiscovery of partial differential equations. Depending on whether the available\ndata is scattered in space-time or arranged in fixed temporal snapshots, we\nintroduce two main classes of algorithms, namely continuous time and discrete\ntime models. The effectiveness of our approach is demonstrated using a wide\nrange of benchmark problems in mathematical physics, including conservation\nlaws, incompressible fluid flow, and the propagation of nonlinear shallow-water\nwaves.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 21:29:35 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Raissi", "Maziar", ""], ["Perdikaris", "Paris", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1711.10589", "submitter": "Ninghao Liu", "authors": "Ninghao Liu, Donghwa Shin, Xia Hu", "title": "Contextual Outlier Interpretation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection plays an essential role in many data-driven applications to\nidentify isolated instances that are different from the majority. While many\nstatistical learning and data mining techniques have been used for developing\nmore effective outlier detection algorithms, the interpretation of detected\noutliers does not receive much attention. Interpretation is becoming\nincreasingly important to help people trust and evaluate the developed models\nthrough providing intrinsic reasons why the certain outliers are chosen. It is\ndifficult, if not impossible, to simply apply feature selection for explaining\noutliers due to the distinct characteristics of various detection models,\ncomplicated structures of data in certain applications, and imbalanced\ndistribution of outliers and normal instances. In addition, the role of\ncontrastive contexts where outliers locate, as well as the relation between\noutliers and contexts, are usually overlooked in interpretation. To tackle the\nissues above, in this paper, we propose a novel Contextual Outlier\nINterpretation (COIN) method to explain the abnormality of existing outliers\nspotted by detectors. The interpretability for an outlier is achieved from\nthree aspects: outlierness score, attributes that contribute to the\nabnormality, and contextual description of its neighborhoods. Experimental\nresults on various types of datasets demonstrate the flexibility and\neffectiveness of the proposed framework compared with existing interpretation\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 22:17:56 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 21:37:27 GMT"}, {"version": "v3", "created": "Fri, 4 May 2018 23:25:18 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Liu", "Ninghao", ""], ["Shin", "Donghwa", ""], ["Hu", "Xia", ""]]}, {"id": "1711.10604", "submitter": "Dustin Tran", "authors": "Joshua V. Dillon, Ian Langmore, Dustin Tran, Eugene Brevdo, Srinivas\n  Vasudevan, Dave Moore, Brian Patton, Alex Alemi, Matt Hoffman, Rif A. Saurous", "title": "TensorFlow Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The TensorFlow Distributions library implements a vision of probability\ntheory adapted to the modern deep-learning paradigm of end-to-end\ndifferentiable computation. Building on two basic abstractions, it offers\nflexible building blocks for probabilistic computation. Distributions provide\nfast, numerically stable methods for generating samples and computing\nstatistics, e.g., log density. Bijectors provide composable volume-tracking\ntransformations with automatic caching. Together these enable modular\nconstruction of high dimensional distributions and transformations not possible\nwith previous libraries (e.g., pixelCNNs, autoregressive flows, and reversible\nresidual networks). They are the workhorse behind deep probabilistic\nprogramming systems like Edward and empower fast black-box inference in\nprobabilistic models built on deep-network components. TensorFlow Distributions\nhas proven an important part of the TensorFlow toolkit within Google and in the\nbroader deep learning community.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 23:05:15 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Dillon", "Joshua V.", ""], ["Langmore", "Ian", ""], ["Tran", "Dustin", ""], ["Brevdo", "Eugene", ""], ["Vasudevan", "Srinivas", ""], ["Moore", "Dave", ""], ["Patton", "Brian", ""], ["Alemi", "Alex", ""], ["Hoffman", "Matt", ""], ["Saurous", "Rif A.", ""]]}, {"id": "1711.10677", "submitter": "Richard Nock", "authors": "Stephen Hardy, Wilko Henecka, Hamish Ivey-Law, Richard Nock, Giorgio\n  Patrini, Guillaume Smith, Brian Thorne", "title": "Private federated learning on vertically partitioned data via entity\n  resolution and additively homomorphic encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider two data providers, each maintaining private records of different\nfeature sets about common entities. They aim to learn a linear model jointly in\na federated setting, namely, data is local and a shared model is trained from\nlocally computed updates. In contrast with most work on distributed learning,\nin this scenario (i) data is split vertically, i.e. by features, (ii) only one\ndata provider knows the target variable and (iii) entities are not linked\nacross the data providers. Hence, to the challenge of private learning, we add\nthe potentially negative consequences of mistakes in entity resolution. Our\ncontribution is twofold. First, we describe a three-party end-to-end solution\nin two phases ---privacy-preserving entity resolution and federated logistic\nregression over messages encrypted with an additively homomorphic scheme---,\nsecure against a honest-but-curious adversary. The system allows learning\nwithout either exposing data in the clear or sharing which entities the data\nproviders have in common. Our implementation is as accurate as a naive\nnon-private solution that brings all data in one place, and scales to problems\nwith millions of entities with hundreds of features. Second, we provide what is\nto our knowledge the first formal analysis of the impact of entity resolution's\nmistakes on learning, with results on how optimal classifiers, empirical\nlosses, margins and generalisation abilities are affected. Our results bring a\nclear and strong support for federated learning: under reasonable assumptions\non the number and magnitude of entity resolution's mistakes, it can be\nextremely beneficial to carry out federated learning in the setting where each\npeer's data provides a significant uplift to the other.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 04:29:29 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Hardy", "Stephen", ""], ["Henecka", "Wilko", ""], ["Ivey-Law", "Hamish", ""], ["Nock", "Richard", ""], ["Patrini", "Giorgio", ""], ["Smith", "Guillaume", ""], ["Thorne", "Brian", ""]]}, {"id": "1711.10718", "submitter": "Yue Mao", "authors": "Yue Mao, Yi Shen, Gang Qin, Longjun Cai", "title": "Predicting the Popularity of Online Videos via Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the popularity of online videos is important for video streaming\ncontent providers. This is a challenging problem because of the following two\nreasons. First, the problem is both \"wide\" and \"deep\". That is, it not only\ndepends on a wide range of features, but also be highly non-linear and complex.\nSecond, multiple competitors may be involved. In this paper, we propose a\ngeneral prediction model using the multi-task learning (MTL) module and the\nrelation network (RN) module, where MTL can reduce over-fitting and RN can\nmodel the relations of multiple competitors. Experimental results show that our\nproposed approach significantly increases the accuracy on predicting the total\nview counts of TV series with RN and MTL modules.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 08:11:19 GMT"}, {"version": "v2", "created": "Thu, 30 Nov 2017 02:49:17 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Mao", "Yue", ""], ["Shen", "Yi", ""], ["Qin", "Gang", ""], ["Cai", "Longjun", ""]]}, {"id": "1711.10781", "submitter": "Stephan Rabanser", "authors": "Stephan Rabanser, Oleksandr Shchur, Stephan G\\\"unnemann", "title": "Introduction to Tensor Decompositions and their Applications in Machine\n  Learning", "comments": "13 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensors are multidimensional arrays of numerical values and therefore\ngeneralize matrices to multiple dimensions. While tensors first emerged in the\npsychometrics community in the $20^{\\text{th}}$ century, they have since then\nspread to numerous other disciplines, including machine learning. Tensors and\ntheir decompositions are especially beneficial in unsupervised learning\nsettings, but are gaining popularity in other sub-disciplines like temporal and\nmulti-relational data analysis, too.\n  The scope of this paper is to give a broad overview of tensors, their\ndecompositions, and how they are used in machine learning. As part of this, we\nare going to introduce basic tensor concepts, discuss why tensors can be\nconsidered more rigid than matrices with respect to the uniqueness of their\ndecomposition, explain the most important factorization algorithms and their\nproperties, provide concrete examples of tensor decomposition applications in\nmachine learning, conduct a case study on tensor-based estimation of mixture\nmodels, talk about the current state of research, and provide references to\navailable software libraries.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 11:29:09 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Rabanser", "Stephan", ""], ["Shchur", "Oleksandr", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1711.10785", "submitter": "Mogens Graf Plessen", "authors": "Mogens Graf Plessen", "title": "Automating Vehicles by Deep Reinforcement Learning using Task Separation\n  with Hill Climbing", "comments": "10 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the context of autonomous driving a model-based reinforcement learning\nalgorithm is proposed for the design of neural network-parameterized\ncontrollers. Classical model-based control methods, which include sampling- and\nlattice-based algorithms and model predictive control, suffer from the\ntrade-off between model complexity and computational burden required for the\nonline solution of expensive optimization or search problems at every short\nsampling time. To circumvent this trade-off, a 2-step procedure is motivated:\nfirst learning of a controller during offline training based on an arbitrarily\ncomplicated mathematical system model, before online fast feedforward\nevaluation of the trained controller. The contribution of this paper is the\nproposition of a simple gradient-free and model-based algorithm for deep\nreinforcement learning using task separation with hill climbing (TSHC). In\nparticular, (i) simultaneous training on separate deterministic tasks with the\npurpose of encoding many motion primitives in a neural network, and (ii) the\nemployment of maximally sparse rewards in combination with virtual velocity\nconstraints (VVCs) in setpoint proximity are advocated.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 11:37:29 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 12:49:52 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Plessen", "Mogens Graf", ""]]}, {"id": "1711.10789", "submitter": "Thomas Moerland", "authors": "Thomas M. Moerland, Joost Broekens and Catholijn M. Jonker", "title": "Efficient exploration with Double Uncertain Value Networks", "comments": "Deep Reinforcement Learning Symposium @ Conference on Neural\n  Information Processing Systems (NIPS) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies directed exploration for reinforcement learning agents by\ntracking uncertainty about the value of each available action. We identify two\nsources of uncertainty that are relevant for exploration. The first originates\nfrom limited data (parametric uncertainty), while the second originates from\nthe distribution of the returns (return uncertainty). We identify methods to\nlearn these distributions with deep neural networks, where we estimate\nparametric uncertainty with Bayesian drop-out, while return uncertainty is\npropagated through the Bellman equation as a Gaussian distribution. Then, we\nidentify that both can be jointly estimated in one network, which we call the\nDouble Uncertain Value Network. The policy is directly derived from the learned\ndistributions based on Thompson sampling. Experimental results show that both\ntypes of uncertainty may vastly improve learning in domains with a strong\nexploration challenge.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 11:41:41 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Moerland", "Thomas M.", ""], ["Broekens", "Joost", ""], ["Jonker", "Catholijn M.", ""]]}, {"id": "1711.10791", "submitter": "Rasool Fakoor", "authors": "Rasool Fakoor, Xiaodong He, Ivan Tashev, Shuayb Zarar", "title": "Reinforcement Learning To Adapt Speech Enhancement to Instantaneous\n  Input Signal Quality", "comments": "NIPS 2017, Machine Learning for Audio Signal Processing workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, the optimal performance of existing noise-suppression algorithms, both\ndata-driven and those based on classic statistical methods, is range bound to\nspecific levels of instantaneous input signal-to-noise ratios. In this paper,\nwe present a new approach to improve the adaptivity of such algorithms enabling\nthem to perform robustly across a wide range of input signal and noise types.\nOur methodology is based on the dynamic control of algorithmic parameters via\nreinforcement learning. Specifically, we model the noise-suppression module as\na black box, requiring no knowledge of the algorithmic mechanics except a\nsimple feedback from the output. We utilize this feedback as the reward signal\nfor a reinforcement-learning agent that learns a policy to adapt the\nalgorithmic parameters for every incoming audio frame (16 ms of data). Our\npreliminary results show that such a control mechanism can substantially\nincrease the overall performance of the underlying noise-suppression algorithm;\n42% and 16% improvements in output SNR and MSE, respectively, when compared to\nno adaptivity.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 11:43:13 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2018 06:49:27 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Fakoor", "Rasool", ""], ["He", "Xiaodong", ""], ["Tashev", "Ivan", ""], ["Zarar", "Shuayb", ""]]}, {"id": "1711.10856", "submitter": "Rinu Boney", "authors": "Rinu Boney and Alexander Ilin", "title": "Semi-Supervised and Active Few-Shot Learning with Prototypical Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of semi-supervised few-shot classification where a\nclassifier needs to adapt to new tasks using a few labeled examples and\n(potentially many) unlabeled examples. We propose a clustering approach to the\nproblem. The features extracted with Prototypical Networks are clustered using\n$K$-means with the few labeled examples guiding the clustering process. We note\nthat in many real-world applications the adaptation performance can be\nsignificantly improved by requesting the few labels through user feedback. We\ndemonstrate good performance of the active adaptation strategy using image\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 14:02:42 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 11:56:17 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Boney", "Rinu", ""], ["Ilin", "Alexander", ""]]}, {"id": "1711.10907", "submitter": "Olexandr Isayev", "authors": "Mariya Popova, Olexandr Isayev, Alexander Tropsha", "title": "Deep Reinforcement Learning for De-Novo Drug Design", "comments": null, "journal-ref": "Science Advances, 2018, vol. 4, no. 7, eaap7885", "doi": "10.1126/sciadv.aap7885", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel computational strategy for de novo design of molecules\nwith desired properties termed ReLeaSE (Reinforcement Learning for Structural\nEvolution). Based on deep and reinforcement learning approaches, ReLeaSE\nintegrates two deep neural networks - generative and predictive - that are\ntrained separately but employed jointly to generate novel targeted chemical\nlibraries. ReLeaSE employs simple representation of molecules by their SMILES\nstrings only. Generative models are trained with stack-augmented memory network\nto produce chemically feasible SMILES strings, and predictive models are\nderived to forecast the desired properties of the de novo generated compounds.\nIn the first phase of the method, generative and predictive models are trained\nseparately with a supervised learning algorithm. In the second phase, both\nmodels are trained jointly with the reinforcement learning approach to bias the\ngeneration of new chemical structures towards those with the desired physical\nand/or biological properties. In the proof-of-concept study, we have employed\nthe ReLeaSE method to design chemical libraries with a bias toward structural\ncomplexity or biased toward compounds with either maximal, minimal, or specific\nrange of physical properties such as melting point or hydrophobicity, as well\nas to develop novel putative inhibitors of JAK2. The approach proposed herein\ncan find a general use for generating targeted chemical libraries of novel\ncompounds optimized for either a single desired property or multiple\nproperties.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 15:10:49 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 17:13:56 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Popova", "Mariya", ""], ["Isayev", "Olexandr", ""], ["Tropsha", "Alexander", ""]]}, {"id": "1711.10915", "submitter": "Marcus Klasson", "authors": "Marcus Klasson, Kun Zhang, Bo C. Bertilson, Cheng Zhang, Hedvig\n  Kjellstr\\\"om", "title": "Causality Refined Diagnostic Prediction", "comments": "NIPS 2017 Workshop on Machine Learning for Health (ML4H)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying machine learning in the health care domain has shown promising\nresults in recent years. Interpretable outputs from learning algorithms are\ndesirable for decision making by health care personnel. In this work, we\nexplore the possibility of utilizing causal relationships to refine diagnostic\nprediction. We focus on the task of diagnostic prediction using discomfort\ndrawings, and explore two ways to employ causal identification to improve the\ndiagnostic results. Firstly, we use causal identification to infer the causal\nrelationships among diagnostic labels which, by itself, provides interpretable\nresults to aid the decision making and training of health care personnel.\nSecondly, we suggest a post-processing approach where the inferred causal\nrelationships are used to refine the prediction accuracy of a multi-view\nprobabilistic model. Experimental results show firstly that causal\nidentification is capable of detecting the causal relationships among\ndiagnostic labels correctly, and secondly that there is potential for improving\npain diagnostics prediction accuracy using the causal relationships.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 15:28:20 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Klasson", "Marcus", ""], ["Zhang", "Kun", ""], ["Bertilson", "Bo C.", ""], ["Zhang", "Cheng", ""], ["Kjellstr\u00f6m", "Hedvig", ""]]}, {"id": "1711.10934", "submitter": "Soroush Saryazdi", "authors": "Soroush Saryazdi, Bahareh Nikpour and Hossein Nezamabadi-pour", "title": "NPC: Neighbors Progressive Competition Algorithm for Classification of\n  Imbalanced Data Sets", "comments": "6 Pages. Accepted Signal Processing and Intelligent Systems (ICSPIS),\n  International Conference of. IEEE, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from many real-world datasets is limited by a problem called the\nclass imbalance problem. A dataset is imbalanced when one class (the majority\nclass) has significantly more samples than the other class (the minority\nclass). Such datasets cause typical machine learning algorithms to perform\npoorly on the classification task. To overcome this issue, this paper proposes\na new approach Neighbors Progressive Competition (NPC) for classification of\nimbalanced datasets. Whilst the proposed algorithm is inspired by weighted\nk-Nearest Neighbor (k-NN) algorithms, it has major differences from them.\nUnlike k- NN, NPC does not limit its decision criteria to a preset number of\nnearest neighbors. In contrast, NPC considers progressively more neighbors of\nthe query sample in its decision making until the sum of grades for one class\nis much higher than the other classes. Furthermore, NPC uses a novel method for\ngrading the training samples to compensate for the imbalance issue. The grades\nare calculated using both local and global information. In brief, the\ncontribution of this paper is an entirely new classifier for handling the\nimbalance issue effectively without any manually-set parameters or any need for\nexpert knowledge. Experimental results compare the proposed approach with five\nrepresentative algorithms applied to fifteen imbalanced datasets and illustrate\nthis algorithms effectiveness.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 16:15:59 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Saryazdi", "Soroush", ""], ["Nikpour", "Bahareh", ""], ["Nezamabadi-pour", "Hossein", ""]]}, {"id": "1711.10938", "submitter": "Fulton Wang", "authors": "Fulton Wang, Cynthia Rudin", "title": "Extreme Dimension Reduction for Handling Covariate Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the covariate shift learning scenario, the training and test covariate\ndistributions differ, so that a predictor's average loss over the training and\ntest distributions also differ. In this work, we explore the potential of\nextreme dimension reduction, i.e. to very low dimensions, in improving the\nperformance of importance weighting methods for handling covariate shift, which\nfail in high dimensions due to potentially high train/test covariate divergence\nand the inability to accurately estimate the requisite density ratios. We first\nformulate and solve a problem optimizing over linear subspaces a combination of\ntheir predictive utility and train/test divergence within. Applying it to\nsimulated and real data, we show extreme dimension reduction helps sometimes\nbut not always, due to a bias introduced by dimension reduction.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 16:20:06 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2018 15:44:49 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Wang", "Fulton", ""], ["Rudin", "Cynthia", ""]]}, {"id": "1711.10967", "submitter": "Kevin Xu", "authors": "Ruthwik R. Junuthula, Maysam Haghdan, Kevin S. Xu, and Vijay K.\n  Devabhaktuni", "title": "The Block Point Process Model for Continuous-Time Event-Based Dynamic\n  Networks", "comments": "To appear at The Web Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of analyzing timestamped relational events between a\nset of entities, such as messages between users of an on-line social network.\nSuch data are often analyzed using static or discrete-time network models,\nwhich discard a significant amount of information by aggregating events over\ntime to form network snapshots. In this paper, we introduce a block point\nprocess model (BPPM) for continuous-time event-based dynamic networks. The BPPM\nis inspired by the well-known stochastic block model (SBM) for static networks.\nWe show that networks generated by the BPPM follow an SBM in the limit of a\ngrowing number of nodes. We use this property to develop principled and\nefficient local search and variational inference procedures initialized by\nregularized spectral clustering. We fit BPPMs with exponential Hawkes processes\nto analyze several real network data sets, including a Facebook wall post\nnetwork with over 3,500 nodes and 130,000 events.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 17:11:28 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 01:56:18 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Junuthula", "Ruthwik R.", ""], ["Haghdan", "Maysam", ""], ["Xu", "Kevin S.", ""], ["Devabhaktuni", "Vijay K.", ""]]}, {"id": "1711.11022", "submitter": "Prithwish Chakraborty", "authors": "Prithwish Chakraborty and Vishrawas Gopalakrishnan and Sharon M.H.\n  Alford and Faisal Farooq", "title": "A Novel Data-Driven Framework for Risk Characterization and Prediction\n  from Electronic Medical Records: A Case Study of Renal Failure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic medical records (EMR) contain longitudinal information about\npatients that can be used to analyze outcomes. Typically, studies on EMR data\nhave worked with established variables that have already been acknowledged to\nbe associated with certain outcomes. However, EMR data may also contain\nhitherto unrecognized factors for risk association and prediction of outcomes\nfor a disease. In this paper, we present a scalable data-driven framework to\nanalyze EMR data corpus in a disease agnostic way that systematically uncovers\nimportant factors influencing outcomes in patients, as supported by data and\nwithout expert guidance. We validate the importance of such factors by using\nthe framework to predict for the relevant outcomes. Specifically, we analyze\nEMR data covering approximately 47 million unique patients to characterize\nrenal failure (RF) among type 2 diabetic (T2DM) patients. We propose a\nspecialized L1 regularized Cox Proportional Hazards (CoxPH) survival model to\nidentify the important factors from those available from patient encounter\nhistory. To validate the identified factors, we use a specialized generalized\nlinear model (GLM) to predict the probability of renal failure for individual\npatients within a specified time window. Our experiments indicate that the\nfactors identified via our data-driven method overlap with the patient\ncharacteristics recognized by experts. Our approach allows for scalable,\nrepeatable and efficient utilization of data available in EMRs, confirms prior\nmedical knowledge and can generate new hypothesis without expert supervision.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 18:50:33 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Chakraborty", "Prithwish", ""], ["Gopalakrishnan", "Vishrawas", ""], ["Alford", "Sharon M. H.", ""], ["Farooq", "Faisal", ""]]}, {"id": "1711.11027", "submitter": "Serhii Havrylov", "authors": "Arthur Bra\\v{z}inskas, Serhii Havrylov, Ivan Titov", "title": "Embedding Words as Distributions with a Bayesian Skip-gram Model", "comments": "COLING 2018. For the associated code, see\n  https://github.com/ixlan/BSG", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method for embedding words as probability densities in a\nlow-dimensional space. Rather than assuming that a word embedding is fixed\nacross the entire text collection, as in standard word embedding methods, in\nour Bayesian model we generate it from a word-specific prior density for each\noccurrence of a given word. Intuitively, for each word, the prior density\nencodes the distribution of its potential 'meanings'. These prior densities are\nconceptually similar to Gaussian embeddings. Interestingly, unlike the Gaussian\nembeddings, we can also obtain context-specific densities: they encode\nuncertainty about the sense of a word given its context and correspond to\nposterior distributions within our model. The context-dependent densities have\nmany potential applications: for example, we show that they can be directly\nused in the lexical substitution task. We describe an effective estimation\nmethod based on the variational autoencoding framework. We also demonstrate\nthat our embeddings achieve competitive results on standard benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 18:55:48 GMT"}, {"version": "v2", "created": "Sun, 10 Jun 2018 15:44:44 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Bra\u017einskas", "Arthur", ""], ["Havrylov", "Serhii", ""], ["Titov", "Ivan", ""]]}, {"id": "1711.11059", "submitter": "Sebastian Urban", "authors": "Sebastian Urban, Marcus Basalla, Patrick van der Smagt", "title": "Gaussian Process Neurons Learn Stochastic Activation Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose stochastic, non-parametric activation functions that are fully\nlearnable and individual to each neuron. Complexity and the risk of overfitting\nare controlled by placing a Gaussian process prior over these functions. The\nresult is the Gaussian process neuron, a probabilistic unit that can be used as\nthe basic building block for probabilistic graphical models that resemble the\nstructure of neural networks. The proposed model can intrinsically handle\nuncertainties in its inputs and self-estimate the confidence of its\npredictions. Using variational Bayesian inference and the central limit\ntheorem, a fully deterministic loss function is derived, allowing it to be\ntrained as efficiently as a conventional neural network using mini-batch\ngradient descent. The posterior distribution of activation functions is\ninferred from the training data alongside the weights of the network.\n  The proposed model favorably compares to deep Gaussian processes, both in\nmodel complexity and efficiency of inference. It can be directly applied to\nrecurrent or convolutional network structures, allowing its use in audio and\nimage processing tasks.\n  As an preliminary empirical evaluation we present experiments on regression\nand classification tasks, in which our model achieves performance comparable to\nor better than a Dropout regularized neural network with a fixed activation\nfunction. Experiments are ongoing and results will be added as they become\navailable.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 19:09:14 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Urban", "Sebastian", ""], ["Basalla", "Marcus", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "1711.11066", "submitter": "Andrew Morgan", "authors": "Andrew Morgan and Rafael Pass", "title": "Paradoxes in Fair Computer-Aided Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-aided decision making--where a human decision-maker is aided by a\ncomputational classifier in making a decision--is becoming increasingly\nprevalent. For instance, judges in at least nine states make use of algorithmic\ntools meant to determine \"recidivism risk scores\" for criminal defendants in\nsentencing, parole, or bail decisions. A subject of much recent debate is\nwhether such algorithmic tools are \"fair\" in the sense that they do not\ndiscriminate against certain groups (e.g., races) of people.\n  Our main result shows that for \"non-trivial\" computer-aided decision making,\neither the classifier must be discriminatory, or a rational decision-maker\nusing the output of the classifier is forced to be discriminatory. We further\nprovide a complete characterization of situations where fair computer-aided\ndecision making is possible.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 19:23:23 GMT"}, {"version": "v2", "created": "Wed, 31 Jan 2018 20:14:48 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Morgan", "Andrew", ""], ["Pass", "Rafael", ""]]}, {"id": "1711.11071", "submitter": "Antonia Korba", "authors": "Antonia Korba", "title": "HSC: A Novel Method for Clustering Hierarchies of Networked Data", "comments": "This is a thesis project, it isn't sufficiently exhaustive", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical clustering is one of the most powerful solutions to the problem\nof clustering, on the grounds that it performs a multi scale organization of\nthe data. In recent years, research on hierarchical clustering methods has\nattracted considerable interest due to the demanding modern application\ndomains.\n  We present a novel divisive hierarchical clustering framework called\nHierarchical Stochastic Clustering (HSC), that acts in two stages. In the first\nstage, it finds a primary hierarchy of clustering partitions in a dataset. In\nthe second stage, feeds a clustering algorithm with each one of the clusters of\nthe very detailed partition, in order to settle the final result. The output is\na hierarchy of clusters. Our method is based on the previous research of Meyer\nand Weissel Stochastic Data Clustering and the theory of Simon and Ando on\nVariable Aggregation.\n  Our experiments show that our framework builds a meaningful hierarchy of\nclusters and benefits consistently the clustering algorithm that acts in the\nsecond stage, not only computationally but also in terms of cluster quality.\nThis result suggest that HSC framework is ideal for obtaining hierarchical\nsolutions of large volumes of data.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 19:29:16 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 11:56:28 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Korba", "Antonia", ""]]}, {"id": "1711.11124", "submitter": "Adit Krishnan", "authors": "Adit Krishnan, Ashish Sharma, Hari Sundaram", "title": "Improving Latent User Models in Online Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern social platforms are characterized by the presence of rich\nuser-behavior data associated with the publication, sharing and consumption of\ntextual content. Users interact with content and with each other in a complex\nand dynamic social environment while simultaneously evolving over time. In\norder to effectively characterize users and predict their future behavior in\nsuch a setting, it is necessary to overcome several challenges. Content\nheterogeneity and temporal inconsistency of behavior data result in severe\nsparsity at the user level. In this paper, we propose a novel\nmutual-enhancement framework to simultaneously partition and learn latent\nactivity profiles of users. We propose a flexible user partitioning approach to\neffectively discover rare behaviors and tackle user-level sparsity. We\nextensively evaluate the proposed framework on massive datasets from real-world\nplatforms including Q&A networks and interactive online courses (MOOCs). Our\nresults indicate significant gains over state-of-the-art behavior models ( 15%\navg ) in a varied range of tasks and our gains are further magnified for users\nwith limited interaction data. The proposed algorithms are amenable to\nparallelization, scale linearly in the size of datasets, and provide\nflexibility to model diverse facets of user behavior.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 06:46:09 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 08:29:57 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Krishnan", "Adit", ""], ["Sharma", "Ashish", ""], ["Sundaram", "Hari", ""]]}, {"id": "1711.11139", "submitter": "Vinay Jethava", "authors": "Vinay Jethava and Devdatt Dubhashi", "title": "Easy High-Dimensional Likelihood-Free Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework using Generative Adversarial Networks (GANs) for\nlikelihood--free inference (LFI) and Approximate Bayesian Computation (ABC)\nwhere we replace the black-box simulator model with an approximator network and\ngenerate a rich set of summary features in a data driven fashion. On benchmark\ndata sets, our approach improves on others with respect to scalability, ability\nto handle high dimensional data and complex probability distributions.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 22:43:20 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 14:27:53 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Jethava", "Vinay", ""], ["Dubhashi", "Devdatt", ""]]}, {"id": "1711.11157", "submitter": "Yitao Liang", "authors": "Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, Guy Van den Broeck", "title": "A Semantic Loss Function for Deep Learning with Symbolic Knowledge", "comments": "This version appears in the Proceedings of the 35th International\n  Conference on Machine Learning (ICML 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a novel methodology for using symbolic knowledge in deep\nlearning. From first principles, we derive a semantic loss function that\nbridges between neural output vectors and logical constraints. This loss\nfunction captures how close the neural network is to satisfying the constraints\non its output. An experimental evaluation shows that it effectively guides the\nlearner to achieve (near-)state-of-the-art results on semi-supervised\nmulti-class classification. Moreover, it significantly increases the ability of\nthe neural network to predict structured objects, such as rankings and paths.\nThese discrete concepts are tremendously difficult to learn, and benefit from a\ntight integration of deep learning and symbolic reasoning methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 23:49:55 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 00:05:58 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Xu", "Jingyi", ""], ["Zhang", "Zilu", ""], ["Friedman", "Tal", ""], ["Liang", "Yitao", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "1711.11165", "submitter": "Tyler Lu", "authors": "Tyler Lu and Martin Zinkevich and Craig Boutilier and Binz Roy and\n  Dale Schuurmans", "title": "Safe Exploration for Identifying Linear Systems via Robust Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safely exploring an unknown dynamical system is critical to the deployment of\nreinforcement learning (RL) in physical systems where failures may have\ncatastrophic consequences. In scenarios where one knows little about the\ndynamics, diverse transition data covering relevant regions of state-action\nspace is needed to apply either model-based or model-free RL. Motivated by the\ncooling of Google's data centers, we study how one can safely identify the\nparameters of a system model with a desired accuracy and confidence level. In\nparticular, we focus on learning an unknown linear system with Gaussian noise\nassuming only that, initially, a nominal safe action is known. Define safety as\nsatisfying specific linear constraints on the state space (e.g., requirements\non process variable) that must hold over the span of an entire trajectory, and\ngiven a Probably Approximately Correct (PAC) style bound on the estimation\nerror of model parameters, we show how to compute safe regions of action space\nby gradually growing a ball around the nominal safe action. One can apply any\nexploration strategy where actions are chosen from such safe regions.\nExperiments on a stylized model of data center cooling dynamics show how\ncomputing proper safe regions can increase the sample efficiency of safe\nexploration.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 00:13:28 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Lu", "Tyler", ""], ["Zinkevich", "Martin", ""], ["Boutilier", "Craig", ""], ["Roy", "Binz", ""], ["Schuurmans", "Dale", ""]]}, {"id": "1711.11179", "submitter": "Manzil Zaheer", "authors": "Xun Zheng, Manzil Zaheer, Amr Ahmed, Yuan Wang, Eric P Xing, Alexander\n  J Smola", "title": "State Space LSTM Models with Particle MCMC Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short-Term Memory (LSTM) is one of the most powerful sequence models.\nDespite the strong performance, however, it lacks the nice interpretability as\nin state space models. In this paper, we present a way to combine the best of\nboth worlds by introducing State Space LSTM (SSL) models that generalizes the\nearlier work \\cite{zaheer2017latent} of combining topic models with LSTM.\nHowever, unlike \\cite{zaheer2017latent}, we do not make any factorization\nassumptions in our inference algorithm. We present an efficient sampler based\non sequential Monte Carlo (SMC) method that draws from the joint posterior\ndirectly. Experimental results confirms the superiority and stability of this\nSMC inference algorithm on a variety of domains.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 01:42:26 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Zheng", "Xun", ""], ["Zaheer", "Manzil", ""], ["Ahmed", "Amr", ""], ["Wang", "Yuan", ""], ["Xing", "Eric P", ""], ["Smola", "Alexander J", ""]]}, {"id": "1711.11225", "submitter": "Yunhao Tang", "authors": "Yunhao Tang and Alp Kucukelbir", "title": "Variational Deep Q Network", "comments": "12 pages, 5 figures, Second workshop on Bayesian Deep Learning (NIPS\n  2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework that directly tackles the probability distribution of\nthe value function parameters in Deep Q Network (DQN), with powerful\nvariational inference subroutines to approximate the posterior of the\nparameters. We will establish the equivalence between our proposed surrogate\nobjective and variational inference loss. Our new algorithm achieves efficient\nexploration and performs well on large scale chain Markov Decision Process\n(MDP).\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 04:52:09 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Tang", "Yunhao", ""], ["Kucukelbir", "Alp", ""]]}, {"id": "1711.11247", "submitter": "Shrinu Kushagra", "authors": "Shrinu Kushagra, Yaoliang Yu and Shai Ben-David", "title": "Provably noise-robust, regularised $k$-means clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of clustering in the presence of noise. That is, when\non top of cluster structure, the data also contains a subset of\n\\emph{unstructured} points. Our goal is to detect the clusters despite the\npresence of many unstructured points. Any algorithm that achieves this goal is\nnoise-robust. We consider a regularisation method which converts any\ncenter-based clustering objective into a noise-robust one. We focus on the\n$k$-means objective and we prove that the regularised version of $k$-means is\nNP-Hard even for $k=1$. We consider two algorithms based on the convex (sdp and\nlp) relaxation of the regularised objective and prove robustness guarantees for\nboth.\n  The sdp and lp relaxation of the standard (non-regularised) $k$-means\nobjective has been previously studied by [ABC+15]. Under the stochastic ball\nmodel of the data they show that the sdp-based algorithm recovers the\nunderlying structure as long as the balls are separated by $\\delta > 2\\sqrt{2}\n+ \\epsilon$. We improve upon this result in two ways. First, we show recovery\neven for $\\delta > 2 + \\epsilon$. Second, our regularised algorithm recovers\nthe balls even in the presence of noise so long as the number of noisy points\nis not too large. We complement our theoretical analysis with simulations and\nanalyse the effect of various parameters like regularization constant,\nnoise-level etc. on the performance of our algorithm. In the presence of noise,\nour algorithm performs better than $k$-means++ on MNIST.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 06:23:52 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 23:52:02 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2018 16:03:31 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Kushagra", "Shrinu", ""], ["Yu", "Yaoliang", ""], ["Ben-David", "Shai", ""]]}, {"id": "1711.11294", "submitter": "Wei Pan", "authors": "Xiaofan Lin, Cong Zhao, Wei Pan", "title": "Towards Accurate Binary Convolutional Neural Network", "comments": null, "journal-ref": "NIPS 2017", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a novel scheme to train binary convolutional neural networks\n(CNNs) -- CNNs with weights and activations constrained to {-1,+1} at run-time.\nIt has been known that using binary weights and activations drastically reduce\nmemory size and accesses, and can replace arithmetic operations with more\nefficient bitwise operations, leading to much faster test-time inference and\nlower power consumption. However, previous works on binarizing CNNs usually\nresult in severe prediction accuracy degradation. In this paper, we address\nthis issue with two major innovations: (1) approximating full-precision weights\nwith the linear combination of multiple binary weight bases; (2) employing\nmultiple binary activations to alleviate information loss. The implementation\nof the resulting binary CNN, denoted as ABC-Net, is shown to achieve much\ncloser performance to its full-precision counterpart, and even reach the\ncomparable prediction accuracy on ImageNet and forest trail datasets, given\nadequate binary weight bases and activations.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 09:58:14 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Lin", "Xiaofan", ""], ["Zhao", "Cong", ""], ["Pan", "Wei", ""]]}, {"id": "1711.11343", "submitter": "Patrick Sch\\\"afer", "authors": "Patrick Sch\\\"afer and Ulf Leser", "title": "Multivariate Time Series Classification with WEASEL+MUSE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series (MTS) arise when multiple interconnected sensors\nrecord data over time. Dealing with this high-dimensional data is challenging\nfor every classifier for at least two aspects: First, an MTS is not only\ncharacterized by individual feature values, but also by the interplay of\nfeatures in different dimensions. Second, this typically adds large amounts of\nirrelevant data and noise. We present our novel MTS classifier WEASEL+MUSE\nwhich addresses both challenges. WEASEL+MUSE builds a multivariate feature\nvector, first using a sliding-window approach applied to each dimension of the\nMTS, then extracts discrete features per window and dimension. The feature\nvector is subsequently fed through feature selection, removing\nnon-discriminative features, and analysed by a machine learning classifier. The\nnovelty of WEASEL+MUSE lies in its specific way of extracting and filtering\nmultivariate features from MTS by encoding context information into each\nfeature. Still the resulting feature set is small, yet very discriminative and\nuseful for MTS classification. Based on a popular benchmark of 20 MTS datasets,\nwe found that WEASEL+MUSE is among the most accurate classifiers, when compared\nto the state of the art. The outstanding robustness of WEASEL+MUSE is further\nconfirmed based on motion gesture recognition data, where it out-of-the-box\nachieved similar accuracies as domain-specific methods.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 12:36:35 GMT"}, {"version": "v2", "created": "Thu, 7 Dec 2017 20:39:57 GMT"}, {"version": "v3", "created": "Tue, 29 May 2018 13:03:34 GMT"}, {"version": "v4", "created": "Fri, 17 Aug 2018 14:37:09 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Sch\u00e4fer", "Patrick", ""], ["Leser", "Ulf", ""]]}, {"id": "1711.11383", "submitter": "Mostafa Dehghani", "authors": "Mostafa Dehghani, Aliaksei Severyn, Sascha Rothe, Jaap Kamps", "title": "Learning to Learn from Weak Supervision by Full Supervision", "comments": "Accepted at NIPS Workshop on Meta-Learning (MetaLearn 2017), Long\n  Beach, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a method for training neural networks when we have\na large set of data with weak labels and a small amount of data with true\nlabels. In our proposed model, we train two neural networks: a target network,\nthe learner and a confidence network, the meta-learner. The target network is\noptimized to perform a given task and is trained using a large set of unlabeled\ndata that are weakly annotated. We propose to control the magnitude of the\ngradient updates to the target network using the scores provided by the second\nconfidence network, which is trained on a small amount of supervised data. Thus\nwe avoid that the weight updates computed from noisy labels harm the quality of\nthe target network model.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 13:32:45 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Dehghani", "Mostafa", ""], ["Severyn", "Aliaksei", ""], ["Rothe", "Sascha", ""], ["Kamps", "Jaap", ""]]}, {"id": "1711.11417", "submitter": "Kim Peter Wabersich", "authors": "Kim P. Wabersich and Melanie N. Zeilinger", "title": "Scalable synthesis of safety certificates from data with application to\n  learning-based control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The control of complex systems faces a trade-off between high performance and\nsafety guarantees, which in particular restricts the application of\nlearning-based methods to safety-critical systems. A recently proposed\nframework to address this issue is the use of a safety controller, which\nguarantees to keep the system within a safe region of the state space. This\npaper introduces efficient techniques for the synthesis of a safe set and\ncontrol law, which offer improved scalability properties by relying on\napproximations based on convex optimization problems. The first proposed method\nrequires only an approximate linear system model and Lipschitz continuity of\nthe unknown nonlinear dynamics. The second method extends the results by\nshowing how a Gaussian process prior on the unknown system dynamics can be used\nin order to reduce conservatism of the resulting safe set. We demonstrate the\nresults with numerical examples, including an autonomous convoy of vehicles.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 14:23:54 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 19:32:13 GMT"}, {"version": "v3", "created": "Mon, 8 Apr 2019 10:28:49 GMT"}, {"version": "v4", "created": "Sun, 24 May 2020 12:09:55 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Wabersich", "Kim P.", ""], ["Zeilinger", "Melanie N.", ""]]}, {"id": "1711.11423", "submitter": "Remi Flamary", "authors": "Ibrahim El Khalil Harrane, R\\'emi Flamary, C\\'edric Richard", "title": "On reducing the communication cost of the diffusion LMS algorithm", "comments": null, "journal-ref": null, "doi": "10.1109/TSIPN.2018.2863218", "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of digital and mobile communications has recently made the world\nmore connected and networked, resulting in an unprecedented volume of data\nflowing between sources, data centers, or processes. While these data may be\nprocessed in a centralized manner, it is often more suitable to consider\ndistributed strategies such as diffusion as they are scalable and can handle\nlarge amounts of data by distributing tasks over networked agents. Although it\nis relatively simple to implement diffusion strategies over a cluster, it\nappears to be challenging to deploy them in an ad-hoc network with limited\nenergy budget for communication. In this paper, we introduce a diffusion LMS\nstrategy that significantly reduces communication costs without compromising\nthe performance. Then, we analyze the proposed algorithm in the mean and\nmean-square sense. Next, we conduct numerical experiments to confirm the\ntheoretical findings. Finally, we perform large scale simulations to test the\nalgorithm efficiency in a scenario where energy is limited.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 14:31:11 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 06:32:31 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Harrane", "Ibrahim El Khalil", ""], ["Flamary", "R\u00e9mi", ""], ["Richard", "C\u00e9dric", ""]]}, {"id": "1711.11438", "submitter": "EPTCS", "authors": "Rajeev Alur (1), Dana Fisman (2), Rishabh Singh (3), Armando\n  Solar-Lezama (4) ((1) University of Pennsylvania, (2) Ben-Gurion University,\n  (3) Microsoft Research, Redmond, (4) Massachusetts Institute of Technology)", "title": "SyGuS-Comp 2017: Results and Analysis", "comments": "In Proceedings SYNT 2017, arXiv:1711.10224. arXiv admin note: text\n  overlap with arXiv:1611.07627, arXiv:1602.01170", "journal-ref": "EPTCS 260, 2017, pp. 97-115", "doi": "10.4204/EPTCS.260.9", "report-no": null, "categories": "cs.SE cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntax-Guided Synthesis (SyGuS) is the computational problem of finding an\nimplementation f that meets both a semantic constraint given by a logical\nformula phi in a background theory T, and a syntactic constraint given by a\ngrammar G, which specifies the allowed set of candidate implementations. Such a\nsynthesis problem can be formally defined in SyGuS-IF, a language that is built\non top of SMT-LIB.\n  The Syntax-Guided Synthesis Competition (SyGuS-Comp) is an effort to\nfacilitate, bring together and accelerate research and development of efficient\nsolvers for SyGuS by providing a platform for evaluating different synthesis\ntechniques on a comprehensive set of benchmarks. In this year's competition six\nnew solvers competed on over 1500 benchmarks. This paper presents and analyses\nthe results of SyGuS-Comp'17.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 01:31:10 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Alur", "Rajeev", ""], ["Fisman", "Dana", ""], ["Singh", "Rishabh", ""], ["Solar-Lezama", "Armando", ""]]}, {"id": "1711.11443", "submitter": "Pierre Stock", "authors": "Pierre Stock and Moustapha Cisse", "title": "ConvNets and ImageNet Beyond Accuracy: Understanding Mistakes and\n  Uncovering Biases", "comments": "ECCV 2018 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ConvNets and Imagenet have driven the recent success of deep learning for\nimage classification. However, the marked slowdown in performance improvement\ncombined with the lack of robustness of neural networks to adversarial examples\nand their tendency to exhibit undesirable biases question the reliability of\nthese methods. This work investigates these questions from the perspective of\nthe end-user by using human subject studies and explanations. The contribution\nof this study is threefold. We first experimentally demonstrate that the\naccuracy and robustness of ConvNets measured on Imagenet are vastly\nunderestimated. Next, we show that explanations can mitigate the impact of\nmisclassified adversarial examples from the perspective of the end-user. We\nfinally introduce a novel tool for uncovering the undesirable biases learned by\na model. These contributions also show that explanations are a valuable tool\nboth for improving our understanding of ConvNets' predictions and for designing\nmore reliable models.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 14:50:55 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 16:57:30 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Stock", "Pierre", ""], ["Cisse", "Moustapha", ""]]}, {"id": "1711.11486", "submitter": "Pawe{\\l} Budzianowski", "authors": "Christopher Tegho, Pawe{\\l} Budzianowski, Milica Ga\\v{s}i\\'c", "title": "Uncertainty Estimates for Efficient Neural Network-based Dialogue Policy\n  Optimisation", "comments": "Accepted at the Bayesian Deep Learning Workshop, 31st Conference on\n  Neural Information Processing Systems (NIPS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In statistical dialogue management, the dialogue manager learns a policy that\nmaps a belief state to an action for the system to perform. Efficient\nexploration is key to successful policy optimisation. Current deep\nreinforcement learning methods are very promising but rely on epsilon-greedy\nexploration, thus subjecting the user to a random choice of action during\nlearning. Alternative approaches such as Gaussian Process SARSA (GPSARSA)\nestimate uncertainties and are sample efficient, leading to better user\nexperience, but on the expense of a greater computational complexity. This\npaper examines approaches to extract uncertainty estimates from deep Q-networks\n(DQN) in the context of dialogue management. We perform an extensive benchmark\nof deep Bayesian methods to extract uncertainty estimates, namely\nBayes-By-Backprop, dropout, its concrete variation, bootstrapped ensemble and\nalpha-divergences, combining it with DQN algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 16:09:02 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Tegho", "Christopher", ""], ["Budzianowski", "Pawe\u0142", ""], ["Ga\u0161i\u0107", "Milica", ""]]}, {"id": "1711.11503", "submitter": "Andreas Veit", "authors": "Andreas Veit, Serge Belongie", "title": "Convolutional Networks with Adaptive Inference Graphs", "comments": "IJCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Do convolutional networks really need a fixed feed-forward structure? What\nif, after identifying the high-level concept of an image, a network could move\ndirectly to a layer that can distinguish fine-grained differences? Currently, a\nnetwork would first need to execute sometimes hundreds of intermediate layers\nthat specialize in unrelated aspects. Ideally, the more a network already knows\nabout an image, the better it should be at deciding which layer to compute\nnext. In this work, we propose convolutional networks with adaptive inference\ngraphs (ConvNet-AIG) that adaptively define their network topology conditioned\non the input image. Following a high-level structure similar to residual\nnetworks (ResNets), ConvNet-AIG decides for each input image on the fly which\nlayers are needed. In experiments on ImageNet we show that ConvNet-AIG learns\ndistinct inference graphs for different categories. Both ConvNet-AIG with 50\nand 101 layers outperform their ResNet counterpart, while using 20% and 38%\nless computations respectively. By grouping parameters into layers for related\nclasses and only executing relevant layers, ConvNet-AIG improves both\nefficiency and overall classification quality. Lastly, we also study the effect\nof adaptive inference graphs on the susceptibility towards adversarial\nexamples. We observe that ConvNet-AIG shows a higher robustness than ResNets,\ncomplementing other known defense mechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 16:45:25 GMT"}, {"version": "v2", "created": "Tue, 24 Jul 2018 19:21:00 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 20:20:25 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Veit", "Andreas", ""], ["Belongie", "Serge", ""]]}, {"id": "1711.11527", "submitter": "Kshiteej Sheth Jitesh", "authors": "Kshiteej Sheth, Dinesh Garg and Anirban Dasgupta", "title": "Improved Linear Embeddings via Lagrange Duality", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Near isometric orthogonal embeddings to lower dimensions are a fundamental\ntool in data science and machine learning. In this paper, we present the\nconstruction of such embeddings that minimizes the maximum distortion for a\ngiven set of points. We formulate the problem as a non convex constrained\noptimization problem. We first construct a primal relaxation and then use the\ntheory of Lagrange duality to create dual relaxation. We also suggest a\npolynomial time algorithm based on the theory of convex optimization to solve\nthe dual relaxation provably. We provide a theoretical upper bound on the\napproximation guarantees for our algorithm, which depends only on the spectral\nproperties of the dataset. We experimentally demonstrate the superiority of our\nalgorithm compared to baselines in terms of the scalability and the ability to\nachieve lower distortion.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 17:31:56 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 14:37:02 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Sheth", "Kshiteej", ""], ["Garg", "Dinesh", ""], ["Dasgupta", "Anirban", ""]]}, {"id": "1711.11536", "submitter": "Steve Gallant", "authors": "Phil Culliton, Michael Levinson, Alice Ehresman, Joshua Wherry, Jay S.\n  Steingrub, Stephen I. Gallant", "title": "Predicting Severe Sepsis Using Text from the Electronic Health Record", "comments": "Accepted at workshop on Machine Learning For Health at the conference\n  on Neural Information Processing Systems, 2017. Near-final draft version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Employing a machine learning approach we predict, up to 24 hours prior, a\ndiagnosis of severe sepsis. Strongly predictive models are possible that use\nonly text reports from the Electronic Health Record (EHR), and omit structured\nnumerical data. Unstructured text alone gives slightly better performance than\nstructured data alone, and the combination further improves performance. We\nalso discuss advantages of using unstructured EHR text for modeling, as\ncompared to structured EHR data.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 17:52:07 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Culliton", "Phil", ""], ["Levinson", "Michael", ""], ["Ehresman", "Alice", ""], ["Wherry", "Joshua", ""], ["Steingrub", "Jay S.", ""], ["Gallant", "Stephen I.", ""]]}, {"id": "1711.11542", "submitter": "Alexander Ororbia II", "authors": "Alexander G. Ororbia II, Patrick Haffner, David Reitter, and C. Lee\n  Giles", "title": "Learning to Adapt by Minimizing Discrepancy", "comments": "Note: Additional experiments in support of this paper are still\n  running (updates will be made as they are completed)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore whether useful temporal neural generative models can be learned\nfrom sequential data without back-propagation through time. We investigate the\nviability of a more neurocognitively-grounded approach in the context of\nunsupervised generative modeling of sequences. Specifically, we build on the\nconcept of predictive coding, which has gained influence in cognitive science,\nin a neural framework. To do so we develop a novel architecture, the Temporal\nNeural Coding Network, and its learning algorithm, Discrepancy Reduction. The\nunderlying directed generative model is fully recurrent, meaning that it\nemploys structural feedback connections and temporal feedback connections,\nyielding information propagation cycles that create local learning signals.\nThis facilitates a unified bottom-up and top-down approach for information\ntransfer inside the architecture. Our proposed algorithm shows promise on the\nbouncing balls generative modeling problem. Further experiments could be\nconducted to explore the strengths and weaknesses of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 18:03:47 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Ororbia", "Alexander G.", "II"], ["Haffner", "Patrick", ""], ["Reitter", "David", ""], ["Giles", "C. Lee", ""]]}, {"id": "1711.11543", "submitter": "Abhishek Das", "authors": "Abhishek Das, Samyak Datta, Georgia Gkioxari, Stefan Lee, Devi Parikh,\n  Dhruv Batra", "title": "Embodied Question Answering", "comments": "20 pages, 13 figures, Webpage: https://embodiedqa.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new AI task -- Embodied Question Answering (EmbodiedQA) -- where\nan agent is spawned at a random location in a 3D environment and asked a\nquestion (\"What color is the car?\"). In order to answer, the agent must first\nintelligently navigate to explore the environment, gather information through\nfirst-person (egocentric) vision, and then answer the question (\"orange\").\n  This challenging task requires a range of AI skills -- active perception,\nlanguage understanding, goal-driven navigation, commonsense reasoning, and\ngrounding of language into actions. In this work, we develop the environments,\nend-to-end-trained reinforcement learning agents, and evaluation protocols for\nEmbodiedQA.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 18:06:47 GMT"}, {"version": "v2", "created": "Fri, 1 Dec 2017 16:55:05 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Das", "Abhishek", ""], ["Datta", "Samyak", ""], ["Gkioxari", "Georgia", ""], ["Lee", "Stefan", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "1711.11561", "submitter": "Jason Jo", "authors": "Jason Jo, Yoshua Bengio", "title": "Measuring the tendency of CNNs to Learn Surface Statistical Regularities", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep CNNs are known to exhibit the following peculiarity: on the one hand\nthey generalize extremely well to a test set, while on the other hand they are\nextremely sensitive to so-called adversarial perturbations. The extreme\nsensitivity of high performance CNNs to adversarial examples casts serious\ndoubt that these networks are learning high level abstractions in the dataset.\nWe are concerned with the following question: How can a deep CNN that does not\nlearn any high level semantics of the dataset manage to generalize so well? The\ngoal of this article is to measure the tendency of CNNs to learn surface\nstatistical regularities of the dataset. To this end, we use Fourier filtering\nto construct datasets which share the exact same high level abstractions but\nexhibit qualitatively different surface statistical regularities. For the SVHN\nand CIFAR-10 datasets, we present two Fourier filtered variants: a low\nfrequency variant and a randomly filtered variant. Each of the Fourier\nfiltering schemes is tuned to preserve the recognizability of the objects. Our\nmain finding is that CNNs exhibit a tendency to latch onto the Fourier image\nstatistics of the training dataset, sometimes exhibiting up to a 28%\ngeneralization gap across the various test sets. Moreover, we observe that\nsignificantly increasing the depth of a network has a very marginal impact on\nclosing the aforementioned generalization gap. Thus we provide quantitative\nevidence supporting the hypothesis that deep CNNs tend to learn surface\nstatistical regularities in the dataset rather than higher-level abstract\nconcepts.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 18:30:49 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Jo", "Jason", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1711.11566", "submitter": "Sergey Tulyakov", "authors": "Sergey Tulyakov, Andrew Fitzgibbon, Sebastian Nowozin", "title": "Hybrid VAE: Improving Deep Generative Models using Partial Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network models trained on large labeled datasets are the\nstate-of-the-art in a large variety of computer vision tasks. In many\napplications, however, labeled data is expensive to obtain or requires a time\nconsuming manual annotation process. In contrast, unlabeled data is often\nabundant and available in large quantities. We present a principled framework\nto capitalize on unlabeled data by training deep generative models on both\nlabeled and unlabeled data. We show that such a combination is beneficial\nbecause the unlabeled data acts as a data-driven form of regularization,\nallowing generative models trained on few labeled samples to reach the\nperformance of fully-supervised generative models trained on much larger\ndatasets. We call our method Hybrid VAE (H-VAE) as it contains both the\ngenerative and the discriminative parts. We validate H-VAE on three large-scale\ndatasets of different modalities: two face datasets: (MultiPIE, CelebA) and a\nhand pose dataset (NYU Hand Pose). Our qualitative visualizations further\nsupport improvements achieved by using partial observations.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 18:37:37 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Tulyakov", "Sergey", ""], ["Fitzgibbon", "Andrew", ""], ["Nowozin", "Sebastian", ""]]}, {"id": "1711.11581", "submitter": "David Steurer", "authors": "Pravesh K. Kothari and David Steurer", "title": "Outlier-robust moment-estimation via sum-of-squares", "comments": "Fix references for robust mean estimation without exploiting\n  higher-order moments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop efficient algorithms for estimating low-degree moments of unknown\ndistributions in the presence of adversarial outliers. The guarantees of our\nalgorithms improve in many cases significantly over the best previous ones,\nobtained in recent works of Diakonikolas et al, Lai et al, and Charikar et al.\nWe also show that the guarantees of our algorithms match information-theoretic\nlower-bounds for the class of distributions we consider. These improved\nguarantees allow us to give improved algorithms for independent component\nanalysis and learning mixtures of Gaussians in the presence of outliers.\n  Our algorithms are based on a standard sum-of-squares relaxation of the\nfollowing conceptually-simple optimization problem: Among all distributions\nwhose moments are bounded in the same way as for the unknown distribution, find\nthe one that is closest in statistical distance to the empirical distribution\nof the adversarially-corrupted sample.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 18:54:33 GMT"}, {"version": "v2", "created": "Sat, 23 Dec 2017 22:24:18 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Kothari", "Pravesh K.", ""], ["Steurer", "David", ""]]}, {"id": "1711.11585", "submitter": "Ting-Chun Wang", "authors": "Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Andrew Tao, Jan Kautz, Bryan\n  Catanzaro", "title": "High-Resolution Image Synthesis and Semantic Manipulation with\n  Conditional GANs", "comments": "v2: CVPR camera ready, adding more results for edge-to-photo examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for synthesizing high-resolution photo-realistic\nimages from semantic label maps using conditional generative adversarial\nnetworks (conditional GANs). Conditional GANs have enabled a variety of\napplications, but the results are often limited to low-resolution and still far\nfrom realistic. In this work, we generate 2048x1024 visually appealing results\nwith a novel adversarial loss, as well as new multi-scale generator and\ndiscriminator architectures. Furthermore, we extend our framework to\ninteractive visual manipulation with two additional features. First, we\nincorporate object instance segmentation information, which enables object\nmanipulations such as removing/adding objects and changing the object category.\nSecond, we propose a method to generate diverse results given the same input,\nallowing users to edit the object appearance interactively. Human opinion\nstudies demonstrate that our method significantly outperforms existing methods,\nadvancing both the quality and the resolution of deep image synthesis and\nediting.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 18:57:21 GMT"}, {"version": "v2", "created": "Mon, 20 Aug 2018 17:55:56 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Wang", "Ting-Chun", ""], ["Liu", "Ming-Yu", ""], ["Zhu", "Jun-Yan", ""], ["Tao", "Andrew", ""], ["Kautz", "Jan", ""], ["Catanzaro", "Bryan", ""]]}]